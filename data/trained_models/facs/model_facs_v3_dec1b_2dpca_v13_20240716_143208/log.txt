Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v13', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v13', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 319939569

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.468300998963566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.468300998963566 | validation: 1.2140067543261537]
	TIME [epoch: 23.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.357179008746068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.357179008746068 | validation: 1.1878569257868783]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3058747892301095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3058747892301095 | validation: 1.059828804966638]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2584677383162808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2584677383162808 | validation: 1.0671828082768906]
	TIME [epoch: 7.44 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2201439940285133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2201439940285133 | validation: 0.9722806586018548]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1916749744817812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1916749744817812 | validation: 0.9493598427166621]
	TIME [epoch: 7.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1490881474877321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1490881474877321 | validation: 1.047305404747233]
	TIME [epoch: 7.4 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.204556610649723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.204556610649723 | validation: 0.9399924302514175]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.061550616870434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.061550616870434 | validation: 0.9183858005159273]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0855858880087723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0855858880087723 | validation: 0.8413767067262505]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9674050631899417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9674050631899417 | validation: 0.834348817941534]
	TIME [epoch: 7.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.912998279576627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.912998279576627 | validation: 0.7848406113027832]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8167460127032934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8167460127032934 | validation: 0.7409173847877749]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7367222708850257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7367222708850257 | validation: 0.6597151939980838]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7049040107320264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7049040107320264 | validation: 0.6402334279277915]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6692921236776074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6692921236776074 | validation: 1.0268296683270326]
	TIME [epoch: 7.41 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7668708443112956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7668708443112956 | validation: 0.5143217325627657]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5229851091540504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5229851091540504 | validation: 0.4529228021263495]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47825133312160045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47825133312160045 | validation: 0.43331491285012297]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5482399773510408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5482399773510408 | validation: 0.4091181132295124]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4372048156084361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4372048156084361 | validation: 0.3829971038116554]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41733940666853303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41733940666853303 | validation: 0.4826129834271427]
	TIME [epoch: 7.28 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41901026412621495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41901026412621495 | validation: 0.3235284752619886]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3808197922679464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3808197922679464 | validation: 0.32125264497612205]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4011479672014427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4011479672014427 | validation: 0.31091199571018796]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3579631840514477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3579631840514477 | validation: 0.32815233073244976]
	TIME [epoch: 7.39 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3675434448393989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3675434448393989 | validation: 0.28985618113992395]
	TIME [epoch: 7.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3787055886829998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3787055886829998 | validation: 0.306923800985229]
	TIME [epoch: 7.38 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3549335015675445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3549335015675445 | validation: 0.2838533792118649]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3591869512771662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3591869512771662 | validation: 0.2777921673683442]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3526912147577257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3526912147577257 | validation: 0.26864355429965137]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3232553868469174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3232553868469174 | validation: 0.28836883398622415]
	TIME [epoch: 7.43 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38332804017743655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38332804017743655 | validation: 0.28038599667846154]
	TIME [epoch: 7.44 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32108437825748454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32108437825748454 | validation: 0.26798378647230253]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3219324135931051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219324135931051 | validation: 0.2571843832125954]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32237218567346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32237218567346 | validation: 0.2734196710459109]
	TIME [epoch: 7.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37911299721180414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37911299721180414 | validation: 0.2808492642549305]
	TIME [epoch: 7.41 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32809056911699136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32809056911699136 | validation: 0.29030656800935234]
	TIME [epoch: 7.41 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33359185321897183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33359185321897183 | validation: 0.2700043424250399]
	TIME [epoch: 7.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.337080845065828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.337080845065828 | validation: 0.2922684768847698]
	TIME [epoch: 7.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.307023650828742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.307023650828742 | validation: 0.2496728367745294]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3305138724854169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3305138724854169 | validation: 0.2589932364859915]
	TIME [epoch: 7.37 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30644469656008644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30644469656008644 | validation: 0.2621965859742629]
	TIME [epoch: 7.35 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32166682087293125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32166682087293125 | validation: 0.2579803781116338]
	TIME [epoch: 7.37 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31772560723575627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31772560723575627 | validation: 0.269670668879639]
	TIME [epoch: 7.36 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30360931625239435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30360931625239435 | validation: 0.2704488626059559]
	TIME [epoch: 7.36 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31386129256290846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31386129256290846 | validation: 0.2662827462448688]
	TIME [epoch: 7.36 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3223952077660455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3223952077660455 | validation: 0.2434482608733263]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29841430189529783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29841430189529783 | validation: 0.26376452260734]
	TIME [epoch: 7.39 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3069645045451811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3069645045451811 | validation: 0.25043217845099514]
	TIME [epoch: 7.37 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33074274223424366		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.33074274223424366 | validation: 0.25936182369682154]
	TIME [epoch: 28.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33365229532067264		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.33365229532067264 | validation: 0.26238214294265216]
	TIME [epoch: 14.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29441399193660983		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.29441399193660983 | validation: 0.24045472405262824]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2930305702386367		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.2930305702386367 | validation: 0.24121444300910197]
	TIME [epoch: 14.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29311738354229516		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.29311738354229516 | validation: 0.245735354355537]
	TIME [epoch: 14.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29578871902528975		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.29578871902528975 | validation: 0.24277046131979177]
	TIME [epoch: 14.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2929064969661955		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.2929064969661955 | validation: 0.2474306011148351]
	TIME [epoch: 14.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29324316493366326		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.29324316493366326 | validation: 0.23035374039677742]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2969248574705825		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.2969248574705825 | validation: 0.24982450489416586]
	TIME [epoch: 14.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31075526492123107		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.31075526492123107 | validation: 0.2353374096240568]
	TIME [epoch: 14.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3352844010216645		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.3352844010216645 | validation: 0.22644370122890672]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29045445181071977		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.29045445181071977 | validation: 0.23750297202580586]
	TIME [epoch: 14.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29099836523184347		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.29099836523184347 | validation: 0.2387835809703887]
	TIME [epoch: 14.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2986760066530862		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2986760066530862 | validation: 0.2417978833981346]
	TIME [epoch: 14.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3101988450000242		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.3101988450000242 | validation: 0.23119965027327732]
	TIME [epoch: 14.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2939052204665223		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.2939052204665223 | validation: 0.23090898114640276]
	TIME [epoch: 14.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2826234095314518		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.2826234095314518 | validation: 0.2650749032064465]
	TIME [epoch: 14.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29675297594747657		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.29675297594747657 | validation: 0.23703078296357472]
	TIME [epoch: 14.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29272052820363287		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.29272052820363287 | validation: 0.2227151830561533]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28505905266935766		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.28505905266935766 | validation: 0.2195016584549446]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2892436677881172		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.2892436677881172 | validation: 0.23306116736176924]
	TIME [epoch: 14.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27797840266807744		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.27797840266807744 | validation: 0.2314599641923838]
	TIME [epoch: 14.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2924084943003971		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2924084943003971 | validation: 0.2186613373465593]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30266726243227704		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.30266726243227704 | validation: 0.22554905720227744]
	TIME [epoch: 14.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817782440227716		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.2817782440227716 | validation: 0.23398359866878207]
	TIME [epoch: 14.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2738415752438105		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.2738415752438105 | validation: 0.2267046016197345]
	TIME [epoch: 14.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795019656546634		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2795019656546634 | validation: 0.23175754171676433]
	TIME [epoch: 14.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2975411956273522		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.2975411956273522 | validation: 0.24839827116525642]
	TIME [epoch: 14.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2856209141694925		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.2856209141694925 | validation: 0.2281172159100676]
	TIME [epoch: 14.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2796055769762796		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.2796055769762796 | validation: 0.2177400486492111]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27771997805000204		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.27771997805000204 | validation: 0.22624583797602232]
	TIME [epoch: 14.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875200662498516		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.2875200662498516 | validation: 0.23482856916787243]
	TIME [epoch: 14.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28951727922444603		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.28951727922444603 | validation: 0.23602457062199736]
	TIME [epoch: 14.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2956768403820377		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.2956768403820377 | validation: 0.21797888167150553]
	TIME [epoch: 14.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2715536010336855		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.2715536010336855 | validation: 0.2317427770341169]
	TIME [epoch: 14.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27172169812899266		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.27172169812899266 | validation: 0.22147489796794612]
	TIME [epoch: 14.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2777061988691994		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.2777061988691994 | validation: 0.22608040239736454]
	TIME [epoch: 14.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27071612514820914		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.27071612514820914 | validation: 0.21842650434756555]
	TIME [epoch: 14.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35962414039975227		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.35962414039975227 | validation: 0.3032251544184693]
	TIME [epoch: 14.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29176567441358925		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29176567441358925 | validation: 0.2312615286488852]
	TIME [epoch: 14.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26626846375614993		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.26626846375614993 | validation: 0.22765716845734577]
	TIME [epoch: 14.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28638156347791016		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.28638156347791016 | validation: 0.2228957139778614]
	TIME [epoch: 14.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27448180127337696		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.27448180127337696 | validation: 0.23412957874478324]
	TIME [epoch: 14.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799840948344745		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.2799840948344745 | validation: 0.22355201118123888]
	TIME [epoch: 14.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799381162000547		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2799381162000547 | validation: 0.23189634043665652]
	TIME [epoch: 14.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721919574085046		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.2721919574085046 | validation: 0.2311857832650274]
	TIME [epoch: 14.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29825513058543013		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.29825513058543013 | validation: 0.22711927175119836]
	TIME [epoch: 14.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665478185537954		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.2665478185537954 | validation: 0.21456866274764272]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802972492362263		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2802972492362263 | validation: 0.24865746976164055]
	TIME [epoch: 14.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28452931281186983		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.28452931281186983 | validation: 0.21867161208442223]
	TIME [epoch: 14.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2803956109769821		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.2803956109769821 | validation: 0.2318550072994355]
	TIME [epoch: 14.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26926439477928793		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.26926439477928793 | validation: 0.22208793079193873]
	TIME [epoch: 14.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2615163431606553		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2615163431606553 | validation: 0.21455093868035258]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26917457766910985		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.26917457766910985 | validation: 0.21865524290984575]
	TIME [epoch: 14.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629472504409547		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.2629472504409547 | validation: 0.23107310655131044]
	TIME [epoch: 14.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27473926405186644		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.27473926405186644 | validation: 0.22399354782318168]
	TIME [epoch: 14.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26305130599846527		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.26305130599846527 | validation: 0.24720076222318849]
	TIME [epoch: 14.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2881716139087214		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2881716139087214 | validation: 0.2389646625952789]
	TIME [epoch: 14.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270006870286891		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.270006870286891 | validation: 0.2277370150582753]
	TIME [epoch: 14.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2725095960035857		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.2725095960035857 | validation: 0.22161562350460345]
	TIME [epoch: 14.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2867686480592568		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2867686480592568 | validation: 0.22697550789037874]
	TIME [epoch: 14.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703160791616989		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2703160791616989 | validation: 0.219699483483404]
	TIME [epoch: 14.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26728789412106674		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.26728789412106674 | validation: 0.22591489986099367]
	TIME [epoch: 14.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27618462807615834		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.27618462807615834 | validation: 0.2266504618426645]
	TIME [epoch: 14.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751516582757649		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2751516582757649 | validation: 0.22026287087850785]
	TIME [epoch: 14.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691441014894623		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2691441014894623 | validation: 0.21866911809113465]
	TIME [epoch: 14.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2720850000296778		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2720850000296778 | validation: 0.21361962583278987]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25862230994400404		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.25862230994400404 | validation: 0.21224842646240766]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621454961286393		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.2621454961286393 | validation: 0.23098953909453446]
	TIME [epoch: 14.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30931184785772		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.30931184785772 | validation: 0.21879406470227752]
	TIME [epoch: 14.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676456941517599		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2676456941517599 | validation: 0.22437430078891962]
	TIME [epoch: 14.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42420919688764774		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.42420919688764774 | validation: 0.24867075764402263]
	TIME [epoch: 14.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2882262011836612		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2882262011836612 | validation: 0.20641475290135808]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621885070543608		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2621885070543608 | validation: 0.2174927770787546]
	TIME [epoch: 14.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26368451498638285		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.26368451498638285 | validation: 0.2175683446110676]
	TIME [epoch: 14.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26231712153980485		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.26231712153980485 | validation: 0.21129137275947577]
	TIME [epoch: 14.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599613187311338		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2599613187311338 | validation: 0.22931593884767856]
	TIME [epoch: 14.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2645628012214331		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.2645628012214331 | validation: 0.2133851361593096]
	TIME [epoch: 14.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26670287353620187		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.26670287353620187 | validation: 0.237104748113704]
	TIME [epoch: 14.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701321212949284		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.2701321212949284 | validation: 0.21776367737862384]
	TIME [epoch: 14.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571711607808031		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.2571711607808031 | validation: 0.23290934388106505]
	TIME [epoch: 14.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26122589669880447		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26122589669880447 | validation: 0.23789356346748605]
	TIME [epoch: 14.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2784310513765057		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2784310513765057 | validation: 0.22244583614078522]
	TIME [epoch: 14.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26319090997518324		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.26319090997518324 | validation: 0.21751956271977427]
	TIME [epoch: 14.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542217688623073		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2542217688623073 | validation: 0.2322483333782377]
	TIME [epoch: 14.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668356342270257		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2668356342270257 | validation: 0.21687517892400252]
	TIME [epoch: 14.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728816669957246		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2728816669957246 | validation: 0.22029212258390074]
	TIME [epoch: 14.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26344872775789385		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.26344872775789385 | validation: 0.2124200605417494]
	TIME [epoch: 14.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27153731904917416		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.27153731904917416 | validation: 0.23521211957471802]
	TIME [epoch: 14.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638120419939011		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2638120419939011 | validation: 0.22538073751364437]
	TIME [epoch: 14.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26117304187804563		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.26117304187804563 | validation: 0.22214830409662367]
	TIME [epoch: 14.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27261127780924416		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.27261127780924416 | validation: 0.21004603956334011]
	TIME [epoch: 14.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25484063709666954		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.25484063709666954 | validation: 0.22263910881797208]
	TIME [epoch: 14.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562299067116775		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2562299067116775 | validation: 0.21557913814602606]
	TIME [epoch: 14.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647586227804953		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2647586227804953 | validation: 0.23398851710864738]
	TIME [epoch: 14.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27215205056541975		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.27215205056541975 | validation: 0.22158961438757901]
	TIME [epoch: 14.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2633159225404837		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.2633159225404837 | validation: 0.22055326637958123]
	TIME [epoch: 14.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27352377082826684		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.27352377082826684 | validation: 0.2229981472939102]
	TIME [epoch: 14.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27222482503301093		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.27222482503301093 | validation: 0.21875529657987433]
	TIME [epoch: 14.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575682253891035		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2575682253891035 | validation: 0.2143464729985632]
	TIME [epoch: 14.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26103145159501384		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.26103145159501384 | validation: 0.21519691940358307]
	TIME [epoch: 14.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26941710945449193		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.26941710945449193 | validation: 0.23466516574437266]
	TIME [epoch: 14.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26888705416833897		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.26888705416833897 | validation: 0.2233461284941026]
	TIME [epoch: 14.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680219521703948		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2680219521703948 | validation: 0.21733258687997759]
	TIME [epoch: 14.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26028682753674587		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.26028682753674587 | validation: 0.22388188951552251]
	TIME [epoch: 14.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668856152619545		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2668856152619545 | validation: 0.22125094007842536]
	TIME [epoch: 14.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588411448249614		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2588411448249614 | validation: 0.21385243523863764]
	TIME [epoch: 14.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26471901556834987		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.26471901556834987 | validation: 0.22634249556846936]
	TIME [epoch: 14.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25633064896245544		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.25633064896245544 | validation: 0.21823605209279778]
	TIME [epoch: 14.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27213742795332774		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.27213742795332774 | validation: 0.21825710192251732]
	TIME [epoch: 14.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26504143499264693		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.26504143499264693 | validation: 0.21908685468637706]
	TIME [epoch: 14.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689853218500576		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2689853218500576 | validation: 0.21983572320251307]
	TIME [epoch: 14.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2622590781213244		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2622590781213244 | validation: 0.22569504454791645]
	TIME [epoch: 14.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26076585500283606		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.26076585500283606 | validation: 0.22530327565539654]
	TIME [epoch: 14.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578610677444194		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.2578610677444194 | validation: 0.21953075881447784]
	TIME [epoch: 14.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25946000826342686		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.25946000826342686 | validation: 0.22071695910815645]
	TIME [epoch: 14.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25987599122874144		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.25987599122874144 | validation: 0.21435381399752992]
	TIME [epoch: 14.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26761308788386556		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.26761308788386556 | validation: 0.2141064525219189]
	TIME [epoch: 14.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632454461214216		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.2632454461214216 | validation: 0.21439613735018082]
	TIME [epoch: 14.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27603253176189474		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.27603253176189474 | validation: 0.22040007360831995]
	TIME [epoch: 14.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26905883403847974		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.26905883403847974 | validation: 0.21510027240390306]
	TIME [epoch: 14.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584056514742191		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2584056514742191 | validation: 0.21713157123816024]
	TIME [epoch: 14.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25857639971286184		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.25857639971286184 | validation: 0.21779102315540172]
	TIME [epoch: 14.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249823408660007		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.249823408660007 | validation: 0.22539828016524505]
	TIME [epoch: 14.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26362706825388804		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.26362706825388804 | validation: 0.21626582990582302]
	TIME [epoch: 14.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25402861095918444		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.25402861095918444 | validation: 0.21723124717214262]
	TIME [epoch: 14.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25553738947645155		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.25553738947645155 | validation: 0.2185427199590638]
	TIME [epoch: 14.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555232421441194		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2555232421441194 | validation: 0.22223212701637066]
	TIME [epoch: 14.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592270718229152		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2592270718229152 | validation: 0.22980150271759298]
	TIME [epoch: 14.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584449146967948		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2584449146967948 | validation: 0.22105757624811498]
	TIME [epoch: 14.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697669068175668		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2697669068175668 | validation: 0.23250348943606128]
	TIME [epoch: 14.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28186704085928693		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.28186704085928693 | validation: 0.2208076021612846]
	TIME [epoch: 14.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506031344157728		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2506031344157728 | validation: 0.23318136799157138]
	TIME [epoch: 14.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26595966602960797		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.26595966602960797 | validation: 0.21155573335886335]
	TIME [epoch: 14.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25870920392986996		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.25870920392986996 | validation: 0.2311576101729393]
	TIME [epoch: 14.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25906550762357355		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.25906550762357355 | validation: 0.2196407933944729]
	TIME [epoch: 14.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25361577226076615		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25361577226076615 | validation: 0.21599373148992024]
	TIME [epoch: 14.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25782099709678546		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.25782099709678546 | validation: 0.22585581483046138]
	TIME [epoch: 14.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25454358727811693		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.25454358727811693 | validation: 0.22655128732697732]
	TIME [epoch: 14.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25941021993014696		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.25941021993014696 | validation: 0.22044692887678333]
	TIME [epoch: 14.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586566982171347		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2586566982171347 | validation: 0.2328620371302869]
	TIME [epoch: 14.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26410838166169803		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.26410838166169803 | validation: 0.21862196133343267]
	TIME [epoch: 14.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26489182210789436		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.26489182210789436 | validation: 0.21895725879506056]
	TIME [epoch: 14.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579166495259198		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2579166495259198 | validation: 0.2177088196538805]
	TIME [epoch: 14.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28177688156782765		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.28177688156782765 | validation: 0.2360892344296089]
	TIME [epoch: 14.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24963101051394884		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.24963101051394884 | validation: 0.21550280066490402]
	TIME [epoch: 14.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596344717713391		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.2596344717713391 | validation: 0.21993108340703676]
	TIME [epoch: 14.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25579742543767164		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.25579742543767164 | validation: 0.23008642687361286]
	TIME [epoch: 14.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26598860723345824		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.26598860723345824 | validation: 0.2191670904600309]
	TIME [epoch: 14.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638936850015968		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2638936850015968 | validation: 0.22156903392915384]
	TIME [epoch: 14.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25318200136224783		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25318200136224783 | validation: 0.21421200204767848]
	TIME [epoch: 14.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794434500374137		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.2794434500374137 | validation: 0.2262691219850244]
	TIME [epoch: 14.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555620686009657		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2555620686009657 | validation: 0.22370058572964197]
	TIME [epoch: 14.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578354285612633		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2578354285612633 | validation: 0.21043259573089265]
	TIME [epoch: 14.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503461461457339		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2503461461457339 | validation: 0.21387841593981016]
	TIME [epoch: 14.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25677971884402623		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.25677971884402623 | validation: 0.239121175543164]
	TIME [epoch: 14.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709328878991448		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.2709328878991448 | validation: 0.22572937534274665]
	TIME [epoch: 14.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595131781259973		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2595131781259973 | validation: 0.21355704842058487]
	TIME [epoch: 14.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27605336488706494		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.27605336488706494 | validation: 0.22164656598613613]
	TIME [epoch: 14.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25275607343370865		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.25275607343370865 | validation: 0.22144627172188577]
	TIME [epoch: 14.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546088983452119		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2546088983452119 | validation: 0.22978740074375584]
	TIME [epoch: 14.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580481214373492		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2580481214373492 | validation: 0.21190652005921035]
	TIME [epoch: 14.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25745051574423655		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.25745051574423655 | validation: 0.2197840714978016]
	TIME [epoch: 14.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701063899634723		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2701063899634723 | validation: 0.21306218947321098]
	TIME [epoch: 14.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24867202717866832		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.24867202717866832 | validation: 0.22231261124857685]
	TIME [epoch: 14.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26418355810016325		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.26418355810016325 | validation: 0.2192148168805928]
	TIME [epoch: 14.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27156281159844037		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.27156281159844037 | validation: 0.2121181964812176]
	TIME [epoch: 14.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26082897862990123		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.26082897862990123 | validation: 0.21398424579782627]
	TIME [epoch: 14.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25176231999574133		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.25176231999574133 | validation: 0.22708422315348226]
	TIME [epoch: 14.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614049452288389		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2614049452288389 | validation: 0.22842499704191618]
	TIME [epoch: 14.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619671330980157		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.2619671330980157 | validation: 0.21733728952726863]
	TIME [epoch: 14.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605861032392986		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2605861032392986 | validation: 0.2296345958571296]
	TIME [epoch: 14.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26138311961850275		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.26138311961850275 | validation: 0.2217327288307584]
	TIME [epoch: 14.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576177581795645		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2576177581795645 | validation: 0.21006637173632817]
	TIME [epoch: 14.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528466638295552		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2528466638295552 | validation: 0.2180693428177297]
	TIME [epoch: 14.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517251629665351		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2517251629665351 | validation: 0.21390860653997912]
	TIME [epoch: 14.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542195889254178		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2542195889254178 | validation: 0.22960736986449465]
	TIME [epoch: 14.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28745498625174887		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.28745498625174887 | validation: 0.2108038129111307]
	TIME [epoch: 14.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27054016048492385		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.27054016048492385 | validation: 0.21100876681000344]
	TIME [epoch: 14.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25137593670454317		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25137593670454317 | validation: 0.207989272711845]
	TIME [epoch: 14.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553885749303721		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2553885749303721 | validation: 0.21111140954766744]
	TIME [epoch: 14.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531707071023029		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2531707071023029 | validation: 0.21683611967250135]
	TIME [epoch: 14.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568894021330947		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.2568894021330947 | validation: 0.22095087221560045]
	TIME [epoch: 14.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259345646500274		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.259345646500274 | validation: 0.2217416955169303]
	TIME [epoch: 14.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25938449100171185		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.25938449100171185 | validation: 0.216211465936206]
	TIME [epoch: 14.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661258261112102		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2661258261112102 | validation: 0.20899271695275803]
	TIME [epoch: 14.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25560376030064147		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25560376030064147 | validation: 0.21009224360786655]
	TIME [epoch: 14.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24801784686515113		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.24801784686515113 | validation: 0.21545029661488307]
	TIME [epoch: 14.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25709687073289045		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.25709687073289045 | validation: 0.21811251575370197]
	TIME [epoch: 14.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26351533911296227		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.26351533911296227 | validation: 0.22265616843935274]
	TIME [epoch: 14.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25515465743909965		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.25515465743909965 | validation: 0.2089528308484887]
	TIME [epoch: 14.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24924239524162048		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.24924239524162048 | validation: 0.21281171169383986]
	TIME [epoch: 14.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25739752202145877		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.25739752202145877 | validation: 0.21410833284614078]
	TIME [epoch: 14.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25792955489400643		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.25792955489400643 | validation: 0.22108501025375923]
	TIME [epoch: 14.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716351003643986		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.2716351003643986 | validation: 0.20459034190381434]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25268878377258713		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.25268878377258713 | validation: 0.21218183844891572]
	TIME [epoch: 14.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25119382714683686		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.25119382714683686 | validation: 0.22081565990343677]
	TIME [epoch: 14.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544493307021258		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.2544493307021258 | validation: 0.2162739043544461]
	TIME [epoch: 14.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24848709410476377		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.24848709410476377 | validation: 0.21768977432993694]
	TIME [epoch: 14.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512752655091657		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2512752655091657 | validation: 0.21063968066549776]
	TIME [epoch: 14.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25942229877277584		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.25942229877277584 | validation: 0.21332880131849818]
	TIME [epoch: 14.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517528716755051		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.2517528716755051 | validation: 0.22334976645583032]
	TIME [epoch: 14.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24653169152407117		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.24653169152407117 | validation: 0.20520486961638862]
	TIME [epoch: 14.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24621269930878473		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.24621269930878473 | validation: 0.21576516156253672]
	TIME [epoch: 14.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26038492439714683		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.26038492439714683 | validation: 0.2150442516369034]
	TIME [epoch: 14.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25416382419839784		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.25416382419839784 | validation: 0.21582486752868418]
	TIME [epoch: 14.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513049930641682		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2513049930641682 | validation: 0.22205648510588188]
	TIME [epoch: 14.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537937847352729		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2537937847352729 | validation: 0.21754421653708578]
	TIME [epoch: 14.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571430207700584		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.2571430207700584 | validation: 0.22232842022338875]
	TIME [epoch: 14.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534085623107818		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.2534085623107818 | validation: 0.21547515089779523]
	TIME [epoch: 14.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880713445785085		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.24880713445785085 | validation: 0.21805054597585122]
	TIME [epoch: 14.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25237352323821977		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.25237352323821977 | validation: 0.22375066723647272]
	TIME [epoch: 14.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564678484186431		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2564678484186431 | validation: 0.21972424377469083]
	TIME [epoch: 14.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25760665672408123		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.25760665672408123 | validation: 0.21199317557833144]
	TIME [epoch: 14.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26220342737178565		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.26220342737178565 | validation: 0.21339868469066578]
	TIME [epoch: 14.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25194464257285865		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.25194464257285865 | validation: 0.2205792016025042]
	TIME [epoch: 14.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513439399503537		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2513439399503537 | validation: 0.21405093022949356]
	TIME [epoch: 14.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25430411806978925		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25430411806978925 | validation: 0.21721998827557704]
	TIME [epoch: 14.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636549054319368		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2636549054319368 | validation: 0.2245340018960691]
	TIME [epoch: 14.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541392072844396		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2541392072844396 | validation: 0.2162720945696789]
	TIME [epoch: 14.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25260858050043483		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.25260858050043483 | validation: 0.2164583770274676]
	TIME [epoch: 14.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517761047194362		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2517761047194362 | validation: 0.2202550997926341]
	TIME [epoch: 14.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650320364729673		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.2650320364729673 | validation: 0.22656507849368118]
	TIME [epoch: 14.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259875856726791		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.259875856726791 | validation: 0.21806704990690368]
	TIME [epoch: 14.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541398341593328		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2541398341593328 | validation: 0.2083167937126209]
	TIME [epoch: 14.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25585733919187725		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.25585733919187725 | validation: 0.22086108020964978]
	TIME [epoch: 14.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24388934988681132		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.24388934988681132 | validation: 0.2115509884800384]
	TIME [epoch: 14.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24887607402664216		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.24887607402664216 | validation: 0.2057171192733131]
	TIME [epoch: 14.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24753644937806937		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.24753644937806937 | validation: 0.2187204743805598]
	TIME [epoch: 14.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553342523595769		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2553342523595769 | validation: 0.2240335383720935]
	TIME [epoch: 14.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525505196370011		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2525505196370011 | validation: 0.21341168905589208]
	TIME [epoch: 14.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526063874410209		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2526063874410209 | validation: 0.21914783631413176]
	TIME [epoch: 14.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053207963113644		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.25053207963113644 | validation: 0.21298984606773294]
	TIME [epoch: 14.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512680353293982		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2512680353293982 | validation: 0.21382382885990286]
	TIME [epoch: 14.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25527165179484		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.25527165179484 | validation: 0.2185161007762106]
	TIME [epoch: 14.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527430586286161		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.2527430586286161 | validation: 0.21204743791544928]
	TIME [epoch: 14.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575848571278004		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2575848571278004 | validation: 0.22077067429083103]
	TIME [epoch: 14.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514811867499432		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2514811867499432 | validation: 0.21895502882345785]
	TIME [epoch: 14.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513762933014854		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2513762933014854 | validation: 0.21705300242243203]
	TIME [epoch: 14.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934621917305863		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.24934621917305863 | validation: 0.2192619965837952]
	TIME [epoch: 14.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25625179238479495		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.25625179238479495 | validation: 0.20870599023536962]
	TIME [epoch: 14.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25504361143927734		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25504361143927734 | validation: 0.21399706481428965]
	TIME [epoch: 14.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25741260237500657		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.25741260237500657 | validation: 0.22012924856629645]
	TIME [epoch: 14.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24825648042743934		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.24825648042743934 | validation: 0.21760146121472396]
	TIME [epoch: 14.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472892052820974		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2472892052820974 | validation: 0.21293152372592994]
	TIME [epoch: 14.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500754321947201		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2500754321947201 | validation: 0.22940254657238696]
	TIME [epoch: 14.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621772024189115		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.2621772024189115 | validation: 0.2215225020832617]
	TIME [epoch: 14.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559453656101999		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.2559453656101999 | validation: 0.21911417272810568]
	TIME [epoch: 14.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588972007395762		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.24588972007395762 | validation: 0.2148583149562932]
	TIME [epoch: 14.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545940446903029		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2545940446903029 | validation: 0.221243699388234]
	TIME [epoch: 14.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511946435055819		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2511946435055819 | validation: 0.21685546822326468]
	TIME [epoch: 14.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555300451317291		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2555300451317291 | validation: 0.23052324521210038]
	TIME [epoch: 14.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257791565147717		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.257791565147717 | validation: 0.21315957340448266]
	TIME [epoch: 14.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544839079703578		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.2544839079703578 | validation: 0.21753815452326272]
	TIME [epoch: 14.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641351260415686		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.2641351260415686 | validation: 0.21692819802232766]
	TIME [epoch: 14.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24911022861113571		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24911022861113571 | validation: 0.2118797918036317]
	TIME [epoch: 14.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252449749687784		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.252449749687784 | validation: 0.2170291820188226]
	TIME [epoch: 14.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2658142130856085		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.2658142130856085 | validation: 0.21265306439246964]
	TIME [epoch: 14.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24843229416231413		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24843229416231413 | validation: 0.21564535602810447]
	TIME [epoch: 14.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596177961917004		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2596177961917004 | validation: 0.21791509257992336]
	TIME [epoch: 14.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579605966421334		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.2579605966421334 | validation: 0.21338814971020623]
	TIME [epoch: 14.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546959837890192		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2546959837890192 | validation: 0.21891067700343364]
	TIME [epoch: 14.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25045990014358627		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25045990014358627 | validation: 0.21467128465287927]
	TIME [epoch: 14.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522596107544796		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.2522596107544796 | validation: 0.21124627819531896]
	TIME [epoch: 14.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24926883681886314		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.24926883681886314 | validation: 0.21950809718243564]
	TIME [epoch: 14.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24729064283720817		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.24729064283720817 | validation: 0.22163543913485953]
	TIME [epoch: 14.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539016448685656		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.2539016448685656 | validation: 0.22423031076921843]
	TIME [epoch: 14.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250098151514091		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.250098151514091 | validation: 0.2155964743460644]
	TIME [epoch: 14.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25665616131125146		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.25665616131125146 | validation: 0.2141403367589138]
	TIME [epoch: 14.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486220682787028		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2486220682787028 | validation: 0.21408095836577953]
	TIME [epoch: 14.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578844501164154		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2578844501164154 | validation: 0.22173704338464334]
	TIME [epoch: 14.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25430975626271846		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25430975626271846 | validation: 0.2154644779392339]
	TIME [epoch: 14.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25134437295191664		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.25134437295191664 | validation: 0.21088692678681115]
	TIME [epoch: 14.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465419972727895		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2465419972727895 | validation: 0.21231928926476668]
	TIME [epoch: 14.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521239268297326		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.2521239268297326 | validation: 0.2178691808311802]
	TIME [epoch: 14.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24983391569425342		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.24983391569425342 | validation: 0.21867467392192416]
	TIME [epoch: 14.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24933312825574536		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.24933312825574536 | validation: 0.22330058284480653]
	TIME [epoch: 14.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24571889085630141		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.24571889085630141 | validation: 0.21534596783942878]
	TIME [epoch: 14.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539557677909808		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2539557677909808 | validation: 0.21043175807340572]
	TIME [epoch: 14.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24610009794633814		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24610009794633814 | validation: 0.2235613533117368]
	TIME [epoch: 14.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24977739359692167		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.24977739359692167 | validation: 0.21948014361731052]
	TIME [epoch: 14.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345370172177525		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24345370172177525 | validation: 0.22177930267990784]
	TIME [epoch: 14.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25095807747235804		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.25095807747235804 | validation: 0.22689624965415783]
	TIME [epoch: 14.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25794563434178924		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.25794563434178924 | validation: 0.2107051103781028]
	TIME [epoch: 14.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25363776428004636		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.25363776428004636 | validation: 0.21503671836385047]
	TIME [epoch: 14.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531586332512722		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2531586332512722 | validation: 0.2131460628861924]
	TIME [epoch: 14.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24314288699996722		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.24314288699996722 | validation: 0.221173647869611]
	TIME [epoch: 14.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522330206859639		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.2522330206859639 | validation: 0.21481506635846923]
	TIME [epoch: 14.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511343381199677		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2511343381199677 | validation: 0.21793066584909573]
	TIME [epoch: 14.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533797758921235		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2533797758921235 | validation: 0.20554872871467147]
	TIME [epoch: 14.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584474154259613		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.2584474154259613 | validation: 0.22045139049364354]
	TIME [epoch: 14.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797798147657013		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.24797798147657013 | validation: 0.2135105877133649]
	TIME [epoch: 14.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502817356342097		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2502817356342097 | validation: 0.21428579135582337]
	TIME [epoch: 14.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25019948749863613		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.25019948749863613 | validation: 0.21915438450332111]
	TIME [epoch: 14.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535605093771665		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.2535605093771665 | validation: 0.22079656135007011]
	TIME [epoch: 14.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546562824900767		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2546562824900767 | validation: 0.2182680618725759]
	TIME [epoch: 14.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25787257064473595		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.25787257064473595 | validation: 0.21451436183830866]
	TIME [epoch: 14.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471993944778292		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2471993944778292 | validation: 0.21894871529783783]
	TIME [epoch: 14.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25281883905918345		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.25281883905918345 | validation: 0.21513005347737027]
	TIME [epoch: 14.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25137996298039633		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.25137996298039633 | validation: 0.22131803399345054]
	TIME [epoch: 14.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517092030651466		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2517092030651466 | validation: 0.21791198520206137]
	TIME [epoch: 14.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473547785309194		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2473547785309194 | validation: 0.21008192320725855]
	TIME [epoch: 14.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25438133678878116		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.25438133678878116 | validation: 0.21151772366532606]
	TIME [epoch: 14.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24578887440962846		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.24578887440962846 | validation: 0.2160462638991501]
	TIME [epoch: 14.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24530916338871248		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.24530916338871248 | validation: 0.2143062337816663]
	TIME [epoch: 14.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24852179978626965		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.24852179978626965 | validation: 0.21089496303683145]
	TIME [epoch: 14.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24956033459343588		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.24956033459343588 | validation: 0.2163144740424526]
	TIME [epoch: 14.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24551922594934691		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.24551922594934691 | validation: 0.20487376522181053]
	TIME [epoch: 14.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527644493295073		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2527644493295073 | validation: 0.21340775521478453]
	TIME [epoch: 14.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24949994727298966		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24949994727298966 | validation: 0.20654456654203884]
	TIME [epoch: 14.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24916532407497596		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.24916532407497596 | validation: 0.22075384339563592]
	TIME [epoch: 14.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518546166559707		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.2518546166559707 | validation: 0.2127737831416568]
	TIME [epoch: 14.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24855709765931164		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.24855709765931164 | validation: 0.22204825291999342]
	TIME [epoch: 14.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25899510322643554		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.25899510322643554 | validation: 0.217489452191001]
	TIME [epoch: 14.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25373866581739163		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.25373866581739163 | validation: 0.21514413228326826]
	TIME [epoch: 14.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478104062500958		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2478104062500958 | validation: 0.2186921453628896]
	TIME [epoch: 14.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27033082352867527		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.27033082352867527 | validation: 0.22589661933464153]
	TIME [epoch: 14.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545146166389311		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.2545146166389311 | validation: 0.21498777807754088]
	TIME [epoch: 14.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24869027812113154		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.24869027812113154 | validation: 0.22242464807691706]
	TIME [epoch: 14.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24720203415342992		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.24720203415342992 | validation: 0.21370821593765105]
	TIME [epoch: 14.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24878785355132083		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.24878785355132083 | validation: 0.21772694298790257]
	TIME [epoch: 14.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565291067886405		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2565291067886405 | validation: 0.20973248939318062]
	TIME [epoch: 14.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482331898844974		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2482331898844974 | validation: 0.21008211361415924]
	TIME [epoch: 14.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24787647163458668		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.24787647163458668 | validation: 0.2138106910407612]
	TIME [epoch: 14.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312108059839994		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.25312108059839994 | validation: 0.21274408882450735]
	TIME [epoch: 14.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471271914315847		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.2471271914315847 | validation: 0.21778964916839683]
	TIME [epoch: 14.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522189111276696		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2522189111276696 | validation: 0.21698684646971195]
	TIME [epoch: 14.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24964048960091922		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24964048960091922 | validation: 0.21490869953703112]
	TIME [epoch: 14.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25407100789887305		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.25407100789887305 | validation: 0.21609030611929736]
	TIME [epoch: 14.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25678607873091114		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.25678607873091114 | validation: 0.20918555641860442]
	TIME [epoch: 14.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25386143100210457		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.25386143100210457 | validation: 0.20887220587985408]
	TIME [epoch: 14.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25730109626406006		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.25730109626406006 | validation: 0.21198565363436273]
	TIME [epoch: 14.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899185252680436		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.24899185252680436 | validation: 0.20659533910681455]
	TIME [epoch: 14.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050201434439373		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.25050201434439373 | validation: 0.20867786477770256]
	TIME [epoch: 14.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24633931614752277		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24633931614752277 | validation: 0.2128152679753057]
	TIME [epoch: 14.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454740524582075		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.2454740524582075 | validation: 0.21450840304365681]
	TIME [epoch: 14.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532447755848915		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2532447755848915 | validation: 0.2171241158485079]
	TIME [epoch: 14.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559967504998801		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.2559967504998801 | validation: 0.2138801229854636]
	TIME [epoch: 14.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522419097817184		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.2522419097817184 | validation: 0.20749506577017476]
	TIME [epoch: 14.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25224902470619803		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.25224902470619803 | validation: 0.21092428713479466]
	TIME [epoch: 14.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498432603728862		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.2498432603728862 | validation: 0.2131459760405936]
	TIME [epoch: 14.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459320834252662		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24459320834252662 | validation: 0.2107841265119948]
	TIME [epoch: 14.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24619961301110807		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.24619961301110807 | validation: 0.2095584275803343]
	TIME [epoch: 14.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518552479836734		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2518552479836734 | validation: 0.21665241928184079]
	TIME [epoch: 14.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256379308208206		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.256379308208206 | validation: 0.22335023949059404]
	TIME [epoch: 14.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24752238623234446		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24752238623234446 | validation: 0.21244843844093234]
	TIME [epoch: 14.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25229485091322684		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.25229485091322684 | validation: 0.2081269293664135]
	TIME [epoch: 14.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504123952867548		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2504123952867548 | validation: 0.22437654563545215]
	TIME [epoch: 14.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482553366994603		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2482553366994603 | validation: 0.2123444385600513]
	TIME [epoch: 14.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500600962490492		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2500600962490492 | validation: 0.21377916480830242]
	TIME [epoch: 14.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24274933816819658		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24274933816819658 | validation: 0.2123640424422441]
	TIME [epoch: 14.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24898980783153538		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24898980783153538 | validation: 0.21186138011454694]
	TIME [epoch: 14.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431754992279966		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.2431754992279966 | validation: 0.21736062807660414]
	TIME [epoch: 14.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478811126433782		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.2478811126433782 | validation: 0.22127441794921832]
	TIME [epoch: 14.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24650347489342436		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24650347489342436 | validation: 0.21913132920020076]
	TIME [epoch: 14.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25457021517605555		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.25457021517605555 | validation: 0.22367798379779877]
	TIME [epoch: 14.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25082083324156595		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.25082083324156595 | validation: 0.21877828037474586]
	TIME [epoch: 14.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24868268357495996		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.24868268357495996 | validation: 0.2095661510641776]
	TIME [epoch: 14.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24992379269047585		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24992379269047585 | validation: 0.21400470289016021]
	TIME [epoch: 14.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24697205239981024		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.24697205239981024 | validation: 0.21428700483507157]
	TIME [epoch: 14.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24568533131392004		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24568533131392004 | validation: 0.21541448185904621]
	TIME [epoch: 14.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491099018704724		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.2491099018704724 | validation: 0.21690117017121055]
	TIME [epoch: 14.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551032101331037		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2551032101331037 | validation: 0.21195978478207927]
	TIME [epoch: 14.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517950465578342		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.2517950465578342 | validation: 0.20910947192746762]
	TIME [epoch: 14.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539662346341054		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.2539662346341054 | validation: 0.22097220562101474]
	TIME [epoch: 14.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522943595915283		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.2522943595915283 | validation: 0.21069055294521805]
	TIME [epoch: 14.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24022584721493376		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24022584721493376 | validation: 0.20976807904637346]
	TIME [epoch: 14.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24881177451224587		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24881177451224587 | validation: 0.209718495865918]
	TIME [epoch: 14.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24472070832514678		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24472070832514678 | validation: 0.21053434102948407]
	TIME [epoch: 14.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474431649377531		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.2474431649377531 | validation: 0.21097514278393792]
	TIME [epoch: 14.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24625566688077563		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24625566688077563 | validation: 0.21391807008261193]
	TIME [epoch: 14.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25398688595132585		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.25398688595132585 | validation: 0.20942829581822622]
	TIME [epoch: 14.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628064433142186		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.24628064433142186 | validation: 0.20914681657454107]
	TIME [epoch: 14.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24625027230228969		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24625027230228969 | validation: 0.2232740262236106]
	TIME [epoch: 14.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24338403784831705		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.24338403784831705 | validation: 0.21785261992999402]
	TIME [epoch: 14.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505182667243426		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2505182667243426 | validation: 0.2134072669660089]
	TIME [epoch: 14.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446407836310804		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.2446407836310804 | validation: 0.21014769936098715]
	TIME [epoch: 14.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25469716295920103		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.25469716295920103 | validation: 0.20878941695543957]
	TIME [epoch: 14.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24926038439831358		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24926038439831358 | validation: 0.21973927151509826]
	TIME [epoch: 14.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25012499289719675		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.25012499289719675 | validation: 0.21814828481028817]
	TIME [epoch: 14.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436209044575511		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.2436209044575511 | validation: 0.21683725994282416]
	TIME [epoch: 14.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425028918968204		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2425028918968204 | validation: 0.20802628619235017]
	TIME [epoch: 14.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050282269528706		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.25050282269528706 | validation: 0.20781351809896784]
	TIME [epoch: 14.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24226192711566427		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24226192711566427 | validation: 0.22080373841341014]
	TIME [epoch: 14.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24851624464164437		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.24851624464164437 | validation: 0.21535644592911143]
	TIME [epoch: 14.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656628131276792		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.24656628131276792 | validation: 0.21452477462752575]
	TIME [epoch: 14.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24922476588924525		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.24922476588924525 | validation: 0.20797111855121503]
	TIME [epoch: 14.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24701160737016528		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.24701160737016528 | validation: 0.2122155231251078]
	TIME [epoch: 14.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543853022808934		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2543853022808934 | validation: 0.21136447766983743]
	TIME [epoch: 14.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542382390052195		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.2542382390052195 | validation: 0.2042209200200767]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534121915480311		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2534121915480311 | validation: 0.20985987752099994]
	TIME [epoch: 14.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886593986491848		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.24886593986491848 | validation: 0.20939712392672444]
	TIME [epoch: 14.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24795502790270194		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.24795502790270194 | validation: 0.21783676078985792]
	TIME [epoch: 14.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501542735387901		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.2501542735387901 | validation: 0.20607835749724007]
	TIME [epoch: 14.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514495904001195		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.2514495904001195 | validation: 0.20895828094546717]
	TIME [epoch: 14.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473197659694669		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.2473197659694669 | validation: 0.21229078108528446]
	TIME [epoch: 14.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934822688804745		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24934822688804745 | validation: 0.20815854945477108]
	TIME [epoch: 14.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534168521072416		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24534168521072416 | validation: 0.21291866638656928]
	TIME [epoch: 14.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24234801696921301		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24234801696921301 | validation: 0.20624164757696334]
	TIME [epoch: 14.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532519501900312		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2532519501900312 | validation: 0.2010076813979001]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25359367461105237		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.25359367461105237 | validation: 0.20453024340775988]
	TIME [epoch: 14.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245744545844802		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.245744545844802 | validation: 0.20856935551752537]
	TIME [epoch: 14.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24857111709644317		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24857111709644317 | validation: 0.21060025278343691]
	TIME [epoch: 14.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24395910597561188		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24395910597561188 | validation: 0.20830122692354486]
	TIME [epoch: 14.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24400597945709623		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.24400597945709623 | validation: 0.2136907800194514]
	TIME [epoch: 14.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25001921922507114		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.25001921922507114 | validation: 0.21447400855488982]
	TIME [epoch: 14.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24613915964448974		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24613915964448974 | validation: 0.21068260901019825]
	TIME [epoch: 14.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496699080578069		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2496699080578069 | validation: 0.20875051634050168]
	TIME [epoch: 14.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432229126998724		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.2432229126998724 | validation: 0.21432395955110675]
	TIME [epoch: 14.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460932575351206		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.2460932575351206 | validation: 0.20878385554265283]
	TIME [epoch: 14.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24083317395615655		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24083317395615655 | validation: 0.20679276725247214]
	TIME [epoch: 14.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517453581733328		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.2517453581733328 | validation: 0.20876369904599984]
	TIME [epoch: 14.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492659153087418		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.2492659153087418 | validation: 0.21367249692041365]
	TIME [epoch: 14.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24372157797026064		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24372157797026064 | validation: 0.2061271942327496]
	TIME [epoch: 14.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246797348586403		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.246797348586403 | validation: 0.21360017898193912]
	TIME [epoch: 14.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25064336413085586		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.25064336413085586 | validation: 0.21754233515023685]
	TIME [epoch: 14.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394996389648818		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24394996389648818 | validation: 0.21352505022908988]
	TIME [epoch: 14.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327294243686173		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.24327294243686173 | validation: 0.21595259761876462]
	TIME [epoch: 14.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24763445821959004		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24763445821959004 | validation: 0.2216126815890973]
	TIME [epoch: 14.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25483353685847704		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.25483353685847704 | validation: 0.2131072650560643]
	TIME [epoch: 14.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24637314016903197		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.24637314016903197 | validation: 0.2097509330934324]
	TIME [epoch: 14.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24325514452922373		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24325514452922373 | validation: 0.22526753520867548]
	TIME [epoch: 14.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25060641348347434		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.25060641348347434 | validation: 0.2097241256761338]
	TIME [epoch: 14.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24484610344278546		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24484610344278546 | validation: 0.20410117958785037]
	TIME [epoch: 14.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24645530167149418		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.24645530167149418 | validation: 0.20975145966852166]
	TIME [epoch: 14.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462015305651697		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2462015305651697 | validation: 0.20921832363013718]
	TIME [epoch: 14.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25289310873866483		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.25289310873866483 | validation: 0.21269977662344397]
	TIME [epoch: 14.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24927213185036914		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24927213185036914 | validation: 0.21497080878944136]
	TIME [epoch: 14.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443072827152147		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.2443072827152147 | validation: 0.20650511111500877]
	TIME [epoch: 14.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24640313362077557		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.24640313362077557 | validation: 0.20563686037602763]
	TIME [epoch: 14.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542160843113204		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.2542160843113204 | validation: 0.2064458326073133]
	TIME [epoch: 14.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586885745062811		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24586885745062811 | validation: 0.20996230049747194]
	TIME [epoch: 14.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24949173210943523		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24949173210943523 | validation: 0.21455442586350362]
	TIME [epoch: 14.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24503912872276415		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.24503912872276415 | validation: 0.2073081254250179]
	TIME [epoch: 14.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24569030032385253		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24569030032385253 | validation: 0.20868871445928194]
	TIME [epoch: 14.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429079014256498		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.2429079014256498 | validation: 0.21350629001094198]
	TIME [epoch: 14.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24154471077619225		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24154471077619225 | validation: 0.2141639612148732]
	TIME [epoch: 14.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24918799392565397		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24918799392565397 | validation: 0.20689539268100954]
	TIME [epoch: 14.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464118631303286		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.2464118631303286 | validation: 0.20401867206763188]
	TIME [epoch: 14.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23907003717808006		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.23907003717808006 | validation: 0.21629145379428305]
	TIME [epoch: 14.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24684897876251055		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.24684897876251055 | validation: 0.20905203153404042]
	TIME [epoch: 14.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467228772889131		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.2467228772889131 | validation: 0.2127642496838244]
	TIME [epoch: 14.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2430113959206591		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.2430113959206591 | validation: 0.21365674723771103]
	TIME [epoch: 14.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492740157954326		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.2492740157954326 | validation: 0.21067082056909947]
	TIME [epoch: 14.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686450733596318		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.24686450733596318 | validation: 0.2079322911542818]
	TIME [epoch: 14.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23933520056587185		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.23933520056587185 | validation: 0.20853909438518198]
	TIME [epoch: 14.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24951238556720498		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24951238556720498 | validation: 0.21462723354692895]
	TIME [epoch: 14.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24055009716927975		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24055009716927975 | validation: 0.20969426740685787]
	TIME [epoch: 14.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24910459983226363		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24910459983226363 | validation: 0.21035383251097678]
	TIME [epoch: 14.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24123470044732284		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24123470044732284 | validation: 0.20886073886595685]
	TIME [epoch: 14.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24263606018762096		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.24263606018762096 | validation: 0.21314115254395713]
	TIME [epoch: 44.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477008007986595		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2477008007986595 | validation: 0.20879759382003513]
	TIME [epoch: 30.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450732464243959		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.2450732464243959 | validation: 0.20714784421935187]
	TIME [epoch: 30.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531457598329487		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24531457598329487 | validation: 0.20524777078250298]
	TIME [epoch: 30.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510176706813834		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2510176706813834 | validation: 0.20964538318900305]
	TIME [epoch: 30.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465853524186257		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.2465853524186257 | validation: 0.20707150921320933]
	TIME [epoch: 30.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24667509114424535		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24667509114424535 | validation: 0.20974404710429068]
	TIME [epoch: 30.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24243159994564842		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24243159994564842 | validation: 0.21336652270901718]
	TIME [epoch: 30.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24641200638313807		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24641200638313807 | validation: 0.21505952845004406]
	TIME [epoch: 30.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24289570731576704		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24289570731576704 | validation: 0.2084774536491047]
	TIME [epoch: 30.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745237540415052		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24745237540415052 | validation: 0.20911523572759635]
	TIME [epoch: 30.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469836935388027		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2469836935388027 | validation: 0.21256469245333123]
	TIME [epoch: 30.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796733976272944		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.24796733976272944 | validation: 0.20885085987863478]
	TIME [epoch: 30.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24045666331137897		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24045666331137897 | validation: 0.20837225469286075]
	TIME [epoch: 30.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24974806253240175		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24974806253240175 | validation: 0.2095364295339756]
	TIME [epoch: 30.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23791597287155833		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.23791597287155833 | validation: 0.2095997626345698]
	TIME [epoch: 30.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24802763458759983		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24802763458759983 | validation: 0.2143611674644562]
	TIME [epoch: 30.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24326021300693057		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24326021300693057 | validation: 0.20864649494507465]
	TIME [epoch: 30.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24221964486820657		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24221964486820657 | validation: 0.20876724208849554]
	TIME [epoch: 30.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24837209141368788		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24837209141368788 | validation: 0.20394005155634068]
	TIME [epoch: 30.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24380355614970925		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24380355614970925 | validation: 0.2079881677868694]
	TIME [epoch: 30.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24702854446467803		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.24702854446467803 | validation: 0.20969977965264572]
	TIME [epoch: 30.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359910073721183		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24359910073721183 | validation: 0.2059820065148113]
	TIME [epoch: 30.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24563354447846067		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24563354447846067 | validation: 0.2116274673124341]
	TIME [epoch: 30.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24711845702435395		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24711845702435395 | validation: 0.21641764153620519]
	TIME [epoch: 30.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24901530190934232		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24901530190934232 | validation: 0.2085211231127379]
	TIME [epoch: 30.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24871692542997434		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24871692542997434 | validation: 0.2042574994514859]
	TIME [epoch: 30.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378559275255232		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24378559275255232 | validation: 0.20947629288499275]
	TIME [epoch: 30.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24859330330598514		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24859330330598514 | validation: 0.22041453893286572]
	TIME [epoch: 30.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24346826825132875		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.24346826825132875 | validation: 0.2034697447594609]
	TIME [epoch: 30.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245117448379869		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.245117448379869 | validation: 0.20698017962688442]
	TIME [epoch: 30.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478422175526478		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.2478422175526478 | validation: 0.21276296425304086]
	TIME [epoch: 30.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586190385099607		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24586190385099607 | validation: 0.20912584396178432]
	TIME [epoch: 30.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24617791282096338		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24617791282096338 | validation: 0.20407323262811014]
	TIME [epoch: 30.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683615687285151		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.24683615687285151 | validation: 0.21022136396465302]
	TIME [epoch: 30.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25174292123424097		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.25174292123424097 | validation: 0.20790640618693468]
	TIME [epoch: 30.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459255537701652		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24459255537701652 | validation: 0.2084007286870865]
	TIME [epoch: 30.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24331027649585416		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.24331027649585416 | validation: 0.20570179114006715]
	TIME [epoch: 30.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529627432849277		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.2529627432849277 | validation: 0.20926438045434798]
	TIME [epoch: 30.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24215972453274137		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.24215972453274137 | validation: 0.20411705473508174]
	TIME [epoch: 30.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531407855617573		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.2531407855617573 | validation: 0.20833741260996846]
	TIME [epoch: 30.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500901815611076		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2500901815611076 | validation: 0.21083331269842026]
	TIME [epoch: 30.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25397809222606593		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.25397809222606593 | validation: 0.20760351516499073]
	TIME [epoch: 30.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508097608332565		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.2508097608332565 | validation: 0.2132946073042284]
	TIME [epoch: 30.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469524214997593		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.2469524214997593 | validation: 0.20980908708103346]
	TIME [epoch: 30.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25092321696941394		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.25092321696941394 | validation: 0.2070034724760486]
	TIME [epoch: 30.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683425071367018		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.24683425071367018 | validation: 0.20667563002652475]
	TIME [epoch: 30.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24643327013546265		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24643327013546265 | validation: 0.20896440625365154]
	TIME [epoch: 30.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434763223611137		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.2434763223611137 | validation: 0.20461244417180885]
	TIME [epoch: 30.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24204283690743314		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.24204283690743314 | validation: 0.21318194876902555]
	TIME [epoch: 30.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480476249794974		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.2480476249794974 | validation: 0.2068907985359961]
	TIME [epoch: 30.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442385821926966		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.2442385821926966 | validation: 0.20463136648633706]
	TIME [epoch: 30.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999733999170656		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.24999733999170656 | validation: 0.20395437992003268]
	TIME [epoch: 30.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511381774991145		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2511381774991145 | validation: 0.205741692817024]
	TIME [epoch: 30.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24728467173380797		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24728467173380797 | validation: 0.20737227139307124]
	TIME [epoch: 30.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251888508888006		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.251888508888006 | validation: 0.20670894972729745]
	TIME [epoch: 30.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24662865177661986		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.24662865177661986 | validation: 0.21189909057123005]
	TIME [epoch: 30.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24705101513566916		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.24705101513566916 | validation: 0.20470605465554245]
	TIME [epoch: 30.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24524275201882054		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.24524275201882054 | validation: 0.20855894110090661]
	TIME [epoch: 30.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24216685192883425		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24216685192883425 | validation: 0.21073702184996984]
	TIME [epoch: 30.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24167593837245868		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.24167593837245868 | validation: 0.2012798402081067]
	TIME [epoch: 30.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511214625931561		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.2511214625931561 | validation: 0.20392463587048187]
	TIME [epoch: 30.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467733399421903		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.2467733399421903 | validation: 0.20596987266154093]
	TIME [epoch: 30.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24864391057761392		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24864391057761392 | validation: 0.21356859727355842]
	TIME [epoch: 30.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24894557934135655		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.24894557934135655 | validation: 0.20806984193601874]
	TIME [epoch: 30.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24415193144248662		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.24415193144248662 | validation: 0.210935920559443]
	TIME [epoch: 30.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745827459188052		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.24745827459188052 | validation: 0.20860536779690347]
	TIME [epoch: 30.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432159106950723		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.2432159106950723 | validation: 0.2078262782829195]
	TIME [epoch: 30.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24472976414185613		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24472976414185613 | validation: 0.21271052368573193]
	TIME [epoch: 30.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24920696782952648		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.24920696782952648 | validation: 0.21244210083252213]
	TIME [epoch: 30.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24159708675752978		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.24159708675752978 | validation: 0.21021605292935322]
	TIME [epoch: 30.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24248421511216348		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.24248421511216348 | validation: 0.2129211991155368]
	TIME [epoch: 30.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451615938797406		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.2451615938797406 | validation: 0.21738780647306802]
	TIME [epoch: 30.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644927563676214		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24644927563676214 | validation: 0.21035776966805136]
	TIME [epoch: 30.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24341203089105254		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.24341203089105254 | validation: 0.20966193592194865]
	TIME [epoch: 30.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531249181815404		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.24531249181815404 | validation: 0.2079572555690949]
	TIME [epoch: 30.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24462607446931572		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.24462607446931572 | validation: 0.21091459142382196]
	TIME [epoch: 30.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23864854667254856		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.23864854667254856 | validation: 0.21011203287078226]
	TIME [epoch: 30.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396179419443534		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.24396179419443534 | validation: 0.21491718882735045]
	TIME [epoch: 30.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429535737627371		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.2429535737627371 | validation: 0.21356582222034123]
	TIME [epoch: 30.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24312906054713082		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24312906054713082 | validation: 0.20575224798312322]
	TIME [epoch: 30.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24532137896891734		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24532137896891734 | validation: 0.21584555922789397]
	TIME [epoch: 30.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24298921867055964		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24298921867055964 | validation: 0.21349592555818084]
	TIME [epoch: 30.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24183076012445137		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24183076012445137 | validation: 0.20778713270137583]
	TIME [epoch: 30.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24222260416666008		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.24222260416666008 | validation: 0.20846877459165242]
	TIME [epoch: 30.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25042001609517467		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.25042001609517467 | validation: 0.21382705396141038]
	TIME [epoch: 30.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2457251603532462		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.2457251603532462 | validation: 0.2084697830458042]
	TIME [epoch: 30.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24679083331129012		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.24679083331129012 | validation: 0.20234792455736858]
	TIME [epoch: 30.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24736731679949467		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.24736731679949467 | validation: 0.20971358639029]
	TIME [epoch: 30.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459745595382261		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.2459745595382261 | validation: 0.20922326171439623]
	TIME [epoch: 30.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25046187599936404		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.25046187599936404 | validation: 0.2081166126678379]
	TIME [epoch: 30.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450021820539268		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.2450021820539268 | validation: 0.20937776814023876]
	TIME [epoch: 30.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24117869624074398		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.24117869624074398 | validation: 0.2132343072708589]
	TIME [epoch: 30.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217667811383678		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24217667811383678 | validation: 0.21222056788574487]
	TIME [epoch: 30.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460837734321775		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.2460837734321775 | validation: 0.2093358526201682]
	TIME [epoch: 30.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24098295620933533		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.24098295620933533 | validation: 0.20764943161162708]
	TIME [epoch: 30.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451622474634664		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.2451622474634664 | validation: 0.20974913498210426]
	TIME [epoch: 30.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797568015069635		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.24797568015069635 | validation: 0.21295695663874845]
	TIME [epoch: 30.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242003433502209		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.242003433502209 | validation: 0.21020571317347442]
	TIME [epoch: 30.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243454701446043		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.243454701446043 | validation: 0.20878555671086332]
	TIME [epoch: 30.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758888548588265		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.24758888548588265 | validation: 0.20736965040386562]
	TIME [epoch: 30.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477130015260474		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2477130015260474 | validation: 0.2119077601226794]
	TIME [epoch: 30.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24499609702158734		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24499609702158734 | validation: 0.20561012453342659]
	TIME [epoch: 30.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359961242140785		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.24359961242140785 | validation: 0.2061062790328095]
	TIME [epoch: 30.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24497473372139375		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24497473372139375 | validation: 0.20456090083319745]
	TIME [epoch: 30.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435509962000968		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.2435509962000968 | validation: 0.21168806008871593]
	TIME [epoch: 30.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24767296585566764		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.24767296585566764 | validation: 0.20506440129570652]
	TIME [epoch: 30.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24491875906190308		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.24491875906190308 | validation: 0.2066832443107435]
	TIME [epoch: 30.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24690676607688822		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.24690676607688822 | validation: 0.2110252849665631]
	TIME [epoch: 30.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490751200169505		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.2490751200169505 | validation: 0.20949634106761678]
	TIME [epoch: 30.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24800295461690114		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24800295461690114 | validation: 0.21427618651316957]
	TIME [epoch: 30.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24541755622770958		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.24541755622770958 | validation: 0.2137634902212727]
	TIME [epoch: 30.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24441001742163956		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.24441001742163956 | validation: 0.21526553009038327]
	TIME [epoch: 30.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24355056360828384		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.24355056360828384 | validation: 0.21470194880701285]
	TIME [epoch: 30.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884619608971562		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.24884619608971562 | validation: 0.21239445904187235]
	TIME [epoch: 30.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2418626455576669		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.2418626455576669 | validation: 0.207915408703435]
	TIME [epoch: 30.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24662912611322588		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.24662912611322588 | validation: 0.21066553724404571]
	TIME [epoch: 30.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465497310392669		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.2465497310392669 | validation: 0.20994164972586038]
	TIME [epoch: 30.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241752615909519		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.241752615909519 | validation: 0.21225364726088403]
	TIME [epoch: 30.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24480300656645074		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.24480300656645074 | validation: 0.20990013090798318]
	TIME [epoch: 30.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408152970395452		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.2408152970395452 | validation: 0.21080029233026912]
	TIME [epoch: 30.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24503163754918988		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.24503163754918988 | validation: 0.20693424490653767]
	TIME [epoch: 30.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24413196994428762		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.24413196994428762 | validation: 0.20451861172029773]
	TIME [epoch: 30.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24273809884257336		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.24273809884257336 | validation: 0.2229003705149911]
	TIME [epoch: 30.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25269756495520423		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.25269756495520423 | validation: 0.22070702730489553]
	TIME [epoch: 30.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962881875657747		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.24962881875657747 | validation: 0.20813424611579587]
	TIME [epoch: 30.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24835250427008768		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.24835250427008768 | validation: 0.21096860255150912]
	TIME [epoch: 30.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24193223471633393		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.24193223471633393 | validation: 0.20600038162927956]
	TIME [epoch: 30.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695038373782194		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24695038373782194 | validation: 0.2062496113908144]
	TIME [epoch: 30.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23878430341297419		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.23878430341297419 | validation: 0.21487322959489674]
	TIME [epoch: 30.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24450885521114837		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.24450885521114837 | validation: 0.20720499960346736]
	TIME [epoch: 30.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24258561291018146		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24258561291018146 | validation: 0.2027188922559208]
	TIME [epoch: 30.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24733262215761243		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.24733262215761243 | validation: 0.20332163797115177]
	TIME [epoch: 30.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24279015310816945		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.24279015310816945 | validation: 0.20563738832916942]
	TIME [epoch: 30.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24923086441030531		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.24923086441030531 | validation: 0.21340024671003865]
	TIME [epoch: 30.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403248646500472		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.2403248646500472 | validation: 0.20219572957292695]
	TIME [epoch: 30.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24467315046696778		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.24467315046696778 | validation: 0.20930191609490345]
	TIME [epoch: 30.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24595984270188576		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.24595984270188576 | validation: 0.20786009275944872]
	TIME [epoch: 30.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24622968713246593		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.24622968713246593 | validation: 0.20885766588409113]
	TIME [epoch: 30.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24595625411024433		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24595625411024433 | validation: 0.20730729723815178]
	TIME [epoch: 30.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24155029110560292		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24155029110560292 | validation: 0.2144943621418435]
	TIME [epoch: 30.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2418669125809397		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.2418669125809397 | validation: 0.20939670413292158]
	TIME [epoch: 30.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121965189080408		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.24121965189080408 | validation: 0.2115018005560553]
	TIME [epoch: 30.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24301349565257394		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24301349565257394 | validation: 0.21348044180782783]
	TIME [epoch: 30.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24376997343953		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.24376997343953 | validation: 0.21487726568257828]
	TIME [epoch: 30.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24173885991196767		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.24173885991196767 | validation: 0.21150703672247326]
	TIME [epoch: 30.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24384334739855498		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.24384334739855498 | validation: 0.21263314394091198]
	TIME [epoch: 30.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24501879204959773		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24501879204959773 | validation: 0.20842339251458109]
	TIME [epoch: 30.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24571366667790226		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.24571366667790226 | validation: 0.20689722315939144]
	TIME [epoch: 30.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24554426803571647		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.24554426803571647 | validation: 0.2098992443853173]
	TIME [epoch: 30.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243173506087939		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.243173506087939 | validation: 0.2119922949227248]
	TIME [epoch: 30.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240716_143208/states/model_facs_v3_dec1b_2dpca_v13_651.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 11488.049 seconds.
