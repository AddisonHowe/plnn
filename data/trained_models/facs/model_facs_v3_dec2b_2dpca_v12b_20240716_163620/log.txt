Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v12b', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v12b', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1773940983

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6348807238167207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6348807238167207 | validation: 1.7543940579936455]
	TIME [epoch: 33.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268388861472004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0268388861472004 | validation: 0.9947533823141173]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983870537134763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6983870537134763 | validation: 0.8505905884390268]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.633592237824928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.633592237824928 | validation: 0.7945502409773131]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216878108166967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6216878108166967 | validation: 0.7593347441674729]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641229785402676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5641229785402676 | validation: 0.7750317213162897]
	TIME [epoch: 6.07 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879829571039823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5879829571039823 | validation: 0.6986893045071191]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404971865633799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5404971865633799 | validation: 0.7443748708260854]
	TIME [epoch: 6.07 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935720484276454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4935720484276454 | validation: 0.6895370739901978]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.542416281514129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.542416281514129 | validation: 0.643511429201933]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462636584844696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5462636584844696 | validation: 0.6880729921003623]
	TIME [epoch: 6.32 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070579028449352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5070579028449352 | validation: 0.6316704915306415]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44433953154485173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44433953154485173 | validation: 0.5821467626549391]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.426329979585404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.426329979585404 | validation: 0.5694869946761926]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825599379912175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3825599379912175 | validation: 0.577054928214185]
	TIME [epoch: 6.08 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.37490602808998347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37490602808998347 | validation: 0.6175414252841674]
	TIME [epoch: 6.09 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464568102728298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3464568102728298 | validation: 0.5028385219081811]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.32145167371906247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32145167371906247 | validation: 0.518108959525134]
	TIME [epoch: 6.09 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250725858050285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3250725858050285 | validation: 0.5025266079610026]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276638198430936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3276638198430936 | validation: 0.4765291597844887]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.30219768046996665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30219768046996665 | validation: 0.44808074740857917]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.29570398734974035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29570398734974035 | validation: 0.4905677097637286]
	TIME [epoch: 6.07 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.27975476997280646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27975476997280646 | validation: 0.5767775766030154]
	TIME [epoch: 6.07 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315508213549967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3315508213549967 | validation: 0.4448948015706595]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106285455297351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3106285455297351 | validation: 0.4969745698912095]
	TIME [epoch: 6.07 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.267630074591198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.267630074591198 | validation: 0.4367023118198414]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.24392058427421945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24392058427421945 | validation: 0.4263679593459484]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857975074104484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2857975074104484 | validation: 0.6078424629105286]
	TIME [epoch: 6.08 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401545454789238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3401545454789238 | validation: 0.48352615948996697]
	TIME [epoch: 6.07 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26912512277646344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26912512277646344 | validation: 0.44529608613199956]
	TIME [epoch: 6.07 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26374655383209433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26374655383209433 | validation: 0.43435505243632366]
	TIME [epoch: 6.07 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510785236820777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2510785236820777 | validation: 0.43419534072547983]
	TIME [epoch: 6.08 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26171415992382036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26171415992382036 | validation: 0.4484293004088228]
	TIME [epoch: 6.08 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.30259873032616896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30259873032616896 | validation: 0.4308045853966085]
	TIME [epoch: 6.07 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667371567638769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2667371567638769 | validation: 0.48977998881630014]
	TIME [epoch: 6.07 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730168786049643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2730168786049643 | validation: 0.469189746131357]
	TIME [epoch: 6.07 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651327089457528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2651327089457528 | validation: 0.45447025510855593]
	TIME [epoch: 6.07 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26745010045108025		[learning rate: 0.0099758]
	Learning Rate: 0.00997579
	LOSS [training: 0.26745010045108025 | validation: 0.44353443260039593]
	TIME [epoch: 6.08 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3120858943312484		[learning rate: 0.0098795]
	Learning Rate: 0.00987954
	LOSS [training: 0.3120858943312484 | validation: 0.4608684248967728]
	TIME [epoch: 6.08 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641121040168861		[learning rate: 0.0097842]
	Learning Rate: 0.00978422
	LOSS [training: 0.2641121040168861 | validation: 0.478228051746315]
	TIME [epoch: 6.07 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511886168193346		[learning rate: 0.0096898]
	Learning Rate: 0.00968982
	LOSS [training: 0.2511886168193346 | validation: 0.4640223801605406]
	TIME [epoch: 6.07 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26811813148954505		[learning rate: 0.0095963]
	Learning Rate: 0.00959633
	LOSS [training: 0.26811813148954505 | validation: 0.3992286969473528]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546695520962152		[learning rate: 0.0095037]
	Learning Rate: 0.00950374
	LOSS [training: 0.2546695520962152 | validation: 0.5684280958898267]
	TIME [epoch: 6.07 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884218143391082		[learning rate: 0.009412]
	Learning Rate: 0.00941205
	LOSS [training: 0.2884218143391082 | validation: 0.4480386110818273]
	TIME [epoch: 6.09 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22307049824872194		[learning rate: 0.0093212]
	Learning Rate: 0.00932124
	LOSS [training: 0.22307049824872194 | validation: 0.4254729406730922]
	TIME [epoch: 6.08 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2732395776769635		[learning rate: 0.0092313]
	Learning Rate: 0.00923131
	LOSS [training: 0.2732395776769635 | validation: 0.49637181476882575]
	TIME [epoch: 6.07 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569111587384002		[learning rate: 0.0091422]
	Learning Rate: 0.00914224
	LOSS [training: 0.2569111587384002 | validation: 0.3976764659649121]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2350368632101081		[learning rate: 0.009054]
	Learning Rate: 0.00905403
	LOSS [training: 0.2350368632101081 | validation: 0.35991519535994526]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2170392878094618		[learning rate: 0.0089667]
	Learning Rate: 0.00896668
	LOSS [training: 0.2170392878094618 | validation: 0.4236958188669065]
	TIME [epoch: 6.08 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20209562107043855		[learning rate: 0.0088802]
	Learning Rate: 0.00888017
	LOSS [training: 0.20209562107043855 | validation: 0.4395862603320671]
	TIME [epoch: 6.08 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.29228993165165185		[learning rate: 0.0087945]
	Learning Rate: 0.00879449
	LOSS [training: 0.29228993165165185 | validation: 0.3568869424378686]
	TIME [epoch: 37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20833539276501895		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.20833539276501895 | validation: 0.3827346676815659]
	TIME [epoch: 11.7 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125402166102879		[learning rate: 0.0086256]
	Learning Rate: 0.0086256
	LOSS [training: 0.2125402166102879 | validation: 0.41730191357989566]
	TIME [epoch: 11.7 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.24294603781176985		[learning rate: 0.0085424]
	Learning Rate: 0.00854238
	LOSS [training: 0.24294603781176985 | validation: 0.45412448510942466]
	TIME [epoch: 11.7 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513849646485639		[learning rate: 0.00846]
	Learning Rate: 0.00845996
	LOSS [training: 0.2513849646485639 | validation: 0.3911499545451217]
	TIME [epoch: 11.7 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447320694369444		[learning rate: 0.0083783]
	Learning Rate: 0.00837834
	LOSS [training: 0.22447320694369444 | validation: 0.5537520884520033]
	TIME [epoch: 11.7 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.24757306031610202		[learning rate: 0.0082975]
	Learning Rate: 0.0082975
	LOSS [training: 0.24757306031610202 | validation: 0.35418142497441657]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039688985812126		[learning rate: 0.0082174]
	Learning Rate: 0.00821745
	LOSS [training: 0.2039688985812126 | validation: 0.39872062545237635]
	TIME [epoch: 11.7 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.23952517949317093		[learning rate: 0.0081382]
	Learning Rate: 0.00813816
	LOSS [training: 0.23952517949317093 | validation: 0.39122999649188883]
	TIME [epoch: 11.7 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272541730492153		[learning rate: 0.0080596]
	Learning Rate: 0.00805964
	LOSS [training: 0.2272541730492153 | validation: 0.4244020774772792]
	TIME [epoch: 11.7 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22023152548293398		[learning rate: 0.0079819]
	Learning Rate: 0.00798188
	LOSS [training: 0.22023152548293398 | validation: 0.3377666086668195]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20574229738039743		[learning rate: 0.0079049]
	Learning Rate: 0.00790487
	LOSS [training: 0.20574229738039743 | validation: 0.4574780781604848]
	TIME [epoch: 11.7 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.23030581033424313		[learning rate: 0.0078286]
	Learning Rate: 0.0078286
	LOSS [training: 0.23030581033424313 | validation: 0.3660597308002925]
	TIME [epoch: 11.7 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18607709635019146		[learning rate: 0.0077531]
	Learning Rate: 0.00775307
	LOSS [training: 0.18607709635019146 | validation: 0.3666033936977019]
	TIME [epoch: 11.7 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20982981210103197		[learning rate: 0.0076783]
	Learning Rate: 0.00767827
	LOSS [training: 0.20982981210103197 | validation: 0.4939225494752017]
	TIME [epoch: 11.7 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21462790566614826		[learning rate: 0.0076042]
	Learning Rate: 0.00760418
	LOSS [training: 0.21462790566614826 | validation: 0.3985093714817246]
	TIME [epoch: 11.7 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22677889548362054		[learning rate: 0.0075308]
	Learning Rate: 0.00753082
	LOSS [training: 0.22677889548362054 | validation: 0.3589699101771343]
	TIME [epoch: 11.7 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20943219887402945		[learning rate: 0.0074582]
	Learning Rate: 0.00745816
	LOSS [training: 0.20943219887402945 | validation: 0.4339814983275858]
	TIME [epoch: 11.7 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21275759745044043		[learning rate: 0.0073862]
	Learning Rate: 0.0073862
	LOSS [training: 0.21275759745044043 | validation: 0.3712448019624923]
	TIME [epoch: 11.7 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517992511256323		[learning rate: 0.0073149]
	Learning Rate: 0.00731494
	LOSS [training: 0.2517992511256323 | validation: 0.36690050294130444]
	TIME [epoch: 11.7 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.230806602171674		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.230806602171674 | validation: 0.43781652583031505]
	TIME [epoch: 11.7 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094796537620959		[learning rate: 0.0071745]
	Learning Rate: 0.00717446
	LOSS [training: 0.2094796537620959 | validation: 0.4927577444976929]
	TIME [epoch: 11.7 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.24712267236144514		[learning rate: 0.0071052]
	Learning Rate: 0.00710524
	LOSS [training: 0.24712267236144514 | validation: 0.3281387338795496]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21970174239083579		[learning rate: 0.0070367]
	Learning Rate: 0.00703669
	LOSS [training: 0.21970174239083579 | validation: 0.40491244176686375]
	TIME [epoch: 11.7 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.23189226563989845		[learning rate: 0.0069688]
	Learning Rate: 0.0069688
	LOSS [training: 0.23189226563989845 | validation: 0.32306339912736803]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766850087485206		[learning rate: 0.0069016]
	Learning Rate: 0.00690156
	LOSS [training: 0.1766850087485206 | validation: 0.34695826492636644]
	TIME [epoch: 11.7 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16604716942881154		[learning rate: 0.006835]
	Learning Rate: 0.00683497
	LOSS [training: 0.16604716942881154 | validation: 0.3665182401897679]
	TIME [epoch: 11.7 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21540173344926197		[learning rate: 0.006769]
	Learning Rate: 0.00676903
	LOSS [training: 0.21540173344926197 | validation: 0.4837075538393628]
	TIME [epoch: 11.7 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.193703327140398		[learning rate: 0.0067037]
	Learning Rate: 0.00670372
	LOSS [training: 0.193703327140398 | validation: 0.38104063425905044]
	TIME [epoch: 11.7 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19658252195328058		[learning rate: 0.006639]
	Learning Rate: 0.00663904
	LOSS [training: 0.19658252195328058 | validation: 0.41738751511935185]
	TIME [epoch: 11.7 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012575349007578		[learning rate: 0.006575]
	Learning Rate: 0.00657498
	LOSS [training: 0.2012575349007578 | validation: 0.3042684867590284]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16758105326143624		[learning rate: 0.0065115]
	Learning Rate: 0.00651155
	LOSS [training: 0.16758105326143624 | validation: 0.3181485732391366]
	TIME [epoch: 11.7 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18623202744995213		[learning rate: 0.0064487]
	Learning Rate: 0.00644872
	LOSS [training: 0.18623202744995213 | validation: 0.40256344738069794]
	TIME [epoch: 11.7 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20096131010589577		[learning rate: 0.0063865]
	Learning Rate: 0.0063865
	LOSS [training: 0.20096131010589577 | validation: 0.40336184660137375]
	TIME [epoch: 11.7 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199904253496589		[learning rate: 0.0063249]
	Learning Rate: 0.00632488
	LOSS [training: 0.2199904253496589 | validation: 0.3304700882686055]
	TIME [epoch: 11.7 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14802626219566797		[learning rate: 0.0062639]
	Learning Rate: 0.00626386
	LOSS [training: 0.14802626219566797 | validation: 0.35526039302102025]
	TIME [epoch: 11.7 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20454905809027504		[learning rate: 0.0062034]
	Learning Rate: 0.00620343
	LOSS [training: 0.20454905809027504 | validation: 0.3760215090661741]
	TIME [epoch: 11.7 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443556004985043		[learning rate: 0.0061436]
	Learning Rate: 0.00614357
	LOSS [training: 0.21443556004985043 | validation: 0.341169384165426]
	TIME [epoch: 11.7 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828842571794635		[learning rate: 0.0060843]
	Learning Rate: 0.0060843
	LOSS [training: 0.1828842571794635 | validation: 0.340221015774103]
	TIME [epoch: 11.7 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375003587750466		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.15375003587750466 | validation: 0.3481977508388198]
	TIME [epoch: 11.7 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114633577982001		[learning rate: 0.0059675]
	Learning Rate: 0.00596746
	LOSS [training: 0.19114633577982001 | validation: 0.3138064750932774]
	TIME [epoch: 11.7 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20561740285999391		[learning rate: 0.0059099]
	Learning Rate: 0.00590988
	LOSS [training: 0.20561740285999391 | validation: 0.5897988722225872]
	TIME [epoch: 11.7 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032484184065343		[learning rate: 0.0058529]
	Learning Rate: 0.00585286
	LOSS [training: 0.22032484184065343 | validation: 0.39007040829400363]
	TIME [epoch: 11.7 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872605117649446		[learning rate: 0.0057964]
	Learning Rate: 0.00579639
	LOSS [training: 0.1872605117649446 | validation: 0.3103902233341872]
	TIME [epoch: 11.7 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1784025501321462		[learning rate: 0.0057405]
	Learning Rate: 0.00574047
	LOSS [training: 0.1784025501321462 | validation: 0.3935402493936666]
	TIME [epoch: 11.7 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17653510951388723		[learning rate: 0.0056851]
	Learning Rate: 0.00568508
	LOSS [training: 0.17653510951388723 | validation: 0.3824852197838648]
	TIME [epoch: 11.7 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21228101318729528		[learning rate: 0.0056302]
	Learning Rate: 0.00563023
	LOSS [training: 0.21228101318729528 | validation: 0.3378970170900379]
	TIME [epoch: 11.7 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2009340767209802		[learning rate: 0.0055759]
	Learning Rate: 0.00557591
	LOSS [training: 0.2009340767209802 | validation: 0.3274564733583032]
	TIME [epoch: 11.7 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19611869155462178		[learning rate: 0.0055221]
	Learning Rate: 0.00552211
	LOSS [training: 0.19611869155462178 | validation: 0.3509315149258457]
	TIME [epoch: 11.7 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16726659353811427		[learning rate: 0.0054688]
	Learning Rate: 0.00546883
	LOSS [training: 0.16726659353811427 | validation: 0.3396983518885281]
	TIME [epoch: 11.7 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17705043189553515		[learning rate: 0.0054161]
	Learning Rate: 0.00541607
	LOSS [training: 0.17705043189553515 | validation: 0.4179128157327143]
	TIME [epoch: 50.3 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17952301279543395		[learning rate: 0.0053638]
	Learning Rate: 0.00536381
	LOSS [training: 0.17952301279543395 | validation: 0.3401254848460551]
	TIME [epoch: 24.9 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16789803496207797		[learning rate: 0.0053121]
	Learning Rate: 0.00531206
	LOSS [training: 0.16789803496207797 | validation: 0.34738800367990275]
	TIME [epoch: 24.9 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17769578254272683		[learning rate: 0.0052608]
	Learning Rate: 0.00526081
	LOSS [training: 0.17769578254272683 | validation: 0.3087369081173095]
	TIME [epoch: 24.9 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19217271602371389		[learning rate: 0.0052101]
	Learning Rate: 0.00521005
	LOSS [training: 0.19217271602371389 | validation: 0.3909255889134575]
	TIME [epoch: 24.9 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19555440507897007		[learning rate: 0.0051598]
	Learning Rate: 0.00515978
	LOSS [training: 0.19555440507897007 | validation: 0.3399139315677017]
	TIME [epoch: 24.9 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930264623163126		[learning rate: 0.00511]
	Learning Rate: 0.00511
	LOSS [training: 0.15930264623163126 | validation: 0.39143271988534967]
	TIME [epoch: 24.9 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19932223947569927		[learning rate: 0.0050607]
	Learning Rate: 0.0050607
	LOSS [training: 0.19932223947569927 | validation: 0.3267269353516987]
	TIME [epoch: 24.9 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869862397474472		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1869862397474472 | validation: 0.43699869055189566]
	TIME [epoch: 24.9 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20590764842448994		[learning rate: 0.0049635]
	Learning Rate: 0.00496352
	LOSS [training: 0.20590764842448994 | validation: 0.4817537595546284]
	TIME [epoch: 24.9 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18250320657722088		[learning rate: 0.0049156]
	Learning Rate: 0.00491563
	LOSS [training: 0.18250320657722088 | validation: 0.3075630264348235]
	TIME [epoch: 24.9 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18099304074595393		[learning rate: 0.0048682]
	Learning Rate: 0.0048682
	LOSS [training: 0.18099304074595393 | validation: 0.39829717207858206]
	TIME [epoch: 24.9 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18638984631656652		[learning rate: 0.0048212]
	Learning Rate: 0.00482123
	LOSS [training: 0.18638984631656652 | validation: 0.3163564450494276]
	TIME [epoch: 24.9 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15392648811209886		[learning rate: 0.0047747]
	Learning Rate: 0.00477471
	LOSS [training: 0.15392648811209886 | validation: 0.3577359104569733]
	TIME [epoch: 24.9 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639705649655665		[learning rate: 0.0047286]
	Learning Rate: 0.00472865
	LOSS [training: 0.1639705649655665 | validation: 0.3146598380549835]
	TIME [epoch: 24.9 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16391377132399818		[learning rate: 0.004683]
	Learning Rate: 0.00468302
	LOSS [training: 0.16391377132399818 | validation: 0.3220801785184207]
	TIME [epoch: 24.9 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773528413665635		[learning rate: 0.0046378]
	Learning Rate: 0.00463784
	LOSS [training: 0.17773528413665635 | validation: 0.4094511498199817]
	TIME [epoch: 24.9 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18722946165045978		[learning rate: 0.0045931]
	Learning Rate: 0.00459309
	LOSS [training: 0.18722946165045978 | validation: 0.40639575610439543]
	TIME [epoch: 24.9 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320971903423456		[learning rate: 0.0045488]
	Learning Rate: 0.00454878
	LOSS [training: 0.19320971903423456 | validation: 0.34327396504919677]
	TIME [epoch: 24.9 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762444446374917		[learning rate: 0.0045049]
	Learning Rate: 0.00450489
	LOSS [training: 0.14762444446374917 | validation: 0.32898865869332206]
	TIME [epoch: 24.9 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16449051185488345		[learning rate: 0.0044614]
	Learning Rate: 0.00446143
	LOSS [training: 0.16449051185488345 | validation: 0.37804414693401933]
	TIME [epoch: 24.9 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18592395782338042		[learning rate: 0.0044184]
	Learning Rate: 0.00441838
	LOSS [training: 0.18592395782338042 | validation: 0.36313066006992195]
	TIME [epoch: 24.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17949982523802963		[learning rate: 0.0043758]
	Learning Rate: 0.00437575
	LOSS [training: 0.17949982523802963 | validation: 0.37557231606636093]
	TIME [epoch: 24.9 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17029019831660125		[learning rate: 0.0043335]
	Learning Rate: 0.00433353
	LOSS [training: 0.17029019831660125 | validation: 0.333224084623257]
	TIME [epoch: 24.9 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602845822736328		[learning rate: 0.0042917]
	Learning Rate: 0.00429172
	LOSS [training: 0.1602845822736328 | validation: 0.35456709547109194]
	TIME [epoch: 24.9 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528900274874637		[learning rate: 0.0042503]
	Learning Rate: 0.00425031
	LOSS [training: 0.1528900274874637 | validation: 0.35364470950798477]
	TIME [epoch: 24.9 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20508500096079035		[learning rate: 0.0042093]
	Learning Rate: 0.00420931
	LOSS [training: 0.20508500096079035 | validation: 0.3577306709714312]
	TIME [epoch: 24.9 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838315778338525		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1838315778338525 | validation: 0.4003542983320961]
	TIME [epoch: 24.9 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646818734309345		[learning rate: 0.0041285]
	Learning Rate: 0.00412847
	LOSS [training: 0.1646818734309345 | validation: 0.3099373216905569]
	TIME [epoch: 24.9 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16615213534331807		[learning rate: 0.0040886]
	Learning Rate: 0.00408864
	LOSS [training: 0.16615213534331807 | validation: 0.34099466704812087]
	TIME [epoch: 24.9 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564774450494596		[learning rate: 0.0040492]
	Learning Rate: 0.00404919
	LOSS [training: 0.16564774450494596 | validation: 0.3089335906778395]
	TIME [epoch: 24.9 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15771401989651432		[learning rate: 0.0040101]
	Learning Rate: 0.00401012
	LOSS [training: 0.15771401989651432 | validation: 0.30844744694938014]
	TIME [epoch: 24.9 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684268477172695		[learning rate: 0.0039714]
	Learning Rate: 0.00397143
	LOSS [training: 0.1684268477172695 | validation: 0.33199177834301136]
	TIME [epoch: 24.9 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642824818579384		[learning rate: 0.0039331]
	Learning Rate: 0.00393312
	LOSS [training: 0.1642824818579384 | validation: 0.3523366500135805]
	TIME [epoch: 24.9 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17251976751849496		[learning rate: 0.0038952]
	Learning Rate: 0.00389517
	LOSS [training: 0.17251976751849496 | validation: 0.3220241497100936]
	TIME [epoch: 24.9 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.146709768272757		[learning rate: 0.0038576]
	Learning Rate: 0.00385759
	LOSS [training: 0.146709768272757 | validation: 0.3333822879734823]
	TIME [epoch: 24.9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18008084415319803		[learning rate: 0.0038204]
	Learning Rate: 0.00382037
	LOSS [training: 0.18008084415319803 | validation: 0.32498947254221294]
	TIME [epoch: 24.9 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17680282737798939		[learning rate: 0.0037835]
	Learning Rate: 0.00378351
	LOSS [training: 0.17680282737798939 | validation: 0.3087256797296734]
	TIME [epoch: 24.9 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14835263569514406		[learning rate: 0.003747]
	Learning Rate: 0.003747
	LOSS [training: 0.14835263569514406 | validation: 0.3288399364656067]
	TIME [epoch: 24.9 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18832039090221375		[learning rate: 0.0037109]
	Learning Rate: 0.00371085
	LOSS [training: 0.18832039090221375 | validation: 0.43662145502730937]
	TIME [epoch: 24.9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871474233489933		[learning rate: 0.003675]
	Learning Rate: 0.00367505
	LOSS [training: 0.1871474233489933 | validation: 0.333256157863183]
	TIME [epoch: 24.9 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721844487890427		[learning rate: 0.0036396]
	Learning Rate: 0.00363959
	LOSS [training: 0.1721844487890427 | validation: 0.3364373092163891]
	TIME [epoch: 24.9 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16542697799037548		[learning rate: 0.0036045]
	Learning Rate: 0.00360448
	LOSS [training: 0.16542697799037548 | validation: 0.3964487124940778]
	TIME [epoch: 24.9 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17329134606870222		[learning rate: 0.0035697]
	Learning Rate: 0.0035697
	LOSS [training: 0.17329134606870222 | validation: 0.31256208210169806]
	TIME [epoch: 24.9 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17091026776400675		[learning rate: 0.0035353]
	Learning Rate: 0.00353526
	LOSS [training: 0.17091026776400675 | validation: 0.3344613009069971]
	TIME [epoch: 24.9 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15560333318708286		[learning rate: 0.0035011]
	Learning Rate: 0.00350115
	LOSS [training: 0.15560333318708286 | validation: 0.3629450442026064]
	TIME [epoch: 24.9 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494297292320589		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.1494297292320589 | validation: 0.39634401246868983]
	TIME [epoch: 24.9 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264876217220217		[learning rate: 0.0034339]
	Learning Rate: 0.00343391
	LOSS [training: 0.16264876217220217 | validation: 0.4185342926290407]
	TIME [epoch: 24.9 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712615436216271		[learning rate: 0.0034008]
	Learning Rate: 0.00340078
	LOSS [training: 0.1712615436216271 | validation: 0.3428461396950401]
	TIME [epoch: 24.9 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17117803743315435		[learning rate: 0.003368]
	Learning Rate: 0.00336797
	LOSS [training: 0.17117803743315435 | validation: 0.3208904202285526]
	TIME [epoch: 24.9 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15504945754762653		[learning rate: 0.0033355]
	Learning Rate: 0.00333548
	LOSS [training: 0.15504945754762653 | validation: 0.305053658433248]
	TIME [epoch: 24.9 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618250749971702		[learning rate: 0.0033033]
	Learning Rate: 0.00330329
	LOSS [training: 0.1618250749971702 | validation: 0.32747422145908067]
	TIME [epoch: 24.9 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16295981375542462		[learning rate: 0.0032714]
	Learning Rate: 0.00327142
	LOSS [training: 0.16295981375542462 | validation: 0.33376607525382695]
	TIME [epoch: 24.9 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17800010332116753		[learning rate: 0.0032399]
	Learning Rate: 0.00323986
	LOSS [training: 0.17800010332116753 | validation: 0.3385196394006725]
	TIME [epoch: 24.9 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15906347920649097		[learning rate: 0.0032086]
	Learning Rate: 0.0032086
	LOSS [training: 0.15906347920649097 | validation: 0.30836988738529203]
	TIME [epoch: 24.9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415756134384388		[learning rate: 0.0031776]
	Learning Rate: 0.00317764
	LOSS [training: 0.16415756134384388 | validation: 0.3557010461198049]
	TIME [epoch: 24.9 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640334295004112		[learning rate: 0.003147]
	Learning Rate: 0.00314699
	LOSS [training: 0.1640334295004112 | validation: 0.3360891451722402]
	TIME [epoch: 24.9 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15693603842757525		[learning rate: 0.0031166]
	Learning Rate: 0.00311662
	LOSS [training: 0.15693603842757525 | validation: 0.31926975287792847]
	TIME [epoch: 24.9 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567465473094475		[learning rate: 0.0030866]
	Learning Rate: 0.00308655
	LOSS [training: 0.1567465473094475 | validation: 0.2863563743091958]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689333037005615		[learning rate: 0.0030568]
	Learning Rate: 0.00305677
	LOSS [training: 0.15689333037005615 | validation: 0.34151470169355475]
	TIME [epoch: 24.9 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463314726226989		[learning rate: 0.0030273]
	Learning Rate: 0.00302728
	LOSS [training: 0.1463314726226989 | validation: 0.34007150402389724]
	TIME [epoch: 24.9 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1606342391766926		[learning rate: 0.0029981]
	Learning Rate: 0.00299807
	LOSS [training: 0.1606342391766926 | validation: 0.32136273964620665]
	TIME [epoch: 24.9 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630328234895113		[learning rate: 0.0029691]
	Learning Rate: 0.00296915
	LOSS [training: 0.1630328234895113 | validation: 0.3088770922739836]
	TIME [epoch: 24.9 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444048196249912		[learning rate: 0.0029405]
	Learning Rate: 0.0029405
	LOSS [training: 0.17444048196249912 | validation: 0.33736271702353915]
	TIME [epoch: 24.9 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17183839987610935		[learning rate: 0.0029121]
	Learning Rate: 0.00291213
	LOSS [training: 0.17183839987610935 | validation: 0.47770001357212805]
	TIME [epoch: 24.9 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16747988530214866		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16747988530214866 | validation: 0.3740232547188542]
	TIME [epoch: 24.9 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15133697401109533		[learning rate: 0.0028562]
	Learning Rate: 0.00285621
	LOSS [training: 0.15133697401109533 | validation: 0.334305298883769]
	TIME [epoch: 24.9 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367556569916389		[learning rate: 0.0028286]
	Learning Rate: 0.00282865
	LOSS [training: 0.1367556569916389 | validation: 0.37515407911467025]
	TIME [epoch: 24.9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14831370486339868		[learning rate: 0.0028014]
	Learning Rate: 0.00280136
	LOSS [training: 0.14831370486339868 | validation: 0.3081088362499565]
	TIME [epoch: 24.9 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19164588846842723		[learning rate: 0.0027743]
	Learning Rate: 0.00277433
	LOSS [training: 0.19164588846842723 | validation: 0.32232825301208656]
	TIME [epoch: 24.9 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.18243859551045016		[learning rate: 0.0027476]
	Learning Rate: 0.00274756
	LOSS [training: 0.18243859551045016 | validation: 0.34584063431129136]
	TIME [epoch: 24.9 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17213433869600228		[learning rate: 0.0027211]
	Learning Rate: 0.00272105
	LOSS [training: 0.17213433869600228 | validation: 0.3277589325364904]
	TIME [epoch: 24.9 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792443484481325		[learning rate: 0.0026948]
	Learning Rate: 0.0026948
	LOSS [training: 0.1792443484481325 | validation: 0.3309004602564632]
	TIME [epoch: 24.9 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16807296311216405		[learning rate: 0.0026688]
	Learning Rate: 0.0026688
	LOSS [training: 0.16807296311216405 | validation: 0.3168685155014208]
	TIME [epoch: 24.9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14007004621484073		[learning rate: 0.002643]
	Learning Rate: 0.00264305
	LOSS [training: 0.14007004621484073 | validation: 0.3533116867040766]
	TIME [epoch: 24.9 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14509669482213622		[learning rate: 0.0026175]
	Learning Rate: 0.00261755
	LOSS [training: 0.14509669482213622 | validation: 0.3458437292759803]
	TIME [epoch: 24.9 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.165394677006668		[learning rate: 0.0025923]
	Learning Rate: 0.00259229
	LOSS [training: 0.165394677006668 | validation: 0.3966201173401392]
	TIME [epoch: 24.9 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16825223751764187		[learning rate: 0.0025673]
	Learning Rate: 0.00256728
	LOSS [training: 0.16825223751764187 | validation: 0.3048744616497617]
	TIME [epoch: 24.9 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712033200176714		[learning rate: 0.0025425]
	Learning Rate: 0.00254251
	LOSS [training: 0.1712033200176714 | validation: 0.3193553234848346]
	TIME [epoch: 24.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14771562570746408		[learning rate: 0.002518]
	Learning Rate: 0.00251798
	LOSS [training: 0.14771562570746408 | validation: 0.30326382221840775]
	TIME [epoch: 24.9 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15018700289364623		[learning rate: 0.0024937]
	Learning Rate: 0.00249369
	LOSS [training: 0.15018700289364623 | validation: 0.3352371137176216]
	TIME [epoch: 24.9 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15851479005503707		[learning rate: 0.0024696]
	Learning Rate: 0.00246963
	LOSS [training: 0.15851479005503707 | validation: 0.29688567583868514]
	TIME [epoch: 24.9 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15864058478297893		[learning rate: 0.0024458]
	Learning Rate: 0.0024458
	LOSS [training: 0.15864058478297893 | validation: 0.3251130798795597]
	TIME [epoch: 24.9 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16488516251712682		[learning rate: 0.0024222]
	Learning Rate: 0.0024222
	LOSS [training: 0.16488516251712682 | validation: 0.44337365799291095]
	TIME [epoch: 24.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800433066638032		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.16800433066638032 | validation: 0.33325161829339256]
	TIME [epoch: 24.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449896628929137		[learning rate: 0.0023757]
	Learning Rate: 0.00237569
	LOSS [training: 0.1449896628929137 | validation: 0.3725194508504129]
	TIME [epoch: 24.9 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.162584135088974		[learning rate: 0.0023528]
	Learning Rate: 0.00235277
	LOSS [training: 0.162584135088974 | validation: 0.32379169175094563]
	TIME [epoch: 24.9 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15060364854968675		[learning rate: 0.0023301]
	Learning Rate: 0.00233007
	LOSS [training: 0.15060364854968675 | validation: 0.3180622509372269]
	TIME [epoch: 24.9 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326772432873208		[learning rate: 0.0023076]
	Learning Rate: 0.00230759
	LOSS [training: 0.14326772432873208 | validation: 0.3188906849185429]
	TIME [epoch: 24.9 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711797543139293		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.14711797543139293 | validation: 0.2791143888892444]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15452634115994576		[learning rate: 0.0022633]
	Learning Rate: 0.00226327
	LOSS [training: 0.15452634115994576 | validation: 0.32327009486364655]
	TIME [epoch: 24.9 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14692218090190196		[learning rate: 0.0022414]
	Learning Rate: 0.00224144
	LOSS [training: 0.14692218090190196 | validation: 0.3244178580672314]
	TIME [epoch: 24.9 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641128402150432		[learning rate: 0.0022198]
	Learning Rate: 0.00221981
	LOSS [training: 0.1641128402150432 | validation: 0.316753682568673]
	TIME [epoch: 24.9 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084964003448698		[learning rate: 0.0021984]
	Learning Rate: 0.00219839
	LOSS [training: 0.15084964003448698 | validation: 0.3334761090449293]
	TIME [epoch: 24.9 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15996249173315544		[learning rate: 0.0021772]
	Learning Rate: 0.00217718
	LOSS [training: 0.15996249173315544 | validation: 0.3816891809016907]
	TIME [epoch: 24.9 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580745235068771		[learning rate: 0.0021562]
	Learning Rate: 0.00215618
	LOSS [training: 0.1580745235068771 | validation: 0.3099601595063666]
	TIME [epoch: 24.9 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17356415097646827		[learning rate: 0.0021354]
	Learning Rate: 0.00213537
	LOSS [training: 0.17356415097646827 | validation: 0.3264796912404488]
	TIME [epoch: 24.9 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13523012448615968		[learning rate: 0.0021148]
	Learning Rate: 0.00211477
	LOSS [training: 0.13523012448615968 | validation: 0.32421028869774154]
	TIME [epoch: 24.9 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510900317861172		[learning rate: 0.0020944]
	Learning Rate: 0.00209437
	LOSS [training: 0.1510900317861172 | validation: 0.31935532948218]
	TIME [epoch: 24.9 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15286370173436786		[learning rate: 0.0020742]
	Learning Rate: 0.00207416
	LOSS [training: 0.15286370173436786 | validation: 0.29881894487854593]
	TIME [epoch: 24.9 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724462542345073		[learning rate: 0.0020541]
	Learning Rate: 0.00205415
	LOSS [training: 0.13724462542345073 | validation: 0.30759852015712785]
	TIME [epoch: 78.2 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942918586104315		[learning rate: 0.0020343]
	Learning Rate: 0.00203433
	LOSS [training: 0.14942918586104315 | validation: 0.3179312102634628]
	TIME [epoch: 52.9 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115574323379923		[learning rate: 0.0020147]
	Learning Rate: 0.0020147
	LOSS [training: 0.14115574323379923 | validation: 0.2982730953380204]
	TIME [epoch: 52.9 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486483768260321		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1486483768260321 | validation: 0.3099670587060848]
	TIME [epoch: 52.9 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13325401949158186		[learning rate: 0.001976]
	Learning Rate: 0.00197601
	LOSS [training: 0.13325401949158186 | validation: 0.3113891020421822]
	TIME [epoch: 52.9 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604590245174979		[learning rate: 0.0019569]
	Learning Rate: 0.00195695
	LOSS [training: 0.1604590245174979 | validation: 0.3208974669135235]
	TIME [epoch: 52.9 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16434410502815472		[learning rate: 0.0019381]
	Learning Rate: 0.00193807
	LOSS [training: 0.16434410502815472 | validation: 0.28958847824783623]
	TIME [epoch: 52.9 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13821258752491605		[learning rate: 0.0019194]
	Learning Rate: 0.00191937
	LOSS [training: 0.13821258752491605 | validation: 0.31419210439297424]
	TIME [epoch: 52.9 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15743636629291852		[learning rate: 0.0019008]
	Learning Rate: 0.00190085
	LOSS [training: 0.15743636629291852 | validation: 0.3355005180369887]
	TIME [epoch: 52.9 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536335282780517		[learning rate: 0.0018825]
	Learning Rate: 0.00188251
	LOSS [training: 0.1536335282780517 | validation: 0.32107032349027886]
	TIME [epoch: 52.9 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12955882838208344		[learning rate: 0.0018643]
	Learning Rate: 0.00186434
	LOSS [training: 0.12955882838208344 | validation: 0.325664291439584]
	TIME [epoch: 52.9 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552726034426241		[learning rate: 0.0018464]
	Learning Rate: 0.00184636
	LOSS [training: 0.1552726034426241 | validation: 0.3271196321393268]
	TIME [epoch: 52.9 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423795654389422		[learning rate: 0.0018285]
	Learning Rate: 0.00182854
	LOSS [training: 0.15423795654389422 | validation: 0.3249178290064988]
	TIME [epoch: 52.8 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15951943297395352		[learning rate: 0.0018109]
	Learning Rate: 0.0018109
	LOSS [training: 0.15951943297395352 | validation: 0.31224996234535923]
	TIME [epoch: 52.9 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14617351714891727		[learning rate: 0.0017934]
	Learning Rate: 0.00179343
	LOSS [training: 0.14617351714891727 | validation: 0.3042486946027863]
	TIME [epoch: 52.9 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15325824735072516		[learning rate: 0.0017761]
	Learning Rate: 0.00177613
	LOSS [training: 0.15325824735072516 | validation: 0.3065990038383277]
	TIME [epoch: 52.9 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15161049172553037		[learning rate: 0.001759]
	Learning Rate: 0.00175899
	LOSS [training: 0.15161049172553037 | validation: 0.2933846455483671]
	TIME [epoch: 52.9 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847648905111122		[learning rate: 0.001742]
	Learning Rate: 0.00174202
	LOSS [training: 0.14847648905111122 | validation: 0.3138580688735838]
	TIME [epoch: 52.9 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15254967868942984		[learning rate: 0.0017252]
	Learning Rate: 0.00172521
	LOSS [training: 0.15254967868942984 | validation: 0.3192090979220432]
	TIME [epoch: 52.9 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16428464279074412		[learning rate: 0.0017086]
	Learning Rate: 0.00170857
	LOSS [training: 0.16428464279074412 | validation: 0.31289237423416]
	TIME [epoch: 52.9 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16683136554395245		[learning rate: 0.0016921]
	Learning Rate: 0.00169208
	LOSS [training: 0.16683136554395245 | validation: 0.3310828765579427]
	TIME [epoch: 52.9 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601749600177754		[learning rate: 0.0016758]
	Learning Rate: 0.00167575
	LOSS [training: 0.1601749600177754 | validation: 0.32290049799626724]
	TIME [epoch: 52.9 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15502810993753896		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.15502810993753896 | validation: 0.33996555005235485]
	TIME [epoch: 52.9 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695277178793643		[learning rate: 0.0016436]
	Learning Rate: 0.00164357
	LOSS [training: 0.15695277178793643 | validation: 0.29700049301410886]
	TIME [epoch: 52.9 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14828605148024632		[learning rate: 0.0016277]
	Learning Rate: 0.00162772
	LOSS [training: 0.14828605148024632 | validation: 0.3151402139539284]
	TIME [epoch: 52.9 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.146691382599446		[learning rate: 0.001612]
	Learning Rate: 0.00161201
	LOSS [training: 0.146691382599446 | validation: 0.3137736927535111]
	TIME [epoch: 52.9 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15097375665171564		[learning rate: 0.0015965]
	Learning Rate: 0.00159646
	LOSS [training: 0.15097375665171564 | validation: 0.3180399895749012]
	TIME [epoch: 52.9 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14297523840164356		[learning rate: 0.0015811]
	Learning Rate: 0.00158106
	LOSS [training: 0.14297523840164356 | validation: 0.31486585916236703]
	TIME [epoch: 52.9 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927258616834962		[learning rate: 0.0015658]
	Learning Rate: 0.0015658
	LOSS [training: 0.13927258616834962 | validation: 0.3104049260791481]
	TIME [epoch: 52.9 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485348653882802		[learning rate: 0.0015507]
	Learning Rate: 0.00155069
	LOSS [training: 0.1485348653882802 | validation: 0.2966161681282149]
	TIME [epoch: 52.9 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394959792939239		[learning rate: 0.0015357]
	Learning Rate: 0.00153573
	LOSS [training: 0.1394959792939239 | validation: 0.3145684302045841]
	TIME [epoch: 52.9 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16137350815432977		[learning rate: 0.0015209]
	Learning Rate: 0.00152092
	LOSS [training: 0.16137350815432977 | validation: 0.3140970056837652]
	TIME [epoch: 52.9 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979647673900816		[learning rate: 0.0015062]
	Learning Rate: 0.00150624
	LOSS [training: 0.13979647673900816 | validation: 0.31193283992042103]
	TIME [epoch: 52.9 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14209282567256934		[learning rate: 0.0014917]
	Learning Rate: 0.00149171
	LOSS [training: 0.14209282567256934 | validation: 0.29767418201870216]
	TIME [epoch: 52.9 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13217935874653047		[learning rate: 0.0014773]
	Learning Rate: 0.00147732
	LOSS [training: 0.13217935874653047 | validation: 0.3050571549541788]
	TIME [epoch: 52.9 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15348344566408556		[learning rate: 0.0014631]
	Learning Rate: 0.00146306
	LOSS [training: 0.15348344566408556 | validation: 0.32022359931357386]
	TIME [epoch: 52.9 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396984525116927		[learning rate: 0.0014489]
	Learning Rate: 0.00144895
	LOSS [training: 0.14396984525116927 | validation: 0.3360850217559713]
	TIME [epoch: 52.9 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15516554100143198		[learning rate: 0.001435]
	Learning Rate: 0.00143497
	LOSS [training: 0.15516554100143198 | validation: 0.31617384878327914]
	TIME [epoch: 52.9 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418536101231057		[learning rate: 0.0014211]
	Learning Rate: 0.00142112
	LOSS [training: 0.1418536101231057 | validation: 0.30302791833935827]
	TIME [epoch: 52.9 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350020112666525		[learning rate: 0.0014074]
	Learning Rate: 0.00140741
	LOSS [training: 0.13350020112666525 | validation: 0.34258653849277615]
	TIME [epoch: 52.9 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372071426742549		[learning rate: 0.0013938]
	Learning Rate: 0.00139383
	LOSS [training: 0.1372071426742549 | validation: 0.32949381574882325]
	TIME [epoch: 52.9 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398268098105674		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1398268098105674 | validation: 0.29634833212234574]
	TIME [epoch: 52.9 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713570023681577		[learning rate: 0.0013671]
	Learning Rate: 0.00136707
	LOSS [training: 0.1713570023681577 | validation: 0.35343189052069934]
	TIME [epoch: 52.9 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668977188294508		[learning rate: 0.0013539]
	Learning Rate: 0.00135388
	LOSS [training: 0.1668977188294508 | validation: 0.306514233931188]
	TIME [epoch: 52.9 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361851295989655		[learning rate: 0.0013408]
	Learning Rate: 0.00134081
	LOSS [training: 0.1361851295989655 | validation: 0.29384513408739477]
	TIME [epoch: 52.9 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16072978715107628		[learning rate: 0.0013279]
	Learning Rate: 0.00132788
	LOSS [training: 0.16072978715107628 | validation: 0.3049275542085214]
	TIME [epoch: 52.9 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15218673630956628		[learning rate: 0.0013151]
	Learning Rate: 0.00131507
	LOSS [training: 0.15218673630956628 | validation: 0.31119834470901087]
	TIME [epoch: 52.9 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409540989622319		[learning rate: 0.0013024]
	Learning Rate: 0.00130238
	LOSS [training: 0.1409540989622319 | validation: 0.31524636519137533]
	TIME [epoch: 52.9 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13751342199860578		[learning rate: 0.0012898]
	Learning Rate: 0.00128981
	LOSS [training: 0.13751342199860578 | validation: 0.3081475540488396]
	TIME [epoch: 52.9 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333715469166245		[learning rate: 0.0012774]
	Learning Rate: 0.00127737
	LOSS [training: 0.1333715469166245 | validation: 0.2947163077809329]
	TIME [epoch: 52.9 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466995463833855		[learning rate: 0.001265]
	Learning Rate: 0.00126504
	LOSS [training: 0.1466995463833855 | validation: 0.32971150168274294]
	TIME [epoch: 52.9 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13321131017690496		[learning rate: 0.0012528]
	Learning Rate: 0.00125284
	LOSS [training: 0.13321131017690496 | validation: 0.321613730808972]
	TIME [epoch: 52.9 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13681490062385745		[learning rate: 0.0012407]
	Learning Rate: 0.00124075
	LOSS [training: 0.13681490062385745 | validation: 0.3125706564258884]
	TIME [epoch: 52.9 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481673037280483		[learning rate: 0.0012288]
	Learning Rate: 0.00122878
	LOSS [training: 0.12481673037280483 | validation: 0.3090910834470282]
	TIME [epoch: 52.9 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13034613577382012		[learning rate: 0.0012169]
	Learning Rate: 0.00121692
	LOSS [training: 0.13034613577382012 | validation: 0.3054269190862403]
	TIME [epoch: 52.9 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14666581801328313		[learning rate: 0.0012052]
	Learning Rate: 0.00120518
	LOSS [training: 0.14666581801328313 | validation: 0.3153132223412719]
	TIME [epoch: 52.8 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15716836016063454		[learning rate: 0.0011936]
	Learning Rate: 0.00119355
	LOSS [training: 0.15716836016063454 | validation: 0.36820405303124054]
	TIME [epoch: 52.9 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15662859790162897		[learning rate: 0.001182]
	Learning Rate: 0.00118204
	LOSS [training: 0.15662859790162897 | validation: 0.31426090490794395]
	TIME [epoch: 52.9 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449584337934798		[learning rate: 0.0011706]
	Learning Rate: 0.00117063
	LOSS [training: 0.14449584337934798 | validation: 0.31992640039760956]
	TIME [epoch: 52.9 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14835060754132162		[learning rate: 0.0011593]
	Learning Rate: 0.00115934
	LOSS [training: 0.14835060754132162 | validation: 0.3102323501027159]
	TIME [epoch: 52.9 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16167869417122088		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.16167869417122088 | validation: 0.3131883503391509]
	TIME [epoch: 52.9 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13064757846389027		[learning rate: 0.0011371]
	Learning Rate: 0.00113708
	LOSS [training: 0.13064757846389027 | validation: 0.3005521230910518]
	TIME [epoch: 52.9 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15734014005253133		[learning rate: 0.0011261]
	Learning Rate: 0.00112611
	LOSS [training: 0.15734014005253133 | validation: 0.31145505855661515]
	TIME [epoch: 52.9 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16012990792064521		[learning rate: 0.0011152]
	Learning Rate: 0.00111524
	LOSS [training: 0.16012990792064521 | validation: 0.3102651614468896]
	TIME [epoch: 52.9 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781136583871711		[learning rate: 0.0011045]
	Learning Rate: 0.00110448
	LOSS [training: 0.13781136583871711 | validation: 0.3080174753736205]
	TIME [epoch: 52.9 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14758523966624096		[learning rate: 0.0010938]
	Learning Rate: 0.00109382
	LOSS [training: 0.14758523966624096 | validation: 0.2990764430558238]
	TIME [epoch: 52.9 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15217849008561207		[learning rate: 0.0010833]
	Learning Rate: 0.00108327
	LOSS [training: 0.15217849008561207 | validation: 0.34785457566619116]
	TIME [epoch: 52.9 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17024014791352438		[learning rate: 0.0010728]
	Learning Rate: 0.00107282
	LOSS [training: 0.17024014791352438 | validation: 0.29596363251561425]
	TIME [epoch: 52.9 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14177101677889103		[learning rate: 0.0010625]
	Learning Rate: 0.00106247
	LOSS [training: 0.14177101677889103 | validation: 0.3127189832606142]
	TIME [epoch: 52.9 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640801290142135		[learning rate: 0.0010522]
	Learning Rate: 0.00105222
	LOSS [training: 0.13640801290142135 | validation: 0.31491748544317744]
	TIME [epoch: 52.9 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713320927714934		[learning rate: 0.0010421]
	Learning Rate: 0.00104206
	LOSS [training: 0.13713320927714934 | validation: 0.3044529679979481]
	TIME [epoch: 52.9 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13275640273146702		[learning rate: 0.001032]
	Learning Rate: 0.00103201
	LOSS [training: 0.13275640273146702 | validation: 0.301563691046602]
	TIME [epoch: 52.9 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442330668752019		[learning rate: 0.0010221]
	Learning Rate: 0.00102205
	LOSS [training: 0.1442330668752019 | validation: 0.29727020404381765]
	TIME [epoch: 52.9 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762646613576697		[learning rate: 0.0010122]
	Learning Rate: 0.00101219
	LOSS [training: 0.12762646613576697 | validation: 0.3236227150292827]
	TIME [epoch: 52.9 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14050215543675962		[learning rate: 0.0010024]
	Learning Rate: 0.00100243
	LOSS [training: 0.14050215543675962 | validation: 0.3019949413797679]
	TIME [epoch: 52.9 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13248377987217225		[learning rate: 0.00099275]
	Learning Rate: 0.000992755
	LOSS [training: 0.13248377987217225 | validation: 0.28917040201791794]
	TIME [epoch: 52.9 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313415521448846		[learning rate: 0.00098318]
	Learning Rate: 0.000983177
	LOSS [training: 0.13313415521448846 | validation: 0.3125252269171143]
	TIME [epoch: 52.9 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621829796024845		[learning rate: 0.00097369]
	Learning Rate: 0.000973691
	LOSS [training: 0.1621829796024845 | validation: 0.3064095938247653]
	TIME [epoch: 52.9 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15332596968543682		[learning rate: 0.0009643]
	Learning Rate: 0.000964296
	LOSS [training: 0.15332596968543682 | validation: 0.32177189574957504]
	TIME [epoch: 52.9 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14869963703781325		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.14869963703781325 | validation: 0.3016969671886216]
	TIME [epoch: 52.9 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930320157803274		[learning rate: 0.00094578]
	Learning Rate: 0.000945778
	LOSS [training: 0.15930320157803274 | validation: 0.322276132550233]
	TIME [epoch: 52.9 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500990752945908		[learning rate: 0.00093665]
	Learning Rate: 0.000936653
	LOSS [training: 0.1500990752945908 | validation: 0.29587282954392036]
	TIME [epoch: 52.9 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484049118444079		[learning rate: 0.00092762]
	Learning Rate: 0.000927616
	LOSS [training: 0.1484049118444079 | validation: 0.28875618059324565]
	TIME [epoch: 52.9 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13402748288109217		[learning rate: 0.00091867]
	Learning Rate: 0.000918666
	LOSS [training: 0.13402748288109217 | validation: 0.3033573036392993]
	TIME [epoch: 52.9 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308384982249869		[learning rate: 0.0009098]
	Learning Rate: 0.000909803
	LOSS [training: 0.1308384982249869 | validation: 0.3040066499407234]
	TIME [epoch: 52.9 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396900269728397		[learning rate: 0.00090102]
	Learning Rate: 0.000901025
	LOSS [training: 0.1396900269728397 | validation: 0.30204219052527514]
	TIME [epoch: 52.9 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14361737771039143		[learning rate: 0.00089233]
	Learning Rate: 0.000892332
	LOSS [training: 0.14361737771039143 | validation: 0.31392299619069175]
	TIME [epoch: 52.9 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304407066355847		[learning rate: 0.00088372]
	Learning Rate: 0.000883722
	LOSS [training: 0.13304407066355847 | validation: 0.30372332949571407]
	TIME [epoch: 52.9 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13681635202063264		[learning rate: 0.0008752]
	Learning Rate: 0.000875196
	LOSS [training: 0.13681635202063264 | validation: 0.30417965819426773]
	TIME [epoch: 52.9 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440179242529623		[learning rate: 0.00086675]
	Learning Rate: 0.000866752
	LOSS [training: 0.1440179242529623 | validation: 0.29670933305602054]
	TIME [epoch: 52.9 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539756948413728		[learning rate: 0.00085839]
	Learning Rate: 0.000858389
	LOSS [training: 0.1539756948413728 | validation: 0.31551275206722407]
	TIME [epoch: 52.9 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585673545235375		[learning rate: 0.00085011]
	Learning Rate: 0.000850107
	LOSS [training: 0.1585673545235375 | validation: 0.30842988163531343]
	TIME [epoch: 52.9 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15933130145402838		[learning rate: 0.00084191]
	Learning Rate: 0.000841905
	LOSS [training: 0.15933130145402838 | validation: 0.30735060486009086]
	TIME [epoch: 52.9 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313848079257565		[learning rate: 0.00083378]
	Learning Rate: 0.000833782
	LOSS [training: 0.13313848079257565 | validation: 0.29661133633269504]
	TIME [epoch: 52.9 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13878559085365977		[learning rate: 0.00082574]
	Learning Rate: 0.000825738
	LOSS [training: 0.13878559085365977 | validation: 0.3068279751007905]
	TIME [epoch: 52.9 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14718737525710954		[learning rate: 0.00081777]
	Learning Rate: 0.000817771
	LOSS [training: 0.14718737525710954 | validation: 0.2991642912797186]
	TIME [epoch: 52.9 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14415187711104255		[learning rate: 0.00080988]
	Learning Rate: 0.000809881
	LOSS [training: 0.14415187711104255 | validation: 0.2991406028530252]
	TIME [epoch: 52.9 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560124122004241		[learning rate: 0.00080207]
	Learning Rate: 0.000802067
	LOSS [training: 0.1560124122004241 | validation: 0.31918436593645627]
	TIME [epoch: 52.9 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13223890703901076		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.13223890703901076 | validation: 0.3114202152389565]
	TIME [epoch: 52.9 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15090778810825173		[learning rate: 0.00078666]
	Learning Rate: 0.000786664
	LOSS [training: 0.15090778810825173 | validation: 0.3034014002590883]
	TIME [epoch: 52.9 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581225101984527		[learning rate: 0.00077907]
	Learning Rate: 0.000779074
	LOSS [training: 0.1581225101984527 | validation: 0.2975851726170348]
	TIME [epoch: 135 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13802341706961774		[learning rate: 0.00077156]
	Learning Rate: 0.000771558
	LOSS [training: 0.13802341706961774 | validation: 0.3259861279583576]
	TIME [epoch: 109 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15673127151907323		[learning rate: 0.00076411]
	Learning Rate: 0.000764114
	LOSS [training: 0.15673127151907323 | validation: 0.3063545916517315]
	TIME [epoch: 109 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331391163969441		[learning rate: 0.00075674]
	Learning Rate: 0.000756741
	LOSS [training: 0.1331391163969441 | validation: 0.3090628488427564]
	TIME [epoch: 109 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.136851233284494		[learning rate: 0.00074944]
	Learning Rate: 0.00074944
	LOSS [training: 0.136851233284494 | validation: 0.3137680031424722]
	TIME [epoch: 109 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463136771225948		[learning rate: 0.00074221]
	Learning Rate: 0.000742209
	LOSS [training: 0.1463136771225948 | validation: 0.317101616591464]
	TIME [epoch: 109 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677556317278848		[learning rate: 0.00073505]
	Learning Rate: 0.000735048
	LOSS [training: 0.14677556317278848 | validation: 0.29048899739183554]
	TIME [epoch: 109 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13937488077154717		[learning rate: 0.00072796]
	Learning Rate: 0.000727956
	LOSS [training: 0.13937488077154717 | validation: 0.30028573417429333]
	TIME [epoch: 109 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14391536785004985		[learning rate: 0.00072093]
	Learning Rate: 0.000720933
	LOSS [training: 0.14391536785004985 | validation: 0.3202107413047546]
	TIME [epoch: 109 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13432654166495847		[learning rate: 0.00071398]
	Learning Rate: 0.000713977
	LOSS [training: 0.13432654166495847 | validation: 0.3072720294046018]
	TIME [epoch: 109 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14498086017917686		[learning rate: 0.00070709]
	Learning Rate: 0.000707088
	LOSS [training: 0.14498086017917686 | validation: 0.30529204325757386]
	TIME [epoch: 109 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12972645430560675		[learning rate: 0.00070027]
	Learning Rate: 0.000700266
	LOSS [training: 0.12972645430560675 | validation: 0.3027477310405295]
	TIME [epoch: 109 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433753481627506		[learning rate: 0.00069351]
	Learning Rate: 0.00069351
	LOSS [training: 0.1433753481627506 | validation: 0.306760643562473]
	TIME [epoch: 109 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517458989479717		[learning rate: 0.00068682]
	Learning Rate: 0.000686819
	LOSS [training: 0.1517458989479717 | validation: 0.3312226629544442]
	TIME [epoch: 109 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15636185178514794		[learning rate: 0.00068019]
	Learning Rate: 0.000680192
	LOSS [training: 0.15636185178514794 | validation: 0.3023884549336932]
	TIME [epoch: 109 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13402786617181534		[learning rate: 0.00067363]
	Learning Rate: 0.000673629
	LOSS [training: 0.13402786617181534 | validation: 0.3005238113788256]
	TIME [epoch: 109 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656177188416135		[learning rate: 0.00066713]
	Learning Rate: 0.00066713
	LOSS [training: 0.13656177188416135 | validation: 0.3057130555682504]
	TIME [epoch: 109 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452359117580566		[learning rate: 0.00066069]
	Learning Rate: 0.000660693
	LOSS [training: 0.1452359117580566 | validation: 0.2913506499955364]
	TIME [epoch: 109 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15843681595086012		[learning rate: 0.00065432]
	Learning Rate: 0.000654319
	LOSS [training: 0.15843681595086012 | validation: 0.31520267478383485]
	TIME [epoch: 109 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14498345152423947		[learning rate: 0.00064801]
	Learning Rate: 0.000648006
	LOSS [training: 0.14498345152423947 | validation: 0.3093903929497354]
	TIME [epoch: 109 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562443857103045		[learning rate: 0.00064175]
	Learning Rate: 0.000641754
	LOSS [training: 0.1562443857103045 | validation: 0.2923194915506136]
	TIME [epoch: 109 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396186499538954		[learning rate: 0.00063556]
	Learning Rate: 0.000635562
	LOSS [training: 0.1396186499538954 | validation: 0.30022873009702244]
	TIME [epoch: 109 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329485319928023		[learning rate: 0.00062943]
	Learning Rate: 0.00062943
	LOSS [training: 0.12329485319928023 | validation: 0.3016473220361358]
	TIME [epoch: 109 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385538674921939		[learning rate: 0.00062336]
	Learning Rate: 0.000623357
	LOSS [training: 0.1385538674921939 | validation: 0.3054976834671671]
	TIME [epoch: 109 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411136262439102		[learning rate: 0.00061734]
	Learning Rate: 0.000617343
	LOSS [training: 0.1411136262439102 | validation: 0.3046614583353349]
	TIME [epoch: 109 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13050632088652436		[learning rate: 0.00061139]
	Learning Rate: 0.000611386
	LOSS [training: 0.13050632088652436 | validation: 0.30150406363443055]
	TIME [epoch: 109 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14878509514760918		[learning rate: 0.00060549]
	Learning Rate: 0.000605487
	LOSS [training: 0.14878509514760918 | validation: 0.3157974346189684]
	TIME [epoch: 109 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351105565272344		[learning rate: 0.00059965]
	Learning Rate: 0.000599646
	LOSS [training: 0.15351105565272344 | validation: 0.29665488436320075]
	TIME [epoch: 109 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838798117768278		[learning rate: 0.00059386]
	Learning Rate: 0.00059386
	LOSS [training: 0.13838798117768278 | validation: 0.3165069571398296]
	TIME [epoch: 109 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540093024397763		[learning rate: 0.00058813]
	Learning Rate: 0.00058813
	LOSS [training: 0.1540093024397763 | validation: 0.31707927764039195]
	TIME [epoch: 109 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14276137832782226		[learning rate: 0.00058246]
	Learning Rate: 0.000582456
	LOSS [training: 0.14276137832782226 | validation: 0.3110314603295641]
	TIME [epoch: 109 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13059036412804403		[learning rate: 0.00057684]
	Learning Rate: 0.000576836
	LOSS [training: 0.13059036412804403 | validation: 0.304337061276016]
	TIME [epoch: 109 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474201351167861		[learning rate: 0.00057127]
	Learning Rate: 0.000571271
	LOSS [training: 0.1474201351167861 | validation: 0.30320445352309033]
	TIME [epoch: 109 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089150063550964		[learning rate: 0.00056576]
	Learning Rate: 0.000565759
	LOSS [training: 0.13089150063550964 | validation: 0.31491198739646925]
	TIME [epoch: 109 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490702747450828		[learning rate: 0.0005603]
	Learning Rate: 0.0005603
	LOSS [training: 0.13490702747450828 | validation: 0.3096594558094031]
	TIME [epoch: 109 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13685130094871548		[learning rate: 0.00055489]
	Learning Rate: 0.000554895
	LOSS [training: 0.13685130094871548 | validation: 0.2956565766402669]
	TIME [epoch: 109 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479034052507372		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.1479034052507372 | validation: 0.3046464838876507]
	TIME [epoch: 109 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462642180647853		[learning rate: 0.00054424]
	Learning Rate: 0.000544239
	LOSS [training: 0.1462642180647853 | validation: 0.31498296803420955]
	TIME [epoch: 109 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421090904624322		[learning rate: 0.00053899]
	Learning Rate: 0.000538988
	LOSS [training: 0.1421090904624322 | validation: 0.3155473270972507]
	TIME [epoch: 109 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313642799163948		[learning rate: 0.00053379]
	Learning Rate: 0.000533787
	LOSS [training: 0.1313642799163948 | validation: 0.31211809510793675]
	TIME [epoch: 109 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14959163994642072		[learning rate: 0.00052864]
	Learning Rate: 0.000528637
	LOSS [training: 0.14959163994642072 | validation: 0.300826468066635]
	TIME [epoch: 109 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938516101061717		[learning rate: 0.00052354]
	Learning Rate: 0.000523537
	LOSS [training: 0.15938516101061717 | validation: 0.3139218242542148]
	TIME [epoch: 109 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766307202319486		[learning rate: 0.00051849]
	Learning Rate: 0.000518486
	LOSS [training: 0.13766307202319486 | validation: 0.3026012608999975]
	TIME [epoch: 109 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491028474358836		[learning rate: 0.00051348]
	Learning Rate: 0.000513483
	LOSS [training: 0.14491028474358836 | validation: 0.3026169184112758]
	TIME [epoch: 109 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021602856930354		[learning rate: 0.00050853]
	Learning Rate: 0.000508529
	LOSS [training: 0.14021602856930354 | validation: 0.2935050343912791]
	TIME [epoch: 109 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532991719466084		[learning rate: 0.00050362]
	Learning Rate: 0.000503623
	LOSS [training: 0.13532991719466084 | validation: 0.2999578298172994]
	TIME [epoch: 109 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15574379163751934		[learning rate: 0.00049876]
	Learning Rate: 0.000498764
	LOSS [training: 0.15574379163751934 | validation: 0.29813368917629535]
	TIME [epoch: 109 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15331828581590484		[learning rate: 0.00049395]
	Learning Rate: 0.000493951
	LOSS [training: 0.15331828581590484 | validation: 0.29880579740413493]
	TIME [epoch: 109 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13993850496462965		[learning rate: 0.00048919]
	Learning Rate: 0.000489186
	LOSS [training: 0.13993850496462965 | validation: 0.29630218442448064]
	TIME [epoch: 109 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445618437092046		[learning rate: 0.00048447]
	Learning Rate: 0.000484466
	LOSS [training: 0.1445618437092046 | validation: 0.2970272342528181]
	TIME [epoch: 109 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15209000318351465		[learning rate: 0.00047979]
	Learning Rate: 0.000479792
	LOSS [training: 0.15209000318351465 | validation: 0.29369929974664877]
	TIME [epoch: 109 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.150523473212179		[learning rate: 0.00047516]
	Learning Rate: 0.000475162
	LOSS [training: 0.150523473212179 | validation: 0.3049980961382609]
	TIME [epoch: 109 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578688509544704		[learning rate: 0.00047058]
	Learning Rate: 0.000470578
	LOSS [training: 0.14578688509544704 | validation: 0.30573396507451]
	TIME [epoch: 109 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12375937332932302		[learning rate: 0.00046604]
	Learning Rate: 0.000466038
	LOSS [training: 0.12375937332932302 | validation: 0.29794701524792033]
	TIME [epoch: 109 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224555719290127		[learning rate: 0.00046154]
	Learning Rate: 0.000461541
	LOSS [training: 0.14224555719290127 | validation: 0.2977904669693018]
	TIME [epoch: 109 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369268546002872		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.1369268546002872 | validation: 0.3056838798230218]
	TIME [epoch: 109 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357981405099047		[learning rate: 0.00045268]
	Learning Rate: 0.000452678
	LOSS [training: 0.1357981405099047 | validation: 0.30150997640165056]
	TIME [epoch: 109 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353601814683026		[learning rate: 0.00044831]
	Learning Rate: 0.00044831
	LOSS [training: 0.1353601814683026 | validation: 0.297542049087083]
	TIME [epoch: 109 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14899330156166862		[learning rate: 0.00044399]
	Learning Rate: 0.000443985
	LOSS [training: 0.14899330156166862 | validation: 0.2997331575946154]
	TIME [epoch: 109 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574661692951953		[learning rate: 0.0004397]
	Learning Rate: 0.000439701
	LOSS [training: 0.1574661692951953 | validation: 0.30692801950357784]
	TIME [epoch: 109 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14481628673886687		[learning rate: 0.00043546]
	Learning Rate: 0.000435459
	LOSS [training: 0.14481628673886687 | validation: 0.30179353547723625]
	TIME [epoch: 109 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282014757610725		[learning rate: 0.00043126]
	Learning Rate: 0.000431258
	LOSS [training: 0.1282014757610725 | validation: 0.30656983454890363]
	TIME [epoch: 109 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442795078088738		[learning rate: 0.0004271]
	Learning Rate: 0.000427097
	LOSS [training: 0.1442795078088738 | validation: 0.30891173278368944]
	TIME [epoch: 109 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413030692628192		[learning rate: 0.00042298]
	Learning Rate: 0.000422976
	LOSS [training: 0.13413030692628192 | validation: 0.2934355736860695]
	TIME [epoch: 109 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377360089116175		[learning rate: 0.0004189]
	Learning Rate: 0.000418895
	LOSS [training: 0.13377360089116175 | validation: 0.3093834521401113]
	TIME [epoch: 109 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676301916431577		[learning rate: 0.00041485]
	Learning Rate: 0.000414853
	LOSS [training: 0.13676301916431577 | validation: 0.3087331230611734]
	TIME [epoch: 109 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14130072874041633		[learning rate: 0.00041085]
	Learning Rate: 0.000410851
	LOSS [training: 0.14130072874041633 | validation: 0.29675818151710637]
	TIME [epoch: 109 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605363449788178		[learning rate: 0.00040689]
	Learning Rate: 0.000406887
	LOSS [training: 0.14605363449788178 | validation: 0.2995300195195881]
	TIME [epoch: 109 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278998868473008		[learning rate: 0.00040296]
	Learning Rate: 0.000402961
	LOSS [training: 0.14278998868473008 | validation: 0.30643468541672775]
	TIME [epoch: 109 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036843884528064		[learning rate: 0.00039907]
	Learning Rate: 0.000399073
	LOSS [training: 0.15036843884528064 | validation: 0.31015986077836394]
	TIME [epoch: 109 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15317495227552538		[learning rate: 0.00039522]
	Learning Rate: 0.000395223
	LOSS [training: 0.15317495227552538 | validation: 0.29878258275789454]
	TIME [epoch: 109 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268308989464522		[learning rate: 0.00039141]
	Learning Rate: 0.00039141
	LOSS [training: 0.1268308989464522 | validation: 0.30609247959245445]
	TIME [epoch: 109 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566489427003978		[learning rate: 0.00038763]
	Learning Rate: 0.000387633
	LOSS [training: 0.1566489427003978 | validation: 0.3088952037897849]
	TIME [epoch: 109 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386356308753405		[learning rate: 0.00038389]
	Learning Rate: 0.000383893
	LOSS [training: 0.1386356308753405 | validation: 0.3038963930437851]
	TIME [epoch: 109 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15241021201399862		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.15241021201399862 | validation: 0.3056813698458579]
	TIME [epoch: 109 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15633482956288725		[learning rate: 0.00037652]
	Learning Rate: 0.000376521
	LOSS [training: 0.15633482956288725 | validation: 0.31310576997602163]
	TIME [epoch: 109 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362268802909843		[learning rate: 0.00037289]
	Learning Rate: 0.000372888
	LOSS [training: 0.1362268802909843 | validation: 0.29792560475004093]
	TIME [epoch: 109 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14212919722069595		[learning rate: 0.00036929]
	Learning Rate: 0.000369291
	LOSS [training: 0.14212919722069595 | validation: 0.3008286690952815]
	TIME [epoch: 109 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13841647635151433		[learning rate: 0.00036573]
	Learning Rate: 0.000365728
	LOSS [training: 0.13841647635151433 | validation: 0.3035819554783334]
	TIME [epoch: 109 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14699641530619104		[learning rate: 0.0003622]
	Learning Rate: 0.000362199
	LOSS [training: 0.14699641530619104 | validation: 0.2923216595740235]
	TIME [epoch: 109 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14183952121097815		[learning rate: 0.0003587]
	Learning Rate: 0.000358705
	LOSS [training: 0.14183952121097815 | validation: 0.30398462092910905]
	TIME [epoch: 109 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243934646650006		[learning rate: 0.00035524]
	Learning Rate: 0.000355244
	LOSS [training: 0.14243934646650006 | validation: 0.3099590694788389]
	TIME [epoch: 109 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575615722262313		[learning rate: 0.00035182]
	Learning Rate: 0.000351816
	LOSS [training: 0.13575615722262313 | validation: 0.3005130367975372]
	TIME [epoch: 109 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836770016329602		[learning rate: 0.00034842]
	Learning Rate: 0.000348422
	LOSS [training: 0.12836770016329602 | validation: 0.3120060608197065]
	TIME [epoch: 109 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14471026451340416		[learning rate: 0.00034506]
	Learning Rate: 0.00034506
	LOSS [training: 0.14471026451340416 | validation: 0.31187350935026914]
	TIME [epoch: 109 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14731235013194982		[learning rate: 0.00034173]
	Learning Rate: 0.000341731
	LOSS [training: 0.14731235013194982 | validation: 0.3063014826508207]
	TIME [epoch: 109 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12657975117355072		[learning rate: 0.00033843]
	Learning Rate: 0.000338434
	LOSS [training: 0.12657975117355072 | validation: 0.3114077769928587]
	TIME [epoch: 109 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421238167564438		[learning rate: 0.00033517]
	Learning Rate: 0.000335168
	LOSS [training: 0.1421238167564438 | validation: 0.3031310189758428]
	TIME [epoch: 109 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.130611279286728		[learning rate: 0.00033193]
	Learning Rate: 0.000331935
	LOSS [training: 0.130611279286728 | validation: 0.29842407623172196]
	TIME [epoch: 109 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786960556378536		[learning rate: 0.00032873]
	Learning Rate: 0.000328732
	LOSS [training: 0.13786960556378536 | validation: 0.30682027911552656]
	TIME [epoch: 109 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416013450850486		[learning rate: 0.00032556]
	Learning Rate: 0.00032556
	LOSS [training: 0.13416013450850486 | validation: 0.3018994321078215]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12b_20240716_163620/states/model_facs_v3_dec2b_2dpca_v12b_391.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 18737.269 seconds.
