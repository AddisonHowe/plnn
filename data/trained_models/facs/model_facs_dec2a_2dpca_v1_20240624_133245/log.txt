Args:
Namespace(name='model_facs_dec2a_2dpca_v1', outdir='out/model_training/model_facs_dec2a_2dpca_v1', training_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3269185338

Training model...

Saving initial model state to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4907896531869361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4907896531869361 | validation: 0.40474940942111104]
	TIME [epoch: 45.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961293675151105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2961293675151105 | validation: 0.3544149477057353]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24361940426208042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24361940426208042 | validation: 0.3751981466305719]
	TIME [epoch: 20.8 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25886929666495223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25886929666495223 | validation: 0.33111254347446867]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23609631221433097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23609631221433097 | validation: 0.32936796774920346]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2447349959754089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2447349959754089 | validation: 0.3615405143736952]
	TIME [epoch: 20.8 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2274004989958641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2274004989958641 | validation: 0.31646092624089517]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23520358807067926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23520358807067926 | validation: 0.4009828984891403]
	TIME [epoch: 20.8 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2298501196744792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2298501196744792 | validation: 0.35360091259951704]
	TIME [epoch: 20.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2370200507647428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2370200507647428 | validation: 0.295584070210246]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19224633064650878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19224633064650878 | validation: 0.3038470070575253]
	TIME [epoch: 20.8 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19860172030875956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19860172030875956 | validation: 0.3096561423400966]
	TIME [epoch: 20.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23167071236813647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23167071236813647 | validation: 0.31019960119778067]
	TIME [epoch: 20.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20141189993231207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20141189993231207 | validation: 0.2782096055189005]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20084852126632793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20084852126632793 | validation: 0.26940743297525277]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16920010065416588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16920010065416588 | validation: 0.2648556755184922]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17726918779971826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17726918779971826 | validation: 0.28213785966766924]
	TIME [epoch: 20.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1684971136793064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1684971136793064 | validation: 0.27242150077946303]
	TIME [epoch: 20.7 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17910333758136146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17910333758136146 | validation: 0.3534815259607801]
	TIME [epoch: 20.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17691604871040784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17691604871040784 | validation: 0.3084675668879676]
	TIME [epoch: 20.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18577157809967407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18577157809967407 | validation: 0.27639326847077295]
	TIME [epoch: 20.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16845898866596834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16845898866596834 | validation: 0.25007989247307216]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15869399968985287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15869399968985287 | validation: 0.2525046344597108]
	TIME [epoch: 20.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759692105109272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1759692105109272 | validation: 0.25953666327085245]
	TIME [epoch: 20.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16021305461536234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16021305461536234 | validation: 0.2347711410191984]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15250813594275145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15250813594275145 | validation: 0.2732524239447651]
	TIME [epoch: 20.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14598199313127863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14598199313127863 | validation: 0.2438248230414501]
	TIME [epoch: 20.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907225012971479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1907225012971479 | validation: 0.2540611353096996]
	TIME [epoch: 20.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.177867338362446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.177867338362446 | validation: 0.22603098348135575]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1561597430678692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1561597430678692 | validation: 0.2715996983517035]
	TIME [epoch: 20.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18725227334792055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18725227334792055 | validation: 0.22505554345324374]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16205322080858903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16205322080858903 | validation: 0.2599101455456083]
	TIME [epoch: 20.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655186595496519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1655186595496519 | validation: 0.22961816294116114]
	TIME [epoch: 20.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16031677061388044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16031677061388044 | validation: 0.2365226420479054]
	TIME [epoch: 20.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518295089504062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1518295089504062 | validation: 0.22165568311560613]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16613329834801682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16613329834801682 | validation: 0.22985387565133994]
	TIME [epoch: 20.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15444178680046716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15444178680046716 | validation: 0.2632844354064273]
	TIME [epoch: 20.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16583312932959066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16583312932959066 | validation: 0.22548856016231106]
	TIME [epoch: 20.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15212711434218829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15212711434218829 | validation: 0.2169822964118045]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14848282821740214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14848282821740214 | validation: 0.20635610771304808]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1418634192698099		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.1418634192698099 | validation: 0.2731506256347439]
	TIME [epoch: 20.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15623350817498588		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.15623350817498588 | validation: 0.22353971622653535]
	TIME [epoch: 20.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.143509441562771		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.143509441562771 | validation: 0.21575434000576998]
	TIME [epoch: 20.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14641263256110837		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.14641263256110837 | validation: 0.23758772281951807]
	TIME [epoch: 20.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17247566969917366		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.17247566969917366 | validation: 0.24232858900573104]
	TIME [epoch: 20.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15789098602802992		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.15789098602802992 | validation: 0.21534947640300078]
	TIME [epoch: 20.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14667275521885442		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.14667275521885442 | validation: 0.20922609168594913]
	TIME [epoch: 20.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14367988547551538		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.14367988547551538 | validation: 0.19316685967788255]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15562439151267393		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.15562439151267393 | validation: 0.20380096582171328]
	TIME [epoch: 20.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1480986994194772		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.1480986994194772 | validation: 0.21987745535673203]
	TIME [epoch: 20.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14503399369432815		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.14503399369432815 | validation: 0.20339598940063996]
	TIME [epoch: 20.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14603070316535555		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.14603070316535555 | validation: 0.2090423439008637]
	TIME [epoch: 20.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15350343861452043		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.15350343861452043 | validation: 0.21268633969193285]
	TIME [epoch: 20.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493208660920212		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.1493208660920212 | validation: 0.2129060032406372]
	TIME [epoch: 20.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518517345393316		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.1518517345393316 | validation: 0.20383308138977643]
	TIME [epoch: 20.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14287761194904774		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.14287761194904774 | validation: 0.23658819521105642]
	TIME [epoch: 20.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1436169996739828		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.1436169996739828 | validation: 0.21872365371861396]
	TIME [epoch: 20.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13510592296390617		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.13510592296390617 | validation: 0.21652251866151345]
	TIME [epoch: 20.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13599341756204714		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.13599341756204714 | validation: 0.19588784311263846]
	TIME [epoch: 20.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12974158456575186		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.12974158456575186 | validation: 0.17810746053870463]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1407389285236563		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.1407389285236563 | validation: 0.1775503051531313]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12897442671017537		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.12897442671017537 | validation: 0.2103317299914214]
	TIME [epoch: 20.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253369794844427		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.1253369794844427 | validation: 0.2574237262949832]
	TIME [epoch: 21 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14937300487437685		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.14937300487437685 | validation: 0.21244571596728232]
	TIME [epoch: 21 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14370741851963956		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.14370741851963956 | validation: 0.1816743385103059]
	TIME [epoch: 20.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11722335354362552		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.11722335354362552 | validation: 0.18129248803429196]
	TIME [epoch: 20.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13252127982319545		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.13252127982319545 | validation: 0.2439763588691926]
	TIME [epoch: 20.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14169329456758709		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.14169329456758709 | validation: 0.24019511310184977]
	TIME [epoch: 20.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17249190077891854		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.17249190077891854 | validation: 0.19250749392291555]
	TIME [epoch: 20.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12536700964569444		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.12536700964569444 | validation: 0.2300862873303282]
	TIME [epoch: 20.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13744765821809693		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.13744765821809693 | validation: 0.22334906780338346]
	TIME [epoch: 20.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14225387547295448		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.14225387547295448 | validation: 0.1991808367881355]
	TIME [epoch: 20.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13658277437365748		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.13658277437365748 | validation: 0.21408308116152575]
	TIME [epoch: 20.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1165904821538037		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.1165904821538037 | validation: 0.19962410192601351]
	TIME [epoch: 20.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12263090120789025		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.12263090120789025 | validation: 0.23142159586795585]
	TIME [epoch: 20.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15317426667724682		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.15317426667724682 | validation: 0.20545931067114834]
	TIME [epoch: 20.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16053397554045593		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.16053397554045593 | validation: 0.19790007826840178]
	TIME [epoch: 20.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547210494174508		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.1547210494174508 | validation: 0.18544931021082012]
	TIME [epoch: 20.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13269866414065515		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.13269866414065515 | validation: 0.20992201167147054]
	TIME [epoch: 20.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13401743454754111		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.13401743454754111 | validation: 0.20087000077512585]
	TIME [epoch: 20.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824086051877778		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.15824086051877778 | validation: 0.18634838231992684]
	TIME [epoch: 20.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12969668551816627		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12969668551816627 | validation: 0.1949577121177213]
	TIME [epoch: 20.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12763946999872533		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.12763946999872533 | validation: 0.21270331862565112]
	TIME [epoch: 20.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13339120633081825		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.13339120633081825 | validation: 0.17138215222175485]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11325602172265534		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.11325602172265534 | validation: 0.18074968404752945]
	TIME [epoch: 20.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11091883466626602		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.11091883466626602 | validation: 0.17771044490522356]
	TIME [epoch: 20.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.139501207961942		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.139501207961942 | validation: 0.22825101256137956]
	TIME [epoch: 20.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12589125922499605		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.12589125922499605 | validation: 0.16246330922974128]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12493030754446295		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.12493030754446295 | validation: 0.22213231280490564]
	TIME [epoch: 20.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1409262413803022		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.1409262413803022 | validation: 0.19348912950446132]
	TIME [epoch: 20.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1321404826796917		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1321404826796917 | validation: 0.22203750772267777]
	TIME [epoch: 20.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525772966572232		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1525772966572232 | validation: 0.17285868190717066]
	TIME [epoch: 20.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11971803043843358		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.11971803043843358 | validation: 0.20326992386836987]
	TIME [epoch: 20.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13166516262869993		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.13166516262869993 | validation: 0.1762381147129422]
	TIME [epoch: 20.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11605527483849207		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.11605527483849207 | validation: 0.18996379165567123]
	TIME [epoch: 20.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11218356096007157		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.11218356096007157 | validation: 0.19824881909622366]
	TIME [epoch: 20.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11223963623471811		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.11223963623471811 | validation: 0.2080393736578803]
	TIME [epoch: 20.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12582073174859837		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.12582073174859837 | validation: 0.17278336264209465]
	TIME [epoch: 20.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12157081036674555		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.12157081036674555 | validation: 0.18310501809884722]
	TIME [epoch: 20.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11704758771293725		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11704758771293725 | validation: 0.18944999152999212]
	TIME [epoch: 20.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1295745737951509		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.1295745737951509 | validation: 0.21172686133058746]
	TIME [epoch: 20.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1346069656732297		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.1346069656732297 | validation: 0.1649768186062202]
	TIME [epoch: 20.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11736343864732204		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.11736343864732204 | validation: 0.18445968231509804]
	TIME [epoch: 20.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11759385652383729		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.11759385652383729 | validation: 0.19344425783325625]
	TIME [epoch: 20.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12507775731983267		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.12507775731983267 | validation: 0.1786808527288081]
	TIME [epoch: 20.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10537386642630105		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.10537386642630105 | validation: 0.2755908600040432]
	TIME [epoch: 20.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13122749437111159		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.13122749437111159 | validation: 0.19216611818892132]
	TIME [epoch: 20.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12872081257310725		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.12872081257310725 | validation: 0.17825849660963478]
	TIME [epoch: 20.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11210935720334873		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.11210935720334873 | validation: 0.17001588382925664]
	TIME [epoch: 20.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13124787022463758		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.13124787022463758 | validation: 0.1940672599462754]
	TIME [epoch: 20.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.115632182512163		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.115632182512163 | validation: 0.17553268399968044]
	TIME [epoch: 20.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11748462123228758		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.11748462123228758 | validation: 0.20093323855668688]
	TIME [epoch: 20.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12287048062471154		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.12287048062471154 | validation: 0.1837281976535626]
	TIME [epoch: 20.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1164732066541748		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.1164732066541748 | validation: 0.17924066427803187]
	TIME [epoch: 20.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12217825143283804		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.12217825143283804 | validation: 0.216311294987163]
	TIME [epoch: 20.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10794014077633048		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.10794014077633048 | validation: 0.19494246238642376]
	TIME [epoch: 20.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12397059218322937		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.12397059218322937 | validation: 0.17447851534144826]
	TIME [epoch: 20.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1108447954548287		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.1108447954548287 | validation: 0.19391371389288145]
	TIME [epoch: 20.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12154862721225432		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.12154862721225432 | validation: 0.23747473056076177]
	TIME [epoch: 20.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252979034168158		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.1252979034168158 | validation: 0.16426900121997806]
	TIME [epoch: 20.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168525465324681		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.1168525465324681 | validation: 0.19496455155721154]
	TIME [epoch: 20.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.120405877360057		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.120405877360057 | validation: 0.16296080663035978]
	TIME [epoch: 20.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429848827806279		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.10429848827806279 | validation: 0.20105793530484217]
	TIME [epoch: 20.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12344506193492596		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.12344506193492596 | validation: 0.17291141816681208]
	TIME [epoch: 20.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11525621067051148		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.11525621067051148 | validation: 0.1871314697930039]
	TIME [epoch: 20.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12932272494389946		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.12932272494389946 | validation: 0.1803656795414246]
	TIME [epoch: 20.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11109850633929681		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11109850633929681 | validation: 0.1725955313251683]
	TIME [epoch: 20.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12648322571799836		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.12648322571799836 | validation: 0.17569443499072485]
	TIME [epoch: 20.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11915230688579033		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.11915230688579033 | validation: 0.18039572664787637]
	TIME [epoch: 20.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11015165093522125		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.11015165093522125 | validation: 0.17834237740808628]
	TIME [epoch: 20.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11312148916137996		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.11312148916137996 | validation: 0.18236717596354807]
	TIME [epoch: 20.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092844660250392		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1092844660250392 | validation: 0.18846701078819056]
	TIME [epoch: 20.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13230668953385405		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.13230668953385405 | validation: 0.18804487532887781]
	TIME [epoch: 20.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11349772904925508		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.11349772904925508 | validation: 0.18728510093068007]
	TIME [epoch: 20.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10568526874052257		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.10568526874052257 | validation: 0.21774998362674422]
	TIME [epoch: 20.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11541667131104236		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11541667131104236 | validation: 0.17319871630380734]
	TIME [epoch: 20.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12115949658703078		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.12115949658703078 | validation: 0.1822667696263411]
	TIME [epoch: 20.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11343195918496365		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.11343195918496365 | validation: 0.170871758409476]
	TIME [epoch: 20.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10868732977950046		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.10868732977950046 | validation: 0.1971899821872757]
	TIME [epoch: 20.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623996657039787		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.10623996657039787 | validation: 0.17507531052077938]
	TIME [epoch: 20.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12675258849619336		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.12675258849619336 | validation: 0.16511230714467273]
	TIME [epoch: 20.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12181034879276624		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.12181034879276624 | validation: 0.1667194110281786]
	TIME [epoch: 20.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10829868720262689		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.10829868720262689 | validation: 0.21821532159555168]
	TIME [epoch: 20.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12006320048199723		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.12006320048199723 | validation: 0.1694159982943954]
	TIME [epoch: 20.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11229483025363533		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11229483025363533 | validation: 0.18121413640133455]
	TIME [epoch: 20.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10713844446668104		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.10713844446668104 | validation: 0.19726879965987693]
	TIME [epoch: 20.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11152719176570344		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.11152719176570344 | validation: 0.19497882407364217]
	TIME [epoch: 20.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254206194105462		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.1254206194105462 | validation: 0.17265264968841032]
	TIME [epoch: 20.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119471512079049		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.119471512079049 | validation: 0.21450678644786375]
	TIME [epoch: 20.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1322621681629053		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.1322621681629053 | validation: 0.1914930542226432]
	TIME [epoch: 20.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12184962988373757		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.12184962988373757 | validation: 0.1860166644841906]
	TIME [epoch: 20.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1057485624481678		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1057485624481678 | validation: 0.17026100262240645]
	TIME [epoch: 20.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11737904039713179		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.11737904039713179 | validation: 0.18369516935756733]
	TIME [epoch: 20.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11386491880345531		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11386491880345531 | validation: 0.26404593712165714]
	TIME [epoch: 20.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278872102910084		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.11278872102910084 | validation: 0.203083412664531]
	TIME [epoch: 20.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11741427548487415		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.11741427548487415 | validation: 0.15810647544800774]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10854110172748585		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.10854110172748585 | validation: 0.20147921356926038]
	TIME [epoch: 20.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11298253190357002		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.11298253190357002 | validation: 0.1724251858544274]
	TIME [epoch: 20.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11574965022204772		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.11574965022204772 | validation: 0.16005055392179823]
	TIME [epoch: 20.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212366332869458		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.11212366332869458 | validation: 0.17701715574900087]
	TIME [epoch: 20.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1103615522748052		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1103615522748052 | validation: 0.1767707706415997]
	TIME [epoch: 20.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11195484308119867		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.11195484308119867 | validation: 0.19177394749575127]
	TIME [epoch: 20.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12199813018141507		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.12199813018141507 | validation: 0.173770141605982]
	TIME [epoch: 20.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12504604657000312		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.12504604657000312 | validation: 0.17734906849970322]
	TIME [epoch: 20.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10578996077061067		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.10578996077061067 | validation: 0.15997586406435488]
	TIME [epoch: 20.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10878624504121832		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.10878624504121832 | validation: 0.18356132862724617]
	TIME [epoch: 20.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10552222505848778		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.10552222505848778 | validation: 0.18370650747368095]
	TIME [epoch: 20.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1287340502151826		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1287340502151826 | validation: 0.1603891262829647]
	TIME [epoch: 20.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1131797788101819		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1131797788101819 | validation: 0.1590538087344876]
	TIME [epoch: 20.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11176420527610068		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.11176420527610068 | validation: 0.16933817189013664]
	TIME [epoch: 20.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1120463496927584		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.1120463496927584 | validation: 0.16300124486715192]
	TIME [epoch: 20.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09576943211137855		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.09576943211137855 | validation: 0.17964455896148637]
	TIME [epoch: 20.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10937843643371188		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.10937843643371188 | validation: 0.17018889569385798]
	TIME [epoch: 20.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11008172184840359		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.11008172184840359 | validation: 0.1656538154664878]
	TIME [epoch: 20.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778769966158658		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.09778769966158658 | validation: 0.18959019117360384]
	TIME [epoch: 20.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11463423112333611		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.11463423112333611 | validation: 0.16554986999077914]
	TIME [epoch: 20.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1177851479520859		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1177851479520859 | validation: 0.20937395363276684]
	TIME [epoch: 20.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10768057984156851		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.10768057984156851 | validation: 0.1580038487311394]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11400493314050338		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.11400493314050338 | validation: 0.1738244770279206]
	TIME [epoch: 20.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11322307225394661		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.11322307225394661 | validation: 0.16179772575712317]
	TIME [epoch: 20.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11388783937162887		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11388783937162887 | validation: 0.19968943496827574]
	TIME [epoch: 20.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1121326824759407		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.1121326824759407 | validation: 0.175535495129133]
	TIME [epoch: 20.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10855195678672476		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.10855195678672476 | validation: 0.1890760385243706]
	TIME [epoch: 20.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11516502327370784		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.11516502327370784 | validation: 0.1995921496641933]
	TIME [epoch: 20.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10219838307339424		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.10219838307339424 | validation: 0.16955328692843138]
	TIME [epoch: 20.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11750724685177225		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.11750724685177225 | validation: 0.17198757977412704]
	TIME [epoch: 20.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10433454872511519		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.10433454872511519 | validation: 0.16975018534898056]
	TIME [epoch: 20.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1023445382316766		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1023445382316766 | validation: 0.17245175640032792]
	TIME [epoch: 20.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10200049863850613		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.10200049863850613 | validation: 0.16536568582276528]
	TIME [epoch: 20.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10350062963017323		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.10350062963017323 | validation: 0.24121764585969413]
	TIME [epoch: 20.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1237200794772531		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1237200794772531 | validation: 0.1760924654364419]
	TIME [epoch: 20.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1278588647068893		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1278588647068893 | validation: 0.16683436543046157]
	TIME [epoch: 20.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10524835717874814		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.10524835717874814 | validation: 0.15851331596182908]
	TIME [epoch: 20.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623287745885727		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.10623287745885727 | validation: 0.1623224140163531]
	TIME [epoch: 20.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1038264430693602		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1038264430693602 | validation: 0.1982525862306486]
	TIME [epoch: 20.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13128502473696654		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.13128502473696654 | validation: 0.16864759173729646]
	TIME [epoch: 20.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11554503063096107		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.11554503063096107 | validation: 0.1637158921159953]
	TIME [epoch: 20.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09987408998536848		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09987408998536848 | validation: 0.16593957160741282]
	TIME [epoch: 20.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11249867239767475		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.11249867239767475 | validation: 0.17839094527174143]
	TIME [epoch: 20.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11478685098537929		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.11478685098537929 | validation: 0.19287213020151983]
	TIME [epoch: 20.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11855265313519858		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.11855265313519858 | validation: 0.17401452233295694]
	TIME [epoch: 20.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10974632548061329		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.10974632548061329 | validation: 0.15917006242328743]
	TIME [epoch: 20.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11162805863579725		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.11162805863579725 | validation: 0.1915355448419225]
	TIME [epoch: 20.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11721902440120782		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.11721902440120782 | validation: 0.1708086404764692]
	TIME [epoch: 20.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0959090801106584		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.0959090801106584 | validation: 0.2192999972453505]
	TIME [epoch: 20.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1079373738642456		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.1079373738642456 | validation: 0.15997575437276113]
	TIME [epoch: 20.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10698183401299288		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.10698183401299288 | validation: 0.2038427466247869]
	TIME [epoch: 20.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11923835708550715		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.11923835708550715 | validation: 0.16932209003994553]
	TIME [epoch: 20.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10765135884092188		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.10765135884092188 | validation: 0.18327409689876445]
	TIME [epoch: 20.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10803363802493511		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.10803363802493511 | validation: 0.168925979529308]
	TIME [epoch: 20.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10740969879406317		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.10740969879406317 | validation: 0.17623870493474342]
	TIME [epoch: 20.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11422460940996118		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.11422460940996118 | validation: 0.16319047678701232]
	TIME [epoch: 20.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034133665609471		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.1034133665609471 | validation: 0.1697976217374953]
	TIME [epoch: 20.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751382801883841		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.09751382801883841 | validation: 0.16756577866751413]
	TIME [epoch: 20.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10971454402378704		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.10971454402378704 | validation: 0.18578366083652595]
	TIME [epoch: 20.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10187368114903103		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.10187368114903103 | validation: 0.17798723740841474]
	TIME [epoch: 20.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10595017194861445		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.10595017194861445 | validation: 0.16647722829682768]
	TIME [epoch: 20.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11505107555671427		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.11505107555671427 | validation: 0.16196813616478764]
	TIME [epoch: 20.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09776821863536785		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.09776821863536785 | validation: 0.16844437005492657]
	TIME [epoch: 20.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11230270131287759		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.11230270131287759 | validation: 0.18707053975235888]
	TIME [epoch: 20.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10184642197573446		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.10184642197573446 | validation: 0.15153462495185918]
	TIME [epoch: 20.7 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10380243211874991		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.10380243211874991 | validation: 0.1774740508847381]
	TIME [epoch: 20.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11472986332473459		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.11472986332473459 | validation: 0.16919673382725933]
	TIME [epoch: 20.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09541563559616338		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.09541563559616338 | validation: 0.17091561212594703]
	TIME [epoch: 20.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10060214991727176		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.10060214991727176 | validation: 0.18059813040492023]
	TIME [epoch: 20.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11360346754610376		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11360346754610376 | validation: 0.16385131431709996]
	TIME [epoch: 20.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11078292657941904		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.11078292657941904 | validation: 0.1656135465972667]
	TIME [epoch: 20.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10235879954066678		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.10235879954066678 | validation: 0.17477088785502062]
	TIME [epoch: 20.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09868898810002429		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.09868898810002429 | validation: 0.16103470776042106]
	TIME [epoch: 20.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09946592064459639		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.09946592064459639 | validation: 0.15699893163810685]
	TIME [epoch: 20.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10119685218649374		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.10119685218649374 | validation: 0.17513189086553016]
	TIME [epoch: 20.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1003098681750387		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1003098681750387 | validation: 0.1885898391186826]
	TIME [epoch: 20.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11223030921606451		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.11223030921606451 | validation: 0.17954821014882758]
	TIME [epoch: 20.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10724886364464328		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.10724886364464328 | validation: 0.1755379185962302]
	TIME [epoch: 20.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10219692876483244		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.10219692876483244 | validation: 0.16699612568607913]
	TIME [epoch: 20.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10166630885430775		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.10166630885430775 | validation: 0.1607450244660489]
	TIME [epoch: 20.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10552477296081739		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.10552477296081739 | validation: 0.17622565369957202]
	TIME [epoch: 20.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10372556945961578		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.10372556945961578 | validation: 0.1609409498147421]
	TIME [epoch: 20.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10435478988007763		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.10435478988007763 | validation: 0.17362909956614286]
	TIME [epoch: 20.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10984689360144206		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.10984689360144206 | validation: 0.18059759577599838]
	TIME [epoch: 20.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10958959976242295		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.10958959976242295 | validation: 0.15922614848113423]
	TIME [epoch: 20.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09696394772911954		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09696394772911954 | validation: 0.17520043925417442]
	TIME [epoch: 20.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10727256862506329		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.10727256862506329 | validation: 0.1779247651743097]
	TIME [epoch: 20.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10900654243951621		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.10900654243951621 | validation: 0.1594850233650456]
	TIME [epoch: 20.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10316522346057307		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.10316522346057307 | validation: 0.18068783898543944]
	TIME [epoch: 20.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11279979500571376		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.11279979500571376 | validation: 0.18649436509628436]
	TIME [epoch: 20.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000608182993479		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.1000608182993479 | validation: 0.17601092209670602]
	TIME [epoch: 20.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10234880043571142		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.10234880043571142 | validation: 0.18450430072552598]
	TIME [epoch: 20.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09396347302823442		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.09396347302823442 | validation: 0.19936104699462082]
	TIME [epoch: 20.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10048449911867419		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.10048449911867419 | validation: 0.15595394869162588]
	TIME [epoch: 20.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10458900091195641		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.10458900091195641 | validation: 0.1606794982665689]
	TIME [epoch: 20.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09482705542481742		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.09482705542481742 | validation: 0.17642008675630078]
	TIME [epoch: 20.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10467852912662283		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.10467852912662283 | validation: 0.18671571672045567]
	TIME [epoch: 20.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1115225574699074		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1115225574699074 | validation: 0.1520096253628389]
	TIME [epoch: 20.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10097313472255749		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.10097313472255749 | validation: 0.16140881453094452]
	TIME [epoch: 20.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1055336125689926		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.1055336125689926 | validation: 0.1732413911162279]
	TIME [epoch: 20.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10889878795780646		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.10889878795780646 | validation: 0.1686290478627956]
	TIME [epoch: 20.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09577383004053168		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.09577383004053168 | validation: 0.16466184803649558]
	TIME [epoch: 20.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1018829551040922		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.1018829551040922 | validation: 0.17358841119144267]
	TIME [epoch: 20.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10576088132551328		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.10576088132551328 | validation: 0.17641343931586023]
	TIME [epoch: 20.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11379084609887553		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.11379084609887553 | validation: 0.16436098676703684]
	TIME [epoch: 20.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11134523477934799		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.11134523477934799 | validation: 0.17783334568887288]
	TIME [epoch: 20.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10867437538157539		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.10867437538157539 | validation: 0.17868451363079155]
	TIME [epoch: 20.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10839903341213604		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.10839903341213604 | validation: 0.15664769479342922]
	TIME [epoch: 20.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10590677868649145		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.10590677868649145 | validation: 0.16315532878968472]
	TIME [epoch: 20.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10054592410780602		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.10054592410780602 | validation: 0.1700560801421085]
	TIME [epoch: 20.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09569447713151945		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09569447713151945 | validation: 0.16612982331583037]
	TIME [epoch: 20.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10421827932530696		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.10421827932530696 | validation: 0.1694940055217568]
	TIME [epoch: 20.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10166642744691161		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.10166642744691161 | validation: 0.16114410028402282]
	TIME [epoch: 20.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901512065067453		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.09901512065067453 | validation: 0.17698095304460995]
	TIME [epoch: 20.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004161001837599		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1004161001837599 | validation: 0.17167907564307894]
	TIME [epoch: 20.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10294112601962033		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.10294112601962033 | validation: 0.1576302058606337]
	TIME [epoch: 20.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10463012069113717		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.10463012069113717 | validation: 0.17855328550365984]
	TIME [epoch: 21.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10439617584113585		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.10439617584113585 | validation: 0.15327959766922614]
	TIME [epoch: 21.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10117238621308253		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.10117238621308253 | validation: 0.1718423998328238]
	TIME [epoch: 21.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10747231788735916		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.10747231788735916 | validation: 0.17783452869552813]
	TIME [epoch: 21.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1079975414980023		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.1079975414980023 | validation: 0.16742941305983325]
	TIME [epoch: 21.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09722715295924074		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09722715295924074 | validation: 0.16227623114078724]
	TIME [epoch: 21.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09615324540449718		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.09615324540449718 | validation: 0.17391568405878982]
	TIME [epoch: 21.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09641106685368325		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.09641106685368325 | validation: 0.1886191132431644]
	TIME [epoch: 21.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695138458361573		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.11695138458361573 | validation: 0.1557841127941222]
	TIME [epoch: 21.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09808935484633131		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.09808935484633131 | validation: 0.17234251733104314]
	TIME [epoch: 21.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09888365529517315		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.09888365529517315 | validation: 0.16970497575891044]
	TIME [epoch: 21.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10183802452523745		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.10183802452523745 | validation: 0.1704578407605467]
	TIME [epoch: 21.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10507358586691681		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.10507358586691681 | validation: 0.15683897045549688]
	TIME [epoch: 21.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09268516697080155		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09268516697080155 | validation: 0.17155034100822444]
	TIME [epoch: 21.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10321149338775408		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.10321149338775408 | validation: 0.15648312920270324]
	TIME [epoch: 21.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10287938209792728		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.10287938209792728 | validation: 0.16824798078476655]
	TIME [epoch: 21.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10157431298206457		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.10157431298206457 | validation: 0.17492150126697772]
	TIME [epoch: 21.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10071009753340812		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.10071009753340812 | validation: 0.15269318484838315]
	TIME [epoch: 21.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10346704708280788		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.10346704708280788 | validation: 0.16172224646729455]
	TIME [epoch: 21.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10385718982871321		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.10385718982871321 | validation: 0.17242707993925402]
	TIME [epoch: 21.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10653269229757574		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.10653269229757574 | validation: 0.1876953160263563]
	TIME [epoch: 21.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09157139117323886		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.09157139117323886 | validation: 0.15508875441174896]
	TIME [epoch: 21.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10351658851167503		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.10351658851167503 | validation: 0.16735294126657957]
	TIME [epoch: 21.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10022977429944087		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.10022977429944087 | validation: 0.16503854028300263]
	TIME [epoch: 21.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10344630763342111		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.10344630763342111 | validation: 0.16365906455395973]
	TIME [epoch: 21.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0922084320650611		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.0922084320650611 | validation: 0.16678733745517896]
	TIME [epoch: 21.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09221301126672281		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.09221301126672281 | validation: 0.17011414131747202]
	TIME [epoch: 21.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1039405181414244		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1039405181414244 | validation: 0.16006437266788195]
	TIME [epoch: 21.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10048412323447535		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.10048412323447535 | validation: 0.1623267125336372]
	TIME [epoch: 21.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10877681876865783		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.10877681876865783 | validation: 0.18844820530497908]
	TIME [epoch: 21.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09920844654855918		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.09920844654855918 | validation: 0.16210557208449872]
	TIME [epoch: 21.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10111095150791796		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.10111095150791796 | validation: 0.17871979932421395]
	TIME [epoch: 21.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09506965811212637		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.09506965811212637 | validation: 0.16089957881295444]
	TIME [epoch: 21.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10147999954914462		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.10147999954914462 | validation: 0.16375867709087236]
	TIME [epoch: 21.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09994691882400271		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.09994691882400271 | validation: 0.15725382008786523]
	TIME [epoch: 21.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09457282664362938		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.09457282664362938 | validation: 0.16109645988363533]
	TIME [epoch: 21.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10288193959500283		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.10288193959500283 | validation: 0.15823286580844792]
	TIME [epoch: 21.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09590860518029237		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.09590860518029237 | validation: 0.17168241974587292]
	TIME [epoch: 21.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10295773352818793		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.10295773352818793 | validation: 0.1650725773116704]
	TIME [epoch: 21.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10523193012211166		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.10523193012211166 | validation: 0.15497857076260815]
	TIME [epoch: 21.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09166617964998733		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.09166617964998733 | validation: 0.17031285178587602]
	TIME [epoch: 21.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09348493236781016		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.09348493236781016 | validation: 0.15811496045919657]
	TIME [epoch: 21.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10950644035059283		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.10950644035059283 | validation: 0.14790166621345463]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10290301601961398		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.10290301601961398 | validation: 0.1611727099395413]
	TIME [epoch: 21.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1006297485203119		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1006297485203119 | validation: 0.15913499611358112]
	TIME [epoch: 21.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10405311069729115		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.10405311069729115 | validation: 0.18287384275118054]
	TIME [epoch: 21.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0999686779519687		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.0999686779519687 | validation: 0.1581038427839649]
	TIME [epoch: 21.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09917571072463953		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09917571072463953 | validation: 0.17818314608699704]
	TIME [epoch: 21.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09362646516213394		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.09362646516213394 | validation: 0.15828483194901055]
	TIME [epoch: 21.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10186418804478752		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.10186418804478752 | validation: 0.19616151449869745]
	TIME [epoch: 21.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09510113266388573		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.09510113266388573 | validation: 0.16521690847904494]
	TIME [epoch: 21.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0926645749556114		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.0926645749556114 | validation: 0.163252543731766]
	TIME [epoch: 21.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09163137512378124		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.09163137512378124 | validation: 0.1693818279788404]
	TIME [epoch: 21.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930843439881267		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.0930843439881267 | validation: 0.1638759470402667]
	TIME [epoch: 21.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10153822999337732		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.10153822999337732 | validation: 0.15266592844761354]
	TIME [epoch: 21.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09466975463774305		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.09466975463774305 | validation: 0.1485724399479135]
	TIME [epoch: 21.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09522711289842498		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.09522711289842498 | validation: 0.16831078197130947]
	TIME [epoch: 21.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09978220779110165		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.09978220779110165 | validation: 0.1654685057568048]
	TIME [epoch: 21.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10164236259541803		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.10164236259541803 | validation: 0.1575784855264737]
	TIME [epoch: 21.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11179333587070231		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.11179333587070231 | validation: 0.16273846276061127]
	TIME [epoch: 21.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10735988518070934		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.10735988518070934 | validation: 0.15494511227375296]
	TIME [epoch: 21.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09700658067586039		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.09700658067586039 | validation: 0.16061264088724128]
	TIME [epoch: 21.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10051578038890818		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.10051578038890818 | validation: 0.15893128926022973]
	TIME [epoch: 21.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1106367431544624		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1106367431544624 | validation: 0.14893390308012336]
	TIME [epoch: 21.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1052460660054038		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1052460660054038 | validation: 0.1543372385134395]
	TIME [epoch: 21.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09109402098031946		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.09109402098031946 | validation: 0.1768819838340602]
	TIME [epoch: 21.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09409258941995828		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.09409258941995828 | validation: 0.16104437751468026]
	TIME [epoch: 21.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09780457137543623		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09780457137543623 | validation: 0.17903644139780378]
	TIME [epoch: 21.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10405356652888771		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.10405356652888771 | validation: 0.1756436242748325]
	TIME [epoch: 21.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10600727333611955		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.10600727333611955 | validation: 0.15465442896815174]
	TIME [epoch: 21.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10095462768843948		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.10095462768843948 | validation: 0.1694020638974296]
	TIME [epoch: 21.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0938281081461185		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.0938281081461185 | validation: 0.15156132086997892]
	TIME [epoch: 21.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09474288937193268		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.09474288937193268 | validation: 0.1648104494414247]
	TIME [epoch: 21.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545699416599393		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.09545699416599393 | validation: 0.1629474640968448]
	TIME [epoch: 21.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09308198866466737		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.09308198866466737 | validation: 0.17962645453031761]
	TIME [epoch: 21.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09163899914080076		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.09163899914080076 | validation: 0.1624575005641621]
	TIME [epoch: 21.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09508941655611114		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.09508941655611114 | validation: 0.17948332278315146]
	TIME [epoch: 21.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10102687819056651		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.10102687819056651 | validation: 0.16198900813275838]
	TIME [epoch: 21.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09342580870804731		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.09342580870804731 | validation: 0.17211312616490076]
	TIME [epoch: 21.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924304247703793		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.0924304247703793 | validation: 0.16045244668988595]
	TIME [epoch: 21.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09373613586255573		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.09373613586255573 | validation: 0.15898623447547314]
	TIME [epoch: 21.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10195308084856922		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.10195308084856922 | validation: 0.15503092276216027]
	TIME [epoch: 21.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10352284761270444		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.10352284761270444 | validation: 0.17138944271072531]
	TIME [epoch: 21.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.100552968392247		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.100552968392247 | validation: 0.16274039713633837]
	TIME [epoch: 21.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758367728075105		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.09758367728075105 | validation: 0.1500023482555145]
	TIME [epoch: 21.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10303031041929708		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.10303031041929708 | validation: 0.16026702710204652]
	TIME [epoch: 21.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0991592364810204		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.0991592364810204 | validation: 0.1615440060820776]
	TIME [epoch: 21.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0954424223743445		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.0954424223743445 | validation: 0.15560286461681178]
	TIME [epoch: 21.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10209346594039885		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.10209346594039885 | validation: 0.15743032132026677]
	TIME [epoch: 21.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10544392410321271		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.10544392410321271 | validation: 0.1559480453954592]
	TIME [epoch: 21.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09830704997088964		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.09830704997088964 | validation: 0.15565639786323343]
	TIME [epoch: 21.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09358920579256394		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.09358920579256394 | validation: 0.16532087213133517]
	TIME [epoch: 21.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615615220191499		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.10615615220191499 | validation: 0.17285754484660043]
	TIME [epoch: 21.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09695928132094868		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.09695928132094868 | validation: 0.16303574609356392]
	TIME [epoch: 21.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09772216062616106		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.09772216062616106 | validation: 0.15303700548045923]
	TIME [epoch: 21.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09183230450630986		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09183230450630986 | validation: 0.1694768161554215]
	TIME [epoch: 21.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09827864917096715		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.09827864917096715 | validation: 0.16326966575478782]
	TIME [epoch: 21.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09609773461477572		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.09609773461477572 | validation: 0.16132628492144802]
	TIME [epoch: 21.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1024198463214466		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.1024198463214466 | validation: 0.1540127569825227]
	TIME [epoch: 21.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09914623287331928		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.09914623287331928 | validation: 0.16247195687871924]
	TIME [epoch: 21.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09689119900228407		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.09689119900228407 | validation: 0.15957364191487805]
	TIME [epoch: 21.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09908603686231326		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.09908603686231326 | validation: 0.18025415260999073]
	TIME [epoch: 21.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10076869424197192		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.10076869424197192 | validation: 0.16332134350756336]
	TIME [epoch: 21.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0974343492277029		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.0974343492277029 | validation: 0.161079167189521]
	TIME [epoch: 21.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09501828808863487		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.09501828808863487 | validation: 0.1582884601570391]
	TIME [epoch: 21.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09405812420071569		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.09405812420071569 | validation: 0.15612510579240985]
	TIME [epoch: 21.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10120114206002247		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.10120114206002247 | validation: 0.1781938462927843]
	TIME [epoch: 21.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0963190220631546		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.0963190220631546 | validation: 0.15977614020283798]
	TIME [epoch: 21.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09123732631787793		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.09123732631787793 | validation: 0.1643952579844551]
	TIME [epoch: 21.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10800673226297217		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.10800673226297217 | validation: 0.16087393265256733]
	TIME [epoch: 21.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09389826785012494		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.09389826785012494 | validation: 0.1630380147790397]
	TIME [epoch: 21.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0965002624616376		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.0965002624616376 | validation: 0.1734225266807015]
	TIME [epoch: 21.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09266326939458033		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.09266326939458033 | validation: 0.1737942681608386]
	TIME [epoch: 21.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09492457141773555		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.09492457141773555 | validation: 0.15824312314381678]
	TIME [epoch: 21.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09773802228848674		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.09773802228848674 | validation: 0.15438747227866717]
	TIME [epoch: 21.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10067929179463057		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10067929179463057 | validation: 0.16398052200107324]
	TIME [epoch: 21.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10265039502876658		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.10265039502876658 | validation: 0.16570266938330236]
	TIME [epoch: 21.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0964492298096534		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.0964492298096534 | validation: 0.15745249201649425]
	TIME [epoch: 21.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10041890036903352		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.10041890036903352 | validation: 0.15491611882654982]
	TIME [epoch: 21.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09804589650086315		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.09804589650086315 | validation: 0.16641729189525636]
	TIME [epoch: 21.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0888747139157001		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.0888747139157001 | validation: 0.14844847973459815]
	TIME [epoch: 21.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09719745461347402		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.09719745461347402 | validation: 0.15629672762351673]
	TIME [epoch: 21.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09132727333415336		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.09132727333415336 | validation: 0.16741076054839185]
	TIME [epoch: 21.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09654831377178093		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09654831377178093 | validation: 0.16777241933228187]
	TIME [epoch: 21.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0936522281076754		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.0936522281076754 | validation: 0.15513524435436052]
	TIME [epoch: 21.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08810124362937059		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08810124362937059 | validation: 0.16911937756084033]
	TIME [epoch: 21.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09312469210731174		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.09312469210731174 | validation: 0.1593539378370053]
	TIME [epoch: 21.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10336294323330306		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.10336294323330306 | validation: 0.1617831146738505]
	TIME [epoch: 21.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244386626940498		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.09244386626940498 | validation: 0.16460995384359647]
	TIME [epoch: 21.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09996052070615054		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.09996052070615054 | validation: 0.17632936105400362]
	TIME [epoch: 21.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09527154259419948		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.09527154259419948 | validation: 0.16678179249238997]
	TIME [epoch: 21.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08855577184250199		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08855577184250199 | validation: 0.1648804002495925]
	TIME [epoch: 21.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771868879522396		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08771868879522396 | validation: 0.16161634347208556]
	TIME [epoch: 21.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09355597737609697		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.09355597737609697 | validation: 0.16778091366804676]
	TIME [epoch: 21.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181365799441836		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.09181365799441836 | validation: 0.17095846851084867]
	TIME [epoch: 21.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859707411520262		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.0859707411520262 | validation: 0.15399178861513857]
	TIME [epoch: 21.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09551193234791644		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.09551193234791644 | validation: 0.1547217523331674]
	TIME [epoch: 21.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08989766075368169		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08989766075368169 | validation: 0.1677441486215048]
	TIME [epoch: 21.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10044862768471421		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.10044862768471421 | validation: 0.15026108384356612]
	TIME [epoch: 21.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09992175935158912		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.09992175935158912 | validation: 0.1605198741011288]
	TIME [epoch: 21.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09141721202720068		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.09141721202720068 | validation: 0.15357408073281317]
	TIME [epoch: 21.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09362168360461989		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.09362168360461989 | validation: 0.15433639972674973]
	TIME [epoch: 21.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751749037467212		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08751749037467212 | validation: 0.15466628001247373]
	TIME [epoch: 21.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09365679867370863		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.09365679867370863 | validation: 0.15518407668334727]
	TIME [epoch: 21.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09940708528743321		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.09940708528743321 | validation: 0.15160927491159876]
	TIME [epoch: 21.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08981646545965834		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.08981646545965834 | validation: 0.17089482650603544]
	TIME [epoch: 21.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09257600700413318		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.09257600700413318 | validation: 0.15083880881463035]
	TIME [epoch: 21.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09063975115192076		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09063975115192076 | validation: 0.16422656459416995]
	TIME [epoch: 21.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568761293874523		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08568761293874523 | validation: 0.17117370285815856]
	TIME [epoch: 21.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09581032925639363		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.09581032925639363 | validation: 0.16315468528204488]
	TIME [epoch: 21.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09388388647689094		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.09388388647689094 | validation: 0.15577133625719294]
	TIME [epoch: 21.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09194443204289497		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.09194443204289497 | validation: 0.16932562708701743]
	TIME [epoch: 21.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09300648469649737		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.09300648469649737 | validation: 0.1759724240369211]
	TIME [epoch: 21.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10179273881443333		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.10179273881443333 | validation: 0.1603748080514902]
	TIME [epoch: 21.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911167637325326		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.0911167637325326 | validation: 0.15950196824505614]
	TIME [epoch: 21.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09148690864490018		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.09148690864490018 | validation: 0.15559530007446068]
	TIME [epoch: 21.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265825518298615		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.09265825518298615 | validation: 0.16431621004769165]
	TIME [epoch: 21.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09361515119430387		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.09361515119430387 | validation: 0.15371265842594772]
	TIME [epoch: 21.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942992770287423		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.0942992770287423 | validation: 0.17165858152639468]
	TIME [epoch: 21.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09370009902256612		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09370009902256612 | validation: 0.16301908324173928]
	TIME [epoch: 21.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08893447711712245		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.08893447711712245 | validation: 0.15644533575218975]
	TIME [epoch: 21.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09775755567263111		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.09775755567263111 | validation: 0.15571446996918695]
	TIME [epoch: 21.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751978949005251		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.09751978949005251 | validation: 0.1420023246614616]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09516777663623684		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.09516777663623684 | validation: 0.14298805993583139]
	TIME [epoch: 21.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10533218343092601		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.10533218343092601 | validation: 0.1587592711956816]
	TIME [epoch: 21.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09710306555518745		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.09710306555518745 | validation: 0.15719282408314142]
	TIME [epoch: 21.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161673914171894		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.09161673914171894 | validation: 0.1679875823136337]
	TIME [epoch: 21.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09201064155853987		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.09201064155853987 | validation: 0.15853195364758277]
	TIME [epoch: 21.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09283624861531546		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.09283624861531546 | validation: 0.16129651077129883]
	TIME [epoch: 21.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10437832795990831		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.10437832795990831 | validation: 0.16023210873532204]
	TIME [epoch: 21.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08972950936153783		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08972950936153783 | validation: 0.1686966653133866]
	TIME [epoch: 21.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09671536575913338		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.09671536575913338 | validation: 0.16638762080214933]
	TIME [epoch: 21.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09342950493320516		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.09342950493320516 | validation: 0.16726824102289473]
	TIME [epoch: 21.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09908869087390908		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.09908869087390908 | validation: 0.15145615690990238]
	TIME [epoch: 21.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0895641791680574		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.0895641791680574 | validation: 0.1558304308486149]
	TIME [epoch: 21.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09564880194907036		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.09564880194907036 | validation: 0.1584974525383067]
	TIME [epoch: 21.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0938711243614782		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.0938711243614782 | validation: 0.17101838600264693]
	TIME [epoch: 21.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09491661402172195		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.09491661402172195 | validation: 0.14291953826480125]
	TIME [epoch: 21.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09942204147820169		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.09942204147820169 | validation: 0.1669758159957026]
	TIME [epoch: 21.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09007991725156757		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09007991725156757 | validation: 0.17423575077808823]
	TIME [epoch: 21.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09731460481492335		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.09731460481492335 | validation: 0.1551414980684544]
	TIME [epoch: 21.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08329209750565691		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08329209750565691 | validation: 0.1607283854794715]
	TIME [epoch: 21.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758134909644153		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.09758134909644153 | validation: 0.14832685265511591]
	TIME [epoch: 21.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09636260556421973		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.09636260556421973 | validation: 0.15893792203751259]
	TIME [epoch: 21.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09020626030868278		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.09020626030868278 | validation: 0.157035254394303]
	TIME [epoch: 21.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09421333421525772		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.09421333421525772 | validation: 0.16486331600722653]
	TIME [epoch: 21.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09257370519434929		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.09257370519434929 | validation: 0.17001509260255254]
	TIME [epoch: 21.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008816989985143		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.09008816989985143 | validation: 0.14518154783073783]
	TIME [epoch: 21.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343659400829053		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.09343659400829053 | validation: 0.16496074509028158]
	TIME [epoch: 21.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09178806197874789		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.09178806197874789 | validation: 0.16390016977281577]
	TIME [epoch: 21.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10050728453564713		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.10050728453564713 | validation: 0.1597480645612737]
	TIME [epoch: 21.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09982504802743553		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.09982504802743553 | validation: 0.15833092346247252]
	TIME [epoch: 21.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09518972355744046		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.09518972355744046 | validation: 0.15573192310496178]
	TIME [epoch: 21.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133596539594788		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.09133596539594788 | validation: 0.16551669711886782]
	TIME [epoch: 21.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09243202695111395		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.09243202695111395 | validation: 0.15187223830724433]
	TIME [epoch: 21.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09391149903737686		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.09391149903737686 | validation: 0.1571397962986401]
	TIME [epoch: 21.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08989984458529958		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08989984458529958 | validation: 0.17698274991302362]
	TIME [epoch: 21.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09274960444262365		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.09274960444262365 | validation: 0.1650422860732193]
	TIME [epoch: 21.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09670460427229495		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.09670460427229495 | validation: 0.16817131418333958]
	TIME [epoch: 21.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08812784561534225		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08812784561534225 | validation: 0.15786047817922744]
	TIME [epoch: 21.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09680904017480386		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.09680904017480386 | validation: 0.17404934669630476]
	TIME [epoch: 21.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0949284841642641		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.0949284841642641 | validation: 0.16331631331190075]
	TIME [epoch: 21.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09549926535773483		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.09549926535773483 | validation: 0.15436659248030526]
	TIME [epoch: 21.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09589771180605564		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09589771180605564 | validation: 0.15445139706482]
	TIME [epoch: 21.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09019685941013222		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.09019685941013222 | validation: 0.1642767431792463]
	TIME [epoch: 21.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09547048810501861		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.09547048810501861 | validation: 0.17464691778780989]
	TIME [epoch: 21.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08837790199633058		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.08837790199633058 | validation: 0.15297577478681276]
	TIME [epoch: 21.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353246748504015		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.09353246748504015 | validation: 0.13932342856158736]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09426762549950451		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.09426762549950451 | validation: 0.16115415911246947]
	TIME [epoch: 21.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0907827916260066		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.0907827916260066 | validation: 0.16187300802720855]
	TIME [epoch: 21.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09147635319162846		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.09147635319162846 | validation: 0.15327598768185585]
	TIME [epoch: 21.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048724150581093		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.09048724150581093 | validation: 0.158151916895905]
	TIME [epoch: 21.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0932611522977796		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.0932611522977796 | validation: 0.1534312139739056]
	TIME [epoch: 21.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0906509272310011		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.0906509272310011 | validation: 0.15428857938681442]
	TIME [epoch: 21.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09619826085583166		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.09619826085583166 | validation: 0.15582327521023265]
	TIME [epoch: 21.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09842630435281836		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09842630435281836 | validation: 0.16099189548108542]
	TIME [epoch: 21.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09116342236054722		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.09116342236054722 | validation: 0.14978653267088532]
	TIME [epoch: 21.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167861159279238		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.09167861159279238 | validation: 0.15362610061134363]
	TIME [epoch: 21.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09221082680773218		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.09221082680773218 | validation: 0.15659005649218538]
	TIME [epoch: 21.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09339241646555729		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.09339241646555729 | validation: 0.15716293332827994]
	TIME [epoch: 21.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401102459946842		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.08401102459946842 | validation: 0.15348533691619964]
	TIME [epoch: 21.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09364662949963307		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.09364662949963307 | validation: 0.16299469601382463]
	TIME [epoch: 21.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08579368090909291		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.08579368090909291 | validation: 0.1577528696374875]
	TIME [epoch: 21.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505036809016769		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.09505036809016769 | validation: 0.15437712593710262]
	TIME [epoch: 21.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09267543067265646		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.09267543067265646 | validation: 0.15358915598147777]
	TIME [epoch: 21.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568582328119145		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.08568582328119145 | validation: 0.16257388026460076]
	TIME [epoch: 21.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09506869611422171		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.09506869611422171 | validation: 0.14514047999512114]
	TIME [epoch: 21.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08572377864283821		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08572377864283821 | validation: 0.1650185989460054]
	TIME [epoch: 21.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08265877287352447		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.08265877287352447 | validation: 0.15564684176771518]
	TIME [epoch: 21.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09701188769877103		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.09701188769877103 | validation: 0.14467311993314047]
	TIME [epoch: 21.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10467369144829057		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.10467369144829057 | validation: 0.15280839349045647]
	TIME [epoch: 21.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.106205775567161		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.106205775567161 | validation: 0.15275656216771044]
	TIME [epoch: 21.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08942550029357099		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08942550029357099 | validation: 0.16019854921911308]
	TIME [epoch: 21.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08671868254759704		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.08671868254759704 | validation: 0.16144790907890966]
	TIME [epoch: 21.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09563638557162359		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.09563638557162359 | validation: 0.16102426832951688]
	TIME [epoch: 21.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09027081787943435		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.09027081787943435 | validation: 0.14734524330162085]
	TIME [epoch: 21.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692977249878346		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.08692977249878346 | validation: 0.15641477828962622]
	TIME [epoch: 21.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09408279240192523		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.09408279240192523 | validation: 0.15209692477785677]
	TIME [epoch: 21.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08915609029049539		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.08915609029049539 | validation: 0.1611087713418637]
	TIME [epoch: 21.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09551029926152572		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09551029926152572 | validation: 0.14778581451998726]
	TIME [epoch: 21.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09396716886981418		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.09396716886981418 | validation: 0.17523988192224416]
	TIME [epoch: 21.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09175950212525966		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.09175950212525966 | validation: 0.15992913693786584]
	TIME [epoch: 21.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353321713584543		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.09353321713584543 | validation: 0.15223366594089466]
	TIME [epoch: 21.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09507460628389253		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.09507460628389253 | validation: 0.1581141716248694]
	TIME [epoch: 21.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09143297289314165		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.09143297289314165 | validation: 0.15882346875502057]
	TIME [epoch: 21.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.090637536039924		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.090637536039924 | validation: 0.15768640676231113]
	TIME [epoch: 21.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08929855321173016		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.08929855321173016 | validation: 0.1638641692524785]
	TIME [epoch: 21.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09925443366975706		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.09925443366975706 | validation: 0.16321995909117737]
	TIME [epoch: 21.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08963390171556333		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.08963390171556333 | validation: 0.15997650383196058]
	TIME [epoch: 21.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1082493415238567		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1082493415238567 | validation: 0.15745415080449715]
	TIME [epoch: 21.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08749075346270711		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.08749075346270711 | validation: 0.15649817969344515]
	TIME [epoch: 21.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09393685389035142		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.09393685389035142 | validation: 0.15896092162348635]
	TIME [epoch: 21.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09299228385515697		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.09299228385515697 | validation: 0.15473975178627142]
	TIME [epoch: 21.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08610138699170242		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.08610138699170242 | validation: 0.15928997054061522]
	TIME [epoch: 21.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10462451943713243		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.10462451943713243 | validation: 0.1518000863693199]
	TIME [epoch: 21.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920327913655535		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0920327913655535 | validation: 0.15533860182258152]
	TIME [epoch: 21.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09035474274282862		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.09035474274282862 | validation: 0.16453810206640407]
	TIME [epoch: 21.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878173930237884		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.0878173930237884 | validation: 0.15309184822540758]
	TIME [epoch: 21.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0874109533076318		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.0874109533076318 | validation: 0.15140217226491243]
	TIME [epoch: 21.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08769470580672978		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.08769470580672978 | validation: 0.1663162815068836]
	TIME [epoch: 21.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09841117791550733		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.09841117791550733 | validation: 0.15024943095664595]
	TIME [epoch: 21.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09061740085596763		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.09061740085596763 | validation: 0.16160727590791663]
	TIME [epoch: 21.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09014121993543942		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.09014121993543942 | validation: 0.1553483873447173]
	TIME [epoch: 21.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10016606663989895		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.10016606663989895 | validation: 0.15824744337668883]
	TIME [epoch: 21.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09465393445225853		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.09465393445225853 | validation: 0.15624471023319078]
	TIME [epoch: 21.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09483048126824987		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.09483048126824987 | validation: 0.15928007284083676]
	TIME [epoch: 21.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10393254903927918		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.10393254903927918 | validation: 0.15575107073921168]
	TIME [epoch: 21.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09169984635009351		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09169984635009351 | validation: 0.17318686800566147]
	TIME [epoch: 21.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0897173129140579		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.0897173129140579 | validation: 0.15734298038737862]
	TIME [epoch: 21.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09350408053910574		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.09350408053910574 | validation: 0.14878654950473205]
	TIME [epoch: 21.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0916328024556046		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.0916328024556046 | validation: 0.1579828828493392]
	TIME [epoch: 21.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09117241871249385		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.09117241871249385 | validation: 0.15660351565808908]
	TIME [epoch: 21.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08794129191510153		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.08794129191510153 | validation: 0.15625536081102603]
	TIME [epoch: 21.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09680956448089305		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.09680956448089305 | validation: 0.14883176011540847]
	TIME [epoch: 21.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08879930654322118		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08879930654322118 | validation: 0.15631038064269365]
	TIME [epoch: 21.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09293596131679598		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.09293596131679598 | validation: 0.15229981131940046]
	TIME [epoch: 21.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09065629879442198		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.09065629879442198 | validation: 0.1695421497015668]
	TIME [epoch: 21.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.090102515570501		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.090102515570501 | validation: 0.16906959843305475]
	TIME [epoch: 21.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09220426384175777		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.09220426384175777 | validation: 0.16165491042870078]
	TIME [epoch: 21.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842071846926474		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.0842071846926474 | validation: 0.1540288695341809]
	TIME [epoch: 21.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728798309945736		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.08728798309945736 | validation: 0.15115435876851352]
	TIME [epoch: 21.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09600880374332303		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.09600880374332303 | validation: 0.1520573252333467]
	TIME [epoch: 21.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09263006019839595		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.09263006019839595 | validation: 0.15213495945681893]
	TIME [epoch: 21.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750134201799195		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.09750134201799195 | validation: 0.1570309449746206]
	TIME [epoch: 21.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557967831209505		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.08557967831209505 | validation: 0.1583680640784443]
	TIME [epoch: 21.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09924079232119691		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.09924079232119691 | validation: 0.163512572250618]
	TIME [epoch: 21.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08865987881245545		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.08865987881245545 | validation: 0.15805673559811392]
	TIME [epoch: 21.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09141026870349438		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.09141026870349438 | validation: 0.14517737454680335]
	TIME [epoch: 21.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09622992863954087		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.09622992863954087 | validation: 0.15199216022884957]
	TIME [epoch: 21.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08393285858392611		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.08393285858392611 | validation: 0.15141754420413597]
	TIME [epoch: 21.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09705089061342535		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.09705089061342535 | validation: 0.15818519450201377]
	TIME [epoch: 21.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09318131960541917		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09318131960541917 | validation: 0.1594833779407366]
	TIME [epoch: 21.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901992286465608		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.0901992286465608 | validation: 0.15166928239787153]
	TIME [epoch: 21.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780767855942448		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.08780767855942448 | validation: 0.15488561258676287]
	TIME [epoch: 21.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509289040307319		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.09509289040307319 | validation: 0.14824084570531404]
	TIME [epoch: 21.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.097950408338689		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.097950408338689 | validation: 0.1441163586126574]
	TIME [epoch: 21.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760249086797661		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.09760249086797661 | validation: 0.15854904644536397]
	TIME [epoch: 21.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08511472856586615		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.08511472856586615 | validation: 0.16177847715010593]
	TIME [epoch: 21.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09652393341514676		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.09652393341514676 | validation: 0.1606145244959167]
	TIME [epoch: 21.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0834726852447839		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0834726852447839 | validation: 0.15326583717390285]
	TIME [epoch: 21.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09174555643167118		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.09174555643167118 | validation: 0.15456223611481876]
	TIME [epoch: 21.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0873078097380402		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.0873078097380402 | validation: 0.1600652807358252]
	TIME [epoch: 21.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08974669538640777		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.08974669538640777 | validation: 0.15819276840881147]
	TIME [epoch: 21.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563213773455323		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08563213773455323 | validation: 0.1641469037475548]
	TIME [epoch: 21.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09564255512248687		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.09564255512248687 | validation: 0.17493194097914538]
	TIME [epoch: 21.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0926510937203874		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.0926510937203874 | validation: 0.1598249985529577]
	TIME [epoch: 21.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09774082910913444		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.09774082910913444 | validation: 0.15079051029468743]
	TIME [epoch: 21.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09236797952658604		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.09236797952658604 | validation: 0.15769295047043774]
	TIME [epoch: 21.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375279913673109		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.08375279913673109 | validation: 0.15554159017428956]
	TIME [epoch: 21.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08806832652399137		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.08806832652399137 | validation: 0.15750968715603475]
	TIME [epoch: 21.1 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08639432930196626		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.08639432930196626 | validation: 0.15941897000244576]
	TIME [epoch: 21.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08762385158935042		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08762385158935042 | validation: 0.16046684188678784]
	TIME [epoch: 21.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08970851702658884		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.08970851702658884 | validation: 0.15512873440791813]
	TIME [epoch: 21.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08672123325027077		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08672123325027077 | validation: 0.16180631319239497]
	TIME [epoch: 21.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0915446484066507		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.0915446484066507 | validation: 0.15835035262353767]
	TIME [epoch: 21.1 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09250893298477472		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.09250893298477472 | validation: 0.1484732281849268]
	TIME [epoch: 21.1 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0825062031120187		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.0825062031120187 | validation: 0.15121536587524742]
	TIME [epoch: 21.1 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09157654383744555		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.09157654383744555 | validation: 0.15200407922565332]
	TIME [epoch: 21.1 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08412885611280121		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.08412885611280121 | validation: 0.16071457919337856]
	TIME [epoch: 21.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10564102437902387		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.10564102437902387 | validation: 0.1419925912891591]
	TIME [epoch: 21.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09498535318546854		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.09498535318546854 | validation: 0.15050363175323783]
	TIME [epoch: 21.1 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09469322173064693		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.09469322173064693 | validation: 0.16908078642644292]
	TIME [epoch: 21.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09489805407224872		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.09489805407224872 | validation: 0.14705236059143129]
	TIME [epoch: 21.1 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09693701795517196		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09693701795517196 | validation: 0.16150937389255396]
	TIME [epoch: 21.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475870057934416		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.09475870057934416 | validation: 0.15205465275196456]
	TIME [epoch: 21.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09245032702793629		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.09245032702793629 | validation: 0.1582627849231461]
	TIME [epoch: 21.1 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495149342342472		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.09495149342342472 | validation: 0.14540031154195934]
	TIME [epoch: 21.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08227231081863995		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08227231081863995 | validation: 0.16007355719093347]
	TIME [epoch: 21.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09162485996442311		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.09162485996442311 | validation: 0.1555583271159285]
	TIME [epoch: 21.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08943744150098965		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.08943744150098965 | validation: 0.15835389250162138]
	TIME [epoch: 21.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08949881143893498		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.08949881143893498 | validation: 0.16171963660712907]
	TIME [epoch: 21.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10247407843906446		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10247407843906446 | validation: 0.15461929456829926]
	TIME [epoch: 21.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0889961309030616		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.0889961309030616 | validation: 0.15105412990813244]
	TIME [epoch: 21.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08504254022522326		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.08504254022522326 | validation: 0.16314172257349088]
	TIME [epoch: 21.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09076391534990194		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.09076391534990194 | validation: 0.14966801131905286]
	TIME [epoch: 21.1 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09411827727569094		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.09411827727569094 | validation: 0.15982471078305932]
	TIME [epoch: 21.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08768629841175232		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.08768629841175232 | validation: 0.1544977071996271]
	TIME [epoch: 21.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08674815053864746		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.08674815053864746 | validation: 0.15281393438428686]
	TIME [epoch: 21.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09415667379989423		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.09415667379989423 | validation: 0.157868079685085]
	TIME [epoch: 21.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08869395127423142		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08869395127423142 | validation: 0.14723787811813108]
	TIME [epoch: 21.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09083439530963874		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.09083439530963874 | validation: 0.15664236039087004]
	TIME [epoch: 21.1 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879520492822636		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.0879520492822636 | validation: 0.15822465294900667]
	TIME [epoch: 21.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0886486736907099		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.0886486736907099 | validation: 0.1670527926399892]
	TIME [epoch: 21.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09345952033514811		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.09345952033514811 | validation: 0.14721822958167932]
	TIME [epoch: 21.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08984896885392957		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.08984896885392957 | validation: 0.1492428450526243]
	TIME [epoch: 21.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08846192555515955		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.08846192555515955 | validation: 0.16032878858913366]
	TIME [epoch: 21.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08916669866277659		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.08916669866277659 | validation: 0.15575184706109763]
	TIME [epoch: 21.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010278668165461		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09010278668165461 | validation: 0.15011803165808305]
	TIME [epoch: 21.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09313044179829683		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.09313044179829683 | validation: 0.15163416448027667]
	TIME [epoch: 21.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08851247329329663		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.08851247329329663 | validation: 0.15406875375893875]
	TIME [epoch: 21.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290627447723778		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.08290627447723778 | validation: 0.15811142242460366]
	TIME [epoch: 21.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09168052775738653		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.09168052775738653 | validation: 0.14900921942643916]
	TIME [epoch: 21.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347954993373094		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.08347954993373094 | validation: 0.15193959805321636]
	TIME [epoch: 21.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08875796878314247		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.08875796878314247 | validation: 0.14748237260650784]
	TIME [epoch: 21.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09856522516046892		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.09856522516046892 | validation: 0.16186975752056929]
	TIME [epoch: 21.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886609104514628		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.08886609104514628 | validation: 0.1608702189509394]
	TIME [epoch: 21.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580171785483489		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.09580171785483489 | validation: 0.1600538988793627]
	TIME [epoch: 21.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09472402346484157		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.09472402346484157 | validation: 0.16014911392203326]
	TIME [epoch: 21.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08984943073063334		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.08984943073063334 | validation: 0.16029979740176792]
	TIME [epoch: 21.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08798674574779455		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.08798674574779455 | validation: 0.16380162133463017]
	TIME [epoch: 21.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0869278714250573		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.0869278714250573 | validation: 0.15221997662748485]
	TIME [epoch: 21 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09032334797997373		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.09032334797997373 | validation: 0.14514545562668668]
	TIME [epoch: 21.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08901387906323861		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.08901387906323861 | validation: 0.1519028366546548]
	TIME [epoch: 21.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09327782109840192		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09327782109840192 | validation: 0.15933810495412845]
	TIME [epoch: 21.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0907204303258509		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.0907204303258509 | validation: 0.1483715478682116]
	TIME [epoch: 21.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093424035312428		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.09093424035312428 | validation: 0.1476842366306963]
	TIME [epoch: 21.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09664781347658036		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.09664781347658036 | validation: 0.15395191729972563]
	TIME [epoch: 21.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08319809173259247		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.08319809173259247 | validation: 0.15773782941958459]
	TIME [epoch: 21.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09049490324967713		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.09049490324967713 | validation: 0.1527918427491326]
	TIME [epoch: 21.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08942259374496657		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.08942259374496657 | validation: 0.15231514376723856]
	TIME [epoch: 21.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09607721752613256		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.09607721752613256 | validation: 0.1593396452802561]
	TIME [epoch: 21.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08952115201329253		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.08952115201329253 | validation: 0.16137825071806766]
	TIME [epoch: 21.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920902139975246		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.0920902139975246 | validation: 0.15349576397753528]
	TIME [epoch: 21.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0943879491634485		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.0943879491634485 | validation: 0.1526143469874337]
	TIME [epoch: 21.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08302948760370969		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.08302948760370969 | validation: 0.14188807875452128]
	TIME [epoch: 21.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08967191030270028		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08967191030270028 | validation: 0.16363897630063517]
	TIME [epoch: 21.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09153156776139745		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.09153156776139745 | validation: 0.1518371161221891]
	TIME [epoch: 21.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09581855474504943		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.09581855474504943 | validation: 0.16064876625010543]
	TIME [epoch: 21.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301680187537645		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.09301680187537645 | validation: 0.15425160620959136]
	TIME [epoch: 21.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09387443042472479		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.09387443042472479 | validation: 0.15307764101845123]
	TIME [epoch: 21.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09420348885941116		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.09420348885941116 | validation: 0.1575739091332003]
	TIME [epoch: 21.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848815302097787		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.0848815302097787 | validation: 0.15690099057939846]
	TIME [epoch: 21.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08704347645093291		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.08704347645093291 | validation: 0.16012132823275768]
	TIME [epoch: 21.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08892886860948271		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.08892886860948271 | validation: 0.15379988330194347]
	TIME [epoch: 21.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09787968161202756		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.09787968161202756 | validation: 0.1427886198889209]
	TIME [epoch: 21.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08191537874571375		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.08191537874571375 | validation: 0.16184086196147418]
	TIME [epoch: 21.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08951151543237668		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.08951151543237668 | validation: 0.14487004247778032]
	TIME [epoch: 21.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09322473419445206		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.09322473419445206 | validation: 0.16016796710834508]
	TIME [epoch: 21.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08875792948873458		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.08875792948873458 | validation: 0.15832886072036922]
	TIME [epoch: 21.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09108706995177686		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.09108706995177686 | validation: 0.15003906012138063]
	TIME [epoch: 21.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08675179783423217		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.08675179783423217 | validation: 0.1606568330861972]
	TIME [epoch: 21.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08976146524655429		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.08976146524655429 | validation: 0.14554695843756177]
	TIME [epoch: 21.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09444242169239961		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.09444242169239961 | validation: 0.1553821363778392]
	TIME [epoch: 21.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09219184467167696		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.09219184467167696 | validation: 0.15920370674277579]
	TIME [epoch: 21.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09435154853184473		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.09435154853184473 | validation: 0.15004938265369003]
	TIME [epoch: 21.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08802128452624929		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08802128452624929 | validation: 0.14762565457197688]
	TIME [epoch: 21.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08173417112211642		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.08173417112211642 | validation: 0.15882481965055384]
	TIME [epoch: 21.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09430607145774485		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.09430607145774485 | validation: 0.1499047690335374]
	TIME [epoch: 21.1 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09598583242147049		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.09598583242147049 | validation: 0.1558200748335713]
	TIME [epoch: 21.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08750819588831259		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08750819588831259 | validation: 0.15458337156251412]
	TIME [epoch: 21.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08945926064574874		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.08945926064574874 | validation: 0.15330724387527322]
	TIME [epoch: 21.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09410372858346701		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.09410372858346701 | validation: 0.14860737921793055]
	TIME [epoch: 21.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09236167721746384		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.09236167721746384 | validation: 0.15166439553233668]
	TIME [epoch: 21.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08923221296292479		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08923221296292479 | validation: 0.16283303592566273]
	TIME [epoch: 21.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09015543924191831		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.09015543924191831 | validation: 0.1548133753396833]
	TIME [epoch: 21.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08847773258265468		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.08847773258265468 | validation: 0.15143114992120796]
	TIME [epoch: 21.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645095173121972		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.09645095173121972 | validation: 0.1513156692264408]
	TIME [epoch: 21.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09401857665556584		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.09401857665556584 | validation: 0.13911217879596305]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08670835884543185		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.08670835884543185 | validation: 0.1583597513922668]
	TIME [epoch: 21.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08391548742324788		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.08391548742324788 | validation: 0.1647640727887863]
	TIME [epoch: 21.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08491310751343466		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.08491310751343466 | validation: 0.1586660632880267]
	TIME [epoch: 21.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08605674603315579		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08605674603315579 | validation: 0.15891970953224124]
	TIME [epoch: 21.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08877744412602576		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.08877744412602576 | validation: 0.15547352370345632]
	TIME [epoch: 21.1 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09046634930444247		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.09046634930444247 | validation: 0.15600410747652957]
	TIME [epoch: 21 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0890861889192452		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.0890861889192452 | validation: 0.15562295453949637]
	TIME [epoch: 21.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09368111159529742		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.09368111159529742 | validation: 0.16176404023107213]
	TIME [epoch: 21.1 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08796844405017312		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.08796844405017312 | validation: 0.14400455165502235]
	TIME [epoch: 21.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09088370651450103		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.09088370651450103 | validation: 0.14755697781298432]
	TIME [epoch: 21.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09660621868451272		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.09660621868451272 | validation: 0.156643457687934]
	TIME [epoch: 21.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08540390950976137		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08540390950976137 | validation: 0.16843648954691637]
	TIME [epoch: 21.1 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08486048327979759		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.08486048327979759 | validation: 0.15848896758602024]
	TIME [epoch: 21.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265839680383518		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.09265839680383518 | validation: 0.16342806326892365]
	TIME [epoch: 21.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252102788001418		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.09252102788001418 | validation: 0.14927308455350854]
	TIME [epoch: 21.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920626783746953		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0920626783746953 | validation: 0.1531101946835866]
	TIME [epoch: 21.1 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08853018745954355		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.08853018745954355 | validation: 0.15421143746622812]
	TIME [epoch: 21.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09658697924378763		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.09658697924378763 | validation: 0.1518878538578102]
	TIME [epoch: 21.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429272052811501		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.08429272052811501 | validation: 0.15248586467896927]
	TIME [epoch: 21.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937426246687204		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08937426246687204 | validation: 0.15628691918742663]
	TIME [epoch: 21.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08329699961742873		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.08329699961742873 | validation: 0.15041262875644568]
	TIME [epoch: 21.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08406718120406678		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.08406718120406678 | validation: 0.15882497560565995]
	TIME [epoch: 21.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08618502602175596		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.08618502602175596 | validation: 0.161296458215326]
	TIME [epoch: 21.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09199568419169193		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09199568419169193 | validation: 0.1511199567892137]
	TIME [epoch: 21.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09113758928708562		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.09113758928708562 | validation: 0.1466713889460392]
	TIME [epoch: 21.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09182022607962306		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.09182022607962306 | validation: 0.15466236069414266]
	TIME [epoch: 21.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0844109673981219		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.0844109673981219 | validation: 0.14415203610817162]
	TIME [epoch: 21.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09605724025881461		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09605724025881461 | validation: 0.15857978496865574]
	TIME [epoch: 21.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09111316168748489		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.09111316168748489 | validation: 0.1459370968027469]
	TIME [epoch: 21.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09500054927151412		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.09500054927151412 | validation: 0.15655573424607688]
	TIME [epoch: 21.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0907249623457674		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.0907249623457674 | validation: 0.1527428345801426]
	TIME [epoch: 21.1 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09458197280867726		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09458197280867726 | validation: 0.16403460134466277]
	TIME [epoch: 21.1 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08800405722482181		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.08800405722482181 | validation: 0.15455695868899103]
	TIME [epoch: 21.1 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08925191633820934		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.08925191633820934 | validation: 0.1499059461287509]
	TIME [epoch: 21.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08505880547249287		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.08505880547249287 | validation: 0.15619865552920748]
	TIME [epoch: 21.1 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08885207808220848		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.08885207808220848 | validation: 0.1560697722945076]
	TIME [epoch: 21.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08726222492478959		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.08726222492478959 | validation: 0.1539434101863748]
	TIME [epoch: 21.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09536273784111356		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.09536273784111356 | validation: 0.15194576581032826]
	TIME [epoch: 21.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343499747264668		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.09343499747264668 | validation: 0.14785970343783011]
	TIME [epoch: 21.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0913438360312214		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0913438360312214 | validation: 0.1678113853448717]
	TIME [epoch: 21.1 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752512969159018		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.08752512969159018 | validation: 0.1421047066164566]
	TIME [epoch: 21.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924561243711923		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.0924561243711923 | validation: 0.15820362064710256]
	TIME [epoch: 21.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09776644007471581		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.09776644007471581 | validation: 0.15457344819839988]
	TIME [epoch: 21.1 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09137333519968978		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.09137333519968978 | validation: 0.1490032135466144]
	TIME [epoch: 21.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08713122190890896		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.08713122190890896 | validation: 0.1515548390100575]
	TIME [epoch: 21.1 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468146245406853		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.09468146245406853 | validation: 0.16159624650284213]
	TIME [epoch: 21.1 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105814143157506		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.09105814143157506 | validation: 0.1526227611630415]
	TIME [epoch: 21.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08136197737061572		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.08136197737061572 | validation: 0.15392706946782417]
	TIME [epoch: 21.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09399113955894442		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.09399113955894442 | validation: 0.15673550297533734]
	TIME [epoch: 21.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08230855730721284		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.08230855730721284 | validation: 0.14621248123601033]
	TIME [epoch: 21.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08978335778821007		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.08978335778821007 | validation: 0.16267118240827483]
	TIME [epoch: 21.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09154429990370376		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09154429990370376 | validation: 0.15292539841102043]
	TIME [epoch: 21.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09215972796961827		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.09215972796961827 | validation: 0.14873631138398244]
	TIME [epoch: 21.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09653283290769576		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.09653283290769576 | validation: 0.15790348900299192]
	TIME [epoch: 21.1 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09644908047281675		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.09644908047281675 | validation: 0.1597899188681538]
	TIME [epoch: 21.1 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899558602617711		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.0899558602617711 | validation: 0.1628416883585762]
	TIME [epoch: 21.1 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09224167400049332		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.09224167400049332 | validation: 0.15836271713656638]
	TIME [epoch: 21.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08883156091104893		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.08883156091104893 | validation: 0.16364183870877755]
	TIME [epoch: 21.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900909823081168		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.08900909823081168 | validation: 0.16545746019190546]
	TIME [epoch: 21.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09647519835053052		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09647519835053052 | validation: 0.15258548789026516]
	TIME [epoch: 21.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08760857134989301		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.08760857134989301 | validation: 0.15375885715638973]
	TIME [epoch: 21.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08844281182597605		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.08844281182597605 | validation: 0.15080246380904896]
	TIME [epoch: 21.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08611806618044468		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.08611806618044468 | validation: 0.13528630086670287]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_743.pth
	Model improved!!!
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793450307668393		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0793450307668393 | validation: 0.14266563554717912]
	TIME [epoch: 21.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08612674347651264		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.08612674347651264 | validation: 0.15696674821694065]
	TIME [epoch: 21.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08775127818928816		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.08775127818928816 | validation: 0.15296202056926667]
	TIME [epoch: 21.1 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845244740616454		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.0845244740616454 | validation: 0.14284860736563204]
	TIME [epoch: 21.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09173218417142728		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09173218417142728 | validation: 0.16258586974757283]
	TIME [epoch: 21.1 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09115067530340994		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.09115067530340994 | validation: 0.15867325202975716]
	TIME [epoch: 21.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08838854710830234		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.08838854710830234 | validation: 0.1618312544398935]
	TIME [epoch: 21.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09162829139108424		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.09162829139108424 | validation: 0.15905554181382367]
	TIME [epoch: 21.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08694242308948927		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.08694242308948927 | validation: 0.1602284415420698]
	TIME [epoch: 21.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847525142329468		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.0847525142329468 | validation: 0.15950008329885645]
	TIME [epoch: 21.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09171095577984503		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.09171095577984503 | validation: 0.15703894020507062]
	TIME [epoch: 21.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08685345738200624		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.08685345738200624 | validation: 0.16271263365664204]
	TIME [epoch: 21.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08275766198377055		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.08275766198377055 | validation: 0.15464658951510557]
	TIME [epoch: 21.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08636631553985588		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.08636631553985588 | validation: 0.154255416138292]
	TIME [epoch: 21.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09030541975583531		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.09030541975583531 | validation: 0.16227128004791405]
	TIME [epoch: 21.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09497310879567525		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.09497310879567525 | validation: 0.1573303191149062]
	TIME [epoch: 21.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08382473504235287		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.08382473504235287 | validation: 0.14685425229856197]
	TIME [epoch: 21.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09070170637263018		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.09070170637263018 | validation: 0.1521931900664713]
	TIME [epoch: 21.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08434948349883269		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.08434948349883269 | validation: 0.14796256540006109]
	TIME [epoch: 21.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08273075280653706		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.08273075280653706 | validation: 0.15538695502071084]
	TIME [epoch: 21.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09170398116984695		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.09170398116984695 | validation: 0.14927008236192393]
	TIME [epoch: 21.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407535843084372		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.09407535843084372 | validation: 0.17034112978968735]
	TIME [epoch: 21.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09453176358715992		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.09453176358715992 | validation: 0.15416650101806026]
	TIME [epoch: 21.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08549169213822397		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.08549169213822397 | validation: 0.16922510891523418]
	TIME [epoch: 21.1 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09250376615276265		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09250376615276265 | validation: 0.14724940106156476]
	TIME [epoch: 21.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09517884780402927		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.09517884780402927 | validation: 0.16594954244650895]
	TIME [epoch: 21.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09487397929942214		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.09487397929942214 | validation: 0.15951623702238515]
	TIME [epoch: 21.1 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09037911257156059		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.09037911257156059 | validation: 0.1536666726368419]
	TIME [epoch: 21.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213293268536708		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.09213293268536708 | validation: 0.15749450245842317]
	TIME [epoch: 21.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08952375954888982		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.08952375954888982 | validation: 0.1557122010705435]
	TIME [epoch: 21.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597582142255837		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.08597582142255837 | validation: 0.15787507655971073]
	TIME [epoch: 21.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08416310745826758		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.08416310745826758 | validation: 0.1435781863047667]
	TIME [epoch: 21.1 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09094804027224482		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.09094804027224482 | validation: 0.14871930402689626]
	TIME [epoch: 21.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858014439339787		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.0858014439339787 | validation: 0.17169977201954603]
	TIME [epoch: 21.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09040959164042776		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.09040959164042776 | validation: 0.15652620158443073]
	TIME [epoch: 21.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09273581693353274		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.09273581693353274 | validation: 0.15427677549036758]
	TIME [epoch: 21.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08867271915340036		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08867271915340036 | validation: 0.15160752056520477]
	TIME [epoch: 21.1 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09675402080846725		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.09675402080846725 | validation: 0.15631958910850413]
	TIME [epoch: 21.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08011467639064654		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.08011467639064654 | validation: 0.14736728072851077]
	TIME [epoch: 21.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09458675816097163		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.09458675816097163 | validation: 0.14325378810296213]
	TIME [epoch: 21.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0866158483475292		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0866158483475292 | validation: 0.14989609959032146]
	TIME [epoch: 21.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08601117744384464		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.08601117744384464 | validation: 0.15327292875492257]
	TIME [epoch: 21.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08708397990102554		[learning rate: 0.00036793]
	Learning Rate: 0.000367933
	LOSS [training: 0.08708397990102554 | validation: 0.16733000060473482]
	TIME [epoch: 21.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213397744554855		[learning rate: 0.00036631]
	Learning Rate: 0.000366308
	LOSS [training: 0.09213397744554855 | validation: 0.14739809345294344]
	TIME [epoch: 21.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08853547693397887		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.08853547693397887 | validation: 0.16036182268831534]
	TIME [epoch: 21.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08816669609934705		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.08816669609934705 | validation: 0.14301552919879693]
	TIME [epoch: 21.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08754536466174831		[learning rate: 0.00036147]
	Learning Rate: 0.000361474
	LOSS [training: 0.08754536466174831 | validation: 0.14886132452825596]
	TIME [epoch: 21.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08767477711523507		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 0.08767477711523507 | validation: 0.15340192880893272]
	TIME [epoch: 21.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08625946904608323		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.08625946904608323 | validation: 0.16025941975152996]
	TIME [epoch: 21.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750964148647348		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.09750964148647348 | validation: 0.16067732050259398]
	TIME [epoch: 21.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08833824015497667		[learning rate: 0.00035513]
	Learning Rate: 0.000355128
	LOSS [training: 0.08833824015497667 | validation: 0.14765302154491122]
	TIME [epoch: 21.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08840175422370411		[learning rate: 0.00035356]
	Learning Rate: 0.000353559
	LOSS [training: 0.08840175422370411 | validation: 0.14894963000484368]
	TIME [epoch: 21.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010220075783268		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09010220075783268 | validation: 0.14810512762101716]
	TIME [epoch: 21.1 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08817710064868214		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.08817710064868214 | validation: 0.16175895346081798]
	TIME [epoch: 21.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09247419938272308		[learning rate: 0.00034889]
	Learning Rate: 0.000348893
	LOSS [training: 0.09247419938272308 | validation: 0.1476507651666572]
	TIME [epoch: 21.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910458191588553		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.0910458191588553 | validation: 0.16280612432947322]
	TIME [epoch: 21.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088334767829492		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.088334767829492 | validation: 0.16816294646173266]
	TIME [epoch: 21.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482516938902222		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.08482516938902222 | validation: 0.1623066556476712]
	TIME [epoch: 21.1 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08983170314019015		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.08983170314019015 | validation: 0.15020304420881078]
	TIME [epoch: 21.1 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09066559281654395		[learning rate: 0.00034125]
	Learning Rate: 0.000341253
	LOSS [training: 0.09066559281654395 | validation: 0.15657840125769626]
	TIME [epoch: 21.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09293405306419769		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.09293405306419769 | validation: 0.1601455106081295]
	TIME [epoch: 21.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08849761823930966		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.08849761823930966 | validation: 0.15043354608679416]
	TIME [epoch: 21.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08982180751313895		[learning rate: 0.00033675]
	Learning Rate: 0.00033675
	LOSS [training: 0.08982180751313895 | validation: 0.15350057490860078]
	TIME [epoch: 21.1 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10089785832594696		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.10089785832594696 | validation: 0.1568028404720752]
	TIME [epoch: 21.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09732370317359364		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09732370317359364 | validation: 0.16548203182797872]
	TIME [epoch: 21.1 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0829863392087497		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.0829863392087497 | validation: 0.16271552920362833]
	TIME [epoch: 21.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09250734840141324		[learning rate: 0.00033084]
	Learning Rate: 0.000330838
	LOSS [training: 0.09250734840141324 | validation: 0.1616329688553379]
	TIME [epoch: 21.1 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09219514777117065		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.09219514777117065 | validation: 0.16578847666985008]
	TIME [epoch: 21.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0961217515419756		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0961217515419756 | validation: 0.1505029806526125]
	TIME [epoch: 21.1 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086400856146517		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.086400856146517 | validation: 0.15749633873180166]
	TIME [epoch: 21.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08503654791606013		[learning rate: 0.00032503]
	Learning Rate: 0.00032503
	LOSS [training: 0.08503654791606013 | validation: 0.1525278975488868]
	TIME [epoch: 21.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08534854079499643		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: 0.08534854079499643 | validation: 0.16153824238278988]
	TIME [epoch: 21.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08602931893536545		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08602931893536545 | validation: 0.1524628156318725]
	TIME [epoch: 21.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09608931611675295		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.09608931611675295 | validation: 0.15334055307087624]
	TIME [epoch: 21.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0960623860438078		[learning rate: 0.00031932]
	Learning Rate: 0.000319323
	LOSS [training: 0.0960623860438078 | validation: 0.16028395542803492]
	TIME [epoch: 21.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262836869854638		[learning rate: 0.00031791]
	Learning Rate: 0.000317913
	LOSS [training: 0.09262836869854638 | validation: 0.14985944562900175]
	TIME [epoch: 21.1 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08702272275201169		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08702272275201169 | validation: 0.15200889986468594]
	TIME [epoch: 21.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886994163532239		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.08886994163532239 | validation: 0.15430461488263567]
	TIME [epoch: 21 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08849475554487896		[learning rate: 0.00031372]
	Learning Rate: 0.000313717
	LOSS [training: 0.08849475554487896 | validation: 0.1704320923610397]
	TIME [epoch: 21.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08549802814075194		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: 0.08549802814075194 | validation: 0.15527718304987553]
	TIME [epoch: 21.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607541570353985		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.08607541570353985 | validation: 0.16070781991209251]
	TIME [epoch: 21.1 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08501731040259607		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.08501731040259607 | validation: 0.16434847365206284]
	TIME [epoch: 21.1 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08834420222963044		[learning rate: 0.00030821]
	Learning Rate: 0.00030821
	LOSS [training: 0.08834420222963044 | validation: 0.1500841935883993]
	TIME [epoch: 21.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08909851633504515		[learning rate: 0.00030685]
	Learning Rate: 0.000306848
	LOSS [training: 0.08909851633504515 | validation: 0.14878322336551347]
	TIME [epoch: 21.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08998700434377482		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08998700434377482 | validation: 0.15250890902739558]
	TIME [epoch: 21.1 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09381867306386127		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.09381867306386127 | validation: 0.1470740116999838]
	TIME [epoch: 21.1 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09238120596931676		[learning rate: 0.0003028]
	Learning Rate: 0.000302799
	LOSS [training: 0.09238120596931676 | validation: 0.1578649848798572]
	TIME [epoch: 21.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08901348788195955		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: 0.08901348788195955 | validation: 0.14502625896116303]
	TIME [epoch: 21.1 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09141638162548178		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.09141638162548178 | validation: 0.15053609094034928]
	TIME [epoch: 21.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08650794527064441		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.08650794527064441 | validation: 0.15498683877174502]
	TIME [epoch: 21.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08287008159702025		[learning rate: 0.00029748]
	Learning Rate: 0.000297483
	LOSS [training: 0.08287008159702025 | validation: 0.15204897513125612]
	TIME [epoch: 21.1 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09098835916975864		[learning rate: 0.00029617]
	Learning Rate: 0.000296168
	LOSS [training: 0.09098835916975864 | validation: 0.14848799831487766]
	TIME [epoch: 21.1 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08644350701063663		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08644350701063663 | validation: 0.15360461018361152]
	TIME [epoch: 21.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0922199023392493		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.0922199023392493 | validation: 0.16054717252712997]
	TIME [epoch: 21.1 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09062992506241155		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.09062992506241155 | validation: 0.1558739046899495]
	TIME [epoch: 21 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09292161465697094		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: 0.09292161465697094 | validation: 0.148885342128447]
	TIME [epoch: 21.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08914097661704987		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.08914097661704987 | validation: 0.1547605789373577]
	TIME [epoch: 21.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09157682510438911		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.09157682510438911 | validation: 0.15074724370554504]
	TIME [epoch: 21.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09363674449764793		[learning rate: 0.00028713]
	Learning Rate: 0.000287129
	LOSS [training: 0.09363674449764793 | validation: 0.15887867082063695]
	TIME [epoch: 21.1 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806141017385246		[learning rate: 0.00028586]
	Learning Rate: 0.00028586
	LOSS [training: 0.0806141017385246 | validation: 0.1527129541206823]
	TIME [epoch: 21.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783023239343606		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08783023239343606 | validation: 0.14567626839050282]
	TIME [epoch: 21.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09397845661567354		[learning rate: 0.00028334]
	Learning Rate: 0.00028334
	LOSS [training: 0.09397845661567354 | validation: 0.15317534444394398]
	TIME [epoch: 21.1 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08349900343366849		[learning rate: 0.00028209]
	Learning Rate: 0.000282088
	LOSS [training: 0.08349900343366849 | validation: 0.15042093835732756]
	TIME [epoch: 21.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08976262296209518		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.08976262296209518 | validation: 0.1517464173178637]
	TIME [epoch: 21.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08669470661363336		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.08669470661363336 | validation: 0.1474805847325908]
	TIME [epoch: 21.1 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08379718670750527		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.08379718670750527 | validation: 0.1540366893376491]
	TIME [epoch: 21.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08114165828597666		[learning rate: 0.00027714]
	Learning Rate: 0.000277136
	LOSS [training: 0.08114165828597666 | validation: 0.1600038658595999]
	TIME [epoch: 21.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09501742077558899		[learning rate: 0.00027591]
	Learning Rate: 0.000275911
	LOSS [training: 0.09501742077558899 | validation: 0.15173211955330176]
	TIME [epoch: 21.1 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09292532483066505		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.09292532483066505 | validation: 0.15787132295234235]
	TIME [epoch: 21.1 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.089851607242937		[learning rate: 0.00027348]
	Learning Rate: 0.000273479
	LOSS [training: 0.089851607242937 | validation: 0.15829083459523996]
	TIME [epoch: 21 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09092861946634288		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.09092861946634288 | validation: 0.15169010870194893]
	TIME [epoch: 21.1 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901762018614454		[learning rate: 0.00027107]
	Learning Rate: 0.000271067
	LOSS [training: 0.0901762018614454 | validation: 0.15966486510595593]
	TIME [epoch: 21.1 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08797869870626965		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08797869870626965 | validation: 0.15840801585219788]
	TIME [epoch: 21.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08765856761564654		[learning rate: 0.00026868]
	Learning Rate: 0.000268677
	LOSS [training: 0.08765856761564654 | validation: 0.14886152543795633]
	TIME [epoch: 21.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0940878058747459		[learning rate: 0.00026749]
	Learning Rate: 0.00026749
	LOSS [training: 0.0940878058747459 | validation: 0.14377829012905868]
	TIME [epoch: 21.1 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08919069163949846		[learning rate: 0.00026631]
	Learning Rate: 0.000266308
	LOSS [training: 0.08919069163949846 | validation: 0.1591800637071009]
	TIME [epoch: 21.1 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09035037406655995		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.09035037406655995 | validation: 0.1587538826356943]
	TIME [epoch: 21.1 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09270730243512959		[learning rate: 0.00026396]
	Learning Rate: 0.00026396
	LOSS [training: 0.09270730243512959 | validation: 0.15042712118597046]
	TIME [epoch: 21.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08618170840469588		[learning rate: 0.00026279]
	Learning Rate: 0.000262794
	LOSS [training: 0.08618170840469588 | validation: 0.15835483023361785]
	TIME [epoch: 21.1 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09052687907141067		[learning rate: 0.00026163]
	Learning Rate: 0.000261633
	LOSS [training: 0.09052687907141067 | validation: 0.15941554218154752]
	TIME [epoch: 21.1 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08700654151880045		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.08700654151880045 | validation: 0.15079262241038052]
	TIME [epoch: 21.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580133602557592		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.09580133602557592 | validation: 0.15261238830401627]
	TIME [epoch: 21.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0874649089010202		[learning rate: 0.00025818]
	Learning Rate: 0.00025818
	LOSS [training: 0.0874649089010202 | validation: 0.16417896777558072]
	TIME [epoch: 21.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08434289407828703		[learning rate: 0.00025704]
	Learning Rate: 0.00025704
	LOSS [training: 0.08434289407828703 | validation: 0.15750432365491554]
	TIME [epoch: 21.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08643911848353836		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08643911848353836 | validation: 0.15481695040782392]
	TIME [epoch: 21.1 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08722643178611066		[learning rate: 0.00025477]
	Learning Rate: 0.000254773
	LOSS [training: 0.08722643178611066 | validation: 0.16150361376988656]
	TIME [epoch: 21.1 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08569349241241497		[learning rate: 0.00025365]
	Learning Rate: 0.000253648
	LOSS [training: 0.08569349241241497 | validation: 0.15783690299784575]
	TIME [epoch: 21.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08247668766442806		[learning rate: 0.00025253]
	Learning Rate: 0.000252527
	LOSS [training: 0.08247668766442806 | validation: 0.16025222134576023]
	TIME [epoch: 21.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09172140371919155		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.09172140371919155 | validation: 0.15578679453708372]
	TIME [epoch: 21.1 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08389774501275837		[learning rate: 0.0002503]
	Learning Rate: 0.0002503
	LOSS [training: 0.08389774501275837 | validation: 0.15613498612467255]
	TIME [epoch: 21.1 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08861680160368664		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.08861680160368664 | validation: 0.16466360607671882]
	TIME [epoch: 21.1 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09196720279615793		[learning rate: 0.00024809]
	Learning Rate: 0.000248094
	LOSS [training: 0.09196720279615793 | validation: 0.16154271208118107]
	TIME [epoch: 21.1 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0881824451410742		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0881824451410742 | validation: 0.16213493657288994]
	TIME [epoch: 21.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448102269058014		[learning rate: 0.00024591]
	Learning Rate: 0.000245906
	LOSS [training: 0.08448102269058014 | validation: 0.15158134587558372]
	TIME [epoch: 21.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793805405378648		[learning rate: 0.00024482]
	Learning Rate: 0.00024482
	LOSS [training: 0.08793805405378648 | validation: 0.15260573565824723]
	TIME [epoch: 21.1 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905145459826801		[learning rate: 0.00024374]
	Learning Rate: 0.000243738
	LOSS [training: 0.0905145459826801 | validation: 0.14624972219971172]
	TIME [epoch: 21.1 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09454716872226682		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.09454716872226682 | validation: 0.15581220446648952]
	TIME [epoch: 21.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08889038712550147		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.08889038712550147 | validation: 0.15344782279134508]
	TIME [epoch: 21.1 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08971623553460659		[learning rate: 0.00024052]
	Learning Rate: 0.000240521
	LOSS [training: 0.08971623553460659 | validation: 0.15090479801751436]
	TIME [epoch: 21.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986288905775916		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.08986288905775916 | validation: 0.15257066665517438]
	TIME [epoch: 21.1 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367794139962811		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.08367794139962811 | validation: 0.15879676171236018]
	TIME [epoch: 21.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09405657323476477		[learning rate: 0.00023735]
	Learning Rate: 0.000237348
	LOSS [training: 0.09405657323476477 | validation: 0.167651284193782]
	TIME [epoch: 21.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09098318507265182		[learning rate: 0.0002363]
	Learning Rate: 0.000236299
	LOSS [training: 0.09098318507265182 | validation: 0.17148982826769452]
	TIME [epoch: 21.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08914208251060429		[learning rate: 0.00023525]
	Learning Rate: 0.000235255
	LOSS [training: 0.08914208251060429 | validation: 0.14947941752431607]
	TIME [epoch: 21.1 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167400091413792		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.09167400091413792 | validation: 0.16109515148439163]
	TIME [epoch: 21.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09227850153782323		[learning rate: 0.00023318]
	Learning Rate: 0.000233181
	LOSS [training: 0.09227850153782323 | validation: 0.1506214878353857]
	TIME [epoch: 21.1 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08711543490434936		[learning rate: 0.00023215]
	Learning Rate: 0.00023215
	LOSS [training: 0.08711543490434936 | validation: 0.1529306280028012]
	TIME [epoch: 21.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662818914416962		[learning rate: 0.00023112]
	Learning Rate: 0.000231125
	LOSS [training: 0.08662818914416962 | validation: 0.1537612200492701]
	TIME [epoch: 21.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08942287905940431		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08942287905940431 | validation: 0.15128321002554426]
	TIME [epoch: 21.1 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08268551198976795		[learning rate: 0.00022909]
	Learning Rate: 0.000229087
	LOSS [training: 0.08268551198976795 | validation: 0.15804124975265435]
	TIME [epoch: 21.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09263204481968638		[learning rate: 0.00022807]
	Learning Rate: 0.000228075
	LOSS [training: 0.09263204481968638 | validation: 0.15963915051108118]
	TIME [epoch: 21.1 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09073495281387264		[learning rate: 0.00022707]
	Learning Rate: 0.000227067
	LOSS [training: 0.09073495281387264 | validation: 0.14686863211579232]
	TIME [epoch: 21.1 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09594004509295251		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.09594004509295251 | validation: 0.14580986808700966]
	TIME [epoch: 21.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413696579397521		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.09413696579397521 | validation: 0.15225926701145606]
	TIME [epoch: 21.1 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09405626895355876		[learning rate: 0.00022407]
	Learning Rate: 0.00022407
	LOSS [training: 0.09405626895355876 | validation: 0.1430744880509939]
	TIME [epoch: 21.1 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08636345422372196		[learning rate: 0.00022308]
	Learning Rate: 0.000223081
	LOSS [training: 0.08636345422372196 | validation: 0.16011093230361964]
	TIME [epoch: 21.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08909693383101511		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.08909693383101511 | validation: 0.1636735499891768]
	TIME [epoch: 21.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07939097819162681		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.07939097819162681 | validation: 0.15787183377400266]
	TIME [epoch: 21.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09692866234191004		[learning rate: 0.00022014]
	Learning Rate: 0.000220137
	LOSS [training: 0.09692866234191004 | validation: 0.14954506402177878]
	TIME [epoch: 21.1 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0890383878261841		[learning rate: 0.00021916]
	Learning Rate: 0.000219164
	LOSS [training: 0.0890383878261841 | validation: 0.15459490041888505]
	TIME [epoch: 21.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08875001976495386		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.08875001976495386 | validation: 0.16165532928448464]
	TIME [epoch: 21.1 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09416824397200503		[learning rate: 0.00021723]
	Learning Rate: 0.000217232
	LOSS [training: 0.09416824397200503 | validation: 0.151568458889742]
	TIME [epoch: 21.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08405946525908356		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.08405946525908356 | validation: 0.15744438996504906]
	TIME [epoch: 21.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08784267526908598		[learning rate: 0.00021532]
	Learning Rate: 0.000215316
	LOSS [training: 0.08784267526908598 | validation: 0.15097908588647135]
	TIME [epoch: 21.1 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340902290106718		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.08340902290106718 | validation: 0.16432476221530448]
	TIME [epoch: 21.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0906315537696794		[learning rate: 0.00021342]
	Learning Rate: 0.000213418
	LOSS [training: 0.0906315537696794 | validation: 0.15439337356152652]
	TIME [epoch: 21.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08919810154930172		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.08919810154930172 | validation: 0.148752245154521]
	TIME [epoch: 21.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08726064302300657		[learning rate: 0.00021154]
	Learning Rate: 0.000211536
	LOSS [training: 0.08726064302300657 | validation: 0.15432533968689177]
	TIME [epoch: 21.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08634183773867107		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.08634183773867107 | validation: 0.15241773396917663]
	TIME [epoch: 21.1 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08844503650992322		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.08844503650992322 | validation: 0.14550726484270265]
	TIME [epoch: 21.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09309866415090166		[learning rate: 0.00020874]
	Learning Rate: 0.000208745
	LOSS [training: 0.09309866415090166 | validation: 0.1474815007715124]
	TIME [epoch: 21.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08194850705760125		[learning rate: 0.00020782]
	Learning Rate: 0.000207822
	LOSS [training: 0.08194850705760125 | validation: 0.14898471596014917]
	TIME [epoch: 21.1 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08750911107790563		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08750911107790563 | validation: 0.14983124920800467]
	TIME [epoch: 21.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08535687637304855		[learning rate: 0.00020599]
	Learning Rate: 0.00020599
	LOSS [training: 0.08535687637304855 | validation: 0.16386985556269842]
	TIME [epoch: 21.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08913581382588284		[learning rate: 0.00020508]
	Learning Rate: 0.00020508
	LOSS [training: 0.08913581382588284 | validation: 0.15725232231968875]
	TIME [epoch: 21.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08848668199286833		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.08848668199286833 | validation: 0.17062452008783976]
	TIME [epoch: 21.1 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09314038577190745		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09314038577190745 | validation: 0.15914046123767708]
	TIME [epoch: 21.1 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008646632654618		[learning rate: 0.00020237]
	Learning Rate: 0.000202374
	LOSS [training: 0.09008646632654618 | validation: 0.16058279483230647]
	TIME [epoch: 21.1 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396240329323698		[learning rate: 0.00020148]
	Learning Rate: 0.000201479
	LOSS [training: 0.08396240329323698 | validation: 0.15680835714016172]
	TIME [epoch: 21.1 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086626491175236		[learning rate: 0.00020059]
	Learning Rate: 0.000200589
	LOSS [training: 0.09086626491175236 | validation: 0.16762377770503045]
	TIME [epoch: 21.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09500605203322669		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.09500605203322669 | validation: 0.15283656429099024]
	TIME [epoch: 21.1 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09220999445641366		[learning rate: 0.00019882]
	Learning Rate: 0.000198821
	LOSS [training: 0.09220999445641366 | validation: 0.15956974828371154]
	TIME [epoch: 21.1 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08693403805437414		[learning rate: 0.00019794]
	Learning Rate: 0.000197942
	LOSS [training: 0.08693403805437414 | validation: 0.1603709140758796]
	TIME [epoch: 21.1 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09083362695108006		[learning rate: 0.00019707]
	Learning Rate: 0.000197068
	LOSS [training: 0.09083362695108006 | validation: 0.14865480623571348]
	TIME [epoch: 21.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07992810457147519		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07992810457147519 | validation: 0.15727153874035502]
	TIME [epoch: 21.1 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09034219992619524		[learning rate: 0.00019533]
	Learning Rate: 0.00019533
	LOSS [training: 0.09034219992619524 | validation: 0.15222504690135946]
	TIME [epoch: 21.1 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09270069078370861		[learning rate: 0.00019447]
	Learning Rate: 0.000194467
	LOSS [training: 0.09270069078370861 | validation: 0.15260851925468386]
	TIME [epoch: 21.1 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0843258598271596		[learning rate: 0.00019361]
	Learning Rate: 0.000193608
	LOSS [training: 0.0843258598271596 | validation: 0.14892343021365947]
	TIME [epoch: 21.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08473516899917316		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08473516899917316 | validation: 0.15759368766005302]
	TIME [epoch: 21.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09556051702159588		[learning rate: 0.0001919]
	Learning Rate: 0.000191901
	LOSS [training: 0.09556051702159588 | validation: 0.16158751428108967]
	TIME [epoch: 21.1 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857677992162968		[learning rate: 0.00019105]
	Learning Rate: 0.000191053
	LOSS [training: 0.08857677992162968 | validation: 0.14807633904809034]
	TIME [epoch: 21.1 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.084165563695008		[learning rate: 0.00019021]
	Learning Rate: 0.000190209
	LOSS [training: 0.084165563695008 | validation: 0.14723856209344943]
	TIME [epoch: 21.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09123416055358886		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.09123416055358886 | validation: 0.16692908108046814]
	TIME [epoch: 21.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08988434060561291		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.08988434060561291 | validation: 0.15689022131257838]
	TIME [epoch: 21.1 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09128660264111212		[learning rate: 0.0001877]
	Learning Rate: 0.000187699
	LOSS [training: 0.09128660264111212 | validation: 0.16252051209831833]
	TIME [epoch: 21.1 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857437106621376		[learning rate: 0.00018687]
	Learning Rate: 0.00018687
	LOSS [training: 0.0857437106621376 | validation: 0.16583090038539638]
	TIME [epoch: 21.1 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08470112345901648		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.08470112345901648 | validation: 0.16106758927026513]
	TIME [epoch: 21.1 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826194006427113		[learning rate: 0.00018522]
	Learning Rate: 0.000185222
	LOSS [training: 0.0826194006427113 | validation: 0.16054378411603676]
	TIME [epoch: 21.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09984559607587329		[learning rate: 0.0001844]
	Learning Rate: 0.000184404
	LOSS [training: 0.09984559607587329 | validation: 0.1431616288336568]
	TIME [epoch: 21.1 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08801754310277488		[learning rate: 0.00018359]
	Learning Rate: 0.000183589
	LOSS [training: 0.08801754310277488 | validation: 0.14489147092525975]
	TIME [epoch: 21.1 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08308555311782836		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.08308555311782836 | validation: 0.15768129859382005]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240624_133245/states/model_facs_dec2a_2dpca_v1_944.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 20117.000 seconds.
