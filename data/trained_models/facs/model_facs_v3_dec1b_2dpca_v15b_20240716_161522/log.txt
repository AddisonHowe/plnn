Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v15b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v15b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1416844062

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3980690910560638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3980690910560638 | validation: 1.1184324577419202]
	TIME [epoch: 22.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2468839277092105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2468839277092105 | validation: 1.1195389585043196]
	TIME [epoch: 5.33 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2027661996215684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2027661996215684 | validation: 1.0300372332199383]
	TIME [epoch: 5.31 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.143882945499308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.143882945499308 | validation: 0.9538247128502009]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.090931686456179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.090931686456179 | validation: 0.9205205215744661]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0600701293276658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0600701293276658 | validation: 0.8663140351382506]
	TIME [epoch: 5.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9960962438005683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9960962438005683 | validation: 0.8787713275376834]
	TIME [epoch: 5.34 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8984088901753461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8984088901753461 | validation: 0.7522274819463373]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9048365253208033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9048365253208033 | validation: 0.7544064894250975]
	TIME [epoch: 5.33 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8057514038862874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8057514038862874 | validation: 0.6630008946234804]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8129849016408438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8129849016408438 | validation: 0.7522341799128307]
	TIME [epoch: 5.33 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7135291354543267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7135291354543267 | validation: 0.7158719291038431]
	TIME [epoch: 5.32 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9335361247658209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9335361247658209 | validation: 0.6994492248707872]
	TIME [epoch: 5.33 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.881201941248047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.881201941248047 | validation: 0.7298671745662911]
	TIME [epoch: 5.33 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8152048700580399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8152048700580399 | validation: 0.682509789748569]
	TIME [epoch: 5.33 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7210058626166761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7210058626166761 | validation: 0.6515139224599418]
	TIME [epoch: 5.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6680220037097887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6680220037097887 | validation: 0.5407225851550773]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6063420642672981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6063420642672981 | validation: 0.5536734275836055]
	TIME [epoch: 5.32 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5912939196573254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5912939196573254 | validation: 0.40569757327648254]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4716487744235584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4716487744235584 | validation: 0.39962023193547086]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46122747636607003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46122747636607003 | validation: 0.3574212805984976]
	TIME [epoch: 5.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4296018818216906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4296018818216906 | validation: 0.35164664938242474]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4975632910789011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4975632910789011 | validation: 0.3347468232877422]
	TIME [epoch: 5.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39937451066484364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39937451066484364 | validation: 0.3502999369907186]
	TIME [epoch: 5.33 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40279621932485105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40279621932485105 | validation: 0.32112703688073496]
	TIME [epoch: 5.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41361375253803373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41361375253803373 | validation: 0.468906972478663]
	TIME [epoch: 5.34 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4339659703736399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4339659703736399 | validation: 0.312482925340442]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3939298331335361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3939298331335361 | validation: 0.3556992268120471]
	TIME [epoch: 5.33 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40077268054670806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40077268054670806 | validation: 0.360258094265149]
	TIME [epoch: 5.33 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3873518200438814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3873518200438814 | validation: 0.32394252703382026]
	TIME [epoch: 5.34 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3999897905924053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3999897905924053 | validation: 0.32287834534970916]
	TIME [epoch: 5.33 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40284661094460034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40284661094460034 | validation: 0.30082020601363335]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41202393950888566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41202393950888566 | validation: 0.31765321646848727]
	TIME [epoch: 5.34 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4002670198573411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4002670198573411 | validation: 0.30520005233496905]
	TIME [epoch: 5.33 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37460882831228154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37460882831228154 | validation: 0.30105307076699883]
	TIME [epoch: 5.33 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36410210361006734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36410210361006734 | validation: 0.30881457657981654]
	TIME [epoch: 5.34 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3925855840932589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3925855840932589 | validation: 0.2930545599156531]
	TIME [epoch: 5.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3612901656152463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3612901656152463 | validation: 0.3273618448660741]
	TIME [epoch: 5.32 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.343138510519363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.343138510519363 | validation: 0.2895412106050658]
	TIME [epoch: 5.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3826120670744703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3826120670744703 | validation: 0.2885303002485305]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37059635714708966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37059635714708966 | validation: 0.2750680190841841]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34125547102702214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34125547102702214 | validation: 0.25981401913545743]
	TIME [epoch: 5.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35570872714496554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35570872714496554 | validation: 0.32561192832256675]
	TIME [epoch: 5.34 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3598252844708471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3598252844708471 | validation: 0.2917335991267646]
	TIME [epoch: 5.33 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.353535379935376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.353535379935376 | validation: 0.30158103445300627]
	TIME [epoch: 5.33 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33456202070422186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33456202070422186 | validation: 0.29155277900909404]
	TIME [epoch: 5.33 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3487554575203198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3487554575203198 | validation: 0.26877887989418897]
	TIME [epoch: 5.33 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3409146191998018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3409146191998018 | validation: 0.25671719445854674]
	TIME [epoch: 5.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3273947407918987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3273947407918987 | validation: 0.25971469028748306]
	TIME [epoch: 5.33 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34008921046032303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34008921046032303 | validation: 0.2848655895287857]
	TIME [epoch: 5.33 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3465314678333055		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3465314678333055 | validation: 0.3022229240858052]
	TIME [epoch: 25.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34285979853445386		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.34285979853445386 | validation: 0.2752436030786566]
	TIME [epoch: 10.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3347141040061439		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3347141040061439 | validation: 0.2533217039985164]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33797667118402713		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.33797667118402713 | validation: 0.32945314230210987]
	TIME [epoch: 10.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3679576939978266		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.3679576939978266 | validation: 0.26953492565411824]
	TIME [epoch: 10.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32409257814885095		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.32409257814885095 | validation: 0.2972317172879474]
	TIME [epoch: 10.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3309048769280469		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.3309048769280469 | validation: 0.26326893976020294]
	TIME [epoch: 10.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3264078993752008		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.3264078993752008 | validation: 0.2511433773567314]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3528910862135104		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.3528910862135104 | validation: 0.30976806756805514]
	TIME [epoch: 10.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3398942779519459		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.3398942779519459 | validation: 0.24182287640130662]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30573388910159033		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.30573388910159033 | validation: 0.2788408915148196]
	TIME [epoch: 10.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33962208146893813		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.33962208146893813 | validation: 0.25713280530712623]
	TIME [epoch: 10.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34632648972491364		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.34632648972491364 | validation: 0.2460657994169876]
	TIME [epoch: 10.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30994519503930423		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.30994519503930423 | validation: 0.24701160406113307]
	TIME [epoch: 10.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32151642955279014		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.32151642955279014 | validation: 0.23680200922407568]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31253850585751014		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.31253850585751014 | validation: 0.23532438369813896]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3306390850184316		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.3306390850184316 | validation: 0.24197071302798978]
	TIME [epoch: 10.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3198764462082312		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.3198764462082312 | validation: 0.24243471163048014]
	TIME [epoch: 10.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31601292440798984		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.31601292440798984 | validation: 0.24176829519207926]
	TIME [epoch: 10.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30383511716332684		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.30383511716332684 | validation: 0.24393889005115668]
	TIME [epoch: 10.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31155966860035184		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.31155966860035184 | validation: 0.2514692260727596]
	TIME [epoch: 10.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29025667844729147		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29025667844729147 | validation: 0.2324937374511286]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3153905438844768		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.3153905438844768 | validation: 0.24762315813572017]
	TIME [epoch: 10.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.331467671261968		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.331467671261968 | validation: 0.25979786755476847]
	TIME [epoch: 10.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29851550562402823		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.29851550562402823 | validation: 0.23407763752644883]
	TIME [epoch: 10.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.294127705079136		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.294127705079136 | validation: 0.26009462132895933]
	TIME [epoch: 10.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3104128009232577		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.3104128009232577 | validation: 0.2541966972736188]
	TIME [epoch: 10.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3022372107458929		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.3022372107458929 | validation: 0.23797421420754747]
	TIME [epoch: 10.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2982912644720809		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.2982912644720809 | validation: 0.2442097123379968]
	TIME [epoch: 10.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29659478583457105		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.29659478583457105 | validation: 0.25760730021688466]
	TIME [epoch: 10.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3266509768842391		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.3266509768842391 | validation: 0.21980173120448793]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30279936654193523		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.30279936654193523 | validation: 0.25554770615766165]
	TIME [epoch: 10.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29440788628234954		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.29440788628234954 | validation: 0.24056636621109173]
	TIME [epoch: 10.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30510738477963417		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.30510738477963417 | validation: 0.22344052261942887]
	TIME [epoch: 10.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3026017696631331		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.3026017696631331 | validation: 0.2452019938473778]
	TIME [epoch: 10.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31300120139528115		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.31300120139528115 | validation: 0.23417147411120331]
	TIME [epoch: 10.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27892767385122463		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.27892767385122463 | validation: 0.29348141398778116]
	TIME [epoch: 10.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.304449468476549		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.304449468476549 | validation: 0.2568087097270493]
	TIME [epoch: 10.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2894168531576216		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2894168531576216 | validation: 0.24662459186984834]
	TIME [epoch: 10.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29384796572288774		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29384796572288774 | validation: 0.21896256543073683]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802886919480819		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2802886919480819 | validation: 0.21977310164602087]
	TIME [epoch: 10.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2891659428817362		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2891659428817362 | validation: 0.24064355997638445]
	TIME [epoch: 10.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2933424113392508		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2933424113392508 | validation: 0.24696214422080381]
	TIME [epoch: 10.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3286638343489512		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.3286638343489512 | validation: 0.22499939385275133]
	TIME [epoch: 10.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2933138474134964		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2933138474134964 | validation: 0.23102426626616843]
	TIME [epoch: 10.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27482085617301377		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.27482085617301377 | validation: 0.2241023761458311]
	TIME [epoch: 10.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2867336810667896		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2867336810667896 | validation: 0.21835909188427377]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3055225270611779		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.3055225270611779 | validation: 0.2537345984507536]
	TIME [epoch: 10.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31259580906714085		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.31259580906714085 | validation: 0.2271173270615797]
	TIME [epoch: 10.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2876963668220483		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2876963668220483 | validation: 0.2178328743938895]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29372259128593536		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.29372259128593536 | validation: 0.22116431887960714]
	TIME [epoch: 37.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875152568387837		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.2875152568387837 | validation: 0.2430387711910805]
	TIME [epoch: 22.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2833561771238293		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2833561771238293 | validation: 0.22847382822444487]
	TIME [epoch: 22.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2938566920442463		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.2938566920442463 | validation: 0.22288770815140566]
	TIME [epoch: 22.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2769003298441754		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.2769003298441754 | validation: 0.2331992435987731]
	TIME [epoch: 22.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28987465864573175		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.28987465864573175 | validation: 0.22808554850484625]
	TIME [epoch: 22.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2831235003722456		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.2831235003722456 | validation: 0.2292778011718863]
	TIME [epoch: 22.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2836472523704725		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2836472523704725 | validation: 0.21804557008848788]
	TIME [epoch: 22.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28028395554889424		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.28028395554889424 | validation: 0.21299632346761238]
	TIME [epoch: 22.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.281814355034956		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.281814355034956 | validation: 0.24365974462019713]
	TIME [epoch: 22.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27761545266951215		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.27761545266951215 | validation: 0.22754857841040863]
	TIME [epoch: 22.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29552624298585467		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.29552624298585467 | validation: 0.24116058963569306]
	TIME [epoch: 22.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3011466187414704		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.3011466187414704 | validation: 0.23658262235835262]
	TIME [epoch: 22.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27299536898844556		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.27299536898844556 | validation: 0.2190090603061549]
	TIME [epoch: 22.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2789003107823096		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2789003107823096 | validation: 0.23328198867028513]
	TIME [epoch: 22.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27937287594930965		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.27937287594930965 | validation: 0.22812702430874232]
	TIME [epoch: 22.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28302724473454316		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.28302724473454316 | validation: 0.22335017024614068]
	TIME [epoch: 22.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735753029111921		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.2735753029111921 | validation: 0.21705724761986178]
	TIME [epoch: 22.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2734707376699414		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.2734707376699414 | validation: 0.2625826838615043]
	TIME [epoch: 22.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28869049864199403		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.28869049864199403 | validation: 0.22327756469370907]
	TIME [epoch: 22.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572699179074068		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2572699179074068 | validation: 0.21065348198208783]
	TIME [epoch: 22.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26535154001690386		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.26535154001690386 | validation: 0.22745353280090833]
	TIME [epoch: 22.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28205627447042786		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.28205627447042786 | validation: 0.2140678319687887]
	TIME [epoch: 22.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28706354240057375		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.28706354240057375 | validation: 0.22034340282094073]
	TIME [epoch: 22.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263306385601763		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.263306385601763 | validation: 0.26970018362140613]
	TIME [epoch: 22.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2995318059991053		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.2995318059991053 | validation: 0.24289882815383118]
	TIME [epoch: 22.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2771565788668124		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2771565788668124 | validation: 0.21401589096236684]
	TIME [epoch: 22.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26167742079253303		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.26167742079253303 | validation: 0.21593042221731756]
	TIME [epoch: 22.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2763789461062527		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2763789461062527 | validation: 0.2100313590862842]
	TIME [epoch: 22.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2770846131372879		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.2770846131372879 | validation: 0.22986154280261478]
	TIME [epoch: 22.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27798804410620853		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.27798804410620853 | validation: 0.2228811884714935]
	TIME [epoch: 22.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26501133994769804		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26501133994769804 | validation: 0.24578975117669472]
	TIME [epoch: 22.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685674472207751		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2685674472207751 | validation: 0.21689259310384953]
	TIME [epoch: 22.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2753537330341797		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2753537330341797 | validation: 0.22245635097798547]
	TIME [epoch: 22.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2744499975120234		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2744499975120234 | validation: 0.2265946877946276]
	TIME [epoch: 22.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660869252390498		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2660869252390498 | validation: 0.2236934491337283]
	TIME [epoch: 22.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26629028865772414		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.26629028865772414 | validation: 0.22400785038736956]
	TIME [epoch: 22.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751498792421478		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2751498792421478 | validation: 0.21712039000719238]
	TIME [epoch: 22.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844488777783894		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.2844488777783894 | validation: 0.2280709309199751]
	TIME [epoch: 22.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28997166282961323		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.28997166282961323 | validation: 0.21605920222221114]
	TIME [epoch: 22.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28365913777910456		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.28365913777910456 | validation: 0.21531680575399675]
	TIME [epoch: 22.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704498592174643		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2704498592174643 | validation: 0.22335582593922104]
	TIME [epoch: 22.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26547120692620757		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.26547120692620757 | validation: 0.23003687081930785]
	TIME [epoch: 22.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754895263067268		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2754895263067268 | validation: 0.22544770210468895]
	TIME [epoch: 22.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654612440006343		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2654612440006343 | validation: 0.21265132054917552]
	TIME [epoch: 22.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26643402678885236		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.26643402678885236 | validation: 0.22847582001003713]
	TIME [epoch: 22.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269028153509125		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.269028153509125 | validation: 0.24322701280913414]
	TIME [epoch: 22.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2847844966376058		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2847844966376058 | validation: 0.2318636284738723]
	TIME [epoch: 22.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2905316300868011		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2905316300868011 | validation: 0.21514773618462685]
	TIME [epoch: 22.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601074998480853		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2601074998480853 | validation: 0.2161680526877027]
	TIME [epoch: 22.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795281922086424		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2795281922086424 | validation: 0.21258352821379806]
	TIME [epoch: 22.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27791048406997393		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.27791048406997393 | validation: 0.21766375516859773]
	TIME [epoch: 22.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690220107829434		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2690220107829434 | validation: 0.2295944243282845]
	TIME [epoch: 22.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816494875995929		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2816494875995929 | validation: 0.22773233124447256]
	TIME [epoch: 22.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2755538277262472		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2755538277262472 | validation: 0.21114323592045475]
	TIME [epoch: 22.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27732480561174694		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.27732480561174694 | validation: 0.22455833722260027]
	TIME [epoch: 22.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554634820649244		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2554634820649244 | validation: 0.22777311750781237]
	TIME [epoch: 22.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27602352329507723		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.27602352329507723 | validation: 0.2193021777506435]
	TIME [epoch: 22.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27086252827490115		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.27086252827490115 | validation: 0.2166203751002204]
	TIME [epoch: 22.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754439790110838		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2754439790110838 | validation: 0.21802784481605947]
	TIME [epoch: 22.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675976250101513		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2675976250101513 | validation: 0.21856453547940796]
	TIME [epoch: 22.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27275014084985844		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.27275014084985844 | validation: 0.2211795643921543]
	TIME [epoch: 22.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574430303116723		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2574430303116723 | validation: 0.22096191191740716]
	TIME [epoch: 22.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26791440537317585		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.26791440537317585 | validation: 0.22155873873414245]
	TIME [epoch: 22.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26554793433502216		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.26554793433502216 | validation: 0.21507939640569287]
	TIME [epoch: 22.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26679687357419973		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.26679687357419973 | validation: 0.21628280572353625]
	TIME [epoch: 22.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26412357139907444		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26412357139907444 | validation: 0.22155125604740727]
	TIME [epoch: 22.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26339804423957575		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.26339804423957575 | validation: 0.21275600064189346]
	TIME [epoch: 22.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684380358962068		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.2684380358962068 | validation: 0.2214148499623013]
	TIME [epoch: 22.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2706337212720508		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.2706337212720508 | validation: 0.21318761369695904]
	TIME [epoch: 22.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669507564865756		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2669507564865756 | validation: 0.23156597533833834]
	TIME [epoch: 22.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26703120083188886		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.26703120083188886 | validation: 0.2228668589760281]
	TIME [epoch: 22.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26695939479568054		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26695939479568054 | validation: 0.20354115295161468]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674309433556037		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.2674309433556037 | validation: 0.2225182560352746]
	TIME [epoch: 22.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704473034309277		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2704473034309277 | validation: 0.22388060788691105]
	TIME [epoch: 22.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2695394274724297		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.2695394274724297 | validation: 0.22843410744064957]
	TIME [epoch: 22.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703321095658099		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.2703321095658099 | validation: 0.2365152107893537]
	TIME [epoch: 22.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26659824678789384		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.26659824678789384 | validation: 0.2180323587290391]
	TIME [epoch: 22.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569335929379261		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2569335929379261 | validation: 0.2283831655002854]
	TIME [epoch: 22.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2618600874733095		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2618600874733095 | validation: 0.22169525307450244]
	TIME [epoch: 22.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25574074286331355		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.25574074286331355 | validation: 0.21386503445513835]
	TIME [epoch: 22.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643506172255195		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2643506172255195 | validation: 0.20791727159463438]
	TIME [epoch: 22.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27293612350487617		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.27293612350487617 | validation: 0.21994818493353935]
	TIME [epoch: 22.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27484212261497293		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.27484212261497293 | validation: 0.23007323173594157]
	TIME [epoch: 22.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26258936373302544		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.26258936373302544 | validation: 0.21937032960640973]
	TIME [epoch: 22.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670370199329214		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.2670370199329214 | validation: 0.21258036330563942]
	TIME [epoch: 22.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25968069954470147		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25968069954470147 | validation: 0.21472144670276724]
	TIME [epoch: 22.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25326790849434827		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.25326790849434827 | validation: 0.22651903004544233]
	TIME [epoch: 22.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702830168658946		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2702830168658946 | validation: 0.22811290693619646]
	TIME [epoch: 22.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2746244931462078		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2746244931462078 | validation: 0.2391445483809968]
	TIME [epoch: 22.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817726740056383		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2817726740056383 | validation: 0.2143664118800817]
	TIME [epoch: 22.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26351140962070235		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.26351140962070235 | validation: 0.21742003472735544]
	TIME [epoch: 22.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26074617727225885		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.26074617727225885 | validation: 0.21728087195978962]
	TIME [epoch: 22.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572164986022214		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2572164986022214 | validation: 0.21276160124629334]
	TIME [epoch: 22.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2710835037729227		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.2710835037729227 | validation: 0.22040413841402762]
	TIME [epoch: 22.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2712217340201499		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2712217340201499 | validation: 0.20685306060734562]
	TIME [epoch: 22.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27223368204224624		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.27223368204224624 | validation: 0.22093149719750144]
	TIME [epoch: 22.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571995346340452		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2571995346340452 | validation: 0.2114107364435041]
	TIME [epoch: 22.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475957151126038		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.2475957151126038 | validation: 0.2292375454762964]
	TIME [epoch: 22.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27773593575782013		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.27773593575782013 | validation: 0.21518016848682908]
	TIME [epoch: 22.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27853654737892225		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.27853654737892225 | validation: 0.20334930111410993]
	TIME [epoch: 62.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.278867130841899		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.278867130841899 | validation: 0.20888130894234744]
	TIME [epoch: 47.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26226306669610966		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.26226306669610966 | validation: 0.21203982917958908]
	TIME [epoch: 47.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642971293345115		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2642971293345115 | validation: 0.2168892489120942]
	TIME [epoch: 47.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26122721432803614		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.26122721432803614 | validation: 0.2259874510568325]
	TIME [epoch: 47.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636134951158269		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.2636134951158269 | validation: 0.21959546166304791]
	TIME [epoch: 47.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.264988293956462		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.264988293956462 | validation: 0.20570338696775686]
	TIME [epoch: 47.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614511961182433		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2614511961182433 | validation: 0.21325411032519273]
	TIME [epoch: 47.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26387575997324536		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.26387575997324536 | validation: 0.19822068159596587]
	TIME [epoch: 47.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721737169804635		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2721737169804635 | validation: 0.20953630715902669]
	TIME [epoch: 47.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632952334854148		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2632952334854148 | validation: 0.21698729472958322]
	TIME [epoch: 47.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26223176132016035		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.26223176132016035 | validation: 0.2123709283009]
	TIME [epoch: 47.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26385636911267973		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.26385636911267973 | validation: 0.20799125865447535]
	TIME [epoch: 47.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967398573153346		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.24967398573153346 | validation: 0.22391401303933303]
	TIME [epoch: 47.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27965045964661717		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.27965045964661717 | validation: 0.22355896894094104]
	TIME [epoch: 47.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25220670081175217		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.25220670081175217 | validation: 0.21567770841627243]
	TIME [epoch: 47.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25917002679136963		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.25917002679136963 | validation: 0.22147644498690644]
	TIME [epoch: 47.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25170609479662986		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.25170609479662986 | validation: 0.21002280784566282]
	TIME [epoch: 47.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26048759833374385		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.26048759833374385 | validation: 0.208558317684132]
	TIME [epoch: 47.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597330242742944		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2597330242742944 | validation: 0.22355097013471942]
	TIME [epoch: 47.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642041061501302		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.2642041061501302 | validation: 0.21243910656558573]
	TIME [epoch: 47.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25345758560325043		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.25345758560325043 | validation: 0.2003013055825858]
	TIME [epoch: 47.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603198729591991		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2603198729591991 | validation: 0.21118351327205068]
	TIME [epoch: 47.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26090504441572254		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.26090504441572254 | validation: 0.23558111863422376]
	TIME [epoch: 47.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27471700194733345		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.27471700194733345 | validation: 0.2148677671891941]
	TIME [epoch: 47.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664491433396733		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2664491433396733 | validation: 0.21722633174961725]
	TIME [epoch: 47.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510611140158601		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2510611140158601 | validation: 0.23160348997796404]
	TIME [epoch: 47.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27014293427627695		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.27014293427627695 | validation: 0.2125290933782221]
	TIME [epoch: 47.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25731037469448753		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.25731037469448753 | validation: 0.2291763561145264]
	TIME [epoch: 47.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548999626511195		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.2548999626511195 | validation: 0.20583741898424118]
	TIME [epoch: 47.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24728653357799768		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.24728653357799768 | validation: 0.21184246819460367]
	TIME [epoch: 47.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595247595338119		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2595247595338119 | validation: 0.2151847771950554]
	TIME [epoch: 47.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26228507654395333		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.26228507654395333 | validation: 0.206837997420506]
	TIME [epoch: 47.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704582572242597		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2704582572242597 | validation: 0.22194777909222863]
	TIME [epoch: 47.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541512822093275		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2541512822093275 | validation: 0.2059718104552478]
	TIME [epoch: 47.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591566736059157		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2591566736059157 | validation: 0.21172704128252864]
	TIME [epoch: 47.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25623116071871704		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25623116071871704 | validation: 0.21998674066087057]
	TIME [epoch: 47.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559325325196616		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2559325325196616 | validation: 0.21703972433150048]
	TIME [epoch: 47.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27156645618807346		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.27156645618807346 | validation: 0.23189514639978803]
	TIME [epoch: 47.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25712967093466527		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.25712967093466527 | validation: 0.21184376902100457]
	TIME [epoch: 47.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653312611052522		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2653312611052522 | validation: 0.22575289517604497]
	TIME [epoch: 47.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25934412290393377		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25934412290393377 | validation: 0.2187832406155731]
	TIME [epoch: 47.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25761254298433217		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.25761254298433217 | validation: 0.21844523449740963]
	TIME [epoch: 47.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518555438696775		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2518555438696775 | validation: 0.22189596228249986]
	TIME [epoch: 47.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25638285903706964		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.25638285903706964 | validation: 0.21910109072901815]
	TIME [epoch: 47.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25756824421742486		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.25756824421742486 | validation: 0.2259725217754794]
	TIME [epoch: 47.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26693215983070595		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.26693215983070595 | validation: 0.229356739139034]
	TIME [epoch: 47.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547247646822768		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.2547247646822768 | validation: 0.21895813761878008]
	TIME [epoch: 47.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26012470203752924		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.26012470203752924 | validation: 0.22293776958000522]
	TIME [epoch: 47.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546134449498078		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2546134449498078 | validation: 0.1994309994544349]
	TIME [epoch: 47.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23272867435864955		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.23272867435864955 | validation: 0.22459376335705553]
	TIME [epoch: 47.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27644940917307875		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.27644940917307875 | validation: 0.21603000574994882]
	TIME [epoch: 47.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24722002300886933		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.24722002300886933 | validation: 0.20862963472456078]
	TIME [epoch: 47.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584671423756492		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2584671423756492 | validation: 0.21585456200612926]
	TIME [epoch: 47.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716966292642137		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2716966292642137 | validation: 0.2115142136532257]
	TIME [epoch: 47.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586384880773785		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2586384880773785 | validation: 0.21059098323588338]
	TIME [epoch: 47.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589419163072357		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2589419163072357 | validation: 0.22863177473989907]
	TIME [epoch: 47.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26298366520336075		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.26298366520336075 | validation: 0.2099252902297942]
	TIME [epoch: 47.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26954843677178636		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.26954843677178636 | validation: 0.1933326896505571]
	TIME [epoch: 47.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26237157239172365		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.26237157239172365 | validation: 0.22348007203785678]
	TIME [epoch: 47.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638482941329296		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2638482941329296 | validation: 0.21523938825817765]
	TIME [epoch: 47.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590376507252972		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2590376507252972 | validation: 0.21808920532262688]
	TIME [epoch: 47.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25761735932047014		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.25761735932047014 | validation: 0.20957917705972595]
	TIME [epoch: 47.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566680689129473		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.2566680689129473 | validation: 0.20578256707496534]
	TIME [epoch: 47.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25649365128350526		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.25649365128350526 | validation: 0.21914224675763064]
	TIME [epoch: 47.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496089802197646		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.2496089802197646 | validation: 0.21536845966052556]
	TIME [epoch: 47.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509474029237225		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2509474029237225 | validation: 0.21289166362212059]
	TIME [epoch: 47.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661669772889846		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.2661669772889846 | validation: 0.21426076167649052]
	TIME [epoch: 47.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26379007534380267		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.26379007534380267 | validation: 0.21992232939555012]
	TIME [epoch: 47.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503258843523081		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2503258843523081 | validation: 0.20870079122554913]
	TIME [epoch: 47.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24223786495645158		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.24223786495645158 | validation: 0.22094531093209419]
	TIME [epoch: 47.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26014878071303477		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.26014878071303477 | validation: 0.2170973204473717]
	TIME [epoch: 47.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25912365878375593		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25912365878375593 | validation: 0.21773989589285775]
	TIME [epoch: 47.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611503327975971		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2611503327975971 | validation: 0.20671220457592598]
	TIME [epoch: 47.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528409274722179		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2528409274722179 | validation: 0.21215182802619398]
	TIME [epoch: 47.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667984757439219		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2667984757439219 | validation: 0.20891039000478093]
	TIME [epoch: 47.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24720766528822624		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.24720766528822624 | validation: 0.21295105747042498]
	TIME [epoch: 47.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555385095990903		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2555385095990903 | validation: 0.21836266860995499]
	TIME [epoch: 47.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2730010252573946		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.2730010252573946 | validation: 0.21846735217538163]
	TIME [epoch: 47.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539324871676415		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2539324871676415 | validation: 0.20007150202697285]
	TIME [epoch: 47.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26219650823413815		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.26219650823413815 | validation: 0.23043291899986124]
	TIME [epoch: 47.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420771878666074		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2420771878666074 | validation: 0.22372709261916773]
	TIME [epoch: 47.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664824385430327		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2664824385430327 | validation: 0.20611606749071854]
	TIME [epoch: 47.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259557447045774		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.259557447045774 | validation: 0.2091845433848052]
	TIME [epoch: 47.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592748317926844		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.2592748317926844 | validation: 0.20595628141436487]
	TIME [epoch: 47.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24024365408540407		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.24024365408540407 | validation: 0.20462583139570817]
	TIME [epoch: 47.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518334574789973		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2518334574789973 | validation: 0.21817932898060302]
	TIME [epoch: 47.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590739344898234		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2590739344898234 | validation: 0.22488612825842189]
	TIME [epoch: 47.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25095020294745646		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.25095020294745646 | validation: 0.22210010013368836]
	TIME [epoch: 47.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24981306586227725		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.24981306586227725 | validation: 0.21991611627972643]
	TIME [epoch: 47.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24960478890458238		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.24960478890458238 | validation: 0.22108306612210943]
	TIME [epoch: 47.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26298975017694354		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.26298975017694354 | validation: 0.21343609883581274]
	TIME [epoch: 47.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24985627895619214		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.24985627895619214 | validation: 0.21157999768292787]
	TIME [epoch: 47.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535482049254569		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2535482049254569 | validation: 0.21651337334863743]
	TIME [epoch: 47.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579788925632127		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2579788925632127 | validation: 0.22267296617510643]
	TIME [epoch: 47.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26880218801872796		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.26880218801872796 | validation: 0.21467259930706115]
	TIME [epoch: 47.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606033209650744		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.2606033209650744 | validation: 0.22254529961285235]
	TIME [epoch: 47.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24025685010766784		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.24025685010766784 | validation: 0.21589920318530167]
	TIME [epoch: 47.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583892659473684		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2583892659473684 | validation: 0.2191059847679885]
	TIME [epoch: 47.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546869340845912		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2546869340845912 | validation: 0.20643438846613119]
	TIME [epoch: 47.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546872730056855		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2546872730056855 | validation: 0.1931129044759198]
	TIME [epoch: 114 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252930565913204		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.252930565913204 | validation: 0.23177124417409126]
	TIME [epoch: 98.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25945603824231966		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.25945603824231966 | validation: 0.2134573862604677]
	TIME [epoch: 98.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2706585709804905		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.2706585709804905 | validation: 0.21193338568852593]
	TIME [epoch: 98.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25907490581744325		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.25907490581744325 | validation: 0.22000044032757454]
	TIME [epoch: 98.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601002031319935		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.2601002031319935 | validation: 0.21965572807904277]
	TIME [epoch: 98.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25517985589863384		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.25517985589863384 | validation: 0.20793702300146383]
	TIME [epoch: 98.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24674716175979708		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24674716175979708 | validation: 0.21095994086661812]
	TIME [epoch: 98.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24936536825840996		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24936536825840996 | validation: 0.21612848901173715]
	TIME [epoch: 98.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251731793981611		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.251731793981611 | validation: 0.20819387802399345]
	TIME [epoch: 98.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25118520691784124		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.25118520691784124 | validation: 0.21475380358105034]
	TIME [epoch: 98.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24039841936845238		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.24039841936845238 | validation: 0.22133622987631982]
	TIME [epoch: 98.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253410396545199		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.253410396545199 | validation: 0.21851978191708116]
	TIME [epoch: 98.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24641319039753806		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.24641319039753806 | validation: 0.20451509336597778]
	TIME [epoch: 98.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25836048435580633		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.25836048435580633 | validation: 0.2173147745873198]
	TIME [epoch: 98.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456347873481746		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.24456347873481746 | validation: 0.21094216568778937]
	TIME [epoch: 98.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436156544792615		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.2436156544792615 | validation: 0.21664980954409976]
	TIME [epoch: 98.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255581102996746		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.255581102996746 | validation: 0.22150515457519174]
	TIME [epoch: 98.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535445314364486		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2535445314364486 | validation: 0.2166244550505672]
	TIME [epoch: 98.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576755831570603		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2576755831570603 | validation: 0.21310167866528307]
	TIME [epoch: 98.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623797025744779		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2623797025744779 | validation: 0.20279416009664314]
	TIME [epoch: 98.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25765983169144396		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25765983169144396 | validation: 0.21197800602089698]
	TIME [epoch: 98.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23814761627126946		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.23814761627126946 | validation: 0.2213995126487333]
	TIME [epoch: 98.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665361153021364		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2665361153021364 | validation: 0.21670697594035876]
	TIME [epoch: 98.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899377716537083		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.24899377716537083 | validation: 0.21142788151992287]
	TIME [epoch: 98.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521374037282933		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.2521374037282933 | validation: 0.200642497456177]
	TIME [epoch: 98.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25161163663884045		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.25161163663884045 | validation: 0.21161776319058964]
	TIME [epoch: 98.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607335951137017		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2607335951137017 | validation: 0.20768074970261088]
	TIME [epoch: 98.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25104111893935666		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.25104111893935666 | validation: 0.20338005232537068]
	TIME [epoch: 98.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505626634840382		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.2505626634840382 | validation: 0.21039353532207264]
	TIME [epoch: 98.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571688319793008		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2571688319793008 | validation: 0.2207142597959169]
	TIME [epoch: 98.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24728665940035413		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24728665940035413 | validation: 0.19966803203690345]
	TIME [epoch: 98.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735397350840413		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.24735397350840413 | validation: 0.21347084898922083]
	TIME [epoch: 98.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425267602252902		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2425267602252902 | validation: 0.2050662826401773]
	TIME [epoch: 98.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966961778010374		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.24966961778010374 | validation: 0.1947866069972307]
	TIME [epoch: 98.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25432824280000704		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.25432824280000704 | validation: 0.2129150584250262]
	TIME [epoch: 98.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677381245542783		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.2677381245542783 | validation: 0.22417151132077157]
	TIME [epoch: 98.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593340217576257		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.2593340217576257 | validation: 0.19558614329054963]
	TIME [epoch: 98.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26471823826513213		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.26471823826513213 | validation: 0.2082845746723903]
	TIME [epoch: 98.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580168951382563		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2580168951382563 | validation: 0.20469286093168862]
	TIME [epoch: 98.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24072404368115854		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24072404368115854 | validation: 0.21533944044719658]
	TIME [epoch: 98.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25811420347037745		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.25811420347037745 | validation: 0.2216251204195881]
	TIME [epoch: 98.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23753986757940418		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.23753986757940418 | validation: 0.20457523116217832]
	TIME [epoch: 98.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26321630092758225		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.26321630092758225 | validation: 0.22529011285093548]
	TIME [epoch: 98.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25653255313080814		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.25653255313080814 | validation: 0.2054751237513496]
	TIME [epoch: 98.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24337606609990134		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24337606609990134 | validation: 0.20471422477197257]
	TIME [epoch: 98.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429911646670567		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.2429911646670567 | validation: 0.20494121442091967]
	TIME [epoch: 98.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510549105098796		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2510549105098796 | validation: 0.2020990115791222]
	TIME [epoch: 98.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25713258454399446		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.25713258454399446 | validation: 0.2162210195824851]
	TIME [epoch: 98.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25160869611947506		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.25160869611947506 | validation: 0.21231066667742504]
	TIME [epoch: 98.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25867913471124454		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.25867913471124454 | validation: 0.2134747810634094]
	TIME [epoch: 98.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502036633949855		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2502036633949855 | validation: 0.19985472047652572]
	TIME [epoch: 98.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2609331655297162		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.2609331655297162 | validation: 0.21286815229595035]
	TIME [epoch: 98.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25932522536575753		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.25932522536575753 | validation: 0.21277458150987633]
	TIME [epoch: 98.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510633245358619		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2510633245358619 | validation: 0.2129426037232188]
	TIME [epoch: 98.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25410979729172833		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.25410979729172833 | validation: 0.21691384236451072]
	TIME [epoch: 98.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966134534404225		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.24966134534404225 | validation: 0.20037974060769503]
	TIME [epoch: 98.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460273668644025		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2460273668644025 | validation: 0.21111553161318614]
	TIME [epoch: 98.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636996636735909		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2636996636735909 | validation: 0.22286343132754488]
	TIME [epoch: 98.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543033855626648		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.2543033855626648 | validation: 0.20270859552646062]
	TIME [epoch: 98.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479880391920747		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.2479880391920747 | validation: 0.2164677905536399]
	TIME [epoch: 98.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549217143108215		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.2549217143108215 | validation: 0.2176132098410824]
	TIME [epoch: 98.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251635249108789		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.251635249108789 | validation: 0.2139854316559245]
	TIME [epoch: 98.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249467110215284		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.249467110215284 | validation: 0.21230403149489732]
	TIME [epoch: 98.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24447770396170732		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24447770396170732 | validation: 0.21310234886686988]
	TIME [epoch: 99 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2499287010293799		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2499287010293799 | validation: 0.21221439289283076]
	TIME [epoch: 98.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526136536836938		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.2526136536836938 | validation: 0.21349640682639165]
	TIME [epoch: 98.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24870677818568732		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.24870677818568732 | validation: 0.20735587545971496]
	TIME [epoch: 98.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25264189044029345		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.25264189044029345 | validation: 0.2118713974838276]
	TIME [epoch: 98.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479148454197949		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2479148454197949 | validation: 0.19177206156032406]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26223084353660053		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.26223084353660053 | validation: 0.2000787104971236]
	TIME [epoch: 99.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524020433024602		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2524020433024602 | validation: 0.2044808048813481]
	TIME [epoch: 99.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25440614607479034		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.25440614607479034 | validation: 0.2086347675226868]
	TIME [epoch: 99.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26161111685442606		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.26161111685442606 | validation: 0.21422932513469814]
	TIME [epoch: 99.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24448673560845133		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24448673560845133 | validation: 0.21234483520942032]
	TIME [epoch: 99.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.22620770995044392		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.22620770995044392 | validation: 0.20880693903596423]
	TIME [epoch: 98.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560850035532599		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2560850035532599 | validation: 0.21617653750906313]
	TIME [epoch: 99 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24957377392070426		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24957377392070426 | validation: 0.21386533856377068]
	TIME [epoch: 99.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25527658276622217		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.25527658276622217 | validation: 0.20664481445037586]
	TIME [epoch: 99 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413506025033183		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.2413506025033183 | validation: 0.21537030569904872]
	TIME [epoch: 99 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557868220832825		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2557868220832825 | validation: 0.21177756975185424]
	TIME [epoch: 99.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601071228531642		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2601071228531642 | validation: 0.20722109229109384]
	TIME [epoch: 99.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619011930582424		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2619011930582424 | validation: 0.21144492554236902]
	TIME [epoch: 99 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652084505942142		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.2652084505942142 | validation: 0.21001595610327128]
	TIME [epoch: 99.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962328493439254		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24962328493439254 | validation: 0.212633463709094]
	TIME [epoch: 99.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24666438630207263		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.24666438630207263 | validation: 0.21742177461781603]
	TIME [epoch: 99.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485610290060135		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2485610290060135 | validation: 0.2205969266463022]
	TIME [epoch: 99 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25376252622647727		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.25376252622647727 | validation: 0.22024714266958748]
	TIME [epoch: 99.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449279977727341		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.2449279977727341 | validation: 0.2017737187000909]
	TIME [epoch: 99.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688889420474328		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.2688889420474328 | validation: 0.20362650982262812]
	TIME [epoch: 99.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24072301447286407		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24072301447286407 | validation: 0.21836362960090422]
	TIME [epoch: 99.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25806945574218965		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.25806945574218965 | validation: 0.209777494621255]
	TIME [epoch: 99.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456280305163807		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.2456280305163807 | validation: 0.2133627971319647]
	TIME [epoch: 99.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591694990341296		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2591694990341296 | validation: 0.21487172348654093]
	TIME [epoch: 99.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2367348345202287		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.2367348345202287 | validation: 0.21359991278139692]
	TIME [epoch: 99 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592818096746008		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.2592818096746008 | validation: 0.20181281308799157]
	TIME [epoch: 99 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24488381981263296		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.24488381981263296 | validation: 0.2087093083910269]
	TIME [epoch: 99 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525706932785241		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2525706932785241 | validation: 0.21414328588444526]
	TIME [epoch: 99.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758140134208692		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.24758140134208692 | validation: 0.2091197690549879]
	TIME [epoch: 98.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782809770486616		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.24782809770486616 | validation: 0.20981616152052368]
	TIME [epoch: 99.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585254008761479		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.2585254008761479 | validation: 0.2141406824059437]
	TIME [epoch: 99.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24878962862966425		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24878962862966425 | validation: 0.20868788093628177]
	TIME [epoch: 99.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25085976120366626		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.25085976120366626 | validation: 0.2118905559782795]
	TIME [epoch: 99.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25347875144026055		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.25347875144026055 | validation: 0.20393505851853058]
	TIME [epoch: 99.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505378194471179		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.2505378194471179 | validation: 0.21617812492473845]
	TIME [epoch: 99.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423003409754284		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.2423003409754284 | validation: 0.21561799920586933]
	TIME [epoch: 99.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24878257231603107		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.24878257231603107 | validation: 0.2127834831091145]
	TIME [epoch: 99.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582837179438979		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.2582837179438979 | validation: 0.21731685965052008]
	TIME [epoch: 99.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534530394754195		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2534530394754195 | validation: 0.21532592931440994]
	TIME [epoch: 99.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503777769550304		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.2503777769550304 | validation: 0.21493329129982777]
	TIME [epoch: 99.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500671899301891		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2500671899301891 | validation: 0.22112921917786715]
	TIME [epoch: 99.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572516372111787		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.2572516372111787 | validation: 0.2088293634802915]
	TIME [epoch: 99.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508159582206845		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2508159582206845 | validation: 0.20369555586648733]
	TIME [epoch: 99.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24850516657295185		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24850516657295185 | validation: 0.20810258102364335]
	TIME [epoch: 99.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24018257942291277		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.24018257942291277 | validation: 0.20926037216604385]
	TIME [epoch: 99.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25730290347775053		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.25730290347775053 | validation: 0.20921859132114795]
	TIME [epoch: 99.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25000126100453995		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.25000126100453995 | validation: 0.21307113703551508]
	TIME [epoch: 99.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24102021484038957		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24102021484038957 | validation: 0.19323371811158385]
	TIME [epoch: 99.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25968157627629407		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.25968157627629407 | validation: 0.21444538248971884]
	TIME [epoch: 99.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23513083286603265		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.23513083286603265 | validation: 0.2133777276949534]
	TIME [epoch: 99.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541179697493614		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.2541179697493614 | validation: 0.20665534132439478]
	TIME [epoch: 99.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25320510226244597		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.25320510226244597 | validation: 0.20934920907564072]
	TIME [epoch: 99.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25020751194569724		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.25020751194569724 | validation: 0.2129136385892058]
	TIME [epoch: 99.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24455907036422928		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24455907036422928 | validation: 0.19453486758330424]
	TIME [epoch: 99.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25637063409196287		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.25637063409196287 | validation: 0.21285987227549347]
	TIME [epoch: 99.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254114351203865		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.254114351203865 | validation: 0.23342018591484712]
	TIME [epoch: 99.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26197113221612134		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.26197113221612134 | validation: 0.22062336654970185]
	TIME [epoch: 99.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25588819040536265		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.25588819040536265 | validation: 0.2101085707310487]
	TIME [epoch: 99 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646260458015337		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.2646260458015337 | validation: 0.2088131725982037]
	TIME [epoch: 99.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25724504741151466		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.25724504741151466 | validation: 0.20684220807048112]
	TIME [epoch: 99.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256762365728338		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.256762365728338 | validation: 0.21108958287604626]
	TIME [epoch: 99.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413434931304802		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2413434931304802 | validation: 0.21641469933364127]
	TIME [epoch: 99.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25688265951254613		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.25688265951254613 | validation: 0.20642916268498396]
	TIME [epoch: 99.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24110652226463547		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24110652226463547 | validation: 0.22177905693366212]
	TIME [epoch: 99.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536219492443017		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2536219492443017 | validation: 0.19713715286230288]
	TIME [epoch: 99.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25211364899503275		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.25211364899503275 | validation: 0.21872233910718847]
	TIME [epoch: 99.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613943543082385		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2613943543082385 | validation: 0.22896834829248638]
	TIME [epoch: 99 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25102099063365396		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.25102099063365396 | validation: 0.20879484818825644]
	TIME [epoch: 99.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25447045906113486		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.25447045906113486 | validation: 0.2114429437168389]
	TIME [epoch: 99.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24634855126658625		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24634855126658625 | validation: 0.1968417373409461]
	TIME [epoch: 98.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239307644046989		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.239307644046989 | validation: 0.19702067115451644]
	TIME [epoch: 99.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567342837840829		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.2567342837840829 | validation: 0.21063096476334967]
	TIME [epoch: 99.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459949029794803		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.24459949029794803 | validation: 0.21551649235715775]
	TIME [epoch: 99 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24488773051917948		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24488773051917948 | validation: 0.20454673034335236]
	TIME [epoch: 99.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24971468010760242		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24971468010760242 | validation: 0.20914827139190986]
	TIME [epoch: 99.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655449851682856		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.24655449851682856 | validation: 0.20184933013549014]
	TIME [epoch: 99 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407186498784332		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.2407186498784332 | validation: 0.20887196384540002]
	TIME [epoch: 99 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23726212503359156		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.23726212503359156 | validation: 0.21675356456632366]
	TIME [epoch: 99.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25903190167130136		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.25903190167130136 | validation: 0.20202122193726701]
	TIME [epoch: 99.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24039493575211932		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.24039493575211932 | validation: 0.20108928195361822]
	TIME [epoch: 99.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25027066000517456		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.25027066000517456 | validation: 0.21658024269037326]
	TIME [epoch: 99.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534016342763245		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.2534016342763245 | validation: 0.20531048197231344]
	TIME [epoch: 99 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2430471908840026		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.2430471908840026 | validation: 0.20171143577156583]
	TIME [epoch: 98.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251989336877083		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.251989336877083 | validation: 0.2061294654678778]
	TIME [epoch: 99.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533777607287649		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2533777607287649 | validation: 0.21270406796438057]
	TIME [epoch: 99 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543948412818145		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.2543948412818145 | validation: 0.2183880340711875]
	TIME [epoch: 99.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24352265778057358		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24352265778057358 | validation: 0.2072693400774647]
	TIME [epoch: 99 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496251026236799		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2496251026236799 | validation: 0.20856034109684712]
	TIME [epoch: 99 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708834375511454		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24708834375511454 | validation: 0.22220035687277956]
	TIME [epoch: 99.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25635408257919884		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.25635408257919884 | validation: 0.2109392512598129]
	TIME [epoch: 99 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24128345939381293		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24128345939381293 | validation: 0.2132054927014891]
	TIME [epoch: 99.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24551588182439565		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24551588182439565 | validation: 0.21086220119896276]
	TIME [epoch: 99 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475194980243756		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.24475194980243756 | validation: 0.21166423837451115]
	TIME [epoch: 99.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24987960722167635		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24987960722167635 | validation: 0.20647731583749587]
	TIME [epoch: 99.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521144949217034		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.2521144949217034 | validation: 0.20774563658952583]
	TIME [epoch: 99 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569927919442841		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.2569927919442841 | validation: 0.21609048451590787]
	TIME [epoch: 99.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24391589080704879		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24391589080704879 | validation: 0.22128728801719588]
	TIME [epoch: 99.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509418817509241		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.2509418817509241 | validation: 0.2071346012792903]
	TIME [epoch: 99 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24055274949071395		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24055274949071395 | validation: 0.21007906077532726]
	TIME [epoch: 99.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647968528219557		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.2647968528219557 | validation: 0.2145015820751266]
	TIME [epoch: 99 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25029094131110097		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.25029094131110097 | validation: 0.20223049103400287]
	TIME [epoch: 99 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435846866560115		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.2435846866560115 | validation: 0.20885058862088973]
	TIME [epoch: 98.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421423778380929		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2421423778380929 | validation: 0.19495020842817615]
	TIME [epoch: 99.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25605685185037885		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.25605685185037885 | validation: 0.21685555487521277]
	TIME [epoch: 98.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506501095702695		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.2506501095702695 | validation: 0.20573086160051018]
	TIME [epoch: 99.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400563640787298		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2400563640787298 | validation: 0.20142702932353568]
	TIME [epoch: 99 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24448015812431934		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24448015812431934 | validation: 0.21182906318784203]
	TIME [epoch: 99.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24789407781069406		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24789407781069406 | validation: 0.19378927608680074]
	TIME [epoch: 99.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523636152422036		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.2523636152422036 | validation: 0.20104686221538098]
	TIME [epoch: 99.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2361071738791347		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.2361071738791347 | validation: 0.20816210467417737]
	TIME [epoch: 99.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24077211844567012		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24077211844567012 | validation: 0.20164911054343015]
	TIME [epoch: 99.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24101383999476733		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24101383999476733 | validation: 0.21346889908617928]
	TIME [epoch: 99.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573349605584496		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.2573349605584496 | validation: 0.201513820005028]
	TIME [epoch: 99.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24602559060755366		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.24602559060755366 | validation: 0.2036142387875061]
	TIME [epoch: 99.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24906646377569377		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24906646377569377 | validation: 0.21893717018341893]
	TIME [epoch: 99.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24587901933185585		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24587901933185585 | validation: 0.2050455394996465]
	TIME [epoch: 99.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24593263427083176		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24593263427083176 | validation: 0.20394938556374717]
	TIME [epoch: 99.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25575119125600515		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.25575119125600515 | validation: 0.22238177588220304]
	TIME [epoch: 99 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513706352764368		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.2513706352764368 | validation: 0.21060178284241057]
	TIME [epoch: 99.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468637423638426		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.2468637423638426 | validation: 0.22022733774173053]
	TIME [epoch: 99.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498982806959568		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.2498982806959568 | validation: 0.20688603193023888]
	TIME [epoch: 99.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513122102014324		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.2513122102014324 | validation: 0.21457842007877187]
	TIME [epoch: 99.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24343495383382474		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24343495383382474 | validation: 0.2006017859909599]
	TIME [epoch: 99.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306695485176125		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24306695485176125 | validation: 0.2066141718952302]
	TIME [epoch: 99.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23494236620010978		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.23494236620010978 | validation: 0.20345641746721005]
	TIME [epoch: 99.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586225049999408		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24586225049999408 | validation: 0.19827066977057556]
	TIME [epoch: 99.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25300242135323464		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.25300242135323464 | validation: 0.19875120567170115]
	TIME [epoch: 99.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25000891476345133		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.25000891476345133 | validation: 0.20995195319286197]
	TIME [epoch: 99.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24326669812461965		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24326669812461965 | validation: 0.18942285177550183]
	TIME [epoch: 99.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v15b_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24817833700756234		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24817833700756234 | validation: 0.21046692024941155]
	TIME [epoch: 99.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776589568876597		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.24776589568876597 | validation: 0.20180900369056998]
	TIME [epoch: 99.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24174251854093268		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24174251854093268 | validation: 0.22268930228572872]
	TIME [epoch: 99.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25244358070675		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.25244358070675 | validation: 0.2009191959654253]
	TIME [epoch: 99.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24769416796238378		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24769416796238378 | validation: 0.2113379319352303]
	TIME [epoch: 99.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420762057193796		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2420762057193796 | validation: 0.21000428038209704]
	TIME [epoch: 99.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25514895555532907		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.25514895555532907 | validation: 0.2021459195140197]
	TIME [epoch: 99.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25336783422327697		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.25336783422327697 | validation: 0.20935096897229233]
	TIME [epoch: 99.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24032736034295674		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24032736034295674 | validation: 0.21314332138526754]
	TIME [epoch: 99.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345696951314477		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24345696951314477 | validation: 0.2135732193060349]
	TIME [epoch: 99.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472083216694522		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.2472083216694522 | validation: 0.21373190276196383]
	TIME [epoch: 99.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24828857822791364		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24828857822791364 | validation: 0.21037093559761963]
	TIME [epoch: 99.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24525898681505506		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24525898681505506 | validation: 0.2084793458939822]
	TIME [epoch: 99.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23170052533774457		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.23170052533774457 | validation: 0.19269924422272044]
	TIME [epoch: 99.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24314160564782705		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24314160564782705 | validation: 0.1974381807241545]
	TIME [epoch: 99 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443491229876703		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.2443491229876703 | validation: 0.20274375583141713]
	TIME [epoch: 99.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24909735388210183		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24909735388210183 | validation: 0.20459506318359028]
	TIME [epoch: 99.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797790333451306		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24797790333451306 | validation: 0.21316601896811935]
	TIME [epoch: 99.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25107396791765946		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.25107396791765946 | validation: 0.20662456242270544]
	TIME [epoch: 99.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23830363001176605		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.23830363001176605 | validation: 0.21239157062886244]
	TIME [epoch: 99.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25259797181700366		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.25259797181700366 | validation: 0.21295496310587952]
	TIME [epoch: 99.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26224784737144086		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.26224784737144086 | validation: 0.19723335544992435]
	TIME [epoch: 99.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558440483139564		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.2558440483139564 | validation: 0.2213605352271495]
	TIME [epoch: 99.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485875843317599		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.2485875843317599 | validation: 0.2137888280178827]
	TIME [epoch: 99.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569550102318991		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.2569550102318991 | validation: 0.21289238881102954]
	TIME [epoch: 99.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25194721827179223		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.25194721827179223 | validation: 0.19544664629121183]
	TIME [epoch: 99.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24892467967172194		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24892467967172194 | validation: 0.21737288012547845]
	TIME [epoch: 99.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413574421917766		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.2413574421917766 | validation: 0.21447725298215783]
	TIME [epoch: 99.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24818643091990275		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24818643091990275 | validation: 0.21528522669102088]
	TIME [epoch: 99.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24849870735390858		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24849870735390858 | validation: 0.22069108321971304]
	TIME [epoch: 99.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24805285488954976		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.24805285488954976 | validation: 0.20163735927517173]
	TIME [epoch: 99.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24903779812817928		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.24903779812817928 | validation: 0.2096850239053505]
	TIME [epoch: 99.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24369245650993385		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.24369245650993385 | validation: 0.21922901518027685]
	TIME [epoch: 99.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24650313671569515		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24650313671569515 | validation: 0.20766140400011537]
	TIME [epoch: 99.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539776777103708		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.2539776777103708 | validation: 0.1940413583790907]
	TIME [epoch: 99.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24654236591335846		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.24654236591335846 | validation: 0.21091617698792206]
	TIME [epoch: 99.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.235866957291767		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.235866957291767 | validation: 0.21441608640735335]
	TIME [epoch: 99.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250906907852671		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.250906907852671 | validation: 0.20578122978926033]
	TIME [epoch: 99.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26335824508830236		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.26335824508830236 | validation: 0.21587520155271642]
	TIME [epoch: 99.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491045338630767		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.2491045338630767 | validation: 0.2035920810360902]
	TIME [epoch: 99.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585834459802078		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.2585834459802078 | validation: 0.2087697473881252]
	TIME [epoch: 99.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24923867384990306		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.24923867384990306 | validation: 0.20346081014306683]
	TIME [epoch: 99.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449541733560963		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2449541733560963 | validation: 0.21996537267245656]
	TIME [epoch: 99.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545335671537563		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.24545335671537563 | validation: 0.2088038851445698]
	TIME [epoch: 99.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24098686215115364		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24098686215115364 | validation: 0.207235620376604]
	TIME [epoch: 99.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23973647648258123		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.23973647648258123 | validation: 0.21062563966189227]
	TIME [epoch: 99.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526822885835386		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.2526822885835386 | validation: 0.21144681000289084]
	TIME [epoch: 99.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24844976851182032		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.24844976851182032 | validation: 0.21520856967372853]
	TIME [epoch: 99.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24740204693548104		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24740204693548104 | validation: 0.2049878607511116]
	TIME [epoch: 99.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506811491293163		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.2506811491293163 | validation: 0.1924562619503974]
	TIME [epoch: 99.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24186653997532692		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.24186653997532692 | validation: 0.21066941884646395]
	TIME [epoch: 99.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24114323450616867		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.24114323450616867 | validation: 0.20837229307947353]
	TIME [epoch: 99.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24125141939488623		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.24125141939488623 | validation: 0.22175220693064362]
	TIME [epoch: 99.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24914939820165402		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.24914939820165402 | validation: 0.2170734474560488]
	TIME [epoch: 99.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399531723283124		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2399531723283124 | validation: 0.21567137378498175]
	TIME [epoch: 99 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616022177104462		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.2616022177104462 | validation: 0.2136522096568673]
	TIME [epoch: 99.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572313234115757		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.2572313234115757 | validation: 0.20406131980741282]
	TIME [epoch: 99.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23988709113629314		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.23988709113629314 | validation: 0.20578567826047905]
	TIME [epoch: 99.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25174183920311416		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.25174183920311416 | validation: 0.21806736308611313]
	TIME [epoch: 99.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23876514950906966		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.23876514950906966 | validation: 0.1999657256110326]
	TIME [epoch: 99.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517175234813335		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.2517175234813335 | validation: 0.21178473974236942]
	TIME [epoch: 99.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25435955563721074		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.25435955563721074 | validation: 0.2146416070066821]
	TIME [epoch: 99.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479905583141476		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.2479905583141476 | validation: 0.21222182489255892]
	TIME [epoch: 99.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247479102843727		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.247479102843727 | validation: 0.21240568031470736]
	TIME [epoch: 99.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448554130609999		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.2448554130609999 | validation: 0.2092675776899938]
	TIME [epoch: 99.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25402223395000456		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.25402223395000456 | validation: 0.21515326363736786]
	TIME [epoch: 99.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23976146143657243		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.23976146143657243 | validation: 0.20246672968820917]
	TIME [epoch: 99.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544528348963678		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.2544528348963678 | validation: 0.20564686229805243]
	TIME [epoch: 99.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25005135038874654		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.25005135038874654 | validation: 0.2084506241712729]
	TIME [epoch: 99.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656491949361223		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24656491949361223 | validation: 0.20316258068303883]
	TIME [epoch: 99.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25258641725255965		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.25258641725255965 | validation: 0.2083651169084768]
	TIME [epoch: 99.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25028952696945245		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.25028952696945245 | validation: 0.2047743361776869]
	TIME [epoch: 99.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440057963117738		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.2440057963117738 | validation: 0.22525724346121656]
	TIME [epoch: 99.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24591703328645784		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.24591703328645784 | validation: 0.20036742034863536]
	TIME [epoch: 99.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24458337754754866		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24458337754754866 | validation: 0.22073128893486538]
	TIME [epoch: 99.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23966806175043268		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.23966806175043268 | validation: 0.21707034305678877]
	TIME [epoch: 99.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23645928366058847		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.23645928366058847 | validation: 0.2305556694217757]
	TIME [epoch: 99.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24932153550645145		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.24932153550645145 | validation: 0.21037698642765262]
	TIME [epoch: 99.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24869049604042692		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24869049604042692 | validation: 0.20878592212043445]
	TIME [epoch: 99 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433497090370308		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.2433497090370308 | validation: 0.21161748102941988]
	TIME [epoch: 99.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25100796670864167		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.25100796670864167 | validation: 0.20994364337468668]
	TIME [epoch: 99.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24629938074989757		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24629938074989757 | validation: 0.20565925107478286]
	TIME [epoch: 99.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24297374501583002		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24297374501583002 | validation: 0.2128433685406681]
	TIME [epoch: 99.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23904742939790416		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.23904742939790416 | validation: 0.2125284428938276]
	TIME [epoch: 99.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25475855696228294		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.25475855696228294 | validation: 0.21073800001770823]
	TIME [epoch: 99.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2345583282353135		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.2345583282353135 | validation: 0.21164375847190872]
	TIME [epoch: 99.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404903817776366		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.2404903817776366 | validation: 0.20766965560839643]
	TIME [epoch: 99.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24716398802703834		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.24716398802703834 | validation: 0.2189324089559707]
	TIME [epoch: 99.1 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526557718344226		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.2526557718344226 | validation: 0.2041517969949913]
	TIME [epoch: 99.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23982287881752742		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.23982287881752742 | validation: 0.21582551340489114]
	TIME [epoch: 99.1 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24110313220200041		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.24110313220200041 | validation: 0.21445584744362717]
	TIME [epoch: 99.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510343809535223		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.2510343809535223 | validation: 0.20494373912179897]
	TIME [epoch: 99.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25047624662791995		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.25047624662791995 | validation: 0.20944701386653297]
	TIME [epoch: 99.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2359798644473907		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.2359798644473907 | validation: 0.21324967551164206]
	TIME [epoch: 99.1 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2355692951364057		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.2355692951364057 | validation: 0.2112023108375963]
	TIME [epoch: 99.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23841168626115575		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.23841168626115575 | validation: 0.2162754120609293]
	TIME [epoch: 99.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24070957989085118		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.24070957989085118 | validation: 0.21100164024076734]
	TIME [epoch: 99.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23831784814469878		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.23831784814469878 | validation: 0.21430045862653274]
	TIME [epoch: 99.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24809691507107204		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.24809691507107204 | validation: 0.22224549383070272]
	TIME [epoch: 99.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24898347674513097		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.24898347674513097 | validation: 0.2110086249073948]
	TIME [epoch: 99.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511060906551568		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.2511060906551568 | validation: 0.19710818696106316]
	TIME [epoch: 99.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244746623646688		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.244746623646688 | validation: 0.2029029223987709]
	TIME [epoch: 99.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436463927195942		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2436463927195942 | validation: 0.21824578387385613]
	TIME [epoch: 99.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24577643245584158		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24577643245584158 | validation: 0.20377276412230638]
	TIME [epoch: 99.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462788418162343		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.2462788418162343 | validation: 0.20407841095428675]
	TIME [epoch: 99.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24237030944572305		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24237030944572305 | validation: 0.20920708161859186]
	TIME [epoch: 99.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469620752022482		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.2469620752022482 | validation: 0.21301501907665515]
	TIME [epoch: 99.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23649461760089782		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.23649461760089782 | validation: 0.21067889743144746]
	TIME [epoch: 99.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436468689993501		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.2436468689993501 | validation: 0.2054965083515155]
	TIME [epoch: 99.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454939067815877		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.2454939067815877 | validation: 0.20066687651386964]
	TIME [epoch: 99.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23806628751008097		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.23806628751008097 | validation: 0.20787535809682045]
	TIME [epoch: 99.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656287562549564		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24656287562549564 | validation: 0.2136393098064296]
	TIME [epoch: 99.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25206163982302576		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.25206163982302576 | validation: 0.21182931514964848]
	TIME [epoch: 99.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492223091552078		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.2492223091552078 | validation: 0.22119790056718305]
	TIME [epoch: 99.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25223914111556084		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.25223914111556084 | validation: 0.21590848482315983]
	TIME [epoch: 99.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23578813630547504		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.23578813630547504 | validation: 0.2112111548816727]
	TIME [epoch: 99.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26454473303671994		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.26454473303671994 | validation: 0.21451724807468392]
	TIME [epoch: 99.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429330007803648		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2429330007803648 | validation: 0.21331255529695578]
	TIME [epoch: 99 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442461596383232		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.2442461596383232 | validation: 0.1983881986311852]
	TIME [epoch: 99.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24379229349578102		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.24379229349578102 | validation: 0.1973242718907907]
	TIME [epoch: 99.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24652705195243432		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.24652705195243432 | validation: 0.20067425825063956]
	TIME [epoch: 99.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399586674333768		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.2399586674333768 | validation: 0.21189660199396232]
	TIME [epoch: 99.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25344126959895813		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.25344126959895813 | validation: 0.2125946005645034]
	TIME [epoch: 99.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542427671451746		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.2542427671451746 | validation: 0.21726119379239126]
	TIME [epoch: 99.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669015630674096		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.24669015630674096 | validation: 0.22219860019197216]
	TIME [epoch: 99.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452849783748202		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.2452849783748202 | validation: 0.21333865313623757]
	TIME [epoch: 99.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432560932416202		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.2432560932416202 | validation: 0.2115480085424169]
	TIME [epoch: 99.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24315651810755748		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.24315651810755748 | validation: 0.20897366262518666]
	TIME [epoch: 99.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24852770113833497		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.24852770113833497 | validation: 0.21451356545902386]
	TIME [epoch: 99.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24779008312390624		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24779008312390624 | validation: 0.20878708630324372]
	TIME [epoch: 99.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24898286679531922		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.24898286679531922 | validation: 0.20748852400697296]
	TIME [epoch: 99.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2301550408668431		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.2301550408668431 | validation: 0.20508761763626615]
	TIME [epoch: 99.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24889253365324096		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24889253365324096 | validation: 0.2076734770062977]
	TIME [epoch: 99.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24672530581366428		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.24672530581366428 | validation: 0.21387603163034438]
	TIME [epoch: 98.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893187232434508		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.24893187232434508 | validation: 0.21669393386377928]
	TIME [epoch: 99.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424762341623137		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.2424762341623137 | validation: 0.20454036754103105]
	TIME [epoch: 99.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431688337082297		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.2431688337082297 | validation: 0.21600972471980867]
	TIME [epoch: 99.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797909056361098		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.24797909056361098 | validation: 0.2049452710762651]
	TIME [epoch: 99.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24082954835361248		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.24082954835361248 | validation: 0.20680132353105535]
	TIME [epoch: 99.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463958809563824		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.24463958809563824 | validation: 0.20614073138770667]
	TIME [epoch: 99.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2355362679678834		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.2355362679678834 | validation: 0.21179803252993484]
	TIME [epoch: 99.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24952680707145844		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24952680707145844 | validation: 0.19904991275689737]
	TIME [epoch: 99 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2335745622117047		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.2335745622117047 | validation: 0.21925915081843028]
	TIME [epoch: 99.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497734222277274		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.2497734222277274 | validation: 0.21517919230871652]
	TIME [epoch: 99.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24372706086587123		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24372706086587123 | validation: 0.2158659893496646]
	TIME [epoch: 99.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451821805535223		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.24451821805535223 | validation: 0.21137666226767907]
	TIME [epoch: 99.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24008483423763485		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.24008483423763485 | validation: 0.21321340557749605]
	TIME [epoch: 99.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508159327940324		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.2508159327940324 | validation: 0.19781756586685345]
	TIME [epoch: 99.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23652574341210378		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.23652574341210378 | validation: 0.21061397452898403]
	TIME [epoch: 99.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414638645832032		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.2414638645832032 | validation: 0.20980849812119667]
	TIME [epoch: 99.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25472208993437423		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.25472208993437423 | validation: 0.21814167230982823]
	TIME [epoch: 99.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25131883726716236		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.25131883726716236 | validation: 0.21562244951129786]
	TIME [epoch: 99.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485301489182534		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.24485301489182534 | validation: 0.20292651325142957]
	TIME [epoch: 99.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482401630926984		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.2482401630926984 | validation: 0.2123555622817376]
	TIME [epoch: 99 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2397896147541694		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.2397896147541694 | validation: 0.21345500403013667]
	TIME [epoch: 99.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24091151128793067		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.24091151128793067 | validation: 0.2207866529780098]
	TIME [epoch: 99 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445494831532967		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.2445494831532967 | validation: 0.20957952431961796]
	TIME [epoch: 99.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540368194770473		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.2540368194770473 | validation: 0.21197611187460338]
	TIME [epoch: 99.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24362312327952865		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.24362312327952865 | validation: 0.2051001899575184]
	TIME [epoch: 99.1 sec]
EPOCH 659/2000:
	Training over batches...
