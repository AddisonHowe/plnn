Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v13b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v13b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 190220771

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214761693088001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0214761693088001 | validation: 1.1121409013704018]
	TIME [epoch: 31.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8157643127390998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8157643127390998 | validation: 0.9651932814844324]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160566796552259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7160566796552259 | validation: 0.9349367441193042]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891740447272373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6891740447272373 | validation: 0.907954978541648]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517186384430889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6517186384430889 | validation: 0.8628226099388938]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315726573966811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6315726573966811 | validation: 0.7539487729144406]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.585517932209268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.585517932209268 | validation: 0.7329117513813614]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4708675689125036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4708675689125036 | validation: 0.6723850285904406]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45700332499084434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45700332499084434 | validation: 0.68703970822761]
	TIME [epoch: 4.48 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171707003604473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4171707003604473 | validation: 0.6292305089763044]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5256302876930898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5256302876930898 | validation: 0.6341630545830158]
	TIME [epoch: 4.49 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42523830102439564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42523830102439564 | validation: 0.6180152585988353]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46674155386817795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46674155386817795 | validation: 0.7545428658435345]
	TIME [epoch: 4.48 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41261806461565076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41261806461565076 | validation: 0.5409796706113318]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166040594584768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4166040594584768 | validation: 0.5340625054608201]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571250301283554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3571250301283554 | validation: 0.4817032620154149]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37440103481313636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37440103481313636 | validation: 0.49074645618267165]
	TIME [epoch: 4.49 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993105650681359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2993105650681359 | validation: 0.5251295272956373]
	TIME [epoch: 4.48 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31384447766373036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31384447766373036 | validation: 0.4440130053811378]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282781067168622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.282781067168622 | validation: 0.4299799239841116]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27721579787089073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27721579787089073 | validation: 0.5032928101234007]
	TIME [epoch: 4.48 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27082685794521216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27082685794521216 | validation: 0.48389031205076766]
	TIME [epoch: 4.49 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215977566784695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3215977566784695 | validation: 0.40906178283539785]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625441152291814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2625441152291814 | validation: 0.45753799241109006]
	TIME [epoch: 4.48 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119057744553508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3119057744553508 | validation: 0.4180126567255439]
	TIME [epoch: 4.48 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26513850023019003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26513850023019003 | validation: 0.4944562988036004]
	TIME [epoch: 4.48 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28491080148321934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28491080148321934 | validation: 0.41109516038761673]
	TIME [epoch: 4.47 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2239831447580252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2239831447580252 | validation: 0.44318560680125735]
	TIME [epoch: 4.47 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23234801588450638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23234801588450638 | validation: 0.40002741417932425]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525215943010243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2525215943010243 | validation: 0.40552214294919375]
	TIME [epoch: 4.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30248505848656965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30248505848656965 | validation: 0.3730594124496356]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24576739642732065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24576739642732065 | validation: 0.396100390987179]
	TIME [epoch: 4.48 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23946042084409386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23946042084409386 | validation: 0.4049025006487908]
	TIME [epoch: 4.47 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23015183819058097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23015183819058097 | validation: 0.5024197296707001]
	TIME [epoch: 4.47 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501561606323876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2501561606323876 | validation: 0.38334350959729824]
	TIME [epoch: 4.47 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24612544749632193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24612544749632193 | validation: 0.44324635989895733]
	TIME [epoch: 4.49 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25804613552607136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25804613552607136 | validation: 0.38665606902352784]
	TIME [epoch: 4.49 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23311808729835287		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.23311808729835287 | validation: 0.3666187134702193]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352657461027213		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2352657461027213 | validation: 0.36919644923214856]
	TIME [epoch: 4.48 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2200946726923914		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2200946726923914 | validation: 0.4004620442934842]
	TIME [epoch: 4.48 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26037016695677023		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.26037016695677023 | validation: 0.4071378662959335]
	TIME [epoch: 4.48 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359193798321116		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2359193798321116 | validation: 0.3900097183258654]
	TIME [epoch: 4.48 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23552770094351466		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.23552770094351466 | validation: 0.40272882253222353]
	TIME [epoch: 4.48 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22848920253682123		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.22848920253682123 | validation: 0.3644583870259737]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21388567264062655		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.21388567264062655 | validation: 0.4083140757108173]
	TIME [epoch: 4.49 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22732941646273203		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.22732941646273203 | validation: 0.4541670541471128]
	TIME [epoch: 4.48 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794615976730365		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2794615976730365 | validation: 0.39365499990104663]
	TIME [epoch: 4.47 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22047590281473048		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.22047590281473048 | validation: 0.42462406325552465]
	TIME [epoch: 4.47 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525504666261048		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.2525504666261048 | validation: 0.40844147393392793]
	TIME [epoch: 4.47 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2237321471643426		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2237321471643426 | validation: 0.4333514226601891]
	TIME [epoch: 4.48 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29498413965522613		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.29498413965522613 | validation: 0.5060998379136792]
	TIME [epoch: 33.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25568232698263804		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.25568232698263804 | validation: 0.4062344942624446]
	TIME [epoch: 8.63 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21573163235469917		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.21573163235469917 | validation: 0.3919804533687486]
	TIME [epoch: 8.63 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17739231323591415		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.17739231323591415 | validation: 0.35975110649935343]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20944962238826415		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.20944962238826415 | validation: 0.3749233583545586]
	TIME [epoch: 8.65 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23873753001661802		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.23873753001661802 | validation: 0.3764623955764081]
	TIME [epoch: 8.64 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19778318188253347		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.19778318188253347 | validation: 0.5005348726685057]
	TIME [epoch: 8.66 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24080932023512708		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.24080932023512708 | validation: 0.39917145820120925]
	TIME [epoch: 8.65 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23765286079898762		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.23765286079898762 | validation: 0.3426457945104784]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2062456431068325		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.2062456431068325 | validation: 0.35723513191070183]
	TIME [epoch: 8.62 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22083900206109794		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.22083900206109794 | validation: 0.3876568323781414]
	TIME [epoch: 8.62 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19774472110078933		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.19774472110078933 | validation: 0.36182256526131573]
	TIME [epoch: 8.63 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786027797479827		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.1786027797479827 | validation: 0.49032928715531765]
	TIME [epoch: 8.64 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430802735588385		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2430802735588385 | validation: 0.38966197402375646]
	TIME [epoch: 8.66 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20163461196843369		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.20163461196843369 | validation: 0.4771013369825834]
	TIME [epoch: 8.65 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19063442946121217		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.19063442946121217 | validation: 0.4184884879104765]
	TIME [epoch: 8.64 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058374081899871		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.2058374081899871 | validation: 0.5393026612015862]
	TIME [epoch: 8.62 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2447626604195306		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.2447626604195306 | validation: 0.35069108351158146]
	TIME [epoch: 8.63 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106156529410703		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.2106156529410703 | validation: 0.5351944674389235]
	TIME [epoch: 8.63 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21296485941160959		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.21296485941160959 | validation: 0.35852942328427273]
	TIME [epoch: 8.65 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16868948303240142		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.16868948303240142 | validation: 0.3163313134197174]
	TIME [epoch: 8.66 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21519568425984223		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.21519568425984223 | validation: 0.3093296505011198]
	TIME [epoch: 8.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19979750491111814		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.19979750491111814 | validation: 0.5143485412082419]
	TIME [epoch: 8.62 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958325571889553		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.1958325571889553 | validation: 0.45527891935427134]
	TIME [epoch: 8.63 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21749412476529867		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.21749412476529867 | validation: 0.3839918622886835]
	TIME [epoch: 8.61 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2013742733462601		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.2013742733462601 | validation: 0.3367838261564316]
	TIME [epoch: 8.61 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18744748601097036		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.18744748601097036 | validation: 0.31585044391589456]
	TIME [epoch: 8.62 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17000339267619471		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.17000339267619471 | validation: 0.37784442513688665]
	TIME [epoch: 8.63 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161271791714675		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.161271791714675 | validation: 0.40547570714730546]
	TIME [epoch: 8.62 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18297080494451745		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.18297080494451745 | validation: 0.30723313665397783]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18422622156878377		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.18422622156878377 | validation: 0.3037501257775744]
	TIME [epoch: 8.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18810469901356552		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.18810469901356552 | validation: 0.3215683529554695]
	TIME [epoch: 8.64 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18629958897952012		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.18629958897952012 | validation: 0.41120733057429454]
	TIME [epoch: 8.63 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965565615137943		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.1965565615137943 | validation: 0.46408906010539236]
	TIME [epoch: 8.63 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25594773460007303		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.25594773460007303 | validation: 0.3998155434261122]
	TIME [epoch: 8.64 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958194457377338		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1958194457377338 | validation: 0.42895989985674954]
	TIME [epoch: 8.64 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17466575306774781		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.17466575306774781 | validation: 0.30978240977077187]
	TIME [epoch: 8.64 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16721053265175792		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.16721053265175792 | validation: 0.36348719968862087]
	TIME [epoch: 8.62 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22107621089085952		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.22107621089085952 | validation: 0.3414156892280328]
	TIME [epoch: 8.63 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20731197862892475		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.20731197862892475 | validation: 0.32259571393801934]
	TIME [epoch: 8.64 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18847627044378676		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.18847627044378676 | validation: 0.4818134437510113]
	TIME [epoch: 8.63 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20999166873108976		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.20999166873108976 | validation: 0.35587702442591373]
	TIME [epoch: 8.63 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18503092689410278		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.18503092689410278 | validation: 0.3766679105805121]
	TIME [epoch: 8.63 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16226192070683926		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16226192070683926 | validation: 0.36034900810489806]
	TIME [epoch: 8.63 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18006610232407436		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.18006610232407436 | validation: 0.32708108969650435]
	TIME [epoch: 8.64 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21369919280598879		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.21369919280598879 | validation: 0.3398411597806258]
	TIME [epoch: 8.64 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18349532908048222		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.18349532908048222 | validation: 0.3240445859544356]
	TIME [epoch: 8.63 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972897862982383		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1972897862982383 | validation: 0.3922131695205045]
	TIME [epoch: 8.64 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610425988018941		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.1610425988018941 | validation: 0.37082957479741363]
	TIME [epoch: 8.64 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16342500225595172		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.16342500225595172 | validation: 0.47725844208571405]
	TIME [epoch: 8.63 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21616422509736		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.21616422509736 | validation: 0.31517670648393226]
	TIME [epoch: 43.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18768221848963457		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.18768221848963457 | validation: 0.4667081047707402]
	TIME [epoch: 18.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2480467856522786		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.2480467856522786 | validation: 0.5052749251488329]
	TIME [epoch: 18.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1893483331692896		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1893483331692896 | validation: 0.3180683096491875]
	TIME [epoch: 18.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18570355581971332		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.18570355581971332 | validation: 0.47657988117495714]
	TIME [epoch: 18.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18357025730415272		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18357025730415272 | validation: 0.3367250202535975]
	TIME [epoch: 18.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744365857051579		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.1744365857051579 | validation: 0.3196876242706143]
	TIME [epoch: 18.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17828013837299234		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.17828013837299234 | validation: 0.37266156062493133]
	TIME [epoch: 18.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17814917469397362		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.17814917469397362 | validation: 0.4010538303944092]
	TIME [epoch: 18.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20039089846321168		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.20039089846321168 | validation: 0.44469450447503783]
	TIME [epoch: 18.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19279957516107893		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19279957516107893 | validation: 0.5067680987445434]
	TIME [epoch: 18.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18268961617613988		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18268961617613988 | validation: 0.5241136791838261]
	TIME [epoch: 18.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17034950647086833		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.17034950647086833 | validation: 0.30063512516207974]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871297259990795		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.1871297259990795 | validation: 0.41559925395636016]
	TIME [epoch: 18.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084917087538573		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.20084917087538573 | validation: 0.32583838936735904]
	TIME [epoch: 18.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15913375201480343		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.15913375201480343 | validation: 0.33825113048941285]
	TIME [epoch: 18.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566025540093106		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.1566025540093106 | validation: 0.34414279908980494]
	TIME [epoch: 18.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16961810756746348		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.16961810756746348 | validation: 0.44663776703646774]
	TIME [epoch: 18.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18789004041576723		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.18789004041576723 | validation: 0.3377822538631064]
	TIME [epoch: 18.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19055895899417466		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.19055895899417466 | validation: 0.40722429757107104]
	TIME [epoch: 18.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18607284760648665		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.18607284760648665 | validation: 0.3156335877709755]
	TIME [epoch: 18.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14270200640860414		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.14270200640860414 | validation: 0.3364209726380009]
	TIME [epoch: 18.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454012885644188		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1454012885644188 | validation: 0.42120163575098507]
	TIME [epoch: 18.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18888002000621806		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.18888002000621806 | validation: 0.3608325145504063]
	TIME [epoch: 18.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18909193259706553		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.18909193259706553 | validation: 0.47275617622815125]
	TIME [epoch: 18.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19490780871192953		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19490780871192953 | validation: 0.3419261308408501]
	TIME [epoch: 18.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20348393503396534		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.20348393503396534 | validation: 0.3621276200692239]
	TIME [epoch: 18.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18082170356330013		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.18082170356330013 | validation: 0.40459201086002505]
	TIME [epoch: 18.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631466027551346		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.14631466027551346 | validation: 0.3229064206260271]
	TIME [epoch: 18.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20857086755150256		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.20857086755150256 | validation: 0.38086766128826893]
	TIME [epoch: 18.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847022295020385		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.15847022295020385 | validation: 0.33478743988193993]
	TIME [epoch: 18.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702308938305899		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.1702308938305899 | validation: 0.5496002691454629]
	TIME [epoch: 18.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20004503787935082		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.20004503787935082 | validation: 0.3849881203911134]
	TIME [epoch: 18.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14405031544078886		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.14405031544078886 | validation: 0.4062061013238935]
	TIME [epoch: 18.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585585391180023		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1585585391180023 | validation: 0.31263390062890467]
	TIME [epoch: 18.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257909324151967		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.13257909324151967 | validation: 0.42233997695921255]
	TIME [epoch: 18.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1930723061992637		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1930723061992637 | validation: 0.3899477442856741]
	TIME [epoch: 18.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17457181155325724		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.17457181155325724 | validation: 0.3166572377034482]
	TIME [epoch: 18.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603104990630266		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.1603104990630266 | validation: 0.35140006420905534]
	TIME [epoch: 18.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562330287361863		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1562330287361863 | validation: 0.32248368603247984]
	TIME [epoch: 18.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14532943920417676		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.14532943920417676 | validation: 0.4574833318714901]
	TIME [epoch: 18.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957256941323822		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.1957256941323822 | validation: 0.295052991204965]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13705630117851908		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.13705630117851908 | validation: 0.33884650092945157]
	TIME [epoch: 18.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17279703596718768		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.17279703596718768 | validation: 0.2964045000740272]
	TIME [epoch: 18.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440556074972544		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.1440556074972544 | validation: 0.4417240917943238]
	TIME [epoch: 18.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871389505924114		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.1871389505924114 | validation: 0.3016799590797433]
	TIME [epoch: 18.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14462260059300994		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.14462260059300994 | validation: 0.2994644314740034]
	TIME [epoch: 18.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582213595732859		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1582213595732859 | validation: 0.33255147947880626]
	TIME [epoch: 18.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15473701473185353		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.15473701473185353 | validation: 0.3070069779028055]
	TIME [epoch: 18.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560596759189022		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1560596759189022 | validation: 0.3007555662006792]
	TIME [epoch: 18.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14361279039750097		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14361279039750097 | validation: 0.317295655249179]
	TIME [epoch: 18.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17081261222889338		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.17081261222889338 | validation: 0.2889505872450102]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291366733125817		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.13291366733125817 | validation: 0.35615636015015195]
	TIME [epoch: 18.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17611294073885575		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.17611294073885575 | validation: 0.32966179281079083]
	TIME [epoch: 18.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16420601810057095		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.16420601810057095 | validation: 0.4306927375159944]
	TIME [epoch: 18.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16337284279023093		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.16337284279023093 | validation: 0.34658119068604704]
	TIME [epoch: 18.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18902570802391377		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.18902570802391377 | validation: 0.40673325849691583]
	TIME [epoch: 18.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16398245755837912		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.16398245755837912 | validation: 0.3428265795187039]
	TIME [epoch: 18.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350288945532726		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1350288945532726 | validation: 0.42428553667820323]
	TIME [epoch: 18.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15040231678733787		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.15040231678733787 | validation: 0.32842264780788255]
	TIME [epoch: 18.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458712705066536		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.1458712705066536 | validation: 0.34479316801800536]
	TIME [epoch: 18.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16990652533836795		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.16990652533836795 | validation: 0.3713911619174285]
	TIME [epoch: 18.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15009283057123507		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.15009283057123507 | validation: 0.3494498108923709]
	TIME [epoch: 18.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496925313453811		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.13496925313453811 | validation: 0.30546013223874213]
	TIME [epoch: 18.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241122168923045		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.13241122168923045 | validation: 0.31952756018639605]
	TIME [epoch: 18.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14423534660195508		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.14423534660195508 | validation: 0.3272275924868424]
	TIME [epoch: 18.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14998313112345135		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.14998313112345135 | validation: 0.30603074799240293]
	TIME [epoch: 18.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449790425650358		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.1449790425650358 | validation: 0.32911267959687407]
	TIME [epoch: 18.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17421740517696097		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.17421740517696097 | validation: 0.2995417500781244]
	TIME [epoch: 18.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628225143796741		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1628225143796741 | validation: 0.30255484274346406]
	TIME [epoch: 18.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549029812544484		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.1549029812544484 | validation: 0.33781766483513836]
	TIME [epoch: 18.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156721202896613		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.156721202896613 | validation: 0.3266550808360485]
	TIME [epoch: 18.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16393988458894926		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.16393988458894926 | validation: 0.4407761579568238]
	TIME [epoch: 18.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16551809004599394		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.16551809004599394 | validation: 0.3830016112138908]
	TIME [epoch: 18.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942082453936473		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.14942082453936473 | validation: 0.3133396700133042]
	TIME [epoch: 18.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12440965256691167		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.12440965256691167 | validation: 0.353842778079422]
	TIME [epoch: 18.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13849140730804366		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.13849140730804366 | validation: 0.34978552454922407]
	TIME [epoch: 18.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292943060504962		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1292943060504962 | validation: 0.3975661973446873]
	TIME [epoch: 18.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377765402317606		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1377765402317606 | validation: 0.2803289145684736]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13909775604621283		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.13909775604621283 | validation: 0.3626258417077667]
	TIME [epoch: 18.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532711503293327		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.13532711503293327 | validation: 0.3703329522967801]
	TIME [epoch: 18.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049077723791937		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.15049077723791937 | validation: 0.3056386744309696]
	TIME [epoch: 18.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190754309115507		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.16190754309115507 | validation: 0.34070703764626764]
	TIME [epoch: 18.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1404677769961351		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1404677769961351 | validation: 0.3739255445602664]
	TIME [epoch: 18.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16122884958337974		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.16122884958337974 | validation: 0.3843494582813995]
	TIME [epoch: 18.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499268413788793		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.14499268413788793 | validation: 0.3556779431892213]
	TIME [epoch: 18.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17342566644538948		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.17342566644538948 | validation: 0.296215493452901]
	TIME [epoch: 18.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14143378331240192		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.14143378331240192 | validation: 0.306243243496332]
	TIME [epoch: 18.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549858168898446		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1549858168898446 | validation: 0.2989356226687802]
	TIME [epoch: 18.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347945102911478		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1347945102911478 | validation: 0.286592943064958]
	TIME [epoch: 18.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14889598158884304		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.14889598158884304 | validation: 0.31118276702266534]
	TIME [epoch: 18.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17192896589342188		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.17192896589342188 | validation: 0.2893879142220063]
	TIME [epoch: 18.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056262175671924		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.14056262175671924 | validation: 0.3724271485007793]
	TIME [epoch: 18.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14313473781782077		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.14313473781782077 | validation: 0.3346995842718388]
	TIME [epoch: 18.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702817441398724		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.13702817441398724 | validation: 0.32230714172652936]
	TIME [epoch: 18.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373659094449739		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.12373659094449739 | validation: 0.30815523261036487]
	TIME [epoch: 18.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13785668954368596		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.13785668954368596 | validation: 0.4315039597743711]
	TIME [epoch: 18.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16102647589630587		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.16102647589630587 | validation: 0.28872445419214865]
	TIME [epoch: 18.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14297812851416294		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.14297812851416294 | validation: 0.28833371034728694]
	TIME [epoch: 18.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14048336969665873		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.14048336969665873 | validation: 0.3031253447945017]
	TIME [epoch: 18.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14393445297694604		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.14393445297694604 | validation: 0.29258720365356994]
	TIME [epoch: 64.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288382904429453		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1288382904429453 | validation: 0.30801521413327737]
	TIME [epoch: 39.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567216038683031		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1567216038683031 | validation: 0.31473941886398416]
	TIME [epoch: 39.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610051998689716		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.1610051998689716 | validation: 0.3011233908229909]
	TIME [epoch: 39.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11976786525377286		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.11976786525377286 | validation: 0.32938367417734793]
	TIME [epoch: 39.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12066168249573336		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.12066168249573336 | validation: 0.3795102898542442]
	TIME [epoch: 39.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352824322303723		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.1352824322303723 | validation: 0.40733197748244454]
	TIME [epoch: 39.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14431554262276827		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.14431554262276827 | validation: 0.43655308760773415]
	TIME [epoch: 39.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351457035421115		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.15351457035421115 | validation: 0.33073401399185803]
	TIME [epoch: 39.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13294084362167416		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.13294084362167416 | validation: 0.3099515262957246]
	TIME [epoch: 39.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12589107285732326		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.12589107285732326 | validation: 0.33159586685340636]
	TIME [epoch: 39.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13349059328720358		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.13349059328720358 | validation: 0.33922026211085854]
	TIME [epoch: 39.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13258718576749876		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.13258718576749876 | validation: 0.3631397823720697]
	TIME [epoch: 39.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14150681564068196		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.14150681564068196 | validation: 0.33656131394147887]
	TIME [epoch: 39.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14061095968931592		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.14061095968931592 | validation: 0.35784841911590815]
	TIME [epoch: 39.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16579101793095294		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.16579101793095294 | validation: 0.35369366444148703]
	TIME [epoch: 39.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14111484270620767		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14111484270620767 | validation: 0.3431060285760157]
	TIME [epoch: 39.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14448040735114323		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.14448040735114323 | validation: 0.33533301097029944]
	TIME [epoch: 39.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12506090301186024		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.12506090301186024 | validation: 0.3251463102557028]
	TIME [epoch: 39.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430819599615715		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13430819599615715 | validation: 0.4207060640188992]
	TIME [epoch: 39.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381338395284162		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.1381338395284162 | validation: 0.3115716600994662]
	TIME [epoch: 39.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13785699596731116		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.13785699596731116 | validation: 0.278275734212382]
	TIME [epoch: 39.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13345896034076749		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.13345896034076749 | validation: 0.3839941251801343]
	TIME [epoch: 39.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479595232101596		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.1479595232101596 | validation: 0.3215191298006188]
	TIME [epoch: 39.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593039434143996		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.12593039434143996 | validation: 0.31266112008405345]
	TIME [epoch: 39.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316954633926298		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1316954633926298 | validation: 0.31421633969622403]
	TIME [epoch: 39.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818637528102594		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.12818637528102594 | validation: 0.3779050360750925]
	TIME [epoch: 39.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379895294207881		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.1379895294207881 | validation: 0.3619553336437851]
	TIME [epoch: 39.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377505015070585		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.1377505015070585 | validation: 0.3226074962039421]
	TIME [epoch: 39.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622384157334264		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.13622384157334264 | validation: 0.3351589336902305]
	TIME [epoch: 39.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327624110420299		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.1327624110420299 | validation: 0.3048297655693545]
	TIME [epoch: 39.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532822461056976		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.13532822461056976 | validation: 0.30541762541607487]
	TIME [epoch: 39.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12254263121630253		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.12254263121630253 | validation: 0.365924421336887]
	TIME [epoch: 39.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295750572868954		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.1295750572868954 | validation: 0.2864163820919338]
	TIME [epoch: 39.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13468944929394971		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.13468944929394971 | validation: 0.28001860547749247]
	TIME [epoch: 39.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788130557038897		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.13788130557038897 | validation: 0.33926186279689696]
	TIME [epoch: 39.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15647849691121457		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15647849691121457 | validation: 0.3499634703237364]
	TIME [epoch: 39.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443782952498253		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1443782952498253 | validation: 0.4165122847205847]
	TIME [epoch: 39.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382538957408909		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1382538957408909 | validation: 0.38476963092787975]
	TIME [epoch: 39.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570195680597234		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1570195680597234 | validation: 0.341818331641192]
	TIME [epoch: 39.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12335176794430017		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.12335176794430017 | validation: 0.3005323311810925]
	TIME [epoch: 39.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882370399385423		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.12882370399385423 | validation: 0.29596209246458716]
	TIME [epoch: 39.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11894215756758997		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.11894215756758997 | validation: 0.33307743164942816]
	TIME [epoch: 39.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480425475792053		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.1480425475792053 | validation: 0.27684650271454586]
	TIME [epoch: 39.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261231034993955		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.12261231034993955 | validation: 0.301139037021698]
	TIME [epoch: 39.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14601361070424848		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.14601361070424848 | validation: 0.35799506317825924]
	TIME [epoch: 39.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142486696271011		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.142486696271011 | validation: 0.3375854340968513]
	TIME [epoch: 39.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12735910721953603		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12735910721953603 | validation: 0.33408361916163376]
	TIME [epoch: 39.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12360579685118286		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.12360579685118286 | validation: 0.3548554538975391]
	TIME [epoch: 39.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422770907564779		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1422770907564779 | validation: 0.32145984196363026]
	TIME [epoch: 39.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024629342966368		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.12024629342966368 | validation: 0.27564417929271484]
	TIME [epoch: 39.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14321790161535958		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.14321790161535958 | validation: 0.37548059827567126]
	TIME [epoch: 39.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415692212359284		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.1415692212359284 | validation: 0.2953715208534269]
	TIME [epoch: 39.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656956951841404		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.13656956951841404 | validation: 0.2801619081486454]
	TIME [epoch: 39.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344051608785887		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1344051608785887 | validation: 0.2852168548676112]
	TIME [epoch: 39.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096527755229404		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.14096527755229404 | validation: 0.3321442751925366]
	TIME [epoch: 39.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13070682450979906		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.13070682450979906 | validation: 0.3306809270563275]
	TIME [epoch: 39.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139311728622078		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.139311728622078 | validation: 0.28621548106759603]
	TIME [epoch: 39.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13765259471688238		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.13765259471688238 | validation: 0.29209330982726284]
	TIME [epoch: 39.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197201727233051		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.1197201727233051 | validation: 0.30343998871783834]
	TIME [epoch: 39.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13722702005117604		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.13722702005117604 | validation: 0.30440582470957234]
	TIME [epoch: 39.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14509694123227312		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14509694123227312 | validation: 0.30325004948380574]
	TIME [epoch: 39.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11932060807716668		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.11932060807716668 | validation: 0.31044814581504837]
	TIME [epoch: 39.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186012033363271		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.12186012033363271 | validation: 0.36256699291017336]
	TIME [epoch: 39.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13909233758611908		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.13909233758611908 | validation: 0.37785902758323914]
	TIME [epoch: 39.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12886416137744416		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.12886416137744416 | validation: 0.3117125336677041]
	TIME [epoch: 39.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490156827968333		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.11490156827968333 | validation: 0.3250637714315279]
	TIME [epoch: 39.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476822831708337		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1476822831708337 | validation: 0.33275818057334866]
	TIME [epoch: 39.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260743774037722		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.1260743774037722 | validation: 0.3017612215947767]
	TIME [epoch: 39.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402567889414791		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1402567889414791 | validation: 0.2920772675967763]
	TIME [epoch: 39.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12297905616667164		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.12297905616667164 | validation: 0.2924274769137171]
	TIME [epoch: 39.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15447967295232756		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.15447967295232756 | validation: 0.3187069925605201]
	TIME [epoch: 39.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232952944469666		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.12232952944469666 | validation: 0.28812244440336615]
	TIME [epoch: 39.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620554698829087		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.12620554698829087 | validation: 0.31482344124383355]
	TIME [epoch: 39.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11566585636790964		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.11566585636790964 | validation: 0.29597926760338616]
	TIME [epoch: 39.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210224106377445		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1210224106377445 | validation: 0.29757402134605687]
	TIME [epoch: 39.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212948779131984		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.1212948779131984 | validation: 0.3182734854269699]
	TIME [epoch: 39.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931502202882334		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.13931502202882334 | validation: 0.3499352858884714]
	TIME [epoch: 39.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14647706848522868		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14647706848522868 | validation: 0.2981238675005255]
	TIME [epoch: 39.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13846376723489148		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.13846376723489148 | validation: 0.3022774268123556]
	TIME [epoch: 39.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180951720539834		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1180951720539834 | validation: 0.3399113704214944]
	TIME [epoch: 39.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14487275826153173		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.14487275826153173 | validation: 0.3223109987674871]
	TIME [epoch: 39.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13222077688685496		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.13222077688685496 | validation: 0.2839089718560277]
	TIME [epoch: 39.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329822723617767		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.12329822723617767 | validation: 0.35222238280391394]
	TIME [epoch: 39.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961894059378504		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.12961894059378504 | validation: 0.3406491759596443]
	TIME [epoch: 39.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420209197747601		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1420209197747601 | validation: 0.32222381994172017]
	TIME [epoch: 39.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321861296023806		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1321861296023806 | validation: 0.3889848596147327]
	TIME [epoch: 39.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13040274803691612		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.13040274803691612 | validation: 0.3080071343978408]
	TIME [epoch: 39.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12212211508506483		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.12212211508506483 | validation: 0.3171351432086016]
	TIME [epoch: 39.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377040507348975		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.1377040507348975 | validation: 0.30413845984362115]
	TIME [epoch: 39.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12315128510917989		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.12315128510917989 | validation: 0.28714829465204855]
	TIME [epoch: 39.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336622679221389		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1336622679221389 | validation: 0.2870834822449293]
	TIME [epoch: 39.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595771575368126		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.11595771575368126 | validation: 0.3330804821522613]
	TIME [epoch: 39.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737471439442178		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13737471439442178 | validation: 0.34916654964954164]
	TIME [epoch: 39.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191968565587523		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.1191968565587523 | validation: 0.28952924995207163]
	TIME [epoch: 39.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155634449337938		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.12155634449337938 | validation: 0.3086998349643748]
	TIME [epoch: 39.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13065143168106022		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.13065143168106022 | validation: 0.2816267060065042]
	TIME [epoch: 39.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296695836526158		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.1296695836526158 | validation: 0.27527763518334997]
	TIME [epoch: 39.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076937924389648		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.13076937924389648 | validation: 0.3029485323718713]
	TIME [epoch: 39.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365433755674609		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.11365433755674609 | validation: 0.28815157934712715]
	TIME [epoch: 39.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298575748701148		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1298575748701148 | validation: 0.2814966600672432]
	TIME [epoch: 107 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139089190947754		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.12139089190947754 | validation: 0.34537917775685195]
	TIME [epoch: 81.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11229535468359444		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.11229535468359444 | validation: 0.30817401546208106]
	TIME [epoch: 81.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296089295442137		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.1296089295442137 | validation: 0.2863988633655601]
	TIME [epoch: 81.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11885947597243046		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.11885947597243046 | validation: 0.3591694806908487]
	TIME [epoch: 81.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12974365063086496		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.12974365063086496 | validation: 0.3111764506461137]
	TIME [epoch: 81.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761805641730264		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.15761805641730264 | validation: 0.36562179289861096]
	TIME [epoch: 81.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564174104193472		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14564174104193472 | validation: 0.39162084440750533]
	TIME [epoch: 81.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14622467349492002		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14622467349492002 | validation: 0.29406689893973303]
	TIME [epoch: 81.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070274332399088		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.12070274332399088 | validation: 0.29121826570815634]
	TIME [epoch: 81.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13016340785472408		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.13016340785472408 | validation: 0.339479713025913]
	TIME [epoch: 81.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203393448469158		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.1203393448469158 | validation: 0.3228981762409766]
	TIME [epoch: 81.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405442226284137		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.13405442226284137 | validation: 0.29259013646848975]
	TIME [epoch: 81.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12728662916251493		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12728662916251493 | validation: 0.3528116278144642]
	TIME [epoch: 81.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12511265032093594		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.12511265032093594 | validation: 0.31189499467690057]
	TIME [epoch: 81.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342494534979284		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1342494534979284 | validation: 0.29682667826313863]
	TIME [epoch: 81.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11847387381280466		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.11847387381280466 | validation: 0.3222550369305102]
	TIME [epoch: 81.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273028208161529		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.1273028208161529 | validation: 0.33019577120385957]
	TIME [epoch: 81.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949984533852867		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.11949984533852867 | validation: 0.2960663681632794]
	TIME [epoch: 81.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12218344662884065		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.12218344662884065 | validation: 0.29053742581660597]
	TIME [epoch: 81.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13013833768386854		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.13013833768386854 | validation: 0.36119391344608015]
	TIME [epoch: 81.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13706577022523966		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.13706577022523966 | validation: 0.3025476784922624]
	TIME [epoch: 81.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1171532857281179		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.1171532857281179 | validation: 0.28879616042726536]
	TIME [epoch: 81.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953116396451288		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.11953116396451288 | validation: 0.33786902440965355]
	TIME [epoch: 81.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695940857117752		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.15695940857117752 | validation: 0.30471243232918976]
	TIME [epoch: 81.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11959618685635912		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.11959618685635912 | validation: 0.3547505631988823]
	TIME [epoch: 81.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703303610103083		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.11703303610103083 | validation: 0.341765122673873]
	TIME [epoch: 81.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297596301819809		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1297596301819809 | validation: 0.2955035282345379]
	TIME [epoch: 81.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11710233327570978		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.11710233327570978 | validation: 0.3363835622577966]
	TIME [epoch: 81.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415906428241275		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.12415906428241275 | validation: 0.3397331263366975]
	TIME [epoch: 81.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207139553437108		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1207139553437108 | validation: 0.30279807972970707]
	TIME [epoch: 81.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170778035877557		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.11170778035877557 | validation: 0.33099472767624033]
	TIME [epoch: 81.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484236714817632		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.10484236714817632 | validation: 0.2957298321940274]
	TIME [epoch: 81.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12751223566888414		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12751223566888414 | validation: 0.3034076061471283]
	TIME [epoch: 81.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490504639859138		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.13490504639859138 | validation: 0.32691805452513323]
	TIME [epoch: 81.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14349423172578996		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.14349423172578996 | validation: 0.37576987553851554]
	TIME [epoch: 81.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12278568765187121		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.12278568765187121 | validation: 0.30506977528622936]
	TIME [epoch: 81.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11762624829178167		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.11762624829178167 | validation: 0.31025831396835524]
	TIME [epoch: 81.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12350571763677987		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.12350571763677987 | validation: 0.29789924097780895]
	TIME [epoch: 81.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12105296758808994		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.12105296758808994 | validation: 0.34828658653929717]
	TIME [epoch: 81.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11724272097673714		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.11724272097673714 | validation: 0.32020697363324374]
	TIME [epoch: 81.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680010969582343		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.11680010969582343 | validation: 0.31413490572976877]
	TIME [epoch: 81.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455459377784503		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.12455459377784503 | validation: 0.2854879966619267]
	TIME [epoch: 81.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216291736208689		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1216291736208689 | validation: 0.3438969780786289]
	TIME [epoch: 81.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125576466151792		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.125576466151792 | validation: 0.2974759686715458]
	TIME [epoch: 81.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988317841610755		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.12988317841610755 | validation: 0.2973059656058259]
	TIME [epoch: 81.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11510935066650858		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.11510935066650858 | validation: 0.32035021534466956]
	TIME [epoch: 81.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125034059169858		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.1125034059169858 | validation: 0.3219602244877822]
	TIME [epoch: 81.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258921673819142		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.11258921673819142 | validation: 0.29794054795553726]
	TIME [epoch: 81.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504399464313406		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.11504399464313406 | validation: 0.33550977977111746]
	TIME [epoch: 81.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254022624884997		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.1254022624884997 | validation: 0.2979983718306728]
	TIME [epoch: 81.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272090378961998		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1272090378961998 | validation: 0.289578775031244]
	TIME [epoch: 81.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093006137046267		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.12093006137046267 | validation: 0.3536537084030327]
	TIME [epoch: 81.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11301308509689		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.11301308509689 | validation: 0.2972362840016725]
	TIME [epoch: 81.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11647634555149015		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11647634555149015 | validation: 0.3182468773405952]
	TIME [epoch: 81.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070736417394498		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.12070736417394498 | validation: 0.3499275780724635]
	TIME [epoch: 81.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090319943393265		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1090319943393265 | validation: 0.3141373672719985]
	TIME [epoch: 81.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11635220676355529		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.11635220676355529 | validation: 0.31165377041713954]
	TIME [epoch: 81.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11639039759024254		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.11639039759024254 | validation: 0.30091488119653853]
	TIME [epoch: 81.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11617836593709555		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11617836593709555 | validation: 0.3280073670693684]
	TIME [epoch: 81.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13005129095580553		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13005129095580553 | validation: 0.291424088805519]
	TIME [epoch: 81.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137588038929895		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.12137588038929895 | validation: 0.2804772140562135]
	TIME [epoch: 81.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197343476197811		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.12197343476197811 | validation: 0.35884050377450916]
	TIME [epoch: 81.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13287396110181104		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.13287396110181104 | validation: 0.3064453971388161]
	TIME [epoch: 81.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10790969427065261		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.10790969427065261 | validation: 0.29103469194006504]
	TIME [epoch: 81.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092163375206183		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.12092163375206183 | validation: 0.3203627146199941]
	TIME [epoch: 81.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11758557385867613		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.11758557385867613 | validation: 0.30967859498834244]
	TIME [epoch: 81.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11551021714299217		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.11551021714299217 | validation: 0.2897334378454587]
	TIME [epoch: 81.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748097323310928		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.10748097323310928 | validation: 0.29898192427626014]
	TIME [epoch: 81.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902730199884551		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.11902730199884551 | validation: 0.30209864128929087]
	TIME [epoch: 81.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093260702654685		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1093260702654685 | validation: 0.2787912180158624]
	TIME [epoch: 81.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257373001458536		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1257373001458536 | validation: 0.35713146091026043]
	TIME [epoch: 81.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113439311924008		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.13113439311924008 | validation: 0.30044402491998884]
	TIME [epoch: 81.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11380150542607559		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.11380150542607559 | validation: 0.32891420279223527]
	TIME [epoch: 81.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11513021404246129		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.11513021404246129 | validation: 0.31755235219736694]
	TIME [epoch: 81.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446480294458101		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.12446480294458101 | validation: 0.3330959352484158]
	TIME [epoch: 81.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12983424003305907		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.12983424003305907 | validation: 0.3485549969318169]
	TIME [epoch: 81.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10972651803854601		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.10972651803854601 | validation: 0.2990684093258817]
	TIME [epoch: 81.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190448201021192		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12190448201021192 | validation: 0.29854653096247635]
	TIME [epoch: 81.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039100126302265		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.11039100126302265 | validation: 0.2891464242997689]
	TIME [epoch: 81.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273348798139665		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11273348798139665 | validation: 0.33523740289899]
	TIME [epoch: 81.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110949841143683		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.11110949841143683 | validation: 0.3018381502512397]
	TIME [epoch: 81.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297698440157668		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.13297698440157668 | validation: 0.3403190766925293]
	TIME [epoch: 81.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11843990824781936		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.11843990824781936 | validation: 0.3345155715226074]
	TIME [epoch: 81.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13246995069060544		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13246995069060544 | validation: 0.3079611901017429]
	TIME [epoch: 81.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12279690195810268		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.12279690195810268 | validation: 0.29157787844223304]
	TIME [epoch: 81.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469867616721345		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.12469867616721345 | validation: 0.31989888013224055]
	TIME [epoch: 81.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298566974503721		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.11298566974503721 | validation: 0.2857355949290729]
	TIME [epoch: 81.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690422752070755		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.10690422752070755 | validation: 0.31369438378345005]
	TIME [epoch: 81.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510012138196581		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.10510012138196581 | validation: 0.3031735928663385]
	TIME [epoch: 81.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147110904424143		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1147110904424143 | validation: 0.3100118360489976]
	TIME [epoch: 81.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226302750565482		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.10226302750565482 | validation: 0.349377597892223]
	TIME [epoch: 81.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954724640072173		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.11954724640072173 | validation: 0.29524445856689197]
	TIME [epoch: 81.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13001078957489215		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.13001078957489215 | validation: 0.2819130799199401]
	TIME [epoch: 81.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13023008996058175		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.13023008996058175 | validation: 0.29944385100680826]
	TIME [epoch: 81.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329229282666424		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11329229282666424 | validation: 0.27486850744399327]
	TIME [epoch: 81.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249027088132505		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12249027088132505 | validation: 0.3441302134081971]
	TIME [epoch: 81.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11559352476635464		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.11559352476635464 | validation: 0.30360398000186883]
	TIME [epoch: 81.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11095070090277426		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.11095070090277426 | validation: 0.2969109237268157]
	TIME [epoch: 81.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11821028571213901		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.11821028571213901 | validation: 0.33050101733680864]
	TIME [epoch: 81.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832790323647998		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.10832790323647998 | validation: 0.28616420977715107]
	TIME [epoch: 81.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860009824388729		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.10860009824388729 | validation: 0.2782213336302586]
	TIME [epoch: 81.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065094408582926		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.11065094408582926 | validation: 0.31800898736599087]
	TIME [epoch: 81.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11803322207139355		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.11803322207139355 | validation: 0.3194075798028627]
	TIME [epoch: 81.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11256183923527834		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.11256183923527834 | validation: 0.2832243867075067]
	TIME [epoch: 81.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170851677440005		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11170851677440005 | validation: 0.29095950140292454]
	TIME [epoch: 81.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663471761084319		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.10663471761084319 | validation: 0.32675336790407494]
	TIME [epoch: 81.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107979621364407		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.11107979621364407 | validation: 0.287175568905307]
	TIME [epoch: 81.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12058468582051027		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12058468582051027 | validation: 0.32331153055130507]
	TIME [epoch: 81.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12584498043956954		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.12584498043956954 | validation: 0.304055526061022]
	TIME [epoch: 81.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252311264491375		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.1252311264491375 | validation: 0.28871540402057977]
	TIME [epoch: 81.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13836060252734533		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.13836060252734533 | validation: 0.29743126596832703]
	TIME [epoch: 81.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11817428961406129		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.11817428961406129 | validation: 0.31586755904906316]
	TIME [epoch: 81.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824297797726426		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.10824297797726426 | validation: 0.29664522612011457]
	TIME [epoch: 81.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834969821837558		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.10834969821837558 | validation: 0.3136260231896242]
	TIME [epoch: 81.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073987367482917		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.11073987367482917 | validation: 0.29349336473408644]
	TIME [epoch: 81.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10790524544539987		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.10790524544539987 | validation: 0.3130761002074414]
	TIME [epoch: 81.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12535927710840006		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.12535927710840006 | validation: 0.29798082763735423]
	TIME [epoch: 81.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374191169939774		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.11374191169939774 | validation: 0.30549401540548676]
	TIME [epoch: 81.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11815743982585297		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.11815743982585297 | validation: 0.29794685406116517]
	TIME [epoch: 81.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12605104657328337		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12605104657328337 | validation: 0.31996008815075494]
	TIME [epoch: 81.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12585531106239828		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.12585531106239828 | validation: 0.29792736954170834]
	TIME [epoch: 81.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027913345687264		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.11027913345687264 | validation: 0.31668745951425675]
	TIME [epoch: 81.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433030675134583		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.12433030675134583 | validation: 0.3162030754636929]
	TIME [epoch: 81.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212659871453495		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1212659871453495 | validation: 0.3085585835551897]
	TIME [epoch: 81.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11305776837282322		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.11305776837282322 | validation: 0.3044980062069851]
	TIME [epoch: 81.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869189538070169		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.10869189538070169 | validation: 0.3153864817342403]
	TIME [epoch: 81.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11707708246233192		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.11707708246233192 | validation: 0.2881619857460893]
	TIME [epoch: 81.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951218925704388		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.11951218925704388 | validation: 0.330137327836512]
	TIME [epoch: 81.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10754614760594824		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.10754614760594824 | validation: 0.3109721315361953]
	TIME [epoch: 81.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211446775170066		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.12211446775170066 | validation: 0.3192247482512411]
	TIME [epoch: 81.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162967603121862		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.12162967603121862 | validation: 0.32402237000383355]
	TIME [epoch: 81.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141007500900924		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1141007500900924 | validation: 0.28919278444680957]
	TIME [epoch: 81.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033778384466274		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.10033778384466274 | validation: 0.31410716270104466]
	TIME [epoch: 81.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092439180281134		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.12092439180281134 | validation: 0.3052960872244205]
	TIME [epoch: 81.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13869192896345797		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.13869192896345797 | validation: 0.2898882945067336]
	TIME [epoch: 81.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1144500418292958		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.1144500418292958 | validation: 0.2885447913975496]
	TIME [epoch: 81.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809187491445099		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.10809187491445099 | validation: 0.29001322384274714]
	TIME [epoch: 81.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12546637203591693		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.12546637203591693 | validation: 0.33123221976791073]
	TIME [epoch: 81.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10457567071183126		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.10457567071183126 | validation: 0.31882498127156933]
	TIME [epoch: 81.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416981081826353		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.10416981081826353 | validation: 0.3057427867732475]
	TIME [epoch: 81.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12122832820028524		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.12122832820028524 | validation: 0.31347106063384045]
	TIME [epoch: 81.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11976104086291595		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.11976104086291595 | validation: 0.2819330126040844]
	TIME [epoch: 81.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11286324590996306		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.11286324590996306 | validation: 0.31229943326431264]
	TIME [epoch: 81.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172768348903746		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.1172768348903746 | validation: 0.2916902362719727]
	TIME [epoch: 81.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726249967348283		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.12726249967348283 | validation: 0.29997248735862475]
	TIME [epoch: 81.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391374127305402		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11391374127305402 | validation: 0.3055371712487843]
	TIME [epoch: 81.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11736005542723525		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.11736005542723525 | validation: 0.326626173282087]
	TIME [epoch: 81.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11706116543140423		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.11706116543140423 | validation: 0.3100998015704116]
	TIME [epoch: 81.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11402647814949432		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.11402647814949432 | validation: 0.3141483251081322]
	TIME [epoch: 81.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259372816831576		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.12259372816831576 | validation: 0.30716453226625295]
	TIME [epoch: 81.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466326364073848		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11466326364073848 | validation: 0.3065035286410663]
	TIME [epoch: 81.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155931836472426		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.12155931836472426 | validation: 0.2984964459751428]
	TIME [epoch: 81.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185827607632724		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.1185827607632724 | validation: 0.29569750369973474]
	TIME [epoch: 81.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126353120108908		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.1126353120108908 | validation: 0.2880543959218981]
	TIME [epoch: 81.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10945752796998146		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.10945752796998146 | validation: 0.2942461639044088]
	TIME [epoch: 81.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887739944207304		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.10887739944207304 | validation: 0.3276830473926328]
	TIME [epoch: 81.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10778449811922562		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.10778449811922562 | validation: 0.31522098989889563]
	TIME [epoch: 81.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10658264505872098		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.10658264505872098 | validation: 0.2842393643970002]
	TIME [epoch: 81.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10836891423820544		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.10836891423820544 | validation: 0.3160909608801658]
	TIME [epoch: 81.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064890448927038		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.11064890448927038 | validation: 0.35745644414093597]
	TIME [epoch: 81.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296353294720101		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.12296353294720101 | validation: 0.28880037962236027]
	TIME [epoch: 81.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384387090459731		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.12384387090459731 | validation: 0.3075113484695932]
	TIME [epoch: 81.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11752400570990758		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.11752400570990758 | validation: 0.3312718175119264]
	TIME [epoch: 81.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063648214324194		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.12063648214324194 | validation: 0.297340953803792]
	TIME [epoch: 81.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995194433564654		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.11995194433564654 | validation: 0.2988071411294142]
	TIME [epoch: 81.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069913396095528		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.11069913396095528 | validation: 0.28875560185295884]
	TIME [epoch: 81.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12721931575216636		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.12721931575216636 | validation: 0.31724486368680643]
	TIME [epoch: 81.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294887778766422		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1294887778766422 | validation: 0.29777491222096303]
	TIME [epoch: 81.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123222473985104		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.1123222473985104 | validation: 0.30867643429364444]
	TIME [epoch: 81.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418153678230872		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.11418153678230872 | validation: 0.29545892157792225]
	TIME [epoch: 81.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11809455710300355		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11809455710300355 | validation: 0.33334338948548314]
	TIME [epoch: 81.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633233099548019		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.10633233099548019 | validation: 0.3049416998518562]
	TIME [epoch: 81.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14424500630484513		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.14424500630484513 | validation: 0.3323490152806115]
	TIME [epoch: 81.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11851222276496813		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.11851222276496813 | validation: 0.32403314202298555]
	TIME [epoch: 81.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940707204064949		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.10940707204064949 | validation: 0.29795679531619]
	TIME [epoch: 81.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11508930742543642		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.11508930742543642 | validation: 0.3145742259093565]
	TIME [epoch: 81.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200830373467053		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.10200830373467053 | validation: 0.3071507049388514]
	TIME [epoch: 81.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048145977070563		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.13048145977070563 | validation: 0.3043337790741978]
	TIME [epoch: 81.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089431730465594		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.1089431730465594 | validation: 0.31616036741377723]
	TIME [epoch: 81.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654427855230236		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.10654427855230236 | validation: 0.3138013307947525]
	TIME [epoch: 81.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10964369641079037		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.10964369641079037 | validation: 0.30200826964993854]
	TIME [epoch: 81.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12607662465416303		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.12607662465416303 | validation: 0.2948472140851224]
	TIME [epoch: 81.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462864465782084		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.12462864465782084 | validation: 0.3058564082403156]
	TIME [epoch: 81.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117195167085097		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.1117195167085097 | validation: 0.2987095800499652]
	TIME [epoch: 81.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129474584651078		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.11129474584651078 | validation: 0.3098916401523318]
	TIME [epoch: 81.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172097532995812		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.1172097532995812 | validation: 0.3247625860591809]
	TIME [epoch: 81.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13723974297805297		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13723974297805297 | validation: 0.31147760664687796]
	TIME [epoch: 81.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288453784632303		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.1288453784632303 | validation: 0.30087201712522754]
	TIME [epoch: 81.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827094752198675		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.11827094752198675 | validation: 0.30786897010584857]
	TIME [epoch: 81.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13995196932587084		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.13995196932587084 | validation: 0.3424204287812238]
	TIME [epoch: 81.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169960505936487		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.1169960505936487 | validation: 0.29576519385594235]
	TIME [epoch: 81.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231549006947869		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1231549006947869 | validation: 0.2948200372555697]
	TIME [epoch: 81.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269105638090045		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.1269105638090045 | validation: 0.2725720135061135]
	TIME [epoch: 81.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034782777464217		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.12034782777464217 | validation: 0.2942618763964263]
	TIME [epoch: 81.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811743755697495		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.10811743755697495 | validation: 0.2851959333194284]
	TIME [epoch: 81.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697140703548177		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.10697140703548177 | validation: 0.3087467371028172]
	TIME [epoch: 81.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230497523600694		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.10230497523600694 | validation: 0.32624944372661746]
	TIME [epoch: 81.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355883689266198		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.11355883689266198 | validation: 0.2728133407194394]
	TIME [epoch: 81.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10969802547524306		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.10969802547524306 | validation: 0.29892623887296654]
	TIME [epoch: 81.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546282995083978		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.10546282995083978 | validation: 0.286070959920884]
	TIME [epoch: 81.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13184459796278403		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.13184459796278403 | validation: 0.3312049010440827]
	TIME [epoch: 81.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11162029601879708		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.11162029601879708 | validation: 0.2941361702918353]
	TIME [epoch: 81.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143340818550214		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.11143340818550214 | validation: 0.30269416114643616]
	TIME [epoch: 81.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11668097846211678		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.11668097846211678 | validation: 0.30030122287776084]
	TIME [epoch: 81.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060662461658606		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.13060662461658606 | validation: 0.29116746603958193]
	TIME [epoch: 81.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11598027388606232		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.11598027388606232 | validation: 0.2895965667703746]
	TIME [epoch: 81.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10698079232154065		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.10698079232154065 | validation: 0.29320285869085433]
	TIME [epoch: 81.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102732145088612		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.10102732145088612 | validation: 0.28125884624241715]
	TIME [epoch: 81.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11520783783174157		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.11520783783174157 | validation: 0.2998781622652801]
	TIME [epoch: 81.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595433107991414		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.10595433107991414 | validation: 0.3151823346792932]
	TIME [epoch: 81.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10512342430194196		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.10512342430194196 | validation: 0.32449870760770877]
	TIME [epoch: 81.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213600207840402		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.11213600207840402 | validation: 0.28509087632074515]
	TIME [epoch: 81.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224125084921377		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1224125084921377 | validation: 0.35105067003001905]
	TIME [epoch: 81.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11606682413282912		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.11606682413282912 | validation: 0.3069212648730476]
	TIME [epoch: 81.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107612574355451		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.10107612574355451 | validation: 0.3012654752817475]
	TIME [epoch: 81.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10960784371819676		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.10960784371819676 | validation: 0.29337904995548264]
	TIME [epoch: 81.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413462561747974		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.10413462561747974 | validation: 0.3338885234728136]
	TIME [epoch: 81.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999092542061471		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.10999092542061471 | validation: 0.2984385364497925]
	TIME [epoch: 81.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049086480389419		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1049086480389419 | validation: 0.29159478941176487]
	TIME [epoch: 81.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12439654043594031		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.12439654043594031 | validation: 0.28487362815137235]
	TIME [epoch: 81.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298870018406196		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.11298870018406196 | validation: 0.30987087511904915]
	TIME [epoch: 81.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171795774483249		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.12171795774483249 | validation: 0.3117312645795375]
	TIME [epoch: 81.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207957839470663		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.1207957839470663 | validation: 0.30169283492593024]
	TIME [epoch: 81.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1137620541110239		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.1137620541110239 | validation: 0.2853217256964829]
	TIME [epoch: 81.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11946108680393994		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.11946108680393994 | validation: 0.3314759733872883]
	TIME [epoch: 81.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968504933898946		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.11968504933898946 | validation: 0.29622450437256664]
	TIME [epoch: 81.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335988997241682		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.13335988997241682 | validation: 0.2990985298697992]
	TIME [epoch: 81.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502693231989215		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1502693231989215 | validation: 0.30227776564691755]
	TIME [epoch: 81.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11838598521668836		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.11838598521668836 | validation: 0.28549622356448023]
	TIME [epoch: 81.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11802898001345447		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.11802898001345447 | validation: 0.32630895388728887]
	TIME [epoch: 81.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11432157405359447		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.11432157405359447 | validation: 0.2961610994551743]
	TIME [epoch: 81.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10884282256375238		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.10884282256375238 | validation: 0.2996339028751368]
	TIME [epoch: 81.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232000013287307		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.1232000013287307 | validation: 0.2750454789519103]
	TIME [epoch: 81.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355434314896363		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.12355434314896363 | validation: 0.28945381665189895]
	TIME [epoch: 81.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164624091727034		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.11164624091727034 | validation: 0.28639807284220575]
	TIME [epoch: 81.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048347617459407		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.1048347617459407 | validation: 0.29782928235468714]
	TIME [epoch: 81.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034952218565468		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.1034952218565468 | validation: 0.2888964841958881]
	TIME [epoch: 81.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11328403107858125		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.11328403107858125 | validation: 0.2981273777860371]
	TIME [epoch: 81.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10602931486495322		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.10602931486495322 | validation: 0.29165783030765063]
	TIME [epoch: 81.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026912684861044		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.12026912684861044 | validation: 0.2963841472678167]
	TIME [epoch: 81.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197868239618428		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.10197868239618428 | validation: 0.30574266636827213]
	TIME [epoch: 81.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840031315179259		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.10840031315179259 | validation: 0.31531002176234235]
	TIME [epoch: 81.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12330965213686565		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.12330965213686565 | validation: 0.3000030103233126]
	TIME [epoch: 81.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11798156065406012		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.11798156065406012 | validation: 0.3099749140901717]
	TIME [epoch: 81.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523566168886673		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.11523566168886673 | validation: 0.30024144018822313]
	TIME [epoch: 81.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935610219690677		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.10935610219690677 | validation: 0.2895985235424976]
	TIME [epoch: 81.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921322983502365		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.12921322983502365 | validation: 0.29734432641301006]
	TIME [epoch: 81.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167242135896001		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.10167242135896001 | validation: 0.3218116138437065]
	TIME [epoch: 81.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747113978956302		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.10747113978956302 | validation: 0.29409620648365326]
	TIME [epoch: 81.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825779476409558		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.11825779476409558 | validation: 0.2760083371219348]
	TIME [epoch: 81.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11058723296297807		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.11058723296297807 | validation: 0.29687293913420687]
	TIME [epoch: 81.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621143506679666		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.10621143506679666 | validation: 0.29513561347494777]
	TIME [epoch: 81.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11659635870350735		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.11659635870350735 | validation: 0.32242942519621703]
	TIME [epoch: 81.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11420005397571956		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.11420005397571956 | validation: 0.3034588252022545]
	TIME [epoch: 81.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288060617865141		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.11288060617865141 | validation: 0.2968007466647903]
	TIME [epoch: 81.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12321791819063463		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.12321791819063463 | validation: 0.3082567321328648]
	TIME [epoch: 81.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534556892720641		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.10534556892720641 | validation: 0.30219565785751124]
	TIME [epoch: 81.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11587603090823556		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.11587603090823556 | validation: 0.29986942537918365]
	TIME [epoch: 81.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073917970366387		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.11073917970366387 | validation: 0.3230837290600917]
	TIME [epoch: 81.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252095745254309		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.11252095745254309 | validation: 0.29038331852633037]
	TIME [epoch: 81.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11725013257345474		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.11725013257345474 | validation: 0.3037741688609592]
	TIME [epoch: 81.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601982180340767		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.10601982180340767 | validation: 0.30965445071154635]
	TIME [epoch: 81.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10895242401654008		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.10895242401654008 | validation: 0.3039252978695716]
	TIME [epoch: 81.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11447765305721089		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.11447765305721089 | validation: 0.2914557229836901]
	TIME [epoch: 81.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634231012695596		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.11634231012695596 | validation: 0.3018562186100773]
	TIME [epoch: 81.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163988145764482		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.1163988145764482 | validation: 0.28900870299320897]
	TIME [epoch: 81.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187293254586447		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.11187293254586447 | validation: 0.29823667401752196]
	TIME [epoch: 81.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11205962178952658		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.11205962178952658 | validation: 0.28686215918470737]
	TIME [epoch: 81.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280685838078993		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.1280685838078993 | validation: 0.29331412149315483]
	TIME [epoch: 81.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623617359793945		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.10623617359793945 | validation: 0.3081491097298471]
	TIME [epoch: 81.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048351953796128		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.1048351953796128 | validation: 0.302540855963101]
	TIME [epoch: 81.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928506208726091		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.09928506208726091 | validation: 0.29318703950137215]
	TIME [epoch: 81.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11071916341286747		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.11071916341286747 | validation: 0.2999316439821312]
	TIME [epoch: 81.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081338054870833		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.1081338054870833 | validation: 0.2980428176594856]
	TIME [epoch: 81.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485752890644865		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.11485752890644865 | validation: 0.29569989578229]
	TIME [epoch: 81.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299013263125983		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.10299013263125983 | validation: 0.3059393583067158]
	TIME [epoch: 81.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11814768691833233		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.11814768691833233 | validation: 0.3008255628479549]
	TIME [epoch: 81.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12414234590004661		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.12414234590004661 | validation: 0.30724531422468077]
	TIME [epoch: 81.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11667055415960542		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.11667055415960542 | validation: 0.31054153912469856]
	TIME [epoch: 81.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286135020532137		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.1286135020532137 | validation: 0.29797117609267876]
	TIME [epoch: 81.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218077010024781		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.11218077010024781 | validation: 0.3205711473308835]
	TIME [epoch: 81.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11240614588714604		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.11240614588714604 | validation: 0.30321767305690717]
	TIME [epoch: 81.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10524233546315931		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.10524233546315931 | validation: 0.2980900151702149]
	TIME [epoch: 81.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454457227423407		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.10454457227423407 | validation: 0.31152563389164806]
	TIME [epoch: 81.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069652426205186		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1069652426205186 | validation: 0.300711604307376]
	TIME [epoch: 81.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196081730352925		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.1196081730352925 | validation: 0.2899087372895526]
	TIME [epoch: 81.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11573646706691004		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.11573646706691004 | validation: 0.29678980755489526]
	TIME [epoch: 81.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107872659982252		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.107872659982252 | validation: 0.28182852536287406]
	TIME [epoch: 81.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10717689088084009		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.10717689088084009 | validation: 0.2876332442927435]
	TIME [epoch: 81.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13858396375043647		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.13858396375043647 | validation: 0.2950928586503231]
	TIME [epoch: 81.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461034583347066		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.11461034583347066 | validation: 0.28384827588591083]
	TIME [epoch: 81.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10858785218235209		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.10858785218235209 | validation: 0.3064590179412181]
	TIME [epoch: 81.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840210636623579		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.10840210636623579 | validation: 0.29816583681581665]
	TIME [epoch: 81.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351572587792043		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.10351572587792043 | validation: 0.30063622587037103]
	TIME [epoch: 81.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12085199455625228		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.12085199455625228 | validation: 0.30399931366155974]
	TIME [epoch: 81.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363563426493718		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.1363563426493718 | validation: 0.30540759824179264]
	TIME [epoch: 81.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11858460561980683		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.11858460561980683 | validation: 0.2892268110508337]
	TIME [epoch: 81.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10698324641902193		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.10698324641902193 | validation: 0.3050237715574426]
	TIME [epoch: 81.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758233435268254		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.12758233435268254 | validation: 0.2914179233876706]
	TIME [epoch: 81.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151965492360712		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.11151965492360712 | validation: 0.31509009458996573]
	TIME [epoch: 81.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11443944673002243		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.11443944673002243 | validation: 0.29544583540465624]
	TIME [epoch: 81.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267108902370844		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.11267108902370844 | validation: 0.29532625512464017]
	TIME [epoch: 81.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207745234065713		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.1207745234065713 | validation: 0.3136047645113309]
	TIME [epoch: 81.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11123854622787303		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.11123854622787303 | validation: 0.3098369829454344]
	TIME [epoch: 81.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052689616175353		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.10052689616175353 | validation: 0.30337534295055074]
	TIME [epoch: 81.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366178841870242		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.11366178841870242 | validation: 0.3003968227168416]
	TIME [epoch: 81.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302372389515893		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.10302372389515893 | validation: 0.29663613827028934]
	TIME [epoch: 81.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854315190555584		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.10854315190555584 | validation: 0.3031028560087898]
	TIME [epoch: 81.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024024078467719		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.1024024078467719 | validation: 0.2953195384727872]
	TIME [epoch: 81.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11070290551106267		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.11070290551106267 | validation: 0.32699937246995736]
	TIME [epoch: 81.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080698610099203		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.12080698610099203 | validation: 0.2988268161640725]
	TIME [epoch: 81.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11498408266325727		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.11498408266325727 | validation: 0.29517529120742947]
	TIME [epoch: 81.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184448790476207		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.10184448790476207 | validation: 0.307398914408252]
	TIME [epoch: 81.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140229594708406		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.1140229594708406 | validation: 0.29935181097652724]
	TIME [epoch: 81.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024275396516218		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.12024275396516218 | validation: 0.30713743097587176]
	TIME [epoch: 81.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10816394812367346		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.10816394812367346 | validation: 0.29142471345275467]
	TIME [epoch: 81.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257450150097889		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.11257450150097889 | validation: 0.29973789431564346]
	TIME [epoch: 81.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11603895245574017		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.11603895245574017 | validation: 0.303577987558371]
	TIME [epoch: 81.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12366004821738479		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.12366004821738479 | validation: 0.30086990193486485]
	TIME [epoch: 81.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11481494821046176		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.11481494821046176 | validation: 0.3164467741231636]
	TIME [epoch: 81.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11464976371593895		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.11464976371593895 | validation: 0.2855083965242996]
	TIME [epoch: 81.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10340761670076548		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.10340761670076548 | validation: 0.2986873926527223]
	TIME [epoch: 81.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463125136844486		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.12463125136844486 | validation: 0.28718064344973604]
	TIME [epoch: 81.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10170136675143582		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.10170136675143582 | validation: 0.2969790610785959]
	TIME [epoch: 81.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862079408526319		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.10862079408526319 | validation: 0.30775107972755184]
	TIME [epoch: 81.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910021340803797		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.10910021340803797 | validation: 0.30428959076697243]
	TIME [epoch: 81.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359655620012204		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.10359655620012204 | validation: 0.3166114681578234]
	TIME [epoch: 81.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682181287984757		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.10682181287984757 | validation: 0.3035488869886489]
	TIME [epoch: 81.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431327047752272		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.10431327047752272 | validation: 0.31791535824197503]
	TIME [epoch: 81.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11831730508177243		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.11831730508177243 | validation: 0.2828524779302119]
	TIME [epoch: 81.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471979956830141		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.10471979956830141 | validation: 0.30540029900732985]
	TIME [epoch: 81.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11155514677983291		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.11155514677983291 | validation: 0.297286127525799]
	TIME [epoch: 81.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298738851407759		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.10298738851407759 | validation: 0.2931441656304569]
	TIME [epoch: 81.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10572017882046039		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.10572017882046039 | validation: 0.2947772221685314]
	TIME [epoch: 81.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09885244452091178		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.09885244452091178 | validation: 0.3129859738948182]
	TIME [epoch: 81.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525966275432819		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.10525966275432819 | validation: 0.2922554743228479]
	TIME [epoch: 81.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257125461129167		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.11257125461129167 | validation: 0.29666348224400885]
	TIME [epoch: 81.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10994127055984793		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.10994127055984793 | validation: 0.30481525101284485]
	TIME [epoch: 81.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317494100663818		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.10317494100663818 | validation: 0.28949615266676304]
	TIME [epoch: 81.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655121974032662		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.11655121974032662 | validation: 0.2940779957685937]
	TIME [epoch: 81.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956175785324083		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.09956175785324083 | validation: 0.3030603750621204]
	TIME [epoch: 81.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10758354548354392		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.10758354548354392 | validation: 0.3079693632748248]
	TIME [epoch: 81.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057679282254097		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.11057679282254097 | validation: 0.28872610433655893]
	TIME [epoch: 81.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1026223551076598		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.1026223551076598 | validation: 0.30928945679124525]
	TIME [epoch: 81.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11313247154804221		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.11313247154804221 | validation: 0.30044518932420017]
	TIME [epoch: 81.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776798035604932		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.11776798035604932 | validation: 0.2989652122535007]
	TIME [epoch: 81.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086163683792482		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.10086163683792482 | validation: 0.30035144494676846]
	TIME [epoch: 81.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12108307016433702		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.12108307016433702 | validation: 0.32247686733851355]
	TIME [epoch: 81.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11672459520625392		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.11672459520625392 | validation: 0.3086746640606324]
	TIME [epoch: 81.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133761016998771		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.10133761016998771 | validation: 0.30483400450021636]
	TIME [epoch: 81.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12550473791662786		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.12550473791662786 | validation: 0.2983538721005803]
	TIME [epoch: 81.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133267764722122		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.1133267764722122 | validation: 0.30312400647061444]
	TIME [epoch: 81.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1088555965342305		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.1088555965342305 | validation: 0.3094031441956845]
	TIME [epoch: 81.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105679233983998		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.105679233983998 | validation: 0.2939765257636498]
	TIME [epoch: 81.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887667616794678		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.09887667616794678 | validation: 0.28932936061761294]
	TIME [epoch: 81.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10580248543417742		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.10580248543417742 | validation: 0.30065797620903484]
	TIME [epoch: 81.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105463104632242		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.10105463104632242 | validation: 0.29557955925363766]
	TIME [epoch: 81.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968898617077102		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.11968898617077102 | validation: 0.30855108432940404]
	TIME [epoch: 81.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1129782529218535		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.1129782529218535 | validation: 0.30573044784540315]
	TIME [epoch: 81.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12021400805690463		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.12021400805690463 | validation: 0.3009012243875649]
	TIME [epoch: 81.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235352982060068		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.1235352982060068 | validation: 0.29402719315638126]
	TIME [epoch: 81.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594017376618887		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.11594017376618887 | validation: 0.29066621058552106]
	TIME [epoch: 81.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11467080170690439		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.11467080170690439 | validation: 0.2862803872290312]
	TIME [epoch: 81.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596225902241894		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.10596225902241894 | validation: 0.2955551442922838]
	TIME [epoch: 81.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11533679627833397		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.11533679627833397 | validation: 0.2922280871458444]
	TIME [epoch: 81.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281878676097114		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.11281878676097114 | validation: 0.30145486876104527]
	TIME [epoch: 81.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271275051453359		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.1271275051453359 | validation: 0.3015939598352994]
	TIME [epoch: 81.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131223008115303		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.11131223008115303 | validation: 0.28555492301705543]
	TIME [epoch: 81.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013189802910724		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.1013189802910724 | validation: 0.30284557715078764]
	TIME [epoch: 81.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09492188334144595		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.09492188334144595 | validation: 0.30550221772871344]
	TIME [epoch: 81.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587725532139657		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.12587725532139657 | validation: 0.2968044509039214]
	TIME [epoch: 81.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384927404151204		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.12384927404151204 | validation: 0.31222143707195854]
	TIME [epoch: 81.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12051700874341685		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.12051700874341685 | validation: 0.28796154792267503]
	TIME [epoch: 81.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954541636194375		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.10954541636194375 | validation: 0.28986510803590393]
	TIME [epoch: 81.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544962144679135		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.10544962144679135 | validation: 0.30215062804204446]
	TIME [epoch: 81.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053374394598155		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.1053374394598155 | validation: 0.2984109931935328]
	TIME [epoch: 81.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268572174288103		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.1268572174288103 | validation: 0.30887113139103056]
	TIME [epoch: 81.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695632399717084		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.10695632399717084 | validation: 0.28445872076030704]
	TIME [epoch: 81.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524087805461404		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.12524087805461404 | validation: 0.3093971099134081]
	TIME [epoch: 81.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11762982929144336		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.11762982929144336 | validation: 0.29339454775347584]
	TIME [epoch: 81.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443363497335276		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.10443363497335276 | validation: 0.3155876366168462]
	TIME [epoch: 81.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141134348748475		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.12141134348748475 | validation: 0.2972464294020127]
	TIME [epoch: 81.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903909581450875		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.11903909581450875 | validation: 0.29742402552292724]
	TIME [epoch: 81.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11310128928025792		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.11310128928025792 | validation: 0.29585611272586426]
	TIME [epoch: 81.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259454623384034		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.11259454623384034 | validation: 0.2857024113635714]
	TIME [epoch: 81.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11275655179459353		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.11275655179459353 | validation: 0.2959852534463035]
	TIME [epoch: 81.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484117843979214		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.10484117843979214 | validation: 0.2982237921954463]
	TIME [epoch: 81.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560783683388853		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.11560783683388853 | validation: 0.28992173547981454]
	TIME [epoch: 81.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237847550396104		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.10237847550396104 | validation: 0.2979040059369994]
	TIME [epoch: 81.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610240101647454		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.11610240101647454 | validation: 0.30444607189956835]
	TIME [epoch: 81.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164736801773549		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.1164736801773549 | validation: 0.30883359809219285]
	TIME [epoch: 81.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10081292971463726		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.10081292971463726 | validation: 0.28741003056752745]
	TIME [epoch: 81.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921382460403187		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.10921382460403187 | validation: 0.29724198701516646]
	TIME [epoch: 81.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1063933685907554		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.1063933685907554 | validation: 0.29346902408539294]
	TIME [epoch: 81.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v13b_695.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 38960.173 seconds.
