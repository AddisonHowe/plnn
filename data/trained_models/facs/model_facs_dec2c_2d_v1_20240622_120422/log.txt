Args:
Namespace(name='model_facs_dec2c_2d_v1', outdir='out/model_training/model_facs_dec2c_2d_v1', training_data='data/training_data/facs/dec2_varnorm_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/dec2_varnorm_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1874558971

Training model...

Saving initial model state to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6797368169694448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6797368169694448 | validation: 0.643808884748183]
	TIME [epoch: 49.5 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.411126094605864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.411126094605864 | validation: 0.5266662672747312]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3670824039856281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3670824039856281 | validation: 0.5930723938355227]
	TIME [epoch: 21.2 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36134210749930196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36134210749930196 | validation: 0.5388888588891074]
	TIME [epoch: 21.2 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37706350288442136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37706350288442136 | validation: 0.5117601397305703]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742300639988584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3742300639988584 | validation: 0.5035422822341108]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37208250601821147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37208250601821147 | validation: 0.5217647768875844]
	TIME [epoch: 21.2 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36113001649576637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36113001649576637 | validation: 0.50552883676042]
	TIME [epoch: 21.1 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3575910273852629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3575910273852629 | validation: 0.45863331462607787]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312317679780939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3312317679780939 | validation: 0.4686405124354222]
	TIME [epoch: 21.2 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3291192864849944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3291192864849944 | validation: 0.43449987001555596]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32080716378956176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32080716378956176 | validation: 0.49377041295160656]
	TIME [epoch: 21.2 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33483617229426027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33483617229426027 | validation: 0.4306677662088104]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31778150055791377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31778150055791377 | validation: 0.4547964126233899]
	TIME [epoch: 21.2 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2986390585685615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2986390585685615 | validation: 0.41089269596419015]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31296523667868337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31296523667868337 | validation: 0.40940006604257134]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29599408390158966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29599408390158966 | validation: 0.43046311748551225]
	TIME [epoch: 21.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2983383416224274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2983383416224274 | validation: 0.3745234168123004]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.271699533585832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.271699533585832 | validation: 0.42835932710913277]
	TIME [epoch: 21.2 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2688092893000592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2688092893000592 | validation: 0.36900781649220477]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623710134477709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2623710134477709 | validation: 0.37077316133809557]
	TIME [epoch: 21.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26585673366276713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26585673366276713 | validation: 0.34862931156992877]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26269861985881754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26269861985881754 | validation: 0.33512840831527324]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2608585970777084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2608585970777084 | validation: 0.3327287860153676]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.244381018208535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.244381018208535 | validation: 0.3381865365809818]
	TIME [epoch: 21.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23380889514518258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23380889514518258 | validation: 0.3303387552548448]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25383733520411805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25383733520411805 | validation: 0.3302474126183237]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24387119971239096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24387119971239096 | validation: 0.3206671485281902]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21966566963033302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21966566963033302 | validation: 0.3196188144621697]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22601820873303255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22601820873303255 | validation: 0.308858509570469]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22561813274784548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22561813274784548 | validation: 0.2884134861345125]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.228857216854625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.228857216854625 | validation: 0.30423925745912334]
	TIME [epoch: 21.2 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22604193754266705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22604193754266705 | validation: 0.29709225842943204]
	TIME [epoch: 21.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23229500903648245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23229500903648245 | validation: 0.2904149739551435]
	TIME [epoch: 21.2 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2214079344013443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2214079344013443 | validation: 0.28000648865970207]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22604955089617995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22604955089617995 | validation: 0.27048890046288554]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21665964208783595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21665964208783595 | validation: 0.25224355476529714]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20590055283945147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20590055283945147 | validation: 0.2530744302260328]
	TIME [epoch: 21.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20829681665887684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20829681665887684 | validation: 0.26751502580774494]
	TIME [epoch: 21.2 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19362395451450667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19362395451450667 | validation: 0.24449730640852035]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18548103806060706		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.18548103806060706 | validation: 0.2833217418601074]
	TIME [epoch: 21.2 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20782612781758814		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.20782612781758814 | validation: 0.2551241335315222]
	TIME [epoch: 21.2 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17911368145243844		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.17911368145243844 | validation: 0.2453880916223486]
	TIME [epoch: 21.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20163277127572554		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.20163277127572554 | validation: 0.27956908934249797]
	TIME [epoch: 21.2 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1904407681699404		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.1904407681699404 | validation: 0.22638576659636225]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18498268196674833		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.18498268196674833 | validation: 0.22883544881113344]
	TIME [epoch: 21.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20057919842559624		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.20057919842559624 | validation: 0.26902162326448287]
	TIME [epoch: 21.2 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18377084916037806		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.18377084916037806 | validation: 0.22997940954349058]
	TIME [epoch: 21.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1813701298144949		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.1813701298144949 | validation: 0.2340689491232173]
	TIME [epoch: 21.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1956652619447282		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.1956652619447282 | validation: 0.2341567564806016]
	TIME [epoch: 21.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761763979928767		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.1761763979928767 | validation: 0.24547179329159743]
	TIME [epoch: 21.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1781431380719401		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.1781431380719401 | validation: 0.2296653961182808]
	TIME [epoch: 21.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18533455322793627		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.18533455322793627 | validation: 0.24541752439226183]
	TIME [epoch: 21.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17401996475361747		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.17401996475361747 | validation: 0.21985933182409217]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19469450562093785		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.19469450562093785 | validation: 0.22939493347706028]
	TIME [epoch: 21.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1858248064048313		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.1858248064048313 | validation: 0.22865441854246854]
	TIME [epoch: 21.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16613607266477987		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.16613607266477987 | validation: 0.22398416729185355]
	TIME [epoch: 21.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860713533660703		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.1860713533660703 | validation: 0.22808089327294434]
	TIME [epoch: 21.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16943023813814778		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.16943023813814778 | validation: 0.23824920722915988]
	TIME [epoch: 21.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17887892725188345		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.17887892725188345 | validation: 0.2512038394604467]
	TIME [epoch: 21.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18691476978856808		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.18691476978856808 | validation: 0.22567297204963055]
	TIME [epoch: 21.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17979343877807036		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.17979343877807036 | validation: 0.23702532529831616]
	TIME [epoch: 21.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1760515049490679		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.1760515049490679 | validation: 0.2763463538080637]
	TIME [epoch: 21.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750447574887588		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1750447574887588 | validation: 0.24098918344240983]
	TIME [epoch: 21.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16992840896547215		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.16992840896547215 | validation: 0.26746662112393993]
	TIME [epoch: 21.2 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19942973279465542		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.19942973279465542 | validation: 0.2292298435725881]
	TIME [epoch: 21.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17506169422955345		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.17506169422955345 | validation: 0.23319695117224506]
	TIME [epoch: 21.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17569944690901607		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.17569944690901607 | validation: 0.22386574749866764]
	TIME [epoch: 21.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1764856651697846		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.1764856651697846 | validation: 0.24104273957235944]
	TIME [epoch: 21.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708271875690909		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.1708271875690909 | validation: 0.2245712319245743]
	TIME [epoch: 21.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775341868875923		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1775341868875923 | validation: 0.24286123149477534]
	TIME [epoch: 21.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1801138625880352		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.1801138625880352 | validation: 0.23216497725576632]
	TIME [epoch: 21.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17748773800087436		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.17748773800087436 | validation: 0.23315816967888348]
	TIME [epoch: 21.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15936559805693334		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.15936559805693334 | validation: 0.21868854641006358]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1844676841537543		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.1844676841537543 | validation: 0.24234690019018695]
	TIME [epoch: 21.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17644626891075552		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.17644626891075552 | validation: 0.21186907657355272]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17043396654590062		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.17043396654590062 | validation: 0.24177675692931042]
	TIME [epoch: 21.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1710452321530412		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.1710452321530412 | validation: 0.2134878218598837]
	TIME [epoch: 21.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16237806893613835		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.16237806893613835 | validation: 0.22499193032991865]
	TIME [epoch: 21.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17144831475950317		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.17144831475950317 | validation: 0.26095944021317685]
	TIME [epoch: 21.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728568427344556		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.1728568427344556 | validation: 0.22709964859602091]
	TIME [epoch: 21.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17349117797499464		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.17349117797499464 | validation: 0.23316462431809037]
	TIME [epoch: 21.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18525447741762952		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.18525447741762952 | validation: 0.24366240364718256]
	TIME [epoch: 21.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1824950356559129		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.1824950356559129 | validation: 0.222196001258681]
	TIME [epoch: 21.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1693070413390727		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.1693070413390727 | validation: 0.21635224301675193]
	TIME [epoch: 21.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16452972962907775		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.16452972962907775 | validation: 0.21623818203766693]
	TIME [epoch: 21.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17922563458517496		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.17922563458517496 | validation: 0.25594940187126936]
	TIME [epoch: 21.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17055381276146558		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.17055381276146558 | validation: 0.2183953908858552]
	TIME [epoch: 21.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730251967092284		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1730251967092284 | validation: 0.2071025272227598]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18121270829486974		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.18121270829486974 | validation: 0.20969931931408056]
	TIME [epoch: 21.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616975766825817		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1616975766825817 | validation: 0.252915157419564]
	TIME [epoch: 21.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1802825719314126		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1802825719314126 | validation: 0.21580249352188668]
	TIME [epoch: 21.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15668416240505761		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.15668416240505761 | validation: 0.2661753535753755]
	TIME [epoch: 21.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1683498309310568		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.1683498309310568 | validation: 0.23052832896250647]
	TIME [epoch: 21.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17165097313906502		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.17165097313906502 | validation: 0.24351115589841515]
	TIME [epoch: 21.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17272822689521283		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.17272822689521283 | validation: 0.2132957467186149]
	TIME [epoch: 21.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16348779059348165		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.16348779059348165 | validation: 0.2143907784877605]
	TIME [epoch: 21.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16858208127242388		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.16858208127242388 | validation: 0.20477458983104396]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725841959912551		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.1725841959912551 | validation: 0.22015651658429441]
	TIME [epoch: 21.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17033239090868024		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.17033239090868024 | validation: 0.24027279508425925]
	TIME [epoch: 21.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721396637228799		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.1721396637228799 | validation: 0.24524238681435173]
	TIME [epoch: 21.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672939555265675		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.1672939555265675 | validation: 0.1935356913324204]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16924752021372935		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.16924752021372935 | validation: 0.2210047575595858]
	TIME [epoch: 21.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16514773756681694		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.16514773756681694 | validation: 0.22232478849790777]
	TIME [epoch: 21.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14598099943652507		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.14598099943652507 | validation: 0.22272372820742958]
	TIME [epoch: 21.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17293378889220393		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.17293378889220393 | validation: 0.2802498437791787]
	TIME [epoch: 21.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17207905133065102		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.17207905133065102 | validation: 0.19746014642404144]
	TIME [epoch: 21.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628118589741863		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1628118589741863 | validation: 0.21952237597873564]
	TIME [epoch: 21.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16138248178181236		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.16138248178181236 | validation: 0.2234233792474288]
	TIME [epoch: 21.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17482417259726923		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.17482417259726923 | validation: 0.2167532615685653]
	TIME [epoch: 21.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1665798327312139		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.1665798327312139 | validation: 0.2280815318929849]
	TIME [epoch: 21.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1567068112677555		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.1567068112677555 | validation: 0.19945894710386364]
	TIME [epoch: 21.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15479950172924545		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.15479950172924545 | validation: 0.21633287461261955]
	TIME [epoch: 21.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17339412775596993		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.17339412775596993 | validation: 0.1977162949739489]
	TIME [epoch: 21.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15805885348712168		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.15805885348712168 | validation: 0.19726777827999453]
	TIME [epoch: 21.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17084928241807243		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.17084928241807243 | validation: 0.19298122844530488]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15519629942799762		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.15519629942799762 | validation: 0.19599176964154294]
	TIME [epoch: 21.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1660096196912863		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.1660096196912863 | validation: 0.2118960196500661]
	TIME [epoch: 21.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512622333552552		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.1512622333552552 | validation: 0.2186517934771072]
	TIME [epoch: 21.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14609088817064378		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.14609088817064378 | validation: 0.2817970257200504]
	TIME [epoch: 21.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17361616909979227		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.17361616909979227 | validation: 0.20139469549427574]
	TIME [epoch: 21.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564337636310289		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.1564337636310289 | validation: 0.2131584401712571]
	TIME [epoch: 21.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14479472513116906		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.14479472513116906 | validation: 0.21326403618823248]
	TIME [epoch: 21.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718805149345048		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.1718805149345048 | validation: 0.2433342178641249]
	TIME [epoch: 21.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581602604033975		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.1581602604033975 | validation: 0.20554665434310843]
	TIME [epoch: 21.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152516890247147		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.152516890247147 | validation: 0.21550918991519552]
	TIME [epoch: 21.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15604720691453264		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.15604720691453264 | validation: 0.22379489585149706]
	TIME [epoch: 21.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15445253964544178		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.15445253964544178 | validation: 0.22671695231211986]
	TIME [epoch: 21.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16033752117859457		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.16033752117859457 | validation: 0.2295782540489953]
	TIME [epoch: 21.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528571904967964		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1528571904967964 | validation: 0.1954763440638551]
	TIME [epoch: 21.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14288932045334715		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.14288932045334715 | validation: 0.21707274274496574]
	TIME [epoch: 21.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15356391813973186		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.15356391813973186 | validation: 0.19478303696963517]
	TIME [epoch: 21.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14881948392303862		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.14881948392303862 | validation: 0.2115104119876567]
	TIME [epoch: 21.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15321017290387234		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.15321017290387234 | validation: 0.2317787369211324]
	TIME [epoch: 21.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15530306718747489		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.15530306718747489 | validation: 0.2026917843251202]
	TIME [epoch: 21.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15483174260992016		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.15483174260992016 | validation: 0.21133797164453333]
	TIME [epoch: 21.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14466472301217947		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.14466472301217947 | validation: 0.19293438914334968]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14761639879341376		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.14761639879341376 | validation: 0.2542235291519769]
	TIME [epoch: 21.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16373436613759937		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.16373436613759937 | validation: 0.20190666345158814]
	TIME [epoch: 21.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15355155912281737		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.15355155912281737 | validation: 0.23105980663181497]
	TIME [epoch: 21.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13889142231617374		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.13889142231617374 | validation: 0.2157311413910464]
	TIME [epoch: 21.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15349495038720978		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.15349495038720978 | validation: 0.23710879912019886]
	TIME [epoch: 21.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1447382278726724		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.1447382278726724 | validation: 0.19260458473194303]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14125644236352347		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.14125644236352347 | validation: 0.19697217504753]
	TIME [epoch: 21.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14818896328228304		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.14818896328228304 | validation: 0.1849185067874689]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1432293944433757		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.1432293944433757 | validation: 0.2161612236506664]
	TIME [epoch: 21.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14277057679215419		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.14277057679215419 | validation: 0.21296912517192002]
	TIME [epoch: 21.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14766151009122724		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.14766151009122724 | validation: 0.20735897592796979]
	TIME [epoch: 21.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14071725821893216		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.14071725821893216 | validation: 0.20674658353688866]
	TIME [epoch: 21.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15662514429781416		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.15662514429781416 | validation: 0.18567755830904595]
	TIME [epoch: 21.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14424278887082548		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.14424278887082548 | validation: 0.2261362575747558]
	TIME [epoch: 21.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512292115908965		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1512292115908965 | validation: 0.20715608034792318]
	TIME [epoch: 21.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155554745154654		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.155554745154654 | validation: 0.21223763536144447]
	TIME [epoch: 21.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15127544014283098		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.15127544014283098 | validation: 0.21183389508195505]
	TIME [epoch: 21.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1545675651504178		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.1545675651504178 | validation: 0.1814611885241564]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15212040367019003		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.15212040367019003 | validation: 0.2094221352273276]
	TIME [epoch: 21.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13877832554671382		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.13877832554671382 | validation: 0.2146547222005533]
	TIME [epoch: 21.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.144118395254702		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.144118395254702 | validation: 0.22342014127415855]
	TIME [epoch: 21.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632732688274307		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.1632732688274307 | validation: 0.2264894283209451]
	TIME [epoch: 21.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15939128165515284		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.15939128165515284 | validation: 0.18846447892113913]
	TIME [epoch: 21.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13536504079482187		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.13536504079482187 | validation: 0.21389951496439433]
	TIME [epoch: 21.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1450743400299481		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.1450743400299481 | validation: 0.1876498095661385]
	TIME [epoch: 21.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15978709271100539		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.15978709271100539 | validation: 0.1869251086189651]
	TIME [epoch: 21.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1329750364891804		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.1329750364891804 | validation: 0.20972448317244619]
	TIME [epoch: 21.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13715573488735616		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.13715573488735616 | validation: 0.1928210352965822]
	TIME [epoch: 21.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14251082778208385		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.14251082778208385 | validation: 0.20152820437675717]
	TIME [epoch: 21.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15269103653512314		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.15269103653512314 | validation: 0.19279320203217615]
	TIME [epoch: 21.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1428717087949781		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1428717087949781 | validation: 0.181749284433699]
	TIME [epoch: 21.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559139484183214		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1559139484183214 | validation: 0.19224562156344271]
	TIME [epoch: 21.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14556483836730155		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.14556483836730155 | validation: 0.185915672366184]
	TIME [epoch: 21.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13055826514688013		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.13055826514688013 | validation: 0.2245050544252821]
	TIME [epoch: 21.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14092446092825694		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.14092446092825694 | validation: 0.19039000140934412]
	TIME [epoch: 21.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14558068471052948		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.14558068471052948 | validation: 0.20613300316152372]
	TIME [epoch: 21.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541738202463666		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.13541738202463666 | validation: 0.20012013292755906]
	TIME [epoch: 21.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13632260816241493		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.13632260816241493 | validation: 0.19527614968059184]
	TIME [epoch: 21.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15601493420595453		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.15601493420595453 | validation: 0.18545541351196054]
	TIME [epoch: 21.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13555053325308394		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.13555053325308394 | validation: 0.18740055594231433]
	TIME [epoch: 21.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1323515374152344		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.1323515374152344 | validation: 0.19143766849690208]
	TIME [epoch: 21.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14706944668849686		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.14706944668849686 | validation: 0.2043512840942575]
	TIME [epoch: 21.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1365060670223842		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1365060670223842 | validation: 0.21812976637962317]
	TIME [epoch: 21.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14875555328222484		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.14875555328222484 | validation: 0.19413100207562284]
	TIME [epoch: 21.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1472027617185336		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.1472027617185336 | validation: 0.19520645235939918]
	TIME [epoch: 21.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14088777607024822		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.14088777607024822 | validation: 0.19863133653928705]
	TIME [epoch: 21.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14502927252121048		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.14502927252121048 | validation: 0.17189667370266745]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14472137307536345		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.14472137307536345 | validation: 0.1767829421819816]
	TIME [epoch: 21.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14247562109271267		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.14247562109271267 | validation: 0.20472937423967433]
	TIME [epoch: 21.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1436157430171606		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.1436157430171606 | validation: 0.18955931432332873]
	TIME [epoch: 21.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13513513348694747		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.13513513348694747 | validation: 0.18838347557439983]
	TIME [epoch: 21.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13564113594097044		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.13564113594097044 | validation: 0.19082627195968727]
	TIME [epoch: 21.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13965518646002945		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.13965518646002945 | validation: 0.20028623347371002]
	TIME [epoch: 21.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13794534010821385		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.13794534010821385 | validation: 0.23924886082514343]
	TIME [epoch: 21.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14456354944649177		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.14456354944649177 | validation: 0.19309134554051138]
	TIME [epoch: 21.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13112261569960293		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.13112261569960293 | validation: 0.17634149041272312]
	TIME [epoch: 21.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13124228824759124		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.13124228824759124 | validation: 0.21412244643643188]
	TIME [epoch: 21.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14365468911192317		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.14365468911192317 | validation: 0.18575870432083694]
	TIME [epoch: 21.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1364709546081214		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1364709546081214 | validation: 0.1808385373839999]
	TIME [epoch: 21.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1470328464196131		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.1470328464196131 | validation: 0.20096929863525162]
	TIME [epoch: 21.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.138628118318093		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.138628118318093 | validation: 0.1962845137885225]
	TIME [epoch: 21.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14414953284663495		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.14414953284663495 | validation: 0.22272524185918746]
	TIME [epoch: 21.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.140557143630265		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.140557143630265 | validation: 0.17580451874375339]
	TIME [epoch: 21.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1364440996286739		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.1364440996286739 | validation: 0.18986600373077117]
	TIME [epoch: 21.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1400546292557625		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1400546292557625 | validation: 0.19383296590405702]
	TIME [epoch: 21.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13955665060860892		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.13955665060860892 | validation: 0.1903312921162635]
	TIME [epoch: 21.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128872662825256		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.128872662825256 | validation: 0.18601653436695215]
	TIME [epoch: 21.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13437705053322668		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.13437705053322668 | validation: 0.19268484328373728]
	TIME [epoch: 21.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12440893770138908		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.12440893770138908 | validation: 0.18293591777460463]
	TIME [epoch: 21.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14172012811294965		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.14172012811294965 | validation: 0.19725241745731148]
	TIME [epoch: 21.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14503794006075924		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.14503794006075924 | validation: 0.20939774598994135]
	TIME [epoch: 21.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443173156679652		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1443173156679652 | validation: 0.19372108126475795]
	TIME [epoch: 21.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13662737506926956		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.13662737506926956 | validation: 0.21208872462219644]
	TIME [epoch: 21.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1491191166730324		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.1491191166730324 | validation: 0.1781898451196002]
	TIME [epoch: 21.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14340810018431155		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.14340810018431155 | validation: 0.22756560032968784]
	TIME [epoch: 21.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13335239286776263		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.13335239286776263 | validation: 0.1833201663898554]
	TIME [epoch: 21.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1397240736574576		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.1397240736574576 | validation: 0.22002120694566074]
	TIME [epoch: 21.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12601721926119752		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.12601721926119752 | validation: 0.18015999006960362]
	TIME [epoch: 21.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13535702422447074		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.13535702422447074 | validation: 0.19205906132546255]
	TIME [epoch: 21.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13034629024690592		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.13034629024690592 | validation: 0.20427673665664056]
	TIME [epoch: 21.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14390744659214033		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.14390744659214033 | validation: 0.17807484241290822]
	TIME [epoch: 21.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12037947793596548		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.12037947793596548 | validation: 0.18598233445170892]
	TIME [epoch: 21.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13940550249287195		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.13940550249287195 | validation: 0.21297301936405166]
	TIME [epoch: 21.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12958356089118764		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.12958356089118764 | validation: 0.20407978127671486]
	TIME [epoch: 21.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1398397745052994		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1398397745052994 | validation: 0.19604097707025533]
	TIME [epoch: 21.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13703901253637718		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.13703901253637718 | validation: 0.19078433353003274]
	TIME [epoch: 21.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12579267967312938		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.12579267967312938 | validation: 0.17435616665951473]
	TIME [epoch: 21.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13186625509656522		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.13186625509656522 | validation: 0.20194767434063232]
	TIME [epoch: 21.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13966246881933106		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.13966246881933106 | validation: 0.17703335096779332]
	TIME [epoch: 21.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12517546916973904		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.12517546916973904 | validation: 0.207050967504835]
	TIME [epoch: 21.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13690280337605815		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.13690280337605815 | validation: 0.17079256005263357]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1420818908681034		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.1420818908681034 | validation: 0.1815584002355712]
	TIME [epoch: 21.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13927164642697434		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.13927164642697434 | validation: 0.17556109905722883]
	TIME [epoch: 21.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13680983434387967		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.13680983434387967 | validation: 0.17877909713890153]
	TIME [epoch: 21.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13545388627527613		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.13545388627527613 | validation: 0.19654809549513008]
	TIME [epoch: 21.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13324378387363306		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.13324378387363306 | validation: 0.2090327610410975]
	TIME [epoch: 21.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13159772668284747		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.13159772668284747 | validation: 0.19389067371436958]
	TIME [epoch: 21.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1351943255833517		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.1351943255833517 | validation: 0.2156557316524806]
	TIME [epoch: 21.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13988476365437857		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.13988476365437857 | validation: 0.1773688208866933]
	TIME [epoch: 21.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13614643554421213		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.13614643554421213 | validation: 0.18616705395804167]
	TIME [epoch: 21.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13515248638881272		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.13515248638881272 | validation: 0.18474994401777659]
	TIME [epoch: 21.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1307511686968322		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.1307511686968322 | validation: 0.17206135694225716]
	TIME [epoch: 21.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12538473231096123		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.12538473231096123 | validation: 0.20037419724906277]
	TIME [epoch: 21.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1310932586937175		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1310932586937175 | validation: 0.18736618531974572]
	TIME [epoch: 21.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14091309238826438		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.14091309238826438 | validation: 0.18878266752026945]
	TIME [epoch: 21.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14584725611020016		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.14584725611020016 | validation: 0.18484427308633322]
	TIME [epoch: 21.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13834699352668828		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.13834699352668828 | validation: 0.1829080389117591]
	TIME [epoch: 21.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12795855073354173		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.12795855073354173 | validation: 0.17558698731120212]
	TIME [epoch: 21.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12750326865928846		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.12750326865928846 | validation: 0.18647539918899164]
	TIME [epoch: 21.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13670206199184587		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.13670206199184587 | validation: 0.16944178551501102]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13386579608539878		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.13386579608539878 | validation: 0.19799698449750014]
	TIME [epoch: 21.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13753715418442575		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.13753715418442575 | validation: 0.1781426787380238]
	TIME [epoch: 21.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13723698573949245		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.13723698573949245 | validation: 0.20116094683396016]
	TIME [epoch: 21.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13377440667489687		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.13377440667489687 | validation: 0.18865042370646307]
	TIME [epoch: 21.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14538363449724145		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.14538363449724145 | validation: 0.1860163001626288]
	TIME [epoch: 21.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1314012934531846		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1314012934531846 | validation: 0.1973473623314026]
	TIME [epoch: 21.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128726372527266		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.128726372527266 | validation: 0.19188457776149043]
	TIME [epoch: 21.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1345046960771776		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.1345046960771776 | validation: 0.18473831621543851]
	TIME [epoch: 21.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12609116821299335		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.12609116821299335 | validation: 0.19818090241007544]
	TIME [epoch: 21.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304823184438716		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1304823184438716 | validation: 0.18953314606563051]
	TIME [epoch: 21.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12373472531405408		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.12373472531405408 | validation: 0.17742731633060815]
	TIME [epoch: 21.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13246017840029306		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.13246017840029306 | validation: 0.19396948466925829]
	TIME [epoch: 21.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13660502828567062		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.13660502828567062 | validation: 0.2048242819232451]
	TIME [epoch: 21.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13396030423359648		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.13396030423359648 | validation: 0.1902970918942418]
	TIME [epoch: 21.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13458200476618978		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.13458200476618978 | validation: 0.2327298245195113]
	TIME [epoch: 21.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1499718984275251		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.1499718984275251 | validation: 0.18566506217027248]
	TIME [epoch: 21.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13505289005401844		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.13505289005401844 | validation: 0.18369699567851672]
	TIME [epoch: 21.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1341942054050034		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.1341942054050034 | validation: 0.18127066214132626]
	TIME [epoch: 21.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13061453852453644		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.13061453852453644 | validation: 0.22578943256226588]
	TIME [epoch: 21.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13269930710708616		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.13269930710708616 | validation: 0.1941801194409037]
	TIME [epoch: 21.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13642301768017948		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.13642301768017948 | validation: 0.17235138927162577]
	TIME [epoch: 21.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12588779279725756		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.12588779279725756 | validation: 0.16771443471632552]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13017912731838877		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.13017912731838877 | validation: 0.20351405628184127]
	TIME [epoch: 21.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13911757374181818		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.13911757374181818 | validation: 0.18232238016661526]
	TIME [epoch: 21.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1323659989999268		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1323659989999268 | validation: 0.1910289273634044]
	TIME [epoch: 21.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12659211889615363		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.12659211889615363 | validation: 0.18981639050640398]
	TIME [epoch: 21.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1315718301550327		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1315718301550327 | validation: 0.17395176446544305]
	TIME [epoch: 21.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14450354278973973		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.14450354278973973 | validation: 0.1855905312567204]
	TIME [epoch: 21.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12726140558482502		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.12726140558482502 | validation: 0.2007420511202968]
	TIME [epoch: 21.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13283119866680573		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.13283119866680573 | validation: 0.20529667460213646]
	TIME [epoch: 21.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13627105213153062		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.13627105213153062 | validation: 0.18398879211885544]
	TIME [epoch: 21.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11528191285266223		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.11528191285266223 | validation: 0.2159352506060953]
	TIME [epoch: 21.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12475083228755177		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.12475083228755177 | validation: 0.1768798267366679]
	TIME [epoch: 21.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13115733831605617		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.13115733831605617 | validation: 0.19002755175988156]
	TIME [epoch: 21.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12565055027943128		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.12565055027943128 | validation: 0.20142333921124006]
	TIME [epoch: 21.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12417231746020466		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.12417231746020466 | validation: 0.18336476767443768]
	TIME [epoch: 21.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1281572462043267		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1281572462043267 | validation: 0.20726668365288536]
	TIME [epoch: 21.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13044937315539226		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.13044937315539226 | validation: 0.1909462402178636]
	TIME [epoch: 21.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1345038756890876		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.1345038756890876 | validation: 0.1822654776299357]
	TIME [epoch: 21.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14019048379834378		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.14019048379834378 | validation: 0.18463079031703658]
	TIME [epoch: 21.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12140434127027536		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.12140434127027536 | validation: 0.19866147814588225]
	TIME [epoch: 21.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13195535476835968		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.13195535476835968 | validation: 0.18761401079121406]
	TIME [epoch: 21.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12669243596373156		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.12669243596373156 | validation: 0.17611204515878218]
	TIME [epoch: 21.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12965918860737924		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.12965918860737924 | validation: 0.19901928615205566]
	TIME [epoch: 21.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1281841312052332		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1281841312052332 | validation: 0.18482699672376227]
	TIME [epoch: 21.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1329497525407244		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.1329497525407244 | validation: 0.18331359245702086]
	TIME [epoch: 21.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12940714139083323		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.12940714139083323 | validation: 0.19103663411131547]
	TIME [epoch: 21.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13526700521048807		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.13526700521048807 | validation: 0.1753951578959761]
	TIME [epoch: 21.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12864738978200804		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.12864738978200804 | validation: 0.19031397666429217]
	TIME [epoch: 21.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12951907653694886		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.12951907653694886 | validation: 0.1808332946190976]
	TIME [epoch: 21.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1349170010091553		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.1349170010091553 | validation: 0.1852306976829622]
	TIME [epoch: 21.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12278551329133243		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.12278551329133243 | validation: 0.19288404252693583]
	TIME [epoch: 21.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13543495495225785		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.13543495495225785 | validation: 0.191911451161518]
	TIME [epoch: 21.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12239386161387526		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.12239386161387526 | validation: 0.19637740971327505]
	TIME [epoch: 21.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1335435176701169		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1335435176701169 | validation: 0.18294591948360855]
	TIME [epoch: 21.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12726841361441316		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.12726841361441316 | validation: 0.19358692256925664]
	TIME [epoch: 21.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13189128472992756		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.13189128472992756 | validation: 0.19561737058625994]
	TIME [epoch: 21.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13308473238522658		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.13308473238522658 | validation: 0.20157031011912985]
	TIME [epoch: 21.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13419727532053566		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.13419727532053566 | validation: 0.19088869455656718]
	TIME [epoch: 21.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12668684027942634		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.12668684027942634 | validation: 0.18203301290969187]
	TIME [epoch: 21.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12999362659277972		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.12999362659277972 | validation: 0.2126388518891854]
	TIME [epoch: 21.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12707441254678595		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.12707441254678595 | validation: 0.21191158854613118]
	TIME [epoch: 21.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14346586461300764		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.14346586461300764 | validation: 0.19215695023992707]
	TIME [epoch: 21.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14029284153002142		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.14029284153002142 | validation: 0.1753606661669897]
	TIME [epoch: 21.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1322625145965265		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1322625145965265 | validation: 0.18780028287129946]
	TIME [epoch: 21.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12653462556743117		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.12653462556743117 | validation: 0.19387026438298546]
	TIME [epoch: 21.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12854494628988195		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.12854494628988195 | validation: 0.18518259457200323]
	TIME [epoch: 21.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1190536003836283		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.1190536003836283 | validation: 0.19009851073714357]
	TIME [epoch: 21.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14573117684661796		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.14573117684661796 | validation: 0.17922561849630103]
	TIME [epoch: 21.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13516733941085496		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.13516733941085496 | validation: 0.18541520491386299]
	TIME [epoch: 21.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13242646383813572		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.13242646383813572 | validation: 0.19187643304319907]
	TIME [epoch: 21.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12614572475626465		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.12614572475626465 | validation: 0.17758340060440558]
	TIME [epoch: 21.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1284555323733315		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1284555323733315 | validation: 0.19294437201510029]
	TIME [epoch: 21.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12164725281539583		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.12164725281539583 | validation: 0.18133374859687665]
	TIME [epoch: 21.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12771983313326613		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.12771983313326613 | validation: 0.1962803503056547]
	TIME [epoch: 21.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12403578895053946		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.12403578895053946 | validation: 0.17005860542793758]
	TIME [epoch: 21.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13783399260706722		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.13783399260706722 | validation: 0.17265607392515914]
	TIME [epoch: 21.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1145828992991393		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.1145828992991393 | validation: 0.1689954668409654]
	TIME [epoch: 21.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13217858242840536		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.13217858242840536 | validation: 0.18443771356834648]
	TIME [epoch: 21.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342970057934533		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1342970057934533 | validation: 0.1840204605868796]
	TIME [epoch: 21.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11771822511216228		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.11771822511216228 | validation: 0.17520324822530076]
	TIME [epoch: 21.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12176565358366076		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.12176565358366076 | validation: 0.18657105736694646]
	TIME [epoch: 21.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13188186818005115		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.13188186818005115 | validation: 0.17971439682495075]
	TIME [epoch: 21.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12593776394195738		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.12593776394195738 | validation: 0.16799561338903157]
	TIME [epoch: 21.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13445244893934477		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.13445244893934477 | validation: 0.19265888115004298]
	TIME [epoch: 21.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1309248517210177		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.1309248517210177 | validation: 0.175223862174558]
	TIME [epoch: 21.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14264963384153728		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.14264963384153728 | validation: 0.1812191550476175]
	TIME [epoch: 21.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12261242855683148		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.12261242855683148 | validation: 0.1781961666478817]
	TIME [epoch: 21.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1281950635709785		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1281950635709785 | validation: 0.1883593619000512]
	TIME [epoch: 21.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11841774887814668		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.11841774887814668 | validation: 0.17111147296884552]
	TIME [epoch: 21.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128871342709298		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.128871342709298 | validation: 0.18008764581127185]
	TIME [epoch: 21.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13181775973384094		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.13181775973384094 | validation: 0.1895229751222391]
	TIME [epoch: 21.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12363290652261161		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.12363290652261161 | validation: 0.18925005868793518]
	TIME [epoch: 21.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12757696842995586		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.12757696842995586 | validation: 0.21179596106551946]
	TIME [epoch: 21.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1263631362560049		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1263631362560049 | validation: 0.1890515013536812]
	TIME [epoch: 21.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12643323597650916		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.12643323597650916 | validation: 0.18418282867008345]
	TIME [epoch: 21.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11690977993434773		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.11690977993434773 | validation: 0.18150446394049768]
	TIME [epoch: 21.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13163846450091862		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.13163846450091862 | validation: 0.16652359957630752]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12910311657146287		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.12910311657146287 | validation: 0.19012837810857686]
	TIME [epoch: 21.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1235653916491144		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1235653916491144 | validation: 0.1847449145374231]
	TIME [epoch: 21.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12099775658706684		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.12099775658706684 | validation: 0.18221303708793224]
	TIME [epoch: 21.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12485171196706127		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.12485171196706127 | validation: 0.17939613931703274]
	TIME [epoch: 21.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1232894863362243		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.1232894863362243 | validation: 0.19825564857919026]
	TIME [epoch: 21.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12592440023607257		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.12592440023607257 | validation: 0.170841741025968]
	TIME [epoch: 21.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12795193188929715		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.12795193188929715 | validation: 0.16986405698452642]
	TIME [epoch: 21.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12614577870492177		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12614577870492177 | validation: 0.17941595297635815]
	TIME [epoch: 21.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12262714280574186		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.12262714280574186 | validation: 0.18970875739078774]
	TIME [epoch: 21.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11938661919999789		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.11938661919999789 | validation: 0.19409287623712324]
	TIME [epoch: 21.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12338541427345455		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.12338541427345455 | validation: 0.18021933393380607]
	TIME [epoch: 21.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12909231955157882		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.12909231955157882 | validation: 0.184827433203252]
	TIME [epoch: 21.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1267317120222864		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1267317120222864 | validation: 0.17559176254757392]
	TIME [epoch: 21.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12747718348403964		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.12747718348403964 | validation: 0.17330084870116044]
	TIME [epoch: 21.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1262134658233011		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1262134658233011 | validation: 0.17833569249595851]
	TIME [epoch: 21.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1280651879241349		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1280651879241349 | validation: 0.17898764809662016]
	TIME [epoch: 21.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12688230643510578		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.12688230643510578 | validation: 0.16111895105727458]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1172183569837673		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.1172183569837673 | validation: 0.20155289252379738]
	TIME [epoch: 21.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.120029219070798		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.120029219070798 | validation: 0.167180886572482]
	TIME [epoch: 21.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11860265225866529		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.11860265225866529 | validation: 0.1920994097740108]
	TIME [epoch: 21.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12034675210749582		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.12034675210749582 | validation: 0.17990427356030758]
	TIME [epoch: 21.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12882733748052083		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.12882733748052083 | validation: 0.17837214593797873]
	TIME [epoch: 21.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1288684346293143		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1288684346293143 | validation: 0.1860195845680193]
	TIME [epoch: 21.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11846115587825348		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11846115587825348 | validation: 0.17852472840738337]
	TIME [epoch: 21.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.120261217833503		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.120261217833503 | validation: 0.17281773652061355]
	TIME [epoch: 21.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12491757510379808		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.12491757510379808 | validation: 0.18611809885897287]
	TIME [epoch: 21.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12602050291130099		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.12602050291130099 | validation: 0.17053793165167713]
	TIME [epoch: 21.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1119822431597016		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.1119822431597016 | validation: 0.2103889537866756]
	TIME [epoch: 21.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11906599714731914		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.11906599714731914 | validation: 0.18731195392605338]
	TIME [epoch: 21.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12017803368186397		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.12017803368186397 | validation: 0.1865576913731986]
	TIME [epoch: 21.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1244369598931883		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1244369598931883 | validation: 0.18548664792202]
	TIME [epoch: 21.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1243155849280145		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1243155849280145 | validation: 0.1739794768917717]
	TIME [epoch: 21.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253313755114681		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.1253313755114681 | validation: 0.1885874507175997]
	TIME [epoch: 21.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11710185181260344		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.11710185181260344 | validation: 0.1826678288834157]
	TIME [epoch: 21.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1345030113482631		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1345030113482631 | validation: 0.18319951263676176]
	TIME [epoch: 21.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12435287654591524		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.12435287654591524 | validation: 0.19516327491694213]
	TIME [epoch: 21.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12720392344391668		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.12720392344391668 | validation: 0.1835143878673886]
	TIME [epoch: 21.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12317819851615726		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.12317819851615726 | validation: 0.1925169906026667]
	TIME [epoch: 21.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12713362454332866		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.12713362454332866 | validation: 0.17423035424011252]
	TIME [epoch: 21.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12044733110824749		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.12044733110824749 | validation: 0.18647281762590237]
	TIME [epoch: 21.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12424596320694759		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.12424596320694759 | validation: 0.17561283090465396]
	TIME [epoch: 21.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11352157319149334		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.11352157319149334 | validation: 0.16504010185158555]
	TIME [epoch: 21.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12291762982632157		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.12291762982632157 | validation: 0.20588353485419314]
	TIME [epoch: 21.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12745326129339324		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.12745326129339324 | validation: 0.18918748949789718]
	TIME [epoch: 21.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12308640664812484		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.12308640664812484 | validation: 0.17697723583068362]
	TIME [epoch: 21.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12700905425042927		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.12700905425042927 | validation: 0.19469153363059627]
	TIME [epoch: 21.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12471070650831106		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.12471070650831106 | validation: 0.169168620049641]
	TIME [epoch: 21.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276227352956783		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.1276227352956783 | validation: 0.18612316702491782]
	TIME [epoch: 21.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12329911916994436		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.12329911916994436 | validation: 0.17413233149795196]
	TIME [epoch: 21.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1271756395789774		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1271756395789774 | validation: 0.19123425233260313]
	TIME [epoch: 21.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11851483129132752		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.11851483129132752 | validation: 0.17659298743749208]
	TIME [epoch: 21.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.124606673667977		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.124606673667977 | validation: 0.17379942691261463]
	TIME [epoch: 21.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11794291989732875		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.11794291989732875 | validation: 0.16804244532737075]
	TIME [epoch: 21.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11564216774240525		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.11564216774240525 | validation: 0.17052078880865387]
	TIME [epoch: 21.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11373480707742072		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.11373480707742072 | validation: 0.18441506898176574]
	TIME [epoch: 21.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12432851854194567		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.12432851854194567 | validation: 0.18926442378262348]
	TIME [epoch: 21.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11868094368234387		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.11868094368234387 | validation: 0.1910518592550386]
	TIME [epoch: 21.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12396311232093778		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.12396311232093778 | validation: 0.1670815572166624]
	TIME [epoch: 21.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12419505950766507		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.12419505950766507 | validation: 0.17207985095091827]
	TIME [epoch: 21.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12125012455180606		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.12125012455180606 | validation: 0.18794828283552317]
	TIME [epoch: 21.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1129619323626733		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.1129619323626733 | validation: 0.20096576802437427]
	TIME [epoch: 21.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12946036877159062		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.12946036877159062 | validation: 0.18191667916605903]
	TIME [epoch: 21.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11925083119565556		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.11925083119565556 | validation: 0.17230686054221356]
	TIME [epoch: 21.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12208899948471481		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.12208899948471481 | validation: 0.1759145998358559]
	TIME [epoch: 21.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12506310123499315		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.12506310123499315 | validation: 0.18362040032753849]
	TIME [epoch: 21.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12034475039082067		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.12034475039082067 | validation: 0.1680976927927871]
	TIME [epoch: 21.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1274621914499628		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1274621914499628 | validation: 0.17604731765277942]
	TIME [epoch: 21.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12176705546354812		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.12176705546354812 | validation: 0.18245958757213887]
	TIME [epoch: 21.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1312780770793538		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.1312780770793538 | validation: 0.15552639050973927]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1212655201564909		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.1212655201564909 | validation: 0.17668339942317113]
	TIME [epoch: 21.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11604771988558338		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.11604771988558338 | validation: 0.185317794249823]
	TIME [epoch: 21.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12089092515319652		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.12089092515319652 | validation: 0.1812547123833709]
	TIME [epoch: 21.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1125021726173409		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1125021726173409 | validation: 0.1929452316537635]
	TIME [epoch: 21.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12246217782551116		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.12246217782551116 | validation: 0.21053509060395859]
	TIME [epoch: 21.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12869205604610215		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.12869205604610215 | validation: 0.18135847733032082]
	TIME [epoch: 21.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11544287515112064		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.11544287515112064 | validation: 0.1837580181643685]
	TIME [epoch: 21.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11668003594807871		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.11668003594807871 | validation: 0.17838020086456727]
	TIME [epoch: 21.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13165625201476133		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.13165625201476133 | validation: 0.1865589458591661]
	TIME [epoch: 21.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270090725337367		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1270090725337367 | validation: 0.17280410386895545]
	TIME [epoch: 21.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11795032929265722		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.11795032929265722 | validation: 0.1767514786504783]
	TIME [epoch: 21.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12108436424801168		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.12108436424801168 | validation: 0.17918483585353986]
	TIME [epoch: 21.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11852062559799445		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.11852062559799445 | validation: 0.18753449590898721]
	TIME [epoch: 21.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12170307624406526		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.12170307624406526 | validation: 0.19350996933877215]
	TIME [epoch: 21.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11976054576876068		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.11976054576876068 | validation: 0.1680866986270318]
	TIME [epoch: 21.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11585401923198288		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.11585401923198288 | validation: 0.1666304728812131]
	TIME [epoch: 21.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12854972440481477		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.12854972440481477 | validation: 0.17474333612905202]
	TIME [epoch: 21.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11687363469851722		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.11687363469851722 | validation: 0.18801917908374383]
	TIME [epoch: 21.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12506141883855243		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.12506141883855243 | validation: 0.16819704185388798]
	TIME [epoch: 21.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11789565767778028		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.11789565767778028 | validation: 0.17971771334305472]
	TIME [epoch: 21.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1199983621260901		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.1199983621260901 | validation: 0.18214760226815058]
	TIME [epoch: 21.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11802037242917784		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.11802037242917784 | validation: 0.1755208608022205]
	TIME [epoch: 21.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1128665387782184		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1128665387782184 | validation: 0.18382800123134668]
	TIME [epoch: 21.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12927414209744392		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.12927414209744392 | validation: 0.18499642361576946]
	TIME [epoch: 21.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1177352239492171		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.1177352239492171 | validation: 0.17983039910531054]
	TIME [epoch: 21.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1160952591252494		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1160952591252494 | validation: 0.1779777491393462]
	TIME [epoch: 21.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11634507226213357		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.11634507226213357 | validation: 0.17253247282367445]
	TIME [epoch: 21.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12482521202519688		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.12482521202519688 | validation: 0.1764308318455991]
	TIME [epoch: 21.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11300022452593017		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.11300022452593017 | validation: 0.17970336305715476]
	TIME [epoch: 21.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1256454818391128		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1256454818391128 | validation: 0.17730470804247964]
	TIME [epoch: 21.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1251190459931098		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.1251190459931098 | validation: 0.15814484952046115]
	TIME [epoch: 21.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252143313947519		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.1252143313947519 | validation: 0.1757623856392691]
	TIME [epoch: 21.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12634457868668975		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.12634457868668975 | validation: 0.18421650052218697]
	TIME [epoch: 21.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12473540108529421		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.12473540108529421 | validation: 0.17986212118217398]
	TIME [epoch: 21.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12524653417446951		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12524653417446951 | validation: 0.18345965651771146]
	TIME [epoch: 21.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11395860142687186		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.11395860142687186 | validation: 0.1785236118283322]
	TIME [epoch: 21.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12708313785910158		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.12708313785910158 | validation: 0.18929335784574544]
	TIME [epoch: 21.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12242422848277383		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.12242422848277383 | validation: 0.1655656738661448]
	TIME [epoch: 21.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1289112894378853		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.1289112894378853 | validation: 0.16844921449962416]
	TIME [epoch: 21.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11296135649780144		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.11296135649780144 | validation: 0.17485289558776707]
	TIME [epoch: 21.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12002134766219434		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.12002134766219434 | validation: 0.18121794290611187]
	TIME [epoch: 21.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11800652633748002		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.11800652633748002 | validation: 0.18931882658560933]
	TIME [epoch: 21.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12164370165685683		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.12164370165685683 | validation: 0.17295452782230417]
	TIME [epoch: 21.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11284682186001911		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.11284682186001911 | validation: 0.17919329986383034]
	TIME [epoch: 21.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11778346836065937		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.11778346836065937 | validation: 0.17401631273475726]
	TIME [epoch: 21.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11395821857086183		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.11395821857086183 | validation: 0.16945755335091633]
	TIME [epoch: 21.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12661232127654523		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.12661232127654523 | validation: 0.18083246680565557]
	TIME [epoch: 21.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12120317149631421		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.12120317149631421 | validation: 0.18218748784541508]
	TIME [epoch: 21.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12411495065946516		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.12411495065946516 | validation: 0.17279810241013543]
	TIME [epoch: 21.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12087688488348147		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.12087688488348147 | validation: 0.18242852536408105]
	TIME [epoch: 21.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1234744519280698		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1234744519280698 | validation: 0.19251180766472675]
	TIME [epoch: 21.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1284623566802545		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.1284623566802545 | validation: 0.1680511211484248]
	TIME [epoch: 21.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11989609187571867		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.11989609187571867 | validation: 0.17370331784614984]
	TIME [epoch: 21.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12173270732029165		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12173270732029165 | validation: 0.17459909895393724]
	TIME [epoch: 21.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1219819319512216		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1219819319512216 | validation: 0.16097519626963286]
	TIME [epoch: 21.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11799296810755541		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.11799296810755541 | validation: 0.1735371777690097]
	TIME [epoch: 21.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12100797773860408		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.12100797773860408 | validation: 0.1718384752493602]
	TIME [epoch: 21.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1192105093935019		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.1192105093935019 | validation: 0.17324892681683127]
	TIME [epoch: 21.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11142181350207166		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.11142181350207166 | validation: 0.18278147718532914]
	TIME [epoch: 21.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12322052139350936		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.12322052139350936 | validation: 0.1797508549476657]
	TIME [epoch: 21.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1250145268269493		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.1250145268269493 | validation: 0.16846383680917232]
	TIME [epoch: 21.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12883684307605753		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.12883684307605753 | validation: 0.19146927432477717]
	TIME [epoch: 21.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11815066813727512		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.11815066813727512 | validation: 0.16607134171216237]
	TIME [epoch: 21.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11548421510329794		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.11548421510329794 | validation: 0.17478357297383462]
	TIME [epoch: 21.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11387626325889044		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.11387626325889044 | validation: 0.18201448636698928]
	TIME [epoch: 21.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12473647033785347		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.12473647033785347 | validation: 0.1702973457310797]
	TIME [epoch: 21.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11497231104685104		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.11497231104685104 | validation: 0.17886530517282273]
	TIME [epoch: 21.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10600298747805312		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.10600298747805312 | validation: 0.16877546963426138]
	TIME [epoch: 21.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1143691207427912		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.1143691207427912 | validation: 0.17515376389941217]
	TIME [epoch: 21.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11871246109657614		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.11871246109657614 | validation: 0.16471030039875528]
	TIME [epoch: 21.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11856233631038968		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.11856233631038968 | validation: 0.1834532295547181]
	TIME [epoch: 21.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12513990151628368		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.12513990151628368 | validation: 0.16827980749829324]
	TIME [epoch: 21.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12709507231034425		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.12709507231034425 | validation: 0.16582548226054747]
	TIME [epoch: 21.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1245629312147517		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1245629312147517 | validation: 0.17395104524371838]
	TIME [epoch: 21.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11080776332404571		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.11080776332404571 | validation: 0.18143356215234674]
	TIME [epoch: 21.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11946329595182215		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.11946329595182215 | validation: 0.183979485620253]
	TIME [epoch: 21.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11252284655428631		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.11252284655428631 | validation: 0.17831596865475263]
	TIME [epoch: 21.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12521914390512046		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.12521914390512046 | validation: 0.1815625066059781]
	TIME [epoch: 21.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1267690523819714		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.1267690523819714 | validation: 0.1772913565687469]
	TIME [epoch: 21.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.117469107095946		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.117469107095946 | validation: 0.1690543567410882]
	TIME [epoch: 21.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11489580265502461		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.11489580265502461 | validation: 0.167004983199533]
	TIME [epoch: 21.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1043022375873569		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1043022375873569 | validation: 0.18028499848911786]
	TIME [epoch: 21.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12259093863165789		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.12259093863165789 | validation: 0.18279251924280548]
	TIME [epoch: 21.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092191825867829		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.1092191825867829 | validation: 0.18987435218496887]
	TIME [epoch: 21.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12151460655591637		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.12151460655591637 | validation: 0.17419028210692467]
	TIME [epoch: 21.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1255564568443773		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1255564568443773 | validation: 0.18667145981833771]
	TIME [epoch: 21.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12054497020307571		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.12054497020307571 | validation: 0.1806013926197201]
	TIME [epoch: 21.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11398974438394782		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.11398974438394782 | validation: 0.18095288193931724]
	TIME [epoch: 21.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11496280727687128		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.11496280727687128 | validation: 0.18627044762110498]
	TIME [epoch: 21.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12248444553080402		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.12248444553080402 | validation: 0.18521128535864964]
	TIME [epoch: 21.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.126948835818237		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.126948835818237 | validation: 0.18265154977660963]
	TIME [epoch: 21.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11022270725343111		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.11022270725343111 | validation: 0.19600713025450678]
	TIME [epoch: 21.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12168097509832983		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.12168097509832983 | validation: 0.18619193933976125]
	TIME [epoch: 21.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12134563708208154		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.12134563708208154 | validation: 0.17381483068729364]
	TIME [epoch: 21.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950760995316094		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.11950760995316094 | validation: 0.17667413686352873]
	TIME [epoch: 21.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1124501959451445		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.1124501959451445 | validation: 0.17871147296436335]
	TIME [epoch: 21.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12939165496227678		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.12939165496227678 | validation: 0.17749577076806505]
	TIME [epoch: 21.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11871790031366344		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.11871790031366344 | validation: 0.180061395190385]
	TIME [epoch: 21.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12260477417745538		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.12260477417745538 | validation: 0.16314343592100533]
	TIME [epoch: 21.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11875669013289651		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.11875669013289651 | validation: 0.18125871766009422]
	TIME [epoch: 21.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12655639882116215		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.12655639882116215 | validation: 0.1789975420987542]
	TIME [epoch: 21.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13110143171854538		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.13110143171854538 | validation: 0.18730852813500076]
	TIME [epoch: 21.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11200157669591708		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.11200157669591708 | validation: 0.1757690432480633]
	TIME [epoch: 21.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11665714925596053		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.11665714925596053 | validation: 0.18423064327268382]
	TIME [epoch: 21.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11735042392508466		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.11735042392508466 | validation: 0.16616358733039288]
	TIME [epoch: 21.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11602753163885707		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.11602753163885707 | validation: 0.18071728379259783]
	TIME [epoch: 21.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1280340594869546		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.1280340594869546 | validation: 0.15939060986027298]
	TIME [epoch: 21.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1190725488953017		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1190725488953017 | validation: 0.18494377097958337]
	TIME [epoch: 21.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12032190478954333		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.12032190478954333 | validation: 0.1723170983653833]
	TIME [epoch: 21.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1154761185695942		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1154761185695942 | validation: 0.1927042015544912]
	TIME [epoch: 21.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12078207669781915		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.12078207669781915 | validation: 0.17195517777027328]
	TIME [epoch: 21.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1214835337092918		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.1214835337092918 | validation: 0.19134612976229576]
	TIME [epoch: 21.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11092281902609664		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.11092281902609664 | validation: 0.1757405119942068]
	TIME [epoch: 21.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11545386098633112		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.11545386098633112 | validation: 0.17495567748552976]
	TIME [epoch: 21.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12670963329292845		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.12670963329292845 | validation: 0.18244582196294767]
	TIME [epoch: 21.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11997657059371732		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.11997657059371732 | validation: 0.16534676671366186]
	TIME [epoch: 21.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12615156306965064		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.12615156306965064 | validation: 0.17088170648626116]
	TIME [epoch: 21.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12370133891605292		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12370133891605292 | validation: 0.17213064888730478]
	TIME [epoch: 21.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12679916890743895		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.12679916890743895 | validation: 0.17900003554863791]
	TIME [epoch: 21.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11638378762311094		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.11638378762311094 | validation: 0.18186715916668994]
	TIME [epoch: 21.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1086093509768125		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.1086093509768125 | validation: 0.1745891034268377]
	TIME [epoch: 21.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11582276713455586		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.11582276713455586 | validation: 0.1684345411956838]
	TIME [epoch: 21.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12480888902108078		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.12480888902108078 | validation: 0.15965521174709904]
	TIME [epoch: 21.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950505045515891		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.11950505045515891 | validation: 0.16909759150601578]
	TIME [epoch: 21.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11482528012751081		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.11482528012751081 | validation: 0.1660004627974014]
	TIME [epoch: 21.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11755283766082836		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.11755283766082836 | validation: 0.17498617911741896]
	TIME [epoch: 21.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12439344996486583		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.12439344996486583 | validation: 0.1710625919748378]
	TIME [epoch: 21.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12437160218277377		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.12437160218277377 | validation: 0.1837531531383384]
	TIME [epoch: 21.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11477318860125436		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.11477318860125436 | validation: 0.17984896866624672]
	TIME [epoch: 21.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1197680300244264		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1197680300244264 | validation: 0.17640839932591307]
	TIME [epoch: 21.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11795503191799277		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.11795503191799277 | validation: 0.1777463678726093]
	TIME [epoch: 21.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11644229399941301		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.11644229399941301 | validation: 0.1723051103827074]
	TIME [epoch: 21.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12215135019390547		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.12215135019390547 | validation: 0.18530487662007128]
	TIME [epoch: 21.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11422373522428206		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11422373522428206 | validation: 0.18532831718131187]
	TIME [epoch: 21.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12614447396998127		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.12614447396998127 | validation: 0.17532737196568338]
	TIME [epoch: 21.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12923476568287856		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.12923476568287856 | validation: 0.1692089097652944]
	TIME [epoch: 21.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11609882295652448		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.11609882295652448 | validation: 0.17327724840015735]
	TIME [epoch: 21.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11745340149951533		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.11745340149951533 | validation: 0.17658200311544042]
	TIME [epoch: 21.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11463431689434392		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.11463431689434392 | validation: 0.16612923911424576]
	TIME [epoch: 21.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11574788369020408		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.11574788369020408 | validation: 0.1869273317800925]
	TIME [epoch: 21.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11858367937196106		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.11858367937196106 | validation: 0.17578260800606163]
	TIME [epoch: 21.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11709076423472223		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.11709076423472223 | validation: 0.1819624107583826]
	TIME [epoch: 21.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12387579729419729		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.12387579729419729 | validation: 0.1801697405740249]
	TIME [epoch: 21.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11783449520871984		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.11783449520871984 | validation: 0.17759834444393793]
	TIME [epoch: 21.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12208868956545396		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.12208868956545396 | validation: 0.1692408407405162]
	TIME [epoch: 21.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1176300053675726		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1176300053675726 | validation: 0.17663638585107408]
	TIME [epoch: 21.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11432831472248099		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.11432831472248099 | validation: 0.17068989921211117]
	TIME [epoch: 21.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11925549451523745		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.11925549451523745 | validation: 0.16448069882677907]
	TIME [epoch: 21.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12242444437443689		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.12242444437443689 | validation: 0.1739137809060341]
	TIME [epoch: 21.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1184735357563241		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1184735357563241 | validation: 0.17119046871251345]
	TIME [epoch: 21.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11373468286039894		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.11373468286039894 | validation: 0.18623326417489877]
	TIME [epoch: 21.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12501358616998387		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.12501358616998387 | validation: 0.17317229913166093]
	TIME [epoch: 21.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11640578041849262		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.11640578041849262 | validation: 0.16091410354206895]
	TIME [epoch: 21.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10863690105613884		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.10863690105613884 | validation: 0.17149298826754075]
	TIME [epoch: 21.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11591985279447736		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.11591985279447736 | validation: 0.1733254100254178]
	TIME [epoch: 21.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12257267329609592		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.12257267329609592 | validation: 0.1878211298069738]
	TIME [epoch: 21.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10861806280531774		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.10861806280531774 | validation: 0.18255987379500754]
	TIME [epoch: 21.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10925142214972436		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.10925142214972436 | validation: 0.17674273658025363]
	TIME [epoch: 21.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1127015963290833		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.1127015963290833 | validation: 0.17988967945976106]
	TIME [epoch: 21.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12332798781327363		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.12332798781327363 | validation: 0.17653820940654025]
	TIME [epoch: 21.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11909243893025878		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.11909243893025878 | validation: 0.17811116813144146]
	TIME [epoch: 21.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11735465362182773		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.11735465362182773 | validation: 0.19074580323297902]
	TIME [epoch: 21.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11458216536485051		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.11458216536485051 | validation: 0.18303828083223017]
	TIME [epoch: 21.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11121991354954615		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.11121991354954615 | validation: 0.17598997599755806]
	TIME [epoch: 21.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11095264702924049		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.11095264702924049 | validation: 0.1826030416583094]
	TIME [epoch: 21.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11521196570201511		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.11521196570201511 | validation: 0.1872199253314127]
	TIME [epoch: 21.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1221330650580315		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.1221330650580315 | validation: 0.18994132408863085]
	TIME [epoch: 21.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11907708056038713		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.11907708056038713 | validation: 0.16808734801789652]
	TIME [epoch: 21.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11904234310980519		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.11904234310980519 | validation: 0.18017508452198985]
	TIME [epoch: 21.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11343134654895756		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.11343134654895756 | validation: 0.17791935739268225]
	TIME [epoch: 21.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11483291170340604		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.11483291170340604 | validation: 0.18595452128737797]
	TIME [epoch: 21.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12623513016584842		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.12623513016584842 | validation: 0.16867911805482064]
	TIME [epoch: 21.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1132519708560296		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1132519708560296 | validation: 0.16353951441336131]
	TIME [epoch: 21.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12120160974193686		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.12120160974193686 | validation: 0.1840403848962976]
	TIME [epoch: 21.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11255311529139725		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.11255311529139725 | validation: 0.17335640076148146]
	TIME [epoch: 21.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11685089302721038		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.11685089302721038 | validation: 0.1706928277266861]
	TIME [epoch: 21.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12324293271530415		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.12324293271530415 | validation: 0.1691093772596065]
	TIME [epoch: 21.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11885349253378903		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.11885349253378903 | validation: 0.17669132700969892]
	TIME [epoch: 21.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11681995131018386		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.11681995131018386 | validation: 0.16916027781804766]
	TIME [epoch: 21.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12261528840619033		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.12261528840619033 | validation: 0.1723955078782358]
	TIME [epoch: 21.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12892200383902813		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.12892200383902813 | validation: 0.17396825997210252]
	TIME [epoch: 21.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12055184523010812		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.12055184523010812 | validation: 0.17719285935546325]
	TIME [epoch: 21.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12720313458474902		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.12720313458474902 | validation: 0.16913394016302177]
	TIME [epoch: 21.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12202946025753554		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.12202946025753554 | validation: 0.17281516980690756]
	TIME [epoch: 21.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11519728197621108		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.11519728197621108 | validation: 0.1597914769753369]
	TIME [epoch: 21.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11107117255927637		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.11107117255927637 | validation: 0.17754456837213084]
	TIME [epoch: 21.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1162839571319368		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1162839571319368 | validation: 0.18727176694836448]
	TIME [epoch: 21.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11096066662807447		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.11096066662807447 | validation: 0.16677068502224773]
	TIME [epoch: 21.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11577664786570392		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.11577664786570392 | validation: 0.16621301701740443]
	TIME [epoch: 21.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11568256323055426		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.11568256323055426 | validation: 0.17168150718845399]
	TIME [epoch: 21.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12390017116570799		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.12390017116570799 | validation: 0.17738033761548136]
	TIME [epoch: 21.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12347529611580654		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.12347529611580654 | validation: 0.1788569766290391]
	TIME [epoch: 21.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12351428951687031		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.12351428951687031 | validation: 0.1846023917518124]
	TIME [epoch: 21.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11044711074644042		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.11044711074644042 | validation: 0.18143696773324777]
	TIME [epoch: 21.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11711377158398162		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.11711377158398162 | validation: 0.16009115903715787]
	TIME [epoch: 21.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12152693562497037		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.12152693562497037 | validation: 0.17651909504983887]
	TIME [epoch: 21.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11933504545065074		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.11933504545065074 | validation: 0.17456563275983328]
	TIME [epoch: 21.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11943423311849644		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.11943423311849644 | validation: 0.16770888970638617]
	TIME [epoch: 21.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11520031180636252		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.11520031180636252 | validation: 0.18004410882743652]
	TIME [epoch: 21.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11834092041617501		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.11834092041617501 | validation: 0.17679294587510713]
	TIME [epoch: 21.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12499020422151723		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.12499020422151723 | validation: 0.1859141506970191]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_dec2c_2d_v1_20240622_120422/states/model_facs_dec2c_2d_v1_615.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 13113.185 seconds.
