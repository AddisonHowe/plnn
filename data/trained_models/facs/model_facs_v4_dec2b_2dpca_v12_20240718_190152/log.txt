Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v12', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v12', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1271622477

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3224519465393083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3224519465393083 | validation: 1.1027731578072024]
	TIME [epoch: 29.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7782859324250402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7782859324250402 | validation: 0.8669616870322103]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690982143697229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.690982143697229 | validation: 0.8298230542391744]
	TIME [epoch: 6.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814057993753124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5814057993753124 | validation: 0.780703411262231]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627764741070974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5627764741070974 | validation: 0.737248970272127]
	TIME [epoch: 6.44 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639450895811622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5639450895811622 | validation: 0.7547757717581685]
	TIME [epoch: 6.43 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5830610034646708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5830610034646708 | validation: 0.6359410985921455]
	TIME [epoch: 6.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672902954336733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4672902954336733 | validation: 0.5934012957124095]
	TIME [epoch: 6.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518296806726634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4518296806726634 | validation: 0.5796534229333241]
	TIME [epoch: 6.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44963093493077033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44963093493077033 | validation: 0.5195163981313107]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597296788557356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3597296788557356 | validation: 0.5971790277851653]
	TIME [epoch: 6.44 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626527005733656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4626527005733656 | validation: 0.49670001740503433]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261886990295538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3261886990295538 | validation: 0.45901764739260104]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32520047414851183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32520047414851183 | validation: 0.42180556585653173]
	TIME [epoch: 6.44 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29442717576028976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29442717576028976 | validation: 0.41661567556078405]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34648566493917077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34648566493917077 | validation: 0.6700735533903937]
	TIME [epoch: 6.42 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37252600978394745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37252600978394745 | validation: 0.41621319878043983]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270090789041759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.270090789041759 | validation: 0.3959241843649048]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507735306496038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2507735306496038 | validation: 0.38391967761204726]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278684098005833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.278684098005833 | validation: 0.551142925301293]
	TIME [epoch: 6.4 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36760690262825013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36760690262825013 | validation: 0.43698153484285096]
	TIME [epoch: 6.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26597476023891575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26597476023891575 | validation: 0.37400157771179016]
	TIME [epoch: 6.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24520426615749447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24520426615749447 | validation: 0.5188204414623951]
	TIME [epoch: 6.43 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354730201668236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3354730201668236 | validation: 0.37288728191620063]
	TIME [epoch: 6.44 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26243466486947387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26243466486947387 | validation: 0.3522663213660668]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23604324332004814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23604324332004814 | validation: 0.4152132375682311]
	TIME [epoch: 6.43 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22783828254129881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22783828254129881 | validation: 0.41150652671841265]
	TIME [epoch: 6.43 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31705301079244164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31705301079244164 | validation: 0.4541985227351503]
	TIME [epoch: 6.42 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23943636007925148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23943636007925148 | validation: 0.3748327363958577]
	TIME [epoch: 6.43 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22464041432312815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22464041432312815 | validation: 0.3680626433144354]
	TIME [epoch: 6.43 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23545852920519783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23545852920519783 | validation: 0.4568666825890722]
	TIME [epoch: 6.44 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26236250683907925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26236250683907925 | validation: 0.4173016371079904]
	TIME [epoch: 6.43 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27009738377699477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27009738377699477 | validation: 0.4545632384488638]
	TIME [epoch: 6.43 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23099997321793148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23099997321793148 | validation: 0.3558622209697943]
	TIME [epoch: 6.43 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24181935338452032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24181935338452032 | validation: 0.5243495911813667]
	TIME [epoch: 6.42 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268324368757161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.268324368757161 | validation: 0.38200687136927197]
	TIME [epoch: 6.42 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22584486896221695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22584486896221695 | validation: 0.37875219458370385]
	TIME [epoch: 6.42 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910816000038768		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.1910816000038768 | validation: 0.3537554115062509]
	TIME [epoch: 6.43 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23055209010511937		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.23055209010511937 | validation: 0.38624613115519113]
	TIME [epoch: 6.43 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22164837619725197		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.22164837619725197 | validation: 0.40841033275999744]
	TIME [epoch: 6.42 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22904030976117734		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.22904030976117734 | validation: 0.3618029446856783]
	TIME [epoch: 6.43 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.209003806597037		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.209003806597037 | validation: 0.3660839400012188]
	TIME [epoch: 6.42 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20211895184700776		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.20211895184700776 | validation: 0.39601720590353745]
	TIME [epoch: 6.43 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18676923650083144		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.18676923650083144 | validation: 0.4913184791603285]
	TIME [epoch: 6.42 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2372954242614651		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2372954242614651 | validation: 0.43686780123897295]
	TIME [epoch: 6.43 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24742587906848118		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24742587906848118 | validation: 0.379781520910203]
	TIME [epoch: 6.43 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19591072758551248		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.19591072758551248 | validation: 0.4517244143930351]
	TIME [epoch: 6.43 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19258294586873592		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.19258294586873592 | validation: 0.37703493277755346]
	TIME [epoch: 6.43 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344731711439364		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.2344731711439364 | validation: 0.4271524487807024]
	TIME [epoch: 6.43 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23821508574233524		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.23821508574233524 | validation: 0.3355472021666944]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17433596102741478		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.17433596102741478 | validation: 0.36510083640699964]
	TIME [epoch: 33.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17744384084100526		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.17744384084100526 | validation: 0.3743175864736921]
	TIME [epoch: 12.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23345539728879694		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.23345539728879694 | validation: 0.5965078425911686]
	TIME [epoch: 12.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27336330682640114		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.27336330682640114 | validation: 0.38123357182398865]
	TIME [epoch: 12.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990278638891476		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.1990278638891476 | validation: 0.3341257451655272]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1877211470169687		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.1877211470169687 | validation: 0.4535104395592704]
	TIME [epoch: 12.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19221912744492536		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.19221912744492536 | validation: 0.34871108411753926]
	TIME [epoch: 12.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24238303080831508		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.24238303080831508 | validation: 0.3868817402468737]
	TIME [epoch: 12.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19636724990435284		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.19636724990435284 | validation: 0.327363864406781]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21758178908643103		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.21758178908643103 | validation: 0.3702498579776045]
	TIME [epoch: 12.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033500407916532		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2033500407916532 | validation: 0.33556146561403716]
	TIME [epoch: 12.4 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792747977658718		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.1792747977658718 | validation: 0.33439604268672657]
	TIME [epoch: 12.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22287935684204063		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.22287935684204063 | validation: 0.3562767229571605]
	TIME [epoch: 12.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19238698216171407		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.19238698216171407 | validation: 0.4164310092962756]
	TIME [epoch: 12.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23037055242102314		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.23037055242102314 | validation: 0.3378010510924002]
	TIME [epoch: 12.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21761144694074946		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.21761144694074946 | validation: 0.4167165694514433]
	TIME [epoch: 12.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20333467318444823		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.20333467318444823 | validation: 0.5267341549252259]
	TIME [epoch: 12.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22315657909667036		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.22315657909667036 | validation: 0.4315661317060143]
	TIME [epoch: 12.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22477969305504916		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.22477969305504916 | validation: 0.3368394082282198]
	TIME [epoch: 12.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18493141870075405		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.18493141870075405 | validation: 0.4037392532680108]
	TIME [epoch: 12.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19401312829688527		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.19401312829688527 | validation: 0.5225901641290853]
	TIME [epoch: 12.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131911453504306		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.2131911453504306 | validation: 0.37077350760184197]
	TIME [epoch: 12.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17340897104669808		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.17340897104669808 | validation: 0.3853698941523602]
	TIME [epoch: 12.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21250807341477745		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.21250807341477745 | validation: 0.4223351543741118]
	TIME [epoch: 12.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19596407553579767		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.19596407553579767 | validation: 0.3331414819680595]
	TIME [epoch: 12.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19200480493377958		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.19200480493377958 | validation: 0.3110798103766877]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20711210689383205		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.20711210689383205 | validation: 0.297567714377144]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632136798909211		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.1632136798909211 | validation: 0.3470921089864114]
	TIME [epoch: 12.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18668288868136115		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.18668288868136115 | validation: 0.4108516838698383]
	TIME [epoch: 12.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17047453896162695		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.17047453896162695 | validation: 0.39161416954190076]
	TIME [epoch: 12.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17150642517202888		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.17150642517202888 | validation: 0.3615729424833789]
	TIME [epoch: 12.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24146909083695134		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.24146909083695134 | validation: 0.3735739835334867]
	TIME [epoch: 12.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2009749485769175		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.2009749485769175 | validation: 0.33214951472122695]
	TIME [epoch: 12.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16638194612416363		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.16638194612416363 | validation: 0.442251450605341]
	TIME [epoch: 12.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704518434079644		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.2704518434079644 | validation: 0.4490862057322247]
	TIME [epoch: 12.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785854723634942		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.2785854723634942 | validation: 0.3721254947952136]
	TIME [epoch: 12.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21373066179947958		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.21373066179947958 | validation: 0.3689765239521492]
	TIME [epoch: 12.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19907449910789776		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.19907449910789776 | validation: 0.32702906461443304]
	TIME [epoch: 12.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17733114719291		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17733114719291 | validation: 0.3494362316498714]
	TIME [epoch: 12.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16382183234367223		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.16382183234367223 | validation: 0.3464069501330211]
	TIME [epoch: 12.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19037229843768938		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.19037229843768938 | validation: 0.6042130611063198]
	TIME [epoch: 12.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23960361353878806		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.23960361353878806 | validation: 0.3856952022380973]
	TIME [epoch: 12.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16037261580938994		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.16037261580938994 | validation: 0.32585007371167385]
	TIME [epoch: 12.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16754652698943934		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16754652698943934 | validation: 0.40480075814694305]
	TIME [epoch: 12.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18564904247150116		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.18564904247150116 | validation: 0.36155531980711586]
	TIME [epoch: 12.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15645824919413817		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.15645824919413817 | validation: 0.4668290257042246]
	TIME [epoch: 12.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20297661958724067		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.20297661958724067 | validation: 0.3767739408450756]
	TIME [epoch: 12.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671410602757896		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1671410602757896 | validation: 0.3789317459723228]
	TIME [epoch: 12.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181238923133336		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.181238923133336 | validation: 0.31876199473302147]
	TIME [epoch: 12.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503547818580136		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1503547818580136 | validation: 0.41580929097148217]
	TIME [epoch: 12.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319241181710197		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.2319241181710197 | validation: 0.307712098239315]
	TIME [epoch: 12.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658443263748375		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.1658443263748375 | validation: 0.50388151298006]
	TIME [epoch: 12.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17308238622061173		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.17308238622061173 | validation: 0.4657623718195711]
	TIME [epoch: 12.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17362520925967767		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.17362520925967767 | validation: 0.2965883762145573]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15251238939133027		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.15251238939133027 | validation: 0.3280535891517046]
	TIME [epoch: 12.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740542775556655		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1740542775556655 | validation: 0.4379570718564013]
	TIME [epoch: 12.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16204807453868333		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.16204807453868333 | validation: 0.3576114363752864]
	TIME [epoch: 12.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085068099089036		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.18085068099089036 | validation: 0.43881878856667017]
	TIME [epoch: 12.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771804037842186		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.2771804037842186 | validation: 0.4035054403507577]
	TIME [epoch: 12.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23682794060220635		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.23682794060220635 | validation: 0.3898646096828281]
	TIME [epoch: 12.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16583086320851545		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.16583086320851545 | validation: 0.2937709252733291]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695261988595091		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.1695261988595091 | validation: 0.37377971359057477]
	TIME [epoch: 12.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19647138145180154		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.19647138145180154 | validation: 0.31058319178541266]
	TIME [epoch: 12.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17304157231121417		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.17304157231121417 | validation: 0.3231408261422709]
	TIME [epoch: 12.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664311794031331		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1664311794031331 | validation: 0.34593884983856027]
	TIME [epoch: 12.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17403086037694795		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.17403086037694795 | validation: 0.4397039949504569]
	TIME [epoch: 12.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19023091652106003		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.19023091652106003 | validation: 0.38850745160157424]
	TIME [epoch: 12.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588279578772942		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.1588279578772942 | validation: 0.36302522511887736]
	TIME [epoch: 12.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16036884841512766		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.16036884841512766 | validation: 0.30586783653073063]
	TIME [epoch: 12.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14560028017506244		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.14560028017506244 | validation: 0.3167112301947858]
	TIME [epoch: 12.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15174890954405706		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.15174890954405706 | validation: 0.4556086154401132]
	TIME [epoch: 12.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15620231280058		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.15620231280058 | validation: 0.3147709858494367]
	TIME [epoch: 12.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15656829610700124		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.15656829610700124 | validation: 0.3156627291850805]
	TIME [epoch: 12.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573979264867143		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1573979264867143 | validation: 0.2950042409808727]
	TIME [epoch: 12.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15747400497961556		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.15747400497961556 | validation: 0.5406920817638955]
	TIME [epoch: 12.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19901401600855928		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19901401600855928 | validation: 0.4035874261171825]
	TIME [epoch: 12.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17735146613410943		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.17735146613410943 | validation: 0.3569699024684898]
	TIME [epoch: 12.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16833482943462386		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.16833482943462386 | validation: 0.36015481121717097]
	TIME [epoch: 12.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15284915040324915		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.15284915040324915 | validation: 0.4043688947637837]
	TIME [epoch: 12.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17724754730689232		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.17724754730689232 | validation: 0.37499842833112274]
	TIME [epoch: 12.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15929828303294258		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.15929828303294258 | validation: 0.31074470405503246]
	TIME [epoch: 12.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168506508143631		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.168506508143631 | validation: 0.36819046469271166]
	TIME [epoch: 12.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833030252766727		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.1833030252766727 | validation: 0.3141446294203949]
	TIME [epoch: 12.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487010488916434		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.1487010488916434 | validation: 0.3812835681919024]
	TIME [epoch: 12.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20579673877542126		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.20579673877542126 | validation: 0.33868321848761623]
	TIME [epoch: 12.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184561919767991		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.184561919767991 | validation: 0.36306435341701826]
	TIME [epoch: 12.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691069812724667		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1691069812724667 | validation: 0.34330518270467847]
	TIME [epoch: 12.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670993168022333		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.1670993168022333 | validation: 0.30443054917313983]
	TIME [epoch: 12.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521590683132742		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.1521590683132742 | validation: 0.44942996785275346]
	TIME [epoch: 12.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17616841490853113		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.17616841490853113 | validation: 0.3926339509193224]
	TIME [epoch: 12.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18478669156354474		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.18478669156354474 | validation: 0.32558163765447745]
	TIME [epoch: 12.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15010088279622802		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.15010088279622802 | validation: 0.35743476844757294]
	TIME [epoch: 12.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15100894602448547		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15100894602448547 | validation: 0.3864513181948813]
	TIME [epoch: 12.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18642823714413637		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.18642823714413637 | validation: 0.2990686605224653]
	TIME [epoch: 12.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369192810569858		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.1369192810569858 | validation: 0.3399142035006145]
	TIME [epoch: 12.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15786597807108393		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.15786597807108393 | validation: 0.3163254476183724]
	TIME [epoch: 12.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612375494549961		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.1612375494549961 | validation: 0.3377834290976016]
	TIME [epoch: 12.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14640088741760593		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.14640088741760593 | validation: 0.41263188004065265]
	TIME [epoch: 12.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750217381354798		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1750217381354798 | validation: 0.3397041394613015]
	TIME [epoch: 12.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17114325758734866		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.17114325758734866 | validation: 0.35280055294943763]
	TIME [epoch: 12.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15324590117404388		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.15324590117404388 | validation: 0.2990936867103062]
	TIME [epoch: 12.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16180645440878103		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.16180645440878103 | validation: 0.31810093205977197]
	TIME [epoch: 12.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16869813398412145		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.16869813398412145 | validation: 0.3894871162193758]
	TIME [epoch: 12.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15056917555880228		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.15056917555880228 | validation: 0.34899193421334607]
	TIME [epoch: 12.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813226458111664		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.14813226458111664 | validation: 0.3424523617314132]
	TIME [epoch: 12.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18698155924419857		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.18698155924419857 | validation: 0.5522306284854737]
	TIME [epoch: 12.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1945207946842673		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1945207946842673 | validation: 0.3447319479102017]
	TIME [epoch: 12.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469220247324749		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.1469220247324749 | validation: 0.30618410486649106]
	TIME [epoch: 12.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14394962646644127		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.14394962646644127 | validation: 0.2964893967077353]
	TIME [epoch: 12.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17849660751598875		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.17849660751598875 | validation: 0.32547808095281605]
	TIME [epoch: 12.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582151910476456		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.1582151910476456 | validation: 0.3169691899543856]
	TIME [epoch: 12.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15793135073247916		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.15793135073247916 | validation: 0.3162627086630778]
	TIME [epoch: 12.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344189068184035		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.14344189068184035 | validation: 0.35402234296512197]
	TIME [epoch: 12.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17033569731860412		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.17033569731860412 | validation: 0.330647001617044]
	TIME [epoch: 12.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14966632864262763		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.14966632864262763 | validation: 0.30397543252333065]
	TIME [epoch: 12.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12483389523515079		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.12483389523515079 | validation: 0.2791997197290166]
	TIME [epoch: 12.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448619227709444		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.1448619227709444 | validation: 0.349265868050093]
	TIME [epoch: 12.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18613131363144805		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.18613131363144805 | validation: 0.3751952430709529]
	TIME [epoch: 12.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066465724705244		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.15066465724705244 | validation: 0.2917557829575932]
	TIME [epoch: 12.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14697369783973532		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.14697369783973532 | validation: 0.34176019043988726]
	TIME [epoch: 12.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19019595135658024		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.19019595135658024 | validation: 0.3884558879943591]
	TIME [epoch: 12.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602182501286802		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.1602182501286802 | validation: 0.3238850499379162]
	TIME [epoch: 12.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14258270026391623		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14258270026391623 | validation: 0.4663510412614055]
	TIME [epoch: 12.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18069730628600136		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.18069730628600136 | validation: 0.3464379886190286]
	TIME [epoch: 12.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15926856424371139		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.15926856424371139 | validation: 0.32182328471312255]
	TIME [epoch: 12.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141080353476147		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.15141080353476147 | validation: 0.3710564153452771]
	TIME [epoch: 12.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17421554862635424		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.17421554862635424 | validation: 0.332322071267371]
	TIME [epoch: 12.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16590602594615325		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.16590602594615325 | validation: 0.3815910110957479]
	TIME [epoch: 12.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19364026411364615		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.19364026411364615 | validation: 0.30854986953667807]
	TIME [epoch: 12.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14715861609163766		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.14715861609163766 | validation: 0.3831468620632315]
	TIME [epoch: 12.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14258368704843832		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.14258368704843832 | validation: 0.2730866619913259]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14183054158657762		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.14183054158657762 | validation: 0.3631978998338201]
	TIME [epoch: 12.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716147660415277		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.1716147660415277 | validation: 0.37922624651890463]
	TIME [epoch: 12.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15045002779286754		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.15045002779286754 | validation: 0.3597149319928423]
	TIME [epoch: 12.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375035568558486		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.14375035568558486 | validation: 0.3375381649067474]
	TIME [epoch: 12.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15372672303859417		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.15372672303859417 | validation: 0.3419440397536399]
	TIME [epoch: 12.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17675940176832222		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.17675940176832222 | validation: 0.36563701788550995]
	TIME [epoch: 12.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19662341372894654		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.19662341372894654 | validation: 0.3006013345864338]
	TIME [epoch: 12.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565685748597761		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1565685748597761 | validation: 0.3215728984889053]
	TIME [epoch: 12.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351482644376448		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.14351482644376448 | validation: 0.3118358384522888]
	TIME [epoch: 12.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021192355837097		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.13021192355837097 | validation: 0.3930745745559912]
	TIME [epoch: 12.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044797450834664		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16044797450834664 | validation: 0.318156165710636]
	TIME [epoch: 12.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14844400273960306		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.14844400273960306 | validation: 0.3127703450274274]
	TIME [epoch: 12.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166336984601862		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.166336984601862 | validation: 0.36186200637273536]
	TIME [epoch: 12.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16511464232136513		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.16511464232136513 | validation: 0.36281805369215225]
	TIME [epoch: 12.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13736011643364668		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.13736011643364668 | validation: 0.29833234147515164]
	TIME [epoch: 12.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406445686921037		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.13406445686921037 | validation: 0.32606586177890784]
	TIME [epoch: 12.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13828560223676387		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.13828560223676387 | validation: 0.442441685617491]
	TIME [epoch: 12.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446542975044698		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.1446542975044698 | validation: 0.32685983720769124]
	TIME [epoch: 12.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15916292648854552		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.15916292648854552 | validation: 0.3099107799906038]
	TIME [epoch: 12.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13920870519869033		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.13920870519869033 | validation: 0.3131351249895636]
	TIME [epoch: 12.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15157821528827814		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.15157821528827814 | validation: 0.39728571393252643]
	TIME [epoch: 12.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714557079950666		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1714557079950666 | validation: 0.34952619093036735]
	TIME [epoch: 12.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15674922868930422		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.15674922868930422 | validation: 0.31886828332032874]
	TIME [epoch: 12.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334213108240962		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.1334213108240962 | validation: 0.34318970450838426]
	TIME [epoch: 12.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16865600203648032		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.16865600203648032 | validation: 0.3152577266924877]
	TIME [epoch: 12.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13606110555803685		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.13606110555803685 | validation: 0.2809962807450095]
	TIME [epoch: 12.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16895671282240327		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.16895671282240327 | validation: 0.39755000082845177]
	TIME [epoch: 12.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033519189627119		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.2033519189627119 | validation: 0.3511641262858961]
	TIME [epoch: 12.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404761553710388		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.14404761553710388 | validation: 0.3114008654849175]
	TIME [epoch: 12.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660027819661467		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1660027819661467 | validation: 0.3092185265163835]
	TIME [epoch: 12.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15226896441506652		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15226896441506652 | validation: 0.35109445941271983]
	TIME [epoch: 12.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444096729917212		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1444096729917212 | validation: 0.29357376269158625]
	TIME [epoch: 12.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14649663978784602		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.14649663978784602 | validation: 0.3089047130040882]
	TIME [epoch: 12.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13026043631717213		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.13026043631717213 | validation: 0.3356296680999886]
	TIME [epoch: 12.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16880392189794588		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.16880392189794588 | validation: 0.295789583080463]
	TIME [epoch: 12.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13528171441114012		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.13528171441114012 | validation: 0.3168361166460326]
	TIME [epoch: 12.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400359920233435		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1400359920233435 | validation: 0.2813004916403374]
	TIME [epoch: 12.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13284943161659907		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.13284943161659907 | validation: 0.3285761069554294]
	TIME [epoch: 12.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13934957693784658		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13934957693784658 | validation: 0.34630304709470977]
	TIME [epoch: 12.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929281026041493		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.13929281026041493 | validation: 0.3361309041469079]
	TIME [epoch: 12.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360367970741698		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.1360367970741698 | validation: 0.27915569929711637]
	TIME [epoch: 12.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14619583955537097		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.14619583955537097 | validation: 0.3140997526118329]
	TIME [epoch: 12.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14181998882329455		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.14181998882329455 | validation: 0.2834152383477603]
	TIME [epoch: 12.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15446974046890743		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.15446974046890743 | validation: 0.33925652183597654]
	TIME [epoch: 12.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15407313935106853		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.15407313935106853 | validation: 0.4149824461998843]
	TIME [epoch: 12.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571536460710714		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1571536460710714 | validation: 0.31735506949373465]
	TIME [epoch: 12.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130492209062957		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.15130492209062957 | validation: 0.31359877806104586]
	TIME [epoch: 12.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14940373797676193		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14940373797676193 | validation: 0.279847283111467]
	TIME [epoch: 12.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212040280046168		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.1212040280046168 | validation: 0.317064015551457]
	TIME [epoch: 12.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042546893744417		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.12042546893744417 | validation: 0.2983683563883661]
	TIME [epoch: 12.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403556536489351		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1403556536489351 | validation: 0.31884818946979315]
	TIME [epoch: 12.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959915845440157		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.13959915845440157 | validation: 0.3691970353853516]
	TIME [epoch: 12.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021921049836433		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.14021921049836433 | validation: 0.3066329615492473]
	TIME [epoch: 12.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352874308781104		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1352874308781104 | validation: 0.2878887053310765]
	TIME [epoch: 12.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13292503393557042		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.13292503393557042 | validation: 0.33428560031275356]
	TIME [epoch: 12.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15281768843991608		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15281768843991608 | validation: 0.3026427972962739]
	TIME [epoch: 12.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13260777247024727		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.13260777247024727 | validation: 0.29941388738231145]
	TIME [epoch: 12.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284146861661201		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1284146861661201 | validation: 0.47469661164271454]
	TIME [epoch: 12.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355417045836838		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1355417045836838 | validation: 0.34003780979098686]
	TIME [epoch: 12.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13723167310676831		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.13723167310676831 | validation: 0.3267894745320624]
	TIME [epoch: 12.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12221601597200651		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.12221601597200651 | validation: 0.3128899558521986]
	TIME [epoch: 12.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498549781564917		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.12498549781564917 | validation: 0.3259731849113646]
	TIME [epoch: 12.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809495412586872		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.12809495412586872 | validation: 0.36470906440320383]
	TIME [epoch: 12.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413275067727864		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.1413275067727864 | validation: 0.3006856463769466]
	TIME [epoch: 12.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14585534217807844		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.14585534217807844 | validation: 0.39552338352929345]
	TIME [epoch: 12.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381580433378242		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1381580433378242 | validation: 0.365766635775404]
	TIME [epoch: 12.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12117116722978383		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12117116722978383 | validation: 0.32317306882551206]
	TIME [epoch: 12.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008597957672907		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.13008597957672907 | validation: 0.3332159428536281]
	TIME [epoch: 12.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121177865601008		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.13121177865601008 | validation: 0.350649908456639]
	TIME [epoch: 12.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332098295937031		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1332098295937031 | validation: 0.32938859534494425]
	TIME [epoch: 12.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494703827753995		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.12494703827753995 | validation: 0.30734101742563985]
	TIME [epoch: 12.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12491165149836286		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12491165149836286 | validation: 0.33707362994814355]
	TIME [epoch: 12.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284009952738881		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.1284009952738881 | validation: 0.3407677338449615]
	TIME [epoch: 12.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380460606440329		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1380460606440329 | validation: 0.31300047188196267]
	TIME [epoch: 12.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348573745884952		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1348573745884952 | validation: 0.3293993535068029]
	TIME [epoch: 12.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652313739848883		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.12652313739848883 | validation: 0.3052619702782872]
	TIME [epoch: 12.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12750912857833163		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12750912857833163 | validation: 0.3236037946633416]
	TIME [epoch: 12.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17854237149794216		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.17854237149794216 | validation: 0.3275825320104818]
	TIME [epoch: 12.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18687444052764224		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.18687444052764224 | validation: 0.3199042496385109]
	TIME [epoch: 12.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14540092079143652		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.14540092079143652 | validation: 0.304559106323404]
	TIME [epoch: 12.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446980292171021		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.12446980292171021 | validation: 0.34962123156644953]
	TIME [epoch: 12.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142440458178837		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.142440458178837 | validation: 0.3223575124864487]
	TIME [epoch: 12.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139474511831199		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.139474511831199 | validation: 0.30549845295143524]
	TIME [epoch: 12.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754939363926333		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.13754939363926333 | validation: 0.3138858835994163]
	TIME [epoch: 12.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496587651787698		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.13496587651787698 | validation: 0.2785433361841439]
	TIME [epoch: 12.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257808212456336		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.1257808212456336 | validation: 0.373201877175601]
	TIME [epoch: 12.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785404764959517		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.14785404764959517 | validation: 0.31322291234276606]
	TIME [epoch: 12.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14041147063736412		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.14041147063736412 | validation: 0.317357241806551]
	TIME [epoch: 12.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11874655657510241		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.11874655657510241 | validation: 0.2829164165309615]
	TIME [epoch: 12.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162181723364807		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.162181723364807 | validation: 0.3497388551285802]
	TIME [epoch: 12.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340141345145609		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.1340141345145609 | validation: 0.29974572401230615]
	TIME [epoch: 12.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12529729394117434		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.12529729394117434 | validation: 0.2942958937890745]
	TIME [epoch: 12.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438819853259629		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.12438819853259629 | validation: 0.2798632484433118]
	TIME [epoch: 12.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313113636843477		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.13313113636843477 | validation: 0.2791942205737152]
	TIME [epoch: 12.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367750412487184		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1367750412487184 | validation: 0.3311319922517118]
	TIME [epoch: 12.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11714067602734064		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.11714067602734064 | validation: 0.30751057062759796]
	TIME [epoch: 12.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14983340498447406		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.14983340498447406 | validation: 0.2890712081262127]
	TIME [epoch: 12.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757428754028885		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.12757428754028885 | validation: 0.30337947093825346]
	TIME [epoch: 12.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14437130139615365		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14437130139615365 | validation: 0.30683470616587805]
	TIME [epoch: 12.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11936612215046268		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.11936612215046268 | validation: 0.32949923454694025]
	TIME [epoch: 12.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353115399840486		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1353115399840486 | validation: 0.320785156669162]
	TIME [epoch: 12.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264757769494398		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.13264757769494398 | validation: 0.3249546472567115]
	TIME [epoch: 12.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13084672668788255		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.13084672668788255 | validation: 0.2859228636299824]
	TIME [epoch: 12.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291038012888099		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.1291038012888099 | validation: 0.320032336338471]
	TIME [epoch: 12.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576018612646644		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.12576018612646644 | validation: 0.291130267375337]
	TIME [epoch: 12.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13193895009689832		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.13193895009689832 | validation: 0.30133615281766457]
	TIME [epoch: 12.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251934359743383		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1251934359743383 | validation: 0.36299231260069964]
	TIME [epoch: 12.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131671087609361		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.131671087609361 | validation: 0.36828193891113686]
	TIME [epoch: 12.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13204618165204815		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.13204618165204815 | validation: 0.3512680323660675]
	TIME [epoch: 12.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272896148008195		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.1272896148008195 | validation: 0.32282015186390167]
	TIME [epoch: 12.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14389919484860653		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.14389919484860653 | validation: 0.3471315758073751]
	TIME [epoch: 12.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363389813670744		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1363389813670744 | validation: 0.298694789446012]
	TIME [epoch: 12.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11964935857958169		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.11964935857958169 | validation: 0.30917712313736323]
	TIME [epoch: 12.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952344796841077		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.11952344796841077 | validation: 0.33095729778126826]
	TIME [epoch: 12.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426372566164127		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1426372566164127 | validation: 0.3097410019297754]
	TIME [epoch: 12.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477467259436531		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.12477467259436531 | validation: 0.3361531855453596]
	TIME [epoch: 12.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970371915874707		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.12970371915874707 | validation: 0.31809308777907896]
	TIME [epoch: 12.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027675817269085		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.12027675817269085 | validation: 0.2963743237431865]
	TIME [epoch: 12.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17245701053242626		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.17245701053242626 | validation: 0.3024040158908827]
	TIME [epoch: 12.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191403444107516		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.13191403444107516 | validation: 0.3240085897994065]
	TIME [epoch: 12.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11429364588567634		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.11429364588567634 | validation: 0.2949393152074777]
	TIME [epoch: 12.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12038078220449197		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12038078220449197 | validation: 0.3108346055271379]
	TIME [epoch: 12.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392239802158746		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.12392239802158746 | validation: 0.2818855577370684]
	TIME [epoch: 12.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11732569998000862		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.11732569998000862 | validation: 0.29272529692627197]
	TIME [epoch: 12.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11966673345921663		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.11966673345921663 | validation: 0.3099313993783761]
	TIME [epoch: 12.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873598472632686		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.12873598472632686 | validation: 0.3376760587499476]
	TIME [epoch: 12.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12479387853001991		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.12479387853001991 | validation: 0.2977112587390404]
	TIME [epoch: 12.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12887435365243566		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.12887435365243566 | validation: 0.31019447356028873]
	TIME [epoch: 12.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319867019659319		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.1319867019659319 | validation: 0.2994463470179821]
	TIME [epoch: 12.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12932349506638746		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.12932349506638746 | validation: 0.29794824459371005]
	TIME [epoch: 12.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521902975955665		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.11521902975955665 | validation: 0.31239653553600893]
	TIME [epoch: 12.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12046958860541648		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.12046958860541648 | validation: 0.3090297601848322]
	TIME [epoch: 12.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11474452715206448		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.11474452715206448 | validation: 0.3122042344407998]
	TIME [epoch: 12.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13722018030153513		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13722018030153513 | validation: 0.36316335631032304]
	TIME [epoch: 12.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291699298568487		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1291699298568487 | validation: 0.290144625071208]
	TIME [epoch: 12.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140747536143897		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.1140747536143897 | validation: 0.31314842372192075]
	TIME [epoch: 12.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12952326068460124		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.12952326068460124 | validation: 0.35075636227433826]
	TIME [epoch: 12.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097758803563435		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.12097758803563435 | validation: 0.29529340528779446]
	TIME [epoch: 12.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13921973933074128		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.13921973933074128 | validation: 0.32125893595802246]
	TIME [epoch: 12.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13574545250710165		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.13574545250710165 | validation: 0.2898722899464331]
	TIME [epoch: 12.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139233105452159		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.1139233105452159 | validation: 0.3148966420881148]
	TIME [epoch: 12.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267111427075501		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.1267111427075501 | validation: 0.32466378214068603]
	TIME [epoch: 12.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194713646812073		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13194713646812073 | validation: 0.3412151727087928]
	TIME [epoch: 12.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406306025488217		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.1406306025488217 | validation: 0.2812514991775092]
	TIME [epoch: 12.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258746087598231		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.1258746087598231 | validation: 0.2998305098347771]
	TIME [epoch: 12.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12223670365247602		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.12223670365247602 | validation: 0.30038954040715765]
	TIME [epoch: 12.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194752600232926		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.13194752600232926 | validation: 0.35450710138382224]
	TIME [epoch: 12.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409917923621856		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.13409917923621856 | validation: 0.31457047463649046]
	TIME [epoch: 12.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11575941292406325		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.11575941292406325 | validation: 0.3396952401096639]
	TIME [epoch: 12.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853128060962105		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.13853128060962105 | validation: 0.3099496240955157]
	TIME [epoch: 12.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15388542153929366		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.15388542153929366 | validation: 0.4177272562901511]
	TIME [epoch: 12.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13688888049487585		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.13688888049487585 | validation: 0.3273642808690553]
	TIME [epoch: 12.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452193356000255		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.13452193356000255 | validation: 0.277889884110154]
	TIME [epoch: 12.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311091421614292		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.1311091421614292 | validation: 0.30522780289367984]
	TIME [epoch: 12.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12198238278009249		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.12198238278009249 | validation: 0.33511113943108184]
	TIME [epoch: 12.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513876328260426		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.12513876328260426 | validation: 0.3275343209940509]
	TIME [epoch: 12.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304660522195244		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.13304660522195244 | validation: 0.31458602970464167]
	TIME [epoch: 12.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13487138212108724		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.13487138212108724 | validation: 0.3095725803218966]
	TIME [epoch: 12.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12485332063261084		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.12485332063261084 | validation: 0.3170200547136902]
	TIME [epoch: 12.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11913129404679926		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.11913129404679926 | validation: 0.2864246042001303]
	TIME [epoch: 12.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12350953544540003		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.12350953544540003 | validation: 0.3046926054588881]
	TIME [epoch: 12.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14327220421787168		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.14327220421787168 | validation: 0.30874938135339725]
	TIME [epoch: 12.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264641861194173		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1264641861194173 | validation: 0.3119641606303596]
	TIME [epoch: 12.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11070730418799164		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.11070730418799164 | validation: 0.2988428069759324]
	TIME [epoch: 12.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218398167913693		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11218398167913693 | validation: 0.3315322156099083]
	TIME [epoch: 12.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112610723705947		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.13112610723705947 | validation: 0.2998737678751391]
	TIME [epoch: 12.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203931634171467		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13203931634171467 | validation: 0.30634102836863186]
	TIME [epoch: 12.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249763305169743		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.13249763305169743 | validation: 0.4020668763780567]
	TIME [epoch: 12.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115507575554426		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.14115507575554426 | validation: 0.29926212972095934]
	TIME [epoch: 12.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12107695918319311		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.12107695918319311 | validation: 0.3062957068122665]
	TIME [epoch: 12.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12832168138227235		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12832168138227235 | validation: 0.30223814871800736]
	TIME [epoch: 12.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190962801515782		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.13190962801515782 | validation: 0.3019334936331923]
	TIME [epoch: 12.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12335138147224342		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.12335138147224342 | validation: 0.3170452633656532]
	TIME [epoch: 12.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12797368623836258		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.12797368623836258 | validation: 0.2822632068416759]
	TIME [epoch: 12.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296302989147612		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.12296302989147612 | validation: 0.30281789957347155]
	TIME [epoch: 12.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11955978849884905		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.11955978849884905 | validation: 0.2992418084352171]
	TIME [epoch: 12.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124270592309806		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.124270592309806 | validation: 0.29934687952150507]
	TIME [epoch: 12.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11840853093561561		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.11840853093561561 | validation: 0.2926592941204502]
	TIME [epoch: 12.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861880965780528		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.12861880965780528 | validation: 0.31202860625584833]
	TIME [epoch: 12.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377195774979816		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13377195774979816 | validation: 0.31248071374246084]
	TIME [epoch: 12.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11622968066454083		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.11622968066454083 | validation: 0.3100606550259962]
	TIME [epoch: 12.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11282767619881055		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.11282767619881055 | validation: 0.31910646286131816]
	TIME [epoch: 12.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12387176986295309		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.12387176986295309 | validation: 0.32535373173343146]
	TIME [epoch: 12.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11804026105818373		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11804026105818373 | validation: 0.30532883115734705]
	TIME [epoch: 12.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12188522219762815		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.12188522219762815 | validation: 0.31214575658426713]
	TIME [epoch: 12.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226657914338573		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.12226657914338573 | validation: 0.3003799659976783]
	TIME [epoch: 12.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721146868910908		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.13721146868910908 | validation: 0.29357597643019084]
	TIME [epoch: 12.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251611002220227		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14251611002220227 | validation: 0.3128446724370244]
	TIME [epoch: 12.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13570290602735433		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13570290602735433 | validation: 0.2929223287370694]
	TIME [epoch: 12.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574137325218613		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1574137325218613 | validation: 0.3068564462707897]
	TIME [epoch: 12.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12928540766092472		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.12928540766092472 | validation: 0.29563887680706125]
	TIME [epoch: 12.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328320124010234		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.1328320124010234 | validation: 0.3038167424673698]
	TIME [epoch: 12.4 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109756104320821		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.12109756104320821 | validation: 0.2983015246214435]
	TIME [epoch: 12.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577015357838764		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.12577015357838764 | validation: 0.31044362545631216]
	TIME [epoch: 12.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13542020926278076		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.13542020926278076 | validation: 0.3049580072431615]
	TIME [epoch: 12.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12887518145378787		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.12887518145378787 | validation: 0.30922511863275515]
	TIME [epoch: 12.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11640291760002495		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.11640291760002495 | validation: 0.3036789912419928]
	TIME [epoch: 12.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124894067777124		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.13124894067777124 | validation: 0.2964289524679487]
	TIME [epoch: 12.4 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759487886990996		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.11759487886990996 | validation: 0.32808760300042467]
	TIME [epoch: 12.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124977755653219		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.124977755653219 | validation: 0.3189538754844248]
	TIME [epoch: 12.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11973506928814923		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.11973506928814923 | validation: 0.2785359652820209]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v12_20240718_190152/states/model_facs_v4_dec2b_2dpca_v12_382.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4523.354 seconds.
