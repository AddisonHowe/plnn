Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v13', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v13', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2611354582

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9568703686556775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9568703686556775 | validation: 0.8239201325711399]
	TIME [epoch: 31.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8434449133957715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8434449133957715 | validation: 1.1578735684317858]
	TIME [epoch: 4.6 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733505309452726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7733505309452726 | validation: 0.7532184698741562]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449240498265722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5449240498265722 | validation: 0.710957315911169]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5594467453195489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5594467453195489 | validation: 0.688965650087655]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349052737244515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5349052737244515 | validation: 0.7032182863708759]
	TIME [epoch: 4.57 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747856144702853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5747856144702853 | validation: 0.8360568675770447]
	TIME [epoch: 4.57 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653494800329796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5653494800329796 | validation: 0.6590444496820436]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48510132429862685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48510132429862685 | validation: 0.6425445885884835]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496480105581429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4496480105581429 | validation: 0.6018891718339547]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4126243845379343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4126243845379343 | validation: 0.602447105338042]
	TIME [epoch: 4.57 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39444560838630427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39444560838630427 | validation: 0.5383663243596053]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468675247307772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5468675247307772 | validation: 0.6184363337142147]
	TIME [epoch: 4.58 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37555364267712427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37555364267712427 | validation: 0.5041543919014817]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096060081810621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3096060081810621 | validation: 0.4523476130641032]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30003220769442285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30003220769442285 | validation: 0.4347005632948798]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34258327630863267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34258327630863267 | validation: 0.6654903848687771]
	TIME [epoch: 4.58 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399103366462269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3399103366462269 | validation: 0.4209838893911115]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3157925365090105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3157925365090105 | validation: 0.4816939482281034]
	TIME [epoch: 4.57 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28051052792202735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28051052792202735 | validation: 0.5108672139820335]
	TIME [epoch: 4.57 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34008015789653534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34008015789653534 | validation: 0.42236589345416164]
	TIME [epoch: 4.57 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22495670433816906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22495670433816906 | validation: 0.44412460221474437]
	TIME [epoch: 4.57 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.255943742362443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.255943742362443 | validation: 0.4513126671007859]
	TIME [epoch: 4.57 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354564329184755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2354564329184755 | validation: 0.44454678295309635]
	TIME [epoch: 4.56 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2395325479826687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2395325479826687 | validation: 0.495762693186081]
	TIME [epoch: 4.57 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27013139940975595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27013139940975595 | validation: 0.4417061790982866]
	TIME [epoch: 4.56 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843922191416691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2843922191416691 | validation: 0.5010492039368241]
	TIME [epoch: 4.56 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28643031018500825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28643031018500825 | validation: 0.3894008382617644]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2714993325351445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2714993325351445 | validation: 0.529751314661247]
	TIME [epoch: 4.58 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720541642851986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2720541642851986 | validation: 0.4293045609584696]
	TIME [epoch: 4.57 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26523875968612587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26523875968612587 | validation: 0.44766174513620693]
	TIME [epoch: 4.57 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24228344100198249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24228344100198249 | validation: 0.41133481485499623]
	TIME [epoch: 4.57 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24313785244368002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24313785244368002 | validation: 0.4105569956661116]
	TIME [epoch: 4.56 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22269118771331814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22269118771331814 | validation: 0.4670372679484902]
	TIME [epoch: 4.57 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30340853363186465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30340853363186465 | validation: 0.5232917663466189]
	TIME [epoch: 4.56 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21351468502569337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21351468502569337 | validation: 0.47175928771077924]
	TIME [epoch: 4.57 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28230765521722945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28230765521722945 | validation: 0.40244807285190715]
	TIME [epoch: 4.57 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23702498882122147		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.23702498882122147 | validation: 0.4584535609424094]
	TIME [epoch: 4.56 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26932358577875026		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.26932358577875026 | validation: 0.439857445109269]
	TIME [epoch: 4.56 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24512812154417735		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.24512812154417735 | validation: 0.4501389529399408]
	TIME [epoch: 4.56 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21812139190129376		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.21812139190129376 | validation: 0.46357939563223044]
	TIME [epoch: 4.56 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645882088307094		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2645882088307094 | validation: 0.4315556587215239]
	TIME [epoch: 4.56 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24767440915315814		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.24767440915315814 | validation: 0.35991300008015326]
	TIME [epoch: 4.56 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24365982383597876		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.24365982383597876 | validation: 0.4825670579915343]
	TIME [epoch: 4.58 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23728324261913972		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.23728324261913972 | validation: 0.4397548891580351]
	TIME [epoch: 4.57 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367025952779371		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2367025952779371 | validation: 0.41879330948730054]
	TIME [epoch: 4.57 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22248826894995227		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.22248826894995227 | validation: 0.41395103921968435]
	TIME [epoch: 4.56 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23331115926842744		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.23331115926842744 | validation: 0.40467943592793304]
	TIME [epoch: 4.56 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22993033788347822		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.22993033788347822 | validation: 0.3802379645245145]
	TIME [epoch: 4.56 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102919558654275		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2102919558654275 | validation: 0.4592530769647709]
	TIME [epoch: 4.56 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108133713700004		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2108133713700004 | validation: 0.3961427321213002]
	TIME [epoch: 34 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24329610108427296		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.24329610108427296 | validation: 0.37605163682789133]
	TIME [epoch: 8.83 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1986923710948532		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.1986923710948532 | validation: 0.3314301170737589]
	TIME [epoch: 8.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21927421236538214		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.21927421236538214 | validation: 0.3910212507376893]
	TIME [epoch: 8.82 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22870902225171877		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.22870902225171877 | validation: 0.37414417197019]
	TIME [epoch: 8.82 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20757533897524835		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.20757533897524835 | validation: 0.3508267324699804]
	TIME [epoch: 8.83 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22530134307348298		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.22530134307348298 | validation: 0.3685508005870285]
	TIME [epoch: 8.84 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25291233961741627		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.25291233961741627 | validation: 0.3406772576981699]
	TIME [epoch: 8.83 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20156629645794472		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.20156629645794472 | validation: 0.3690475543674475]
	TIME [epoch: 8.82 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20669430776493158		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.20669430776493158 | validation: 0.3925473573942356]
	TIME [epoch: 8.82 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2099114590797457		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2099114590797457 | validation: 0.3990335243893745]
	TIME [epoch: 8.84 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113435827971469		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2113435827971469 | validation: 0.360483851228427]
	TIME [epoch: 8.82 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22679390952186212		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.22679390952186212 | validation: 0.5371923967882779]
	TIME [epoch: 8.82 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528871424298666		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2528871424298666 | validation: 0.3554834233679584]
	TIME [epoch: 8.82 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22783132843448867		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.22783132843448867 | validation: 0.44337975811873187]
	TIME [epoch: 8.84 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551014280946021		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2551014280946021 | validation: 0.6846092557520861]
	TIME [epoch: 8.83 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649089631478976		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.2649089631478976 | validation: 0.4414695138158265]
	TIME [epoch: 8.83 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723911225645258		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.1723911225645258 | validation: 0.4285188218479075]
	TIME [epoch: 8.82 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2284815711382579		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.2284815711382579 | validation: 0.481614678155642]
	TIME [epoch: 8.84 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24536374314006548		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.24536374314006548 | validation: 0.45728615746957413]
	TIME [epoch: 8.82 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20940538138339135		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.20940538138339135 | validation: 0.34220070648630846]
	TIME [epoch: 8.82 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17909034770384466		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.17909034770384466 | validation: 0.4320907072196556]
	TIME [epoch: 8.82 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23476275425594492		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.23476275425594492 | validation: 0.3881349697068769]
	TIME [epoch: 8.84 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22221896315694037		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.22221896315694037 | validation: 0.3227353313401404]
	TIME [epoch: 8.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639856740679433		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.1639856740679433 | validation: 0.48980881411268773]
	TIME [epoch: 8.83 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20209504298810302		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.20209504298810302 | validation: 0.3963676227598897]
	TIME [epoch: 8.82 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23107494551008234		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.23107494551008234 | validation: 0.3452469421656699]
	TIME [epoch: 8.84 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19878114188329357		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.19878114188329357 | validation: 0.5622559259835048]
	TIME [epoch: 8.82 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163233740757067		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.2163233740757067 | validation: 0.3740734919805845]
	TIME [epoch: 8.82 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22107517830395113		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.22107517830395113 | validation: 0.3637127732550632]
	TIME [epoch: 8.81 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830504188753186		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.1830504188753186 | validation: 0.39338924820697024]
	TIME [epoch: 8.83 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20205612007095747		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.20205612007095747 | validation: 0.6429135522495908]
	TIME [epoch: 8.82 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24392110427305977		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.24392110427305977 | validation: 0.3493767813465669]
	TIME [epoch: 8.82 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18190632954677938		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.18190632954677938 | validation: 0.35874329093943147]
	TIME [epoch: 8.82 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16418578348279633		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.16418578348279633 | validation: 0.33268476122057455]
	TIME [epoch: 8.83 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909854472881749		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1909854472881749 | validation: 0.3916200687348793]
	TIME [epoch: 8.83 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16625771289727978		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.16625771289727978 | validation: 0.32687492083217207]
	TIME [epoch: 8.82 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18376805366707386		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.18376805366707386 | validation: 0.48083201213699756]
	TIME [epoch: 8.82 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26281030394541327		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.26281030394541327 | validation: 0.3395503064854192]
	TIME [epoch: 8.83 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954170700633856		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.1954170700633856 | validation: 0.3877336265451176]
	TIME [epoch: 8.83 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17119600375970662		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.17119600375970662 | validation: 0.4064634481432431]
	TIME [epoch: 8.82 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189522814687623		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.189522814687623 | validation: 0.3873191419137514]
	TIME [epoch: 8.82 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22113580670713717		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.22113580670713717 | validation: 0.3777619492778729]
	TIME [epoch: 8.82 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19163964798856226		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.19163964798856226 | validation: 0.4174942727226873]
	TIME [epoch: 8.83 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21254556327012541		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.21254556327012541 | validation: 0.33632993557033675]
	TIME [epoch: 8.82 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17262595531339497		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.17262595531339497 | validation: 0.39881612112955456]
	TIME [epoch: 8.82 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24960019054582713		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.24960019054582713 | validation: 0.3642772012800174]
	TIME [epoch: 8.82 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21330955475873842		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.21330955475873842 | validation: 0.43564109134824697]
	TIME [epoch: 8.83 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117036294788491		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.2117036294788491 | validation: 0.3482264127322599]
	TIME [epoch: 8.83 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17821372975492417		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.17821372975492417 | validation: 0.4563018024662328]
	TIME [epoch: 8.82 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100063248121109		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.2100063248121109 | validation: 0.2853733789569574]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15773607054480585		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.15773607054480585 | validation: 0.3670177643849586]
	TIME [epoch: 8.82 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.236414206060544		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.236414206060544 | validation: 0.30989612896867136]
	TIME [epoch: 8.83 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20285975212259888		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.20285975212259888 | validation: 0.32809425579542567]
	TIME [epoch: 8.82 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19008173488496796		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.19008173488496796 | validation: 0.5392408389991841]
	TIME [epoch: 8.82 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20342569672146518		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.20342569672146518 | validation: 0.30567622820527435]
	TIME [epoch: 8.82 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19144639613865305		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.19144639613865305 | validation: 0.3401914676778748]
	TIME [epoch: 8.83 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539572304900867		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.1539572304900867 | validation: 0.3215007160327036]
	TIME [epoch: 8.83 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18201418842136424		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.18201418842136424 | validation: 0.33567418296200613]
	TIME [epoch: 8.82 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20703255468044812		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.20703255468044812 | validation: 0.3910637158772365]
	TIME [epoch: 8.82 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165581698457657		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.165581698457657 | validation: 0.41713594074070415]
	TIME [epoch: 8.82 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20356346565790712		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.20356346565790712 | validation: 0.3918614505908037]
	TIME [epoch: 8.89 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19883675970483494		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.19883675970483494 | validation: 0.39393122931762176]
	TIME [epoch: 8.82 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21262295579473492		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.21262295579473492 | validation: 0.32109391852650093]
	TIME [epoch: 8.82 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778520084721334		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1778520084721334 | validation: 0.3368144877842287]
	TIME [epoch: 8.82 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20636245211104623		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.20636245211104623 | validation: 0.33909048297741573]
	TIME [epoch: 8.84 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17748135640638027		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.17748135640638027 | validation: 0.36024114586481876]
	TIME [epoch: 8.82 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19303057052559347		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.19303057052559347 | validation: 0.4588740296230169]
	TIME [epoch: 8.82 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21104090032395412		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.21104090032395412 | validation: 0.30869421258076074]
	TIME [epoch: 8.82 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617449541238564		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1617449541238564 | validation: 0.34769878396454035]
	TIME [epoch: 8.88 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16251467024911576		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.16251467024911576 | validation: 0.3461396786529416]
	TIME [epoch: 8.82 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19552126287744154		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.19552126287744154 | validation: 0.36589710152968125]
	TIME [epoch: 8.82 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21195610185981245		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.21195610185981245 | validation: 0.34870741234558106]
	TIME [epoch: 8.82 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662595610572288		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1662595610572288 | validation: 0.3586600229154341]
	TIME [epoch: 8.83 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18246778565096353		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.18246778565096353 | validation: 0.36350275409676314]
	TIME [epoch: 8.83 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22509391680368168		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.22509391680368168 | validation: 0.5900530259363321]
	TIME [epoch: 8.82 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21304020218356032		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.21304020218356032 | validation: 0.35660707229042654]
	TIME [epoch: 8.82 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660625368034611		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.1660625368034611 | validation: 0.3371932221733911]
	TIME [epoch: 8.82 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16361712806266127		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.16361712806266127 | validation: 0.3230981729227417]
	TIME [epoch: 8.83 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15820242526162304		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.15820242526162304 | validation: 0.3677924910166553]
	TIME [epoch: 8.82 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18327846680417445		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.18327846680417445 | validation: 0.37842804296529337]
	TIME [epoch: 8.82 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17624946025497776		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.17624946025497776 | validation: 0.4094573696939382]
	TIME [epoch: 8.82 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055098825359458		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.20055098825359458 | validation: 0.3181247704180727]
	TIME [epoch: 8.83 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407577828867448		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.16407577828867448 | validation: 0.3253457611521244]
	TIME [epoch: 8.83 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19667652303329056		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.19667652303329056 | validation: 0.3619080389056931]
	TIME [epoch: 8.82 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19433330185421716		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19433330185421716 | validation: 0.39400463209952274]
	TIME [epoch: 8.82 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19062726271030428		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.19062726271030428 | validation: 0.39908462486892937]
	TIME [epoch: 8.82 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19048032294740186		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.19048032294740186 | validation: 0.3878658691389523]
	TIME [epoch: 8.83 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1788273071410984		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.1788273071410984 | validation: 0.29812122374102057]
	TIME [epoch: 8.82 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750866923906275		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1750866923906275 | validation: 0.37261740891487427]
	TIME [epoch: 8.82 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638586898581682		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.1638586898581682 | validation: 0.34300003515658645]
	TIME [epoch: 8.82 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20105334557500898		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.20105334557500898 | validation: 0.3431659529864943]
	TIME [epoch: 8.83 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17990957273278618		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.17990957273278618 | validation: 0.33442666147177774]
	TIME [epoch: 8.82 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16289573115338635		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.16289573115338635 | validation: 0.3475175331949954]
	TIME [epoch: 8.82 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2000533554518269		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.2000533554518269 | validation: 0.5108932257146958]
	TIME [epoch: 8.82 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919111855440284		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.1919111855440284 | validation: 0.40622139239747906]
	TIME [epoch: 8.83 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17290514866163692		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.17290514866163692 | validation: 0.3716119266799407]
	TIME [epoch: 8.82 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18770454183145674		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.18770454183145674 | validation: 0.3165772815170985]
	TIME [epoch: 8.82 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587956113492256		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1587956113492256 | validation: 0.33264918933328574]
	TIME [epoch: 8.82 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17872645973645107		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.17872645973645107 | validation: 0.3011453391949179]
	TIME [epoch: 8.82 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19006425741365757		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.19006425741365757 | validation: 0.35518181806527005]
	TIME [epoch: 8.83 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18897080914596628		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.18897080914596628 | validation: 0.3324250349996946]
	TIME [epoch: 8.82 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16217818376734924		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.16217818376734924 | validation: 0.43313797093733536]
	TIME [epoch: 8.82 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17001962022378683		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.17001962022378683 | validation: 0.33293861976737565]
	TIME [epoch: 8.82 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15585948887134266		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.15585948887134266 | validation: 0.3405448930600138]
	TIME [epoch: 8.83 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17857484778407878		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17857484778407878 | validation: 0.3405202868643328]
	TIME [epoch: 8.82 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1923196654696724		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1923196654696724 | validation: 0.29275698780843906]
	TIME [epoch: 8.82 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14990390851283947		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.14990390851283947 | validation: 0.4308189691002409]
	TIME [epoch: 8.82 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183374092418939		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.183374092418939 | validation: 0.32893548223053376]
	TIME [epoch: 8.82 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16623103964551317		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.16623103964551317 | validation: 0.31719496576471906]
	TIME [epoch: 8.83 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15858070873627805		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.15858070873627805 | validation: 0.31045749446959736]
	TIME [epoch: 8.82 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670994824067982		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.1670994824067982 | validation: 0.3827431402750582]
	TIME [epoch: 8.82 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18973202252431856		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18973202252431856 | validation: 0.29091954350309696]
	TIME [epoch: 8.82 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765833080144128		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.1765833080144128 | validation: 0.336442698153662]
	TIME [epoch: 8.83 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17957831489803086		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.17957831489803086 | validation: 0.28792013713797215]
	TIME [epoch: 8.82 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385441538815725		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1385441538815725 | validation: 0.28046089067156327]
	TIME [epoch: 8.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14920109618117708		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.14920109618117708 | validation: 0.3538113370744095]
	TIME [epoch: 8.83 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15898355796338703		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.15898355796338703 | validation: 0.3729468693873495]
	TIME [epoch: 8.84 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15831327109495466		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.15831327109495466 | validation: 0.30325326251085843]
	TIME [epoch: 8.83 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15448797103876796		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.15448797103876796 | validation: 0.3478206220767212]
	TIME [epoch: 8.83 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14495240053231595		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.14495240053231595 | validation: 0.3452976776247894]
	TIME [epoch: 8.82 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15863105256959797		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.15863105256959797 | validation: 0.29453391837855686]
	TIME [epoch: 8.82 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16327068586488241		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.16327068586488241 | validation: 0.4940990784935951]
	TIME [epoch: 8.83 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766038131486488		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1766038131486488 | validation: 0.36378750298929813]
	TIME [epoch: 8.82 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15026225126029272		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.15026225126029272 | validation: 0.3367583639237381]
	TIME [epoch: 8.83 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198204521125238		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.14198204521125238 | validation: 0.33886071284056773]
	TIME [epoch: 8.82 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20035547954060728		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.20035547954060728 | validation: 0.4610779230065396]
	TIME [epoch: 8.84 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18906320986825859		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.18906320986825859 | validation: 0.36838746107331105]
	TIME [epoch: 8.83 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547593893867143		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1547593893867143 | validation: 0.3202787738948152]
	TIME [epoch: 8.82 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15393390157330575		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.15393390157330575 | validation: 0.33975607852356776]
	TIME [epoch: 8.83 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17228462173840253		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.17228462173840253 | validation: 0.38957336825469724]
	TIME [epoch: 8.83 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17214285548736113		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.17214285548736113 | validation: 0.3183238701898636]
	TIME [epoch: 8.83 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066812096164403		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.15066812096164403 | validation: 0.3028214357613367]
	TIME [epoch: 8.82 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18221294593787757		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.18221294593787757 | validation: 0.3112338843607956]
	TIME [epoch: 8.82 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701682961476945		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1701682961476945 | validation: 0.3282837750639601]
	TIME [epoch: 8.83 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716470188929099		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.1716470188929099 | validation: 0.2974182234754378]
	TIME [epoch: 8.83 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671302281582878		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1671302281582878 | validation: 0.31654941734619224]
	TIME [epoch: 8.82 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18308469496318708		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.18308469496318708 | validation: 0.3627088427490126]
	TIME [epoch: 8.82 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928727960829483		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.18928727960829483 | validation: 0.31630152001757456]
	TIME [epoch: 8.82 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17830029248111706		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.17830029248111706 | validation: 0.3827749264719041]
	TIME [epoch: 8.84 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605905715849075		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1605905715849075 | validation: 0.3375949661738108]
	TIME [epoch: 8.82 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418361429880182		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.1418361429880182 | validation: 0.31831781387718194]
	TIME [epoch: 8.82 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16493287169076282		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16493287169076282 | validation: 0.4164763937142266]
	TIME [epoch: 8.82 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585843926729907		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1585843926729907 | validation: 0.3094582153805348]
	TIME [epoch: 8.83 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154740938828873		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.154740938828873 | validation: 0.38913060074450545]
	TIME [epoch: 8.83 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15082155091600505		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.15082155091600505 | validation: 0.28924402114879655]
	TIME [epoch: 8.82 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16534804329974237		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.16534804329974237 | validation: 0.2916560722116332]
	TIME [epoch: 8.82 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1667226951155774		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.1667226951155774 | validation: 0.4696123439234433]
	TIME [epoch: 8.83 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15377831942649792		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.15377831942649792 | validation: 0.3801887933926722]
	TIME [epoch: 8.83 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15907426095149263		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.15907426095149263 | validation: 0.31083474227151836]
	TIME [epoch: 8.82 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321175453434642		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1321175453434642 | validation: 0.33668342035184506]
	TIME [epoch: 8.83 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16675327442740234		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.16675327442740234 | validation: 0.3458226591846762]
	TIME [epoch: 8.82 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17508074183598338		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.17508074183598338 | validation: 0.3078098492454478]
	TIME [epoch: 8.83 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14899255523396499		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.14899255523396499 | validation: 0.2987822882955818]
	TIME [epoch: 8.82 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15359943081006958		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.15359943081006958 | validation: 0.3548517240077121]
	TIME [epoch: 8.82 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15670417809531242		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.15670417809531242 | validation: 0.3444774788951086]
	TIME [epoch: 8.82 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16437524107328585		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.16437524107328585 | validation: 0.3038271000174904]
	TIME [epoch: 8.83 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14922021368780042		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.14922021368780042 | validation: 0.32895517233565624]
	TIME [epoch: 8.83 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17808915597712796		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.17808915597712796 | validation: 0.3102258399066258]
	TIME [epoch: 8.82 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17593501500040165		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.17593501500040165 | validation: 0.28931701306962243]
	TIME [epoch: 8.82 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530244133380793		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1530244133380793 | validation: 0.2857685991429454]
	TIME [epoch: 8.83 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15116258222258924		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15116258222258924 | validation: 0.3804765158377647]
	TIME [epoch: 8.83 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690313443152216		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1690313443152216 | validation: 0.34136348272260486]
	TIME [epoch: 8.83 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15429624646083911		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.15429624646083911 | validation: 0.33906838866895217]
	TIME [epoch: 8.82 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676332646130081		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1676332646130081 | validation: 0.3658808319275712]
	TIME [epoch: 8.82 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16726117054952785		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.16726117054952785 | validation: 0.4037413288860515]
	TIME [epoch: 8.83 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18016658954123163		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.18016658954123163 | validation: 0.3625811018310702]
	TIME [epoch: 8.83 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383822686482157		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.15383822686482157 | validation: 0.3346643144522254]
	TIME [epoch: 8.82 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16005864879289558		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.16005864879289558 | validation: 0.3006850246324075]
	TIME [epoch: 8.82 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18781132659500926		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.18781132659500926 | validation: 0.328073158598878]
	TIME [epoch: 8.83 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17687831076919086		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.17687831076919086 | validation: 0.4489520533012252]
	TIME [epoch: 8.83 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17644017442238474		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.17644017442238474 | validation: 0.3327801776505775]
	TIME [epoch: 8.82 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900229776042093		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.14900229776042093 | validation: 0.30437640455635084]
	TIME [epoch: 8.82 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15659622034729212		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.15659622034729212 | validation: 0.30468050450715506]
	TIME [epoch: 8.82 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15894363317436444		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.15894363317436444 | validation: 0.2928200148994411]
	TIME [epoch: 8.83 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15282429645474235		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.15282429645474235 | validation: 0.38108139840399075]
	TIME [epoch: 8.82 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14783256959150978		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.14783256959150978 | validation: 0.4100926015442071]
	TIME [epoch: 8.82 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17683695001064595		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.17683695001064595 | validation: 0.3159903710156134]
	TIME [epoch: 8.82 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1825461523483118		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.1825461523483118 | validation: 0.38839739770309445]
	TIME [epoch: 8.83 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986049565360516		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15986049565360516 | validation: 0.3205203087448781]
	TIME [epoch: 8.82 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16197948352043906		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.16197948352043906 | validation: 0.296866705390669]
	TIME [epoch: 8.82 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441519866961275		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1441519866961275 | validation: 0.3767624935857398]
	TIME [epoch: 8.82 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16449071421402509		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.16449071421402509 | validation: 0.31197250137131854]
	TIME [epoch: 8.83 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14513801632309645		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.14513801632309645 | validation: 0.3229590295345457]
	TIME [epoch: 8.83 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15280196042532945		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.15280196042532945 | validation: 0.32279622112363926]
	TIME [epoch: 8.82 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892104443708069		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1892104443708069 | validation: 0.30152375678182125]
	TIME [epoch: 8.82 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15850865451310192		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15850865451310192 | validation: 0.33898534391017404]
	TIME [epoch: 8.82 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14885991065651227		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.14885991065651227 | validation: 0.313627752819301]
	TIME [epoch: 8.83 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630570648307284		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.14630570648307284 | validation: 0.2993531960735771]
	TIME [epoch: 8.82 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422504706896921		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1422504706896921 | validation: 0.3011317350903334]
	TIME [epoch: 8.82 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513236401116711		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1513236401116711 | validation: 0.3437382191733892]
	TIME [epoch: 8.82 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15969007982629752		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15969007982629752 | validation: 0.39234473764548183]
	TIME [epoch: 8.83 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17336272564537172		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.17336272564537172 | validation: 0.34988186801421806]
	TIME [epoch: 8.83 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17694445955897148		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.17694445955897148 | validation: 0.38685921022917297]
	TIME [epoch: 8.82 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16100787767025654		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.16100787767025654 | validation: 0.34278465266791547]
	TIME [epoch: 8.82 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577394327828776		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.1577394327828776 | validation: 0.29254018447004854]
	TIME [epoch: 8.83 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14063358347001656		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.14063358347001656 | validation: 0.3254636786901231]
	TIME [epoch: 8.83 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17937939863769503		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.17937939863769503 | validation: 0.29198970906032284]
	TIME [epoch: 8.82 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288276630573004		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.16288276630573004 | validation: 0.3617858721255364]
	TIME [epoch: 8.82 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112408540861604		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.14112408540861604 | validation: 0.3015836776680139]
	TIME [epoch: 8.82 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883674458112847		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.14883674458112847 | validation: 0.30184804861217585]
	TIME [epoch: 8.83 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16511499601571364		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.16511499601571364 | validation: 0.3948625661579626]
	TIME [epoch: 8.82 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15379267626155052		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.15379267626155052 | validation: 0.358468647351962]
	TIME [epoch: 8.83 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14181444228046247		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.14181444228046247 | validation: 0.33202664739428966]
	TIME [epoch: 8.82 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152894174877779		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.152894174877779 | validation: 0.3557051876582923]
	TIME [epoch: 8.83 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18313116750653496		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.18313116750653496 | validation: 0.4599524365245563]
	TIME [epoch: 8.83 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686805541449662		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.1686805541449662 | validation: 0.30010555974711917]
	TIME [epoch: 8.82 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15608889672809698		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.15608889672809698 | validation: 0.34124951222754213]
	TIME [epoch: 8.82 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398659099816236		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.14398659099816236 | validation: 0.2756808032060704]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14015826253236535		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.14015826253236535 | validation: 0.3052383414473196]
	TIME [epoch: 8.84 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14844626131603902		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.14844626131603902 | validation: 0.35774870523785884]
	TIME [epoch: 8.83 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16066046311555596		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.16066046311555596 | validation: 0.33625802181954906]
	TIME [epoch: 8.83 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1583945046867414		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1583945046867414 | validation: 0.3341352808343231]
	TIME [epoch: 8.83 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13630326459071712		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.13630326459071712 | validation: 0.3778342052354962]
	TIME [epoch: 8.84 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620087425001131		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.1620087425001131 | validation: 0.3217260760042464]
	TIME [epoch: 8.82 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15708893159153814		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.15708893159153814 | validation: 0.3615274570384426]
	TIME [epoch: 8.83 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813424773645673		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.14813424773645673 | validation: 0.29733836866186]
	TIME [epoch: 8.82 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14907335830735682		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.14907335830735682 | validation: 0.30788915066674694]
	TIME [epoch: 8.83 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13294685647853097		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.13294685647853097 | validation: 0.324642193397515]
	TIME [epoch: 8.83 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988256358503444		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.12988256358503444 | validation: 0.3108737255044883]
	TIME [epoch: 8.82 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15848701294472858		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15848701294472858 | validation: 0.3131643839670643]
	TIME [epoch: 8.82 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17247550476866635		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.17247550476866635 | validation: 0.30203207358320217]
	TIME [epoch: 8.82 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672085581864772		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.1672085581864772 | validation: 0.3971971577686958]
	TIME [epoch: 8.84 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568612697337423		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.1568612697337423 | validation: 0.3370181880436618]
	TIME [epoch: 8.83 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646127735431183		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.1646127735431183 | validation: 0.36352830977084694]
	TIME [epoch: 8.83 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808835522854607		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1808835522854607 | validation: 0.3398068636577094]
	TIME [epoch: 8.82 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914160178167992		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.13914160178167992 | validation: 0.3613697183541608]
	TIME [epoch: 8.83 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15320671472651096		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.15320671472651096 | validation: 0.2946322382608331]
	TIME [epoch: 8.83 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14405053713500487		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14405053713500487 | validation: 0.2852182190394505]
	TIME [epoch: 8.82 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15068561525633947		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.15068561525633947 | validation: 0.3156270003999011]
	TIME [epoch: 8.82 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939740240265945		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.14939740240265945 | validation: 0.300462915777314]
	TIME [epoch: 8.83 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13777548720640548		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.13777548720640548 | validation: 0.35596564533731867]
	TIME [epoch: 8.83 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351707037822807		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.1351707037822807 | validation: 0.3496221990460049]
	TIME [epoch: 8.82 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13288792587177795		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.13288792587177795 | validation: 0.29142528001723506]
	TIME [epoch: 8.82 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15628977214120882		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.15628977214120882 | validation: 0.3093086160673782]
	TIME [epoch: 8.82 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189941926267635		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.14189941926267635 | validation: 0.3160921756534684]
	TIME [epoch: 8.84 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16628967586272542		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.16628967586272542 | validation: 0.31937398286531155]
	TIME [epoch: 8.82 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14128431853102513		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.14128431853102513 | validation: 0.3395913083180867]
	TIME [epoch: 8.82 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544212058847029		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1544212058847029 | validation: 0.34143937133477975]
	TIME [epoch: 8.82 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16171176353179756		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.16171176353179756 | validation: 0.3282141824297305]
	TIME [epoch: 8.83 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15944209688092065		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.15944209688092065 | validation: 0.40433560574231303]
	TIME [epoch: 8.82 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580146674483596		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1580146674483596 | validation: 0.34198289699125506]
	TIME [epoch: 8.82 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598692400078593		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1598692400078593 | validation: 0.3114195683927913]
	TIME [epoch: 8.82 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13311577387148027		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13311577387148027 | validation: 0.2801247658250467]
	TIME [epoch: 8.83 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15296821117081127		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.15296821117081127 | validation: 0.30873185460975056]
	TIME [epoch: 8.83 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589744703636317		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1589744703636317 | validation: 0.2965130577457923]
	TIME [epoch: 8.82 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14869534575721866		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.14869534575721866 | validation: 0.2952819166966903]
	TIME [epoch: 8.82 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471118199172772		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.1471118199172772 | validation: 0.3735397887131528]
	TIME [epoch: 8.82 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15203632898167224		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.15203632898167224 | validation: 0.33940745277419]
	TIME [epoch: 8.83 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442062605579211		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.1442062605579211 | validation: 0.3088017134017188]
	TIME [epoch: 8.83 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15053051119553884		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15053051119553884 | validation: 0.29807551935581017]
	TIME [epoch: 8.83 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505267740470118		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.1505267740470118 | validation: 0.30001890892437194]
	TIME [epoch: 8.82 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138264684480109		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.138264684480109 | validation: 0.2754331265700615]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139602035491267		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.139602035491267 | validation: 0.3370003262604804]
	TIME [epoch: 8.82 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405213208622288		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.13405213208622288 | validation: 0.34180762269494913]
	TIME [epoch: 8.81 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15565823070921583		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.15565823070921583 | validation: 0.31043371902476535]
	TIME [epoch: 8.82 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583873453577556		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.14583873453577556 | validation: 0.3010107327609403]
	TIME [epoch: 8.82 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499733473345172		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14499733473345172 | validation: 0.3091925321898035]
	TIME [epoch: 8.83 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13571188898540185		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.13571188898540185 | validation: 0.29031818491315414]
	TIME [epoch: 8.82 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139511903008568		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.139511903008568 | validation: 0.3165876773269535]
	TIME [epoch: 8.83 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449634832056388		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.14449634832056388 | validation: 0.3480607506212002]
	TIME [epoch: 8.83 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558948604512074		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.1558948604512074 | validation: 0.3704500230172716]
	TIME [epoch: 8.84 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16820868381334764		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.16820868381334764 | validation: 0.29266140738974167]
	TIME [epoch: 8.83 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14518230714650415		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.14518230714650415 | validation: 0.3396117842766724]
	TIME [epoch: 8.83 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559099985368994		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13559099985368994 | validation: 0.30486174310817354]
	TIME [epoch: 8.82 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567383016764238		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1567383016764238 | validation: 0.31183255586877506]
	TIME [epoch: 8.83 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13040389692305313		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.13040389692305313 | validation: 0.3002166650693867]
	TIME [epoch: 8.83 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15076579650791727		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.15076579650791727 | validation: 0.3062305320532261]
	TIME [epoch: 8.83 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288776570712751		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1288776570712751 | validation: 0.2965116450840831]
	TIME [epoch: 8.81 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395728366496209		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1395728366496209 | validation: 0.2872433314088128]
	TIME [epoch: 8.83 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798314722648835		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.15798314722648835 | validation: 0.4072112064356633]
	TIME [epoch: 8.84 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586252118400759		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.1586252118400759 | validation: 0.2948212556640618]
	TIME [epoch: 8.81 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588321347103037		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.1588321347103037 | validation: 0.32789411695931686]
	TIME [epoch: 8.83 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14914520752369548		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.14914520752369548 | validation: 0.3279693314165891]
	TIME [epoch: 8.83 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456973105578596		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13456973105578596 | validation: 0.32726018563241543]
	TIME [epoch: 8.82 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14285132664970873		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.14285132664970873 | validation: 0.30543911210995617]
	TIME [epoch: 8.81 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486791294855529		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.1486791294855529 | validation: 0.30406001918459497]
	TIME [epoch: 8.81 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14604099776714682		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.14604099776714682 | validation: 0.3389733957752431]
	TIME [epoch: 8.82 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13645894660088698		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.13645894660088698 | validation: 0.34954309642682285]
	TIME [epoch: 8.82 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13910808164462085		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13910808164462085 | validation: 0.3648766359197207]
	TIME [epoch: 8.81 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809091521673465		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14809091521673465 | validation: 0.3190307247875126]
	TIME [epoch: 8.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14910581092194644		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.14910581092194644 | validation: 0.32584276572678816]
	TIME [epoch: 8.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15106746028511092		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.15106746028511092 | validation: 0.31256745748674514]
	TIME [epoch: 8.81 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12562581590561106		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12562581590561106 | validation: 0.28928925503634606]
	TIME [epoch: 8.83 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521535626185009		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.1521535626185009 | validation: 0.32744691636555784]
	TIME [epoch: 8.81 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13948813914806196		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13948813914806196 | validation: 0.2917560969376311]
	TIME [epoch: 8.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13951498892271225		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13951498892271225 | validation: 0.2779451127047069]
	TIME [epoch: 8.81 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351500951519242		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.14351500951519242 | validation: 0.32010705919265914]
	TIME [epoch: 8.84 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15600455777967345		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.15600455777967345 | validation: 0.29411781531409226]
	TIME [epoch: 8.81 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15290366722599663		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.15290366722599663 | validation: 0.2984242968934875]
	TIME [epoch: 8.81 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14024218737284977		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.14024218737284977 | validation: 0.2882833413736668]
	TIME [epoch: 8.82 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410201605008563		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1410201605008563 | validation: 0.32097863087122647]
	TIME [epoch: 8.83 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501489339358696		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1501489339358696 | validation: 0.29246828705892325]
	TIME [epoch: 8.84 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13221211731299487		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.13221211731299487 | validation: 0.335729033835883]
	TIME [epoch: 8.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364781675772597		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.13364781675772597 | validation: 0.2955244596830916]
	TIME [epoch: 8.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220464020244335		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.13220464020244335 | validation: 0.29550310795737594]
	TIME [epoch: 8.83 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380658480858676		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.1380658480858676 | validation: 0.295831091056375]
	TIME [epoch: 8.82 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14039740046493654		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.14039740046493654 | validation: 0.29020043409817514]
	TIME [epoch: 8.82 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14710610660183177		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.14710610660183177 | validation: 0.3376004469804531]
	TIME [epoch: 8.82 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358983498520426		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.1358983498520426 | validation: 0.28191431279378026]
	TIME [epoch: 8.82 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855941251536268		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.12855941251536268 | validation: 0.32834346588388724]
	TIME [epoch: 8.84 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14265634124765975		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.14265634124765975 | validation: 0.30401407896272387]
	TIME [epoch: 8.82 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12973721626760945		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.12973721626760945 | validation: 0.27638974937809246]
	TIME [epoch: 8.83 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415153799438533		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.12415153799438533 | validation: 0.2854273651815997]
	TIME [epoch: 8.82 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14267091691168793		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.14267091691168793 | validation: 0.29715669275610196]
	TIME [epoch: 8.83 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14851487198878027		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.14851487198878027 | validation: 0.30738802356346484]
	TIME [epoch: 8.83 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137305585503918		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.137305585503918 | validation: 0.3076591807559072]
	TIME [epoch: 8.83 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13735144799135304		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.13735144799135304 | validation: 0.28467954498169884]
	TIME [epoch: 8.82 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15768130497961055		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.15768130497961055 | validation: 0.2833492900133369]
	TIME [epoch: 8.83 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12905942065213252		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.12905942065213252 | validation: 0.31260507652507297]
	TIME [epoch: 8.83 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14462319140715477		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.14462319140715477 | validation: 0.2907190666272089]
	TIME [epoch: 8.82 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13360177634277695		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.13360177634277695 | validation: 0.30307711617331695]
	TIME [epoch: 8.83 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15122177960545136		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.15122177960545136 | validation: 0.2974256404850757]
	TIME [epoch: 8.82 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13599967621946507		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.13599967621946507 | validation: 0.309635304744216]
	TIME [epoch: 8.84 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383022640156883		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.1383022640156883 | validation: 0.3205569107502437]
	TIME [epoch: 8.83 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13970695009318748		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.13970695009318748 | validation: 0.4017325408063626]
	TIME [epoch: 8.83 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1430368850172164		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1430368850172164 | validation: 0.2911626034856909]
	TIME [epoch: 8.82 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484295933889086		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.1484295933889086 | validation: 0.3134461674329956]
	TIME [epoch: 8.84 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137552478290416		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.137552478290416 | validation: 0.29602487095665214]
	TIME [epoch: 8.83 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15274062498733024		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.15274062498733024 | validation: 0.29077190396185965]
	TIME [epoch: 8.81 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411520908894654		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1411520908894654 | validation: 0.30992682480154554]
	TIME [epoch: 8.83 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252929374283212		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1252929374283212 | validation: 0.3180776560154168]
	TIME [epoch: 8.83 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278557652198203		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.1278557652198203 | validation: 0.3294334810200087]
	TIME [epoch: 8.84 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12716664266584668		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.12716664266584668 | validation: 0.2839535824201597]
	TIME [epoch: 8.81 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929823870452218		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13929823870452218 | validation: 0.2928073462792374]
	TIME [epoch: 8.82 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12175427370089377		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.12175427370089377 | validation: 0.3112100720247716]
	TIME [epoch: 8.83 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109469794475687		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.14109469794475687 | validation: 0.2964219205951566]
	TIME [epoch: 8.83 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609101661927712		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.14609101661927712 | validation: 0.32023225627113505]
	TIME [epoch: 8.83 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13738509285822792		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.13738509285822792 | validation: 0.3507197853247399]
	TIME [epoch: 8.82 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356891630409064		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1356891630409064 | validation: 0.28819961709614467]
	TIME [epoch: 8.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170820639576675		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.13170820639576675 | validation: 0.26917904801845466]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353320352327487		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.1353320352327487 | validation: 0.3236154169350607]
	TIME [epoch: 8.84 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133478276440253		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.133478276440253 | validation: 0.2911685870136901]
	TIME [epoch: 8.83 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14031022568418286		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.14031022568418286 | validation: 0.29337066496767245]
	TIME [epoch: 8.82 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441057851009696		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.1441057851009696 | validation: 0.3067891728293258]
	TIME [epoch: 8.82 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137438333396644		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.12137438333396644 | validation: 0.3159704591470499]
	TIME [epoch: 8.84 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14574344529650937		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.14574344529650937 | validation: 0.3745297760989466]
	TIME [epoch: 8.82 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14256294661946242		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.14256294661946242 | validation: 0.3045278990918731]
	TIME [epoch: 8.82 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135877461081873		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.12135877461081873 | validation: 0.3103892522547554]
	TIME [epoch: 8.82 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14989646711814775		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.14989646711814775 | validation: 0.292879928434523]
	TIME [epoch: 8.83 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319328080755972		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1319328080755972 | validation: 0.2911834334762903]
	TIME [epoch: 8.83 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15144491069287117		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.15144491069287117 | validation: 0.3623911824344708]
	TIME [epoch: 8.83 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13589083635364235		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13589083635364235 | validation: 0.3218116188430381]
	TIME [epoch: 8.82 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13975171517270324		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.13975171517270324 | validation: 0.34931279242414015]
	TIME [epoch: 8.83 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15629311467814044		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.15629311467814044 | validation: 0.2934170139667473]
	TIME [epoch: 8.84 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13515959848763803		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.13515959848763803 | validation: 0.32632848282698024]
	TIME [epoch: 8.83 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326434018467058		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.1326434018467058 | validation: 0.27802841052528915]
	TIME [epoch: 8.83 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283932954224401		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.1283932954224401 | validation: 0.33914428986781575]
	TIME [epoch: 8.82 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14479298408686722		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.14479298408686722 | validation: 0.3233666358372494]
	TIME [epoch: 8.83 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13040674509046754		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13040674509046754 | validation: 0.316948046890202]
	TIME [epoch: 8.82 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13082612801267648		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.13082612801267648 | validation: 0.30331396666220617]
	TIME [epoch: 8.82 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723247481671223		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1723247481671223 | validation: 0.3318562279412403]
	TIME [epoch: 8.82 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13303338757749636		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13303338757749636 | validation: 0.3143033191418775]
	TIME [epoch: 8.83 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12177758515797067		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.12177758515797067 | validation: 0.2958478240611898]
	TIME [epoch: 8.82 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170863844249948		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.14170863844249948 | validation: 0.2872080911543683]
	TIME [epoch: 8.82 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12976007884244137		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.12976007884244137 | validation: 0.30335839476911136]
	TIME [epoch: 8.82 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13696187684616407		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.13696187684616407 | validation: 0.29910115135542714]
	TIME [epoch: 8.82 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355424698590154		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.1355424698590154 | validation: 0.27759136699535625]
	TIME [epoch: 8.83 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017048305254537		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.14017048305254537 | validation: 0.3204379150442114]
	TIME [epoch: 8.82 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010176297977197		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.13010176297977197 | validation: 0.2896676370338882]
	TIME [epoch: 8.81 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766908740261078		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.14766908740261078 | validation: 0.2803254085910868]
	TIME [epoch: 8.82 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16236451209606817		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.16236451209606817 | validation: 0.3342587774755213]
	TIME [epoch: 8.83 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16446535924768213		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.16446535924768213 | validation: 0.29207143851691963]
	TIME [epoch: 8.82 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674551259665677		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.13674551259665677 | validation: 0.2920989551855749]
	TIME [epoch: 8.82 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815567724445785		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13815567724445785 | validation: 0.34838930137389124]
	TIME [epoch: 8.81 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339252121952167		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.14339252121952167 | validation: 0.28685448481138454]
	TIME [epoch: 8.83 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423608757123414		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.15423608757123414 | validation: 0.30495072482443253]
	TIME [epoch: 8.82 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12679690737626523		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.12679690737626523 | validation: 0.3021653837390959]
	TIME [epoch: 8.82 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278359051337901		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.1278359051337901 | validation: 0.28858730202423416]
	TIME [epoch: 8.82 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409293605511876		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.1409293605511876 | validation: 0.2819030737107809]
	TIME [epoch: 8.82 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392973109378487		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1392973109378487 | validation: 0.31654085609681387]
	TIME [epoch: 8.83 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13810427889674867		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.13810427889674867 | validation: 0.31016041493595814]
	TIME [epoch: 8.82 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679157807848548		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.15679157807848548 | validation: 0.30712192139747624]
	TIME [epoch: 8.82 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377527304286287		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.1377527304286287 | validation: 0.28467105274111504]
	TIME [epoch: 8.81 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487069171620946		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1487069171620946 | validation: 0.30592734046919523]
	TIME [epoch: 8.82 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13910482760459383		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.13910482760459383 | validation: 0.301531207923327]
	TIME [epoch: 8.83 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13460505097661826		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.13460505097661826 | validation: 0.3106072133794607]
	TIME [epoch: 8.83 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420501840144496		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.15420501840144496 | validation: 0.29250158746298655]
	TIME [epoch: 8.83 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008741168768357		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.14008741168768357 | validation: 0.2795881665329505]
	TIME [epoch: 8.83 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301741555160314		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.1301741555160314 | validation: 0.283938425680841]
	TIME [epoch: 8.83 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495539145203081		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.1495539145203081 | validation: 0.28405698199279705]
	TIME [epoch: 8.83 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12464594966795739		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.12464594966795739 | validation: 0.2842231352473645]
	TIME [epoch: 8.81 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929817646865972		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.13929817646865972 | validation: 0.35766413493101057]
	TIME [epoch: 8.84 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486254167018149		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.12486254167018149 | validation: 0.27430659177355754]
	TIME [epoch: 8.84 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14119505322643627		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.14119505322643627 | validation: 0.2867576982913879]
	TIME [epoch: 8.81 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967916600817298		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.13967916600817298 | validation: 0.2946729332308564]
	TIME [epoch: 8.82 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13066841202978674		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.13066841202978674 | validation: 0.30966191901239276]
	TIME [epoch: 8.84 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215104492784736		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.14215104492784736 | validation: 0.28455829330828275]
	TIME [epoch: 8.83 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13271218651212544		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13271218651212544 | validation: 0.3258371829497621]
	TIME [epoch: 8.81 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450426523883962		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.12450426523883962 | validation: 0.2910268908231084]
	TIME [epoch: 8.83 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14253915574607456		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.14253915574607456 | validation: 0.3117407832036776]
	TIME [epoch: 8.83 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12826891317488842		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.12826891317488842 | validation: 0.3143332141686197]
	TIME [epoch: 8.84 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290454639468489		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.1290454639468489 | validation: 0.28387810914812406]
	TIME [epoch: 8.83 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580829604509966		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.15580829604509966 | validation: 0.2802354553362341]
	TIME [epoch: 8.83 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14723824838901217		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.14723824838901217 | validation: 0.29565854676495357]
	TIME [epoch: 8.86 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402441434504615		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1402441434504615 | validation: 0.2949432875490023]
	TIME [epoch: 8.83 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616184941716859		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.1616184941716859 | validation: 0.32635810682430777]
	TIME [epoch: 8.81 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13675166239429615		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.13675166239429615 | validation: 0.2798026530597573]
	TIME [epoch: 8.83 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002007853406088		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.12002007853406088 | validation: 0.3030305074267818]
	TIME [epoch: 8.84 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15045003743708707		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.15045003743708707 | validation: 0.2756603989004321]
	TIME [epoch: 8.84 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859897162956797		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.13859897162956797 | validation: 0.28733184853528515]
	TIME [epoch: 8.81 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11697000558027465		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11697000558027465 | validation: 0.3254381297973694]
	TIME [epoch: 8.83 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327284882410987		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.1327284882410987 | validation: 0.28676257395230986]
	TIME [epoch: 8.83 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566820281456893		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.13566820281456893 | validation: 0.2995413927888921]
	TIME [epoch: 8.83 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439119465106902		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.1439119465106902 | validation: 0.35107564947658854]
	TIME [epoch: 8.82 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408605390825291		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.1408605390825291 | validation: 0.30680571865792405]
	TIME [epoch: 8.81 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434251335681325		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1434251335681325 | validation: 0.2849036534785223]
	TIME [epoch: 8.82 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844499787526707		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.13844499787526707 | validation: 0.2912745303364268]
	TIME [epoch: 8.82 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320375990711563		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.1320375990711563 | validation: 0.30565481531564764]
	TIME [epoch: 8.83 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15095581120423085		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.15095581120423085 | validation: 0.2854678385091125]
	TIME [epoch: 8.81 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314438505857219		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1314438505857219 | validation: 0.3059007293913555]
	TIME [epoch: 8.82 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13508726836549806		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.13508726836549806 | validation: 0.2928605594695885]
	TIME [epoch: 8.82 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261867311692896		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.1261867311692896 | validation: 0.31013435315105037]
	TIME [epoch: 8.83 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367188546459761		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1367188546459761 | validation: 0.3124680817585093]
	TIME [epoch: 8.83 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374678373394479		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.1374678373394479 | validation: 0.2955901994316469]
	TIME [epoch: 8.82 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14384037453829815		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.14384037453829815 | validation: 0.3058412400873525]
	TIME [epoch: 8.84 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133646014409514		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.133646014409514 | validation: 0.31528036288265965]
	TIME [epoch: 8.82 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12371490821191578		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.12371490821191578 | validation: 0.3192028596630478]
	TIME [epoch: 8.82 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190725447027362		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1190725447027362 | validation: 0.2808709441553803]
	TIME [epoch: 8.83 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337968039893621		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.1337968039893621 | validation: 0.29171425123111727]
	TIME [epoch: 8.84 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739336050483654		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.12739336050483654 | validation: 0.2943045916665777]
	TIME [epoch: 8.83 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14334543344894402		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.14334543344894402 | validation: 0.2818559240280087]
	TIME [epoch: 8.82 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15614744624687443		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.15614744624687443 | validation: 0.32683886143923035]
	TIME [epoch: 8.81 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809780363716593		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.14809780363716593 | validation: 0.30085534475746856]
	TIME [epoch: 8.84 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14102186517808551		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.14102186517808551 | validation: 0.2958707088985068]
	TIME [epoch: 8.83 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418413613383786		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.1418413613383786 | validation: 0.2957258819741966]
	TIME [epoch: 8.83 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268696675214891		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.1268696675214891 | validation: 0.29787423554029385]
	TIME [epoch: 8.82 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285640747461066		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.1285640747461066 | validation: 0.2776095871089827]
	TIME [epoch: 8.84 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198815309105516		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.13198815309105516 | validation: 0.2957780063428426]
	TIME [epoch: 8.83 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14859604469741902		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.14859604469741902 | validation: 0.2934475937473988]
	TIME [epoch: 8.83 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624994163564058		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.13624994163564058 | validation: 0.29510812949433823]
	TIME [epoch: 8.83 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144752398739254		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.13144752398739254 | validation: 0.31338629063536283]
	TIME [epoch: 8.82 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707884875875138		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.14707884875875138 | validation: 0.28933387441462627]
	TIME [epoch: 8.84 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346858246985506		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1346858246985506 | validation: 0.29868677785052905]
	TIME [epoch: 8.81 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12687873924688445		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.12687873924688445 | validation: 0.27413855560730643]
	TIME [epoch: 8.81 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12363397985026353		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.12363397985026353 | validation: 0.3057523332723665]
	TIME [epoch: 8.82 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12746210312569534		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.12746210312569534 | validation: 0.28089182657225265]
	TIME [epoch: 8.82 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13696353022831176		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13696353022831176 | validation: 0.3343801166104816]
	TIME [epoch: 8.82 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13352611496105518		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.13352611496105518 | validation: 0.2800118801133813]
	TIME [epoch: 8.81 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14343153443445558		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.14343153443445558 | validation: 0.3019360726437849]
	TIME [epoch: 8.83 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036657229889649		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.14036657229889649 | validation: 0.2985518581168682]
	TIME [epoch: 8.84 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13557747769470013		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.13557747769470013 | validation: 0.3030517648828897]
	TIME [epoch: 8.83 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287027475085741		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1287027475085741 | validation: 0.3065286405060733]
	TIME [epoch: 8.82 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13426582906943946		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.13426582906943946 | validation: 0.2820270719567125]
	TIME [epoch: 8.83 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597923867297425		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.12597923867297425 | validation: 0.3085190839120181]
	TIME [epoch: 8.84 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11671103252084945		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.11671103252084945 | validation: 0.2935609316769204]
	TIME [epoch: 8.83 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364077100469924		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.1364077100469924 | validation: 0.2887460495495354]
	TIME [epoch: 8.83 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13633907722299865		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.13633907722299865 | validation: 0.3006521629889794]
	TIME [epoch: 8.83 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123208816281179		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.123208816281179 | validation: 0.29877735180728326]
	TIME [epoch: 8.84 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044177906370012		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.14044177906370012 | validation: 0.2942271262638152]
	TIME [epoch: 8.83 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13345927389375842		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.13345927389375842 | validation: 0.3007968879820558]
	TIME [epoch: 44.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12615402634170161		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.12615402634170161 | validation: 0.29999714225816715]
	TIME [epoch: 19 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432332590292347		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.1432332590292347 | validation: 0.2914434261227698]
	TIME [epoch: 19 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14137671750078662		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.14137671750078662 | validation: 0.28414962433178625]
	TIME [epoch: 19 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15054270903953682		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.15054270903953682 | validation: 0.3238311305513755]
	TIME [epoch: 19 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262060704616786		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.14262060704616786 | validation: 0.30946006170178064]
	TIME [epoch: 19 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13655191870622455		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.13655191870622455 | validation: 0.31210298857093344]
	TIME [epoch: 19 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12683767926739276		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.12683767926739276 | validation: 0.3096691506367301]
	TIME [epoch: 19 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14397896958650164		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.14397896958650164 | validation: 0.2882854094030041]
	TIME [epoch: 19 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11911646720045989		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.11911646720045989 | validation: 0.29494516570758783]
	TIME [epoch: 19 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14027423823216986		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.14027423823216986 | validation: 0.3371483645833368]
	TIME [epoch: 19 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13223721881864783		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.13223721881864783 | validation: 0.3001231819172983]
	TIME [epoch: 19 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14869950257268832		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.14869950257268832 | validation: 0.294838972511425]
	TIME [epoch: 19 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129239864788655		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.129239864788655 | validation: 0.2965391821002619]
	TIME [epoch: 19 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409189381417305		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.1409189381417305 | validation: 0.30180415400934213]
	TIME [epoch: 19 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11614264078400313		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.11614264078400313 | validation: 0.2929008125735084]
	TIME [epoch: 19 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374368606700348		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.1374368606700348 | validation: 0.28851589569154185]
	TIME [epoch: 19 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257320588334867		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.13257320588334867 | validation: 0.30019032042466337]
	TIME [epoch: 19 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13537269808323313		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.13537269808323313 | validation: 0.2854825648148721]
	TIME [epoch: 19 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14837401611203146		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.14837401611203146 | validation: 0.3084587351442349]
	TIME [epoch: 19 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660100138307176		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.12660100138307176 | validation: 0.30108670351112693]
	TIME [epoch: 19 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514208796970561		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.1514208796970561 | validation: 0.28570845131050837]
	TIME [epoch: 19 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215241013884356		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.12215241013884356 | validation: 0.31291430617502336]
	TIME [epoch: 19 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251232656811517		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.1251232656811517 | validation: 0.304984625540689]
	TIME [epoch: 19 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14051040423299224		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.14051040423299224 | validation: 0.3269611637633528]
	TIME [epoch: 19 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183685653432636		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.13183685653432636 | validation: 0.29160539455799883]
	TIME [epoch: 19 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13816911912657986		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.13816911912657986 | validation: 0.2965016554446277]
	TIME [epoch: 19 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13658957612307265		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.13658957612307265 | validation: 0.3060226541919075]
	TIME [epoch: 19 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12642247666409098		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.12642247666409098 | validation: 0.2892721649038855]
	TIME [epoch: 19 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465493930900581		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.12465493930900581 | validation: 0.29964055272105644]
	TIME [epoch: 19 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302293307201688		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.1302293307201688 | validation: 0.29441920783092024]
	TIME [epoch: 19 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426997049377735		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.1426997049377735 | validation: 0.31874351218293484]
	TIME [epoch: 19 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11574784806882915		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.11574784806882915 | validation: 0.28307558886183387]
	TIME [epoch: 19 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13742579941851993		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.13742579941851993 | validation: 0.2857243811889093]
	TIME [epoch: 19 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294641876827634		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.1294641876827634 | validation: 0.3058823278987098]
	TIME [epoch: 19 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12830927070627635		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.12830927070627635 | validation: 0.30955025591973145]
	TIME [epoch: 19 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844936688390636		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.13844936688390636 | validation: 0.30902591598525136]
	TIME [epoch: 19.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13530878185513764		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.13530878185513764 | validation: 0.2995157995900884]
	TIME [epoch: 19 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12431784911949549		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.12431784911949549 | validation: 0.3095873961740794]
	TIME [epoch: 19.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346275694761709		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1346275694761709 | validation: 0.30610756086134727]
	TIME [epoch: 19 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12191268710088253		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.12191268710088253 | validation: 0.29582607339990086]
	TIME [epoch: 19.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11911753301287498		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.11911753301287498 | validation: 0.28683785071135776]
	TIME [epoch: 19 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13778794470709926		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.13778794470709926 | validation: 0.2990762431173589]
	TIME [epoch: 19 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12609394051598136		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.12609394051598136 | validation: 0.29212917149716794]
	TIME [epoch: 19 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11641191955368198		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.11641191955368198 | validation: 0.3014064596372769]
	TIME [epoch: 19.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15034355946415973		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.15034355946415973 | validation: 0.28566970637892525]
	TIME [epoch: 19 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290185016697362		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.1290185016697362 | validation: 0.2791571227882104]
	TIME [epoch: 19.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14055024478394526		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.14055024478394526 | validation: 0.30627539209012095]
	TIME [epoch: 19 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451884531153037		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.1451884531153037 | validation: 0.3026031309009211]
	TIME [epoch: 19 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332498948284633		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.1332498948284633 | validation: 0.28379974375170997]
	TIME [epoch: 19 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163715814597297		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.12163715814597297 | validation: 0.2924239450732781]
	TIME [epoch: 19 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940472381645807		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.12940472381645807 | validation: 0.3226612411842689]
	TIME [epoch: 19 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396416206371186		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.1396416206371186 | validation: 0.29149234098356175]
	TIME [epoch: 19 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12857439989899483		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.12857439989899483 | validation: 0.2992338060944122]
	TIME [epoch: 19 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640888267581424		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.12640888267581424 | validation: 0.27209146647574795]
	TIME [epoch: 19 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13825853373384114		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.13825853373384114 | validation: 0.2940590104623562]
	TIME [epoch: 19 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12958442941039836		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.12958442941039836 | validation: 0.29464648427635737]
	TIME [epoch: 19 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271080930157416		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.1271080930157416 | validation: 0.306948211704614]
	TIME [epoch: 19 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122112073687465		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.14122112073687465 | validation: 0.31352778242839263]
	TIME [epoch: 19 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13596467610147783		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.13596467610147783 | validation: 0.3020915874909938]
	TIME [epoch: 19.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12787522895606057		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.12787522895606057 | validation: 0.2974931323005958]
	TIME [epoch: 19 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12341235096122823		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12341235096122823 | validation: 0.2929009413053477]
	TIME [epoch: 19 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12201519459594562		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.12201519459594562 | validation: 0.2921217728080638]
	TIME [epoch: 19 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13960976873839526		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.13960976873839526 | validation: 0.29331110691236967]
	TIME [epoch: 19 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13106939172953802		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.13106939172953802 | validation: 0.28276078373033803]
	TIME [epoch: 19 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607578730384555		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.11607578730384555 | validation: 0.28957543694682025]
	TIME [epoch: 19 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12965912095196197		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12965912095196197 | validation: 0.3077755715536921]
	TIME [epoch: 19 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844308051829928		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.11844308051829928 | validation: 0.30763201467412177]
	TIME [epoch: 19 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11542281492509301		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.11542281492509301 | validation: 0.29744930243400997]
	TIME [epoch: 19 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13771678387139497		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.13771678387139497 | validation: 0.28256603599652713]
	TIME [epoch: 19 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13348447704159427		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.13348447704159427 | validation: 0.2969416476594199]
	TIME [epoch: 19 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13533836048178505		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.13533836048178505 | validation: 0.2838647537162154]
	TIME [epoch: 19 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427878577754403		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.12427878577754403 | validation: 0.2829423464312642]
	TIME [epoch: 19 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12506835161573113		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.12506835161573113 | validation: 0.327884580575204]
	TIME [epoch: 19 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970893139527747		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.11970893139527747 | validation: 0.2895445748502384]
	TIME [epoch: 19 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13184199638388938		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.13184199638388938 | validation: 0.31900791575772725]
	TIME [epoch: 19 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914693985905727		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.13914693985905727 | validation: 0.2981298547592727]
	TIME [epoch: 19 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616357027206583		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.14616357027206583 | validation: 0.27933380139547503]
	TIME [epoch: 19 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448774794776151		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.1448774794776151 | validation: 0.2978660541495773]
	TIME [epoch: 19 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268062692651697		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.1268062692651697 | validation: 0.3018369253264508]
	TIME [epoch: 19 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608127232660044		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.12608127232660044 | validation: 0.27996623403599624]
	TIME [epoch: 19 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114475923615299		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13114475923615299 | validation: 0.3041395190470555]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13_20240716_191555/states/model_facs_v3_dec2b_2dpca_v13_582.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 5873.950 seconds.
