Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v13b', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v13b', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4195450720

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345987054859817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.345987054859817 | validation: 1.2085066316159108]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8832067400857284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8832067400857284 | validation: 0.9749053951548892]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088893500526381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7088893500526381 | validation: 0.889476823622658]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689570953347959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.689570953347959 | validation: 0.8845401561962527]
	TIME [epoch: 4.46 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6623629871073913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6623629871073913 | validation: 0.870416512916673]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816206474237261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5816206474237261 | validation: 0.7853455338727836]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54881987690012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.54881987690012 | validation: 0.8438602240908457]
	TIME [epoch: 4.47 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579438157056132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6579438157056132 | validation: 0.7274693591381599]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5038221643860461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5038221643860461 | validation: 0.7515541870525396]
	TIME [epoch: 4.47 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936782451284384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5936782451284384 | validation: 0.7782093299113324]
	TIME [epoch: 4.46 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5079609143935157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5079609143935157 | validation: 0.6249574093777526]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4176986097112083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4176986097112083 | validation: 0.597592938436825]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989223275532588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3989223275532588 | validation: 0.6247507315428488]
	TIME [epoch: 4.47 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47147958948157875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47147958948157875 | validation: 0.5479382316784362]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733054660118573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3733054660118573 | validation: 0.5659220098023622]
	TIME [epoch: 4.49 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742953194565448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3742953194565448 | validation: 0.5491991517380062]
	TIME [epoch: 4.48 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39003419155966057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39003419155966057 | validation: 0.53977531783377]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36001811455741284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36001811455741284 | validation: 0.5108950993963788]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405508085597311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3405508085597311 | validation: 0.5377514517843138]
	TIME [epoch: 4.48 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33976232621210933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33976232621210933 | validation: 0.5329775861893612]
	TIME [epoch: 4.48 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475830632436465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3475830632436465 | validation: 0.4489735260915746]
	TIME [epoch: 4.48 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26771437992583663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26771437992583663 | validation: 0.5226630838985907]
	TIME [epoch: 4.48 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33635925030099156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33635925030099156 | validation: 0.43482697900381073]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591489327364845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2591489327364845 | validation: 0.47299573747195434]
	TIME [epoch: 4.47 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258303765595327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3258303765595327 | validation: 0.5091213918343949]
	TIME [epoch: 4.47 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37693888032543627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37693888032543627 | validation: 0.5144885992641991]
	TIME [epoch: 4.46 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290115985970026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.290115985970026 | validation: 0.42578462737772393]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574612704523687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2574612704523687 | validation: 0.41270240242693546]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29222015794794337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29222015794794337 | validation: 0.5743773696446023]
	TIME [epoch: 4.48 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31322569154584434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31322569154584434 | validation: 0.4296622100873848]
	TIME [epoch: 4.48 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23632670786578924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23632670786578924 | validation: 0.4381014677459929]
	TIME [epoch: 4.47 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321833916030469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2321833916030469 | validation: 0.43260733592451767]
	TIME [epoch: 4.47 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650012797951077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2650012797951077 | validation: 0.4486637994045715]
	TIME [epoch: 4.47 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27791914394487555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27791914394487555 | validation: 0.4299443099025348]
	TIME [epoch: 4.47 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297467844847665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2297467844847665 | validation: 0.4523210076313394]
	TIME [epoch: 4.47 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927509138771816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2927509138771816 | validation: 0.39276714267034196]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944396540101072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2944396540101072 | validation: 0.42033483129297694]
	TIME [epoch: 4.48 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24109672572436425		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.24109672572436425 | validation: 0.43333967956442465]
	TIME [epoch: 4.47 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22348845850416518		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.22348845850416518 | validation: 0.4374804689869741]
	TIME [epoch: 4.47 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30338269146160357		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.30338269146160357 | validation: 0.49209047856326404]
	TIME [epoch: 4.47 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608788496274381		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2608788496274381 | validation: 0.4514931539809878]
	TIME [epoch: 4.47 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23117046510306483		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.23117046510306483 | validation: 0.38863906267260306]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26879172815324215		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.26879172815324215 | validation: 0.5088121665525354]
	TIME [epoch: 4.47 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28068034620192744		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.28068034620192744 | validation: 0.36206308804666476]
	TIME [epoch: 4.47 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22915867844588433		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.22915867844588433 | validation: 0.40897967956274445]
	TIME [epoch: 4.48 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255542028562462		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2255542028562462 | validation: 0.37372057580946644]
	TIME [epoch: 4.47 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24877721732190516		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.24877721732190516 | validation: 0.4449366665354878]
	TIME [epoch: 4.46 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521408870413028		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.2521408870413028 | validation: 0.46823688533681396]
	TIME [epoch: 4.46 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775578804788695		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.2775578804788695 | validation: 0.4142246858303104]
	TIME [epoch: 4.46 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112630326999342		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2112630326999342 | validation: 0.39409271861106676]
	TIME [epoch: 4.46 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21517639868947014		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.21517639868947014 | validation: 0.4857222834439826]
	TIME [epoch: 33.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863472814594356		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.2863472814594356 | validation: 0.40855333082368306]
	TIME [epoch: 8.63 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23478441431192076		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.23478441431192076 | validation: 0.4920692297692672]
	TIME [epoch: 8.62 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789338522136577		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2789338522136577 | validation: 0.47425323293031874]
	TIME [epoch: 8.64 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455036605171758		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2455036605171758 | validation: 0.4123635415759871]
	TIME [epoch: 8.62 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24303736581176894		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.24303736581176894 | validation: 0.4105696551019111]
	TIME [epoch: 8.62 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24486703787847		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.24486703787847 | validation: 0.39513603152956434]
	TIME [epoch: 8.62 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22518118096028453		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.22518118096028453 | validation: 0.4264482180497089]
	TIME [epoch: 8.64 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24420341929780381		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.24420341929780381 | validation: 0.40925671926867646]
	TIME [epoch: 8.63 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23704445050019288		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.23704445050019288 | validation: 0.4452034302138215]
	TIME [epoch: 8.63 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22278484080506245		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.22278484080506245 | validation: 0.39212281251048936]
	TIME [epoch: 8.62 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430722147897069		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2430722147897069 | validation: 0.4226698862738151]
	TIME [epoch: 8.64 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20432970773568843		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.20432970773568843 | validation: 0.4723184408461019]
	TIME [epoch: 8.67 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27034383454780475		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.27034383454780475 | validation: 0.48389024757272114]
	TIME [epoch: 8.62 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23666590040058308		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.23666590040058308 | validation: 0.35774688619137135]
	TIME [epoch: 8.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23730230955415688		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.23730230955415688 | validation: 0.39011169564230586]
	TIME [epoch: 8.63 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20724971380702154		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.20724971380702154 | validation: 0.36218415430463274]
	TIME [epoch: 8.61 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21328082625955264		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.21328082625955264 | validation: 0.4214408510524499]
	TIME [epoch: 8.61 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21768210914837444		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.21768210914837444 | validation: 0.3789878180987008]
	TIME [epoch: 8.61 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2562208625434006		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.2562208625434006 | validation: 0.41396831693621683]
	TIME [epoch: 8.62 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21241144028789996		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.21241144028789996 | validation: 0.4389488209104849]
	TIME [epoch: 8.61 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18926293292311014		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.18926293292311014 | validation: 0.4631554184883384]
	TIME [epoch: 8.61 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27702206467312096		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.27702206467312096 | validation: 0.4373752786843809]
	TIME [epoch: 8.61 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349645184366133		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.2349645184366133 | validation: 0.44579392066462786]
	TIME [epoch: 8.61 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23101654872514252		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.23101654872514252 | validation: 0.4588309506490909]
	TIME [epoch: 8.61 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25479989504979195		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.25479989504979195 | validation: 0.3386898580707577]
	TIME [epoch: 8.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17271918533946673		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.17271918533946673 | validation: 0.42433054935862524]
	TIME [epoch: 8.63 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24151349158647645		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.24151349158647645 | validation: 0.6369594741310296]
	TIME [epoch: 8.63 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23222371031602476		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.23222371031602476 | validation: 0.37895105337928264]
	TIME [epoch: 8.64 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21363061094109453		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.21363061094109453 | validation: 0.5326641488139715]
	TIME [epoch: 8.63 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257985313091256		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.257985313091256 | validation: 0.39689957492905875]
	TIME [epoch: 8.63 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24851401526538897		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.24851401526538897 | validation: 0.5125219303466217]
	TIME [epoch: 8.63 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20648211000080638		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.20648211000080638 | validation: 0.32510534857119827]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17535826680380953		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.17535826680380953 | validation: 0.4481272107024695]
	TIME [epoch: 8.64 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22282661526284825		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.22282661526284825 | validation: 0.36507941556876566]
	TIME [epoch: 8.63 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18902671291132137		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.18902671291132137 | validation: 0.38443944243958406]
	TIME [epoch: 8.64 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879545154101715		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.1879545154101715 | validation: 0.3987081234301453]
	TIME [epoch: 8.64 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2035807456569345		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.2035807456569345 | validation: 0.34654563519562803]
	TIME [epoch: 8.63 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20433029531348074		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.20433029531348074 | validation: 0.3674548808922348]
	TIME [epoch: 8.63 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191648043370293		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.191648043370293 | validation: 0.3849160922089702]
	TIME [epoch: 8.63 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046651746780617		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.2046651746780617 | validation: 0.4896582121744004]
	TIME [epoch: 8.64 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092342093751005		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.2092342093751005 | validation: 0.40103674532454864]
	TIME [epoch: 8.62 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20835799742154512		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.20835799742154512 | validation: 0.3578630589421373]
	TIME [epoch: 8.63 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16844413280404313		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16844413280404313 | validation: 0.3842922938981877]
	TIME [epoch: 8.64 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778114086648112		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.1778114086648112 | validation: 0.36484510805612896]
	TIME [epoch: 8.64 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23642165515884547		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.23642165515884547 | validation: 0.4104569453906376]
	TIME [epoch: 8.63 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18551207332732414		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.18551207332732414 | validation: 0.33879474670906606]
	TIME [epoch: 8.63 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866966398281775		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1866966398281775 | validation: 0.4026372420395743]
	TIME [epoch: 8.63 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19587814383646718		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.19587814383646718 | validation: 0.38364002129319097]
	TIME [epoch: 8.64 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21198153598062702		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.21198153598062702 | validation: 0.3253579724682081]
	TIME [epoch: 8.64 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17126892450153158		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.17126892450153158 | validation: 0.4057217923374774]
	TIME [epoch: 43.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20702933375102694		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.20702933375102694 | validation: 0.36822272410098356]
	TIME [epoch: 18.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227765028245371		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.2227765028245371 | validation: 0.3549389526922911]
	TIME [epoch: 18.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075990345975376		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.2075990345975376 | validation: 0.38291115822217114]
	TIME [epoch: 18.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19602024899318532		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.19602024899318532 | validation: 0.353175833794268]
	TIME [epoch: 18.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22180371132684995		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.22180371132684995 | validation: 0.36550685134842426]
	TIME [epoch: 18.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17711233516993757		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.17711233516993757 | validation: 0.3410444175183316]
	TIME [epoch: 18.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2116351761972673		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.2116351761972673 | validation: 0.38648730934877806]
	TIME [epoch: 18.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21766996420729695		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.21766996420729695 | validation: 0.353523928287548]
	TIME [epoch: 18.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21250209936300546		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.21250209936300546 | validation: 0.3344548845603858]
	TIME [epoch: 18.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739783542769175		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1739783542769175 | validation: 0.3605047030866772]
	TIME [epoch: 18.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874510554948175		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.20874510554948175 | validation: 0.39415285003075384]
	TIME [epoch: 18.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16107864056051402		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.16107864056051402 | validation: 0.3330452858416605]
	TIME [epoch: 18.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22657995136063683		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.22657995136063683 | validation: 0.38616184065977066]
	TIME [epoch: 18.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18439379015984003		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.18439379015984003 | validation: 0.4239467448046068]
	TIME [epoch: 18.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16776837465374195		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.16776837465374195 | validation: 0.3186736212863354]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18647808396082455		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.18647808396082455 | validation: 0.3644855285437928]
	TIME [epoch: 18.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19301301913587848		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.19301301913587848 | validation: 0.35022860437684883]
	TIME [epoch: 18.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18767037660331848		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.18767037660331848 | validation: 0.3353416232257011]
	TIME [epoch: 18.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1814037812162881		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1814037812162881 | validation: 0.34045042342888016]
	TIME [epoch: 18.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23768248983806634		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.23768248983806634 | validation: 0.45153576045975685]
	TIME [epoch: 18.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20158345942003647		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.20158345942003647 | validation: 0.3295468305369287]
	TIME [epoch: 18.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17675936460919706		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.17675936460919706 | validation: 0.37068217724345015]
	TIME [epoch: 18.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861477131161245		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1861477131161245 | validation: 0.31438629802330675]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20563316946045784		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.20563316946045784 | validation: 0.3498888017926356]
	TIME [epoch: 18.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18319683111598747		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.18319683111598747 | validation: 0.5690590704776908]
	TIME [epoch: 18.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22571013863803807		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.22571013863803807 | validation: 0.4432984102575043]
	TIME [epoch: 18.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430944277497325		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.3430944277497325 | validation: 0.3984858903438284]
	TIME [epoch: 18.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22763558506797335		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.22763558506797335 | validation: 0.4010703238990871]
	TIME [epoch: 18.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944877396602741		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.1944877396602741 | validation: 0.3307608614173437]
	TIME [epoch: 18.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19878285192411155		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.19878285192411155 | validation: 0.33276187164876625]
	TIME [epoch: 18.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20184731192999789		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.20184731192999789 | validation: 0.5634894468810939]
	TIME [epoch: 18.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2162691684720007		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.2162691684720007 | validation: 0.29482067662175754]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18162896263834993		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.18162896263834993 | validation: 0.3475963096278897]
	TIME [epoch: 18.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17959364798838584		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.17959364798838584 | validation: 0.3618531036362676]
	TIME [epoch: 18.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817140213313241		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1817140213313241 | validation: 0.36614127176861666]
	TIME [epoch: 18.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17391334895463106		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.17391334895463106 | validation: 0.33697549635100454]
	TIME [epoch: 18.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644780828637611		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.1644780828637611 | validation: 0.3214689017616499]
	TIME [epoch: 18.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17762224752287842		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.17762224752287842 | validation: 0.3339239650511731]
	TIME [epoch: 18.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19492438269165097		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.19492438269165097 | validation: 0.3308815532416063]
	TIME [epoch: 18.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16061032932114333		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.16061032932114333 | validation: 0.41543989671341397]
	TIME [epoch: 18.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19806158402181406		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.19806158402181406 | validation: 0.33212247506301373]
	TIME [epoch: 18.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1754722495967559		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.1754722495967559 | validation: 0.34836271065311863]
	TIME [epoch: 18.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200420296849706		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.200420296849706 | validation: 0.46050911926484345]
	TIME [epoch: 18.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18688300442990632		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.18688300442990632 | validation: 0.33894195569710583]
	TIME [epoch: 18.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17426756983311012		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.17426756983311012 | validation: 0.42849192941390246]
	TIME [epoch: 18.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16674547206746193		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.16674547206746193 | validation: 0.42840844922335436]
	TIME [epoch: 18.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20360865148352372		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.20360865148352372 | validation: 0.35382602554313686]
	TIME [epoch: 18.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17329877794312656		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.17329877794312656 | validation: 0.2992132735266026]
	TIME [epoch: 18.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18804070910921128		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.18804070910921128 | validation: 0.32960670896972083]
	TIME [epoch: 18.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865263874141604		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1865263874141604 | validation: 0.36727547832765606]
	TIME [epoch: 18.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697060580465993		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.1697060580465993 | validation: 0.3491443807729349]
	TIME [epoch: 18.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19848778251346838		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.19848778251346838 | validation: 0.3569370855453041]
	TIME [epoch: 18.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859124713177582		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.1859124713177582 | validation: 0.38152941957450726]
	TIME [epoch: 18.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16751341751907156		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.16751341751907156 | validation: 0.3165335827304132]
	TIME [epoch: 18.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197386254632496		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17197386254632496 | validation: 0.30276863200183923]
	TIME [epoch: 18.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605528729516379		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1605528729516379 | validation: 0.32163324141467364]
	TIME [epoch: 18.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19533880094803316		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.19533880094803316 | validation: 0.3204823217300292]
	TIME [epoch: 18.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1732384975021956		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1732384975021956 | validation: 0.35839945261419004]
	TIME [epoch: 18.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763353021672588		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.1763353021672588 | validation: 0.3118446050677649]
	TIME [epoch: 18.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16114384836616227		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.16114384836616227 | validation: 0.4160818295485549]
	TIME [epoch: 18.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766434299038332		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.1766434299038332 | validation: 0.3535786731265033]
	TIME [epoch: 18.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16276054908343723		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.16276054908343723 | validation: 0.32803240853749266]
	TIME [epoch: 18.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16595825317582755		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.16595825317582755 | validation: 0.37590521940461846]
	TIME [epoch: 18.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17159242559744323		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.17159242559744323 | validation: 0.32186379704066526]
	TIME [epoch: 18.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17443645921221584		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17443645921221584 | validation: 0.3607038379436166]
	TIME [epoch: 18.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664318028193608		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.1664318028193608 | validation: 0.37108698312305843]
	TIME [epoch: 18.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396693088831316		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.16396693088831316 | validation: 0.37747969701544065]
	TIME [epoch: 18.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18093618292701036		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.18093618292701036 | validation: 0.34542692030168604]
	TIME [epoch: 18.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18430186897092424		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.18430186897092424 | validation: 0.3443044861969624]
	TIME [epoch: 18.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17877759151566366		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.17877759151566366 | validation: 0.3309049574878553]
	TIME [epoch: 18.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18587286947050863		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.18587286947050863 | validation: 0.40033104786528884]
	TIME [epoch: 18.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22611101923854365		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.22611101923854365 | validation: 0.36006275951184]
	TIME [epoch: 18.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18095611072406306		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.18095611072406306 | validation: 0.3382483390355504]
	TIME [epoch: 18.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16846202166438212		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.16846202166438212 | validation: 0.33234762626638226]
	TIME [epoch: 18.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1738188527454525		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1738188527454525 | validation: 0.3255864557094056]
	TIME [epoch: 18.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17403078914011716		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.17403078914011716 | validation: 0.32248822438886876]
	TIME [epoch: 18.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16034522203417073		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.16034522203417073 | validation: 0.33345709326446965]
	TIME [epoch: 18.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15355061079315926		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.15355061079315926 | validation: 0.36302232028079034]
	TIME [epoch: 18.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16575862173612266		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.16575862173612266 | validation: 0.30121075003673353]
	TIME [epoch: 18.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15499912842775346		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15499912842775346 | validation: 0.40884889971066957]
	TIME [epoch: 18.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256142552387686		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.256142552387686 | validation: 0.3700611204399791]
	TIME [epoch: 18.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570849451505242		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.1570849451505242 | validation: 0.29277669660912586]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17129508148879927		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.17129508148879927 | validation: 0.30115376584729653]
	TIME [epoch: 18.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1839649575332856		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1839649575332856 | validation: 0.34112807522943855]
	TIME [epoch: 18.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17325229140320023		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.17325229140320023 | validation: 0.29732029628077267]
	TIME [epoch: 18.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17747154500134582		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.17747154500134582 | validation: 0.37417529346861866]
	TIME [epoch: 18.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16769266993502438		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.16769266993502438 | validation: 0.3407718465215888]
	TIME [epoch: 18.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1784895649490745		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1784895649490745 | validation: 0.2942364690019076]
	TIME [epoch: 18.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16316102744223665		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16316102744223665 | validation: 0.30173240964214987]
	TIME [epoch: 18.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659269742086047		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1659269742086047 | validation: 0.31007563628984824]
	TIME [epoch: 18.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159111353008905		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.159111353008905 | validation: 0.37813936086797956]
	TIME [epoch: 18.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313464004784342		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16313464004784342 | validation: 0.33616343472898114]
	TIME [epoch: 18.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14287892077101988		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.14287892077101988 | validation: 0.39409239761889575]
	TIME [epoch: 18.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14856013813361027		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.14856013813361027 | validation: 0.34254418019207117]
	TIME [epoch: 18.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18957674578543382		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18957674578543382 | validation: 0.30110681960694485]
	TIME [epoch: 18.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049714919373037		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.2049714919373037 | validation: 0.43442807394835714]
	TIME [epoch: 18.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18569780452616047		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.18569780452616047 | validation: 0.34083181045575595]
	TIME [epoch: 18.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340771428235526		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.16340771428235526 | validation: 0.33806647955747415]
	TIME [epoch: 18.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16226062741020056		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.16226062741020056 | validation: 0.32826192465500387]
	TIME [epoch: 18.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17411258977851604		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.17411258977851604 | validation: 0.32931375351811304]
	TIME [epoch: 64.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628091010917358		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1628091010917358 | validation: 0.45703346443195475]
	TIME [epoch: 39.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17085345461662896		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.17085345461662896 | validation: 0.382295716275263]
	TIME [epoch: 39.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16249260844037317		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.16249260844037317 | validation: 0.3115951822846511]
	TIME [epoch: 39.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17790468486780817		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.17790468486780817 | validation: 0.35375796765611806]
	TIME [epoch: 39.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15615459616873248		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.15615459616873248 | validation: 0.35736852283582393]
	TIME [epoch: 39.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15898124287251506		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15898124287251506 | validation: 0.38112180593636036]
	TIME [epoch: 39.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16175701323538355		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.16175701323538355 | validation: 0.3206292995478407]
	TIME [epoch: 39.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15168280323966327		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.15168280323966327 | validation: 0.338501323594608]
	TIME [epoch: 39.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17613384192919024		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.17613384192919024 | validation: 0.33035204567763465]
	TIME [epoch: 39.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18742703427164248		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18742703427164248 | validation: 0.3481646614437477]
	TIME [epoch: 39.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15562612667831013		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15562612667831013 | validation: 0.3160559203750667]
	TIME [epoch: 39.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16361697316963125		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.16361697316963125 | validation: 0.3756686092123303]
	TIME [epoch: 39.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14930161214099402		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.14930161214099402 | validation: 0.3593816882470655]
	TIME [epoch: 39.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17119903035920375		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.17119903035920375 | validation: 0.31845555700539624]
	TIME [epoch: 39.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17586100785864134		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.17586100785864134 | validation: 0.33747129066281906]
	TIME [epoch: 39.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15836458843299941		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.15836458843299941 | validation: 0.3664048211781456]
	TIME [epoch: 39.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557499366839444		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1557499366839444 | validation: 0.42608871006906285]
	TIME [epoch: 39.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17065252430401784		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.17065252430401784 | validation: 0.36022315763767576]
	TIME [epoch: 39.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14720364436024364		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.14720364436024364 | validation: 0.3001730619524551]
	TIME [epoch: 39.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16693160249866584		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.16693160249866584 | validation: 0.3746142601396522]
	TIME [epoch: 39.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644420079629198		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.1644420079629198 | validation: 0.354739410371797]
	TIME [epoch: 39.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15948741988330528		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.15948741988330528 | validation: 0.34365214287563034]
	TIME [epoch: 39.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899143702587426		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.1899143702587426 | validation: 0.34410003524555666]
	TIME [epoch: 39.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16412144919470653		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.16412144919470653 | validation: 0.4057277815079232]
	TIME [epoch: 39.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17867464284921997		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17867464284921997 | validation: 0.3402477213738171]
	TIME [epoch: 39.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773593936320345		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.17773593936320345 | validation: 0.32533851640086325]
	TIME [epoch: 39.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16404915277350585		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.16404915277350585 | validation: 0.3183205772126814]
	TIME [epoch: 39.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14764209132062656		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14764209132062656 | validation: 0.29343081154920386]
	TIME [epoch: 39.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16604646139320284		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.16604646139320284 | validation: 0.2996952342091251]
	TIME [epoch: 39.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015420978999233		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.15015420978999233 | validation: 0.3300286757254594]
	TIME [epoch: 39.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17118189041548265		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.17118189041548265 | validation: 0.4031185611995785]
	TIME [epoch: 39.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868976656629986		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.1868976656629986 | validation: 0.32493844679204253]
	TIME [epoch: 39.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675633186020166		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.15675633186020166 | validation: 0.32974879367132093]
	TIME [epoch: 39.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15853834190731297		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.15853834190731297 | validation: 0.383977229155673]
	TIME [epoch: 39.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15899126991318704		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.15899126991318704 | validation: 0.332032673151381]
	TIME [epoch: 39.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16468672865297573		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.16468672865297573 | validation: 0.36238847754037307]
	TIME [epoch: 39.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626275685363449		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1626275685363449 | validation: 0.31744497121530946]
	TIME [epoch: 39.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826078677003384		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.16826078677003384 | validation: 0.3058523749056281]
	TIME [epoch: 39.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149614698405081		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.149614698405081 | validation: 0.32599374470220793]
	TIME [epoch: 39.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499826660235904		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1499826660235904 | validation: 0.2908640381858812]
	TIME [epoch: 39.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15502981798871254		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15502981798871254 | validation: 0.3490541715050009]
	TIME [epoch: 39.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17608408146237797		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.17608408146237797 | validation: 0.366585613244709]
	TIME [epoch: 39.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984375890485496		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.14984375890485496 | validation: 0.32729469966104097]
	TIME [epoch: 39.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15865499508434283		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.15865499508434283 | validation: 0.3282586645581794]
	TIME [epoch: 39.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16017361337698188		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.16017361337698188 | validation: 0.30277626636376376]
	TIME [epoch: 39.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15532742742401937		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.15532742742401937 | validation: 0.29147263635113013]
	TIME [epoch: 39.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15473723714808718		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.15473723714808718 | validation: 0.32446324917663005]
	TIME [epoch: 39.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16447806843831467		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.16447806843831467 | validation: 0.4147985942067644]
	TIME [epoch: 39.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611826572137441		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1611826572137441 | validation: 0.3391046281987321]
	TIME [epoch: 39.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316535081250556		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1316535081250556 | validation: 0.2790994945361904]
	TIME [epoch: 39.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402598941254827		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.1402598941254827 | validation: 0.3958363651914679]
	TIME [epoch: 39.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155838706872804		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.155838706872804 | validation: 0.31865515118423754]
	TIME [epoch: 39.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549418148008175		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.1549418148008175 | validation: 0.31602640498084245]
	TIME [epoch: 39.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16561322407606002		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.16561322407606002 | validation: 0.31793402814176913]
	TIME [epoch: 39.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518182247528284		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1518182247528284 | validation: 0.31556312702987455]
	TIME [epoch: 39.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17842444938721427		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.17842444938721427 | validation: 0.3961789636685846]
	TIME [epoch: 39.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660747201750164		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.1660747201750164 | validation: 0.3048990589867367]
	TIME [epoch: 39.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15509320181141067		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.15509320181141067 | validation: 0.3152787159269165]
	TIME [epoch: 39.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17409548905521796		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.17409548905521796 | validation: 0.3318677381087719]
	TIME [epoch: 39.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451626235011928		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.15451626235011928 | validation: 0.303387234271777]
	TIME [epoch: 39.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14498523591638363		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14498523591638363 | validation: 0.312534081918986]
	TIME [epoch: 39.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735046749754342		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1735046749754342 | validation: 0.3528421525685189]
	TIME [epoch: 39.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13704715919661872		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.13704715919661872 | validation: 0.3506565398323875]
	TIME [epoch: 39.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15550320909794085		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.15550320909794085 | validation: 0.30338820217040136]
	TIME [epoch: 39.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17156669039209516		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.17156669039209516 | validation: 0.3309785839296706]
	TIME [epoch: 39.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711480246349679		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.1711480246349679 | validation: 0.3922339225218002]
	TIME [epoch: 39.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483885058950421		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1483885058950421 | validation: 0.35663473242416455]
	TIME [epoch: 39.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559984536268334		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.15559984536268334 | validation: 0.2979161262580493]
	TIME [epoch: 39.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572672552374375		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1572672552374375 | validation: 0.3631608047601135]
	TIME [epoch: 39.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14647127538926752		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.14647127538926752 | validation: 0.33727238412493715]
	TIME [epoch: 39.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14536290671357213		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.14536290671357213 | validation: 0.3413382578359089]
	TIME [epoch: 39.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222580733659487		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.17222580733659487 | validation: 0.2951425700990995]
	TIME [epoch: 39.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161604866946115		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.161604866946115 | validation: 0.36003321014431083]
	TIME [epoch: 39.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15726356206851674		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.15726356206851674 | validation: 0.32818467134660234]
	TIME [epoch: 39.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510824017201228		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1510824017201228 | validation: 0.31942966052579125]
	TIME [epoch: 39.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17959118339747596		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.17959118339747596 | validation: 0.3326383166790439]
	TIME [epoch: 39.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149078244797008		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.149078244797008 | validation: 0.3110456802071258]
	TIME [epoch: 39.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16111073580092194		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.16111073580092194 | validation: 0.30531652600131987]
	TIME [epoch: 39.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16072646959062553		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.16072646959062553 | validation: 0.3345052089709704]
	TIME [epoch: 39.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375223408573487		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.14375223408573487 | validation: 0.2843576886107706]
	TIME [epoch: 39.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17245152586953		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.17245152586953 | validation: 0.3732264769795667]
	TIME [epoch: 39.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559714424378706		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.1559714424378706 | validation: 0.32403731388210366]
	TIME [epoch: 39.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14843847787578585		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.14843847787578585 | validation: 0.34063399028844454]
	TIME [epoch: 39.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144456494182632		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.144456494182632 | validation: 0.3234179719710385]
	TIME [epoch: 39.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143871678639127		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.13143871678639127 | validation: 0.3518175313180075]
	TIME [epoch: 39.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14857132711637058		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.14857132711637058 | validation: 0.32335092072532806]
	TIME [epoch: 39.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16588067744696336		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.16588067744696336 | validation: 0.319314891882773]
	TIME [epoch: 39.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470889218893938		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1470889218893938 | validation: 0.3935115578740727]
	TIME [epoch: 39.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17059575768683818		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.17059575768683818 | validation: 0.30401404262254117]
	TIME [epoch: 39.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16227283596214545		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.16227283596214545 | validation: 0.3674802131409827]
	TIME [epoch: 39.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111661624851568		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.17111661624851568 | validation: 0.3681536900911989]
	TIME [epoch: 39.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655518047303354		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1655518047303354 | validation: 0.3388734532493484]
	TIME [epoch: 39.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15445622808734646		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.15445622808734646 | validation: 0.34283600262329905]
	TIME [epoch: 39.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487832306966425		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.1487832306966425 | validation: 0.34444815050083716]
	TIME [epoch: 39.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15501079602124826		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.15501079602124826 | validation: 0.3292263546559542]
	TIME [epoch: 39.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14651136227507078		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.14651136227507078 | validation: 0.30470604088647285]
	TIME [epoch: 39.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404023512960618		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.14404023512960618 | validation: 0.3190730948951267]
	TIME [epoch: 39.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14920760318322096		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.14920760318322096 | validation: 0.3494046602385181]
	TIME [epoch: 39.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502749737584284		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.1502749737584284 | validation: 0.36093779007636556]
	TIME [epoch: 39.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813767544954476		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.14813767544954476 | validation: 0.3153342664782706]
	TIME [epoch: 106 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143608313534445		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.143608313534445 | validation: 0.2992207517486262]
	TIME [epoch: 81.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12464518036111677		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12464518036111677 | validation: 0.339339419786446]
	TIME [epoch: 81.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15844185943830347		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.15844185943830347 | validation: 0.29794291584018684]
	TIME [epoch: 81.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346794884347137		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.15346794884347137 | validation: 0.3220833393107642]
	TIME [epoch: 81.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17727436580108083		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.17727436580108083 | validation: 0.28928645108955364]
	TIME [epoch: 81.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17014912956606523		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.17014912956606523 | validation: 0.31215894107364645]
	TIME [epoch: 81.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391562922953624		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1391562922953624 | validation: 0.28630420378679]
	TIME [epoch: 81.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14033445348599152		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14033445348599152 | validation: 0.30504164899812963]
	TIME [epoch: 81.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514408626319525		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.14514408626319525 | validation: 0.3388382656584734]
	TIME [epoch: 81.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1578262414393721		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1578262414393721 | validation: 0.2982394882746471]
	TIME [epoch: 81.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13279717535480084		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.13279717535480084 | validation: 0.29809235819116126]
	TIME [epoch: 81.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433066350454359		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1433066350454359 | validation: 0.29259824430056275]
	TIME [epoch: 81.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703185893705345		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.14703185893705345 | validation: 0.3160341599317645]
	TIME [epoch: 81.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14446457053424902		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.14446457053424902 | validation: 0.2865535603892709]
	TIME [epoch: 81.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15639429773337382		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15639429773337382 | validation: 0.30355138785953406]
	TIME [epoch: 81.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14368158764045938		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.14368158764045938 | validation: 0.3592166678019104]
	TIME [epoch: 81.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000887966735578		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.14000887966735578 | validation: 0.3099625980416364]
	TIME [epoch: 81.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397752451267989		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1397752451267989 | validation: 0.32483062087509995]
	TIME [epoch: 81.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13667435477131046		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.13667435477131046 | validation: 0.3163373238969521]
	TIME [epoch: 81.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148946907342418		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.148946907342418 | validation: 0.30197935630222156]
	TIME [epoch: 81.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13811211033216933		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.13811211033216933 | validation: 0.307943437155966]
	TIME [epoch: 81.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15644801033395628		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.15644801033395628 | validation: 0.28958927677761936]
	TIME [epoch: 81.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13780320945001118		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13780320945001118 | validation: 0.276655608266477]
	TIME [epoch: 81.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17911355876208734		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.17911355876208734 | validation: 0.3664628267505673]
	TIME [epoch: 82 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15751882828167807		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.15751882828167807 | validation: 0.313128658482501]
	TIME [epoch: 82 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16096986280517706		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.16096986280517706 | validation: 0.2993731259007529]
	TIME [epoch: 82 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14286141673250927		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.14286141673250927 | validation: 0.3197334678058052]
	TIME [epoch: 82 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302065181067898		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1302065181067898 | validation: 0.30558760654505024]
	TIME [epoch: 82 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14088968528283569		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.14088968528283569 | validation: 0.29781484835405275]
	TIME [epoch: 82 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14974141182349765		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14974141182349765 | validation: 0.3271240204913698]
	TIME [epoch: 82 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021209478341035		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.14021209478341035 | validation: 0.3306093181535264]
	TIME [epoch: 82 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14972368408904882		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.14972368408904882 | validation: 0.32328039055098845]
	TIME [epoch: 82 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15002524336842116		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.15002524336842116 | validation: 0.2931514675084072]
	TIME [epoch: 81.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16095850615400625		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.16095850615400625 | validation: 0.2739861594309028]
	TIME [epoch: 82 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15202026820347453		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.15202026820347453 | validation: 0.33432071455316076]
	TIME [epoch: 81.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13520148080842392		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13520148080842392 | validation: 0.32414283461079174]
	TIME [epoch: 81.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550035702130214		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.1550035702130214 | validation: 0.2953397755079823]
	TIME [epoch: 81.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072846647851453		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.14072846647851453 | validation: 0.3152446024842437]
	TIME [epoch: 81.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14383401875629573		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.14383401875629573 | validation: 0.33916981788174294]
	TIME [epoch: 81.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075415258947884		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.13075415258947884 | validation: 0.29971265094716437]
	TIME [epoch: 81.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293991313623875		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.15293991313623875 | validation: 0.2851415232068196]
	TIME [epoch: 81.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435262091620116		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1435262091620116 | validation: 0.30205017730262523]
	TIME [epoch: 81.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441536554247098		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1441536554247098 | validation: 0.3173885824511288]
	TIME [epoch: 81.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14415351650895628		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.14415351650895628 | validation: 0.31517859817483485]
	TIME [epoch: 81.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833306326451056		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.13833306326451056 | validation: 0.31543960388347986]
	TIME [epoch: 81.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14104700791408187		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.14104700791408187 | validation: 0.32824344427604707]
	TIME [epoch: 81.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14590877891448983		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.14590877891448983 | validation: 0.2905873531338984]
	TIME [epoch: 81.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630206123016828		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1630206123016828 | validation: 0.34430292851064603]
	TIME [epoch: 81.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13195166983859266		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.13195166983859266 | validation: 0.3180482013459514]
	TIME [epoch: 81.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14113181013340725		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.14113181013340725 | validation: 0.30610519003981645]
	TIME [epoch: 81.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793980192647658		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12793980192647658 | validation: 0.32832071806642477]
	TIME [epoch: 81.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774940867327398		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.16774940867327398 | validation: 0.3054861432525094]
	TIME [epoch: 81.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13471377542186677		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.13471377542186677 | validation: 0.3089414413692159]
	TIME [epoch: 81.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13030719789015524		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.13030719789015524 | validation: 0.3139042116127176]
	TIME [epoch: 81.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13683512615798116		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.13683512615798116 | validation: 0.32545794188332033]
	TIME [epoch: 81.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14550569741759337		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.14550569741759337 | validation: 0.3136960515459969]
	TIME [epoch: 81.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402628469769285		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.14402628469769285 | validation: 0.2932469711769092]
	TIME [epoch: 81.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288158330306726		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.1288158330306726 | validation: 0.28287590924437045]
	TIME [epoch: 81.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377875686623249		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.1377875686623249 | validation: 0.29346913804989994]
	TIME [epoch: 81.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16173853496493196		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.16173853496493196 | validation: 0.33649750321399347]
	TIME [epoch: 81.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141644586613832		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.141644586613832 | validation: 0.3148416266526936]
	TIME [epoch: 81.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15508741553294053		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.15508741553294053 | validation: 0.29561568372357844]
	TIME [epoch: 81.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13644756555327048		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.13644756555327048 | validation: 0.3177883038823265]
	TIME [epoch: 81.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416626324950914		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.1416626324950914 | validation: 0.31556116869408174]
	TIME [epoch: 81.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14136088326115304		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.14136088326115304 | validation: 0.2922686279351104]
	TIME [epoch: 81.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13956064978472338		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.13956064978472338 | validation: 0.28107118475190984]
	TIME [epoch: 81.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15046737401520174		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.15046737401520174 | validation: 0.36193056332085727]
	TIME [epoch: 81.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827486256496963		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13827486256496963 | validation: 0.31094522179432094]
	TIME [epoch: 81.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423586612201085		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.15423586612201085 | validation: 0.28748659950944794]
	TIME [epoch: 81.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15318606050129147		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.15318606050129147 | validation: 0.3044083641571062]
	TIME [epoch: 81.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554936222284998		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1554936222284998 | validation: 0.27850226603740386]
	TIME [epoch: 81.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14366995760699053		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.14366995760699053 | validation: 0.341894990069896]
	TIME [epoch: 81.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15248929157697114		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.15248929157697114 | validation: 0.2850379065397803]
	TIME [epoch: 81.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341892339927339		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1341892339927339 | validation: 0.32845980256257723]
	TIME [epoch: 81.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580402073122887		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15580402073122887 | validation: 0.30183607063753815]
	TIME [epoch: 81.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828305607110088		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.12828305607110088 | validation: 0.30529178363363857]
	TIME [epoch: 81.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500968396544056		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.14500968396544056 | validation: 0.3101604735480466]
	TIME [epoch: 81.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13759258598436247		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.13759258598436247 | validation: 0.3580365208015699]
	TIME [epoch: 81.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273608543616216		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1273608543616216 | validation: 0.31772276685503464]
	TIME [epoch: 81.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455714435630991		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.1455714435630991 | validation: 0.2985068184792493]
	TIME [epoch: 81.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15277357338319197		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.15277357338319197 | validation: 0.3116577717826597]
	TIME [epoch: 81.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796558120142049		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.15796558120142049 | validation: 0.31193303461898847]
	TIME [epoch: 81.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15429209749016476		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.15429209749016476 | validation: 0.32495975218453244]
	TIME [epoch: 81.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139839334694878		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.139839334694878 | validation: 0.30891868350981866]
	TIME [epoch: 81.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341916552375993		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.1341916552375993 | validation: 0.28619732895554323]
	TIME [epoch: 81.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486649756439234		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.1486649756439234 | validation: 0.3008313572375333]
	TIME [epoch: 81.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16373874875891295		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.16373874875891295 | validation: 0.32945672538266485]
	TIME [epoch: 81.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14971562313671125		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.14971562313671125 | validation: 0.31685515896950045]
	TIME [epoch: 81.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15531857390264264		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.15531857390264264 | validation: 0.3570755773482903]
	TIME [epoch: 81.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725444607484983		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.14725444607484983 | validation: 0.33294276674116235]
	TIME [epoch: 81.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435226862856952		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.12435226862856952 | validation: 0.30381268863754873]
	TIME [epoch: 81.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13410057202522122		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13410057202522122 | validation: 0.3023808227466567]
	TIME [epoch: 81.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13184070184475494		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.13184070184475494 | validation: 0.3341197544654264]
	TIME [epoch: 81.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877921407916795		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12877921407916795 | validation: 0.321166761916445]
	TIME [epoch: 81.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15317761884339046		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.15317761884339046 | validation: 0.28389093689562594]
	TIME [epoch: 81.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13431371090272914		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.13431371090272914 | validation: 0.2870755887090143]
	TIME [epoch: 81.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592058736792453		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.13592058736792453 | validation: 0.2996379277828645]
	TIME [epoch: 81.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346560712855348		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.1346560712855348 | validation: 0.3085588987456182]
	TIME [epoch: 81.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15125675672564876		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.15125675672564876 | validation: 0.32749324036466343]
	TIME [epoch: 81.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376083707925339		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.1376083707925339 | validation: 0.28859474820026226]
	TIME [epoch: 81.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13407083612037546		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.13407083612037546 | validation: 0.28534429950220475]
	TIME [epoch: 81.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13088953880475707		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13088953880475707 | validation: 0.31204531429737203]
	TIME [epoch: 81.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13863416694575004		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.13863416694575004 | validation: 0.3299851593672328]
	TIME [epoch: 81.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310128470364563		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.1310128470364563 | validation: 0.32690548158925353]
	TIME [epoch: 81.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429247413972281		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1429247413972281 | validation: 0.311608827686772]
	TIME [epoch: 81.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14212907037918887		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.14212907037918887 | validation: 0.289745844199399]
	TIME [epoch: 81.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479541818641014		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.13479541818641014 | validation: 0.3193555294563684]
	TIME [epoch: 81.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643779883706754		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.1643779883706754 | validation: 0.30885156838843797]
	TIME [epoch: 81.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343045064305851		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.1343045064305851 | validation: 0.31167256995107556]
	TIME [epoch: 81.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262019965375449		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.1262019965375449 | validation: 0.2789852951115194]
	TIME [epoch: 81.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1248571188541919		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.1248571188541919 | validation: 0.3352442882348686]
	TIME [epoch: 81.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355155018067304		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.1355155018067304 | validation: 0.30630946835559975]
	TIME [epoch: 81.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448085863648995		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1448085863648995 | validation: 0.34083542655247123]
	TIME [epoch: 81.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14393105143830476		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.14393105143830476 | validation: 0.30317193245803586]
	TIME [epoch: 81.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14409193486887256		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.14409193486887256 | validation: 0.29078052741534005]
	TIME [epoch: 81.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406468721080842		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.1406468721080842 | validation: 0.33286471728189654]
	TIME [epoch: 81.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323364996141062		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.12323364996141062 | validation: 0.3141545154805128]
	TIME [epoch: 81.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13083898921477602		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.13083898921477602 | validation: 0.33464020693278557]
	TIME [epoch: 81.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14014030663109764		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.14014030663109764 | validation: 0.29865208594366327]
	TIME [epoch: 81.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12115066429162422		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12115066429162422 | validation: 0.3064244397019221]
	TIME [epoch: 81.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14759759753059742		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.14759759753059742 | validation: 0.31909154907636106]
	TIME [epoch: 81.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17929305941698004		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.17929305941698004 | validation: 0.32078733478403526]
	TIME [epoch: 81.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13873970051269446		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.13873970051269446 | validation: 0.30551863134679685]
	TIME [epoch: 81.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828993809905187		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.12828993809905187 | validation: 0.3053461238421672]
	TIME [epoch: 81.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12636815459762457		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.12636815459762457 | validation: 0.3010541310575904]
	TIME [epoch: 81.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13666436812730193		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.13666436812730193 | validation: 0.29627911210960317]
	TIME [epoch: 81.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13145112799567682		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.13145112799567682 | validation: 0.27083607408450916]
	TIME [epoch: 81.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15133145618337795		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.15133145618337795 | validation: 0.2965954117217217]
	TIME [epoch: 81.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13934060074010624		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.13934060074010624 | validation: 0.3120242908341429]
	TIME [epoch: 81.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390428817921062		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.1390428817921062 | validation: 0.3046481991149209]
	TIME [epoch: 81.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442976747705532		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.13442976747705532 | validation: 0.31121559026053314]
	TIME [epoch: 81.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15191384168613684		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.15191384168613684 | validation: 0.34102970939141575]
	TIME [epoch: 81.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15082457192867502		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.15082457192867502 | validation: 0.2887965519581676]
	TIME [epoch: 81.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513495815025067		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.1513495815025067 | validation: 0.33351535294802137]
	TIME [epoch: 81.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117145219114487		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.13117145219114487 | validation: 0.3043283911248575]
	TIME [epoch: 81.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15941700314072105		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.15941700314072105 | validation: 0.30197701720433895]
	TIME [epoch: 81.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12241578902735434		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.12241578902735434 | validation: 0.29680770795077094]
	TIME [epoch: 81.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15738326671619562		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.15738326671619562 | validation: 0.29566296663923736]
	TIME [epoch: 81.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940398528028305		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.12940398528028305 | validation: 0.2903308483276072]
	TIME [epoch: 81.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679731860596546		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.15679731860596546 | validation: 0.3242437419823721]
	TIME [epoch: 81.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711604578156287		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.14711604578156287 | validation: 0.2829562637588499]
	TIME [epoch: 81.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15105442844729966		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.15105442844729966 | validation: 0.2989116973746363]
	TIME [epoch: 81.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377789147043157		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.1377789147043157 | validation: 0.32914765683424074]
	TIME [epoch: 82 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641976858188512		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.13641976858188512 | validation: 0.28259794662500615]
	TIME [epoch: 81.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13680198221960935		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.13680198221960935 | validation: 0.29685233202171357]
	TIME [epoch: 81.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14130875836572931		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.14130875836572931 | validation: 0.327101978195724]
	TIME [epoch: 81.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15391376908811424		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.15391376908811424 | validation: 0.320797324889098]
	TIME [epoch: 82 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14848359856850318		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.14848359856850318 | validation: 0.29797807929466613]
	TIME [epoch: 81.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13207052777261863		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.13207052777261863 | validation: 0.32955912371962476]
	TIME [epoch: 81.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13625689009827546		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.13625689009827546 | validation: 0.28923363627918336]
	TIME [epoch: 81.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408986010743416		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.1408986010743416 | validation: 0.2939275131250337]
	TIME [epoch: 82 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11916464811351042		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.11916464811351042 | validation: 0.30832713359869457]
	TIME [epoch: 82 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985041560117447		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.12985041560117447 | validation: 0.3077417499228138]
	TIME [epoch: 81.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072757683374104		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.14072757683374104 | validation: 0.2805896656086217]
	TIME [epoch: 81.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14120091920703956		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.14120091920703956 | validation: 0.28487612998970796]
	TIME [epoch: 81.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332060036687639		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1332060036687639 | validation: 0.2914190839869369]
	TIME [epoch: 81.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294169877179653		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1294169877179653 | validation: 0.299970751659432]
	TIME [epoch: 81.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373411561146495		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.1373411561146495 | validation: 0.27829279104171945]
	TIME [epoch: 81.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346417853475794		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.15346417853475794 | validation: 0.3140050080705911]
	TIME [epoch: 81.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13204262277772		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.13204262277772 | validation: 0.3072928858987897]
	TIME [epoch: 81.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14637594159347378		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.14637594159347378 | validation: 0.3061315124233545]
	TIME [epoch: 81.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15586726501083167		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.15586726501083167 | validation: 0.3077078653382132]
	TIME [epoch: 81.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16171998369899826		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.16171998369899826 | validation: 0.31802924565707796]
	TIME [epoch: 81.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762403488471202		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.12762403488471202 | validation: 0.29361041815741235]
	TIME [epoch: 81.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243105212352497		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.14243105212352497 | validation: 0.2788199823240459]
	TIME [epoch: 82 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312510822296883		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.1312510822296883 | validation: 0.2965963111861973]
	TIME [epoch: 81.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14483247198478522		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.14483247198478522 | validation: 0.3060452715868228]
	TIME [epoch: 82 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738631751134935		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.12738631751134935 | validation: 0.2912635071768621]
	TIME [epoch: 81.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501609335441822		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.1501609335441822 | validation: 0.2989909455159171]
	TIME [epoch: 81.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818912038930563		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.12818912038930563 | validation: 0.3019760201428826]
	TIME [epoch: 81.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498110321557146		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.12498110321557146 | validation: 0.3140380790348131]
	TIME [epoch: 81.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13552251674932295		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.13552251674932295 | validation: 0.2916733940830693]
	TIME [epoch: 81.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13750487562086755		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.13750487562086755 | validation: 0.30863124405970876]
	TIME [epoch: 82 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13099216886056675		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.13099216886056675 | validation: 0.3198820260987661]
	TIME [epoch: 81.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15645728017024083		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.15645728017024083 | validation: 0.30333576953288216]
	TIME [epoch: 81.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12983893307091804		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.12983893307091804 | validation: 0.3161281389206037]
	TIME [epoch: 81.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15732134136890719		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.15732134136890719 | validation: 0.29318501997081325]
	TIME [epoch: 81.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13023425445686704		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.13023425445686704 | validation: 0.2924150267443778]
	TIME [epoch: 81.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940070961102523		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.12940070961102523 | validation: 0.28798713786659913]
	TIME [epoch: 81.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14658041947668404		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.14658041947668404 | validation: 0.29328062313914227]
	TIME [epoch: 82 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12974085799282922		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.12974085799282922 | validation: 0.2978335990269437]
	TIME [epoch: 81.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14520810564357295		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.14520810564357295 | validation: 0.2959147414012348]
	TIME [epoch: 81.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961690751154725		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.12961690751154725 | validation: 0.2975785256293278]
	TIME [epoch: 81.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13671256272539134		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.13671256272539134 | validation: 0.2826522144586868]
	TIME [epoch: 82 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270493246900969		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.1270493246900969 | validation: 0.30011076115281105]
	TIME [epoch: 81.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14166269327874334		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.14166269327874334 | validation: 0.3173759723839206]
	TIME [epoch: 81.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757704433099567		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.11757704433099567 | validation: 0.3090975634879652]
	TIME [epoch: 82 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268779117698552		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.1268779117698552 | validation: 0.2897526832577658]
	TIME [epoch: 81.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332613029398268		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1332613029398268 | validation: 0.28612372725068774]
	TIME [epoch: 81.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13251379631771326		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.13251379631771326 | validation: 0.2879143125881524]
	TIME [epoch: 81.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13099405174312712		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.13099405174312712 | validation: 0.29923422646208947]
	TIME [epoch: 81.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510242590457455		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1510242590457455 | validation: 0.3081888350627169]
	TIME [epoch: 81.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817870545311738		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.12817870545311738 | validation: 0.29744582734841907]
	TIME [epoch: 81.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14358529027291286		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.14358529027291286 | validation: 0.29673920121948383]
	TIME [epoch: 82 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14714605742606485		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.14714605742606485 | validation: 0.30055730770604305]
	TIME [epoch: 81.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317062233207		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.13317062233207 | validation: 0.29258689935393145]
	TIME [epoch: 81.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458403386950738		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.1458403386950738 | validation: 0.30771407651493]
	TIME [epoch: 81.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536339396654706		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.13536339396654706 | validation: 0.30186589625980376]
	TIME [epoch: 81.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14060379881177945		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.14060379881177945 | validation: 0.2963011654134161]
	TIME [epoch: 81.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13669273115131492		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.13669273115131492 | validation: 0.29924428910592427]
	TIME [epoch: 81.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727504508253477		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.13727504508253477 | validation: 0.3160458636612757]
	TIME [epoch: 81.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381423616195386		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.1381423616195386 | validation: 0.31123240926626344]
	TIME [epoch: 81.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536052861239278		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.13536052861239278 | validation: 0.30863365745524174]
	TIME [epoch: 81.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13349058930029176		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.13349058930029176 | validation: 0.3150607721685097]
	TIME [epoch: 81.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13314509656126228		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.13314509656126228 | validation: 0.2988341443725889]
	TIME [epoch: 81.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629093849218312		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.12629093849218312 | validation: 0.2997890253737639]
	TIME [epoch: 81.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13944858684078998		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.13944858684078998 | validation: 0.29758320685835277]
	TIME [epoch: 81.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894446417270833		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.12894446417270833 | validation: 0.30899125153939]
	TIME [epoch: 81.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13538702725433116		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.13538702725433116 | validation: 0.30726044161370225]
	TIME [epoch: 81.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007784167887712		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.13007784167887712 | validation: 0.2919954926290949]
	TIME [epoch: 81.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026010760512583		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.14026010760512583 | validation: 0.29691156900610977]
	TIME [epoch: 81.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13163687995561796		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.13163687995561796 | validation: 0.30440333197498687]
	TIME [epoch: 81.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416024546558605		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.13416024546558605 | validation: 0.2864233323529294]
	TIME [epoch: 81.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14025093294346863		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.14025093294346863 | validation: 0.3189291220347668]
	TIME [epoch: 81.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14541529500976066		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.14541529500976066 | validation: 0.2940155282004272]
	TIME [epoch: 81.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12294530216457843		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.12294530216457843 | validation: 0.29390102915683164]
	TIME [epoch: 81.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916806902588185		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.12916806902588185 | validation: 0.3056090486604315]
	TIME [epoch: 81.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906011569788504		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.13906011569788504 | validation: 0.29145088960857585]
	TIME [epoch: 81.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296554383849365		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1296554383849365 | validation: 0.2790627268594732]
	TIME [epoch: 81.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13223478722248921		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.13223478722248921 | validation: 0.29846136439435783]
	TIME [epoch: 81.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461212184308216		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.1461212184308216 | validation: 0.2853696639166097]
	TIME [epoch: 81.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319545031329786		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1319545031329786 | validation: 0.2957899683318442]
	TIME [epoch: 81.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14321711876627422		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.14321711876627422 | validation: 0.3063118866995766]
	TIME [epoch: 81.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498555482044233		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.1498555482044233 | validation: 0.2956239558085792]
	TIME [epoch: 81.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274915849001389		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.12274915849001389 | validation: 0.2994095621211197]
	TIME [epoch: 81.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14205613680833887		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.14205613680833887 | validation: 0.2954250757168822]
	TIME [epoch: 81.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255633811122512		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1255633811122512 | validation: 0.295138168124202]
	TIME [epoch: 81.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471075004887328		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.12471075004887328 | validation: 0.3005501744428023]
	TIME [epoch: 81.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13247387866986182		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.13247387866986182 | validation: 0.31108763221742886]
	TIME [epoch: 81.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302954675537911		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.1302954675537911 | validation: 0.30266430323170423]
	TIME [epoch: 81.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13200397744398784		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.13200397744398784 | validation: 0.2938641876910243]
	TIME [epoch: 81.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561381582327014		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.12561381582327014 | validation: 0.3094936951452624]
	TIME [epoch: 81.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346652222080612		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.15346652222080612 | validation: 0.28997319916443437]
	TIME [epoch: 81.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14887812168268055		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.14887812168268055 | validation: 0.29418600869571093]
	TIME [epoch: 81.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829006814692306		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.12829006814692306 | validation: 0.30294569918586794]
	TIME [epoch: 81.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488366526118778		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.1488366526118778 | validation: 0.28007202565146355]
	TIME [epoch: 81.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836800754287384		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.12836800754287384 | validation: 0.3151954468600125]
	TIME [epoch: 81.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656731725803938		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.12656731725803938 | validation: 0.28961447323165634]
	TIME [epoch: 81.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249256703884425		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1249256703884425 | validation: 0.287433617138048]
	TIME [epoch: 81.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13372742785475644		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.13372742785475644 | validation: 0.2955115426528083]
	TIME [epoch: 81.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282917680960163		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.13282917680960163 | validation: 0.3139732783102441]
	TIME [epoch: 81.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317925487821669		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.1317925487821669 | validation: 0.279153311607855]
	TIME [epoch: 81.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13797825110734593		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.13797825110734593 | validation: 0.31532558592645304]
	TIME [epoch: 81.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124924687780404		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.13124924687780404 | validation: 0.3101154028427618]
	TIME [epoch: 81.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111221030589495		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.111221030589495 | validation: 0.2974758730741142]
	TIME [epoch: 81.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365230085227877		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.1365230085227877 | validation: 0.2986041323909653]
	TIME [epoch: 81.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270698301107241		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.1270698301107241 | validation: 0.29557668088636435]
	TIME [epoch: 81.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12872791786326376		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.12872791786326376 | validation: 0.281551188099608]
	TIME [epoch: 81.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14113199190999318		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.14113199190999318 | validation: 0.29292888612237994]
	TIME [epoch: 81.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16104474506443384		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.16104474506443384 | validation: 0.30230233437206316]
	TIME [epoch: 81.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13250158168724435		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.13250158168724435 | validation: 0.29326173696413105]
	TIME [epoch: 81.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15125634618406109		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.15125634618406109 | validation: 0.29488594562718895]
	TIME [epoch: 82 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14807260044504122		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.14807260044504122 | validation: 0.3148076447338726]
	TIME [epoch: 81.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11871774726707683		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.11871774726707683 | validation: 0.3129742518113188]
	TIME [epoch: 81.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15225761615535277		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15225761615535277 | validation: 0.3086787553258752]
	TIME [epoch: 81.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262707508010425		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.14262707508010425 | validation: 0.3095175465162615]
	TIME [epoch: 82 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12979184574726246		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.12979184574726246 | validation: 0.3030415971592716]
	TIME [epoch: 81.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422010148412738		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.1422010148412738 | validation: 0.3148007920980459]
	TIME [epoch: 81.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132882249761964		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.12132882249761964 | validation: 0.2992763323030092]
	TIME [epoch: 81.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544737644402785		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.1544737644402785 | validation: 0.29500796573359905]
	TIME [epoch: 81.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868119129721208		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.14868119129721208 | validation: 0.3051008003309576]
	TIME [epoch: 81.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14423381500115603		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.14423381500115603 | validation: 0.3125452556774719]
	TIME [epoch: 82 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307036057750803		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.1307036057750803 | validation: 0.29252860168426453]
	TIME [epoch: 81.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12764244212089063		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.12764244212089063 | validation: 0.309067046350097]
	TIME [epoch: 81.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13520855579227198		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.13520855579227198 | validation: 0.3097725394662549]
	TIME [epoch: 81.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448981462240159		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12448981462240159 | validation: 0.29944888817893833]
	TIME [epoch: 81.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421548548835573		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1421548548835573 | validation: 0.2952071657847984]
	TIME [epoch: 81.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859796736766748		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.11859796736766748 | validation: 0.28574761280398014]
	TIME [epoch: 81.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13556763337512182		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.13556763337512182 | validation: 0.3127351118094075]
	TIME [epoch: 81.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14254751056376874		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.14254751056376874 | validation: 0.30308858833105046]
	TIME [epoch: 81.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12332796619952487		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.12332796619952487 | validation: 0.3107350355330743]
	TIME [epoch: 81.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15237041509980748		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.15237041509980748 | validation: 0.30048517774009215]
	TIME [epoch: 81.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409322628076295		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.1409322628076295 | validation: 0.29765457448584426]
	TIME [epoch: 81.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577561410062055		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.12577561410062055 | validation: 0.3044370285070192]
	TIME [epoch: 81.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267976798699995		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.1267976798699995 | validation: 0.2967291733621543]
	TIME [epoch: 81.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12948445723254617		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.12948445723254617 | validation: 0.29279424863502174]
	TIME [epoch: 81.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12090975663963258		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.12090975663963258 | validation: 0.30103526803885544]
	TIME [epoch: 81.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263737864288916		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.1263737864288916 | validation: 0.30522180418510925]
	TIME [epoch: 81.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12224660085327042		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.12224660085327042 | validation: 0.2878828271595125]
	TIME [epoch: 81.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13771770793095112		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.13771770793095112 | validation: 0.30538063024801626]
	TIME [epoch: 82 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205134863571724		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13205134863571724 | validation: 0.30964495092307404]
	TIME [epoch: 81.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366916734681747		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.1366916734681747 | validation: 0.290340162960802]
	TIME [epoch: 81.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15749012598656503		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.15749012598656503 | validation: 0.31153833745952436]
	TIME [epoch: 82 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12550499152603792		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.12550499152603792 | validation: 0.2918734778433856]
	TIME [epoch: 82 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942512884383423		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.12942512884383423 | validation: 0.3041637413513318]
	TIME [epoch: 81.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407605392692124		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.12407605392692124 | validation: 0.29951295513482107]
	TIME [epoch: 81.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008873981018863		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.14008873981018863 | validation: 0.2987693369137]
	TIME [epoch: 81.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221739059238305		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.1221739059238305 | validation: 0.29624515384937905]
	TIME [epoch: 81.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13778729508775933		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.13778729508775933 | validation: 0.30757785504784957]
	TIME [epoch: 81.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12451326731921923		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.12451326731921923 | validation: 0.29705622007093474]
	TIME [epoch: 81.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13370800014450715		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.13370800014450715 | validation: 0.29454466489652675]
	TIME [epoch: 81.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136309824989716		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.136309824989716 | validation: 0.31210914589722966]
	TIME [epoch: 82 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488651110216935		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.1488651110216935 | validation: 0.30941734136006105]
	TIME [epoch: 81.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430398485604397		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.13430398485604397 | validation: 0.3012418737119381]
	TIME [epoch: 81.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11605347908648288		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.11605347908648288 | validation: 0.2916812782835887]
	TIME [epoch: 81.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11840785471764384		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.11840785471764384 | validation: 0.2966180111882444]
	TIME [epoch: 81.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13273919318049587		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.13273919318049587 | validation: 0.29557148456337184]
	TIME [epoch: 81.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437879717442509		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.1437879717442509 | validation: 0.30748316955074234]
	TIME [epoch: 81.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368615896045923		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.1368615896045923 | validation: 0.3017228237163128]
	TIME [epoch: 81.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129491964566388		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.129491964566388 | validation: 0.2935081644970898]
	TIME [epoch: 82.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365209864668155		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.14365209864668155 | validation: 0.3132899816187417]
	TIME [epoch: 82 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13232951574011803		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.13232951574011803 | validation: 0.3028745808468782]
	TIME [epoch: 82 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324142229482967		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.1324142229482967 | validation: 0.30329170948105444]
	TIME [epoch: 82 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12466705430367996		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.12466705430367996 | validation: 0.2854901935209767]
	TIME [epoch: 82 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12901962791283272		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.12901962791283272 | validation: 0.29646706602042117]
	TIME [epoch: 82 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351895265500382		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.15351895265500382 | validation: 0.29717746565526354]
	TIME [epoch: 82 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14131348004781458		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.14131348004781458 | validation: 0.2899217382290331]
	TIME [epoch: 82 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386112089382141		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.1386112089382141 | validation: 0.295630920572273]
	TIME [epoch: 82 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308791473417094		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.1308791473417094 | validation: 0.29164951987552196]
	TIME [epoch: 82 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363818226259256		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.1363818226259256 | validation: 0.3126659322098478]
	TIME [epoch: 82 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289457871821838		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.1289457871821838 | validation: 0.2854062226923267]
	TIME [epoch: 82 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146065013848272		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.146065013848272 | validation: 0.3005198568550593]
	TIME [epoch: 82 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16809838990233206		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.16809838990233206 | validation: 0.3067758360809569]
	TIME [epoch: 82 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14668683151989417		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.14668683151989417 | validation: 0.28390820763783464]
	TIME [epoch: 82 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13648014098858718		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.13648014098858718 | validation: 0.31216851618156416]
	TIME [epoch: 82 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298814895713737		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.1298814895713737 | validation: 0.2991294586774587]
	TIME [epoch: 82 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456675216797501		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.1456675216797501 | validation: 0.30784126600933537]
	TIME [epoch: 82 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272472968794994		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.1272472968794994 | validation: 0.2947192807063501]
	TIME [epoch: 82 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12653919779082953		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.12653919779082953 | validation: 0.29838232864522146]
	TIME [epoch: 82 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173879105933337		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.13173879105933337 | validation: 0.2774797678287912]
	TIME [epoch: 82 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326155410938216		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.1326155410938216 | validation: 0.30265324423595874]
	TIME [epoch: 82.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051357258085916		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.13051357258085916 | validation: 0.28915920054159233]
	TIME [epoch: 82 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12196086201039628		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.12196086201039628 | validation: 0.30165238660059707]
	TIME [epoch: 81.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422031661055913		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.12422031661055913 | validation: 0.3165958236941838]
	TIME [epoch: 82 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890155053542374		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.11890155053542374 | validation: 0.30005701332872353]
	TIME [epoch: 82 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1220806996901333		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.1220806996901333 | validation: 0.305265824537397]
	TIME [epoch: 82 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330722745253007		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.1330722745253007 | validation: 0.29302938031841574]
	TIME [epoch: 82 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12222082484577579		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.12222082484577579 | validation: 0.30077450121444693]
	TIME [epoch: 82 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v13b_20240716_164232/states/model_facs_v3_dec2b_2dpca_v13b_629.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 33603.398 seconds.
