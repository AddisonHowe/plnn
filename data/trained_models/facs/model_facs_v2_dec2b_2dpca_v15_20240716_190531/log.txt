Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v15', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v15', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 802811346

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057521568506664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.057521568506664 | validation: 0.910763195748628]
	TIME [epoch: 30.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.665869774435127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.665869774435127 | validation: 0.7754483081025756]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5767908975115782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5767908975115782 | validation: 0.7226406027732681]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408189371623098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5408189371623098 | validation: 0.7004623012972895]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5120266802286986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5120266802286986 | validation: 0.7427377427011683]
	TIME [epoch: 4.22 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47264856837428154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47264856837428154 | validation: 0.6397002511731131]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4795465415212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4795465415212 | validation: 0.6050737171439685]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.456127610636009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.456127610636009 | validation: 0.658020589321124]
	TIME [epoch: 4.2 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43952111393171417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43952111393171417 | validation: 0.5789407032041145]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326009658615256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4326009658615256 | validation: 0.6255985793802481]
	TIME [epoch: 4.24 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45277187562466903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45277187562466903 | validation: 0.5908742919907871]
	TIME [epoch: 4.23 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4116372898669886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4116372898669886 | validation: 0.5095568655433624]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.351062424046861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.351062424046861 | validation: 0.48886568776312195]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35978770465139964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35978770465139964 | validation: 0.6215581947872164]
	TIME [epoch: 4.19 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38659240160495567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38659240160495567 | validation: 0.48272753816252234]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.339707324221814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.339707324221814 | validation: 0.46979420187708626]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3337975095904105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3337975095904105 | validation: 0.5035277633265202]
	TIME [epoch: 4.22 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34840313128777123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34840313128777123 | validation: 0.45384860801610183]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3243287869232402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3243287869232402 | validation: 0.4980203416377319]
	TIME [epoch: 4.21 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31821015369705236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31821015369705236 | validation: 0.43616342958577653]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3335701340238678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3335701340238678 | validation: 0.49567634792601467]
	TIME [epoch: 4.22 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34782275490806935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34782275490806935 | validation: 0.45165076265843396]
	TIME [epoch: 4.22 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28821152207805745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28821152207805745 | validation: 0.45367610043112416]
	TIME [epoch: 4.23 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2949368618803867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2949368618803867 | validation: 0.4236155926291998]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30790220375528465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30790220375528465 | validation: 0.4245528894508816]
	TIME [epoch: 4.22 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3044434538275958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3044434538275958 | validation: 0.45002304690831496]
	TIME [epoch: 4.23 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590641217785453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2590641217785453 | validation: 0.4442158062466454]
	TIME [epoch: 4.22 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2841368196813805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2841368196813805 | validation: 0.49848085682186416]
	TIME [epoch: 4.23 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912494331562205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2912494331562205 | validation: 0.39235572133283275]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2524643757196888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2524643757196888 | validation: 0.3739397645506421]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26705737384059275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26705737384059275 | validation: 0.45228880121816967]
	TIME [epoch: 4.24 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29046029120400985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29046029120400985 | validation: 0.44674346832812295]
	TIME [epoch: 4.23 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2418744852943619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2418744852943619 | validation: 0.3747010929809297]
	TIME [epoch: 4.23 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27375349594708814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27375349594708814 | validation: 0.533526013177552]
	TIME [epoch: 4.22 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27476476461311783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27476476461311783 | validation: 0.39954422206269674]
	TIME [epoch: 4.25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24298239042509379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24298239042509379 | validation: 0.41755251523879944]
	TIME [epoch: 4.24 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28299923890256395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28299923890256395 | validation: 0.392433673579335]
	TIME [epoch: 4.23 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2633784777593265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2633784777593265 | validation: 0.4104516491406542]
	TIME [epoch: 4.23 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2521354345329162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2521354345329162 | validation: 0.42052432997820005]
	TIME [epoch: 4.24 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27609801060946315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27609801060946315 | validation: 0.4260693279530544]
	TIME [epoch: 4.24 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23095499131916536		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.23095499131916536 | validation: 0.36876663612848415]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26819198220097445		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.26819198220097445 | validation: 0.3997182744728432]
	TIME [epoch: 4.22 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26773417129737503		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.26773417129737503 | validation: 0.415681139139058]
	TIME [epoch: 4.25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574363415865049		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.2574363415865049 | validation: 0.4627590879056785]
	TIME [epoch: 4.23 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3255349780630074		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.3255349780630074 | validation: 0.3671178027791459]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30288638978448434		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.30288638978448434 | validation: 0.4137389561143828]
	TIME [epoch: 4.21 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27204611549025454		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.27204611549025454 | validation: 0.38573476060387146]
	TIME [epoch: 4.22 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26904978513506483		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.26904978513506483 | validation: 0.4242347007930156]
	TIME [epoch: 4.21 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.319878835482091		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.319878835482091 | validation: 0.3847007784471203]
	TIME [epoch: 4.21 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28185081392418027		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.28185081392418027 | validation: 0.40854928165504867]
	TIME [epoch: 4.21 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24353155983615035		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.24353155983615035 | validation: 0.36092239957107153]
	TIME [epoch: 31.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24394890632796237		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.24394890632796237 | validation: 0.4392505567725431]
	TIME [epoch: 8.06 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2511395575339994		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2511395575339994 | validation: 0.36773455533913646]
	TIME [epoch: 8.08 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243219791125522		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.243219791125522 | validation: 0.46693065809325585]
	TIME [epoch: 8.05 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27971599621122134		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.27971599621122134 | validation: 0.36305646575760625]
	TIME [epoch: 8.05 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23690329765021656		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.23690329765021656 | validation: 0.33974823575210217]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530800630576277		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2530800630576277 | validation: 0.3711177529033898]
	TIME [epoch: 8.04 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24589275171837682		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.24589275171837682 | validation: 0.384568073982412]
	TIME [epoch: 8.04 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25308861078178474		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.25308861078178474 | validation: 0.3555472735000358]
	TIME [epoch: 8.05 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21598538343845491		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.21598538343845491 | validation: 0.3806703967896311]
	TIME [epoch: 8.05 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24119798106349596		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.24119798106349596 | validation: 0.4319143904213285]
	TIME [epoch: 8.04 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24661258923105756		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.24661258923105756 | validation: 0.32607379095216327]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23595934256166062		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.23595934256166062 | validation: 0.34758755138416353]
	TIME [epoch: 8.03 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20984444439454625		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.20984444439454625 | validation: 0.3855293555645175]
	TIME [epoch: 8.04 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2644706113310469		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2644706113310469 | validation: 0.389024921759877]
	TIME [epoch: 8.04 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22528933437832696		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.22528933437832696 | validation: 0.34835177970144643]
	TIME [epoch: 8.06 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24403289504064526		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.24403289504064526 | validation: 0.3280951095838808]
	TIME [epoch: 8.03 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21834626172867946		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.21834626172867946 | validation: 0.3308276033832629]
	TIME [epoch: 8.05 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079534807260676		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.2079534807260676 | validation: 0.4032242222269135]
	TIME [epoch: 8.01 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24987071162926		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.24987071162926 | validation: 0.3655895356552913]
	TIME [epoch: 8.04 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23436762541406503		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.23436762541406503 | validation: 0.41624517496786195]
	TIME [epoch: 8.02 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256808824100652		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.256808824100652 | validation: 0.3631579594851417]
	TIME [epoch: 8.05 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2248972895050617		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2248972895050617 | validation: 0.3416314872995672]
	TIME [epoch: 8.03 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2188835846018617		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2188835846018617 | validation: 0.4068494847007548]
	TIME [epoch: 8.05 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24668329252033167		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.24668329252033167 | validation: 0.5087694458635283]
	TIME [epoch: 8.05 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2430746025136817		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2430746025136817 | validation: 0.3867818150840138]
	TIME [epoch: 8.04 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2152912356829532		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2152912356829532 | validation: 0.48414720463973515]
	TIME [epoch: 8.06 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21596987359028158		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.21596987359028158 | validation: 0.34076666581420967]
	TIME [epoch: 8.05 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2239317167736136		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2239317167736136 | validation: 0.44742331292008825]
	TIME [epoch: 8.05 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2269910245920407		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.2269910245920407 | validation: 0.33390686869863206]
	TIME [epoch: 8.07 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22663444606431823		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22663444606431823 | validation: 0.3534721714893961]
	TIME [epoch: 8.05 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22149699978383258		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.22149699978383258 | validation: 0.34065368677050034]
	TIME [epoch: 8.06 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20684902653211176		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.20684902653211176 | validation: 0.38768701376606063]
	TIME [epoch: 8.04 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22167823795536293		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.22167823795536293 | validation: 0.3261444554436471]
	TIME [epoch: 8.08 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21789854504953404		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.21789854504953404 | validation: 0.37706079181653385]
	TIME [epoch: 8.07 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23122289354988554		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.23122289354988554 | validation: 0.32501458138258665]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2240551337496924		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.2240551337496924 | validation: 0.3939826037406244]
	TIME [epoch: 8.06 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2446481116635701		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.2446481116635701 | validation: 0.35192612744549123]
	TIME [epoch: 8.08 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2178227731728139		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.2178227731728139 | validation: 0.43894527708730346]
	TIME [epoch: 8.07 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.263554335279479		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.263554335279479 | validation: 0.41247052109519233]
	TIME [epoch: 8.07 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20459278986906315		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.20459278986906315 | validation: 0.33986487972962]
	TIME [epoch: 8.06 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21900403385940442		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21900403385940442 | validation: 0.314546417504437]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22244007987546963		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.22244007987546963 | validation: 0.32658425228059135]
	TIME [epoch: 8.07 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21778697201620356		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.21778697201620356 | validation: 0.3494181561574841]
	TIME [epoch: 8.05 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22958875745722956		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.22958875745722956 | validation: 0.3525617496860762]
	TIME [epoch: 8.03 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19955629859728768		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.19955629859728768 | validation: 0.3452598137949637]
	TIME [epoch: 8.04 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21072662601196596		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21072662601196596 | validation: 0.3391712743317746]
	TIME [epoch: 8.07 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23653087216616497		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.23653087216616497 | validation: 0.31814852347927763]
	TIME [epoch: 8.07 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20330411865239081		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.20330411865239081 | validation: 0.343540259972517]
	TIME [epoch: 8.07 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20872468524654067		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.20872468524654067 | validation: 0.3517033701287553]
	TIME [epoch: 8.05 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2555265491377239		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.2555265491377239 | validation: 0.3405244291645144]
	TIME [epoch: 8.05 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2112969631917203		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2112969631917203 | validation: 0.36722335877898077]
	TIME [epoch: 8.08 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22288384734314576		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.22288384734314576 | validation: 0.37428439858327045]
	TIME [epoch: 8.09 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24215782102626657		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.24215782102626657 | validation: 0.3531855555885644]
	TIME [epoch: 8.04 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2559640380415199		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2559640380415199 | validation: 0.3274948833198864]
	TIME [epoch: 8.07 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23575254653452168		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.23575254653452168 | validation: 0.32059728028652834]
	TIME [epoch: 8.08 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20283689669778254		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.20283689669778254 | validation: 0.337906337964918]
	TIME [epoch: 8.06 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18831726312081204		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.18831726312081204 | validation: 0.32684807718401027]
	TIME [epoch: 8.09 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21933629627910417		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.21933629627910417 | validation: 0.401901416775334]
	TIME [epoch: 8.06 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2421124599577938		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.2421124599577938 | validation: 0.3089872488738068]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202440372436286		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.202440372436286 | validation: 0.3154546548222217]
	TIME [epoch: 8.07 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21673396186209307		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.21673396186209307 | validation: 0.32642344859745126]
	TIME [epoch: 8.03 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2060951890918301		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2060951890918301 | validation: 0.42240455726459514]
	TIME [epoch: 8.03 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299777734333892		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.2299777734333892 | validation: 0.35927085950517956]
	TIME [epoch: 8.06 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18592694141365368		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.18592694141365368 | validation: 0.3684142729578742]
	TIME [epoch: 8.05 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21902326598913174		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.21902326598913174 | validation: 0.37873626893741597]
	TIME [epoch: 8.05 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20357517645147727		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.20357517645147727 | validation: 0.3867652761649866]
	TIME [epoch: 8.04 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23763368238683125		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.23763368238683125 | validation: 0.35113920345513794]
	TIME [epoch: 8.07 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22168613169180945		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.22168613169180945 | validation: 0.3258788541384389]
	TIME [epoch: 8.06 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2227586778540714		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2227586778540714 | validation: 0.359561603009682]
	TIME [epoch: 8.05 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2146771082364342		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.2146771082364342 | validation: 0.35642593074348883]
	TIME [epoch: 8.08 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22983061219554832		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.22983061219554832 | validation: 0.4624657244505823]
	TIME [epoch: 8.06 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366463075805801		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.2366463075805801 | validation: 0.37895178352111863]
	TIME [epoch: 8.06 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29444867364308347		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.29444867364308347 | validation: 0.3318613342884279]
	TIME [epoch: 8.04 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2228078256060376		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.2228078256060376 | validation: 0.3171721924982894]
	TIME [epoch: 8.02 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21195980827952293		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.21195980827952293 | validation: 0.33224634511514095]
	TIME [epoch: 8.07 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19798701681325465		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.19798701681325465 | validation: 0.345715351506437]
	TIME [epoch: 8.07 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20441598266838973		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20441598266838973 | validation: 0.35899548535054093]
	TIME [epoch: 8.07 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20703678280610496		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20703678280610496 | validation: 0.380976420550388]
	TIME [epoch: 8.05 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1939358768224913		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1939358768224913 | validation: 0.4138958941312716]
	TIME [epoch: 8.03 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21596723048281258		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.21596723048281258 | validation: 0.466742822212991]
	TIME [epoch: 8.08 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023854748125274		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2023854748125274 | validation: 0.33925407537231694]
	TIME [epoch: 8.05 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18075295421127155		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.18075295421127155 | validation: 0.36115350650162475]
	TIME [epoch: 8.06 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18048287448027517		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.18048287448027517 | validation: 0.3275192235866494]
	TIME [epoch: 8.04 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19911776981259252		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.19911776981259252 | validation: 0.37367428426231153]
	TIME [epoch: 8.03 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20663041924515607		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.20663041924515607 | validation: 0.45890835656170853]
	TIME [epoch: 8.06 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2053831581889783		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.2053831581889783 | validation: 0.34993928262622565]
	TIME [epoch: 8.03 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18957766985613794		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.18957766985613794 | validation: 0.3803843100689959]
	TIME [epoch: 8.04 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19871975667374212		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.19871975667374212 | validation: 0.33047338595881426]
	TIME [epoch: 8.05 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1917382082790696		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1917382082790696 | validation: 0.29710725807464844]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20319084700567763		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.20319084700567763 | validation: 0.3464475358607222]
	TIME [epoch: 8.01 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205688884042524		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.2205688884042524 | validation: 0.3008751014242473]
	TIME [epoch: 8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20747797569767612		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.20747797569767612 | validation: 0.30127134927847843]
	TIME [epoch: 8.03 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20412775767452987		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.20412775767452987 | validation: 0.34735291037007493]
	TIME [epoch: 8.03 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23563223951491546		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.23563223951491546 | validation: 0.2888797640037851]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22469828492271354		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.22469828492271354 | validation: 0.3283797676746827]
	TIME [epoch: 8.02 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19765174470973457		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.19765174470973457 | validation: 0.3031386163717108]
	TIME [epoch: 8.02 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19327423391858228		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.19327423391858228 | validation: 0.3323205716545803]
	TIME [epoch: 8.02 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19873074613652192		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.19873074613652192 | validation: 0.4008521383056954]
	TIME [epoch: 8.04 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16768505099181671		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.16768505099181671 | validation: 0.2972204999473875]
	TIME [epoch: 8.01 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1783627776720323		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1783627776720323 | validation: 0.3110756679528865]
	TIME [epoch: 8.01 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.191694096368277		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.191694096368277 | validation: 0.3288207366929756]
	TIME [epoch: 8.02 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20317999028769082		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.20317999028769082 | validation: 0.3199163112556528]
	TIME [epoch: 8.01 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18230428484260694		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.18230428484260694 | validation: 0.34806716490268336]
	TIME [epoch: 8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1919986191647057		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.1919986191647057 | validation: 0.3046556029831623]
	TIME [epoch: 8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21119908148389116		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.21119908148389116 | validation: 0.3185834975883371]
	TIME [epoch: 8.02 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20023820614703655		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.20023820614703655 | validation: 0.3178064636310951]
	TIME [epoch: 8.02 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23715526221462283		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.23715526221462283 | validation: 0.43007399416299613]
	TIME [epoch: 8.02 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2878700067994999		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.2878700067994999 | validation: 0.3606167934146076]
	TIME [epoch: 8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24331548112352133		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.24331548112352133 | validation: 0.33476601868187683]
	TIME [epoch: 8.02 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21003995493591382		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.21003995493591382 | validation: 0.3056034539697086]
	TIME [epoch: 8.02 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2279621213779913		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.2279621213779913 | validation: 0.3532891618607338]
	TIME [epoch: 8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19347664747963944		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.19347664747963944 | validation: 0.3171828944991115]
	TIME [epoch: 8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18227586484789585		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.18227586484789585 | validation: 0.34041704431202113]
	TIME [epoch: 8.03 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953438445023799		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.1953438445023799 | validation: 0.34748005807192855]
	TIME [epoch: 8.04 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19383672210473757		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.19383672210473757 | validation: 0.30894408644954235]
	TIME [epoch: 8.01 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1877515595618602		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.1877515595618602 | validation: 0.30283855872835663]
	TIME [epoch: 8.04 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1919666903966246		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1919666903966246 | validation: 0.3472312910842254]
	TIME [epoch: 8.04 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17938272335061062		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.17938272335061062 | validation: 0.4004063715670501]
	TIME [epoch: 8.07 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2908383803039897		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.2908383803039897 | validation: 0.33117861960170564]
	TIME [epoch: 8.01 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21706533115326368		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.21706533115326368 | validation: 0.31438688296620526]
	TIME [epoch: 8.01 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18400177365910314		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.18400177365910314 | validation: 0.3482402168838394]
	TIME [epoch: 8.03 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19021422142523928		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.19021422142523928 | validation: 0.323266626784651]
	TIME [epoch: 8.07 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1871962175906845		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.1871962175906845 | validation: 0.3462822728340494]
	TIME [epoch: 8.03 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885750522266357		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.1885750522266357 | validation: 0.36302903565845507]
	TIME [epoch: 8.02 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18865511802369508		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18865511802369508 | validation: 0.30023483087240055]
	TIME [epoch: 8.03 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17771073811042265		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17771073811042265 | validation: 0.298430935741438]
	TIME [epoch: 8.07 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19496063373059905		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.19496063373059905 | validation: 0.2976154398293981]
	TIME [epoch: 8.03 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176886725768451		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.176886725768451 | validation: 0.3449379718849533]
	TIME [epoch: 8.03 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1918998366242123		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1918998366242123 | validation: 0.309981603192173]
	TIME [epoch: 8.04 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19079567548331486		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.19079567548331486 | validation: 0.3106741946748506]
	TIME [epoch: 8.05 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911604801329729		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.1911604801329729 | validation: 0.38300969745226177]
	TIME [epoch: 8.05 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21372384481275403		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.21372384481275403 | validation: 0.38879254368445504]
	TIME [epoch: 8.04 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1993919859871242		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1993919859871242 | validation: 0.32688704724268003]
	TIME [epoch: 8.05 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2059785407571507		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.2059785407571507 | validation: 0.3075689985568003]
	TIME [epoch: 8.07 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17564210324092522		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.17564210324092522 | validation: 0.3152210475018562]
	TIME [epoch: 8.06 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759467601173466		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.1759467601173466 | validation: 0.3017519770992825]
	TIME [epoch: 8.04 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19096308105404616		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.19096308105404616 | validation: 0.29460340368019855]
	TIME [epoch: 8.04 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19137605568240676		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.19137605568240676 | validation: 0.38908011233618056]
	TIME [epoch: 8.06 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17788815497594435		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.17788815497594435 | validation: 0.32124426273993406]
	TIME [epoch: 8.07 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17967787088495174		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.17967787088495174 | validation: 0.30150469548369885]
	TIME [epoch: 8.05 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730282074473573		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1730282074473573 | validation: 0.27240713207596645]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18157329177673331		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18157329177673331 | validation: 0.3189361304073513]
	TIME [epoch: 8.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19055012116102346		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.19055012116102346 | validation: 0.37877248074886294]
	TIME [epoch: 8.03 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19651565176360866		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.19651565176360866 | validation: 0.341898876764609]
	TIME [epoch: 8.01 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1943285200531662		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1943285200531662 | validation: 0.36548262198783715]
	TIME [epoch: 8.02 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22151333980454108		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.22151333980454108 | validation: 0.34419536412700014]
	TIME [epoch: 8.03 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17311711003153774		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17311711003153774 | validation: 0.3168606383270909]
	TIME [epoch: 8.04 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912543521990223		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.1912543521990223 | validation: 0.27277337010335445]
	TIME [epoch: 8.03 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18446837011898515		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.18446837011898515 | validation: 0.3038572136834914]
	TIME [epoch: 8.05 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16932593479808172		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.16932593479808172 | validation: 0.30499159402727477]
	TIME [epoch: 8.04 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19839759378396443		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.19839759378396443 | validation: 0.2960158096751443]
	TIME [epoch: 8.05 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17709411264160094		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.17709411264160094 | validation: 0.2847984175449771]
	TIME [epoch: 8.05 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19196518472683785		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.19196518472683785 | validation: 0.3067801173368711]
	TIME [epoch: 8.04 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17516124043997103		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.17516124043997103 | validation: 0.28595157115794806]
	TIME [epoch: 8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16100307864288274		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.16100307864288274 | validation: 0.35701184862890817]
	TIME [epoch: 8.04 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338976108833634		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.17338976108833634 | validation: 0.31394672099548676]
	TIME [epoch: 8.04 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18176867992236834		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.18176867992236834 | validation: 0.34050381565963445]
	TIME [epoch: 8.02 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18546319346031154		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18546319346031154 | validation: 0.32136988004376527]
	TIME [epoch: 8.05 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18319150851017435		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.18319150851017435 | validation: 0.32494344325401525]
	TIME [epoch: 8.04 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1706371746177477		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.1706371746177477 | validation: 0.31425705316913793]
	TIME [epoch: 8.04 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17878181174592891		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.17878181174592891 | validation: 0.30014578640931355]
	TIME [epoch: 8.05 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16733806456793218		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.16733806456793218 | validation: 0.31291505937131664]
	TIME [epoch: 8.04 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18719741421790886		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18719741421790886 | validation: 0.29284892975915155]
	TIME [epoch: 8.02 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18428294908526885		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.18428294908526885 | validation: 0.29743242467468545]
	TIME [epoch: 8.07 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718167649459689		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1718167649459689 | validation: 0.30441165288701433]
	TIME [epoch: 8.05 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18036918159939433		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.18036918159939433 | validation: 0.31148282806125765]
	TIME [epoch: 8.03 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17058185977471446		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17058185977471446 | validation: 0.33003780563168394]
	TIME [epoch: 8.02 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18432900824644013		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.18432900824644013 | validation: 0.33435927235726814]
	TIME [epoch: 8.04 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498130913735543		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.16498130913735543 | validation: 0.3256564874163597]
	TIME [epoch: 8.03 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16505444534466682		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.16505444534466682 | validation: 0.29524162613859256]
	TIME [epoch: 8.05 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18071047344900887		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.18071047344900887 | validation: 0.31191141116681137]
	TIME [epoch: 8.03 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819554795979501		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.1819554795979501 | validation: 0.3094726827273836]
	TIME [epoch: 8.06 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17816844865223014		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.17816844865223014 | validation: 0.3144920985575924]
	TIME [epoch: 8.04 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18451792109109272		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18451792109109272 | validation: 0.29573556910568327]
	TIME [epoch: 8.05 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17847639626100703		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17847639626100703 | validation: 0.3520768449503364]
	TIME [epoch: 8.04 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18290835035299224		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.18290835035299224 | validation: 0.315439051944742]
	TIME [epoch: 8.07 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18742795223735348		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.18742795223735348 | validation: 0.3031714163945686]
	TIME [epoch: 8.04 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18454906337883506		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.18454906337883506 | validation: 0.3509215210587866]
	TIME [epoch: 8.03 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17207111430744948		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.17207111430744948 | validation: 0.41673880860384516]
	TIME [epoch: 8.02 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1828204275387723		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1828204275387723 | validation: 0.3024237152186742]
	TIME [epoch: 8.06 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18420879218897845		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.18420879218897845 | validation: 0.2968807666178047]
	TIME [epoch: 8.05 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1754446003233072		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1754446003233072 | validation: 0.3140041244315763]
	TIME [epoch: 8.04 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1714925655819273		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.1714925655819273 | validation: 0.2769717922248003]
	TIME [epoch: 8.02 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16520657027646912		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.16520657027646912 | validation: 0.310374801419719]
	TIME [epoch: 8.04 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16434739662165007		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16434739662165007 | validation: 0.3003974286171425]
	TIME [epoch: 8.04 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17443747343866786		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17443747343866786 | validation: 0.3127437468933053]
	TIME [epoch: 8.04 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152502579813232		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.18152502579813232 | validation: 0.2944868307694419]
	TIME [epoch: 8.04 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16881846324545705		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.16881846324545705 | validation: 0.2735961532734306]
	TIME [epoch: 8.03 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17268098589995806		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.17268098589995806 | validation: 0.29855638221243846]
	TIME [epoch: 8.05 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17196796787942498		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17196796787942498 | validation: 0.29905140521396656]
	TIME [epoch: 8.05 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17401909785984043		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.17401909785984043 | validation: 0.32920711391579155]
	TIME [epoch: 8.03 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762342197216957		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.1762342197216957 | validation: 0.30010374099682696]
	TIME [epoch: 8.03 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16459204172025277		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.16459204172025277 | validation: 0.28239326418035376]
	TIME [epoch: 8.05 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16625428500238265		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.16625428500238265 | validation: 0.3058564099000829]
	TIME [epoch: 8.03 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18516912372844757		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.18516912372844757 | validation: 0.3797461745134763]
	TIME [epoch: 8.04 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18167558531342484		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.18167558531342484 | validation: 0.3456635154488479]
	TIME [epoch: 8.04 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1625455623955292		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.1625455623955292 | validation: 0.29479764577022377]
	TIME [epoch: 8.06 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17723806881135684		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17723806881135684 | validation: 0.29653264200467483]
	TIME [epoch: 8.05 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17329447127375502		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.17329447127375502 | validation: 0.28203663377169774]
	TIME [epoch: 8.05 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17713668495535817		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.17713668495535817 | validation: 0.30184518718958264]
	TIME [epoch: 8.04 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17834892780308453		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.17834892780308453 | validation: 0.2894829929368622]
	TIME [epoch: 8.05 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18179826126016402		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18179826126016402 | validation: 0.2887465143713589]
	TIME [epoch: 8.05 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16174073687739637		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.16174073687739637 | validation: 0.2966685941394843]
	TIME [epoch: 8.03 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17607638573531692		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.17607638573531692 | validation: 0.29471373524524336]
	TIME [epoch: 8.04 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15984537057634954		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.15984537057634954 | validation: 0.2874682865575314]
	TIME [epoch: 8.05 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1766356622033058		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1766356622033058 | validation: 0.2742677361851787]
	TIME [epoch: 8.04 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17419738001566185		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17419738001566185 | validation: 0.3488332909396641]
	TIME [epoch: 8.03 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17974650887722646		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.17974650887722646 | validation: 0.29912299639029083]
	TIME [epoch: 8.05 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1695905627818035		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1695905627818035 | validation: 0.2729311109390309]
	TIME [epoch: 8.04 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15460786012745853		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.15460786012745853 | validation: 0.33211167424437066]
	TIME [epoch: 8.06 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16082913000666582		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16082913000666582 | validation: 0.31169975148857704]
	TIME [epoch: 8.06 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18081346102596568		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.18081346102596568 | validation: 0.3377782386647673]
	TIME [epoch: 8.06 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16161166126717028		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16161166126717028 | validation: 0.4345837822139041]
	TIME [epoch: 8.05 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16997565744360452		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16997565744360452 | validation: 0.3129593738146584]
	TIME [epoch: 8.07 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16704950548466138		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16704950548466138 | validation: 0.2941294280992465]
	TIME [epoch: 8.05 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18439534109879646		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.18439534109879646 | validation: 0.2979153638497506]
	TIME [epoch: 8.04 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16941881725609695		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.16941881725609695 | validation: 0.27983704123889563]
	TIME [epoch: 8.06 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17390862588196407		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.17390862588196407 | validation: 0.27104081910765043]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651014247702914		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.1651014247702914 | validation: 0.2964180677015209]
	TIME [epoch: 8.02 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723972092244845		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1723972092244845 | validation: 0.29653413869943757]
	TIME [epoch: 8.04 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715445509456779		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1715445509456779 | validation: 0.2713237861003632]
	TIME [epoch: 8.03 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742630542996652		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1742630542996652 | validation: 0.29323827283254666]
	TIME [epoch: 8.04 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17287611101031458		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.17287611101031458 | validation: 0.3008735502566451]
	TIME [epoch: 8.03 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16174223900773788		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.16174223900773788 | validation: 0.2974437097015273]
	TIME [epoch: 8.03 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17730047718865022		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.17730047718865022 | validation: 0.2797074096777541]
	TIME [epoch: 8.03 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626204173437989		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.1626204173437989 | validation: 0.34315914228219085]
	TIME [epoch: 8.02 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16995098843764017		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16995098843764017 | validation: 0.31446253176952416]
	TIME [epoch: 8.03 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17274433045558174		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.17274433045558174 | validation: 0.28320671606396813]
	TIME [epoch: 8.01 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18150871305826138		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.18150871305826138 | validation: 0.3094390585793443]
	TIME [epoch: 8.03 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1798270856531724		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1798270856531724 | validation: 0.32340914871878534]
	TIME [epoch: 8.02 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16662126649449024		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.16662126649449024 | validation: 0.3180977027849142]
	TIME [epoch: 8.05 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.171820105167991		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.171820105167991 | validation: 0.3047645232489754]
	TIME [epoch: 8.03 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16726097464923395		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16726097464923395 | validation: 0.3026312844535725]
	TIME [epoch: 8.02 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624862228977594		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.1624862228977594 | validation: 0.29441089828808686]
	TIME [epoch: 8.03 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582792979146453		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.1582792979146453 | validation: 0.3019325400328481]
	TIME [epoch: 8.05 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883900931016264		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.1883900931016264 | validation: 0.33572124100484524]
	TIME [epoch: 8.02 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1662299280412351		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1662299280412351 | validation: 0.3181920298588663]
	TIME [epoch: 8.04 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15520859614041418		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15520859614041418 | validation: 0.2842598303479833]
	TIME [epoch: 8.01 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18202822989735062		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.18202822989735062 | validation: 0.30462726564722914]
	TIME [epoch: 8.06 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674133675716249		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1674133675716249 | validation: 0.3069375164192102]
	TIME [epoch: 8.03 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16111656246873376		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16111656246873376 | validation: 0.30021340854005546]
	TIME [epoch: 8.02 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16426931778391773		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16426931778391773 | validation: 0.28513881687108017]
	TIME [epoch: 8.02 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16581485886908318		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.16581485886908318 | validation: 0.2584074633227555]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17147565789367608		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.17147565789367608 | validation: 0.28110612623984493]
	TIME [epoch: 8.02 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18066680280232322		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.18066680280232322 | validation: 0.26605093068329067]
	TIME [epoch: 8.03 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16292851396539038		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16292851396539038 | validation: 0.2876825127191664]
	TIME [epoch: 8.02 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17159859247128179		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.17159859247128179 | validation: 0.27704052214460934]
	TIME [epoch: 8.01 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17049297315938808		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.17049297315938808 | validation: 0.3146252461499196]
	TIME [epoch: 8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707853731300285		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1707853731300285 | validation: 0.3306115261575961]
	TIME [epoch: 8.01 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17396147392375028		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.17396147392375028 | validation: 0.2871320030028902]
	TIME [epoch: 8.08 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18019202385643304		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.18019202385643304 | validation: 0.3299685571723633]
	TIME [epoch: 8.09 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16675289141590968		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.16675289141590968 | validation: 0.2776451706640169]
	TIME [epoch: 8.07 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15660571265675688		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.15660571265675688 | validation: 0.30002590083470526]
	TIME [epoch: 8.09 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18589578288149813		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.18589578288149813 | validation: 0.305024727707949]
	TIME [epoch: 8.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682204991753036		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16682204991753036 | validation: 0.305338406055785]
	TIME [epoch: 8.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15884377443469944		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.15884377443469944 | validation: 0.28513836292301886]
	TIME [epoch: 8.11 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15118235898326962		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.15118235898326962 | validation: 0.2795495180536251]
	TIME [epoch: 8.09 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626656777307412		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.1626656777307412 | validation: 0.3024124119610293]
	TIME [epoch: 8.09 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18046951626663277		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.18046951626663277 | validation: 0.2733780290543203]
	TIME [epoch: 8.09 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15798924732729408		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.15798924732729408 | validation: 0.31318578839994465]
	TIME [epoch: 8.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16347023812739855		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16347023812739855 | validation: 0.3525591614768521]
	TIME [epoch: 8.02 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15714699440024635		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.15714699440024635 | validation: 0.32402252090662237]
	TIME [epoch: 8.02 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16564417011665622		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.16564417011665622 | validation: 0.34879856039682416]
	TIME [epoch: 8.04 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1667572698717379		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.1667572698717379 | validation: 0.30220307787631756]
	TIME [epoch: 8.04 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16786352691109413		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.16786352691109413 | validation: 0.2682595879480404]
	TIME [epoch: 8.04 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288214556872028		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.17288214556872028 | validation: 0.2810211645076692]
	TIME [epoch: 8.06 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16589564896448056		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16589564896448056 | validation: 0.3213870345545997]
	TIME [epoch: 8.02 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538404458510028		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.1538404458510028 | validation: 0.2942994510258108]
	TIME [epoch: 8.02 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643771947788759		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1643771947788759 | validation: 0.3031825205640351]
	TIME [epoch: 8.02 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189891658617966		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16189891658617966 | validation: 0.3203636272343924]
	TIME [epoch: 8.04 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17689947453469895		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.17689947453469895 | validation: 0.290587900905595]
	TIME [epoch: 8.04 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16965590949853002		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.16965590949853002 | validation: 0.270049944549881]
	TIME [epoch: 8.04 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16482520306521478		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16482520306521478 | validation: 0.326388414958734]
	TIME [epoch: 8.03 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725271326363191		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.1725271326363191 | validation: 0.3615664728178864]
	TIME [epoch: 8.03 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15830501131571562		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.15830501131571562 | validation: 0.2681904130419396]
	TIME [epoch: 8.02 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16637500468574223		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.16637500468574223 | validation: 0.3017430321307242]
	TIME [epoch: 8.05 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15688831871379166		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.15688831871379166 | validation: 0.29383088894486553]
	TIME [epoch: 8.02 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277142966791747		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.16277142966791747 | validation: 0.2807332379879425]
	TIME [epoch: 8.04 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1719112726949126		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.1719112726949126 | validation: 0.29121299561070346]
	TIME [epoch: 8.06 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15855010702437983		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.15855010702437983 | validation: 0.29512260600814605]
	TIME [epoch: 8.05 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15496472787306045		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15496472787306045 | validation: 0.29845488652272906]
	TIME [epoch: 8.04 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17233930068612424		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.17233930068612424 | validation: 0.28668673615912954]
	TIME [epoch: 8.04 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16698418737458684		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16698418737458684 | validation: 0.28360626124814203]
	TIME [epoch: 8.04 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16732895240677315		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16732895240677315 | validation: 0.27323101871805666]
	TIME [epoch: 8.05 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609637695512634		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1609637695512634 | validation: 0.29655868376591676]
	TIME [epoch: 8.05 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16485866931554286		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16485866931554286 | validation: 0.3013480929919075]
	TIME [epoch: 8.05 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184504536058385		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.15184504536058385 | validation: 0.2789228610285687]
	TIME [epoch: 8.05 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16992285030513132		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16992285030513132 | validation: 0.2955663484817657]
	TIME [epoch: 8.02 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15844766110808584		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.15844766110808584 | validation: 0.2721274104085547]
	TIME [epoch: 8.04 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1695295466521163		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.1695295466521163 | validation: 0.2918972372347266]
	TIME [epoch: 8.04 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16517282861441954		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.16517282861441954 | validation: 0.35615582676029867]
	TIME [epoch: 8.02 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16223716165790641		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16223716165790641 | validation: 0.2902149668928784]
	TIME [epoch: 8.03 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17069127753340035		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.17069127753340035 | validation: 0.30902735454304925]
	TIME [epoch: 8.05 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16541203634492027		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16541203634492027 | validation: 0.29212938985253323]
	TIME [epoch: 8.04 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15365391726432678		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.15365391726432678 | validation: 0.3157071531237653]
	TIME [epoch: 8.04 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16285761109872543		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.16285761109872543 | validation: 0.28497209274554647]
	TIME [epoch: 8.02 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109284469994955		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.15109284469994955 | validation: 0.2963035350908601]
	TIME [epoch: 8.05 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18380144790963088		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.18380144790963088 | validation: 0.2709674706781297]
	TIME [epoch: 8.01 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16151007434392972		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.16151007434392972 | validation: 0.31638629212636127]
	TIME [epoch: 8.03 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16485054983605316		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16485054983605316 | validation: 0.2884623151404846]
	TIME [epoch: 8.06 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16753474890392658		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16753474890392658 | validation: 0.29906744407955604]
	TIME [epoch: 8.05 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584498162740555		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1584498162740555 | validation: 0.28483042615590326]
	TIME [epoch: 8.06 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742919880704866		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.1742919880704866 | validation: 0.28955619904180274]
	TIME [epoch: 8.05 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16522621929784392		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.16522621929784392 | validation: 0.30537750942329706]
	TIME [epoch: 8.06 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16666797256882554		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.16666797256882554 | validation: 0.29935239775032385]
	TIME [epoch: 8.05 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16319035526886644		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.16319035526886644 | validation: 0.3344211662038812]
	TIME [epoch: 8.05 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16154858569455288		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.16154858569455288 | validation: 0.2869113061252359]
	TIME [epoch: 8.06 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16265180705603688		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16265180705603688 | validation: 0.28008449921702666]
	TIME [epoch: 8.05 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15481973893618745		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.15481973893618745 | validation: 0.3050693523191904]
	TIME [epoch: 8.06 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639105733204303		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1639105733204303 | validation: 0.25532302588362166]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16855797049584587		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16855797049584587 | validation: 0.3039660801175672]
	TIME [epoch: 8.08 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914231028322978		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.15914231028322978 | validation: 0.28000206994734983]
	TIME [epoch: 8.09 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15798455058693306		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15798455058693306 | validation: 0.30940761619267765]
	TIME [epoch: 8.09 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15809050828559107		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15809050828559107 | validation: 0.32559235289846816]
	TIME [epoch: 8.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16262164754094763		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.16262164754094763 | validation: 0.31663100265352856]
	TIME [epoch: 8.08 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14835815725630772		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.14835815725630772 | validation: 0.30619314337581216]
	TIME [epoch: 8.08 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.166804803579666		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.166804803579666 | validation: 0.3073988027803383]
	TIME [epoch: 8.07 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16487240464546768		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.16487240464546768 | validation: 0.3131323651678404]
	TIME [epoch: 8.11 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16448540425796376		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.16448540425796376 | validation: 0.29842374014620787]
	TIME [epoch: 8.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594224955733964		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.1594224955733964 | validation: 0.2845517553557995]
	TIME [epoch: 8.08 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554232517581674		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.1554232517581674 | validation: 0.2693616829514776]
	TIME [epoch: 8.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15357017052235572		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15357017052235572 | validation: 0.26746291535399963]
	TIME [epoch: 8.09 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16148528538158344		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16148528538158344 | validation: 0.27503465030731455]
	TIME [epoch: 8.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16402267928962422		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.16402267928962422 | validation: 0.2744088623774498]
	TIME [epoch: 8.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17359372377244192		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.17359372377244192 | validation: 0.2651042253380231]
	TIME [epoch: 8.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564234522819477		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1564234522819477 | validation: 0.27415167281086805]
	TIME [epoch: 8.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548026631705088		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.1548026631705088 | validation: 0.29224569683886187]
	TIME [epoch: 8.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16773687288381683		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16773687288381683 | validation: 0.2657662397773702]
	TIME [epoch: 8.07 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15050749707930275		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15050749707930275 | validation: 0.34567247129567963]
	TIME [epoch: 8.09 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16115832479932762		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.16115832479932762 | validation: 0.2881395571140766]
	TIME [epoch: 8.09 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15436032622321066		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.15436032622321066 | validation: 0.2970940641652928]
	TIME [epoch: 8.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555910095933522		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.1555910095933522 | validation: 0.2701869906599307]
	TIME [epoch: 8.07 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16011546198286675		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16011546198286675 | validation: 0.26471501797556257]
	TIME [epoch: 8.06 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15524520187830002		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15524520187830002 | validation: 0.2812137795267959]
	TIME [epoch: 8.04 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16060903817934433		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16060903817934433 | validation: 0.31677133764135357]
	TIME [epoch: 8.05 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16598206475724675		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.16598206475724675 | validation: 0.29112971577337066]
	TIME [epoch: 8.05 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15536282674807295		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15536282674807295 | validation: 0.2801815834292209]
	TIME [epoch: 8.04 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16192552025358048		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.16192552025358048 | validation: 0.27971565585078767]
	TIME [epoch: 7.99 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519268841807593		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.1519268841807593 | validation: 0.26832663603825424]
	TIME [epoch: 8.03 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614527000866323		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1614527000866323 | validation: 0.2786081921176606]
	TIME [epoch: 8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14426286921672932		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.14426286921672932 | validation: 0.36197678005435374]
	TIME [epoch: 8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15917264195018163		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15917264195018163 | validation: 0.2771469594296958]
	TIME [epoch: 8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15041952251448412		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.15041952251448412 | validation: 0.2684040883300817]
	TIME [epoch: 8.02 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626773849780612		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1626773849780612 | validation: 0.2733070366007119]
	TIME [epoch: 8.05 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15358285292475213		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15358285292475213 | validation: 0.3188991078222332]
	TIME [epoch: 8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539271082746257		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1539271082746257 | validation: 0.2984444060384501]
	TIME [epoch: 7.99 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535917020415501		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1535917020415501 | validation: 0.2990450657462524]
	TIME [epoch: 8.04 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550201779303167		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.1550201779303167 | validation: 0.2935281705757073]
	TIME [epoch: 8.04 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14636430257312708		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.14636430257312708 | validation: 0.2908769279258583]
	TIME [epoch: 8.02 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833019939450405		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15833019939450405 | validation: 0.3085387923241588]
	TIME [epoch: 8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618636729122643		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1618636729122643 | validation: 0.3023351026431776]
	TIME [epoch: 8.04 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996928580587189		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.15996928580587189 | validation: 0.2716930670867031]
	TIME [epoch: 8.01 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577354331897541		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.1577354331897541 | validation: 0.28898457112775994]
	TIME [epoch: 8.03 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16178854300807258		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.16178854300807258 | validation: 0.30082696278877624]
	TIME [epoch: 8.02 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1565248150057484		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.1565248150057484 | validation: 0.2963918840820409]
	TIME [epoch: 8.08 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493585662861445		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.1493585662861445 | validation: 0.2775609744933425]
	TIME [epoch: 8.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17002701497465889		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.17002701497465889 | validation: 0.30262895534049294]
	TIME [epoch: 8.07 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459972601355526		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1459972601355526 | validation: 0.30642183274172347]
	TIME [epoch: 8.02 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518675735913034		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.1518675735913034 | validation: 0.29305052949254756]
	TIME [epoch: 8.07 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16316892866240812		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.16316892866240812 | validation: 0.2838170197653756]
	TIME [epoch: 8.03 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15529405618093356		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15529405618093356 | validation: 0.2919230867457326]
	TIME [epoch: 8.03 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16156544160181224		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.16156544160181224 | validation: 0.30925925546222716]
	TIME [epoch: 8.03 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038014250738325		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16038014250738325 | validation: 0.4356540389123055]
	TIME [epoch: 8.07 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1814348731091217		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.1814348731091217 | validation: 0.2646428933089727]
	TIME [epoch: 8.05 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470038719278487		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15470038719278487 | validation: 0.2756601850155555]
	TIME [epoch: 8.06 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15314485138753867		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.15314485138753867 | validation: 0.2869139302938531]
	TIME [epoch: 8.03 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16820030223959984		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.16820030223959984 | validation: 0.338716908085521]
	TIME [epoch: 8.04 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574021564883076		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.16574021564883076 | validation: 0.3169703790933184]
	TIME [epoch: 8.04 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642870256941789		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1642870256941789 | validation: 0.28949487128874707]
	TIME [epoch: 8.02 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14545323218533665		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.14545323218533665 | validation: 0.2614180218676058]
	TIME [epoch: 8.02 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15598653382258912		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.15598653382258912 | validation: 0.30715921732278223]
	TIME [epoch: 8.04 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15900777628948173		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15900777628948173 | validation: 0.271745372179292]
	TIME [epoch: 8.05 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15212927836347184		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15212927836347184 | validation: 0.2732035969030506]
	TIME [epoch: 8.03 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577068028105373		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1577068028105373 | validation: 0.2913702580155461]
	TIME [epoch: 8.03 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16306759877620283		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.16306759877620283 | validation: 0.30974009753060366]
	TIME [epoch: 8.03 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15650610321946126		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15650610321946126 | validation: 0.26918082704105445]
	TIME [epoch: 8.06 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1625949578374085		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1625949578374085 | validation: 0.29520970018965115]
	TIME [epoch: 8.03 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15567699064236823		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.15567699064236823 | validation: 0.29626453227520827]
	TIME [epoch: 8.03 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290478731354415		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.15290478731354415 | validation: 0.2861709801338494]
	TIME [epoch: 8.02 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17062216987442647		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.17062216987442647 | validation: 0.2708939156471966]
	TIME [epoch: 8.07 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15595695096727202		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15595695096727202 | validation: 0.2674266760366852]
	TIME [epoch: 8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15995710444965403		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15995710444965403 | validation: 0.2868827089126311]
	TIME [epoch: 8.03 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15076699100284616		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.15076699100284616 | validation: 0.2939041853765073]
	TIME [epoch: 8.03 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17002182620362505		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.17002182620362505 | validation: 0.289662553482316]
	TIME [epoch: 8.05 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16262915440491704		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.16262915440491704 | validation: 0.26997492587714333]
	TIME [epoch: 8.05 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16731905836465272		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.16731905836465272 | validation: 0.29647264258625194]
	TIME [epoch: 8.04 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15689657999163503		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15689657999163503 | validation: 0.3199185239938216]
	TIME [epoch: 8.05 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15877938093585273		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15877938093585273 | validation: 0.2666397084521674]
	TIME [epoch: 8.04 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15624414254253485		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15624414254253485 | validation: 0.27212559487904814]
	TIME [epoch: 8.03 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15113746877627374		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15113746877627374 | validation: 0.2915932172878908]
	TIME [epoch: 8.05 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552588805214991		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.1552588805214991 | validation: 0.2862746435015847]
	TIME [epoch: 8.06 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587610451433429		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.1587610451433429 | validation: 0.28557169154906753]
	TIME [epoch: 8.06 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15751715043099884		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15751715043099884 | validation: 0.30440981499324693]
	TIME [epoch: 8.07 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15432103458210933		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15432103458210933 | validation: 0.28843543372770525]
	TIME [epoch: 8.04 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15562997947870771		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15562997947870771 | validation: 0.3008196004811261]
	TIME [epoch: 8.04 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15403040892270356		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15403040892270356 | validation: 0.30376937367953794]
	TIME [epoch: 8.04 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15312738216035507		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15312738216035507 | validation: 0.29636399663406343]
	TIME [epoch: 8.05 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16016559511975392		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.16016559511975392 | validation: 0.27218916181617187]
	TIME [epoch: 8.04 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225584845425342		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.16225584845425342 | validation: 0.31918498232306636]
	TIME [epoch: 8.05 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15352429150378316		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15352429150378316 | validation: 0.29512799806650974]
	TIME [epoch: 8.05 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14815491305044615		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.14815491305044615 | validation: 0.26402791512809615]
	TIME [epoch: 8.06 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609269555676881		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.1609269555676881 | validation: 0.29942154167153673]
	TIME [epoch: 8.04 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15666535490501016		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15666535490501016 | validation: 0.3183590090034135]
	TIME [epoch: 8.04 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672015668795094		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.1672015668795094 | validation: 0.2687876310784254]
	TIME [epoch: 8.04 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14648164469491715		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.14648164469491715 | validation: 0.29384414651839563]
	TIME [epoch: 8.05 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15774918474166943		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15774918474166943 | validation: 0.2831330535688824]
	TIME [epoch: 8.04 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550343755260029		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.1550343755260029 | validation: 0.2803372349241019]
	TIME [epoch: 8.04 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15614337280138096		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15614337280138096 | validation: 0.2612390873232426]
	TIME [epoch: 8.08 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512467417487349		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1512467417487349 | validation: 0.2896056937850844]
	TIME [epoch: 8.06 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547522179597165		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.1547522179597165 | validation: 0.31325726183696445]
	TIME [epoch: 8.06 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1573552383280657		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1573552383280657 | validation: 0.3346153903895829]
	TIME [epoch: 8.06 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16177178694195854		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.16177178694195854 | validation: 0.2758648626835752]
	TIME [epoch: 8.05 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15786643515886012		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15786643515886012 | validation: 0.266684816976205]
	TIME [epoch: 8.04 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15121412860183564		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15121412860183564 | validation: 0.3126428627551629]
	TIME [epoch: 8.05 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15167771397395957		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15167771397395957 | validation: 0.28306819537226685]
	TIME [epoch: 8.05 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661288445613722		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.1661288445613722 | validation: 0.26658724591314026]
	TIME [epoch: 8.04 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743663547461209		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1743663547461209 | validation: 0.2640931079745905]
	TIME [epoch: 8.04 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14834517404876385		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.14834517404876385 | validation: 0.29418090607426084]
	TIME [epoch: 8.04 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16197394900767828		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.16197394900767828 | validation: 0.27736227096882105]
	TIME [epoch: 8.03 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14542590839164085		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.14542590839164085 | validation: 0.289808857163216]
	TIME [epoch: 8.05 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548104468377413		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.1548104468377413 | validation: 0.2655487464518892]
	TIME [epoch: 8.05 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15092146606466494		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15092146606466494 | validation: 0.27660005455373804]
	TIME [epoch: 8.07 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14079120148758698		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.14079120148758698 | validation: 0.29088588815106864]
	TIME [epoch: 8.06 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14618616299353718		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.14618616299353718 | validation: 0.2600600279282775]
	TIME [epoch: 8.06 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16289156282593165		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16289156282593165 | validation: 0.2677129830434476]
	TIME [epoch: 8.05 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14835176349702373		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.14835176349702373 | validation: 0.27886657112808033]
	TIME [epoch: 8.06 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15238602008739605		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15238602008739605 | validation: 0.25593217697722104]
	TIME [epoch: 8.05 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15955339953658165		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15955339953658165 | validation: 0.2968406603983039]
	TIME [epoch: 8.05 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600359704529215		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1600359704529215 | validation: 0.33995581651590756]
	TIME [epoch: 8.05 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189247206069193		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.16189247206069193 | validation: 0.2829186971403891]
	TIME [epoch: 8.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1453083016576892		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.1453083016576892 | validation: 0.2964728695972668]
	TIME [epoch: 8.05 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559752496586721		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.1559752496586721 | validation: 0.3209524017578534]
	TIME [epoch: 8.03 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14956376437423777		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14956376437423777 | validation: 0.2844043527939232]
	TIME [epoch: 8.05 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290098500714006		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15290098500714006 | validation: 0.2804550052214168]
	TIME [epoch: 8.04 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15189955415156514		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15189955415156514 | validation: 0.29605203329147695]
	TIME [epoch: 8.06 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15329271620877105		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15329271620877105 | validation: 0.29262662298644027]
	TIME [epoch: 8.05 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15971306665245405		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.15971306665245405 | validation: 0.2785484721197138]
	TIME [epoch: 8.04 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15152241244466874		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15152241244466874 | validation: 0.26904744586103774]
	TIME [epoch: 8.03 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14553519667857234		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.14553519667857234 | validation: 0.270977450129277]
	TIME [epoch: 8.07 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15817056443025332		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15817056443025332 | validation: 0.2798979057889272]
	TIME [epoch: 8.06 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14324926026885274		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.14324926026885274 | validation: 0.27894003435736764]
	TIME [epoch: 8.04 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16257827422901022		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.16257827422901022 | validation: 0.28570265589829913]
	TIME [epoch: 8.06 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1446119790475397		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.1446119790475397 | validation: 0.2846674725702249]
	TIME [epoch: 8.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15796767396803474		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15796767396803474 | validation: 0.27265798798873103]
	TIME [epoch: 8.05 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15986752668824084		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15986752668824084 | validation: 0.29715633810863207]
	TIME [epoch: 8.05 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15625912417828988		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15625912417828988 | validation: 0.30228502289197656]
	TIME [epoch: 8.03 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15322376618757122		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.15322376618757122 | validation: 0.268502951344879]
	TIME [epoch: 8.06 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611098983337819		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.1611098983337819 | validation: 0.2836786420053069]
	TIME [epoch: 8.03 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15123216810032242		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15123216810032242 | validation: 0.29758550797073535]
	TIME [epoch: 8.03 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16046786046588032		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.16046786046588032 | validation: 0.30420413422847975]
	TIME [epoch: 41.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16972876871199763		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.16972876871199763 | validation: 0.2731125269229916]
	TIME [epoch: 17.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15593629359037986		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15593629359037986 | validation: 0.2916456456073116]
	TIME [epoch: 17.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14771626554554307		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.14771626554554307 | validation: 0.27865968672682306]
	TIME [epoch: 17.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149787349476548		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.149787349476548 | validation: 0.2783565380378087]
	TIME [epoch: 17.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674404691965836		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.1674404691965836 | validation: 0.31200906018585295]
	TIME [epoch: 17.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16201890198347618		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.16201890198347618 | validation: 0.3228446728610164]
	TIME [epoch: 17.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14785742934508495		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.14785742934508495 | validation: 0.28560032696405835]
	TIME [epoch: 17.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15158976857855727		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15158976857855727 | validation: 0.283542209086864]
	TIME [epoch: 17.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15523714499630226		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15523714499630226 | validation: 0.28513408072075574]
	TIME [epoch: 17.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15523879325054088		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.15523879325054088 | validation: 0.27854353316364305]
	TIME [epoch: 17.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15834053096549622		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15834053096549622 | validation: 0.3130754335305501]
	TIME [epoch: 17.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15776006664228387		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15776006664228387 | validation: 0.30924821918300666]
	TIME [epoch: 17.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14868414022177504		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.14868414022177504 | validation: 0.278446111112797]
	TIME [epoch: 17.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209275966356267		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.15209275966356267 | validation: 0.2889870181587252]
	TIME [epoch: 17.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14896308008822712		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14896308008822712 | validation: 0.2824272047839733]
	TIME [epoch: 17.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14968649036061513		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.14968649036061513 | validation: 0.26012787726003617]
	TIME [epoch: 17.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549389836117256		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.1549389836117256 | validation: 0.27661844244017264]
	TIME [epoch: 17.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15992703825683788		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15992703825683788 | validation: 0.2917344307325549]
	TIME [epoch: 17.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13905489008948257		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.13905489008948257 | validation: 0.27702325997155536]
	TIME [epoch: 17.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.144617890530314		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.144617890530314 | validation: 0.26029404591098965]
	TIME [epoch: 17.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14607245114984688		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.14607245114984688 | validation: 0.28769101727258317]
	TIME [epoch: 17.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15282839314840369		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15282839314840369 | validation: 0.2928572347515461]
	TIME [epoch: 17.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209586800269537		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15209586800269537 | validation: 0.3197955678117648]
	TIME [epoch: 17.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1450093456406405		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.1450093456406405 | validation: 0.3007465360698531]
	TIME [epoch: 17.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613047214598874		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.1613047214598874 | validation: 0.26759309481857074]
	TIME [epoch: 17.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038132450759138		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.16038132450759138 | validation: 0.2847910228636578]
	TIME [epoch: 17.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15207396026457634		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15207396026457634 | validation: 0.2777763085123188]
	TIME [epoch: 17.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16325234767330338		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.16325234767330338 | validation: 0.2981330896060384]
	TIME [epoch: 17.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602696704985234		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.1602696704985234 | validation: 0.2663569643278644]
	TIME [epoch: 17.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15391279975207478		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.15391279975207478 | validation: 0.289129431544004]
	TIME [epoch: 17.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15610615097295033		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15610615097295033 | validation: 0.2801898095972343]
	TIME [epoch: 17.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15519575804203795		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15519575804203795 | validation: 0.28973444704735185]
	TIME [epoch: 17.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15112900875939972		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15112900875939972 | validation: 0.28161346775241597]
	TIME [epoch: 17.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503894544757375		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.1503894544757375 | validation: 0.2802151575986821]
	TIME [epoch: 17.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470330400820367		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15470330400820367 | validation: 0.27545952653489075]
	TIME [epoch: 17.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14430797185856353		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.14430797185856353 | validation: 0.2692611459200711]
	TIME [epoch: 17.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16327687517261152		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.16327687517261152 | validation: 0.27535200710618846]
	TIME [epoch: 17.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16535815001789342		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.16535815001789342 | validation: 0.2943384380103461]
	TIME [epoch: 17.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571432903395289		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1571432903395289 | validation: 0.3160319954772272]
	TIME [epoch: 17.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15578497977144276		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.15578497977144276 | validation: 0.27992231232812526]
	TIME [epoch: 17.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14584882069422558		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.14584882069422558 | validation: 0.2582040493293891]
	TIME [epoch: 17.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914858893047387		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.15914858893047387 | validation: 0.2860501228353793]
	TIME [epoch: 17.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505562334844393		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1505562334844393 | validation: 0.2794440500289248]
	TIME [epoch: 17.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16128521590604417		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.16128521590604417 | validation: 0.3065103707510934]
	TIME [epoch: 17.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15208572119181088		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.15208572119181088 | validation: 0.28599782388753875]
	TIME [epoch: 17.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508103185474094		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.1508103185474094 | validation: 0.317676844576219]
	TIME [epoch: 17.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14402987085085434		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.14402987085085434 | validation: 0.28941038483063286]
	TIME [epoch: 17.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513608005815669		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.1513608005815669 | validation: 0.25407237645978137]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16162570883587407		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.16162570883587407 | validation: 0.27762868385509437]
	TIME [epoch: 17.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871817502432097		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.14871817502432097 | validation: 0.27682526017042897]
	TIME [epoch: 17.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1470222194122191		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1470222194122191 | validation: 0.2746364096687244]
	TIME [epoch: 17.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508091734071818		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.1508091734071818 | validation: 0.290710707717537]
	TIME [epoch: 17.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15048396611725087		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.15048396611725087 | validation: 0.29023590324379206]
	TIME [epoch: 17.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1441465571674611		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.1441465571674611 | validation: 0.2802506158308797]
	TIME [epoch: 17.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1461800626833098		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.1461800626833098 | validation: 0.2894119696431631]
	TIME [epoch: 17.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17137714055863212		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.17137714055863212 | validation: 0.28902995514016305]
	TIME [epoch: 17.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16546696227995913		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.16546696227995913 | validation: 0.2814371774305858]
	TIME [epoch: 17.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527434683412062		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1527434683412062 | validation: 0.2770341668038971]
	TIME [epoch: 17.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14152008638227512		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.14152008638227512 | validation: 0.28390520723401275]
	TIME [epoch: 17.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14450382049025215		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.14450382049025215 | validation: 0.30047845815867363]
	TIME [epoch: 17.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15336395276119436		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.15336395276119436 | validation: 0.26966983614852225]
	TIME [epoch: 17.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15031467516297473		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15031467516297473 | validation: 0.272573096951632]
	TIME [epoch: 17.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529058944922678		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1529058944922678 | validation: 0.27263999858047433]
	TIME [epoch: 17.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1419929176304386		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.1419929176304386 | validation: 0.27928623632960403]
	TIME [epoch: 17.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14006626466206457		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.14006626466206457 | validation: 0.2944996132883694]
	TIME [epoch: 17.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152683198242678		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.152683198242678 | validation: 0.27174761495603283]
	TIME [epoch: 17.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14752140392263352		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.14752140392263352 | validation: 0.2736752393869544]
	TIME [epoch: 17.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15132037788873437		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.15132037788873437 | validation: 0.2731418711237987]
	TIME [epoch: 17.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604330621277154		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.1604330621277154 | validation: 0.29096141024811406]
	TIME [epoch: 17.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15301184638871282		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15301184638871282 | validation: 0.28716709850222055]
	TIME [epoch: 17.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1501565655974628		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1501565655974628 | validation: 0.28833992024255783]
	TIME [epoch: 17.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15182453724309047		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.15182453724309047 | validation: 0.2950323303490643]
	TIME [epoch: 17.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1579485392736129		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.1579485392736129 | validation: 0.29097660688501725]
	TIME [epoch: 17.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14748483358284314		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.14748483358284314 | validation: 0.27620354274175757]
	TIME [epoch: 17.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15529979088485055		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15529979088485055 | validation: 0.27349151509115643]
	TIME [epoch: 17.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14635487110819675		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.14635487110819675 | validation: 0.2928291934137799]
	TIME [epoch: 17.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15203252874889048		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.15203252874889048 | validation: 0.28927310994403727]
	TIME [epoch: 17.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496970614838064		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.1496970614838064 | validation: 0.2885261915845398]
	TIME [epoch: 17.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539040418804371		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1539040418804371 | validation: 0.2815312425972423]
	TIME [epoch: 17.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14119104751626116		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.14119104751626116 | validation: 0.28189857693890696]
	TIME [epoch: 17.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15143640451039692		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.15143640451039692 | validation: 0.2600204549756045]
	TIME [epoch: 17.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14524042851374408		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.14524042851374408 | validation: 0.2701206451958655]
	TIME [epoch: 17.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15269240448165056		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15269240448165056 | validation: 0.29316747811385485]
	TIME [epoch: 17.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16053296338702366		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.16053296338702366 | validation: 0.2961185730450398]
	TIME [epoch: 17.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14889097484982533		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.14889097484982533 | validation: 0.286019913024836]
	TIME [epoch: 17.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15071885137090693		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.15071885137090693 | validation: 0.26846396580617415]
	TIME [epoch: 17.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15995856579495052		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.15995856579495052 | validation: 0.28660402789215134]
	TIME [epoch: 17.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091623395975763		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.16091623395975763 | validation: 0.3109498618347967]
	TIME [epoch: 17.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591821372732451		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.1591821372732451 | validation: 0.3006213328587059]
	TIME [epoch: 17.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15984219906851269		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.15984219906851269 | validation: 0.28367278484023667]
	TIME [epoch: 17.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153067545111976		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.153067545111976 | validation: 0.28032344500606365]
	TIME [epoch: 17.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15563969792488216		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15563969792488216 | validation: 0.2860858656693953]
	TIME [epoch: 17.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496936140141941		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.1496936140141941 | validation: 0.2868603139745941]
	TIME [epoch: 17.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335553764924664		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.15335553764924664 | validation: 0.2728426295643578]
	TIME [epoch: 17.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15991272103346701		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15991272103346701 | validation: 0.26439181887820784]
	TIME [epoch: 17.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14986825893342676		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.14986825893342676 | validation: 0.2923045550216691]
	TIME [epoch: 17.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14815632078663124		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.14815632078663124 | validation: 0.30686456396106543]
	TIME [epoch: 17.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15637760038135057		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.15637760038135057 | validation: 0.2715410985433331]
	TIME [epoch: 17.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15949204508336695		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.15949204508336695 | validation: 0.2636440748027268]
	TIME [epoch: 17.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1462602452271362		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1462602452271362 | validation: 0.289603992913979]
	TIME [epoch: 17.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15340803940014697		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.15340803940014697 | validation: 0.30879122858564956]
	TIME [epoch: 17.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15412310845759886		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15412310845759886 | validation: 0.2728090416490469]
	TIME [epoch: 17.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14144082522030335		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14144082522030335 | validation: 0.3128725590310829]
	TIME [epoch: 17.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16660869226731184		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.16660869226731184 | validation: 0.2759327107183353]
	TIME [epoch: 17.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525231883325067		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1525231883325067 | validation: 0.2802801112868426]
	TIME [epoch: 17.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529930722980684		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1529930722980684 | validation: 0.27453219386901734]
	TIME [epoch: 17.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14971512105306028		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14971512105306028 | validation: 0.28945529081392357]
	TIME [epoch: 17.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15416645372026228		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15416645372026228 | validation: 0.28065669770518664]
	TIME [epoch: 17.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15557453819097508		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.15557453819097508 | validation: 0.2770148703085795]
	TIME [epoch: 17.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14942952030647252		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.14942952030647252 | validation: 0.27043456781273634]
	TIME [epoch: 17.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15439474519409777		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15439474519409777 | validation: 0.272932363718821]
	TIME [epoch: 17.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586511902153771		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.1586511902153771 | validation: 0.32318062836044054]
	TIME [epoch: 17.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14303794278595489		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.14303794278595489 | validation: 0.2834066110490328]
	TIME [epoch: 17.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1403283130152651		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.1403283130152651 | validation: 0.2883187782710979]
	TIME [epoch: 17.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987876676143141		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.14987876676143141 | validation: 0.28741916305958803]
	TIME [epoch: 17.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15738050327243827		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15738050327243827 | validation: 0.2524708832752043]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15453937131588982		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15453937131588982 | validation: 0.27622340123683803]
	TIME [epoch: 17.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13845110008129816		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.13845110008129816 | validation: 0.2895600469042771]
	TIME [epoch: 17.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14629404208780747		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14629404208780747 | validation: 0.28953584813236816]
	TIME [epoch: 17.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15789437491552433		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.15789437491552433 | validation: 0.29942680152307644]
	TIME [epoch: 17.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14712128618912781		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.14712128618912781 | validation: 0.29240723456999845]
	TIME [epoch: 17.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14836502419859304		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.14836502419859304 | validation: 0.2788046653860846]
	TIME [epoch: 17.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14229751243974623		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14229751243974623 | validation: 0.30001743713426854]
	TIME [epoch: 17.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938021864075485		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.14938021864075485 | validation: 0.2750653989408786]
	TIME [epoch: 17.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14174020260741582		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.14174020260741582 | validation: 0.2861048491067611]
	TIME [epoch: 17.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14691088941092106		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.14691088941092106 | validation: 0.26306903887312066]
	TIME [epoch: 17.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15270657548989602		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15270657548989602 | validation: 0.28094636124620154]
	TIME [epoch: 17.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16135544875410926		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.16135544875410926 | validation: 0.2747956927810418]
	TIME [epoch: 17.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14308393351816684		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.14308393351816684 | validation: 0.2829999693215335]
	TIME [epoch: 17.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14333132386658504		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.14333132386658504 | validation: 0.2874838375190764]
	TIME [epoch: 17.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14170398441754015		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.14170398441754015 | validation: 0.26263756911086766]
	TIME [epoch: 17.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14137809731890735		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.14137809731890735 | validation: 0.28973610506653996]
	TIME [epoch: 17.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15277939865949647		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.15277939865949647 | validation: 0.2753886981208448]
	TIME [epoch: 17.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16135737273577672		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.16135737273577672 | validation: 0.2740888980280839]
	TIME [epoch: 17.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15603403579598502		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15603403579598502 | validation: 0.28331487814635153]
	TIME [epoch: 17.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14754320227414455		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.14754320227414455 | validation: 0.2877023756604797]
	TIME [epoch: 17.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14905459453153577		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.14905459453153577 | validation: 0.2770872750916775]
	TIME [epoch: 17.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475851482539155		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.1475851482539155 | validation: 0.30274356372359007]
	TIME [epoch: 17.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15642917587781047		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15642917587781047 | validation: 0.2807796787430218]
	TIME [epoch: 17.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15810970445494002		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.15810970445494002 | validation: 0.2546308686132269]
	TIME [epoch: 17.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14366913302264078		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.14366913302264078 | validation: 0.2706323036914338]
	TIME [epoch: 17.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15807145583507567		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.15807145583507567 | validation: 0.28849401516525885]
	TIME [epoch: 17.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15308870062458724		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15308870062458724 | validation: 0.2771949605028829]
	TIME [epoch: 17.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14518072872912227		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.14518072872912227 | validation: 0.2914648657410478]
	TIME [epoch: 17.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14950145495322026		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.14950145495322026 | validation: 0.28396567575637144]
	TIME [epoch: 17.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14997584832160937		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.14997584832160937 | validation: 0.2788763080592008]
	TIME [epoch: 17.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13807701166253097		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.13807701166253097 | validation: 0.27399073864541534]
	TIME [epoch: 17.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585679659939252		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.1585679659939252 | validation: 0.26912296529132995]
	TIME [epoch: 17.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1449999622197507		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.1449999622197507 | validation: 0.2625472619680293]
	TIME [epoch: 17.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14273786132017827		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.14273786132017827 | validation: 0.2801525577212621]
	TIME [epoch: 17.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15185040609219327		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15185040609219327 | validation: 0.2796717410946998]
	TIME [epoch: 17.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14263650242794443		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.14263650242794443 | validation: 0.27850139389338346]
	TIME [epoch: 17.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14578037750114262		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.14578037750114262 | validation: 0.26444022954329505]
	TIME [epoch: 17.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14080550251613536		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.14080550251613536 | validation: 0.2931859516013442]
	TIME [epoch: 17.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14665752174311728		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.14665752174311728 | validation: 0.29892128961835673]
	TIME [epoch: 17.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1406354555080232		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.1406354555080232 | validation: 0.2865211518637048]
	TIME [epoch: 17.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13827875461130987		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.13827875461130987 | validation: 0.2803288316974871]
	TIME [epoch: 17.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290957061403615		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.15290957061403615 | validation: 0.2848719798413612]
	TIME [epoch: 17.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15309886584097226		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.15309886584097226 | validation: 0.2638676985461933]
	TIME [epoch: 17.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14612561532488375		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.14612561532488375 | validation: 0.27796385656550227]
	TIME [epoch: 17.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1371590506851393		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.1371590506851393 | validation: 0.25126383819049614]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15668771768472567		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.15668771768472567 | validation: 0.28134272603191895]
	TIME [epoch: 17.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15188609060188396		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15188609060188396 | validation: 0.2696816993360482]
	TIME [epoch: 17.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615984300832453		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.1615984300832453 | validation: 0.2661117128508061]
	TIME [epoch: 17.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534786321590358		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.1534786321590358 | validation: 0.2626497114102797]
	TIME [epoch: 17.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14766414662143396		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.14766414662143396 | validation: 0.2798633671017794]
	TIME [epoch: 17.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15759492674468092		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.15759492674468092 | validation: 0.2788647137160679]
	TIME [epoch: 17.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13590864290393573		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.13590864290393573 | validation: 0.2908860812369934]
	TIME [epoch: 17.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15431837709640112		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.15431837709640112 | validation: 0.27992312231681493]
	TIME [epoch: 17.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15762976496291992		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.15762976496291992 | validation: 0.26864104089102236]
	TIME [epoch: 17.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1509815394009905		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1509815394009905 | validation: 0.25739201780520077]
	TIME [epoch: 17.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15802869217396154		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.15802869217396154 | validation: 0.27515992167588643]
	TIME [epoch: 17.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14167531177417345		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.14167531177417345 | validation: 0.2712133767443003]
	TIME [epoch: 17.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14873221692345642		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.14873221692345642 | validation: 0.2898962055409289]
	TIME [epoch: 17.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14267438214064448		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14267438214064448 | validation: 0.2658900687486966]
	TIME [epoch: 17.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14522107366624934		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.14522107366624934 | validation: 0.2794818834863352]
	TIME [epoch: 17.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14386759109991673		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.14386759109991673 | validation: 0.27164075119976594]
	TIME [epoch: 17.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16201981635990859		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.16201981635990859 | validation: 0.25890936756447236]
	TIME [epoch: 17.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15113999356934693		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.15113999356934693 | validation: 0.28483995018101493]
	TIME [epoch: 17.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14879974420111655		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.14879974420111655 | validation: 0.2920909669573345]
	TIME [epoch: 17.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507229839106165		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.1507229839106165 | validation: 0.2768609432591512]
	TIME [epoch: 17.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14539659248029985		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.14539659248029985 | validation: 0.2923928036408349]
	TIME [epoch: 17.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15368510797534704		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.15368510797534704 | validation: 0.28415974912928077]
	TIME [epoch: 17.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574613129215482		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.16574613129215482 | validation: 0.2853980870314162]
	TIME [epoch: 17.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1393630363295658		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.1393630363295658 | validation: 0.2822158588122064]
	TIME [epoch: 17.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886431938427927		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.14886431938427927 | validation: 0.28677650168925806]
	TIME [epoch: 17.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15030392355476727		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.15030392355476727 | validation: 0.2590200348006467]
	TIME [epoch: 17.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15084585477505402		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.15084585477505402 | validation: 0.27903792283379847]
	TIME [epoch: 17.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15717178918404145		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.15717178918404145 | validation: 0.28614405898322615]
	TIME [epoch: 17.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14116524670687874		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.14116524670687874 | validation: 0.2824326336759415]
	TIME [epoch: 17.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15780113484868585		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.15780113484868585 | validation: 0.2704308424118609]
	TIME [epoch: 17.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14172506739101526		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.14172506739101526 | validation: 0.2742049814075598]
	TIME [epoch: 17.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.139987862062564		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.139987862062564 | validation: 0.28299970253064044]
	TIME [epoch: 17.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443147602264648		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.1443147602264648 | validation: 0.27896093289534896]
	TIME [epoch: 17.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1490043280658051		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1490043280658051 | validation: 0.30234888994012626]
	TIME [epoch: 17.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14621220255272038		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.14621220255272038 | validation: 0.2814890979721514]
	TIME [epoch: 17.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1464238944511705		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.1464238944511705 | validation: 0.2879447490755987]
	TIME [epoch: 17.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15388192700720593		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.15388192700720593 | validation: 0.27593629796681757]
	TIME [epoch: 17.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15603122408447712		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.15603122408447712 | validation: 0.28239968719459485]
	TIME [epoch: 17.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14832928364390757		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.14832928364390757 | validation: 0.2927182943904457]
	TIME [epoch: 17.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1579941387971548		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.1579941387971548 | validation: 0.30028234237119494]
	TIME [epoch: 17.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514421082228748		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.1514421082228748 | validation: 0.27385343480151353]
	TIME [epoch: 17.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14930828277451824		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.14930828277451824 | validation: 0.28700759781265617]
	TIME [epoch: 17.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14828461269226917		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.14828461269226917 | validation: 0.2816775587798292]
	TIME [epoch: 17.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15370623055775723		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.15370623055775723 | validation: 0.2712356851483036]
	TIME [epoch: 17.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275623104816635		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.15275623104816635 | validation: 0.28193001016667085]
	TIME [epoch: 17.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14964550878032057		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.14964550878032057 | validation: 0.278956329787142]
	TIME [epoch: 17.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15217253500249456		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.15217253500249456 | validation: 0.27440578047370306]
	TIME [epoch: 17.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15544386389196307		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.15544386389196307 | validation: 0.27355516444622036]
	TIME [epoch: 17.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15186357571137685		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.15186357571137685 | validation: 0.2597982397626746]
	TIME [epoch: 17.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15894101797140286		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.15894101797140286 | validation: 0.2775699930945445]
	TIME [epoch: 17.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14352560702269831		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.14352560702269831 | validation: 0.27915207606348436]
	TIME [epoch: 17.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14089066099680744		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.14089066099680744 | validation: 0.28421694852156903]
	TIME [epoch: 17.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14363764680371943		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.14363764680371943 | validation: 0.2756932181433997]
	TIME [epoch: 17.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539617466845965		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.1539617466845965 | validation: 0.2899923287514637]
	TIME [epoch: 17.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15562257617271547		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.15562257617271547 | validation: 0.272878579195518]
	TIME [epoch: 17.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15668381461461217		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.15668381461461217 | validation: 0.2678458142311454]
	TIME [epoch: 17.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360217539599916		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.15360217539599916 | validation: 0.28628794582323647]
	TIME [epoch: 17.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14711223434826712		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.14711223434826712 | validation: 0.2899637345785938]
	TIME [epoch: 17.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14587205264701147		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.14587205264701147 | validation: 0.28195315889846473]
	TIME [epoch: 17.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500013201491564		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.1500013201491564 | validation: 0.27541499619781307]
	TIME [epoch: 17.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547435806201615		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.1547435806201615 | validation: 0.2900291061827472]
	TIME [epoch: 17.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1498659979448805		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1498659979448805 | validation: 0.2793555679062544]
	TIME [epoch: 17.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14910744508353485		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.14910744508353485 | validation: 0.26934413750999847]
	TIME [epoch: 17.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14878520155914204		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.14878520155914204 | validation: 0.28123459664127903]
	TIME [epoch: 17.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14628165247638109		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.14628165247638109 | validation: 0.2930015684576138]
	TIME [epoch: 17.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15264930665542523		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.15264930665542523 | validation: 0.2749098762863665]
	TIME [epoch: 17.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1383879817024778		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.1383879817024778 | validation: 0.26997695262963173]
	TIME [epoch: 17.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14317660357712672		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.14317660357712672 | validation: 0.292239658208612]
	TIME [epoch: 17.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15671091893128392		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.15671091893128392 | validation: 0.28891834225581153]
	TIME [epoch: 17.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15979377280812265		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.15979377280812265 | validation: 0.27817323008411615]
	TIME [epoch: 17.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14339354106255406		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.14339354106255406 | validation: 0.28497355472458064]
	TIME [epoch: 17.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14116444462020866		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.14116444462020866 | validation: 0.28380481848155736]
	TIME [epoch: 17.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13709009318707133		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.13709009318707133 | validation: 0.2657960913432569]
	TIME [epoch: 17.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14465624360506446		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.14465624360506446 | validation: 0.28796089985015916]
	TIME [epoch: 17.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14793077573307195		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.14793077573307195 | validation: 0.2784067773932192]
	TIME [epoch: 17.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14917180129455376		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.14917180129455376 | validation: 0.28304800580304634]
	TIME [epoch: 17.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14657937256195724		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.14657937256195724 | validation: 0.27394673872208236]
	TIME [epoch: 17.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14678166278710086		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.14678166278710086 | validation: 0.28182054202849877]
	TIME [epoch: 17.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15246555012312268		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.15246555012312268 | validation: 0.27615761410743445]
	TIME [epoch: 17.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15172236503618675		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.15172236503618675 | validation: 0.2624277698749972]
	TIME [epoch: 17.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15376866500249609		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.15376866500249609 | validation: 0.30612577864852175]
	TIME [epoch: 17.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1436552347545453		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.1436552347545453 | validation: 0.2783379657643637]
	TIME [epoch: 17.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15207833661682818		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.15207833661682818 | validation: 0.2884161964675011]
	TIME [epoch: 17.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15015499972363322		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.15015499972363322 | validation: 0.2690608302490057]
	TIME [epoch: 17.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489287465659091		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.1489287465659091 | validation: 0.27252940316654634]
	TIME [epoch: 17.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15182979434783164		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.15182979434783164 | validation: 0.2945237771198571]
	TIME [epoch: 17.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14004339920395698		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.14004339920395698 | validation: 0.29440216454124407]
	TIME [epoch: 17.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15106096089946558		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.15106096089946558 | validation: 0.26395350873936163]
	TIME [epoch: 17.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.158563781020546		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.158563781020546 | validation: 0.2784054944175082]
	TIME [epoch: 17.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14297171242013046		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14297171242013046 | validation: 0.28788439749766415]
	TIME [epoch: 17.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14642981978351036		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.14642981978351036 | validation: 0.28623458985904454]
	TIME [epoch: 17.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15042312532038238		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.15042312532038238 | validation: 0.27728988757756595]
	TIME [epoch: 17.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15182957150048648		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.15182957150048648 | validation: 0.28817013165992916]
	TIME [epoch: 17.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13679403523604441		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.13679403523604441 | validation: 0.27108512799194573]
	TIME [epoch: 17.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15159090096745337		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.15159090096745337 | validation: 0.2694436341769736]
	TIME [epoch: 17.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1465651494651608		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.1465651494651608 | validation: 0.2738812793245566]
	TIME [epoch: 17.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14623092433338059		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.14623092433338059 | validation: 0.28374945204075686]
	TIME [epoch: 17.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14151967239449315		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.14151967239449315 | validation: 0.2829664516599617]
	TIME [epoch: 17.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938656659877975		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.14938656659877975 | validation: 0.2813591706092886]
	TIME [epoch: 17.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382975873177465		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.15382975873177465 | validation: 0.26962802876437697]
	TIME [epoch: 17.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553037257485227		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.1553037257485227 | validation: 0.2658556601691278]
	TIME [epoch: 17.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15081956816825767		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.15081956816825767 | validation: 0.27048184544445]
	TIME [epoch: 17.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459745810508312		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.1459745810508312 | validation: 0.30590008562737353]
	TIME [epoch: 17.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14921102509762382		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.14921102509762382 | validation: 0.2788097508594315]
	TIME [epoch: 17.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15094915471250664		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.15094915471250664 | validation: 0.26684330644116383]
	TIME [epoch: 17.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1479042059321572		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.1479042059321572 | validation: 0.28761905767433715]
	TIME [epoch: 17.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1467937398934748		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.1467937398934748 | validation: 0.29955085340296456]
	TIME [epoch: 17.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14988753755937498		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.14988753755937498 | validation: 0.28292650089467253]
	TIME [epoch: 17.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254477423922677		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.15254477423922677 | validation: 0.2750128857956722]
	TIME [epoch: 17.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486879252137211		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1486879252137211 | validation: 0.2776369171792663]
	TIME [epoch: 17.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13675885474702615		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.13675885474702615 | validation: 0.288415220299469]
	TIME [epoch: 17.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1491810422607277		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.1491810422607277 | validation: 0.29650707780083896]
	TIME [epoch: 17.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1440942476120839		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.1440942476120839 | validation: 0.2786597042309491]
	TIME [epoch: 17.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14394450924918317		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.14394450924918317 | validation: 0.2739370025744855]
	TIME [epoch: 17.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443983564261339		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.1443983564261339 | validation: 0.27702064505693313]
	TIME [epoch: 17.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14396917064594428		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.14396917064594428 | validation: 0.2784546162804798]
	TIME [epoch: 17.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13762885415991993		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.13762885415991993 | validation: 0.29697363474055055]
	TIME [epoch: 17.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.140554194838095		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.140554194838095 | validation: 0.2893271769324307]
	TIME [epoch: 17.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14418073134143933		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.14418073134143933 | validation: 0.3097393885955981]
	TIME [epoch: 17.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1426631046403436		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.1426631046403436 | validation: 0.2663984092569519]
	TIME [epoch: 17.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516199289089461		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.1516199289089461 | validation: 0.28498467419437723]
	TIME [epoch: 17.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14702285250918762		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.14702285250918762 | validation: 0.28041707637962915]
	TIME [epoch: 17.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488880000948575		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.1488880000948575 | validation: 0.28221238620294764]
	TIME [epoch: 17.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14718269205864878		[learning rate: 0.00036793]
	Learning Rate: 0.000367933
	LOSS [training: 0.14718269205864878 | validation: 0.2783005298133559]
	TIME [epoch: 17.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14774195660889952		[learning rate: 0.00036631]
	Learning Rate: 0.000366308
	LOSS [training: 0.14774195660889952 | validation: 0.2902600676004619]
	TIME [epoch: 17.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14213358512285543		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.14213358512285543 | validation: 0.27800657668203815]
	TIME [epoch: 17.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15167880973996567		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.15167880973996567 | validation: 0.2841779525273013]
	TIME [epoch: 17.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15017540003339286		[learning rate: 0.00036147]
	Learning Rate: 0.000361474
	LOSS [training: 0.15017540003339286 | validation: 0.2805320622883783]
	TIME [epoch: 17.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149308076581801		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 0.149308076581801 | validation: 0.29521808209855793]
	TIME [epoch: 17.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14487917163893504		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.14487917163893504 | validation: 0.2842560406977764]
	TIME [epoch: 17.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14584023433196172		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.14584023433196172 | validation: 0.29569294815493335]
	TIME [epoch: 17.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1434269754039272		[learning rate: 0.00035513]
	Learning Rate: 0.000355128
	LOSS [training: 0.1434269754039272 | validation: 0.27513761781383317]
	TIME [epoch: 17.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15463526210514283		[learning rate: 0.00035356]
	Learning Rate: 0.000353559
	LOSS [training: 0.15463526210514283 | validation: 0.285158440741115]
	TIME [epoch: 17.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1340071588655113		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1340071588655113 | validation: 0.270734676642569]
	TIME [epoch: 17.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871617315321833		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.14871617315321833 | validation: 0.2901548864496064]
	TIME [epoch: 17.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14091640920481727		[learning rate: 0.00034889]
	Learning Rate: 0.000348893
	LOSS [training: 0.14091640920481727 | validation: 0.2804667412179332]
	TIME [epoch: 17.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14402593169019287		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.14402593169019287 | validation: 0.2797229562086516]
	TIME [epoch: 17.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526623840560163		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.1526623840560163 | validation: 0.28683505476205595]
	TIME [epoch: 17.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239217437869967		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.15239217437869967 | validation: 0.27381294797543204]
	TIME [epoch: 17.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475284120657397		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.1475284120657397 | validation: 0.2707720584279181]
	TIME [epoch: 17.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15924296943532268		[learning rate: 0.00034125]
	Learning Rate: 0.000341253
	LOSS [training: 0.15924296943532268 | validation: 0.27539381391619955]
	TIME [epoch: 17.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1483474377689283		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.1483474377689283 | validation: 0.2789083344549727]
	TIME [epoch: 17.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13922772658147914		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.13922772658147914 | validation: 0.2828392672176523]
	TIME [epoch: 17.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14162343998622354		[learning rate: 0.00033675]
	Learning Rate: 0.00033675
	LOSS [training: 0.14162343998622354 | validation: 0.28301176992021376]
	TIME [epoch: 17.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13781272794446328		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.13781272794446328 | validation: 0.2598497850953006]
	TIME [epoch: 17.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15284022076052603		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.15284022076052603 | validation: 0.31113420753855225]
	TIME [epoch: 17.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14599038082554938		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.14599038082554938 | validation: 0.27571425482139805]
	TIME [epoch: 17.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254308162485802		[learning rate: 0.00033084]
	Learning Rate: 0.000330838
	LOSS [training: 0.15254308162485802 | validation: 0.2631720134520122]
	TIME [epoch: 17.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14671465619949448		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.14671465619949448 | validation: 0.27578689908180265]
	TIME [epoch: 17.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527618665169967		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.1527618665169967 | validation: 0.29123127443362845]
	TIME [epoch: 17.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1499995396109663		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.1499995396109663 | validation: 0.2870902527672782]
	TIME [epoch: 17.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14974982739057724		[learning rate: 0.00032503]
	Learning Rate: 0.00032503
	LOSS [training: 0.14974982739057724 | validation: 0.2704242202485148]
	TIME [epoch: 17.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497844400803556		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: 0.1497844400803556 | validation: 0.2743819492158165]
	TIME [epoch: 17.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1480474225985135		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1480474225985135 | validation: 0.28410009729697]
	TIME [epoch: 17.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15378061812510296		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.15378061812510296 | validation: 0.271181460715459]
	TIME [epoch: 17.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15204862806097796		[learning rate: 0.00031932]
	Learning Rate: 0.000319323
	LOSS [training: 0.15204862806097796 | validation: 0.2755481886264401]
	TIME [epoch: 17.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612823343486557		[learning rate: 0.00031791]
	Learning Rate: 0.000317913
	LOSS [training: 0.15612823343486557 | validation: 0.26787624121628445]
	TIME [epoch: 17.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559425845387442		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.1559425845387442 | validation: 0.26570924734557194]
	TIME [epoch: 17.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14687940656108028		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.14687940656108028 | validation: 0.2634016462207971]
	TIME [epoch: 17.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149934244746318		[learning rate: 0.00031372]
	Learning Rate: 0.000313717
	LOSS [training: 0.149934244746318 | validation: 0.27247620764776187]
	TIME [epoch: 17.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108684518550913		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: 0.15108684518550913 | validation: 0.2827897367034223]
	TIME [epoch: 17.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153703128413688		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.153703128413688 | validation: 0.28011487070219]
	TIME [epoch: 17.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474489760768804		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.1474489760768804 | validation: 0.262490113296228]
	TIME [epoch: 17.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14972453862979834		[learning rate: 0.00030821]
	Learning Rate: 0.00030821
	LOSS [training: 0.14972453862979834 | validation: 0.2841153536630407]
	TIME [epoch: 17.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15063039974207618		[learning rate: 0.00030685]
	Learning Rate: 0.000306848
	LOSS [training: 0.15063039974207618 | validation: 0.2584537942703981]
	TIME [epoch: 17.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745391141052183		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.14745391141052183 | validation: 0.28018688713309986]
	TIME [epoch: 17.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575675662064666		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.1575675662064666 | validation: 0.2732406876536496]
	TIME [epoch: 17.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14852761701873424		[learning rate: 0.0003028]
	Learning Rate: 0.000302799
	LOSS [training: 0.14852761701873424 | validation: 0.2790641680904696]
	TIME [epoch: 17.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14723183417074254		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: 0.14723183417074254 | validation: 0.2781477310845593]
	TIME [epoch: 17.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1479494803719107		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.1479494803719107 | validation: 0.29173659956249276]
	TIME [epoch: 17.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13086825478253383		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.13086825478253383 | validation: 0.2743172564596898]
	TIME [epoch: 17.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14439412878218777		[learning rate: 0.00029748]
	Learning Rate: 0.000297483
	LOSS [training: 0.14439412878218777 | validation: 0.27469066112413804]
	TIME [epoch: 17.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580205428962556		[learning rate: 0.00029617]
	Learning Rate: 0.000296168
	LOSS [training: 0.1580205428962556 | validation: 0.282821210155147]
	TIME [epoch: 17.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14665747741626883		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.14665747741626883 | validation: 0.2758149512849361]
	TIME [epoch: 17.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14773934945348402		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.14773934945348402 | validation: 0.2798057951206227]
	TIME [epoch: 17.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14625212836274373		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.14625212836274373 | validation: 0.2696328495035932]
	TIME [epoch: 17.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14985110474280658		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: 0.14985110474280658 | validation: 0.27241789811987244]
	TIME [epoch: 17.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1392979836619257		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.1392979836619257 | validation: 0.2770436006079203]
	TIME [epoch: 17.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15065960779622536		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.15065960779622536 | validation: 0.288110771651865]
	TIME [epoch: 17.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505716206763398		[learning rate: 0.00028713]
	Learning Rate: 0.000287129
	LOSS [training: 0.1505716206763398 | validation: 0.26254637634568023]
	TIME [epoch: 17.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1440722349563923		[learning rate: 0.00028586]
	Learning Rate: 0.00028586
	LOSS [training: 0.1440722349563923 | validation: 0.27814191400934074]
	TIME [epoch: 17.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13618013120862502		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.13618013120862502 | validation: 0.2738606483706475]
	TIME [epoch: 17.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14278974291123625		[learning rate: 0.00028334]
	Learning Rate: 0.00028334
	LOSS [training: 0.14278974291123625 | validation: 0.27700916074806914]
	TIME [epoch: 17.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14603713748811778		[learning rate: 0.00028209]
	Learning Rate: 0.000282088
	LOSS [training: 0.14603713748811778 | validation: 0.27951151070145014]
	TIME [epoch: 17.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15813737076262005		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.15813737076262005 | validation: 0.27431056040473634]
	TIME [epoch: 17.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15033076220560937		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.15033076220560937 | validation: 0.29071894394251974]
	TIME [epoch: 17.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745365712778744		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.14745365712778744 | validation: 0.2839237855236453]
	TIME [epoch: 17.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1465325518832008		[learning rate: 0.00027714]
	Learning Rate: 0.000277136
	LOSS [training: 0.1465325518832008 | validation: 0.2831603513878409]
	TIME [epoch: 17.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13716040865238086		[learning rate: 0.00027591]
	Learning Rate: 0.000275911
	LOSS [training: 0.13716040865238086 | validation: 0.25875909775100214]
	TIME [epoch: 17.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275464254579732		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.15275464254579732 | validation: 0.267919838615972]
	TIME [epoch: 17.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15163854086481934		[learning rate: 0.00027348]
	Learning Rate: 0.000273479
	LOSS [training: 0.15163854086481934 | validation: 0.27669711647660683]
	TIME [epoch: 17.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1419051317961843		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.1419051317961843 | validation: 0.27255598837718265]
	TIME [epoch: 17.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15009021801164185		[learning rate: 0.00027107]
	Learning Rate: 0.000271067
	LOSS [training: 0.15009021801164185 | validation: 0.2668360067437043]
	TIME [epoch: 17.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15281575071671546		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.15281575071671546 | validation: 0.2944671453903337]
	TIME [epoch: 17.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481501370133044		[learning rate: 0.00026868]
	Learning Rate: 0.000268677
	LOSS [training: 0.1481501370133044 | validation: 0.2925650485249913]
	TIME [epoch: 17.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14363304492699885		[learning rate: 0.00026749]
	Learning Rate: 0.00026749
	LOSS [training: 0.14363304492699885 | validation: 0.2891915943306226]
	TIME [epoch: 17.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14013695993338776		[learning rate: 0.00026631]
	Learning Rate: 0.000266308
	LOSS [training: 0.14013695993338776 | validation: 0.25658048925310445]
	TIME [epoch: 17.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.151153994948008		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.151153994948008 | validation: 0.2920968900486523]
	TIME [epoch: 17.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1411827913306321		[learning rate: 0.00026396]
	Learning Rate: 0.00026396
	LOSS [training: 0.1411827913306321 | validation: 0.307463011046343]
	TIME [epoch: 17.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14480741678989295		[learning rate: 0.00026279]
	Learning Rate: 0.000262794
	LOSS [training: 0.14480741678989295 | validation: 0.29138145270793225]
	TIME [epoch: 17.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14492223008179672		[learning rate: 0.00026163]
	Learning Rate: 0.000261633
	LOSS [training: 0.14492223008179672 | validation: 0.27652328823838923]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15_20240716_190531/states/model_facs_v2_dec2b_2dpca_v15_863.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 10361.225 seconds.
