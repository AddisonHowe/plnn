Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v15b', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v15b', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1124202271

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6773224325562555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6773224325562555 | validation: 1.3256271202786656]
	TIME [epoch: 30.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.142038682545901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.142038682545901 | validation: 0.9336110224284394]
	TIME [epoch: 4.38 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6064468177511928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6064468177511928 | validation: 0.759456866565329]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411885175045458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5411885175045458 | validation: 0.6603897848243216]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4844568169791751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4844568169791751 | validation: 0.6320391044292716]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308890176406728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5308890176406728 | validation: 0.6374673882508989]
	TIME [epoch: 4.37 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246164708850756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4246164708850756 | validation: 0.537569118071056]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3717903330368102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3717903330368102 | validation: 0.5592216749637433]
	TIME [epoch: 4.37 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40032635850591963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40032635850591963 | validation: 0.5226315848522387]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35573446726787294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35573446726787294 | validation: 0.564960479519283]
	TIME [epoch: 4.37 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4131205418327893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4131205418327893 | validation: 0.5323886053104312]
	TIME [epoch: 4.36 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3450319657197013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3450319657197013 | validation: 0.5100254639236852]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31249744155914005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31249744155914005 | validation: 0.5714923696838311]
	TIME [epoch: 4.36 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.355117450790721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.355117450790721 | validation: 0.5077681714539033]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31758307761753934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31758307761753934 | validation: 0.5251030638052889]
	TIME [epoch: 4.37 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32525563850244954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32525563850244954 | validation: 0.5896976578609223]
	TIME [epoch: 4.37 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162234109973709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4162234109973709 | validation: 0.4900689438260557]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29969281214530175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29969281214530175 | validation: 0.4864285254500394]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302673430501692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3302673430501692 | validation: 0.49162106126223165]
	TIME [epoch: 4.36 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932348642531726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2932348642531726 | validation: 0.4800879807355177]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29845504716026927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29845504716026927 | validation: 0.456355564961219]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27972612907936645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27972612907936645 | validation: 0.4337737306813323]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26160278647129953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26160278647129953 | validation: 0.485712085374946]
	TIME [epoch: 4.37 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3017425692964124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3017425692964124 | validation: 0.5337411434301649]
	TIME [epoch: 4.37 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341127796837056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3341127796837056 | validation: 0.4379778427560966]
	TIME [epoch: 4.36 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2533973777061799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2533973777061799 | validation: 0.46759105760021746]
	TIME [epoch: 4.36 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34449748672362945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34449748672362945 | validation: 0.45278857882344964]
	TIME [epoch: 4.37 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27853388260127876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27853388260127876 | validation: 0.4285529511302522]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27518062191243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27518062191243 | validation: 0.4408534471913779]
	TIME [epoch: 4.38 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30495439543106884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30495439543106884 | validation: 0.46456305123082675]
	TIME [epoch: 4.37 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2721378337949031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2721378337949031 | validation: 0.40016747565758176]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2569034393210773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2569034393210773 | validation: 0.5207917299946381]
	TIME [epoch: 4.36 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105143335483316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3105143335483316 | validation: 0.4439389660097741]
	TIME [epoch: 4.36 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2951232097310041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2951232097310041 | validation: 0.49970773892572773]
	TIME [epoch: 4.36 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3171445815469802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3171445815469802 | validation: 0.3983681126413337]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2800102708491484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2800102708491484 | validation: 0.4315053610783289]
	TIME [epoch: 4.38 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23135843364273137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23135843364273137 | validation: 0.4193543170412098]
	TIME [epoch: 4.37 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33401238698612923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33401238698612923 | validation: 0.5597049045944724]
	TIME [epoch: 4.36 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2916694386364323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2916694386364323 | validation: 0.4032520058259502]
	TIME [epoch: 4.36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2856523100760305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2856523100760305 | validation: 0.4460446600831501]
	TIME [epoch: 4.36 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29983971130205234		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.29983971130205234 | validation: 0.4556782508595157]
	TIME [epoch: 4.36 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26378297459054695		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.26378297459054695 | validation: 0.41020988431375816]
	TIME [epoch: 4.35 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24907965204216126		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.24907965204216126 | validation: 0.4420217446784412]
	TIME [epoch: 4.36 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28740804192372565		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.28740804192372565 | validation: 0.4406761859316367]
	TIME [epoch: 4.37 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2594225254717968		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2594225254717968 | validation: 0.4037855087496868]
	TIME [epoch: 4.37 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2421037034470625		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.2421037034470625 | validation: 0.41325075439143333]
	TIME [epoch: 4.36 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26911356027420374		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.26911356027420374 | validation: 0.392655242596618]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23060144825329046		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.23060144825329046 | validation: 0.40458185165610916]
	TIME [epoch: 4.37 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24952290487223383		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24952290487223383 | validation: 0.46441004784105394]
	TIME [epoch: 4.36 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23595456359431205		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.23595456359431205 | validation: 0.4113950659526363]
	TIME [epoch: 4.36 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30218728473355677		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.30218728473355677 | validation: 0.402502375858696]
	TIME [epoch: 32 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25199561588518504		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.25199561588518504 | validation: 0.409370396315795]
	TIME [epoch: 8.35 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27319298179426277		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.27319298179426277 | validation: 0.4574605504000541]
	TIME [epoch: 8.37 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22279351546763562		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.22279351546763562 | validation: 0.41492889426919644]
	TIME [epoch: 8.37 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24459463528185785		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.24459463528185785 | validation: 0.4125989884382507]
	TIME [epoch: 8.37 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256009585898383		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.256009585898383 | validation: 0.42863076966937064]
	TIME [epoch: 8.36 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2550871444440364		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2550871444440364 | validation: 0.4192323167832064]
	TIME [epoch: 8.36 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571198589240528		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2571198589240528 | validation: 0.39867658673287726]
	TIME [epoch: 8.38 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24071895702106474		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.24071895702106474 | validation: 0.39527575371985096]
	TIME [epoch: 8.36 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24757636442779057		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.24757636442779057 | validation: 0.4262985041491319]
	TIME [epoch: 8.36 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25134886864301836		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.25134886864301836 | validation: 0.3754608254854725]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1966721643992219		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.1966721643992219 | validation: 0.44845669344388633]
	TIME [epoch: 8.38 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2359373377800534		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.2359373377800534 | validation: 0.3794615233346329]
	TIME [epoch: 8.36 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24394648508961975		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.24394648508961975 | validation: 0.3793153187736355]
	TIME [epoch: 8.36 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291318975778463		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2291318975778463 | validation: 0.3777266081454206]
	TIME [epoch: 8.37 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23405824172307227		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.23405824172307227 | validation: 0.385257113025331]
	TIME [epoch: 8.38 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23931961437062882		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.23931961437062882 | validation: 0.39655870283840844]
	TIME [epoch: 8.37 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2678153828043652		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2678153828043652 | validation: 0.431013401412965]
	TIME [epoch: 8.36 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23682118314488054		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.23682118314488054 | validation: 0.38483103433568777]
	TIME [epoch: 8.36 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20964459427094054		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.20964459427094054 | validation: 0.3765000086030462]
	TIME [epoch: 8.37 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22063842796945118		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.22063842796945118 | validation: 0.3787444893039893]
	TIME [epoch: 8.36 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536496680807958		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.2536496680807958 | validation: 0.4122251982605537]
	TIME [epoch: 8.38 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25941997428799896		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.25941997428799896 | validation: 0.408039952038272]
	TIME [epoch: 8.37 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25039792862884347		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.25039792862884347 | validation: 0.33709791493988533]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21392265263685703		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.21392265263685703 | validation: 0.35558632223318304]
	TIME [epoch: 8.38 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23750264039215824		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.23750264039215824 | validation: 0.36736910528522787]
	TIME [epoch: 8.38 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22328023955213214		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.22328023955213214 | validation: 0.42866886709340923]
	TIME [epoch: 8.37 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2727257809942771		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.2727257809942771 | validation: 0.3547167818961077]
	TIME [epoch: 8.38 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205860851018108		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2205860851018108 | validation: 0.33355199854238265]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22791042824394228		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.22791042824394228 | validation: 0.3925555977616101]
	TIME [epoch: 8.38 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22962636580373283		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22962636580373283 | validation: 0.44676446153060895]
	TIME [epoch: 8.37 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24549916396187593		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.24549916396187593 | validation: 0.3685693139174654]
	TIME [epoch: 8.37 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19789753600064613		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.19789753600064613 | validation: 0.37208190066117763]
	TIME [epoch: 8.37 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205539629706906		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.2205539629706906 | validation: 0.48141559940383616]
	TIME [epoch: 8.36 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2528603426789858		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.2528603426789858 | validation: 0.38692570197026754]
	TIME [epoch: 8.38 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.260814346727811		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.260814346727811 | validation: 0.4732996684955041]
	TIME [epoch: 8.37 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24000404426458757		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.24000404426458757 | validation: 0.385536676289985]
	TIME [epoch: 8.36 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22055299106174817		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.22055299106174817 | validation: 0.3632863428449877]
	TIME [epoch: 8.36 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243978470355799		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.243978470355799 | validation: 0.34716686726413254]
	TIME [epoch: 8.37 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19447682556562215		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.19447682556562215 | validation: 0.3624737816496812]
	TIME [epoch: 8.37 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23017661279969842		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.23017661279969842 | validation: 0.3657193518286298]
	TIME [epoch: 8.36 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21920602580472753		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21920602580472753 | validation: 0.42308743665757353]
	TIME [epoch: 8.36 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23181044383006705		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.23181044383006705 | validation: 0.38768565740370275]
	TIME [epoch: 8.36 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21006103353155997		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.21006103353155997 | validation: 0.4304185042968995]
	TIME [epoch: 8.38 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25039904369406885		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.25039904369406885 | validation: 0.32998737769256026]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21642192387089265		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.21642192387089265 | validation: 0.3481455793940382]
	TIME [epoch: 8.37 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1909122623829695		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.1909122623829695 | validation: 0.3898112146738777]
	TIME [epoch: 8.37 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25392739439201295		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.25392739439201295 | validation: 0.3697626196839731]
	TIME [epoch: 8.37 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20564297458071387		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.20564297458071387 | validation: 0.4042958743448425]
	TIME [epoch: 8.37 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23179747637303655		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.23179747637303655 | validation: 0.40429527325959214]
	TIME [epoch: 8.37 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20992878584803787		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.20992878584803787 | validation: 0.3262429160729292]
	TIME [epoch: 41.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19652014333109669		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.19652014333109669 | validation: 0.4368207170581825]
	TIME [epoch: 18.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20995659537597056		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.20995659537597056 | validation: 0.3358817880188972]
	TIME [epoch: 18.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22167160758183177		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.22167160758183177 | validation: 0.3655404820071524]
	TIME [epoch: 18.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2112750610447743		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2112750610447743 | validation: 0.35405155434488234]
	TIME [epoch: 18.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2011392358175831		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.2011392358175831 | validation: 0.34091095674653227]
	TIME [epoch: 18.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22594831076711		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.22594831076711 | validation: 0.344149540953914]
	TIME [epoch: 18.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21112711655754363		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.21112711655754363 | validation: 0.30643952504282623]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21480922467401803		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.21480922467401803 | validation: 0.34408389779799364]
	TIME [epoch: 18.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20538402142000467		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.20538402142000467 | validation: 0.32674901075501567]
	TIME [epoch: 18.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2072371591229854		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.2072371591229854 | validation: 0.48224098276478]
	TIME [epoch: 18.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29128877982752605		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.29128877982752605 | validation: 0.4169304261646306]
	TIME [epoch: 18.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2359509341156636		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2359509341156636 | validation: 0.5348051149546766]
	TIME [epoch: 18.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23614674055658083		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.23614674055658083 | validation: 0.37318456681915724]
	TIME [epoch: 18.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21834312196859634		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.21834312196859634 | validation: 0.34149865911408317]
	TIME [epoch: 18.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22673210693683216		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.22673210693683216 | validation: 0.39929847281022823]
	TIME [epoch: 18.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20158143569672485		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.20158143569672485 | validation: 0.3269554006894569]
	TIME [epoch: 18.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1949745239772905		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.1949745239772905 | validation: 0.31311313362189286]
	TIME [epoch: 18.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20044932563355014		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.20044932563355014 | validation: 0.38362551225103847]
	TIME [epoch: 18.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20185289534854026		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.20185289534854026 | validation: 0.3398037831513703]
	TIME [epoch: 18.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19886686669105672		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.19886686669105672 | validation: 0.5126613823674978]
	TIME [epoch: 18.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21709752730869197		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.21709752730869197 | validation: 0.3465648640502787]
	TIME [epoch: 18.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20496260369055808		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.20496260369055808 | validation: 0.46918353608241553]
	TIME [epoch: 18.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21382740190601252		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.21382740190601252 | validation: 0.3573619227404144]
	TIME [epoch: 18.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1936354647143415		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.1936354647143415 | validation: 0.3557989330207426]
	TIME [epoch: 18.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19641954484347582		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.19641954484347582 | validation: 0.3408105073643343]
	TIME [epoch: 18.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20321834124942972		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.20321834124942972 | validation: 0.36541870390200554]
	TIME [epoch: 18.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21276695001662738		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.21276695001662738 | validation: 0.39577747630398846]
	TIME [epoch: 18.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20984657015254804		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20984657015254804 | validation: 0.3185387950030474]
	TIME [epoch: 18.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1804624709035316		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1804624709035316 | validation: 0.32728297152693714]
	TIME [epoch: 18.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18813564238952074		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.18813564238952074 | validation: 0.5190995030090527]
	TIME [epoch: 18.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2208631150010477		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2208631150010477 | validation: 0.4595765604444864]
	TIME [epoch: 18.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19498862311948784		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19498862311948784 | validation: 0.3691796195211715]
	TIME [epoch: 18.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21101535924716264		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.21101535924716264 | validation: 0.3581384133473206]
	TIME [epoch: 18.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22289128431680472		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.22289128431680472 | validation: 0.35190221653697334]
	TIME [epoch: 18.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2060315060883779		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2060315060883779 | validation: 0.3514696578701679]
	TIME [epoch: 18.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1996070977444404		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.1996070977444404 | validation: 0.3929987792722585]
	TIME [epoch: 18.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22948946253212088		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.22948946253212088 | validation: 0.3507410876511526]
	TIME [epoch: 18.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19398943932774587		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.19398943932774587 | validation: 0.3386624147460904]
	TIME [epoch: 18.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18235640182017637		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.18235640182017637 | validation: 0.3585948906664734]
	TIME [epoch: 18.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20064665521282604		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.20064665521282604 | validation: 0.35398535035855766]
	TIME [epoch: 18.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21721848579502523		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.21721848579502523 | validation: 0.36172868250870727]
	TIME [epoch: 18.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18614136666327052		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.18614136666327052 | validation: 0.3366702847381138]
	TIME [epoch: 18.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079832157765324		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2079832157765324 | validation: 0.34070213133230776]
	TIME [epoch: 18.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20649423694014182		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.20649423694014182 | validation: 0.30545250243731586]
	TIME [epoch: 18.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19600290581284827		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.19600290581284827 | validation: 0.34921845298902804]
	TIME [epoch: 18.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19383944992345908		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.19383944992345908 | validation: 0.33356717069322245]
	TIME [epoch: 18.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1801002939818242		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.1801002939818242 | validation: 0.33447494126534205]
	TIME [epoch: 18.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19211786466349		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.19211786466349 | validation: 0.3330778942390388]
	TIME [epoch: 18.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1969657110181019		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.1969657110181019 | validation: 0.3691119632738969]
	TIME [epoch: 18.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20727595962522546		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.20727595962522546 | validation: 0.3980117647488371]
	TIME [epoch: 18.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23257699062419843		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.23257699062419843 | validation: 0.36555790252008646]
	TIME [epoch: 18.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20723783491536393		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.20723783491536393 | validation: 0.3624442967386296]
	TIME [epoch: 18.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1896673275414396		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1896673275414396 | validation: 0.35164125583639655]
	TIME [epoch: 18.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2041506974724021		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.2041506974724021 | validation: 0.39385654057033814]
	TIME [epoch: 18.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19415145413430007		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.19415145413430007 | validation: 0.42758818829972106]
	TIME [epoch: 18.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19332144314904665		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.19332144314904665 | validation: 0.3302150695233226]
	TIME [epoch: 18.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079434148716237		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.2079434148716237 | validation: 0.3272574712585359]
	TIME [epoch: 18.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19553097877172462		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.19553097877172462 | validation: 0.32722076343039874]
	TIME [epoch: 18.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19711557720761505		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.19711557720761505 | validation: 0.3020082944342818]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17930611308619843		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.17930611308619843 | validation: 0.31613179378144385]
	TIME [epoch: 18.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18042743552792279		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.18042743552792279 | validation: 0.339847994999386]
	TIME [epoch: 18.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19522506052397423		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.19522506052397423 | validation: 0.39448898085999695]
	TIME [epoch: 18.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23793116609030154		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.23793116609030154 | validation: 0.4282452769512447]
	TIME [epoch: 18.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2032951757469758		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.2032951757469758 | validation: 0.43702389752486576]
	TIME [epoch: 18.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21336015376554934		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.21336015376554934 | validation: 0.3400487967773272]
	TIME [epoch: 18.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2067671537263836		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.2067671537263836 | validation: 0.3150033915081689]
	TIME [epoch: 18.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23153511972575833		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.23153511972575833 | validation: 0.3655613389929198]
	TIME [epoch: 18.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835304581189468		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1835304581189468 | validation: 0.3503019924734628]
	TIME [epoch: 18.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18217772638225313		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.18217772638225313 | validation: 0.36564994746468804]
	TIME [epoch: 18.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18899688698500614		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.18899688698500614 | validation: 0.33209851847679916]
	TIME [epoch: 18.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1923936029653946		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1923936029653946 | validation: 0.31353772117022494]
	TIME [epoch: 18.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18611303275939997		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.18611303275939997 | validation: 0.4046546838178598]
	TIME [epoch: 18.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19623440611708923		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.19623440611708923 | validation: 0.3578324621706268]
	TIME [epoch: 18.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20568923813747508		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.20568923813747508 | validation: 0.29971798275081174]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1884631985972522		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.1884631985972522 | validation: 0.3338925503738649]
	TIME [epoch: 18.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1931280380024731		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1931280380024731 | validation: 0.3203270868997936]
	TIME [epoch: 18.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19709148824589556		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.19709148824589556 | validation: 0.3254343143501381]
	TIME [epoch: 18.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21318475697724865		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.21318475697724865 | validation: 0.3215262913468387]
	TIME [epoch: 18.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18788605430388236		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.18788605430388236 | validation: 0.38328330260929044]
	TIME [epoch: 18.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21634281558391547		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.21634281558391547 | validation: 0.3370903950872714]
	TIME [epoch: 18.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18583400113979537		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18583400113979537 | validation: 0.3377267000091203]
	TIME [epoch: 18.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840949614065559		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.1840949614065559 | validation: 0.32611602634816295]
	TIME [epoch: 18.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17397204735767555		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17397204735767555 | validation: 0.32470393875712866]
	TIME [epoch: 18.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18824863390155927		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.18824863390155927 | validation: 0.3196131398914954]
	TIME [epoch: 18.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2107457612396318		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.2107457612396318 | validation: 0.40725383396976]
	TIME [epoch: 18.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015307349535845		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.2015307349535845 | validation: 0.339226891316704]
	TIME [epoch: 18.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196883183763275		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.196883183763275 | validation: 0.33169967133454853]
	TIME [epoch: 18.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18162196788694876		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.18162196788694876 | validation: 0.33052687971170847]
	TIME [epoch: 18.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883795145948865		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1883795145948865 | validation: 0.3089880236071233]
	TIME [epoch: 18.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20598198768650108		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.20598198768650108 | validation: 0.35115882305301716]
	TIME [epoch: 18.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17708251948977793		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.17708251948977793 | validation: 0.38332028289847064]
	TIME [epoch: 18.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18844312420688902		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18844312420688902 | validation: 0.38182311420313525]
	TIME [epoch: 18.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22251923994880113		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.22251923994880113 | validation: 0.3130716686526653]
	TIME [epoch: 18.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1832869110197349		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1832869110197349 | validation: 0.3487712547327045]
	TIME [epoch: 18.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1748375792262386		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1748375792262386 | validation: 0.2995759547131759]
	TIME [epoch: 18.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18228533941903793		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.18228533941903793 | validation: 0.39059301234676624]
	TIME [epoch: 18.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18784635362163055		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.18784635362163055 | validation: 0.30075163806188493]
	TIME [epoch: 18.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20309878467308845		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.20309878467308845 | validation: 0.33974253821191425]
	TIME [epoch: 18.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20207436671946385		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.20207436671946385 | validation: 0.4087059316667299]
	TIME [epoch: 18.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19815879756950586		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.19815879756950586 | validation: 0.41838352445490734]
	TIME [epoch: 63.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1895639242783793		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1895639242783793 | validation: 0.38436007454519866]
	TIME [epoch: 39.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1988756793881292		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.1988756793881292 | validation: 0.3007396656172806]
	TIME [epoch: 39.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202084045004653		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.202084045004653 | validation: 0.35238250623227735]
	TIME [epoch: 39.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17884053226601168		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.17884053226601168 | validation: 0.40116086811819424]
	TIME [epoch: 39.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1803476351344395		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.1803476351344395 | validation: 0.34298426592463105]
	TIME [epoch: 39.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19959124718717974		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.19959124718717974 | validation: 0.29907848788649455]
	TIME [epoch: 39.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2094028959922108		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2094028959922108 | validation: 0.3818408924798009]
	TIME [epoch: 39.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21822842549883048		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.21822842549883048 | validation: 0.3237377533620038]
	TIME [epoch: 39.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19041067678544304		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.19041067678544304 | validation: 0.3493319891526864]
	TIME [epoch: 39.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1854961083907786		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.1854961083907786 | validation: 0.34837557951925263]
	TIME [epoch: 39.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1978191369888488		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1978191369888488 | validation: 0.33229788218566353]
	TIME [epoch: 39.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18935517192415852		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.18935517192415852 | validation: 0.34522467921719163]
	TIME [epoch: 39.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18138217578251314		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18138217578251314 | validation: 0.3603279411289155]
	TIME [epoch: 39.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19699713504078722		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.19699713504078722 | validation: 0.31864533947877105]
	TIME [epoch: 39.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1902690055399981		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1902690055399981 | validation: 0.3293927947476541]
	TIME [epoch: 39.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1999030013970345		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1999030013970345 | validation: 0.3107056541218766]
	TIME [epoch: 39.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17340577824800527		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17340577824800527 | validation: 0.33699749457954953]
	TIME [epoch: 39.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853101348346534		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.1853101348346534 | validation: 0.3502409476968186]
	TIME [epoch: 39.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18262478720580125		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.18262478720580125 | validation: 0.432660890694087]
	TIME [epoch: 39.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27512667104953314		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.27512667104953314 | validation: 0.32801009076819176]
	TIME [epoch: 39.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22508194147844648		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.22508194147844648 | validation: 0.3307362292489514]
	TIME [epoch: 39.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151545494623191		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.2151545494623191 | validation: 0.31453852405140753]
	TIME [epoch: 39.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.179430121910383		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.179430121910383 | validation: 0.3000760629187956]
	TIME [epoch: 39.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18669063863096189		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18669063863096189 | validation: 0.3399195941778485]
	TIME [epoch: 39.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18537348727376968		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.18537348727376968 | validation: 0.3567502114558584]
	TIME [epoch: 39.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18319619835113732		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.18319619835113732 | validation: 0.38118501397320315]
	TIME [epoch: 39.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18696573529801158		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.18696573529801158 | validation: 0.34376366978421247]
	TIME [epoch: 39.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18101482510735928		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.18101482510735928 | validation: 0.3172235112005256]
	TIME [epoch: 39.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17593314567337956		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.17593314567337956 | validation: 0.39406805223770675]
	TIME [epoch: 39.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2174983549957953		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.2174983549957953 | validation: 0.3013802080451481]
	TIME [epoch: 39.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725241396239907		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1725241396239907 | validation: 0.34674723605589286]
	TIME [epoch: 39.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18460469259383408		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.18460469259383408 | validation: 0.321873134000725]
	TIME [epoch: 39.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17493007305355063		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17493007305355063 | validation: 0.32461728566256803]
	TIME [epoch: 39.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17625627590792328		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17625627590792328 | validation: 0.34892270035271744]
	TIME [epoch: 39.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17807593417068174		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.17807593417068174 | validation: 0.3227170265237155]
	TIME [epoch: 39.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1705634380355824		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.1705634380355824 | validation: 0.34129644557899075]
	TIME [epoch: 39.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18045117853511902		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.18045117853511902 | validation: 0.40011428997379894]
	TIME [epoch: 39.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18767642699405773		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.18767642699405773 | validation: 0.31899495635025854]
	TIME [epoch: 39.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19651496617043632		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.19651496617043632 | validation: 0.34974193826213407]
	TIME [epoch: 39.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20316919903300895		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.20316919903300895 | validation: 0.3082453549517154]
	TIME [epoch: 39.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18100662615078963		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.18100662615078963 | validation: 0.35709485746834296]
	TIME [epoch: 39.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18215378178647956		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.18215378178647956 | validation: 0.3083126251832969]
	TIME [epoch: 39.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18196534186615265		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.18196534186615265 | validation: 0.3045583706067304]
	TIME [epoch: 39.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570245559771284		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.1570245559771284 | validation: 0.33467873699168615]
	TIME [epoch: 39.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17315683177949687		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.17315683177949687 | validation: 0.3145063258359048]
	TIME [epoch: 39.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19259329099607708		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.19259329099607708 | validation: 0.34385575223807485]
	TIME [epoch: 39.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21350390376722772		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.21350390376722772 | validation: 0.30930194007769707]
	TIME [epoch: 39.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17609399427099995		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17609399427099995 | validation: 0.31509570001537895]
	TIME [epoch: 39.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18054627049622424		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.18054627049622424 | validation: 0.37165617131246864]
	TIME [epoch: 39.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1967527930258579		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.1967527930258579 | validation: 0.3234373538503232]
	TIME [epoch: 39.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505087454329272		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2505087454329272 | validation: 0.3659290353526159]
	TIME [epoch: 39.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21516985321486914		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.21516985321486914 | validation: 0.3422444635270274]
	TIME [epoch: 39.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20231592117841846		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.20231592117841846 | validation: 0.3115411687057408]
	TIME [epoch: 39.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16828889569895533		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.16828889569895533 | validation: 0.3030436007318288]
	TIME [epoch: 39.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16987684972042263		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16987684972042263 | validation: 0.2976259257993089]
	TIME [epoch: 39.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18245784441371066		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.18245784441371066 | validation: 0.31057374795578296]
	TIME [epoch: 39.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17378725983190882		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17378725983190882 | validation: 0.3137757895258713]
	TIME [epoch: 39.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17543170896838728		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.17543170896838728 | validation: 0.2930317944748132]
	TIME [epoch: 39.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1739246982909824		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1739246982909824 | validation: 0.3344599819027285]
	TIME [epoch: 39.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1859279177640977		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.1859279177640977 | validation: 0.3074256833620671]
	TIME [epoch: 39.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17582757038945399		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.17582757038945399 | validation: 0.30329949252926913]
	TIME [epoch: 39.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16794095821815574		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.16794095821815574 | validation: 0.29469006704527184]
	TIME [epoch: 39.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723114066761476		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.1723114066761476 | validation: 0.32950956919123503]
	TIME [epoch: 39.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17543761835404798		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.17543761835404798 | validation: 0.3579635570600119]
	TIME [epoch: 39.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692031717342446		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.1692031717342446 | validation: 0.32924101903254]
	TIME [epoch: 39.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17357473617902436		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.17357473617902436 | validation: 0.3194476542975281]
	TIME [epoch: 39.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756552292947508		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1756552292947508 | validation: 0.31186641001894594]
	TIME [epoch: 39.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16614195031148635		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.16614195031148635 | validation: 0.34129620967823626]
	TIME [epoch: 39.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17179545630935328		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.17179545630935328 | validation: 0.30561724942525575]
	TIME [epoch: 39.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17087650253540843		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.17087650253540843 | validation: 0.2966761922473855]
	TIME [epoch: 39.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16464635389392562		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.16464635389392562 | validation: 0.30329719751307677]
	TIME [epoch: 39.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1683344981786203		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1683344981786203 | validation: 0.3364482040167266]
	TIME [epoch: 39.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911338251909413		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1911338251909413 | validation: 0.31744935324754936]
	TIME [epoch: 39.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17648647885018798		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.17648647885018798 | validation: 0.30081754740352606]
	TIME [epoch: 39.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1752738462733298		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1752738462733298 | validation: 0.33031645346710703]
	TIME [epoch: 39.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17633323715501784		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.17633323715501784 | validation: 0.2982612156256609]
	TIME [epoch: 39.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16329760568102006		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16329760568102006 | validation: 0.296221025593769]
	TIME [epoch: 39.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1858819015759611		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1858819015759611 | validation: 0.3118511109297982]
	TIME [epoch: 39.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15056997621430124		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.15056997621430124 | validation: 0.318133095901071]
	TIME [epoch: 39.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644654076346664		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1644654076346664 | validation: 0.31188890042018647]
	TIME [epoch: 39.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717038089788398		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1717038089788398 | validation: 0.28741220218061386]
	TIME [epoch: 39.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1817909910193812		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.1817909910193812 | validation: 0.33721225343350775]
	TIME [epoch: 39.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17067844929392514		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.17067844929392514 | validation: 0.34004067850512176]
	TIME [epoch: 39.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16810029429652706		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.16810029429652706 | validation: 0.294383873590626]
	TIME [epoch: 39.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1680341486304991		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.1680341486304991 | validation: 0.31826663424808077]
	TIME [epoch: 39.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718073094969922		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.1718073094969922 | validation: 0.28552821870432665]
	TIME [epoch: 39.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17604407032267821		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.17604407032267821 | validation: 0.28220819755169085]
	TIME [epoch: 39.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16724603277949618		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16724603277949618 | validation: 0.2832397530353661]
	TIME [epoch: 39.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16202348818965068		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.16202348818965068 | validation: 0.2989145794657755]
	TIME [epoch: 39.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18098703924736476		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.18098703924736476 | validation: 0.35482022292562576]
	TIME [epoch: 39.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17843753686527858		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.17843753686527858 | validation: 0.2997269463583733]
	TIME [epoch: 39.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568750144078791		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.1568750144078791 | validation: 0.31276337203658405]
	TIME [epoch: 39.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515615520967278		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.1515615520967278 | validation: 0.3117910329184843]
	TIME [epoch: 39.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672376168118261		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1672376168118261 | validation: 0.29881998892086314]
	TIME [epoch: 39.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1794604542498265		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1794604542498265 | validation: 0.2923363111886408]
	TIME [epoch: 39.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15963792534459426		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.15963792534459426 | validation: 0.2993973021709662]
	TIME [epoch: 39.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17684792119052262		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.17684792119052262 | validation: 0.33399879749254047]
	TIME [epoch: 39.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16844450501096547		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16844450501096547 | validation: 0.29197672606304753]
	TIME [epoch: 39.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16455454658130644		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.16455454658130644 | validation: 0.2877412666792066]
	TIME [epoch: 39.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17771696777644913		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.17771696777644913 | validation: 0.321609379260962]
	TIME [epoch: 106 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16583454952261747		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.16583454952261747 | validation: 0.31647380713577544]
	TIME [epoch: 81.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17058025872532492		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.17058025872532492 | validation: 0.3352629476701562]
	TIME [epoch: 81.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689106410008908		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1689106410008908 | validation: 0.3174980213752854]
	TIME [epoch: 81.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16691356238243085		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16691356238243085 | validation: 0.30318379246965643]
	TIME [epoch: 81.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16702417972584968		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16702417972584968 | validation: 0.30358976345526406]
	TIME [epoch: 81.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15896572191618513		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.15896572191618513 | validation: 0.3212695062463257]
	TIME [epoch: 81.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18083899010742047		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.18083899010742047 | validation: 0.35951745976801]
	TIME [epoch: 81.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16757794354467317		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.16757794354467317 | validation: 0.30189626491557464]
	TIME [epoch: 81.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17221592627741117		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.17221592627741117 | validation: 0.2976147764211723]
	TIME [epoch: 81.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17603901204954647		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.17603901204954647 | validation: 0.31957136793794994]
	TIME [epoch: 81.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17646937450154795		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.17646937450154795 | validation: 0.31829340209239737]
	TIME [epoch: 81.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609741325541651		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1609741325541651 | validation: 0.346022852501064]
	TIME [epoch: 81.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604812529020094		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.1604812529020094 | validation: 0.3279984708282437]
	TIME [epoch: 81.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16972216506140272		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.16972216506140272 | validation: 0.3097518426568229]
	TIME [epoch: 81.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17193413119262255		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.17193413119262255 | validation: 0.30265414043607075]
	TIME [epoch: 81.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16198391777439805		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16198391777439805 | validation: 0.3337082412936181]
	TIME [epoch: 81.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785729703849195		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.1785729703849195 | validation: 0.29789335087311025]
	TIME [epoch: 81.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16400667783192194		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.16400667783192194 | validation: 0.27544865939742763]
	TIME [epoch: 81.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15871723621092512		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.15871723621092512 | validation: 0.2868628885293632]
	TIME [epoch: 82 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16575180302368678		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16575180302368678 | validation: 0.33776031145478624]
	TIME [epoch: 82 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15632428623425682		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.15632428623425682 | validation: 0.3167290213695764]
	TIME [epoch: 81.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16812916876644832		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.16812916876644832 | validation: 0.3135440677934391]
	TIME [epoch: 81.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16437232373278637		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16437232373278637 | validation: 0.28199643556878623]
	TIME [epoch: 82 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16188647190234068		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16188647190234068 | validation: 0.32973488265113493]
	TIME [epoch: 81.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18340987801704337		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.18340987801704337 | validation: 0.3335335888828379]
	TIME [epoch: 81.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16746086817828218		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.16746086817828218 | validation: 0.33884992497218475]
	TIME [epoch: 81.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18724983653277305		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.18724983653277305 | validation: 0.32900580322528705]
	TIME [epoch: 81.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17506987246770417		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.17506987246770417 | validation: 0.29306619826883124]
	TIME [epoch: 81.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15481938614894972		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.15481938614894972 | validation: 0.2820339931682063]
	TIME [epoch: 81.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15943734604287657		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.15943734604287657 | validation: 0.3309396770202012]
	TIME [epoch: 81.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15587146499868118		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15587146499868118 | validation: 0.2865753524804983]
	TIME [epoch: 81.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15952928984684037		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.15952928984684037 | validation: 0.2979148875194647]
	TIME [epoch: 81.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17305062305755675		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.17305062305755675 | validation: 0.30026214534484436]
	TIME [epoch: 81.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15925630686541145		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.15925630686541145 | validation: 0.3180746767414463]
	TIME [epoch: 81.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16107817746178726		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.16107817746178726 | validation: 0.2862016001166561]
	TIME [epoch: 81.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16394006688227075		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16394006688227075 | validation: 0.3066598278805804]
	TIME [epoch: 81.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15620008905865676		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.15620008905865676 | validation: 0.33503292818453695]
	TIME [epoch: 81.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596674060944264		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.1596674060944264 | validation: 0.299069284341916]
	TIME [epoch: 81.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16880506637444498		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16880506637444498 | validation: 0.31594170927334775]
	TIME [epoch: 81.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16979262504508802		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.16979262504508802 | validation: 0.31471552849396633]
	TIME [epoch: 81.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023588222629332		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.17023588222629332 | validation: 0.29599191882926196]
	TIME [epoch: 81.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035975932555702		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16035975932555702 | validation: 0.3035823498326703]
	TIME [epoch: 81.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674968894708233		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1674968894708233 | validation: 0.29136262630346277]
	TIME [epoch: 81.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16415667304607884		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16415667304607884 | validation: 0.3084890619218562]
	TIME [epoch: 81.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18441428183015243		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.18441428183015243 | validation: 0.28929413755568706]
	TIME [epoch: 82 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.168662549303952		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.168662549303952 | validation: 0.3059348985369785]
	TIME [epoch: 82 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15334561415619927		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.15334561415619927 | validation: 0.29863028026228633]
	TIME [epoch: 81.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15905626635166628		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.15905626635166628 | validation: 0.2852539175740296]
	TIME [epoch: 82 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16705105803026854		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.16705105803026854 | validation: 0.2908638068887123]
	TIME [epoch: 81.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16951752420685895		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16951752420685895 | validation: 0.29692402587014405]
	TIME [epoch: 81.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288639631387093		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.17288639631387093 | validation: 0.3040012517801077]
	TIME [epoch: 82 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17008144254277582		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.17008144254277582 | validation: 0.3171840588431306]
	TIME [epoch: 82 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16636375694344113		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16636375694344113 | validation: 0.3038392001570804]
	TIME [epoch: 81.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16256949729929088		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.16256949729929088 | validation: 0.2921353237445431]
	TIME [epoch: 82 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16635736055511435		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.16635736055511435 | validation: 0.3436756019900473]
	TIME [epoch: 81.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16353688216857803		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.16353688216857803 | validation: 0.3189008532693466]
	TIME [epoch: 81.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15786601047258156		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.15786601047258156 | validation: 0.3149186725048669]
	TIME [epoch: 81.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1621041227348872		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.1621041227348872 | validation: 0.30242657793188377]
	TIME [epoch: 82 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1625670789890885		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1625670789890885 | validation: 0.32749033327197374]
	TIME [epoch: 81.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17100034354668772		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.17100034354668772 | validation: 0.32477827369910495]
	TIME [epoch: 82 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16819862924898876		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16819862924898876 | validation: 0.29335180840235836]
	TIME [epoch: 82 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16260438165179364		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.16260438165179364 | validation: 0.2971463903242488]
	TIME [epoch: 82 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16562792369072246		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.16562792369072246 | validation: 0.3005210937065192]
	TIME [epoch: 81.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16679404135482728		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16679404135482728 | validation: 0.2994914047876713]
	TIME [epoch: 82 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1484225166480137		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.1484225166480137 | validation: 0.2815839492887351]
	TIME [epoch: 82 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16343344884018102		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16343344884018102 | validation: 0.3169273450924577]
	TIME [epoch: 81.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525694204226433		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1525694204226433 | validation: 0.3176483173129653]
	TIME [epoch: 82 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587120701179082		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1587120701179082 | validation: 0.32962539337424607]
	TIME [epoch: 82 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682847597540861		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1682847597540861 | validation: 0.2880598920295898]
	TIME [epoch: 82 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525292875721547		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15525292875721547 | validation: 0.31601106582036537]
	TIME [epoch: 82 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15597035586211005		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.15597035586211005 | validation: 0.3100494842077161]
	TIME [epoch: 81.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16419652732149256		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.16419652732149256 | validation: 0.3032725796974435]
	TIME [epoch: 82 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16616388539508223		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16616388539508223 | validation: 0.2971857860694713]
	TIME [epoch: 82 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481212183075689		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.1481212183075689 | validation: 0.302407937264021]
	TIME [epoch: 82.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17187938323832636		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.17187938323832636 | validation: 0.28723262574172276]
	TIME [epoch: 82.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1686921437131102		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1686921437131102 | validation: 0.2793794344308879]
	TIME [epoch: 82.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16870228417844285		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16870228417844285 | validation: 0.28660196712780744]
	TIME [epoch: 82 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16009700720178152		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16009700720178152 | validation: 0.324307302161222]
	TIME [epoch: 82 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15780273392205715		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15780273392205715 | validation: 0.2784389732421677]
	TIME [epoch: 81.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15661614085240677		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.15661614085240677 | validation: 0.29911039514121707]
	TIME [epoch: 82 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17466334311360543		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.17466334311360543 | validation: 0.2951232333847238]
	TIME [epoch: 81.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583615325614969		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.1583615325614969 | validation: 0.35635472265632473]
	TIME [epoch: 81.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15674244227248962		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.15674244227248962 | validation: 0.2951527416486019]
	TIME [epoch: 81.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17973147776811343		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.17973147776811343 | validation: 0.3342411744791628]
	TIME [epoch: 81.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15429679927257606		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15429679927257606 | validation: 0.28762096000899834]
	TIME [epoch: 82 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15797843186777244		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15797843186777244 | validation: 0.3272757222367493]
	TIME [epoch: 82.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656478904816156		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1656478904816156 | validation: 0.3135523881561764]
	TIME [epoch: 82.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15718264503999532		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15718264503999532 | validation: 0.30873999961842535]
	TIME [epoch: 82 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.167225953040879		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.167225953040879 | validation: 0.3391835316891033]
	TIME [epoch: 82 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15754976964372527		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.15754976964372527 | validation: 0.31562763279779305]
	TIME [epoch: 82 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16204487457782205		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.16204487457782205 | validation: 0.28941429438717425]
	TIME [epoch: 82.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569685610923654		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.1569685610923654 | validation: 0.3027860999085403]
	TIME [epoch: 82 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16352646123128187		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16352646123128187 | validation: 0.2981792931740368]
	TIME [epoch: 82.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580178602140465		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1580178602140465 | validation: 0.3059951465538288]
	TIME [epoch: 82 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15728891330231692		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15728891330231692 | validation: 0.2966161520798946]
	TIME [epoch: 82.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15319990921616639		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15319990921616639 | validation: 0.314228071291428]
	TIME [epoch: 82.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652194875103231		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1652194875103231 | validation: 0.30571678495078985]
	TIME [epoch: 82.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14663436631925872		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.14663436631925872 | validation: 0.2804224045795909]
	TIME [epoch: 82.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505962417333922		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1505962417333922 | validation: 0.3016996602280346]
	TIME [epoch: 82.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636937147011865		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1636937147011865 | validation: 0.3064732266626739]
	TIME [epoch: 82 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16370898330209363		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.16370898330209363 | validation: 0.29979623407691497]
	TIME [epoch: 82 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14692212602819563		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.14692212602819563 | validation: 0.3455226344509207]
	TIME [epoch: 82 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16575840606239128		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16575840606239128 | validation: 0.30820313476513644]
	TIME [epoch: 82 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493227714728848		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.1493227714728848 | validation: 0.31492677742859665]
	TIME [epoch: 82 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563564745443971		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.1563564745443971 | validation: 0.33394320771662284]
	TIME [epoch: 82 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590718601228503		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.1590718601228503 | validation: 0.28963284174341997]
	TIME [epoch: 82.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535799733873742		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1535799733873742 | validation: 0.29328369551208844]
	TIME [epoch: 82 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16382534109406113		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.16382534109406113 | validation: 0.289398909232671]
	TIME [epoch: 82.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15524748690521967		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15524748690521967 | validation: 0.3074639301082732]
	TIME [epoch: 82.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15007024169268496		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15007024169268496 | validation: 0.28674117223995216]
	TIME [epoch: 82 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15901725932000088		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15901725932000088 | validation: 0.3645775951569329]
	TIME [epoch: 82 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17184915254838445		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.17184915254838445 | validation: 0.2938780524898171]
	TIME [epoch: 82 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16309209945458808		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16309209945458808 | validation: 0.31554740115270574]
	TIME [epoch: 82 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15182034541856199		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15182034541856199 | validation: 0.2982613552675754]
	TIME [epoch: 82.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16702950070806505		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.16702950070806505 | validation: 0.3226041885950476]
	TIME [epoch: 82 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15347071996716408		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.15347071996716408 | validation: 0.32025461032231445]
	TIME [epoch: 82 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636707492169041		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1636707492169041 | validation: 0.35969258881574273]
	TIME [epoch: 82 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1914954319959093		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.1914954319959093 | validation: 0.2953074721366468]
	TIME [epoch: 82 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16102722184436608		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.16102722184436608 | validation: 0.2971471584867741]
	TIME [epoch: 82 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17077343244200893		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.17077343244200893 | validation: 0.30692277358489306]
	TIME [epoch: 82 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17356872451851263		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.17356872451851263 | validation: 0.3033439610248184]
	TIME [epoch: 81.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15732188450132256		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15732188450132256 | validation: 0.3042363073619117]
	TIME [epoch: 82 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16849152672701537		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16849152672701537 | validation: 0.3374944711527841]
	TIME [epoch: 82 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560444056034684		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1560444056034684 | validation: 0.30150974451329493]
	TIME [epoch: 82 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690927004411878		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.1690927004411878 | validation: 0.29685440467674373]
	TIME [epoch: 82 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15782658219252288		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15782658219252288 | validation: 0.3180358121500934]
	TIME [epoch: 82.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16219641746768831		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16219641746768831 | validation: 0.3005133319725535]
	TIME [epoch: 82 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14841314182298534		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.14841314182298534 | validation: 0.29139081173750975]
	TIME [epoch: 82 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16534300539494562		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.16534300539494562 | validation: 0.2922955661148747]
	TIME [epoch: 82 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16117236942712462		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.16117236942712462 | validation: 0.3055453436665463]
	TIME [epoch: 82 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15862230942377392		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15862230942377392 | validation: 0.3086766114715424]
	TIME [epoch: 82 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1640272187347067		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1640272187347067 | validation: 0.27961953285273566]
	TIME [epoch: 82 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14674396177055885		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.14674396177055885 | validation: 0.30135879375382046]
	TIME [epoch: 81.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745622689095264		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.14745622689095264 | validation: 0.28137532047907454]
	TIME [epoch: 82 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677409781508446		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1677409781508446 | validation: 0.262140340283448]
	TIME [epoch: 82 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14907982359474908		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.14907982359474908 | validation: 0.3072539110072057]
	TIME [epoch: 82 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605419767964209		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.1605419767964209 | validation: 0.2967061184279972]
	TIME [epoch: 82 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16776591965624782		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.16776591965624782 | validation: 0.3208687370325667]
	TIME [epoch: 82.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17371132191161714		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.17371132191161714 | validation: 0.2735726720271709]
	TIME [epoch: 82 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14371076322696524		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.14371076322696524 | validation: 0.2855075825284402]
	TIME [epoch: 82.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1400980731945769		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.1400980731945769 | validation: 0.2746442031689325]
	TIME [epoch: 81.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16227863137405074		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.16227863137405074 | validation: 0.31781928983073143]
	TIME [epoch: 82 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15368172185097254		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15368172185097254 | validation: 0.2928291494855926]
	TIME [epoch: 82 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154736468453527		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.154736468453527 | validation: 0.2851471233268559]
	TIME [epoch: 81.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526204318017375		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.1526204318017375 | validation: 0.28746079730073554]
	TIME [epoch: 82 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1633615747122747		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.1633615747122747 | validation: 0.29719755727259056]
	TIME [epoch: 81.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15626668545136133		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15626668545136133 | validation: 0.2845570680248641]
	TIME [epoch: 82 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15572710294123573		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15572710294123573 | validation: 0.2908088403080268]
	TIME [epoch: 82.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16165531425448748		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.16165531425448748 | validation: 0.27784551405181845]
	TIME [epoch: 82 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15077933677946556		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15077933677946556 | validation: 0.3342035132361682]
	TIME [epoch: 82.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15429947716579878		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15429947716579878 | validation: 0.2893268259287518]
	TIME [epoch: 82 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16064979031399176		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.16064979031399176 | validation: 0.3065759362112176]
	TIME [epoch: 82 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15708211700707878		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15708211700707878 | validation: 0.31875203530197205]
	TIME [epoch: 81.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15447712482707252		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.15447712482707252 | validation: 0.2922585608848396]
	TIME [epoch: 82 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15501118685167972		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15501118685167972 | validation: 0.3090490856951625]
	TIME [epoch: 82 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16331448667223142		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.16331448667223142 | validation: 0.28400654686405014]
	TIME [epoch: 82 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14234015807690925		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.14234015807690925 | validation: 0.2671001811044703]
	TIME [epoch: 81.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16427229025637455		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.16427229025637455 | validation: 0.31834331708656666]
	TIME [epoch: 82 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15510005350362557		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15510005350362557 | validation: 0.2771869029580401]
	TIME [epoch: 82 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15198265904612557		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15198265904612557 | validation: 0.3120745082555815]
	TIME [epoch: 82.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15351319595923785		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.15351319595923785 | validation: 0.2857442237794239]
	TIME [epoch: 82 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728306899760435		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1728306899760435 | validation: 0.26822592962047087]
	TIME [epoch: 82 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627975612504664		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1627975612504664 | validation: 0.3087495454528238]
	TIME [epoch: 82 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15212301926371782		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15212301926371782 | validation: 0.26970581720364956]
	TIME [epoch: 82 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16748817533277577		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.16748817533277577 | validation: 0.2777209145477289]
	TIME [epoch: 82 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15079668238554247		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15079668238554247 | validation: 0.3052837640520814]
	TIME [epoch: 81.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16172285764464117		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.16172285764464117 | validation: 0.3030426682898173]
	TIME [epoch: 81.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14437889799037892		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.14437889799037892 | validation: 0.3039053545428704]
	TIME [epoch: 81.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161523769130931		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.161523769130931 | validation: 0.2944467400465935]
	TIME [epoch: 81.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165926239725921		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.165926239725921 | validation: 0.2787490561895565]
	TIME [epoch: 82.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14781574998763652		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.14781574998763652 | validation: 0.34027233198184487]
	TIME [epoch: 81.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607995794821623		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.1607995794821623 | validation: 0.2874627600768083]
	TIME [epoch: 82 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14518836537615015		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.14518836537615015 | validation: 0.29663936026441085]
	TIME [epoch: 82 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290261241371633		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15290261241371633 | validation: 0.3044803881421203]
	TIME [epoch: 81.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366654280611936		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15366654280611936 | validation: 0.2879248083695896]
	TIME [epoch: 81.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570824326445565		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.1570824326445565 | validation: 0.2900422410876229]
	TIME [epoch: 82 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15709412336335374		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15709412336335374 | validation: 0.28967680142600943]
	TIME [epoch: 82 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15406465459780988		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15406465459780988 | validation: 0.30059229750920724]
	TIME [epoch: 81.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16136118459693766		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.16136118459693766 | validation: 0.31618607115413233]
	TIME [epoch: 81.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549494170415709		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.1549494170415709 | validation: 0.28134580726836017]
	TIME [epoch: 82 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15862565891585198		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.15862565891585198 | validation: 0.28259544029965195]
	TIME [epoch: 82 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14647184888727177		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.14647184888727177 | validation: 0.29623345377261917]
	TIME [epoch: 82.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14546001770696254		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14546001770696254 | validation: 0.2945498792955079]
	TIME [epoch: 82 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15797471414712858		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15797471414712858 | validation: 0.27974948061374977]
	TIME [epoch: 82 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535414581210541		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.1535414581210541 | validation: 0.29898731725648203]
	TIME [epoch: 81.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627637844152447		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.1627637844152447 | validation: 0.31484470980612694]
	TIME [epoch: 81.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15651146421577716		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.15651146421577716 | validation: 0.29971498341643316]
	TIME [epoch: 81.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560997649801221		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.1560997649801221 | validation: 0.30631287504406746]
	TIME [epoch: 81.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569782560125363		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1569782560125363 | validation: 0.2977449568265291]
	TIME [epoch: 81.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488246907008941		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.1488246907008941 | validation: 0.28187066786996917]
	TIME [epoch: 82 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14892576916466801		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.14892576916466801 | validation: 0.30141392359755914]
	TIME [epoch: 82 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15125274175142375		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15125274175142375 | validation: 0.3015768788107186]
	TIME [epoch: 82 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154267044728685		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.154267044728685 | validation: 0.2896008521258248]
	TIME [epoch: 81.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15557160669740788		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15557160669740788 | validation: 0.2980021596036151]
	TIME [epoch: 81.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14831775995380858		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.14831775995380858 | validation: 0.2930520336895667]
	TIME [epoch: 81.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15274033474910018		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15274033474910018 | validation: 0.3401187427184145]
	TIME [epoch: 82 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1648027431078563		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.1648027431078563 | validation: 0.2826119214864046]
	TIME [epoch: 81.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16315759321669887		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.16315759321669887 | validation: 0.3037790360263857]
	TIME [epoch: 82 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15942269907762105		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15942269907762105 | validation: 0.29250198596622773]
	TIME [epoch: 81.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17057285034149858		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.17057285034149858 | validation: 0.28799486445752587]
	TIME [epoch: 81.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17005596363633338		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.17005596363633338 | validation: 0.29163090394629015]
	TIME [epoch: 81.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277299967748476		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.16277299967748476 | validation: 0.2696268059940602]
	TIME [epoch: 82 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15320649515405477		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.15320649515405477 | validation: 0.3363938009658126]
	TIME [epoch: 81.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504516422615015		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1504516422615015 | validation: 0.27850019406804305]
	TIME [epoch: 82 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15412814650677392		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15412814650677392 | validation: 0.2936038621376105]
	TIME [epoch: 82 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15052675971358614		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15052675971358614 | validation: 0.29870293730042874]
	TIME [epoch: 81.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15526576190389801		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15526576190389801 | validation: 0.27671328030963716]
	TIME [epoch: 82 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14359402723559667		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.14359402723559667 | validation: 0.3630101853312743]
	TIME [epoch: 82 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15929536073906708		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15929536073906708 | validation: 0.29624647353194755]
	TIME [epoch: 81.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15271802917719715		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.15271802917719715 | validation: 0.3309794899407811]
	TIME [epoch: 81.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914019944892197		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15914019944892197 | validation: 0.3086384924517591]
	TIME [epoch: 82 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599868925874784		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1599868925874784 | validation: 0.3201819043257119]
	TIME [epoch: 82 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14899724315927715		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.14899724315927715 | validation: 0.2631424101208209]
	TIME [epoch: 82 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16314744951980037		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.16314744951980037 | validation: 0.3092014922697025]
	TIME [epoch: 81.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15851568506320263		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15851568506320263 | validation: 0.2935780232634367]
	TIME [epoch: 82 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1573149794295764		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.1573149794295764 | validation: 0.3140221447398827]
	TIME [epoch: 82 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492737030909045		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.1492737030909045 | validation: 0.2976608367377031]
	TIME [epoch: 82 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914413992795656		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15914413992795656 | validation: 0.28055344572585006]
	TIME [epoch: 81.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15060380080021046		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15060380080021046 | validation: 0.2835316064397121]
	TIME [epoch: 82 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14887271425069404		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.14887271425069404 | validation: 0.28691819947315084]
	TIME [epoch: 81.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15020656014942735		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.15020656014942735 | validation: 0.3071173591087676]
	TIME [epoch: 82 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16030518848892036		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.16030518848892036 | validation: 0.3053529893761953]
	TIME [epoch: 81.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15707649141352228		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15707649141352228 | validation: 0.31365100665601164]
	TIME [epoch: 81.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1523614434401384		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.1523614434401384 | validation: 0.30785330362370655]
	TIME [epoch: 82 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14707654289270472		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.14707654289270472 | validation: 0.2835006626528157]
	TIME [epoch: 81.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15531215945692836		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.15531215945692836 | validation: 0.30703878284500236]
	TIME [epoch: 82 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14555046368804833		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.14555046368804833 | validation: 0.2958880939835576]
	TIME [epoch: 82 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15142430472099594		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15142430472099594 | validation: 0.28978740965092825]
	TIME [epoch: 82 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15871477716950005		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.15871477716950005 | validation: 0.2815583442287105]
	TIME [epoch: 82 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671929382457567		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.1671929382457567 | validation: 0.30640443714267285]
	TIME [epoch: 81.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14856015948319695		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14856015948319695 | validation: 0.2807531916924144]
	TIME [epoch: 82 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15038946429885083		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15038946429885083 | validation: 0.2830509327064325]
	TIME [epoch: 81.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1454354169028775		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.1454354169028775 | validation: 0.2933736398699269]
	TIME [epoch: 82.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15957460216579294		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.15957460216579294 | validation: 0.29826130676019214]
	TIME [epoch: 81.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16125804958598705		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.16125804958598705 | validation: 0.3107450715556989]
	TIME [epoch: 81.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14203872718650695		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.14203872718650695 | validation: 0.29333214694091797]
	TIME [epoch: 82 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15677518889731		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.15677518889731 | validation: 0.28845157091779927]
	TIME [epoch: 81.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606565539861506		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.1606565539861506 | validation: 0.32847507841824075]
	TIME [epoch: 81.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15287177091501672		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15287177091501672 | validation: 0.29607646759398126]
	TIME [epoch: 82 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15322951333144846		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.15322951333144846 | validation: 0.2814895263677853]
	TIME [epoch: 81.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15910233397714776		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.15910233397714776 | validation: 0.2868391027394641]
	TIME [epoch: 82.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554634166489454		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.1554634166489454 | validation: 0.30998777410472217]
	TIME [epoch: 81.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15840576471753282		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15840576471753282 | validation: 0.30434124318550243]
	TIME [epoch: 82 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525477064813557		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.1525477064813557 | validation: 0.29583718617330146]
	TIME [epoch: 81.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14959053786589216		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.14959053786589216 | validation: 0.32542137818654626]
	TIME [epoch: 82 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15296361433272496		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.15296361433272496 | validation: 0.2964095528382969]
	TIME [epoch: 82 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15744005497259458		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15744005497259458 | validation: 0.27981675971177944]
	TIME [epoch: 81.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311950193966042		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15311950193966042 | validation: 0.28693853480276477]
	TIME [epoch: 81.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15316993466649714		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.15316993466649714 | validation: 0.28532651488820215]
	TIME [epoch: 81.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15753630454984652		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15753630454984652 | validation: 0.27032890322020864]
	TIME [epoch: 81.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15613368798252464		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15613368798252464 | validation: 0.27038154042638113]
	TIME [epoch: 81.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15180837162571795		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.15180837162571795 | validation: 0.2971844947098707]
	TIME [epoch: 82 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14736596797752285		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.14736596797752285 | validation: 0.2892190670282865]
	TIME [epoch: 82 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475819108308906		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.1475819108308906 | validation: 0.2968346495843946]
	TIME [epoch: 82 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399903465664816		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15399903465664816 | validation: 0.2999403105424887]
	TIME [epoch: 81.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16302949283744103		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.16302949283744103 | validation: 0.31786878244620637]
	TIME [epoch: 82 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16430300403540699		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.16430300403540699 | validation: 0.2927119179048246]
	TIME [epoch: 81.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15884536707267216		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.15884536707267216 | validation: 0.2925235751297784]
	TIME [epoch: 82 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1650658371482418		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1650658371482418 | validation: 0.2889360820724133]
	TIME [epoch: 81.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14638701655979114		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.14638701655979114 | validation: 0.33026058584907014]
	TIME [epoch: 81.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610959309516576		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.1610959309516576 | validation: 0.2851586646876275]
	TIME [epoch: 82 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15889761878268965		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15889761878268965 | validation: 0.2829293928489894]
	TIME [epoch: 82 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149128309106286		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.149128309106286 | validation: 0.29463526202118295]
	TIME [epoch: 82 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14177925556497306		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.14177925556497306 | validation: 0.28063455752938166]
	TIME [epoch: 81.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494284237595151		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.1494284237595151 | validation: 0.28958451550578346]
	TIME [epoch: 82 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15264805895571917		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.15264805895571917 | validation: 0.2730907746550982]
	TIME [epoch: 82 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15717953997843945		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15717953997843945 | validation: 0.27437557315342914]
	TIME [epoch: 82 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15936025391818576		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.15936025391818576 | validation: 0.2839608223995223]
	TIME [epoch: 81.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13858743182220645		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.13858743182220645 | validation: 0.28866363402267176]
	TIME [epoch: 81.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15413593295035974		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15413593295035974 | validation: 0.3077183681686394]
	TIME [epoch: 81.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551267272119895		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1551267272119895 | validation: 0.28023882760195423]
	TIME [epoch: 81.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541991863808605		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.1541991863808605 | validation: 0.30217312719833483]
	TIME [epoch: 82 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14521004158132364		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.14521004158132364 | validation: 0.3016792108977853]
	TIME [epoch: 81.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14876437825904396		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.14876437825904396 | validation: 0.2789923518018929]
	TIME [epoch: 81.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14177927025331277		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14177927025331277 | validation: 0.307626788164755]
	TIME [epoch: 82 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543426342311764		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.1543426342311764 | validation: 0.26635856822848375]
	TIME [epoch: 82 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15092964872172576		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.15092964872172576 | validation: 0.30722515158695374]
	TIME [epoch: 82 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16201391030088175		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.16201391030088175 | validation: 0.2725318534534111]
	TIME [epoch: 82 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938588733461974		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.14938588733461974 | validation: 0.28508986077631354]
	TIME [epoch: 81.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1467601137493993		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.1467601137493993 | validation: 0.303719624821338]
	TIME [epoch: 81.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15678648944768506		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.15678648944768506 | validation: 0.2988349094976882]
	TIME [epoch: 82 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1471061338590122		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.1471061338590122 | validation: 0.29385129232376206]
	TIME [epoch: 82 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209987124129226		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15209987124129226 | validation: 0.29752123030519184]
	TIME [epoch: 81.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14323547633562334		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.14323547633562334 | validation: 0.2721368186690845]
	TIME [epoch: 82 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14881630828794706		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.14881630828794706 | validation: 0.2805101751596154]
	TIME [epoch: 81.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552754060900287		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1552754060900287 | validation: 0.30357476204444966]
	TIME [epoch: 82 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257792884364108		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.15257792884364108 | validation: 0.2925329733148451]
	TIME [epoch: 82.1 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154449465981159		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.154449465981159 | validation: 0.29362536517134424]
	TIME [epoch: 82 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14407736472190816		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.14407736472190816 | validation: 0.29864079119296666]
	TIME [epoch: 82.1 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516941233870184		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.1516941233870184 | validation: 0.27431660953504616]
	TIME [epoch: 82.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14854766011299053		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.14854766011299053 | validation: 0.30612586305122086]
	TIME [epoch: 82.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14951189713619317		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.14951189713619317 | validation: 0.3014443424219485]
	TIME [epoch: 82 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15345696935574704		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15345696935574704 | validation: 0.2740670379298351]
	TIME [epoch: 82.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14459186481966335		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.14459186481966335 | validation: 0.277994951132576]
	TIME [epoch: 82 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14376975757845245		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.14376975757845245 | validation: 0.3059351492371423]
	TIME [epoch: 82.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14329216188300978		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.14329216188300978 | validation: 0.2918803141016088]
	TIME [epoch: 82 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493917107042441		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.1493917107042441 | validation: 0.27482980345307145]
	TIME [epoch: 81.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1431746243981401		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.1431746243981401 | validation: 0.29899602377216067]
	TIME [epoch: 81.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14827083828903562		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14827083828903562 | validation: 0.28038586095936013]
	TIME [epoch: 81.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260709985820825		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.15260709985820825 | validation: 0.30358206534650606]
	TIME [epoch: 81.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14825341115092133		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.14825341115092133 | validation: 0.28961697608183357]
	TIME [epoch: 81.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14313656227713709		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.14313656227713709 | validation: 0.27938753990200627]
	TIME [epoch: 81.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14469860519871983		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14469860519871983 | validation: 0.27305177988143714]
	TIME [epoch: 81.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543411167732633		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.1543411167732633 | validation: 0.27700147665476266]
	TIME [epoch: 81.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14592550259362486		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.14592550259362486 | validation: 0.2860791330960763]
	TIME [epoch: 81.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619987430952076		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1619987430952076 | validation: 0.27322073794972795]
	TIME [epoch: 81.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570099767144076		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1570099767144076 | validation: 0.2986218340430267]
	TIME [epoch: 81.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519679342964621		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1519679342964621 | validation: 0.28601494702908065]
	TIME [epoch: 81.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546518237567835		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1546518237567835 | validation: 0.2780653009741069]
	TIME [epoch: 81.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14277276020687207		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.14277276020687207 | validation: 0.2780302950273356]
	TIME [epoch: 82 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16420234049375035		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.16420234049375035 | validation: 0.31197464771094574]
	TIME [epoch: 81.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15924916310486745		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15924916310486745 | validation: 0.2847039237701934]
	TIME [epoch: 81.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16503961968272346		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.16503961968272346 | validation: 0.2867085264767529]
	TIME [epoch: 81.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1490228173353875		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.1490228173353875 | validation: 0.29910523373693504]
	TIME [epoch: 81.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15018299571236926		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15018299571236926 | validation: 0.2975394171892857]
	TIME [epoch: 81.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15390218440884834		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15390218440884834 | validation: 0.3117767046002352]
	TIME [epoch: 81.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15462394895593304		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15462394895593304 | validation: 0.30883712668839447]
	TIME [epoch: 81.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14167201577131414		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.14167201577131414 | validation: 0.27732246037712255]
	TIME [epoch: 81.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15318604305796168		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.15318604305796168 | validation: 0.30133296906977514]
	TIME [epoch: 82 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14950471367489188		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.14950471367489188 | validation: 0.3028068864161808]
	TIME [epoch: 82 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14952279150840378		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.14952279150840378 | validation: 0.2902735849270568]
	TIME [epoch: 81.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15229018611815132		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.15229018611815132 | validation: 0.3115028699312889]
	TIME [epoch: 81.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14345479344817835		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14345479344817835 | validation: 0.2824620666991882]
	TIME [epoch: 82 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14703861200411766		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.14703861200411766 | validation: 0.294477214175883]
	TIME [epoch: 81.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514428963939077		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.1514428963939077 | validation: 0.27197913887654407]
	TIME [epoch: 81.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1428716433978234		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.1428716433978234 | validation: 0.28869141723154]
	TIME [epoch: 82 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15656406586447877		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15656406586447877 | validation: 0.2812229606878087]
	TIME [epoch: 81.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15769062411386514		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.15769062411386514 | validation: 0.27971280499957457]
	TIME [epoch: 82 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13663351408749116		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.13663351408749116 | validation: 0.26703057908104827]
	TIME [epoch: 82 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15595916088076212		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.15595916088076212 | validation: 0.28532784276276274]
	TIME [epoch: 82 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15485461321808652		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.15485461321808652 | validation: 0.2967531778786049]
	TIME [epoch: 81.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15173038616915652		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15173038616915652 | validation: 0.3035439705275529]
	TIME [epoch: 81.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14077280787154325		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.14077280787154325 | validation: 0.2878226210542619]
	TIME [epoch: 81.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15679771899882514		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.15679771899882514 | validation: 0.2884277498113801]
	TIME [epoch: 81.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16217344549067045		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.16217344549067045 | validation: 0.29676655865026424]
	TIME [epoch: 81.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532003759246172		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.1532003759246172 | validation: 0.30324427580947383]
	TIME [epoch: 82 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v15b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v15b_637.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 34208.690 seconds.
