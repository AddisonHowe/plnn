Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v5', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v5', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=50, ncells_sample=50, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2236985510

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9529906131665266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9529906131665266 | validation: 1.035329629342705]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7053207567818828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7053207567818828 | validation: 0.7743961076805886]
	TIME [epoch: 4.01 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5868489833618431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5868489833618431 | validation: 0.7781704344243412]
	TIME [epoch: 3.99 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5513508396245277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5513508396245277 | validation: 0.7555348183300518]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5810320752124026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5810320752124026 | validation: 0.6966339545299594]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.514875344810557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.514875344810557 | validation: 0.6317964273897723]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666430667921928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5666430667921928 | validation: 0.6982563122501999]
	TIME [epoch: 3.94 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41991259023218913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41991259023218913 | validation: 0.5763662851607144]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47096687555819816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47096687555819816 | validation: 0.5791097898308568]
	TIME [epoch: 3.96 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36747891507530656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36747891507530656 | validation: 0.5995079573327773]
	TIME [epoch: 3.94 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39125238052598404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39125238052598404 | validation: 0.5287927083842534]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4532309228653128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4532309228653128 | validation: 0.6226287216004245]
	TIME [epoch: 3.94 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37529870101067936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37529870101067936 | validation: 0.5424047989103638]
	TIME [epoch: 3.96 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36210781710464063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36210781710464063 | validation: 0.6011237334318824]
	TIME [epoch: 3.99 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3631702973558525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3631702973558525 | validation: 0.5785178707645684]
	TIME [epoch: 3.95 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3477854164397458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3477854164397458 | validation: 0.6274750873180085]
	TIME [epoch: 3.98 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063042837189334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4063042837189334 | validation: 0.5413335820402915]
	TIME [epoch: 3.99 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31201824812578105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31201824812578105 | validation: 0.5303834092633715]
	TIME [epoch: 3.97 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3964174190280715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3964174190280715 | validation: 0.5535360945289837]
	TIME [epoch: 3.94 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34947391571831316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34947391571831316 | validation: 0.5726939577712384]
	TIME [epoch: 3.94 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412532732206015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3412532732206015 | validation: 0.46826734053232333]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2833421873023905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2833421873023905 | validation: 0.5985604977256068]
	TIME [epoch: 3.97 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3884778083509537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3884778083509537 | validation: 0.5208539892951031]
	TIME [epoch: 3.97 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4185698940903041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4185698940903041 | validation: 0.5244385978252559]
	TIME [epoch: 3.99 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305346489092243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.305346489092243 | validation: 0.5123038644975018]
	TIME [epoch: 3.99 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3222290542029443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3222290542029443 | validation: 0.5509668694998556]
	TIME [epoch: 3.98 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3428817387638049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3428817387638049 | validation: 0.5448425538047881]
	TIME [epoch: 3.94 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380922689342065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3380922689342065 | validation: 0.5274644630136964]
	TIME [epoch: 3.97 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31746811671966346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31746811671966346 | validation: 0.44047334807906996]
	TIME [epoch: 3.99 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3081700518899579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3081700518899579 | validation: 0.5992330857720352]
	TIME [epoch: 3.96 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35723161624950206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35723161624950206 | validation: 0.557172836639205]
	TIME [epoch: 3.99 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3448740189665309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3448740189665309 | validation: 0.47549665771571825]
	TIME [epoch: 3.99 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3139817234777955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3139817234777955 | validation: 0.593666543549687]
	TIME [epoch: 3.98 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3576401011463916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3576401011463916 | validation: 0.4436082080523474]
	TIME [epoch: 3.94 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2661571824906431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2661571824906431 | validation: 0.48876747526544684]
	TIME [epoch: 3.95 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28451311673600765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28451311673600765 | validation: 0.5096984244767506]
	TIME [epoch: 3.99 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146741731138373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3146741731138373 | validation: 0.3919642426128816]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2829315145474619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2829315145474619 | validation: 0.5219258618050124]
	TIME [epoch: 3.98 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29548578193680336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29548578193680336 | validation: 0.47827527297193706]
	TIME [epoch: 3.94 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295826123203499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3295826123203499 | validation: 0.43371394043188416]
	TIME [epoch: 3.95 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26179986088769397		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.26179986088769397 | validation: 0.4028141494050701]
	TIME [epoch: 3.94 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531602336754139		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.2531602336754139 | validation: 0.4064104552436686]
	TIME [epoch: 3.94 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3194838592212039		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.3194838592212039 | validation: 0.5014046437062692]
	TIME [epoch: 3.97 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042631766247599		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.3042631766247599 | validation: 0.46946287500032935]
	TIME [epoch: 3.98 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26366370023675584		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.26366370023675584 | validation: 0.516014489859249]
	TIME [epoch: 3.95 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28053843195276124		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.28053843195276124 | validation: 0.4506903919447074]
	TIME [epoch: 3.98 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22625926852342		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.22625926852342 | validation: 0.40235907338106824]
	TIME [epoch: 3.99 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2773829958135454		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2773829958135454 | validation: 0.478850841109932]
	TIME [epoch: 3.95 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3106657562586695		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.3106657562586695 | validation: 0.37448288527361995]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26814987402728935		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.26814987402728935 | validation: 0.3529612535382546]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626886503462842		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.2626886503462842 | validation: 0.44847670591228006]
	TIME [epoch: 3.95 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30839172164000545		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.30839172164000545 | validation: 0.38268023859510664]
	TIME [epoch: 3.94 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2440696441892002		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2440696441892002 | validation: 0.494685702736218]
	TIME [epoch: 3.98 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27216543790209247		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.27216543790209247 | validation: 0.377998611812372]
	TIME [epoch: 3.97 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26161294116096895		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.26161294116096895 | validation: 0.37411165483695075]
	TIME [epoch: 3.95 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24988395801779273		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.24988395801779273 | validation: 0.4417283662544653]
	TIME [epoch: 3.94 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3021298990701792		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.3021298990701792 | validation: 0.39201798224480155]
	TIME [epoch: 3.94 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2885698338310389		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2885698338310389 | validation: 0.4978589221739269]
	TIME [epoch: 3.98 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26669361131418734		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.26669361131418734 | validation: 0.3918393421305661]
	TIME [epoch: 3.96 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2340295688370591		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2340295688370591 | validation: 0.3601718023876704]
	TIME [epoch: 3.95 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24537114083985184		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.24537114083985184 | validation: 0.4276794008292508]
	TIME [epoch: 3.94 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24040670600304254		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.24040670600304254 | validation: 0.42230874650107075]
	TIME [epoch: 3.94 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25165619073088646		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.25165619073088646 | validation: 0.5077989150911753]
	TIME [epoch: 3.94 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25113950267119817		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.25113950267119817 | validation: 0.38355016916013907]
	TIME [epoch: 3.94 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24138515288524562		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.24138515288524562 | validation: 0.4230046904477479]
	TIME [epoch: 3.94 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2220224740906039		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.2220224740906039 | validation: 0.5021989240320576]
	TIME [epoch: 3.94 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21888194628779784		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.21888194628779784 | validation: 0.5259991628734574]
	TIME [epoch: 3.94 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2911950887401275		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2911950887401275 | validation: 0.4019307946349376]
	TIME [epoch: 3.94 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23070577049455707		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.23070577049455707 | validation: 0.4313215296597573]
	TIME [epoch: 3.94 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28618093120930677		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.28618093120930677 | validation: 0.5110264531551931]
	TIME [epoch: 3.94 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31734555037300793		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.31734555037300793 | validation: 0.5533091469872349]
	TIME [epoch: 3.94 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29135099402691084		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.29135099402691084 | validation: 0.49805470626607073]
	TIME [epoch: 3.95 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2798739937704826		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2798739937704826 | validation: 0.4015487615678184]
	TIME [epoch: 3.94 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20747970945010802		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.20747970945010802 | validation: 0.408874501734574]
	TIME [epoch: 3.94 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2570020002328762		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.2570020002328762 | validation: 0.444378269934512]
	TIME [epoch: 3.94 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381941630760124		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2381941630760124 | validation: 0.4139679253258906]
	TIME [epoch: 3.99 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2374907161406928		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2374907161406928 | validation: 0.3448395060516055]
	TIME [epoch: 3.99 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21392227283769655		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.21392227283769655 | validation: 0.48184591232188834]
	TIME [epoch: 3.95 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2430264284858382		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2430264284858382 | validation: 0.4248266611866141]
	TIME [epoch: 3.94 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2324054243453934		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.2324054243453934 | validation: 0.4806852560264484]
	TIME [epoch: 3.95 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2740122320364182		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.2740122320364182 | validation: 0.38070742590246553]
	TIME [epoch: 3.99 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21173140171970478		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.21173140171970478 | validation: 0.5283241259694651]
	TIME [epoch: 3.96 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35210875708975714		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.35210875708975714 | validation: 0.4877305355834067]
	TIME [epoch: 3.97 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26377548811867935		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.26377548811867935 | validation: 0.4068266234682327]
	TIME [epoch: 3.99 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23909638225192986		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.23909638225192986 | validation: 0.36428191556467776]
	TIME [epoch: 3.96 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24503092863935266		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.24503092863935266 | validation: 0.4245056952645174]
	TIME [epoch: 3.94 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893820363171761		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.2893820363171761 | validation: 0.355989838350664]
	TIME [epoch: 3.94 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23033784815361869		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.23033784815361869 | validation: 0.35523866468780624]
	TIME [epoch: 3.97 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2039385567846217		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.2039385567846217 | validation: 0.3692442696493117]
	TIME [epoch: 3.98 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22294093049550917		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.22294093049550917 | validation: 0.3256354926207946]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22768835854597058		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.22768835854597058 | validation: 0.3554888713547884]
	TIME [epoch: 3.99 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20511853570353705		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.20511853570353705 | validation: 0.35814075390712946]
	TIME [epoch: 3.97 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2274604923754298		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.2274604923754298 | validation: 0.35681323611443855]
	TIME [epoch: 3.98 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2057952484135539		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.2057952484135539 | validation: 0.34670990893526077]
	TIME [epoch: 3.94 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2600824642071984		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.2600824642071984 | validation: 0.43675331309220644]
	TIME [epoch: 3.95 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21676025165890622		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.21676025165890622 | validation: 0.31895408066476055]
	TIME [epoch: 3.99 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3210757205887956		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.3210757205887956 | validation: 0.46714633748413326]
	TIME [epoch: 3.95 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2789827149346145		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.2789827149346145 | validation: 0.414407812985299]
	TIME [epoch: 3.98 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2482830304582532		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.2482830304582532 | validation: 0.4329653432465177]
	TIME [epoch: 3.99 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574320439827802		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.2574320439827802 | validation: 0.38261814650128]
	TIME [epoch: 3.98 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24080861209325438		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.24080861209325438 | validation: 0.38785086050526013]
	TIME [epoch: 3.94 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2285178878579876		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2285178878579876 | validation: 0.32356733167447543]
	TIME [epoch: 3.94 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20992210360631475		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.20992210360631475 | validation: 0.35378472102315406]
	TIME [epoch: 3.99 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20575812499137713		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20575812499137713 | validation: 0.3366596578408095]
	TIME [epoch: 3.98 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2137176243364695		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2137176243364695 | validation: 0.34060930401566114]
	TIME [epoch: 3.97 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24921685971189259		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.24921685971189259 | validation: 0.3501368317740336]
	TIME [epoch: 4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23512194957554317		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.23512194957554317 | validation: 0.406437569214034]
	TIME [epoch: 3.97 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22600877877386996		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.22600877877386996 | validation: 0.35994441423772205]
	TIME [epoch: 3.99 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19405776506632158		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.19405776506632158 | validation: 0.3573330328629048]
	TIME [epoch: 3.99 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22321314957240843		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.22321314957240843 | validation: 0.5466550242119076]
	TIME [epoch: 4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4025277915423368		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.4025277915423368 | validation: 0.5055644192091522]
	TIME [epoch: 3.98 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36939454740722766		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.36939454740722766 | validation: 0.46580979295041824]
	TIME [epoch: 3.95 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3019767901618285		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.3019767901618285 | validation: 0.45473547515856994]
	TIME [epoch: 3.99 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2430803604742408		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.2430803604742408 | validation: 0.4720427341921918]
	TIME [epoch: 3.99 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2220996424572222		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.2220996424572222 | validation: 0.43373623438942877]
	TIME [epoch: 3.98 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22530172241098106		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.22530172241098106 | validation: 0.4185654153184542]
	TIME [epoch: 3.95 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2176900091836361		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.2176900091836361 | validation: 0.4051847240292046]
	TIME [epoch: 3.94 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22135954055183174		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.22135954055183174 | validation: 0.37903979335309096]
	TIME [epoch: 3.99 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2130859784157908		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.2130859784157908 | validation: 0.3433236675210403]
	TIME [epoch: 3.96 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21110289231414975		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.21110289231414975 | validation: 0.3285584653699774]
	TIME [epoch: 3.96 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21550172016083297		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.21550172016083297 | validation: 0.3263551269425146]
	TIME [epoch: 3.99 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2234810089605242		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.2234810089605242 | validation: 0.4015051452440419]
	TIME [epoch: 3.97 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23629912871152953		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.23629912871152953 | validation: 0.4142320586530486]
	TIME [epoch: 3.96 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21491967524904565		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.21491967524904565 | validation: 0.3318650416562581]
	TIME [epoch: 3.94 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1799831860535149		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.1799831860535149 | validation: 0.32917204774313336]
	TIME [epoch: 3.96 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20387649465767832		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.20387649465767832 | validation: 0.3354493828474432]
	TIME [epoch: 3.99 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20281332463706675		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.20281332463706675 | validation: 0.32567474391784385]
	TIME [epoch: 3.96 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20693313788155604		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20693313788155604 | validation: 0.4207848123678453]
	TIME [epoch: 3.98 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23271255109313832		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.23271255109313832 | validation: 0.33679131463981443]
	TIME [epoch: 3.98 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21812054081974744		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.21812054081974744 | validation: 0.3419307626167891]
	TIME [epoch: 3.95 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828707295094766		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.19828707295094766 | validation: 0.4020066011969107]
	TIME [epoch: 3.94 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18243534618529295		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.18243534618529295 | validation: 0.31111527870910805]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17970612593910723		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.17970612593910723 | validation: 0.3323264073076428]
	TIME [epoch: 3.97 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25463691012888506		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.25463691012888506 | validation: 0.3078381673594886]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17614681713308805		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.17614681713308805 | validation: 0.32726447354032784]
	TIME [epoch: 3.97 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3697909353288529		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3697909353288529 | validation: 0.4556681036396464]
	TIME [epoch: 3.99 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34850279141521084		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.34850279141521084 | validation: 0.450079914579135]
	TIME [epoch: 3.99 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2511270698350808		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.2511270698350808 | validation: 0.441266651080436]
	TIME [epoch: 3.96 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2303949519788234		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.2303949519788234 | validation: 0.4142999452106644]
	TIME [epoch: 3.94 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21307320652834977		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.21307320652834977 | validation: 0.45073808330035764]
	TIME [epoch: 3.97 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21752882334414286		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.21752882334414286 | validation: 0.34047914746270286]
	TIME [epoch: 3.98 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23597505649897604		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.23597505649897604 | validation: 0.4415737769160894]
	TIME [epoch: 3.94 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299923137617156		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.2299923137617156 | validation: 0.3600779205250235]
	TIME [epoch: 3.99 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21380977461345346		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.21380977461345346 | validation: 0.35732662590533965]
	TIME [epoch: 3.99 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19665664376095202		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19665664376095202 | validation: 0.3340197569649387]
	TIME [epoch: 3.97 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18096526796212536		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.18096526796212536 | validation: 0.3654431832975625]
	TIME [epoch: 3.94 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215210084483706		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.2215210084483706 | validation: 0.3742685014193381]
	TIME [epoch: 3.94 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21009457031317974		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.21009457031317974 | validation: 0.35491660926620244]
	TIME [epoch: 3.99 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19799200067788156		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.19799200067788156 | validation: 0.3617126027072325]
	TIME [epoch: 3.96 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20269937193839938		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.20269937193839938 | validation: 0.33091969059086823]
	TIME [epoch: 3.98 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712839735984595		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1712839735984595 | validation: 0.3345591388249125]
	TIME [epoch: 4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22009394232206972		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.22009394232206972 | validation: 0.3465104401276233]
	TIME [epoch: 4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19644751880918931		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.19644751880918931 | validation: 0.3672841827818449]
	TIME [epoch: 3.95 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2026209717062722		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.2026209717062722 | validation: 0.37170290528183925]
	TIME [epoch: 3.94 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1917895160806998		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.1917895160806998 | validation: 0.3046313379084513]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20249793811630634		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.20249793811630634 | validation: 0.30632326303745444]
	TIME [epoch: 3.95 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2055221232310788		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.2055221232310788 | validation: 0.3476779002074006]
	TIME [epoch: 3.94 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1683401139447507		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.1683401139447507 | validation: 0.38873440856691543]
	TIME [epoch: 3.99 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29134846092826117		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.29134846092826117 | validation: 0.37975455152771476]
	TIME [epoch: 3.99 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21010616841584717		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.21010616841584717 | validation: 0.35936208876450565]
	TIME [epoch: 3.99 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20815398276798924		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.20815398276798924 | validation: 0.4102496565802281]
	TIME [epoch: 3.97 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835463178076252		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.1835463178076252 | validation: 0.3238260099269124]
	TIME [epoch: 3.94 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23148719286666558		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.23148719286666558 | validation: 0.32750415436005287]
	TIME [epoch: 3.99 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19245231655971756		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.19245231655971756 | validation: 0.37049490443251276]
	TIME [epoch: 3.95 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20100349365071576		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.20100349365071576 | validation: 0.4255831741480943]
	TIME [epoch: 3.97 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2014431953060854		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.2014431953060854 | validation: 0.44864030751641554]
	TIME [epoch: 3.99 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2244192534008409		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.2244192534008409 | validation: 0.3360082483844111]
	TIME [epoch: 3.99 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.188749923745399		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.188749923745399 | validation: 0.2897699336027909]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2159439136935764		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.2159439136935764 | validation: 0.32796375373026465]
	TIME [epoch: 3.94 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2061282175205855		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.2061282175205855 | validation: 0.3285950198958988]
	TIME [epoch: 3.98 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20220925292554223		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.20220925292554223 | validation: 0.3214539001512816]
	TIME [epoch: 3.97 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21169112902392984		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.21169112902392984 | validation: 0.3489589629920092]
	TIME [epoch: 3.98 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20380337592639597		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.20380337592639597 | validation: 0.32132281168779464]
	TIME [epoch: 3.96 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19183708576216946		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.19183708576216946 | validation: 0.36121409305924873]
	TIME [epoch: 3.96 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19971860262398458		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.19971860262398458 | validation: 0.3587755971001946]
	TIME [epoch: 3.96 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19103261450201595		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.19103261450201595 | validation: 0.27248376498086413]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19252720882234817		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.19252720882234817 | validation: 0.3134121464334114]
	TIME [epoch: 3.96 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19121153199418045		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.19121153199418045 | validation: 0.3410586259581787]
	TIME [epoch: 3.96 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18539074949151396		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.18539074949151396 | validation: 0.3539940651092659]
	TIME [epoch: 3.97 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18494895357387134		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.18494895357387134 | validation: 0.30324981872366275]
	TIME [epoch: 3.97 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19046421945745381		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.19046421945745381 | validation: 0.31184743501741713]
	TIME [epoch: 3.94 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20179898667713986		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.20179898667713986 | validation: 0.3694421556892955]
	TIME [epoch: 3.95 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1855618700474166		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.1855618700474166 | validation: 0.37242280786090715]
	TIME [epoch: 3.96 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1678196160265542		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1678196160265542 | validation: 0.3687236678362352]
	TIME [epoch: 3.96 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19442042341514126		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.19442042341514126 | validation: 0.41854805486797814]
	TIME [epoch: 3.97 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21630429653053634		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.21630429653053634 | validation: 0.3240436301710387]
	TIME [epoch: 3.96 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2135530540415183		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.2135530540415183 | validation: 0.39568429281232287]
	TIME [epoch: 3.96 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1901280422082206		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1901280422082206 | validation: 0.3433784404830996]
	TIME [epoch: 3.95 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20172973404101305		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.20172973404101305 | validation: 0.33293425435451]
	TIME [epoch: 3.95 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2024147498156914		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.2024147498156914 | validation: 0.36076220988176166]
	TIME [epoch: 3.96 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19911151768711305		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.19911151768711305 | validation: 0.41547597349806226]
	TIME [epoch: 3.96 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20020039600220793		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.20020039600220793 | validation: 0.3968085868640126]
	TIME [epoch: 3.96 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17470608273641156		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.17470608273641156 | validation: 0.304466900954513]
	TIME [epoch: 3.96 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18775130255824024		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.18775130255824024 | validation: 0.412269875394115]
	TIME [epoch: 3.96 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20182352722207425		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.20182352722207425 | validation: 0.39913471629744823]
	TIME [epoch: 3.99 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19141680228937286		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.19141680228937286 | validation: 0.329163053349581]
	TIME [epoch: 3.95 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17100776721273098		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.17100776721273098 | validation: 0.3352010604989289]
	TIME [epoch: 3.94 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17895637451435875		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17895637451435875 | validation: 0.3610500805056816]
	TIME [epoch: 3.94 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18315701991490002		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.18315701991490002 | validation: 0.34610684798133345]
	TIME [epoch: 3.96 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1998910298156634		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.1998910298156634 | validation: 0.30799068444179417]
	TIME [epoch: 3.96 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20501902600413055		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.20501902600413055 | validation: 0.31015025880090935]
	TIME [epoch: 3.95 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18977081568390192		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.18977081568390192 | validation: 0.3055360176734176]
	TIME [epoch: 3.96 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17439320064834143		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.17439320064834143 | validation: 0.3254133843886445]
	TIME [epoch: 3.96 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21668154782302418		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.21668154782302418 | validation: 0.31141386114313907]
	TIME [epoch: 3.94 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149095327981912		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.2149095327981912 | validation: 0.3829991744864553]
	TIME [epoch: 3.96 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023159540609512		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.2023159540609512 | validation: 0.30141187745542153]
	TIME [epoch: 3.96 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18424626027130364		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.18424626027130364 | validation: 0.35232840255772]
	TIME [epoch: 3.95 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740253827835603		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1740253827835603 | validation: 0.35097001373978187]
	TIME [epoch: 3.95 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19266423864260332		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.19266423864260332 | validation: 0.39795872284652567]
	TIME [epoch: 3.95 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22629218279799157		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.22629218279799157 | validation: 0.32867433692123693]
	TIME [epoch: 3.97 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2337478410980657		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.2337478410980657 | validation: 0.3206390464508004]
	TIME [epoch: 3.96 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1928578946891876		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1928578946891876 | validation: 0.3161098357109828]
	TIME [epoch: 3.95 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18525209820229988		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.18525209820229988 | validation: 0.3151987016363526]
	TIME [epoch: 3.94 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175176438869621		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.20175176438869621 | validation: 0.29337250557326605]
	TIME [epoch: 3.94 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21613846005524429		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.21613846005524429 | validation: 0.41754009592696106]
	TIME [epoch: 3.96 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24984047489165814		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.24984047489165814 | validation: 0.3360499406949592]
	TIME [epoch: 3.96 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20620802776573743		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.20620802776573743 | validation: 0.3267058500222599]
	TIME [epoch: 3.95 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20288131977693058		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.20288131977693058 | validation: 0.31984675677537056]
	TIME [epoch: 3.96 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1735304750146236		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.1735304750146236 | validation: 0.3264361396711176]
	TIME [epoch: 3.94 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676720210923547		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.1676720210923547 | validation: 0.28582415430014524]
	TIME [epoch: 3.94 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20679599908989205		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.20679599908989205 | validation: 0.340981701853583]
	TIME [epoch: 3.94 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.170487700597091		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.170487700597091 | validation: 0.39727849621946243]
	TIME [epoch: 3.94 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22181170654374585		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.22181170654374585 | validation: 0.34577207706659496]
	TIME [epoch: 3.95 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848076701318624		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1848076701318624 | validation: 0.31778629297917754]
	TIME [epoch: 3.94 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21620360133329353		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.21620360133329353 | validation: 0.3523882815336572]
	TIME [epoch: 3.95 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21207084192504072		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.21207084192504072 | validation: 0.39851790463194803]
	TIME [epoch: 3.94 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19504785969066826		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.19504785969066826 | validation: 0.305902535506905]
	TIME [epoch: 3.95 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15616348985245088		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.15616348985245088 | validation: 0.29425313782339574]
	TIME [epoch: 3.95 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17684669439269493		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17684669439269493 | validation: 0.30837455150526827]
	TIME [epoch: 3.95 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1857638145396972		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1857638145396972 | validation: 0.32800542948215056]
	TIME [epoch: 3.95 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698887087382483		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1698887087382483 | validation: 0.36156943027074046]
	TIME [epoch: 3.94 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1792721922185474		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1792721922185474 | validation: 0.3270136580462184]
	TIME [epoch: 3.94 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18224014772143646		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.18224014772143646 | validation: 0.3616099094808141]
	TIME [epoch: 3.95 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1791979466383822		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.1791979466383822 | validation: 0.312263217307148]
	TIME [epoch: 3.94 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17343698217295073		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17343698217295073 | validation: 0.3747374101469579]
	TIME [epoch: 3.95 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18394578314180843		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.18394578314180843 | validation: 0.34929259539520846]
	TIME [epoch: 3.94 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19164006581606405		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.19164006581606405 | validation: 0.3679137944567537]
	TIME [epoch: 3.94 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21439890457527094		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.21439890457527094 | validation: 0.3766393537105127]
	TIME [epoch: 3.95 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2213568004233777		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.2213568004233777 | validation: 0.38714684787142795]
	TIME [epoch: 3.94 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674126148004746		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1674126148004746 | validation: 0.33166176950285187]
	TIME [epoch: 3.95 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19266821446625348		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.19266821446625348 | validation: 0.4006548294847929]
	TIME [epoch: 3.95 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18124298278013984		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.18124298278013984 | validation: 0.37165862325510707]
	TIME [epoch: 3.94 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17625297542206733		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.17625297542206733 | validation: 0.3326344938279668]
	TIME [epoch: 3.95 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20735231276068125		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.20735231276068125 | validation: 0.31495323017635696]
	TIME [epoch: 3.97 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18890475167838522		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.18890475167838522 | validation: 0.3151688782328057]
	TIME [epoch: 3.98 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18363482151271343		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.18363482151271343 | validation: 0.31866233778770797]
	TIME [epoch: 3.94 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1873809620527219		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.1873809620527219 | validation: 0.3151032844955843]
	TIME [epoch: 3.94 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.183217686508506		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.183217686508506 | validation: 0.3184019937903175]
	TIME [epoch: 3.95 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17925464910932892		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17925464910932892 | validation: 0.2884230573101406]
	TIME [epoch: 3.94 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21726613891573088		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.21726613891573088 | validation: 0.35044611255894986]
	TIME [epoch: 3.95 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16884593916601667		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.16884593916601667 | validation: 0.4838638926804602]
	TIME [epoch: 3.94 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712269101339085		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1712269101339085 | validation: 0.37533906465827904]
	TIME [epoch: 3.95 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18419280825508236		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18419280825508236 | validation: 0.3058812926543083]
	TIME [epoch: 3.95 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1831757039724319		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1831757039724319 | validation: 0.3309648389098274]
	TIME [epoch: 3.94 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16367858847668879		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.16367858847668879 | validation: 0.38845436449925735]
	TIME [epoch: 3.95 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18196012744258577		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.18196012744258577 | validation: 0.3709228442831848]
	TIME [epoch: 3.95 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19033121274962067		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.19033121274962067 | validation: 0.33391299775088246]
	TIME [epoch: 3.95 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1729787253167266		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.1729787253167266 | validation: 0.36932919911930884]
	TIME [epoch: 3.95 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19524806156371538		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.19524806156371538 | validation: 0.31082610885621537]
	TIME [epoch: 3.94 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17687800114337165		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.17687800114337165 | validation: 0.28320870424600775]
	TIME [epoch: 3.95 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16484555798252823		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.16484555798252823 | validation: 0.3443109426884757]
	TIME [epoch: 3.95 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21547608249050434		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.21547608249050434 | validation: 0.35061911730297907]
	TIME [epoch: 3.94 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17942917134009517		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.17942917134009517 | validation: 0.3468093639283193]
	TIME [epoch: 3.95 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17681501166072475		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.17681501166072475 | validation: 0.3525613525586348]
	TIME [epoch: 3.95 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16964799449876344		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16964799449876344 | validation: 0.2957802753817274]
	TIME [epoch: 3.94 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16044024493479397		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16044024493479397 | validation: 0.3306141166083893]
	TIME [epoch: 3.95 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18023910830605044		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.18023910830605044 | validation: 0.308718246918758]
	TIME [epoch: 3.94 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15739677211357922		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.15739677211357922 | validation: 0.31563777240773755]
	TIME [epoch: 3.97 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1871126703663041		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.1871126703663041 | validation: 0.31671291667147417]
	TIME [epoch: 3.98 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18503256899506157		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.18503256899506157 | validation: 0.2973967840737982]
	TIME [epoch: 3.94 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17924307108371887		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.17924307108371887 | validation: 0.3596771960927791]
	TIME [epoch: 3.99 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18558060109409602		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.18558060109409602 | validation: 0.29630624007397915]
	TIME [epoch: 3.99 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16577196282259563		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16577196282259563 | validation: 0.28467455938324077]
	TIME [epoch: 3.99 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17554629203472932		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.17554629203472932 | validation: 0.30521196958447694]
	TIME [epoch: 3.99 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17093180310211964		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.17093180310211964 | validation: 0.29128314721404047]
	TIME [epoch: 4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18455723807643193		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.18455723807643193 | validation: 0.3277194483895988]
	TIME [epoch: 3.98 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1703298415804498		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.1703298415804498 | validation: 0.34413424991705927]
	TIME [epoch: 3.96 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17406979350533644		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.17406979350533644 | validation: 0.3644690969127313]
	TIME [epoch: 3.96 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2076272416096164		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.2076272416096164 | validation: 0.2943265318261275]
	TIME [epoch: 3.99 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16161740324576082		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16161740324576082 | validation: 0.32407678757020875]
	TIME [epoch: 3.94 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15997071587534378		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.15997071587534378 | validation: 0.3223137999379063]
	TIME [epoch: 3.98 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16064617780476018		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.16064617780476018 | validation: 0.3056068347262493]
	TIME [epoch: 3.99 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17243440598759102		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.17243440598759102 | validation: 0.3344526535508033]
	TIME [epoch: 3.98 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17743677350576353		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.17743677350576353 | validation: 0.3246717909013661]
	TIME [epoch: 3.98 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.158296602068642		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.158296602068642 | validation: 0.29712606097293964]
	TIME [epoch: 3.94 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17441092346990075		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.17441092346990075 | validation: 0.344302155220198]
	TIME [epoch: 3.99 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18025349670071156		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.18025349670071156 | validation: 0.313584075419512]
	TIME [epoch: 3.99 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15577772028718734		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15577772028718734 | validation: 0.31713374256139426]
	TIME [epoch: 3.99 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17414289703006638		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.17414289703006638 | validation: 0.28986694025507626]
	TIME [epoch: 3.99 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17754215399296214		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.17754215399296214 | validation: 0.3199872721935221]
	TIME [epoch: 3.95 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17594508637379588		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.17594508637379588 | validation: 0.33280642587583914]
	TIME [epoch: 3.98 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17479868006904964		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.17479868006904964 | validation: 0.3510370906591279]
	TIME [epoch: 3.95 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18633988749782043		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.18633988749782043 | validation: 0.33942870502299466]
	TIME [epoch: 3.96 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788619671373677		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.15788619671373677 | validation: 0.36643962252566]
	TIME [epoch: 3.99 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1710986919513768		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1710986919513768 | validation: 0.3208405810493501]
	TIME [epoch: 3.99 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17152063585678543		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.17152063585678543 | validation: 0.29914003658399885]
	TIME [epoch: 3.98 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16207942889488638		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16207942889488638 | validation: 0.288838181462779]
	TIME [epoch: 3.99 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19294731288724348		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.19294731288724348 | validation: 0.32025352507145166]
	TIME [epoch: 4.01 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16266122308929165		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16266122308929165 | validation: 0.3440253835293419]
	TIME [epoch: 3.98 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19086217924107715		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.19086217924107715 | validation: 0.3339503889770655]
	TIME [epoch: 3.94 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16881026012866418		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16881026012866418 | validation: 0.29365776828456097]
	TIME [epoch: 3.99 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1673841424204299		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1673841424204299 | validation: 0.3397119850975199]
	TIME [epoch: 3.99 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17573078682740007		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.17573078682740007 | validation: 0.3316816554555245]
	TIME [epoch: 3.98 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19005844651068154		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.19005844651068154 | validation: 0.34457527390731324]
	TIME [epoch: 3.99 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19370534941360856		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.19370534941360856 | validation: 0.3190770518059866]
	TIME [epoch: 3.95 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16658834131751013		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16658834131751013 | validation: 0.3014339155225646]
	TIME [epoch: 3.98 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1734791543715311		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.1734791543715311 | validation: 0.33257965845766824]
	TIME [epoch: 3.95 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19196603727790165		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.19196603727790165 | validation: 0.2870095306207025]
	TIME [epoch: 3.96 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1688570987291623		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.1688570987291623 | validation: 0.31142300904350506]
	TIME [epoch: 4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643200490702385		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.1643200490702385 | validation: 0.32168628559578544]
	TIME [epoch: 3.99 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15531426527710251		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.15531426527710251 | validation: 0.34197405543724313]
	TIME [epoch: 3.99 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16127932442830237		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16127932442830237 | validation: 0.32201376566152384]
	TIME [epoch: 3.99 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18489504324311873		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.18489504324311873 | validation: 0.3671603232340104]
	TIME [epoch: 3.99 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17006967531595485		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.17006967531595485 | validation: 0.31671180072856764]
	TIME [epoch: 3.98 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775171325104287		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.1775171325104287 | validation: 0.3689308411773824]
	TIME [epoch: 3.94 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17898242507210022		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.17898242507210022 | validation: 0.28330354677993513]
	TIME [epoch: 3.98 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16135081657519762		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16135081657519762 | validation: 0.3399735861441529]
	TIME [epoch: 3.99 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17617409542293774		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.17617409542293774 | validation: 0.3499636764340655]
	TIME [epoch: 3.99 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15669835408675076		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.15669835408675076 | validation: 0.295781247143328]
	TIME [epoch: 3.99 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18394318997885772		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.18394318997885772 | validation: 0.3028536247319432]
	TIME [epoch: 3.95 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16133045301153542		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16133045301153542 | validation: 0.2898015017945616]
	TIME [epoch: 3.99 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17105797302916176		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.17105797302916176 | validation: 0.34623166886558254]
	TIME [epoch: 3.96 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15973607345244628		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.15973607345244628 | validation: 0.3390739006818213]
	TIME [epoch: 3.96 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17095247787697296		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17095247787697296 | validation: 0.3460781105184401]
	TIME [epoch: 3.99 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16566054986822745		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16566054986822745 | validation: 0.3521174823062995]
	TIME [epoch: 3.99 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15721466798520223		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.15721466798520223 | validation: 0.3092933871359987]
	TIME [epoch: 3.98 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17365622979516598		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.17365622979516598 | validation: 0.33811281092393475]
	TIME [epoch: 3.99 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15702211758599338		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.15702211758599338 | validation: 0.30278719395960524]
	TIME [epoch: 3.99 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16881483342220993		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.16881483342220993 | validation: 0.32904216468272596]
	TIME [epoch: 3.98 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570464547803843		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.1570464547803843 | validation: 0.35214325460305057]
	TIME [epoch: 3.94 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18408947243674886		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.18408947243674886 | validation: 0.3031880251033641]
	TIME [epoch: 3.98 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17178167415525336		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.17178167415525336 | validation: 0.3612454574481531]
	TIME [epoch: 4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16346905152354363		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.16346905152354363 | validation: 0.29268151719319513]
	TIME [epoch: 3.98 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18209572245812286		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.18209572245812286 | validation: 0.35650315214809164]
	TIME [epoch: 3.99 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027943347685845		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.17027943347685845 | validation: 0.34476989737069946]
	TIME [epoch: 3.95 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668727034535371		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1668727034535371 | validation: 0.2721220080381068]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15490932696059243		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15490932696059243 | validation: 0.310953126676534]
	TIME [epoch: 3.95 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16939743281266423		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.16939743281266423 | validation: 0.32066446093282625]
	TIME [epoch: 3.97 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17204139112443745		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.17204139112443745 | validation: 0.31740915649071866]
	TIME [epoch: 3.99 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1435283876419982		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1435283876419982 | validation: 0.25479995182667864]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18077167045796014		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.18077167045796014 | validation: 0.3015168957435987]
	TIME [epoch: 3.99 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725233420487538		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1725233420487538 | validation: 0.2765239786077633]
	TIME [epoch: 3.94 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17708495208867972		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.17708495208867972 | validation: 0.29004670521001896]
	TIME [epoch: 3.98 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1748670455197514		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1748670455197514 | validation: 0.3279946696447876]
	TIME [epoch: 3.96 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1684926280415425		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.1684926280415425 | validation: 0.2736704542946099]
	TIME [epoch: 3.95 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708117274742781		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.1708117274742781 | validation: 0.26631349641039537]
	TIME [epoch: 3.99 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1693408931556539		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1693408931556539 | validation: 0.30912266751648587]
	TIME [epoch: 3.99 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15855701135742212		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.15855701135742212 | validation: 0.3109156622228958]
	TIME [epoch: 3.98 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869042917313549		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.1869042917313549 | validation: 0.3281128083230003]
	TIME [epoch: 3.99 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18883826005174434		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.18883826005174434 | validation: 0.364403099953718]
	TIME [epoch: 3.95 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19209194107260913		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.19209194107260913 | validation: 0.3347150254866931]
	TIME [epoch: 3.98 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16326549963946946		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16326549963946946 | validation: 0.3030060892451526]
	TIME [epoch: 3.95 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16978349971101345		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16978349971101345 | validation: 0.34488595699261926]
	TIME [epoch: 3.99 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16531794925223903		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16531794925223903 | validation: 0.3227270075452983]
	TIME [epoch: 3.97 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1729518406975108		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.1729518406975108 | validation: 0.35313565752288806]
	TIME [epoch: 3.95 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18192297881524308		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.18192297881524308 | validation: 0.3022319325486013]
	TIME [epoch: 3.99 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15997783989547618		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.15997783989547618 | validation: 0.3370858906211962]
	TIME [epoch: 3.99 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1719222814755036		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1719222814755036 | validation: 0.2723976554176031]
	TIME [epoch: 3.99 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14930302348210772		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.14930302348210772 | validation: 0.3256789445095246]
	TIME [epoch: 3.97 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15373503637137187		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.15373503637137187 | validation: 0.29731254764230286]
	TIME [epoch: 3.94 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638121400717584		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1638121400717584 | validation: 0.30866344435577553]
	TIME [epoch: 3.99 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16977191522444926		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16977191522444926 | validation: 0.3052423016539432]
	TIME [epoch: 3.98 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16747490593324824		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.16747490593324824 | validation: 0.36804560983999224]
	TIME [epoch: 3.98 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671869369544508		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1671869369544508 | validation: 0.30738050742661865]
	TIME [epoch: 3.98 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15411970889251023		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15411970889251023 | validation: 0.33391048960622505]
	TIME [epoch: 3.95 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17518214512699232		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.17518214512699232 | validation: 0.3112094714764807]
	TIME [epoch: 4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592633389058429		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.1592633389058429 | validation: 0.29624846540762817]
	TIME [epoch: 3.95 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624772221099223		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1624772221099223 | validation: 0.31598417635531395]
	TIME [epoch: 3.99 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16814548442913307		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.16814548442913307 | validation: 0.3085606390833006]
	TIME [epoch: 3.99 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18573523380524254		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.18573523380524254 | validation: 0.3116535210060352]
	TIME [epoch: 3.97 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17670449071258998		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.17670449071258998 | validation: 0.2988879328001036]
	TIME [epoch: 3.99 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16853968551815793		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16853968551815793 | validation: 0.29690948491377406]
	TIME [epoch: 3.99 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618544114547804		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.1618544114547804 | validation: 0.2910787929780209]
	TIME [epoch: 3.99 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655099003105766		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1655099003105766 | validation: 0.31084306696340774]
	TIME [epoch: 3.97 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689306460297633		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.1689306460297633 | validation: 0.29457799700925585]
	TIME [epoch: 3.95 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15594104061521108		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.15594104061521108 | validation: 0.3422903003369052]
	TIME [epoch: 3.94 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1738053939644473		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1738053939644473 | validation: 0.31075878025371106]
	TIME [epoch: 3.98 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16541710297063003		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16541710297063003 | validation: 0.3337220600371904]
	TIME [epoch: 3.97 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17546912493570616		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.17546912493570616 | validation: 0.34463588316099364]
	TIME [epoch: 3.99 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16197363637844311		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16197363637844311 | validation: 0.34999909945123153]
	TIME [epoch: 3.95 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15757880404132407		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.15757880404132407 | validation: 0.26908756608283524]
	TIME [epoch: 3.99 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15170814746087946		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.15170814746087946 | validation: 0.3061409158953765]
	TIME [epoch: 3.95 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17132587817862088		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.17132587817862088 | validation: 0.3143041754790379]
	TIME [epoch: 3.93 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602730852195032		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1602730852195032 | validation: 0.32866286342734163]
	TIME [epoch: 3.94 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15526698086960566		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15526698086960566 | validation: 0.2968171770721629]
	TIME [epoch: 3.94 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14562037660840316		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.14562037660840316 | validation: 0.3042729452436704]
	TIME [epoch: 3.98 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14937366165155466		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.14937366165155466 | validation: 0.3083636744202493]
	TIME [epoch: 3.99 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1764248434220153		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1764248434220153 | validation: 0.2712428694877645]
	TIME [epoch: 3.99 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16481762884032375		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.16481762884032375 | validation: 0.2650840053952923]
	TIME [epoch: 3.98 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13915224673902665		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.13915224673902665 | validation: 0.2925607013649639]
	TIME [epoch: 3.93 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1815843886023538		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1815843886023538 | validation: 0.314479206331647]
	TIME [epoch: 3.95 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1654202478056806		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1654202478056806 | validation: 0.30631328970977145]
	TIME [epoch: 3.98 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155554998729613		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.155554998729613 | validation: 0.312207258054478]
	TIME [epoch: 3.96 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604057986384847		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.1604057986384847 | validation: 0.2794640323831009]
	TIME [epoch: 3.99 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15637371892085378		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15637371892085378 | validation: 0.3016321875887751]
	TIME [epoch: 3.95 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15792821837325238		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15792821837325238 | validation: 0.29633581494453703]
	TIME [epoch: 3.98 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161679985711873		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.161679985711873 | validation: 0.2915082396817442]
	TIME [epoch: 3.95 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590989519619848		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1590989519619848 | validation: 0.32727486035775216]
	TIME [epoch: 3.94 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16511623197862765		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.16511623197862765 | validation: 0.3676603636431341]
	TIME [epoch: 3.94 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15193872211854217		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15193872211854217 | validation: 0.28851533715617494]
	TIME [epoch: 3.95 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14778837426448585		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14778837426448585 | validation: 0.28150842887561395]
	TIME [epoch: 3.99 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15347112506030075		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.15347112506030075 | validation: 0.3143755957652776]
	TIME [epoch: 3.99 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16481688785896625		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.16481688785896625 | validation: 0.32093558690192037]
	TIME [epoch: 3.99 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16299440246585906		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16299440246585906 | validation: 0.28738710247375393]
	TIME [epoch: 3.97 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17290722778935463		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.17290722778935463 | validation: 0.2860094827348118]
	TIME [epoch: 3.94 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15634099713406796		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15634099713406796 | validation: 0.3494397822648662]
	TIME [epoch: 3.94 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15895378410053607		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.15895378410053607 | validation: 0.30923863851244987]
	TIME [epoch: 3.98 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15461947785614055		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15461947785614055 | validation: 0.3142664802051562]
	TIME [epoch: 3.98 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601761549217622		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1601761549217622 | validation: 0.2666350709228032]
	TIME [epoch: 3.99 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14502534771768955		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.14502534771768955 | validation: 0.31237005301483284]
	TIME [epoch: 3.95 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549100037907963		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.1549100037907963 | validation: 0.3035175607013488]
	TIME [epoch: 3.99 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14685316214125457		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.14685316214125457 | validation: 0.29520943447507286]
	TIME [epoch: 3.96 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14655836664492877		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.14655836664492877 | validation: 0.30875647934493305]
	TIME [epoch: 3.98 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16731814161517314		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16731814161517314 | validation: 0.2766998335094276]
	TIME [epoch: 3.94 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16991614966529398		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.16991614966529398 | validation: 0.30155465053579456]
	TIME [epoch: 3.94 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15629717837951457		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15629717837951457 | validation: 0.2958761570326117]
	TIME [epoch: 3.98 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15762728309247018		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.15762728309247018 | validation: 0.3222582772349602]
	TIME [epoch: 3.99 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16405480782583673		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.16405480782583673 | validation: 0.2818142744218902]
	TIME [epoch: 3.99 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15581043969396496		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15581043969396496 | validation: 0.2911795549589182]
	TIME [epoch: 3.97 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529262235827142		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1529262235827142 | validation: 0.2782607527729703]
	TIME [epoch: 3.94 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14573322283727513		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.14573322283727513 | validation: 0.30327681775957605]
	TIME [epoch: 3.94 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17003993832732062		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.17003993832732062 | validation: 0.3122782621417228]
	TIME [epoch: 3.94 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624490569564349		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.1624490569564349 | validation: 0.3509486287347341]
	TIME [epoch: 3.97 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16354049610028198		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16354049610028198 | validation: 0.2783583624780667]
	TIME [epoch: 3.99 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15818325062980979		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.15818325062980979 | validation: 0.30114956777872526]
	TIME [epoch: 3.96 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14791325607473296		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.14791325607473296 | validation: 0.26644763096546603]
	TIME [epoch: 3.98 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15454101367520143		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15454101367520143 | validation: 0.31841255922147615]
	TIME [epoch: 3.96 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643072482688807		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1643072482688807 | validation: 0.279557006289516]
	TIME [epoch: 3.94 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16234065790787605		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.16234065790787605 | validation: 0.27268111744866524]
	TIME [epoch: 3.94 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16611941785031864		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.16611941785031864 | validation: 0.27980926523231203]
	TIME [epoch: 3.94 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591952717811697		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.1591952717811697 | validation: 0.2947127822087306]
	TIME [epoch: 3.97 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16681967364722747		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.16681967364722747 | validation: 0.3212304894543898]
	TIME [epoch: 3.99 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16290338778166155		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.16290338778166155 | validation: 0.2788894741023185]
	TIME [epoch: 3.99 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17287536041765458		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.17287536041765458 | validation: 0.3224278358258713]
	TIME [epoch: 3.99 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15007272788911458		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15007272788911458 | validation: 0.29769429526938446]
	TIME [epoch: 3.94 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14840347616349608		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.14840347616349608 | validation: 0.31315347049421965]
	TIME [epoch: 3.95 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587183352586074		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1587183352586074 | validation: 0.2937651979249859]
	TIME [epoch: 3.94 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15296625102029038		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15296625102029038 | validation: 0.3045239894621873]
	TIME [epoch: 3.95 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16477365713701217		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.16477365713701217 | validation: 0.35591064783871285]
	TIME [epoch: 3.99 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1389772765815133		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1389772765815133 | validation: 0.3099968271318975]
	TIME [epoch: 3.96 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15694256150508007		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15694256150508007 | validation: 0.310851758630299]
	TIME [epoch: 3.98 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16724200536102093		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.16724200536102093 | validation: 0.29835713337756753]
	TIME [epoch: 3.96 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15439242973922593		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15439242973922593 | validation: 0.2843290313234356]
	TIME [epoch: 3.94 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1436959080493935		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1436959080493935 | validation: 0.2810821829003014]
	TIME [epoch: 3.94 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14977456891644708		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.14977456891644708 | validation: 0.3110828379518671]
	TIME [epoch: 3.94 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15373296993622027		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15373296993622027 | validation: 0.339686085036786]
	TIME [epoch: 3.98 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636561908930479		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.1636561908930479 | validation: 0.3288913448319322]
	TIME [epoch: 3.99 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15694402858489812		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15694402858489812 | validation: 0.3174521278075749]
	TIME [epoch: 3.99 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14839918799155682		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.14839918799155682 | validation: 0.24893445607000483]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16553787870986106		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.16553787870986106 | validation: 0.2961688345560737]
	TIME [epoch: 3.94 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16869964206925686		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.16869964206925686 | validation: 0.33583061744534043]
	TIME [epoch: 3.94 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17814495842016345		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.17814495842016345 | validation: 0.2920359705326598]
	TIME [epoch: 3.94 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601151030436711		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.1601151030436711 | validation: 0.2740406363838246]
	TIME [epoch: 3.95 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16790257464444291		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.16790257464444291 | validation: 0.2783594341537814]
	TIME [epoch: 3.99 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14901558243571836		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.14901558243571836 | validation: 0.2790468238618684]
	TIME [epoch: 3.95 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473188557510862		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1473188557510862 | validation: 0.26952165054348826]
	TIME [epoch: 3.97 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1635674122160758		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.1635674122160758 | validation: 0.29128077071951924]
	TIME [epoch: 3.97 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533271759902004		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.1533271759902004 | validation: 0.3070597059618724]
	TIME [epoch: 3.98 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1859613397203562		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.1859613397203562 | validation: 0.3280061636197872]
	TIME [epoch: 3.94 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587961006925038		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1587961006925038 | validation: 0.3795669629140476]
	TIME [epoch: 3.94 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656746935755585		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.1656746935755585 | validation: 0.2844911759195333]
	TIME [epoch: 3.97 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535077826806039		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1535077826806039 | validation: 0.29599250308894465]
	TIME [epoch: 3.99 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1640442748810056		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1640442748810056 | validation: 0.2845079386156878]
	TIME [epoch: 3.99 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15305591074149869		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15305591074149869 | validation: 0.31583607420286863]
	TIME [epoch: 3.98 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15293356333101243		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15293356333101243 | validation: 0.2714026005964619]
	TIME [epoch: 3.94 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15037692997573796		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15037692997573796 | validation: 0.29158753241941127]
	TIME [epoch: 3.96 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14526511624038543		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.14526511624038543 | validation: 0.26679758439283446]
	TIME [epoch: 3.94 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525232511767685		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1525232511767685 | validation: 0.2634544997501964]
	TIME [epoch: 3.95 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614878042793742		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1614878042793742 | validation: 0.2872930311704988]
	TIME [epoch: 3.99 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516051639532997		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.16516051639532997 | validation: 0.30881402297722566]
	TIME [epoch: 3.96 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15853547254040526		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.15853547254040526 | validation: 0.28672899115030404]
	TIME [epoch: 3.97 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14246776995657073		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.14246776995657073 | validation: 0.299305819287257]
	TIME [epoch: 3.95 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569763130315322		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.1569763130315322 | validation: 0.3064369933339576]
	TIME [epoch: 3.95 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16025028746122344		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.16025028746122344 | validation: 0.3031969051078686]
	TIME [epoch: 3.94 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16129418725903794		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.16129418725903794 | validation: 0.3238655211167318]
	TIME [epoch: 3.94 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540561690820112		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1540561690820112 | validation: 0.3156846430427561]
	TIME [epoch: 3.97 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642513957123511		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.1642513957123511 | validation: 0.3198252495305297]
	TIME [epoch: 3.99 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15919244387642809		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15919244387642809 | validation: 0.3287559371428385]
	TIME [epoch: 3.98 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16992357114285123		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.16992357114285123 | validation: 0.28745280564091763]
	TIME [epoch: 3.98 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15562011538277604		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15562011538277604 | validation: 0.3010570183806578]
	TIME [epoch: 3.95 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16129660182732367		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.16129660182732367 | validation: 0.32388626954859245]
	TIME [epoch: 3.94 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15050082689047625		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.15050082689047625 | validation: 0.28865253508923955]
	TIME [epoch: 3.94 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15997494656342118		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15997494656342118 | validation: 0.28130869387171714]
	TIME [epoch: 3.95 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16062164883341856		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.16062164883341856 | validation: 0.3497489363206046]
	TIME [epoch: 3.99 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16133835571575844		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.16133835571575844 | validation: 0.3159611749322045]
	TIME [epoch: 3.97 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493177932441046		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.1493177932441046 | validation: 0.30665451482178413]
	TIME [epoch: 3.97 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15304767482013282		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15304767482013282 | validation: 0.3186008558713926]
	TIME [epoch: 3.96 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675469621524514		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1675469621524514 | validation: 0.30776333229005365]
	TIME [epoch: 3.94 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15202024402472508		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15202024402472508 | validation: 0.318770582273989]
	TIME [epoch: 3.95 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14208291365283282		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.14208291365283282 | validation: 0.2974110271233769]
	TIME [epoch: 3.95 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15732014005219327		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15732014005219327 | validation: 0.2988017826799019]
	TIME [epoch: 3.97 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15305505521554333		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15305505521554333 | validation: 0.3318832158501749]
	TIME [epoch: 4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239852589522593		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15239852589522593 | validation: 0.29245959280393546]
	TIME [epoch: 3.99 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14900439585464734		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.14900439585464734 | validation: 0.2726156673066291]
	TIME [epoch: 3.99 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14491689429532395		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.14491689429532395 | validation: 0.31262957262296454]
	TIME [epoch: 3.94 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16504632361237664		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.16504632361237664 | validation: 0.289195023447585]
	TIME [epoch: 3.95 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15539455316446912		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15539455316446912 | validation: 0.29037367222698035]
	TIME [epoch: 3.95 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13464116546211838		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.13464116546211838 | validation: 0.287314095089994]
	TIME [epoch: 3.95 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14917234624377854		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.14917234624377854 | validation: 0.30191710663331506]
	TIME [epoch: 3.99 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15031458531239703		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15031458531239703 | validation: 0.29451884071266454]
	TIME [epoch: 3.97 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14907463932506695		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.14907463932506695 | validation: 0.29441688280138956]
	TIME [epoch: 27.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16185844561176174		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.16185844561176174 | validation: 0.2771979775477511]
	TIME [epoch: 7.65 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708676673338448		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.1708676673338448 | validation: 0.3085898856460627]
	TIME [epoch: 7.55 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14976506455876973		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.14976506455876973 | validation: 0.31515826425452764]
	TIME [epoch: 7.55 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.164474897707426		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.164474897707426 | validation: 0.2599107754784059]
	TIME [epoch: 7.64 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15897447217439767		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15897447217439767 | validation: 0.30867421617300966]
	TIME [epoch: 7.61 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14963698941748604		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.14963698941748604 | validation: 0.28831798367604156]
	TIME [epoch: 7.58 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15574989117579768		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15574989117579768 | validation: 0.31082248442985577]
	TIME [epoch: 7.57 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624306738975582		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.1624306738975582 | validation: 0.3196536961250164]
	TIME [epoch: 7.63 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15283180263040141		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15283180263040141 | validation: 0.3521245624807852]
	TIME [epoch: 7.62 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558129325960131		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1558129325960131 | validation: 0.28171080719701747]
	TIME [epoch: 7.56 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614216025782606		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1614216025782606 | validation: 0.2733035522421968]
	TIME [epoch: 7.56 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670614212632125		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15670614212632125 | validation: 0.2995357738380151]
	TIME [epoch: 7.61 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16262031699095555		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.16262031699095555 | validation: 0.32612250384679065]
	TIME [epoch: 7.59 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1426115136245351		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.1426115136245351 | validation: 0.2730494498239365]
	TIME [epoch: 7.57 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15310749720572397		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15310749720572397 | validation: 0.3031518185296453]
	TIME [epoch: 7.57 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16159562634175292		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.16159562634175292 | validation: 0.28388588693294486]
	TIME [epoch: 7.64 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14903723917367068		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.14903723917367068 | validation: 0.3354398681527795]
	TIME [epoch: 7.62 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16022371390497897		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.16022371390497897 | validation: 0.28571839247454733]
	TIME [epoch: 7.56 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16392236522618456		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.16392236522618456 | validation: 0.2970814591574483]
	TIME [epoch: 7.59 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532648125459492		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.1532648125459492 | validation: 0.28315307976678195]
	TIME [epoch: 7.61 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15999205024498417		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.15999205024498417 | validation: 0.3035634424830519]
	TIME [epoch: 7.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16048380312374763		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.16048380312374763 | validation: 0.3039357123033668]
	TIME [epoch: 7.56 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645016243458603		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1645016243458603 | validation: 0.3193063936247714]
	TIME [epoch: 7.57 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360858680398415		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15360858680398415 | validation: 0.2874184283046037]
	TIME [epoch: 7.64 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15177678510680453		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.15177678510680453 | validation: 0.2742094236898549]
	TIME [epoch: 7.59 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16187581425467307		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.16187581425467307 | validation: 0.33007808927712207]
	TIME [epoch: 7.54 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732843993343356		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1732843993343356 | validation: 0.2887723440384246]
	TIME [epoch: 7.59 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16592868635957508		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.16592868635957508 | validation: 0.269832031869549]
	TIME [epoch: 7.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14619997919332567		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.14619997919332567 | validation: 0.3060368932758836]
	TIME [epoch: 7.59 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13971522644478576		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.13971522644478576 | validation: 0.3002653048382565]
	TIME [epoch: 7.55 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14331312836959686		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14331312836959686 | validation: 0.3271506251752682]
	TIME [epoch: 7.61 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14876094868791473		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.14876094868791473 | validation: 0.32728211772674115]
	TIME [epoch: 7.63 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15783625525002504		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15783625525002504 | validation: 0.3506763688823849]
	TIME [epoch: 7.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14446146501237345		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.14446146501237345 | validation: 0.2781200243692014]
	TIME [epoch: 7.56 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15977404620252722		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15977404620252722 | validation: 0.29019860802281217]
	TIME [epoch: 7.59 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14747297331745352		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.14747297331745352 | validation: 0.30836593429218867]
	TIME [epoch: 7.61 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14747735150048752		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.14747735150048752 | validation: 0.3050345515803799]
	TIME [epoch: 7.58 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14313371500939584		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.14313371500939584 | validation: 0.30992795565419484]
	TIME [epoch: 7.59 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15271222869814324		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15271222869814324 | validation: 0.30196324964748283]
	TIME [epoch: 7.62 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14996321305869945		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.14996321305869945 | validation: 0.2837038475935321]
	TIME [epoch: 7.63 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13664785587361622		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.13664785587361622 | validation: 0.3279620478402743]
	TIME [epoch: 7.59 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587171279714779		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.1587171279714779 | validation: 0.314396046301595]
	TIME [epoch: 7.57 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263483492957516		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15263483492957516 | validation: 0.28098215079430244]
	TIME [epoch: 7.59 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15588693298453274		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.15588693298453274 | validation: 0.34323598722441945]
	TIME [epoch: 7.62 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592366770718914		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.1592366770718914 | validation: 0.26691765811323637]
	TIME [epoch: 7.57 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15408186753404557		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.15408186753404557 | validation: 0.3423811156252399]
	TIME [epoch: 7.55 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16793407082900128		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.16793407082900128 | validation: 0.29908434239407256]
	TIME [epoch: 7.61 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583646133809991		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.1583646133809991 | validation: 0.30913778383591417]
	TIME [epoch: 7.63 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1480932406184467		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.1480932406184467 | validation: 0.2988868210905623]
	TIME [epoch: 7.58 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15630782331397935		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15630782331397935 | validation: 0.29973644606460786]
	TIME [epoch: 7.58 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14202421656995973		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.14202421656995973 | validation: 0.3133718868686744]
	TIME [epoch: 7.62 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14844045444380632		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.14844045444380632 | validation: 0.28623279828668585]
	TIME [epoch: 7.62 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16206265035260703		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.16206265035260703 | validation: 0.29548945616664696]
	TIME [epoch: 7.57 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15935352045379916		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.15935352045379916 | validation: 0.3136827250633071]
	TIME [epoch: 7.56 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15334250986162345		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15334250986162345 | validation: 0.3083975425056029]
	TIME [epoch: 7.62 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15317951750311304		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.15317951750311304 | validation: 0.28934771705347007]
	TIME [epoch: 7.63 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558652272077575		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.1558652272077575 | validation: 0.2917244780859705]
	TIME [epoch: 7.56 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13852030817590705		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.13852030817590705 | validation: 0.3056413039176111]
	TIME [epoch: 7.55 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14949844670890564		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.14949844670890564 | validation: 0.31788895454991223]
	TIME [epoch: 7.62 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459220523922145		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.1459220523922145 | validation: 0.3271062035112391]
	TIME [epoch: 7.62 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16401322173573965		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.16401322173573965 | validation: 0.2912507029130932]
	TIME [epoch: 7.57 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14625237145123102		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.14625237145123102 | validation: 0.28827150069731367]
	TIME [epoch: 7.55 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507188724853739		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1507188724853739 | validation: 0.3051923599093498]
	TIME [epoch: 7.61 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13361278414506372		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.13361278414506372 | validation: 0.3184610524456186]
	TIME [epoch: 7.63 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15147634502503032		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.15147634502503032 | validation: 0.2958225422144722]
	TIME [epoch: 7.55 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533021702615475		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.1533021702615475 | validation: 0.30808908906640936]
	TIME [epoch: 7.56 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1465656414780102		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1465656414780102 | validation: 0.29609902186706116]
	TIME [epoch: 7.61 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14735398124560375		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.14735398124560375 | validation: 0.30991339602736023]
	TIME [epoch: 7.61 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16321414305324336		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.16321414305324336 | validation: 0.2949344077463186]
	TIME [epoch: 7.55 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14879302270713712		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.14879302270713712 | validation: 0.302749004356233]
	TIME [epoch: 7.58 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15175594053136338		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.15175594053136338 | validation: 0.28471504838312184]
	TIME [epoch: 7.64 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16937543079883693		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.16937543079883693 | validation: 0.28657329989274416]
	TIME [epoch: 7.63 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14967280374554487		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.14967280374554487 | validation: 0.3136735702773199]
	TIME [epoch: 7.57 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518128360457921		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.1518128360457921 | validation: 0.2842486593958215]
	TIME [epoch: 7.55 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14733062030966967		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14733062030966967 | validation: 0.2926832160824149]
	TIME [epoch: 7.63 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15693853980457384		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15693853980457384 | validation: 0.3085177508367271]
	TIME [epoch: 7.59 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15968668108050438		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.15968668108050438 | validation: 0.2844078403172803]
	TIME [epoch: 7.58 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15338517526538625		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.15338517526538625 | validation: 0.2963210933145963]
	TIME [epoch: 7.57 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15665388470768588		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15665388470768588 | validation: 0.288813425697402]
	TIME [epoch: 7.63 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15559070112980217		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.15559070112980217 | validation: 0.3210952930247223]
	TIME [epoch: 7.62 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14111145777033585		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.14111145777033585 | validation: 0.30023801438514014]
	TIME [epoch: 7.56 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14802074373743718		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.14802074373743718 | validation: 0.265835365552059]
	TIME [epoch: 7.54 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14648055588935613		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.14648055588935613 | validation: 0.28537870447000696]
	TIME [epoch: 7.65 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527936456218952		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.1527936456218952 | validation: 0.327557778690517]
	TIME [epoch: 7.58 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655038574878538		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.1655038574878538 | validation: 0.2826432044938991]
	TIME [epoch: 7.55 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527707315425204		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1527707315425204 | validation: 0.29628646800728936]
	TIME [epoch: 7.56 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14104337867702682		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14104337867702682 | validation: 0.3077563809803349]
	TIME [epoch: 7.64 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14269755615053004		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.14269755615053004 | validation: 0.3017059913571237]
	TIME [epoch: 7.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15228959586212074		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.15228959586212074 | validation: 0.37791212423565596]
	TIME [epoch: 7.56 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636909791384337		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.15636909791384337 | validation: 0.3180583395454935]
	TIME [epoch: 7.55 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16032145017933286		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.16032145017933286 | validation: 0.3125767997867826]
	TIME [epoch: 7.62 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14215076525886236		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.14215076525886236 | validation: 0.3159368190226363]
	TIME [epoch: 7.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15662327058065967		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15662327058065967 | validation: 0.3086038895160423]
	TIME [epoch: 7.59 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16986811265740276		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.16986811265740276 | validation: 0.28950871852975935]
	TIME [epoch: 7.56 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13587656297872258		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.13587656297872258 | validation: 0.27364901905808325]
	TIME [epoch: 7.59 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15897394728460162		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15897394728460162 | validation: 0.26638184899020806]
	TIME [epoch: 7.58 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14755331021380375		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.14755331021380375 | validation: 0.32366939873277445]
	TIME [epoch: 7.55 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14756949749578227		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.14756949749578227 | validation: 0.29333857122977247]
	TIME [epoch: 7.58 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16105773935303366		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.16105773935303366 | validation: 0.2964645344094913]
	TIME [epoch: 7.62 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500387750304884		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1500387750304884 | validation: 0.3200508478807314]
	TIME [epoch: 7.58 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14761869488101353		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.14761869488101353 | validation: 0.28191807557626]
	TIME [epoch: 7.58 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14764976541916208		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.14764976541916208 | validation: 0.2979458897484217]
	TIME [epoch: 7.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15010469718167246		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15010469718167246 | validation: 0.3236855168608744]
	TIME [epoch: 7.62 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14725814469984283		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.14725814469984283 | validation: 0.27996142747670566]
	TIME [epoch: 7.58 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15849425994083594		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.15849425994083594 | validation: 0.28903428077549437]
	TIME [epoch: 7.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13949219613709277		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.13949219613709277 | validation: 0.28721965249801357]
	TIME [epoch: 7.58 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109290861912275		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.15109290861912275 | validation: 0.30410206027257336]
	TIME [epoch: 7.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15334552806170992		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15334552806170992 | validation: 0.3394068121368573]
	TIME [epoch: 7.58 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515539968367471		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1515539968367471 | validation: 0.2973304310442534]
	TIME [epoch: 7.57 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494048664750601		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.1494048664750601 | validation: 0.31458985798445865]
	TIME [epoch: 7.62 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15714282419832643		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15714282419832643 | validation: 0.304713055997045]
	TIME [epoch: 7.63 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108063832039225		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.17108063832039225 | validation: 0.2998117027141525]
	TIME [epoch: 7.57 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15460248596732723		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.15460248596732723 | validation: 0.28894831528247483]
	TIME [epoch: 7.57 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594016141425988		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.1594016141425988 | validation: 0.3171324001027438]
	TIME [epoch: 7.59 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1411905012159628		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1411905012159628 | validation: 0.3150398034418739]
	TIME [epoch: 7.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14840056919783703		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.14840056919783703 | validation: 0.31118903575178497]
	TIME [epoch: 7.57 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14890217390652233		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.14890217390652233 | validation: 0.28040282959361534]
	TIME [epoch: 7.55 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627267119629615		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.1627267119629615 | validation: 0.3023275270411241]
	TIME [epoch: 7.55 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14181476728170667		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14181476728170667 | validation: 0.3047460218455606]
	TIME [epoch: 7.56 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16504630996136244		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.16504630996136244 | validation: 0.2928744445989735]
	TIME [epoch: 7.56 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14594471198777495		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.14594471198777495 | validation: 0.2834305837255655]
	TIME [epoch: 7.57 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16187751013444623		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.16187751013444623 | validation: 0.3045082124764652]
	TIME [epoch: 7.57 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664013528858786		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.1664013528858786 | validation: 0.28102580663601956]
	TIME [epoch: 7.61 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15483682262861911		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.15483682262861911 | validation: 0.27779865765145506]
	TIME [epoch: 7.55 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072613154298399		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.16072613154298399 | validation: 0.3121077967596384]
	TIME [epoch: 7.56 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833683677259733		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.15833683677259733 | validation: 0.29741286262319055]
	TIME [epoch: 7.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14943974492948633		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.14943974492948633 | validation: 0.30482185507878756]
	TIME [epoch: 7.64 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16315075203424811		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.16315075203424811 | validation: 0.2708408348458981]
	TIME [epoch: 7.55 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14760253421303765		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.14760253421303765 | validation: 0.288780075718156]
	TIME [epoch: 7.55 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496839111067426		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1496839111067426 | validation: 0.2926543842182032]
	TIME [epoch: 7.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585386385460784		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1585386385460784 | validation: 0.3031693812975475]
	TIME [epoch: 7.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13901553508172046		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.13901553508172046 | validation: 0.27428032752408604]
	TIME [epoch: 7.58 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1662843575096596		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.1662843575096596 | validation: 0.2961853999091568]
	TIME [epoch: 7.56 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157375559846105		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.157375559846105 | validation: 0.3222237869108652]
	TIME [epoch: 7.61 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13084166620169657		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.13084166620169657 | validation: 0.2911448547923683]
	TIME [epoch: 7.63 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493855003767158		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.1493855003767158 | validation: 0.30455775588971024]
	TIME [epoch: 7.58 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15150016123403992		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.15150016123403992 | validation: 0.30574227197703635]
	TIME [epoch: 7.55 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1445627908625628		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.1445627908625628 | validation: 0.2713082396553752]
	TIME [epoch: 7.64 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16074136262412936		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.16074136262412936 | validation: 0.2695779065895159]
	TIME [epoch: 7.59 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559364822419696		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.1559364822419696 | validation: 0.28465611028490095]
	TIME [epoch: 7.57 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1502823569642046		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.1502823569642046 | validation: 0.2901740841335703]
	TIME [epoch: 7.56 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1403303421542807		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.1403303421542807 | validation: 0.3037483236250499]
	TIME [epoch: 7.64 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14185806457764977		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.14185806457764977 | validation: 0.3154111110058869]
	TIME [epoch: 7.62 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14651769563051542		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.14651769563051542 | validation: 0.30782652423359874]
	TIME [epoch: 7.59 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14647839913315092		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.14647839913315092 | validation: 0.2989393322667308]
	TIME [epoch: 7.58 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616221656134662		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.1616221656134662 | validation: 0.25540717379966693]
	TIME [epoch: 7.64 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17039753817439746		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.17039753817439746 | validation: 0.28899810727322617]
	TIME [epoch: 7.57 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16396218734177903		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.16396218734177903 | validation: 0.24953781699446928]
	TIME [epoch: 7.56 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17098240826348804		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.17098240826348804 | validation: 0.2739591234083516]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v5_20240712_121934/states/model_facs_v2_dec2b_2dpca_v5_650.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3198.295 seconds.
