Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v14', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v14', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1580791490

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8569787725308798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8569787725308798 | validation: 0.8389422696897103]
	TIME [epoch: 30.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6512361629996004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6512361629996004 | validation: 0.8608516920659293]
	TIME [epoch: 3.86 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520107823668018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6520107823668018 | validation: 0.7907051962478068]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269632625233281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6269632625233281 | validation: 1.0514808319735334]
	TIME [epoch: 3.84 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445754312766804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6445754312766804 | validation: 0.7833554532017308]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543670015597655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5543670015597655 | validation: 0.8186134016088418]
	TIME [epoch: 3.85 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033770033141745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5033770033141745 | validation: 0.716755604065294]
	TIME [epoch: 3.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458970707674374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5458970707674374 | validation: 0.7713853315040246]
	TIME [epoch: 3.84 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975606798393841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4975606798393841 | validation: 0.6809627403849732]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070720683796006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5070720683796006 | validation: 0.8388241252900224]
	TIME [epoch: 3.83 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388709183546694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4388709183546694 | validation: 0.6114240234314048]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4304098699894823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4304098699894823 | validation: 0.6947673065506964]
	TIME [epoch: 3.84 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401553786421172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.401553786421172 | validation: 0.7675262040333015]
	TIME [epoch: 3.83 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3940414933186366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3940414933186366 | validation: 0.608131390011633]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34542450449977513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34542450449977513 | validation: 0.6308086734953859]
	TIME [epoch: 3.85 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3834947035424928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3834947035424928 | validation: 0.5994543859061341]
	TIME [epoch: 3.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33617813744275105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33617813744275105 | validation: 0.5083123833730595]
	TIME [epoch: 3.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33272158843870875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33272158843870875 | validation: 0.6572701381284951]
	TIME [epoch: 3.83 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37030246157311797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37030246157311797 | validation: 0.5137047387535868]
	TIME [epoch: 3.83 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740594850596182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2740594850596182 | validation: 0.5206501641779067]
	TIME [epoch: 3.83 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29768861939121083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29768861939121083 | validation: 0.5492228966881176]
	TIME [epoch: 3.83 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983111526447982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2983111526447982 | validation: 0.5295564638770119]
	TIME [epoch: 3.83 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200649607662574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3200649607662574 | validation: 0.5683091127852847]
	TIME [epoch: 3.84 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439539193175273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3439539193175273 | validation: 0.44528683955339854]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049058472927817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3049058472927817 | validation: 0.4521220314724196]
	TIME [epoch: 3.84 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558343479394445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2558343479394445 | validation: 0.486129741242605]
	TIME [epoch: 3.83 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26949088711830904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26949088711830904 | validation: 0.43629499073182465]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26905492000318193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26905492000318193 | validation: 0.47304909191240413]
	TIME [epoch: 3.83 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994731203413014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2994731203413014 | validation: 0.5435346577027267]
	TIME [epoch: 3.83 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972431571672572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2972431571672572 | validation: 0.4496898512847971]
	TIME [epoch: 3.83 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26808586756966735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26808586756966735 | validation: 0.4580118178758205]
	TIME [epoch: 3.84 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23213020916713328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23213020916713328 | validation: 0.43187884215986905]
	TIME [epoch: 3.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28218126926576365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28218126926576365 | validation: 0.5139435060110829]
	TIME [epoch: 3.83 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299881596374296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.299881596374296 | validation: 0.5428686020433421]
	TIME [epoch: 3.83 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604454582800063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2604454582800063 | validation: 0.42173489285456534]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3715176275542392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3715176275542392 | validation: 0.4718618335623218]
	TIME [epoch: 3.83 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28592576707175915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28592576707175915 | validation: 0.48764283080173204]
	TIME [epoch: 3.83 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25757048055661386		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.25757048055661386 | validation: 0.4646637345548266]
	TIME [epoch: 3.83 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.277792430197749		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.277792430197749 | validation: 0.4243067181540216]
	TIME [epoch: 3.84 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29668481001665387		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.29668481001665387 | validation: 0.5430241304662531]
	TIME [epoch: 3.84 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28735811651014476		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.28735811651014476 | validation: 0.4274518807971269]
	TIME [epoch: 3.83 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690368175947454		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2690368175947454 | validation: 0.4437381320461583]
	TIME [epoch: 3.83 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22736080347057663		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.22736080347057663 | validation: 0.4059239957708787]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21917238914557763		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.21917238914557763 | validation: 0.6238078978164858]
	TIME [epoch: 3.83 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30523698337709926		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.30523698337709926 | validation: 0.4481438943580619]
	TIME [epoch: 3.83 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23666051167664612		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.23666051167664612 | validation: 0.5138781679264316]
	TIME [epoch: 3.83 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980820878837141		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2980820878837141 | validation: 0.41781707774596777]
	TIME [epoch: 3.84 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23964076460041395		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.23964076460041395 | validation: 0.41790013957787653]
	TIME [epoch: 3.84 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19646065574919594		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.19646065574919594 | validation: 0.39914352691298305]
	TIME [epoch: 3.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515513154251443		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2515513154251443 | validation: 0.44284559432185]
	TIME [epoch: 3.84 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24982723870309773		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.24982723870309773 | validation: 0.4165090796991429]
	TIME [epoch: 31.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256339859990969		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.256339859990969 | validation: 0.4062670113407968]
	TIME [epoch: 7.39 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23964789716357265		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.23964789716357265 | validation: 0.4928576697534682]
	TIME [epoch: 7.37 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262786628695195		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.262786628695195 | validation: 0.4020993455912607]
	TIME [epoch: 7.37 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2286318760164639		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2286318760164639 | validation: 0.6964584374804595]
	TIME [epoch: 7.39 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28312274709574853		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.28312274709574853 | validation: 0.3920580220197981]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19688404338999677		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.19688404338999677 | validation: 0.42155417636432446]
	TIME [epoch: 7.38 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861614788322114		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.2861614788322114 | validation: 0.3915924253023705]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20834450064745463		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.20834450064745463 | validation: 0.39698029960169967]
	TIME [epoch: 7.37 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22390684094766747		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.22390684094766747 | validation: 0.4269184489152004]
	TIME [epoch: 7.38 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594934267480823		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2594934267480823 | validation: 0.41186243858916877]
	TIME [epoch: 7.37 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23080900408423216		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.23080900408423216 | validation: 0.44020284278146626]
	TIME [epoch: 7.36 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24020863392497493		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.24020863392497493 | validation: 0.3894253599681765]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24191879749566964		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.24191879749566964 | validation: 0.37750785317201163]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23886888994500122		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.23886888994500122 | validation: 0.39909462870791995]
	TIME [epoch: 7.37 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22385507746856453		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.22385507746856453 | validation: 0.40911548728692493]
	TIME [epoch: 7.37 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24549302024817313		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.24549302024817313 | validation: 0.45137554589137324]
	TIME [epoch: 7.37 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22463281307201113		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.22463281307201113 | validation: 0.4043657032528178]
	TIME [epoch: 7.36 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23889070267370147		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.23889070267370147 | validation: 0.48408734325057173]
	TIME [epoch: 7.38 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627529043368945		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.2627529043368945 | validation: 0.42209697845238053]
	TIME [epoch: 7.37 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549949279172651		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.2549949279172651 | validation: 0.4359847917188481]
	TIME [epoch: 7.37 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589900787511643		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.2589900787511643 | validation: 0.4168128775746682]
	TIME [epoch: 7.37 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24100378360407615		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24100378360407615 | validation: 0.39923491352010304]
	TIME [epoch: 7.37 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24760390758665463		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.24760390758665463 | validation: 0.4100376683354929]
	TIME [epoch: 7.38 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18667689949832117		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.18667689949832117 | validation: 0.3869255086845664]
	TIME [epoch: 7.37 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22546255314893138		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22546255314893138 | validation: 0.537025074603506]
	TIME [epoch: 7.36 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20935697137780662		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.20935697137780662 | validation: 0.40285717970735674]
	TIME [epoch: 7.37 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22904948289221108		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.22904948289221108 | validation: 0.45606647116243826]
	TIME [epoch: 7.37 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24951762736150684		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.24951762736150684 | validation: 0.39391094370692004]
	TIME [epoch: 7.38 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22200297783423323		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.22200297783423323 | validation: 0.5017112568737602]
	TIME [epoch: 7.37 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23813874220814318		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.23813874220814318 | validation: 0.40175944939845354]
	TIME [epoch: 7.36 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17199107329996824		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.17199107329996824 | validation: 0.43859760193245106]
	TIME [epoch: 7.36 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24488404104541656		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.24488404104541656 | validation: 0.39681906797990546]
	TIME [epoch: 7.37 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.246589730843502		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.246589730843502 | validation: 0.45119924664327726]
	TIME [epoch: 7.37 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24344213723433591		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.24344213723433591 | validation: 0.3645526787730239]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19919059885349977		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.19919059885349977 | validation: 0.37616025195435115]
	TIME [epoch: 7.37 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2152239316326373		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.2152239316326373 | validation: 0.40612931336037417]
	TIME [epoch: 7.37 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21631634303676814		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.21631634303676814 | validation: 0.3646853908689558]
	TIME [epoch: 7.38 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21984207991613047		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.21984207991613047 | validation: 0.4008657048869193]
	TIME [epoch: 7.37 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19717758978170816		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.19717758978170816 | validation: 0.4009525194107561]
	TIME [epoch: 7.36 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22778088039536704		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.22778088039536704 | validation: 0.49107890591200154]
	TIME [epoch: 7.36 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954014174095712		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.1954014174095712 | validation: 0.3975324371853839]
	TIME [epoch: 7.37 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19693481002943078		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.19693481002943078 | validation: 0.38944420942118085]
	TIME [epoch: 7.38 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17399412574410333		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.17399412574410333 | validation: 0.40818907939097926]
	TIME [epoch: 7.36 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142700680923274		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.21142700680923274 | validation: 0.34214639340002384]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20399090005253584		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.20399090005253584 | validation: 0.42637517532253627]
	TIME [epoch: 7.37 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198687612630732		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.2198687612630732 | validation: 0.3375696004094524]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20285948247705637		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.20285948247705637 | validation: 0.42259672612508087]
	TIME [epoch: 7.38 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22096764795297688		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.22096764795297688 | validation: 0.36423449674891495]
	TIME [epoch: 7.36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984537686331696		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1984537686331696 | validation: 0.3803173981520655]
	TIME [epoch: 7.36 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19921819301116023		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.19921819301116023 | validation: 0.36023304583526455]
	TIME [epoch: 7.38 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18765295618970235		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.18765295618970235 | validation: 0.463967426183692]
	TIME [epoch: 7.38 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694886906974948		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.2694886906974948 | validation: 0.6544122125167774]
	TIME [epoch: 7.37 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158775499288535		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.3158775499288535 | validation: 0.3588931713354419]
	TIME [epoch: 7.37 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192553881023643		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.192553881023643 | validation: 0.3364630131380624]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20990806692455508		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.20990806692455508 | validation: 0.42288091971897906]
	TIME [epoch: 7.38 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20334537055508256		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.20334537055508256 | validation: 0.4283564880043954]
	TIME [epoch: 7.39 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18794479737833167		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.18794479737833167 | validation: 0.42020065037565496]
	TIME [epoch: 7.37 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19267795731800252		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.19267795731800252 | validation: 0.4427007036493666]
	TIME [epoch: 7.37 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128590529792566		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.19128590529792566 | validation: 0.36898736217836725]
	TIME [epoch: 7.37 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19727992701772323		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19727992701772323 | validation: 0.37687241416041806]
	TIME [epoch: 7.37 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936090940697498		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.1936090940697498 | validation: 0.41395716007954625]
	TIME [epoch: 7.37 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23170951956240304		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.23170951956240304 | validation: 0.3382609742504905]
	TIME [epoch: 7.37 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875776011840138		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.1875776011840138 | validation: 0.38678598787660134]
	TIME [epoch: 7.37 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865508696052477		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1865508696052477 | validation: 0.3433555456910567]
	TIME [epoch: 7.36 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17437001875785862		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.17437001875785862 | validation: 0.35933982437686895]
	TIME [epoch: 7.37 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21992801378053378		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.21992801378053378 | validation: 0.4825848524088383]
	TIME [epoch: 7.37 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24504395752511893		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.24504395752511893 | validation: 0.39296923386161453]
	TIME [epoch: 7.36 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821011421544234		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1821011421544234 | validation: 0.36047764454384273]
	TIME [epoch: 7.36 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16310716481803972		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.16310716481803972 | validation: 0.3259374626166071]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20142150457868638		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20142150457868638 | validation: 0.3426889233365289]
	TIME [epoch: 7.39 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118588597507605		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.2118588597507605 | validation: 0.39172055668308925]
	TIME [epoch: 7.38 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17781717597975322		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.17781717597975322 | validation: 0.30958090181821873]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128197704083975		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.17128197704083975 | validation: 0.32330574265427275]
	TIME [epoch: 7.38 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20012444584431943		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.20012444584431943 | validation: 0.33959524263730856]
	TIME [epoch: 7.38 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17836136122463883		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.17836136122463883 | validation: 0.36927528030862367]
	TIME [epoch: 7.38 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22071355911068022		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.22071355911068022 | validation: 0.3413366628797117]
	TIME [epoch: 7.37 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164205808634511		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.164205808634511 | validation: 0.30223843408539175]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2289804979021964		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.2289804979021964 | validation: 0.4726190826481774]
	TIME [epoch: 7.38 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247180052019061		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.247180052019061 | validation: 0.5403330066193616]
	TIME [epoch: 7.38 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20757338176358642		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.20757338176358642 | validation: 0.32347321411702606]
	TIME [epoch: 7.38 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16940563938439523		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.16940563938439523 | validation: 0.3327925296402952]
	TIME [epoch: 7.37 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19676159776843108		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.19676159776843108 | validation: 0.40966875384736695]
	TIME [epoch: 7.37 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647981794288821		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.1647981794288821 | validation: 0.41139203486642195]
	TIME [epoch: 7.37 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23038110644816912		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.23038110644816912 | validation: 0.33614296561401324]
	TIME [epoch: 7.38 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915923515575169		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1915923515575169 | validation: 0.32649377487449455]
	TIME [epoch: 7.38 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812405570284646		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1812405570284646 | validation: 0.3950463434223456]
	TIME [epoch: 7.37 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19054518659930922		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.19054518659930922 | validation: 0.3267668427709374]
	TIME [epoch: 7.37 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16950349496695213		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.16950349496695213 | validation: 0.33147120067572816]
	TIME [epoch: 7.37 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17770969479730334		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.17770969479730334 | validation: 0.3670952238270746]
	TIME [epoch: 7.38 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19053196201866246		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.19053196201866246 | validation: 0.43738520303571865]
	TIME [epoch: 7.37 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25010879897381433		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.25010879897381433 | validation: 0.3705045854932281]
	TIME [epoch: 7.37 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337502524784828		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.20337502524784828 | validation: 0.3244245359808391]
	TIME [epoch: 7.37 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18489895969247572		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.18489895969247572 | validation: 0.37646156595755925]
	TIME [epoch: 7.38 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195097810020034		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.195097810020034 | validation: 0.31311159808496375]
	TIME [epoch: 7.38 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17244610943827876		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.17244610943827876 | validation: 0.3185462802960705]
	TIME [epoch: 7.38 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248658790965234		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.2248658790965234 | validation: 0.3206304250931984]
	TIME [epoch: 7.37 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866663839848882		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.18866663839848882 | validation: 0.3605907549951728]
	TIME [epoch: 7.38 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1831847939644461		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1831847939644461 | validation: 0.3627595629010256]
	TIME [epoch: 7.39 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910183768048858		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.15910183768048858 | validation: 0.4194634563747287]
	TIME [epoch: 7.38 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17870819257285955		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.17870819257285955 | validation: 0.5079511810184693]
	TIME [epoch: 7.37 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19978269856766986		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.19978269856766986 | validation: 0.31022353711021805]
	TIME [epoch: 7.37 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15760076248466626		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.15760076248466626 | validation: 0.3823390690513905]
	TIME [epoch: 7.37 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20938081733694788		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.20938081733694788 | validation: 0.34820706696930037]
	TIME [epoch: 7.37 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558287561212962		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.17558287561212962 | validation: 0.3631926453901442]
	TIME [epoch: 7.37 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960658030164139		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1960658030164139 | validation: 0.3597853966448218]
	TIME [epoch: 7.37 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18994841951261396		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.18994841951261396 | validation: 0.43755171908128637]
	TIME [epoch: 7.37 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19689977071010578		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.19689977071010578 | validation: 0.3262907718960456]
	TIME [epoch: 7.39 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682162805001585		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1682162805001585 | validation: 0.31271909508334617]
	TIME [epoch: 7.37 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15676259425979194		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.15676259425979194 | validation: 0.4470154363984128]
	TIME [epoch: 7.37 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17743635433431687		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.17743635433431687 | validation: 0.35771034858500034]
	TIME [epoch: 7.38 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19427023266215904		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.19427023266215904 | validation: 0.36038418642783565]
	TIME [epoch: 7.38 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18291443214991623		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18291443214991623 | validation: 0.5150902566820985]
	TIME [epoch: 7.38 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212446354466676		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.212446354466676 | validation: 0.5676350382639663]
	TIME [epoch: 7.37 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18076732575307736		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.18076732575307736 | validation: 0.35960713912330594]
	TIME [epoch: 7.37 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16347945967432342		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.16347945967432342 | validation: 0.3464075758786041]
	TIME [epoch: 7.37 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17138432039063436		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.17138432039063436 | validation: 0.4598640925761003]
	TIME [epoch: 7.38 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691477889716275		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.1691477889716275 | validation: 0.4418495104216717]
	TIME [epoch: 7.38 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20752629467031697		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.20752629467031697 | validation: 0.3715229726460543]
	TIME [epoch: 7.37 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24601787260665303		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.24601787260665303 | validation: 0.480044841369149]
	TIME [epoch: 7.37 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24827807391558998		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.24827807391558998 | validation: 0.5558613048742556]
	TIME [epoch: 7.37 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18823138511107393		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.18823138511107393 | validation: 0.3242791937758249]
	TIME [epoch: 7.38 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17385542194615938		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.17385542194615938 | validation: 0.34274709053049823]
	TIME [epoch: 7.37 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17057242936975778		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.17057242936975778 | validation: 0.32959096648420744]
	TIME [epoch: 7.36 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16342563346709235		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.16342563346709235 | validation: 0.3914900908515185]
	TIME [epoch: 7.37 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891488830064829		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1891488830064829 | validation: 0.42320818962919177]
	TIME [epoch: 7.38 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18223717671293965		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.18223717671293965 | validation: 0.3599630483608184]
	TIME [epoch: 7.37 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17168122299994992		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.17168122299994992 | validation: 0.3158363089613369]
	TIME [epoch: 7.37 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17680938853965997		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.17680938853965997 | validation: 0.3414833157684737]
	TIME [epoch: 7.36 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18030958387354337		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.18030958387354337 | validation: 0.3246946397065399]
	TIME [epoch: 7.37 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19438276368210397		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.19438276368210397 | validation: 0.338794019632279]
	TIME [epoch: 7.38 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21699088289848012		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.21699088289848012 | validation: 0.5030236396274128]
	TIME [epoch: 7.37 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19752500218105315		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.19752500218105315 | validation: 0.4148812555498385]
	TIME [epoch: 7.37 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17719966837560852		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.17719966837560852 | validation: 0.35281517857137495]
	TIME [epoch: 7.37 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841308653626951		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1841308653626951 | validation: 0.3108772069374987]
	TIME [epoch: 7.38 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16060494437826173		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.16060494437826173 | validation: 0.2937236521924369]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16801797975540225		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.16801797975540225 | validation: 0.2907770966600775]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15434959041955895		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.15434959041955895 | validation: 0.30168859821819854]
	TIME [epoch: 7.37 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16166701032321487		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.16166701032321487 | validation: 0.3147068286768315]
	TIME [epoch: 7.38 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16517793500558783		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16517793500558783 | validation: 0.34556790216471106]
	TIME [epoch: 7.38 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16194294268354392		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.16194294268354392 | validation: 0.49107640440145744]
	TIME [epoch: 7.37 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16546177611460566		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16546177611460566 | validation: 0.39087165801228047]
	TIME [epoch: 7.37 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19263863791261635		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.19263863791261635 | validation: 0.30860782037910794]
	TIME [epoch: 7.37 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544394913284373		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1544394913284373 | validation: 0.3146932554773216]
	TIME [epoch: 7.38 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14840536719292838		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.14840536719292838 | validation: 0.2975955503262139]
	TIME [epoch: 7.37 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928966773744606		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.14928966773744606 | validation: 0.3023102508498906]
	TIME [epoch: 7.37 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556072176171283		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.1556072176171283 | validation: 0.31245496728822736]
	TIME [epoch: 7.37 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17749364167172269		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.17749364167172269 | validation: 0.32025345910280434]
	TIME [epoch: 7.37 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17870461499368928		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.17870461499368928 | validation: 0.31253059234917524]
	TIME [epoch: 7.38 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1881861893494767		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1881861893494767 | validation: 0.3362894194593155]
	TIME [epoch: 7.37 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15892166867816682		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.15892166867816682 | validation: 0.3327040069646764]
	TIME [epoch: 7.37 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17079858339565604		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.17079858339565604 | validation: 0.31347593818905]
	TIME [epoch: 7.36 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13357408594723538		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.13357408594723538 | validation: 0.3520386842894842]
	TIME [epoch: 7.38 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17814116095952512		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.17814116095952512 | validation: 0.3484655363362149]
	TIME [epoch: 7.37 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16223239850621632		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.16223239850621632 | validation: 0.39927265705441184]
	TIME [epoch: 7.36 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711680698225968		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.1711680698225968 | validation: 0.3110874737287654]
	TIME [epoch: 7.36 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15065962931035004		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15065962931035004 | validation: 0.35802017797117713]
	TIME [epoch: 7.37 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17125675399255944		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.17125675399255944 | validation: 0.32895832495550964]
	TIME [epoch: 7.38 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14207218509910874		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.14207218509910874 | validation: 0.35140558885406536]
	TIME [epoch: 7.37 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515051886014534		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1515051886014534 | validation: 0.43518211539461205]
	TIME [epoch: 7.36 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826299869171376		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1826299869171376 | validation: 0.32234271204462056]
	TIME [epoch: 7.37 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15799617667689755		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15799617667689755 | validation: 0.3237554930084484]
	TIME [epoch: 7.38 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17045787726904732		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.17045787726904732 | validation: 0.3323429819925798]
	TIME [epoch: 7.37 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529874614852246		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.15529874614852246 | validation: 0.33747307248747144]
	TIME [epoch: 7.36 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16541966655848905		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.16541966655848905 | validation: 0.3237929517677494]
	TIME [epoch: 7.36 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17141684555635306		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.17141684555635306 | validation: 0.3487724438290021]
	TIME [epoch: 7.37 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19021793577055016		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.19021793577055016 | validation: 0.32732214610778615]
	TIME [epoch: 7.38 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14510780262444253		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.14510780262444253 | validation: 0.33929995462809515]
	TIME [epoch: 7.36 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16981893505884266		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.16981893505884266 | validation: 0.3458703110631801]
	TIME [epoch: 7.36 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16508821752853936		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.16508821752853936 | validation: 0.29977610998948384]
	TIME [epoch: 7.37 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538038747258097		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.17538038747258097 | validation: 0.34408918140007094]
	TIME [epoch: 7.38 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16736778891839932		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.16736778891839932 | validation: 0.33699955325544056]
	TIME [epoch: 7.37 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15201459546711962		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.15201459546711962 | validation: 0.31069996543031286]
	TIME [epoch: 7.37 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15431262270974047		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.15431262270974047 | validation: 0.38129995524663124]
	TIME [epoch: 7.37 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623096078974985		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.1623096078974985 | validation: 0.3606965253890846]
	TIME [epoch: 7.37 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15688138208447433		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.15688138208447433 | validation: 0.3421159859175662]
	TIME [epoch: 7.38 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18895922569725107		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.18895922569725107 | validation: 0.33039939373555516]
	TIME [epoch: 7.37 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15213646081454138		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.15213646081454138 | validation: 0.2940817906643471]
	TIME [epoch: 7.37 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155600550273298		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.155600550273298 | validation: 0.35771435550610664]
	TIME [epoch: 7.37 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15836366107688352		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15836366107688352 | validation: 0.3738983442559781]
	TIME [epoch: 7.37 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15878601422585986		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.15878601422585986 | validation: 0.31851424323826283]
	TIME [epoch: 7.37 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18970558567671714		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.18970558567671714 | validation: 0.4166637159144126]
	TIME [epoch: 7.37 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801917598972974		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.1801917598972974 | validation: 0.4270765275023254]
	TIME [epoch: 7.37 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19351702608893678		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.19351702608893678 | validation: 0.32631417766463855]
	TIME [epoch: 7.36 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582330460355009		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1582330460355009 | validation: 0.3061445969226291]
	TIME [epoch: 7.38 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15550390929442856		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.15550390929442856 | validation: 0.32142179171585783]
	TIME [epoch: 7.37 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15124446878491413		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15124446878491413 | validation: 0.3825227041071033]
	TIME [epoch: 7.36 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16301245825429092		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.16301245825429092 | validation: 0.2941369346615709]
	TIME [epoch: 7.37 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590376135706703		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1590376135706703 | validation: 0.29527395361889164]
	TIME [epoch: 7.37 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15948107146312251		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.15948107146312251 | validation: 0.3130692368904585]
	TIME [epoch: 7.37 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17644219352399523		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17644219352399523 | validation: 0.3131510694467727]
	TIME [epoch: 7.37 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14477660747592402		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.14477660747592402 | validation: 0.33071831077698016]
	TIME [epoch: 7.36 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629851692232618		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.1629851692232618 | validation: 0.30619053812690605]
	TIME [epoch: 7.36 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643217081916849		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.1643217081916849 | validation: 0.39816410559419935]
	TIME [epoch: 7.38 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15399734217973624		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.15399734217973624 | validation: 0.3093493800889192]
	TIME [epoch: 7.37 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15960216727247828		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.15960216727247828 | validation: 0.3085576256356764]
	TIME [epoch: 7.36 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14723663652041719		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.14723663652041719 | validation: 0.3657801711425611]
	TIME [epoch: 7.37 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1902267223763075		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.1902267223763075 | validation: 0.3383428040621045]
	TIME [epoch: 7.37 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15227898335700496		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.15227898335700496 | validation: 0.30355488975658523]
	TIME [epoch: 7.38 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16773171247477117		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.16773171247477117 | validation: 0.32500204304487085]
	TIME [epoch: 7.36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13778012951762764		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.13778012951762764 | validation: 0.38038634434301566]
	TIME [epoch: 7.36 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17272451482085946		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.17272451482085946 | validation: 0.32136455742450903]
	TIME [epoch: 7.37 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610011559335457		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.1610011559335457 | validation: 0.3274833772939041]
	TIME [epoch: 7.38 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13842419117841573		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.13842419117841573 | validation: 0.32948642684910046]
	TIME [epoch: 7.37 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599852422210866		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1599852422210866 | validation: 0.35443698482720465]
	TIME [epoch: 7.37 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777645802817006		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1777645802817006 | validation: 0.30149392054919416]
	TIME [epoch: 7.37 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16038781179904366		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.16038781179904366 | validation: 0.32838404782585445]
	TIME [epoch: 7.37 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16983425770651187		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.16983425770651187 | validation: 0.355932788049846]
	TIME [epoch: 7.38 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15068744431025405		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.15068744431025405 | validation: 0.3414665737828971]
	TIME [epoch: 7.37 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16633632520676836		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.16633632520676836 | validation: 0.33615838934320597]
	TIME [epoch: 7.37 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530084122088974		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.1530084122088974 | validation: 0.3239010427751856]
	TIME [epoch: 7.37 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163981904334484		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.163981904334484 | validation: 0.32337222833952645]
	TIME [epoch: 7.38 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417221559823085		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1417221559823085 | validation: 0.3551063189573043]
	TIME [epoch: 7.37 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16006868858144485		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.16006868858144485 | validation: 0.2912661730225489]
	TIME [epoch: 7.38 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16568302236279492		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.16568302236279492 | validation: 0.3021447191715065]
	TIME [epoch: 7.37 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15994693041720504		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.15994693041720504 | validation: 0.34119263191552884]
	TIME [epoch: 7.37 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14916756110731255		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.14916756110731255 | validation: 0.3126085470461742]
	TIME [epoch: 7.38 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14559366421645725		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.14559366421645725 | validation: 0.331728149653017]
	TIME [epoch: 7.37 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17481620437689183		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.17481620437689183 | validation: 0.3116442349600481]
	TIME [epoch: 7.37 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17207104418793723		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.17207104418793723 | validation: 0.32493183175087953]
	TIME [epoch: 7.37 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506838222233478		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1506838222233478 | validation: 0.320950014093064]
	TIME [epoch: 7.38 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296044790954267		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.16296044790954267 | validation: 0.34269789151555247]
	TIME [epoch: 7.37 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14812039793714146		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.14812039793714146 | validation: 0.3603543876480914]
	TIME [epoch: 7.37 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16200777664040467		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.16200777664040467 | validation: 0.3308267347757262]
	TIME [epoch: 7.36 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15003526005229292		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.15003526005229292 | validation: 0.2928385828170362]
	TIME [epoch: 7.37 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15112930173076108		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.15112930173076108 | validation: 0.32819109186561146]
	TIME [epoch: 7.38 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150984443012701		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.150984443012701 | validation: 0.3608431519355078]
	TIME [epoch: 7.37 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19126751819310217		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.19126751819310217 | validation: 0.3408975988322252]
	TIME [epoch: 7.37 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555509134059908		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.1555509134059908 | validation: 0.3005037986019224]
	TIME [epoch: 7.37 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15095451237676005		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.15095451237676005 | validation: 0.29960967867650273]
	TIME [epoch: 7.38 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374532084474201		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1374532084474201 | validation: 0.3279427005595109]
	TIME [epoch: 7.38 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15135799379311787		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.15135799379311787 | validation: 0.2924530003273745]
	TIME [epoch: 7.37 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15174711738436275		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.15174711738436275 | validation: 0.3110278724360868]
	TIME [epoch: 7.37 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16824660810996928		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.16824660810996928 | validation: 0.3071964099461153]
	TIME [epoch: 7.37 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16180885575595758		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.16180885575595758 | validation: 0.37310449314433525]
	TIME [epoch: 7.39 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351734259102808		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.14351734259102808 | validation: 0.3057276724416587]
	TIME [epoch: 7.37 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705485288418988		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1705485288418988 | validation: 0.2951962661915149]
	TIME [epoch: 7.37 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483265889638365		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.15483265889638365 | validation: 0.3261446209021036]
	TIME [epoch: 7.37 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401918367140897		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.13401918367140897 | validation: 0.36015945710203223]
	TIME [epoch: 7.38 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16629249363504012		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.16629249363504012 | validation: 0.31115327368549206]
	TIME [epoch: 7.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15146595327337659		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.15146595327337659 | validation: 0.32123652652388845]
	TIME [epoch: 7.43 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500383441172953		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1500383441172953 | validation: 0.31132785131506896]
	TIME [epoch: 7.39 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16389776520050445		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.16389776520050445 | validation: 0.28943008101122913]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16426804976430237		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.16426804976430237 | validation: 0.33544327315582856]
	TIME [epoch: 7.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14588859215194536		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.14588859215194536 | validation: 0.3095686784140555]
	TIME [epoch: 7.38 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13073062317167217		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.13073062317167217 | validation: 0.30258131217459305]
	TIME [epoch: 7.38 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435554624186875		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.1435554624186875 | validation: 0.2975403519942531]
	TIME [epoch: 7.38 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474697754661465		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.1474697754661465 | validation: 0.3033763140322213]
	TIME [epoch: 7.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13382990084718913		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.13382990084718913 | validation: 0.3873924908090649]
	TIME [epoch: 7.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326888781021405		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.14326888781021405 | validation: 0.3046166799480421]
	TIME [epoch: 7.39 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424703286986263		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1424703286986263 | validation: 0.3429294854502859]
	TIME [epoch: 7.39 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16757242063676583		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.16757242063676583 | validation: 0.3186972790651983]
	TIME [epoch: 7.38 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928530815290575		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.14928530815290575 | validation: 0.30978110911759976]
	TIME [epoch: 7.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14848982356528723		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14848982356528723 | validation: 0.2986746985728584]
	TIME [epoch: 7.38 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16851060192672798		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.16851060192672798 | validation: 0.3138265644848572]
	TIME [epoch: 7.38 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927945022316313		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.13927945022316313 | validation: 0.3385844447032489]
	TIME [epoch: 7.39 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13098749835561563		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.13098749835561563 | validation: 0.3084717911553906]
	TIME [epoch: 7.39 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13588957849085861		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.13588957849085861 | validation: 0.31788477555313754]
	TIME [epoch: 7.39 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14358228985024973		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14358228985024973 | validation: 0.3089892465447591]
	TIME [epoch: 7.39 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16486507110153165		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.16486507110153165 | validation: 0.35210750725778417]
	TIME [epoch: 7.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13526231080654041		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.13526231080654041 | validation: 0.3062470479183195]
	TIME [epoch: 7.39 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371825978816453		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.15371825978816453 | validation: 0.3380058167718088]
	TIME [epoch: 7.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18487504361417934		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.18487504361417934 | validation: 0.3636435522752471]
	TIME [epoch: 7.39 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14577290110435293		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.14577290110435293 | validation: 0.3166186151955588]
	TIME [epoch: 7.38 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541600062058704		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.1541600062058704 | validation: 0.3422908078397845]
	TIME [epoch: 7.38 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15546591566547918		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15546591566547918 | validation: 0.343477032819866]
	TIME [epoch: 7.37 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14714745530505183		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.14714745530505183 | validation: 0.29805811703949825]
	TIME [epoch: 7.39 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142366876359636		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.142366876359636 | validation: 0.32253964169283406]
	TIME [epoch: 7.38 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453113725748656		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1453113725748656 | validation: 0.3211708045405779]
	TIME [epoch: 7.38 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14831416415671475		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.14831416415671475 | validation: 0.3031663441815071]
	TIME [epoch: 7.37 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14297212141795201		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.14297212141795201 | validation: 0.29084317336201554]
	TIME [epoch: 7.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14940257832109374		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.14940257832109374 | validation: 0.3314843098884216]
	TIME [epoch: 7.39 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649880825928715		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.16649880825928715 | validation: 0.31258093745406895]
	TIME [epoch: 7.39 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13920964823984344		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13920964823984344 | validation: 0.3201445642084605]
	TIME [epoch: 7.39 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14261831440923456		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.14261831440923456 | validation: 0.3040124065366052]
	TIME [epoch: 7.39 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13492429195131364		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.13492429195131364 | validation: 0.30220601793853974]
	TIME [epoch: 7.39 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847130072153275		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.14847130072153275 | validation: 0.31885970648318573]
	TIME [epoch: 7.38 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132194966942493		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.14132194966942493 | validation: 0.3718543591729596]
	TIME [epoch: 7.38 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15666873215336707		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.15666873215336707 | validation: 0.29071388429450407]
	TIME [epoch: 7.38 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15352989408655907		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.15352989408655907 | validation: 0.3474862451258351]
	TIME [epoch: 7.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088775443758567		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.15088775443758567 | validation: 0.2972982926369405]
	TIME [epoch: 7.38 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321741576922374		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.15321741576922374 | validation: 0.2882996687504112]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15779435245095075		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.15779435245095075 | validation: 0.3042598880774427]
	TIME [epoch: 7.39 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228954402445843		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.15228954402445843 | validation: 0.3162366575028566]
	TIME [epoch: 7.41 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14107739367393185		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.14107739367393185 | validation: 0.3280445325823091]
	TIME [epoch: 7.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475998123281695		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.1475998123281695 | validation: 0.3304623010952687]
	TIME [epoch: 7.39 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148353620734135		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.148353620734135 | validation: 0.36468462618824316]
	TIME [epoch: 7.38 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17342882270066112		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.17342882270066112 | validation: 0.3025550492205471]
	TIME [epoch: 7.38 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16616101755213164		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.16616101755213164 | validation: 0.29878650837910925]
	TIME [epoch: 7.39 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388467307073255		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.1388467307073255 | validation: 0.32488215329391434]
	TIME [epoch: 7.38 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204811942411914		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.15204811942411914 | validation: 0.322397908859084]
	TIME [epoch: 7.38 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611044877013129		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1611044877013129 | validation: 0.3977404033093858]
	TIME [epoch: 7.38 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15422372807466922		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.15422372807466922 | validation: 0.29760932576196436]
	TIME [epoch: 7.39 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600180407564578		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1600180407564578 | validation: 0.33353164386706663]
	TIME [epoch: 7.41 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472521355625197		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.13472521355625197 | validation: 0.31828860243213875]
	TIME [epoch: 7.38 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15912765267295018		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15912765267295018 | validation: 0.2883442100730384]
	TIME [epoch: 7.38 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17660213545545406		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.17660213545545406 | validation: 0.3291374442327398]
	TIME [epoch: 7.38 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17976250945371575		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.17976250945371575 | validation: 0.33788887101215587]
	TIME [epoch: 7.39 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16004935650222113		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.16004935650222113 | validation: 0.31708497797616325]
	TIME [epoch: 7.39 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15912884709160938		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.15912884709160938 | validation: 0.3105307323127186]
	TIME [epoch: 7.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13757330272156365		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13757330272156365 | validation: 0.3102702322459341]
	TIME [epoch: 7.39 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436934085593424		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12436934085593424 | validation: 0.30404846312445544]
	TIME [epoch: 7.38 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1742376964861715		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.1742376964861715 | validation: 0.33928598417544464]
	TIME [epoch: 7.39 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13922443557292374		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.13922443557292374 | validation: 0.31268652312682516]
	TIME [epoch: 7.37 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13484868436395447		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.13484868436395447 | validation: 0.28779668694513094]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14007342514674298		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.14007342514674298 | validation: 0.3087900508477896]
	TIME [epoch: 7.39 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335473363692691		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1335473363692691 | validation: 0.3007679511119258]
	TIME [epoch: 7.39 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702795737279008		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.1702795737279008 | validation: 0.34928025795527]
	TIME [epoch: 7.38 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19087051670431654		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.19087051670431654 | validation: 0.3065364213644636]
	TIME [epoch: 7.38 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14441512595588696		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.14441512595588696 | validation: 0.33350428156094053]
	TIME [epoch: 7.41 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673097539599378		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.14673097539599378 | validation: 0.32999165882874754]
	TIME [epoch: 7.38 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876503959366		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.14876503959366 | validation: 0.31131522798466604]
	TIME [epoch: 7.39 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141731905032352		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.15141731905032352 | validation: 0.3071703306382645]
	TIME [epoch: 7.38 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16812902460392984		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.16812902460392984 | validation: 0.2967040189941893]
	TIME [epoch: 7.38 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204815780029678		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.12204815780029678 | validation: 0.2932935996010335]
	TIME [epoch: 7.39 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14822965119947887		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.14822965119947887 | validation: 0.29619557155168186]
	TIME [epoch: 7.41 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468678055358061		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1468678055358061 | validation: 0.32319304287365835]
	TIME [epoch: 7.39 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203220799548877		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.14203220799548877 | validation: 0.31760435102377427]
	TIME [epoch: 7.39 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844251862413903		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13844251862413903 | validation: 0.313288974136514]
	TIME [epoch: 7.38 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304332288686552		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13304332288686552 | validation: 0.3094593545364989]
	TIME [epoch: 7.38 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521429249280236		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1521429249280236 | validation: 0.2966784465792038]
	TIME [epoch: 7.39 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14768819560241586		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.14768819560241586 | validation: 0.3285594693457604]
	TIME [epoch: 7.37 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463485403219411		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.1463485403219411 | validation: 0.2920323576469499]
	TIME [epoch: 7.37 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14226624419881773		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.14226624419881773 | validation: 0.321126705981749]
	TIME [epoch: 7.39 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506765606935886		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1506765606935886 | validation: 0.29381623072186414]
	TIME [epoch: 7.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14436887856617842		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14436887856617842 | validation: 0.30190081292812165]
	TIME [epoch: 7.39 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15150385699779692		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.15150385699779692 | validation: 0.3171682109911017]
	TIME [epoch: 7.38 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13509628712537106		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.13509628712537106 | validation: 0.33298715061434725]
	TIME [epoch: 7.39 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16287502580548394		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.16287502580548394 | validation: 0.3240893282836402]
	TIME [epoch: 7.39 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13518416718176626		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.13518416718176626 | validation: 0.3405837199105996]
	TIME [epoch: 7.41 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592011417212137		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.1592011417212137 | validation: 0.34033837193905253]
	TIME [epoch: 7.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632174571490673		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.15632174571490673 | validation: 0.2865689805592999]
	TIME [epoch: 7.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15892718504742842		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.15892718504742842 | validation: 0.32323843632500476]
	TIME [epoch: 7.38 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14956280714080888		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.14956280714080888 | validation: 0.30805104090444974]
	TIME [epoch: 7.39 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13243172388342503		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13243172388342503 | validation: 0.2788502961187121]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14323079113439016		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.14323079113439016 | validation: 0.29418736843134397]
	TIME [epoch: 7.38 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13780441983517167		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.13780441983517167 | validation: 0.3351587197600819]
	TIME [epoch: 7.38 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13444871690561272		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13444871690561272 | validation: 0.3134901575538629]
	TIME [epoch: 7.39 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14296526149724156		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.14296526149724156 | validation: 0.314185435612156]
	TIME [epoch: 7.38 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147807600783328		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.147807600783328 | validation: 0.32576930098072415]
	TIME [epoch: 7.42 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14319112718963495		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.14319112718963495 | validation: 0.28392810234810806]
	TIME [epoch: 7.37 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464844627318353		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1464844627318353 | validation: 0.3314747683924477]
	TIME [epoch: 7.36 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14849782237544773		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.14849782237544773 | validation: 0.3129196985836088]
	TIME [epoch: 7.39 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14792967608657856		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.14792967608657856 | validation: 0.3106669491521968]
	TIME [epoch: 7.42 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561608584931355		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12561608584931355 | validation: 0.2907270196236867]
	TIME [epoch: 7.39 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375380318057115		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.14375380318057115 | validation: 0.31252699835593023]
	TIME [epoch: 7.37 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962222901481704		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12962222901481704 | validation: 0.3266754307111448]
	TIME [epoch: 7.37 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761747849443403		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.15761747849443403 | validation: 0.3010461959421569]
	TIME [epoch: 7.39 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515891824590614		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.1515891824590614 | validation: 0.28495325187548676]
	TIME [epoch: 7.38 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13893456127551523		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13893456127551523 | validation: 0.29304856029886733]
	TIME [epoch: 7.37 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707852014152178		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.14707852014152178 | validation: 0.2990423043323349]
	TIME [epoch: 7.39 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518107667155513		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.16518107667155513 | validation: 0.28340024421275484]
	TIME [epoch: 7.41 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600858757690691		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.1600858757690691 | validation: 0.3174370750946159]
	TIME [epoch: 7.39 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14937108060746734		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.14937108060746734 | validation: 0.27320828419996984]
	TIME [epoch: 7.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13222938114733668		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.13222938114733668 | validation: 0.2949486240720771]
	TIME [epoch: 7.38 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191666632552304		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.13191666632552304 | validation: 0.32912075711807615]
	TIME [epoch: 7.38 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130014154106808		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.15130014154106808 | validation: 0.3028461922085252]
	TIME [epoch: 7.39 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14671442828401904		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.14671442828401904 | validation: 0.32095583689740814]
	TIME [epoch: 7.38 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15074377894696278		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.15074377894696278 | validation: 0.30284146098592796]
	TIME [epoch: 7.39 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13900163963016188		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.13900163963016188 | validation: 0.31473701232875134]
	TIME [epoch: 7.39 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13382061888984792		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.13382061888984792 | validation: 0.3108489237651235]
	TIME [epoch: 7.39 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962673042544058		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.13962673042544058 | validation: 0.3070166379899846]
	TIME [epoch: 7.39 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16905116042709753		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.16905116042709753 | validation: 0.3206305571555444]
	TIME [epoch: 7.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351302958266411		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1351302958266411 | validation: 0.2999932107505328]
	TIME [epoch: 7.39 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754420398860392		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13754420398860392 | validation: 0.30303821846432155]
	TIME [epoch: 7.39 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12903991204164733		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.12903991204164733 | validation: 0.33704905511586125]
	TIME [epoch: 7.41 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14350828086241524		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.14350828086241524 | validation: 0.3163310619923411]
	TIME [epoch: 7.39 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583792894613062		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.14583792894613062 | validation: 0.33391538540155796]
	TIME [epoch: 7.38 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162704106672674		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.13162704106672674 | validation: 0.28040576169042225]
	TIME [epoch: 7.38 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712731419478982		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.13712731419478982 | validation: 0.2919481549478837]
	TIME [epoch: 7.39 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12302489566185235		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12302489566185235 | validation: 0.30689619329401985]
	TIME [epoch: 7.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584329445647784		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1584329445647784 | validation: 0.30390222652636917]
	TIME [epoch: 7.38 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14195276742563154		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.14195276742563154 | validation: 0.29348894745710297]
	TIME [epoch: 7.37 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737392095997824		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.12737392095997824 | validation: 0.2911162758388878]
	TIME [epoch: 7.39 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293609966934673		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1293609966934673 | validation: 0.2906730316328218]
	TIME [epoch: 7.39 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13473973353263646		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.13473973353263646 | validation: 0.32461418687051496]
	TIME [epoch: 7.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14697226773063984		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.14697226773063984 | validation: 0.30815324325034255]
	TIME [epoch: 7.39 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14395859298168345		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.14395859298168345 | validation: 0.30204877897278004]
	TIME [epoch: 7.39 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261530538175311		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1261530538175311 | validation: 0.2961792992433372]
	TIME [epoch: 7.39 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13797436184012243		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.13797436184012243 | validation: 0.3020753460456657]
	TIME [epoch: 7.39 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14140141927954894		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.14140141927954894 | validation: 0.30909067344158975]
	TIME [epoch: 7.39 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297372913186158		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.15297372913186158 | validation: 0.27526921999152726]
	TIME [epoch: 7.38 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401720548165161		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1401720548165161 | validation: 0.30182187982225717]
	TIME [epoch: 7.38 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18515027752071242		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.18515027752071242 | validation: 0.3200824419940919]
	TIME [epoch: 7.39 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14259975204994454		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.14259975204994454 | validation: 0.3041658831309253]
	TIME [epoch: 7.39 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527046915993723		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.13527046915993723 | validation: 0.32987597473376856]
	TIME [epoch: 7.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421678888240904		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.13421678888240904 | validation: 0.3073301137942952]
	TIME [epoch: 7.39 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14825296536137594		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.14825296536137594 | validation: 0.29521727173798135]
	TIME [epoch: 7.39 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410652802367404		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.1410652802367404 | validation: 0.3212663065161592]
	TIME [epoch: 7.39 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14317837332754346		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14317837332754346 | validation: 0.2882975536412959]
	TIME [epoch: 7.38 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15866883473572552		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.15866883473572552 | validation: 0.31600570936178213]
	TIME [epoch: 7.38 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15727062190183289		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.15727062190183289 | validation: 0.30329972794260796]
	TIME [epoch: 7.37 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14130979958799272		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.14130979958799272 | validation: 0.2884390162759416]
	TIME [epoch: 7.39 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13511527942322102		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.13511527942322102 | validation: 0.2950023341649056]
	TIME [epoch: 7.39 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13597748149013666		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.13597748149013666 | validation: 0.29417241217888723]
	TIME [epoch: 7.39 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17290898287452272		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.17290898287452272 | validation: 0.33093425380461106]
	TIME [epoch: 7.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14666853184161277		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.14666853184161277 | validation: 0.30709027738846706]
	TIME [epoch: 7.39 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293240955003606		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.12293240955003606 | validation: 0.3102416747011465]
	TIME [epoch: 7.39 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154341311895769		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.154341311895769 | validation: 0.2903844599950447]
	TIME [epoch: 7.39 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15355944292342977		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.15355944292342977 | validation: 0.3230703752832554]
	TIME [epoch: 7.38 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914335035208436		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.13914335035208436 | validation: 0.27967704077014294]
	TIME [epoch: 7.38 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286436939692029		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.12286436939692029 | validation: 0.29346506116290694]
	TIME [epoch: 7.42 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15648593314470538		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.15648593314470538 | validation: 0.3046956404003374]
	TIME [epoch: 7.39 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15596958688224777		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.15596958688224777 | validation: 0.2918859876446141]
	TIME [epoch: 7.38 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13461226557578748		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.13461226557578748 | validation: 0.3305655063003503]
	TIME [epoch: 7.37 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12408940667135408		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12408940667135408 | validation: 0.30609860079434664]
	TIME [epoch: 7.38 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14087009112796484		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.14087009112796484 | validation: 0.28567448765067716]
	TIME [epoch: 7.39 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586164793546718		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1586164793546718 | validation: 0.31035950110336513]
	TIME [epoch: 7.38 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16433511093221465		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.16433511093221465 | validation: 0.34309970790181166]
	TIME [epoch: 7.37 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13043806224520002		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13043806224520002 | validation: 0.2906534965331573]
	TIME [epoch: 7.39 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503769659390249		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1503769659390249 | validation: 0.30568289320439923]
	TIME [epoch: 7.41 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15688948258350843		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.15688948258350843 | validation: 0.3226014345211454]
	TIME [epoch: 7.38 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235305605460682		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.1235305605460682 | validation: 0.3003117898635885]
	TIME [epoch: 7.38 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163386252110075		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.163386252110075 | validation: 0.2799158286853025]
	TIME [epoch: 7.38 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312511801046641		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.1312511801046641 | validation: 0.31612747376372935]
	TIME [epoch: 7.38 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15646822330761523		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15646822330761523 | validation: 0.28246531130247304]
	TIME [epoch: 7.39 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13739980904591712		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.13739980904591712 | validation: 0.29472925898601643]
	TIME [epoch: 7.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14680345392465965		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.14680345392465965 | validation: 0.3207052909084412]
	TIME [epoch: 7.38 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16496033445832706		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.16496033445832706 | validation: 0.31006834897166885]
	TIME [epoch: 7.38 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13720078223629242		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.13720078223629242 | validation: 0.292660278052649]
	TIME [epoch: 7.38 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12922139912871433		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.12922139912871433 | validation: 0.3011371673219698]
	TIME [epoch: 7.38 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373456822141625		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.1373456822141625 | validation: 0.3009323586114438]
	TIME [epoch: 7.38 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348546229097539		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.1348546229097539 | validation: 0.294812099070655]
	TIME [epoch: 7.37 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11771017336264136		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.11771017336264136 | validation: 0.30200113513072613]
	TIME [epoch: 7.38 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12794672733771828		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.12794672733771828 | validation: 0.2906346302963969]
	TIME [epoch: 7.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879511534543612		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.13879511534543612 | validation: 0.2941457759321084]
	TIME [epoch: 7.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115538053138782		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.14115538053138782 | validation: 0.32556605097403396]
	TIME [epoch: 7.38 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120891627686701		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.120891627686701 | validation: 0.3036169162696071]
	TIME [epoch: 7.37 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385313255160625		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.1385313255160625 | validation: 0.3220782775014505]
	TIME [epoch: 7.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186048443454487		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.13186048443454487 | validation: 0.3067651453850625]
	TIME [epoch: 7.39 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461339150787741		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1461339150787741 | validation: 0.27372940308094246]
	TIME [epoch: 7.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14081475186783046		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.14081475186783046 | validation: 0.31161688532437376]
	TIME [epoch: 7.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13049982437612961		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.13049982437612961 | validation: 0.29985268753977856]
	TIME [epoch: 7.39 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499291309622173		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.14499291309622173 | validation: 0.29480821031041843]
	TIME [epoch: 7.39 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353055422083389		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.1353055422083389 | validation: 0.3348331793457328]
	TIME [epoch: 7.38 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13524309049260153		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.13524309049260153 | validation: 0.2909022326024394]
	TIME [epoch: 7.38 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15641508481394778		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.15641508481394778 | validation: 0.2993734569004685]
	TIME [epoch: 7.38 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14058324261794047		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.14058324261794047 | validation: 0.30704396283787966]
	TIME [epoch: 7.39 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13504572545974822		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.13504572545974822 | validation: 0.2854964076497371]
	TIME [epoch: 7.38 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015180761233599		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.12015180761233599 | validation: 0.2955866099762695]
	TIME [epoch: 7.39 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481986378496441		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.1481986378496441 | validation: 0.3212367002437269]
	TIME [epoch: 7.41 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14180297518287785		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.14180297518287785 | validation: 0.31051266415421597]
	TIME [epoch: 7.37 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13187802922167408		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.13187802922167408 | validation: 0.29198690652490455]
	TIME [epoch: 7.38 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14645280164310642		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.14645280164310642 | validation: 0.27559694463319306]
	TIME [epoch: 7.37 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112250925798014		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.13112250925798014 | validation: 0.32026384470578645]
	TIME [epoch: 7.37 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910286848555974		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.12910286848555974 | validation: 0.29884072279512325]
	TIME [epoch: 7.37 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15083064217433714		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.15083064217433714 | validation: 0.2925629930261926]
	TIME [epoch: 7.38 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12788842996472638		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.12788842996472638 | validation: 0.3180838747866499]
	TIME [epoch: 7.37 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12895772659765695		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.12895772659765695 | validation: 0.29069868136474925]
	TIME [epoch: 7.37 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446705069257509		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.12446705069257509 | validation: 0.3147445492039984]
	TIME [epoch: 7.37 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11919156406978991		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.11919156406978991 | validation: 0.29566231164623785]
	TIME [epoch: 40.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271816591476333		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.1271816591476333 | validation: 0.319772779139033]
	TIME [epoch: 16 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655564024842028		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.1655564024842028 | validation: 0.30228050369778503]
	TIME [epoch: 16 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14989756466379006		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.14989756466379006 | validation: 0.3161197001128313]
	TIME [epoch: 16 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13798702270704216		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.13798702270704216 | validation: 0.3037090991773185]
	TIME [epoch: 16 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813723037189264		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.14813723037189264 | validation: 0.30250404623841975]
	TIME [epoch: 16 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624479204415121		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.1624479204415121 | validation: 0.29692854884861863]
	TIME [epoch: 16 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939916344637466		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.14939916344637466 | validation: 0.2831407907251753]
	TIME [epoch: 16 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14839615231408582		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.14839615231408582 | validation: 0.3052822784157622]
	TIME [epoch: 16 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168699951173712		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.13168699951173712 | validation: 0.3229096765825608]
	TIME [epoch: 16 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13613251262597448		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.13613251262597448 | validation: 0.2947968926797201]
	TIME [epoch: 16 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390641273747571		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1390641273747571 | validation: 0.30090143262785096]
	TIME [epoch: 15.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15078304547424143		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.15078304547424143 | validation: 0.2967405212336576]
	TIME [epoch: 16 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14849091211777735		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.14849091211777735 | validation: 0.28980393583373654]
	TIME [epoch: 16 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16456458323777234		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.16456458323777234 | validation: 0.3095482070927547]
	TIME [epoch: 16 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883160899834005		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.14883160899834005 | validation: 0.29795374453541384]
	TIME [epoch: 16 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13074638327560648		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.13074638327560648 | validation: 0.30277168653628644]
	TIME [epoch: 16 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15402865051591477		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.15402865051591477 | validation: 0.2963663542273085]
	TIME [epoch: 16 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096576918961531		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.14096576918961531 | validation: 0.31987743024455656]
	TIME [epoch: 16 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318790829325982		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1318790829325982 | validation: 0.2940931772200099]
	TIME [epoch: 16 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12691115691539598		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.12691115691539598 | validation: 0.3042848910516799]
	TIME [epoch: 16 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12517500121480912		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.12517500121480912 | validation: 0.3103237112195978]
	TIME [epoch: 16 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291469496707905		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1291469496707905 | validation: 0.2948011941206074]
	TIME [epoch: 16 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15555549479976377		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.15555549479976377 | validation: 0.28510356718986263]
	TIME [epoch: 16 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390612642682502		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.1390612642682502 | validation: 0.30293382162996624]
	TIME [epoch: 16 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13221844305751765		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.13221844305751765 | validation: 0.31455914333360413]
	TIME [epoch: 16 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212003119632282		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.13212003119632282 | validation: 0.28625382064511046]
	TIME [epoch: 16 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388401578687338		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1388401578687338 | validation: 0.326988145415551]
	TIME [epoch: 16 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365889033359651		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1365889033359651 | validation: 0.2932892767000574]
	TIME [epoch: 16 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364834918432077		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.1364834918432077 | validation: 0.3279242470793907]
	TIME [epoch: 16 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182829697689252		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.13182829697689252 | validation: 0.29726997393658666]
	TIME [epoch: 16 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559546511341142		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.1559546511341142 | validation: 0.3142943418274484]
	TIME [epoch: 16 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362008657128464		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.1362008657128464 | validation: 0.2884881430496189]
	TIME [epoch: 16 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16321877356845088		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.16321877356845088 | validation: 0.31648074927495473]
	TIME [epoch: 16 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337111996180176		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.1337111996180176 | validation: 0.2964812138027095]
	TIME [epoch: 16 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335027815199704		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.13335027815199704 | validation: 0.3109945966154353]
	TIME [epoch: 16 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12382726829255677		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.12382726829255677 | validation: 0.3089258508820123]
	TIME [epoch: 16 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731700119345285		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.12731700119345285 | validation: 0.2827512877070778]
	TIME [epoch: 16 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415173476443921		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.1415173476443921 | validation: 0.3068666232702276]
	TIME [epoch: 16 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183184506446845		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.12183184506446845 | validation: 0.29275980852249933]
	TIME [epoch: 16 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689917936687146		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.13689917936687146 | validation: 0.29100241661949067]
	TIME [epoch: 16 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393821507788132		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.1393821507788132 | validation: 0.2959602280702843]
	TIME [epoch: 16 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13701017141933589		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.13701017141933589 | validation: 0.29132087559090336]
	TIME [epoch: 16 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16301540265712744		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.16301540265712744 | validation: 0.3217383781436819]
	TIME [epoch: 16 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13284139080475987		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.13284139080475987 | validation: 0.300150680542281]
	TIME [epoch: 16 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251845617963537		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.12251845617963537 | validation: 0.30924154795369646]
	TIME [epoch: 16 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269655116657055		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.1269655116657055 | validation: 0.2993583500447632]
	TIME [epoch: 15.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13307868410823992		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.13307868410823992 | validation: 0.3161538683080052]
	TIME [epoch: 15.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180829244382232		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.12180829244382232 | validation: 0.2810268131395876]
	TIME [epoch: 15.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13615131705950417		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.13615131705950417 | validation: 0.3115410580966767]
	TIME [epoch: 16 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819280499990826		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.12819280499990826 | validation: 0.30197360556479513]
	TIME [epoch: 16 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132126138363948		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.132126138363948 | validation: 0.29049285382850687]
	TIME [epoch: 16 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311339296420155		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.1311339296420155 | validation: 0.3029802925773749]
	TIME [epoch: 16 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14667055805762752		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.14667055805762752 | validation: 0.31650683464303]
	TIME [epoch: 16 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257901156795531		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.1257901156795531 | validation: 0.2799523701290261]
	TIME [epoch: 16 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625642137340292		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.14625642137340292 | validation: 0.3022894492370042]
	TIME [epoch: 16 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122051264780622		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.14122051264780622 | validation: 0.2936134340983705]
	TIME [epoch: 16 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396935843659041		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.1396935843659041 | validation: 0.291280872874776]
	TIME [epoch: 16 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12702646745359852		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.12702646745359852 | validation: 0.28997744141667303]
	TIME [epoch: 16 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13995469829514975		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.13995469829514975 | validation: 0.2912651803772684]
	TIME [epoch: 16 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282318854649714		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.14282318854649714 | validation: 0.2875347381938689]
	TIME [epoch: 16 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12090056945330693		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12090056945330693 | validation: 0.30483767428655884]
	TIME [epoch: 16 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17420654605191466		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.17420654605191466 | validation: 0.32005634804100136]
	TIME [epoch: 16 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14284741002769594		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.14284741002769594 | validation: 0.30194762767536965]
	TIME [epoch: 16 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132534155563709		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.14132534155563709 | validation: 0.29020445745577284]
	TIME [epoch: 16 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14796536099359467		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.14796536099359467 | validation: 0.29476445064089024]
	TIME [epoch: 16 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378843919912187		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.13378843919912187 | validation: 0.3099515337092726]
	TIME [epoch: 16 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12841761366376772		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.12841761366376772 | validation: 0.297145983354495]
	TIME [epoch: 16 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13370283603511274		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.13370283603511274 | validation: 0.29505408543489026]
	TIME [epoch: 16 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785019666543729		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.11785019666543729 | validation: 0.30015668075751645]
	TIME [epoch: 15.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417977445204949		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1417977445204949 | validation: 0.3059314839588143]
	TIME [epoch: 16 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168438531996007		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.13168438531996007 | validation: 0.29495287500067374]
	TIME [epoch: 16 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15326428278344878		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.15326428278344878 | validation: 0.2930125885511667]
	TIME [epoch: 16 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298799413584883		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.1298799413584883 | validation: 0.2983924702796929]
	TIME [epoch: 16 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12755645117158843		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.12755645117158843 | validation: 0.31143026042145616]
	TIME [epoch: 16 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14869813661137143		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.14869813661137143 | validation: 0.3060766859371038]
	TIME [epoch: 16 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14322815384249285		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.14322815384249285 | validation: 0.3025049057747968]
	TIME [epoch: 16 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13016781176968095		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.13016781176968095 | validation: 0.30180605913724307]
	TIME [epoch: 16 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13283735038536937		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.13283735038536937 | validation: 0.313896591834764]
	TIME [epoch: 16 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13765305746262296		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.13765305746262296 | validation: 0.29764387530381325]
	TIME [epoch: 16 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11378425386959094		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.11378425386959094 | validation: 0.3084626227975396]
	TIME [epoch: 16 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304957992081013		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.14304957992081013 | validation: 0.2797117427863105]
	TIME [epoch: 15.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15540145350460674		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.15540145350460674 | validation: 0.31431313850644327]
	TIME [epoch: 16 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237358588862268		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.12237358588862268 | validation: 0.2925976839449055]
	TIME [epoch: 16 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14433182893421215		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.14433182893421215 | validation: 0.2881311119479457]
	TIME [epoch: 16 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390832016481376		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1390832016481376 | validation: 0.2921047446114545]
	TIME [epoch: 16 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16837675859505535		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.16837675859505535 | validation: 0.32086563127042644]
	TIME [epoch: 16 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13858906637689639		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.13858906637689639 | validation: 0.2954475753181313]
	TIME [epoch: 16 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470579359366733		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.1470579359366733 | validation: 0.30182223603557096]
	TIME [epoch: 16 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14108778174608902		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.14108778174608902 | validation: 0.28781221469344587]
	TIME [epoch: 16 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591557542054826		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.12591557542054826 | validation: 0.29705952770452976]
	TIME [epoch: 15.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253584032296485		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.1253584032296485 | validation: 0.3030625663578035]
	TIME [epoch: 16 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344701751716524		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.14344701751716524 | validation: 0.29257631212426266]
	TIME [epoch: 16 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14382578622136352		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.14382578622136352 | validation: 0.3214098985714728]
	TIME [epoch: 16 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13309538491326353		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.13309538491326353 | validation: 0.2970340159596351]
	TIME [epoch: 16 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458440120378639		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.12458440120378639 | validation: 0.30911379325505944]
	TIME [epoch: 16 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157156532973685		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.13157156532973685 | validation: 0.29291454101037334]
	TIME [epoch: 16 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13026760958484931		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.13026760958484931 | validation: 0.318743956186199]
	TIME [epoch: 16 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861694282944652		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.12861694282944652 | validation: 0.31147658588879845]
	TIME [epoch: 15.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693413582216922		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.14693413582216922 | validation: 0.2875793086425212]
	TIME [epoch: 15.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16131531200635388		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.16131531200635388 | validation: 0.2950190109205355]
	TIME [epoch: 16.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12570353732459988		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.12570353732459988 | validation: 0.31328851595890966]
	TIME [epoch: 15.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13873376798874276		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.13873376798874276 | validation: 0.30743736649862685]
	TIME [epoch: 15.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14202580343855875		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.14202580343855875 | validation: 0.2867871883255576]
	TIME [epoch: 15.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14864996538388014		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.14864996538388014 | validation: 0.2917745217275742]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14_20240716_201117/states/model_facs_v3_dec2b_2dpca_v14_605.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 5308.701 seconds.
