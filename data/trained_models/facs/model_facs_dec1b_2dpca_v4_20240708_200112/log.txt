Args:
Namespace(name='model_facs_dec1b_2dpca_v4', outdir='out/model_training/model_facs_dec1b_2dpca_v4', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=1000, ncells_sample=1000, model_do_sample=False, dt=0.001, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2228064997

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7052819238462726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7052819238462726 | validation: 1.0716674683189285]
	TIME [epoch: 137 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1094352211709513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1094352211709513 | validation: 1.4559965875536827]
	TIME [epoch: 98.8 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2097012389820063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2097012389820063 | validation: 0.937419872787706]
	TIME [epoch: 98.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0754273514661543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0754273514661543 | validation: 0.902837101695025]
	TIME [epoch: 98.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0331920686288223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0331920686288223 | validation: 1.080692184726847]
	TIME [epoch: 98.7 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0405810504859898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0405810504859898 | validation: 0.8217003453445013]
	TIME [epoch: 98.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9538488408604242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9538488408604242 | validation: 0.9067273865352187]
	TIME [epoch: 98.8 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9371976065160593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9371976065160593 | validation: 1.034207188779862]
	TIME [epoch: 98.8 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9050017092834898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9050017092834898 | validation: 0.7433519273036779]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.864863694209975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.864863694209975 | validation: 0.7330998046324343]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.833531764140585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.833531764140585 | validation: 0.7981709691203027]
	TIME [epoch: 98.8 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7735782385680644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7735782385680644 | validation: 0.694244155139512]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.68592915815031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.68592915815031 | validation: 0.8097011246064356]
	TIME [epoch: 98.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7365551760900618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7365551760900618 | validation: 0.8712021895002632]
	TIME [epoch: 98.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7233953038515726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7233953038515726 | validation: 0.5896402624408322]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6688327070158497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6688327070158497 | validation: 1.052329356529641]
	TIME [epoch: 98.9 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7302527365608664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7302527365608664 | validation: 0.5120875939815115]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.591986187762643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.591986187762643 | validation: 0.5273531563383366]
	TIME [epoch: 98.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7228845076135948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7228845076135948 | validation: 0.5525012366296872]
	TIME [epoch: 98.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5406966793464236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5406966793464236 | validation: 0.7346638080080173]
	TIME [epoch: 98.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.653154500862062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.653154500862062 | validation: 0.5241010143672797]
	TIME [epoch: 98.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5408776724081857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5408776724081857 | validation: 0.6459941462437646]
	TIME [epoch: 98.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6469768372997455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6469768372997455 | validation: 0.4935655934970753]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5392222185966653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5392222185966653 | validation: 0.7254136134222515]
	TIME [epoch: 98.4 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5535632464390929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5535632464390929 | validation: 0.5221924532917525]
	TIME [epoch: 98.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6592337408134017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6592337408134017 | validation: 0.45947571435304263]
	TIME [epoch: 98.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5245951452696541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5245951452696541 | validation: 0.4834625912796219]
	TIME [epoch: 98.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4751791376600926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4751791376600926 | validation: 0.6039110099594241]
	TIME [epoch: 98.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6452634036400464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6452634036400464 | validation: 0.5326240611587124]
	TIME [epoch: 98.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5191799673226375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5191799673226375 | validation: 0.5252029807133249]
	TIME [epoch: 98.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.536130229677049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.536130229677049 | validation: 0.4918065844580896]
	TIME [epoch: 98.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4886435387598343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4886435387598343 | validation: 0.5431383568269598]
	TIME [epoch: 98.4 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48879972133219013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48879972133219013 | validation: 0.595566192725138]
	TIME [epoch: 98.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.55166727136645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.55166727136645 | validation: 0.6469454484941414]
	TIME [epoch: 98.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5686321280000366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5686321280000366 | validation: 0.5633597509171542]
	TIME [epoch: 98.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5016686825637099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5016686825637099 | validation: 0.47326549053609945]
	TIME [epoch: 98.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5250710709639486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5250710709639486 | validation: 0.6247080177434524]
	TIME [epoch: 98.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5049446331025383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049446331025383 | validation: 0.47184449178453436]
	TIME [epoch: 98.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46279672123477145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46279672123477145 | validation: 0.4680409562343765]
	TIME [epoch: 98.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48866292477460266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48866292477460266 | validation: 0.6559573091253108]
	TIME [epoch: 98.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5089688303743011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5089688303743011 | validation: 0.5428492666104383]
	TIME [epoch: 98.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5162321543386149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5162321543386149 | validation: 0.44316986482766685]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44330477388369094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44330477388369094 | validation: 0.5185532647574906]
	TIME [epoch: 98.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48768291622379567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48768291622379567 | validation: 0.3958695954848305]
	TIME [epoch: 98.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4726458907090796		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4726458907090796 | validation: 0.4682691872769061]
	TIME [epoch: 98.4 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47848696251822226		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.47848696251822226 | validation: 0.4872222910658478]
	TIME [epoch: 98.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49475957867200143		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.49475957867200143 | validation: 0.5536079190107112]
	TIME [epoch: 98.4 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45750748144871767		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.45750748144871767 | validation: 0.4940764978936308]
	TIME [epoch: 98.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4767512670492461		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.4767512670492461 | validation: 0.48236543367687856]
	TIME [epoch: 98.3 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4938442511414901		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.4938442511414901 | validation: 0.45521344387016915]
	TIME [epoch: 98.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42619996943896415		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.42619996943896415 | validation: 0.38601333879766037]
	TIME [epoch: 98.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40768764032387		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.40768764032387 | validation: 0.42471936400979826]
	TIME [epoch: 98.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4787976471606994		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.4787976471606994 | validation: 0.4617931495435383]
	TIME [epoch: 98.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44814864918532316		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.44814864918532316 | validation: 0.5601929814585526]
	TIME [epoch: 98.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4453638586437919		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.4453638586437919 | validation: 0.42262423254154646]
	TIME [epoch: 98.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4378574142854508		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4378574142854508 | validation: 0.4068714898123317]
	TIME [epoch: 98.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4424502824000135		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.4424502824000135 | validation: 0.4000745040265765]
	TIME [epoch: 98.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42640986228991185		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.42640986228991185 | validation: 0.40549474296918087]
	TIME [epoch: 98.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4194611882137875		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.4194611882137875 | validation: 0.4660612824470034]
	TIME [epoch: 98.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42425204399376654		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.42425204399376654 | validation: 0.4976236260342512]
	TIME [epoch: 98.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42290452455507155		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.42290452455507155 | validation: 0.3843370760367484]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4351313762340499		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.4351313762340499 | validation: 0.3864042643924762]
	TIME [epoch: 98.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44892550628145955		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.44892550628145955 | validation: 0.4580852528324367]
	TIME [epoch: 98.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4192873379913645		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.4192873379913645 | validation: 0.39695723468416055]
	TIME [epoch: 98.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41802690127341124		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.41802690127341124 | validation: 0.3796483686229781]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3946458855388938		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3946458855388938 | validation: 0.518897129280817]
	TIME [epoch: 98.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4348523700597482		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.4348523700597482 | validation: 0.3749291972027291]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39278623897004356		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.39278623897004356 | validation: 0.4001117331787138]
	TIME [epoch: 98.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4383815691820397		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.4383815691820397 | validation: 0.445102235044167]
	TIME [epoch: 98.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43490243139651824		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.43490243139651824 | validation: 0.42510052439906393]
	TIME [epoch: 98.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46526213016018797		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.46526213016018797 | validation: 0.4278987367432059]
	TIME [epoch: 98.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45456625336579237		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.45456625336579237 | validation: 0.40542998582075407]
	TIME [epoch: 98.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39665150148308675		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.39665150148308675 | validation: 0.4617089135789113]
	TIME [epoch: 98.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3874558721662325		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.3874558721662325 | validation: 0.4309922301935535]
	TIME [epoch: 98.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4158687228254689		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.4158687228254689 | validation: 0.4201061630256312]
	TIME [epoch: 98.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39667346936652936		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.39667346936652936 | validation: 0.3947026241164807]
	TIME [epoch: 98.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39918777452809584		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.39918777452809584 | validation: 0.3870818635922123]
	TIME [epoch: 98.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38621204911262424		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.38621204911262424 | validation: 0.41564986289896294]
	TIME [epoch: 98.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41114712025909683		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.41114712025909683 | validation: 0.40559517756964175]
	TIME [epoch: 98.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3664793633651955		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3664793633651955 | validation: 0.4017677706453756]
	TIME [epoch: 98.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3992335988827614		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.3992335988827614 | validation: 0.3666712057876256]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3996522766458555		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3996522766458555 | validation: 0.36472960268693905]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3689532552205171		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.3689532552205171 | validation: 0.37289732442786494]
	TIME [epoch: 98.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39169568262465604		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.39169568262465604 | validation: 0.40579736768743685]
	TIME [epoch: 98.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3642963270422794		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3642963270422794 | validation: 0.42238349978266737]
	TIME [epoch: 98.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38287314706346964		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.38287314706346964 | validation: 0.36341588574325284]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38483589029260606		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.38483589029260606 | validation: 0.3884753577580512]
	TIME [epoch: 98.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38495898914944493		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.38495898914944493 | validation: 0.3598817985665076]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36733229146838114		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.36733229146838114 | validation: 0.4134655558518171]
	TIME [epoch: 98.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3734701816823734		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3734701816823734 | validation: 0.40523058425299807]
	TIME [epoch: 98.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39338276867457744		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.39338276867457744 | validation: 0.3838907668992767]
	TIME [epoch: 98.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3549623257664701		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.3549623257664701 | validation: 0.3809477802208861]
	TIME [epoch: 98.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3933226991653462		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.3933226991653462 | validation: 0.4176134184847019]
	TIME [epoch: 98.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36528297294379874		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.36528297294379874 | validation: 0.4179227002857645]
	TIME [epoch: 98.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3627742482132005		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3627742482132005 | validation: 0.3723206077065017]
	TIME [epoch: 98.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3555517324030964		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.3555517324030964 | validation: 0.36601092476128455]
	TIME [epoch: 98.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35495638083989106		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.35495638083989106 | validation: 0.354027212183843]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37355191025646256		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.37355191025646256 | validation: 0.4941072699288987]
	TIME [epoch: 98.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37473721891510997		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.37473721891510997 | validation: 0.36130231672816293]
	TIME [epoch: 98.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33780634792025854		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.33780634792025854 | validation: 0.35309592125602995]
	TIME [epoch: 98.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34455721708184045		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.34455721708184045 | validation: 0.36535703386384955]
	TIME [epoch: 98.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3403762176688932		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3403762176688932 | validation: 0.3735025853241365]
	TIME [epoch: 98.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3480181262553264		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3480181262553264 | validation: 0.37141598738926096]
	TIME [epoch: 98.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3419374170759108		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.3419374170759108 | validation: 0.3612840446653943]
	TIME [epoch: 98.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3414247905967561		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.3414247905967561 | validation: 0.3877921310848914]
	TIME [epoch: 98.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35001020361149243		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.35001020361149243 | validation: 0.4064092777153555]
	TIME [epoch: 98.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3517377017671674		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3517377017671674 | validation: 0.3685602007706777]
	TIME [epoch: 98.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33064075516913033		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.33064075516913033 | validation: 0.37787174474883656]
	TIME [epoch: 98.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34310732830788854		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.34310732830788854 | validation: 0.3618943829321555]
	TIME [epoch: 98.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33466464017071157		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.33466464017071157 | validation: 0.37840236370543584]
	TIME [epoch: 98.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3330648358413839		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3330648358413839 | validation: 0.3821531948827409]
	TIME [epoch: 98.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35086389531631346		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.35086389531631346 | validation: 0.3515292158801495]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3367141139240395		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3367141139240395 | validation: 0.3571589988268308]
	TIME [epoch: 98.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3370101099695149		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.3370101099695149 | validation: 0.4582001586041972]
	TIME [epoch: 98.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34843045968012765		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.34843045968012765 | validation: 0.37442191707624184]
	TIME [epoch: 98.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3248058863538587		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.3248058863538587 | validation: 0.353645944724953]
	TIME [epoch: 98.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33898872702571803		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.33898872702571803 | validation: 0.3897355021014069]
	TIME [epoch: 98.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3251748618968529		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.3251748618968529 | validation: 0.38136680214000074]
	TIME [epoch: 98.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31571267803759256		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.31571267803759256 | validation: 0.3798038064680326]
	TIME [epoch: 98.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3249902978110406		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3249902978110406 | validation: 0.3848821364802457]
	TIME [epoch: 98.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34843100089268786		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.34843100089268786 | validation: 0.3708718728402759]
	TIME [epoch: 98.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.326320204410268		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.326320204410268 | validation: 0.35249055540764773]
	TIME [epoch: 98.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3237647938078333		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3237647938078333 | validation: 0.33546333482440527]
	TIME [epoch: 98.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32537097019839034		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.32537097019839034 | validation: 0.38451996753128814]
	TIME [epoch: 98.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3318884122687882		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.3318884122687882 | validation: 0.3460771286112199]
	TIME [epoch: 98.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3191725175738797		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3191725175738797 | validation: 0.37359137348299587]
	TIME [epoch: 98.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32468220783752155		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.32468220783752155 | validation: 0.32402829428446867]
	TIME [epoch: 98.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34301504245588993		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.34301504245588993 | validation: 0.34585007290228675]
	TIME [epoch: 98.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4169937708204876		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.4169937708204876 | validation: 0.4042930007765061]
	TIME [epoch: 98.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3434931922823694		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3434931922823694 | validation: 0.3674220788479488]
	TIME [epoch: 98.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33928453606255593		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.33928453606255593 | validation: 0.36202530549234613]
	TIME [epoch: 98.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38825565995301975		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.38825565995301975 | validation: 0.4433411946410265]
	TIME [epoch: 98.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3641814824915339		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3641814824915339 | validation: 0.35466642278003085]
	TIME [epoch: 98.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34407420904755404		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.34407420904755404 | validation: 0.35588247773632575]
	TIME [epoch: 98.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3521059231216851		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3521059231216851 | validation: 0.4048819995458729]
	TIME [epoch: 98.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3352913064917128		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.3352913064917128 | validation: 0.35596640346385444]
	TIME [epoch: 98.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3348086351609767		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.3348086351609767 | validation: 0.38115381131116544]
	TIME [epoch: 98.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3435096906851633		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3435096906851633 | validation: 0.3550070491970888]
	TIME [epoch: 98.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3340659529954304		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.3340659529954304 | validation: 0.3801836254407719]
	TIME [epoch: 98.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3328150381103201		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.3328150381103201 | validation: 0.34512019234299957]
	TIME [epoch: 98.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32658863855953674		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.32658863855953674 | validation: 0.4090420072904123]
	TIME [epoch: 98.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32272658826528444		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.32272658826528444 | validation: 0.37010565456001426]
	TIME [epoch: 98.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32718524350384315		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.32718524350384315 | validation: 0.3454411213663319]
	TIME [epoch: 98.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3394069860360114		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.3394069860360114 | validation: 1.2875704868539508]
	TIME [epoch: 98.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.675431519949629		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 2.675431519949629 | validation: 3.59916248164546]
	TIME [epoch: 98.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4633477594606656		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 2.4633477594606656 | validation: 2.0954464435732008]
	TIME [epoch: 98.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.405505340191036		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 2.405505340191036 | validation: 3.36394041133669]
	TIME [epoch: 98.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.5721321154893224		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 3.5721321154893224 | validation: 3.3401313685513694]
	TIME [epoch: 98.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.0042615542390756		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 3.0042615542390756 | validation: 2.7889670191007303]
	TIME [epoch: 98.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.7857010716075346		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 2.7857010716075346 | validation: 1.7602405772311465]
	TIME [epoch: 98.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6395675394450169		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.6395675394450169 | validation: 0.9425704521835037]
	TIME [epoch: 98.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0182322001206616		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 1.0182322001206616 | validation: 0.6061236892985777]
	TIME [epoch: 98.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7894156454533543		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.7894156454533543 | validation: 0.5576683357430066]
	TIME [epoch: 98.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6980690755509351		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.6980690755509351 | validation: 0.5762625591678584]
	TIME [epoch: 98.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7117786434981377		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.7117786434981377 | validation: 0.5678743786032163]
	TIME [epoch: 98.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6626774620241622		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.6626774620241622 | validation: 0.5662250381537899]
	TIME [epoch: 98.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6260541158585999		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.6260541158585999 | validation: 0.5314272237201969]
	TIME [epoch: 98.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6094727388073876		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.6094727388073876 | validation: 0.5483671599206528]
	TIME [epoch: 98.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.576889291349404		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.576889291349404 | validation: 0.6015716512948515]
	TIME [epoch: 98.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7545807222965486		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.7545807222965486 | validation: 1.3905569761899756]
	TIME [epoch: 98.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5414797105293618		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 1.5414797105293618 | validation: 1.126045566181042]
	TIME [epoch: 98.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8564721601716608		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.8564721601716608 | validation: 0.7161151828321135]
	TIME [epoch: 98.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6877244743287849		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.6877244743287849 | validation: 0.6707807919351761]
	TIME [epoch: 98.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6587453630918394		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.6587453630918394 | validation: 0.6964560646791569]
	TIME [epoch: 98.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6403838875309406		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.6403838875309406 | validation: 0.5300053333355766]
	TIME [epoch: 98.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5006568408504137		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.5006568408504137 | validation: 0.47824518511868774]
	TIME [epoch: 98.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5053220991929502		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5053220991929502 | validation: 0.4895672273903237]
	TIME [epoch: 98.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6014309104301483		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.6014309104301483 | validation: 0.5077794854559985]
	TIME [epoch: 98.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6379174147451127		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.6379174147451127 | validation: 0.5285232626281918]
	TIME [epoch: 98.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6255367461168733		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.6255367461168733 | validation: 0.5266687075552126]
	TIME [epoch: 98.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5436368517804988		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.5436368517804988 | validation: 0.4846060598472989]
	TIME [epoch: 98.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4540153963122003		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.4540153963122003 | validation: 0.43926997041963817]
	TIME [epoch: 98.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46615265754562596		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.46615265754562596 | validation: 0.5161736773463226]
	TIME [epoch: 98.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4386151423815517		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.4386151423815517 | validation: 0.41251647376538525]
	TIME [epoch: 98.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44952079751408075		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.44952079751408075 | validation: 0.49928992767961533]
	TIME [epoch: 98.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42036566355727994		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.42036566355727994 | validation: 0.4533020539925884]
	TIME [epoch: 98.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5297233325414356		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.5297233325414356 | validation: 0.4986028032954984]
	TIME [epoch: 98.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5837781425321125		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.5837781425321125 | validation: 0.4435317080416447]
	TIME [epoch: 98.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5759146437447102		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.5759146437447102 | validation: 0.5686848967992753]
	TIME [epoch: 98.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5824909231793672		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.5824909231793672 | validation: 0.4649745495090395]
	TIME [epoch: 98.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5188572364606944		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.5188572364606944 | validation: 0.42496614353652673]
	TIME [epoch: 98.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39941824339102		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.39941824339102 | validation: 0.38493655682736483]
	TIME [epoch: 98.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3939387787427751		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3939387787427751 | validation: 0.3998905097668551]
	TIME [epoch: 98.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3966343100578639		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.3966343100578639 | validation: 0.3753119587162425]
	TIME [epoch: 98.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40148488147709643		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.40148488147709643 | validation: 0.37339331918281354]
	TIME [epoch: 98.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40812510293483034		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.40812510293483034 | validation: 0.3874573732180386]
	TIME [epoch: 98.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3784019863359138		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.3784019863359138 | validation: 0.45912779813490695]
	TIME [epoch: 98.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44664577592579824		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.44664577592579824 | validation: 0.36953483430854855]
	TIME [epoch: 98.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43238113658770483		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.43238113658770483 | validation: 0.39295330649434124]
	TIME [epoch: 98.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3766621146523941		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.3766621146523941 | validation: 0.3733552768715179]
	TIME [epoch: 98.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3847960073626376		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3847960073626376 | validation: 0.42976372976918426]
	TIME [epoch: 98.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3772547005596969		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.3772547005596969 | validation: 0.44940408182992025]
	TIME [epoch: 98.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37882840987723687		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.37882840987723687 | validation: 0.3746089282972147]
	TIME [epoch: 98.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3482334373706298		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.3482334373706298 | validation: 0.37350099572218276]
	TIME [epoch: 98.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3863540333396698		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.3863540333396698 | validation: 0.3899544458441393]
	TIME [epoch: 98.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4255631619589649		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.4255631619589649 | validation: 0.4284385216391371]
	TIME [epoch: 98.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42161663141884087		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.42161663141884087 | validation: 0.428760784734492]
	TIME [epoch: 98.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4855489759535373		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.4855489759535373 | validation: 0.4109264113010722]
	TIME [epoch: 98.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4112723002732751		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.4112723002732751 | validation: 0.36985128761843405]
	TIME [epoch: 98.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3909431205528548		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.3909431205528548 | validation: 0.3719483756436595]
	TIME [epoch: 98.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40172271666341747		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.40172271666341747 | validation: 0.41232830983076924]
	TIME [epoch: 232 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3867043684795172		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.3867043684795172 | validation: 0.4059565004719491]
	TIME [epoch: 205 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3831860644776354		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.3831860644776354 | validation: 0.39830009732828514]
	TIME [epoch: 205 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37235983016838575		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.37235983016838575 | validation: 0.3560617907364231]
	TIME [epoch: 205 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36980919770301235		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.36980919770301235 | validation: 0.3904087523004752]
	TIME [epoch: 205 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3613821714835212		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.3613821714835212 | validation: 0.36189099435337485]
	TIME [epoch: 205 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35887091881589034		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.35887091881589034 | validation: 0.3438704437970753]
	TIME [epoch: 205 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35349246242462784		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.35349246242462784 | validation: 0.40007476091584654]
	TIME [epoch: 205 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3488364044660564		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.3488364044660564 | validation: 0.37056298244594826]
	TIME [epoch: 205 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3471702800636338		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.3471702800636338 | validation: 0.3394338665600996]
	TIME [epoch: 205 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3532001901071627		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.3532001901071627 | validation: 0.3657850713859086]
	TIME [epoch: 205 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34754361048952154		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.34754361048952154 | validation: 0.33959379859703104]
	TIME [epoch: 205 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3303551158504711		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.3303551158504711 | validation: 0.3403822606676793]
	TIME [epoch: 205 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3692089247403967		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.3692089247403967 | validation: 0.3797577192281775]
	TIME [epoch: 205 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33125484544864015		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.33125484544864015 | validation: 0.35087361632091085]
	TIME [epoch: 205 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3775118358457719		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.3775118358457719 | validation: 0.43377396442151667]
	TIME [epoch: 205 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36493029399883625		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.36493029399883625 | validation: 0.3990478037889748]
	TIME [epoch: 205 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3370053344146341		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.3370053344146341 | validation: 0.3430448662283295]
	TIME [epoch: 205 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34047801436068387		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.34047801436068387 | validation: 0.36438889517914774]
	TIME [epoch: 205 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3472513573728683		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3472513573728683 | validation: 0.41099813314723066]
	TIME [epoch: 205 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44954471066094825		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.44954471066094825 | validation: 0.35860457940563983]
	TIME [epoch: 205 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.431592083374742		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.431592083374742 | validation: 0.4103513253879599]
	TIME [epoch: 205 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40491696150100004		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.40491696150100004 | validation: 0.3516874925633132]
	TIME [epoch: 205 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3878999865046486		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.3878999865046486 | validation: 0.33267571969638354]
	TIME [epoch: 205 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3765066105155644		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.3765066105155644 | validation: 0.33305528805044743]
	TIME [epoch: 205 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37151703024650257		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.37151703024650257 | validation: 0.43221299507854527]
	TIME [epoch: 205 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3882192399210509		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.3882192399210509 | validation: 0.394021998933011]
	TIME [epoch: 205 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3881123132386473		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.3881123132386473 | validation: 0.43598932173627214]
	TIME [epoch: 205 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4050965241478816		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.4050965241478816 | validation: 0.35581225071254174]
	TIME [epoch: 205 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33686314359015246		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.33686314359015246 | validation: 0.359231332259304]
	TIME [epoch: 205 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32368623321392004		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.32368623321392004 | validation: 0.3424527275714595]
	TIME [epoch: 205 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33817592380191486		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.33817592380191486 | validation: 0.3430618491712564]
	TIME [epoch: 205 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3150031006300721		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.3150031006300721 | validation: 0.378968097694075]
	TIME [epoch: 205 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3401492730705576		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.3401492730705576 | validation: 0.37644972865761006]
	TIME [epoch: 205 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32654451732631257		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.32654451732631257 | validation: 0.3609414527352783]
	TIME [epoch: 205 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3608241793539382		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.3608241793539382 | validation: 0.36755676091100237]
	TIME [epoch: 205 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3101544351483139		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.3101544351483139 | validation: 0.33751364286408503]
	TIME [epoch: 205 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32792441574088566		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.32792441574088566 | validation: 0.3263512841131794]
	TIME [epoch: 205 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32835275217321835		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.32835275217321835 | validation: 0.362840397954115]
	TIME [epoch: 205 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3114449666345331		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.3114449666345331 | validation: 0.309878994222859]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3413866781916341		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.3413866781916341 | validation: 0.36285857616525136]
	TIME [epoch: 205 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31487905272797906		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.31487905272797906 | validation: 0.3210785537182846]
	TIME [epoch: 205 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3088578167940686		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.3088578167940686 | validation: 0.31159580351869565]
	TIME [epoch: 205 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3180368908877764		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.3180368908877764 | validation: 0.3238020710354019]
	TIME [epoch: 205 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30885768191889335		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.30885768191889335 | validation: 0.32144757790056777]
	TIME [epoch: 205 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3076540717670049		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.3076540717670049 | validation: 0.37366584257857427]
	TIME [epoch: 205 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32935503499859786		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.32935503499859786 | validation: 0.3400586777695025]
	TIME [epoch: 205 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32023098769899505		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.32023098769899505 | validation: 0.34274049914982074]
	TIME [epoch: 205 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31697425382936584		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.31697425382936584 | validation: 0.3397232425272584]
	TIME [epoch: 205 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3031370113214699		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.3031370113214699 | validation: 0.3324085564505978]
	TIME [epoch: 205 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3086992328062597		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.3086992328062597 | validation: 0.311302163334935]
	TIME [epoch: 205 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30620176430805973		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.30620176430805973 | validation: 0.30776488431165355]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30459437740829526		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.30459437740829526 | validation: 0.35629806279923965]
	TIME [epoch: 205 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3003154067078379		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.3003154067078379 | validation: 0.3592234017465081]
	TIME [epoch: 205 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3169392958916871		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3169392958916871 | validation: 0.339819510774809]
	TIME [epoch: 205 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2913466437862759		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.2913466437862759 | validation: 0.3087039919400431]
	TIME [epoch: 205 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29843299283066105		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.29843299283066105 | validation: 0.349074079790411]
	TIME [epoch: 205 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30075418563571055		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.30075418563571055 | validation: 0.32311282579199424]
	TIME [epoch: 205 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29921411269688614		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.29921411269688614 | validation: 0.309495156823255]
	TIME [epoch: 205 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2816970473250932		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.2816970473250932 | validation: 0.3077666557053585]
	TIME [epoch: 205 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29986573737913425		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.29986573737913425 | validation: 0.3036410578538273]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28565581585871874		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.28565581585871874 | validation: 0.3200718326577126]
	TIME [epoch: 205 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29993951350959935		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.29993951350959935 | validation: 0.34655817651858695]
	TIME [epoch: 205 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3408400500652975		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.3408400500652975 | validation: 0.35698171118687555]
	TIME [epoch: 205 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32570689681132575		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.32570689681132575 | validation: 0.3166333831514004]
	TIME [epoch: 205 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31938060720038125		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.31938060720038125 | validation: 0.33465502845876366]
	TIME [epoch: 205 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31775189455459385		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.31775189455459385 | validation: 0.29423072735635325]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3164914392087914		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.3164914392087914 | validation: 0.38749485628744595]
	TIME [epoch: 205 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33030206080587105		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.33030206080587105 | validation: 0.34679093207734024]
	TIME [epoch: 205 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2957627495909978		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.2957627495909978 | validation: 0.36780499501904196]
	TIME [epoch: 205 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2882873777590244		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2882873777590244 | validation: 0.2899349801627174]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32561278738980776		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.32561278738980776 | validation: 0.3457259042198056]
	TIME [epoch: 205 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31223287470285055		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.31223287470285055 | validation: 0.3673185267667539]
	TIME [epoch: 205 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32098628127553736		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.32098628127553736 | validation: 0.34415882362903777]
	TIME [epoch: 205 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31155411284290646		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.31155411284290646 | validation: 0.29955268208532515]
	TIME [epoch: 205 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3205252985791761		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.3205252985791761 | validation: 0.3018765377117525]
	TIME [epoch: 205 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29366580624536276		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.29366580624536276 | validation: 0.30117254714087754]
	TIME [epoch: 205 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2908985142283049		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.2908985142283049 | validation: 0.36127014802902063]
	TIME [epoch: 205 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3295730125827989		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3295730125827989 | validation: 0.2921333050037951]
	TIME [epoch: 205 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30177117477895427		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.30177117477895427 | validation: 0.3196983791103131]
	TIME [epoch: 205 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28981216450055725		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.28981216450055725 | validation: 0.3000376326160601]
	TIME [epoch: 205 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2925531800561566		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.2925531800561566 | validation: 0.30225047283061]
	TIME [epoch: 205 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28568820856726374		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.28568820856726374 | validation: 0.34909191784494753]
	TIME [epoch: 205 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31247133021044676		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.31247133021044676 | validation: 0.3556364084096262]
	TIME [epoch: 205 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2897420705705895		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.2897420705705895 | validation: 0.29654589964267275]
	TIME [epoch: 205 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29592264564235127		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.29592264564235127 | validation: 0.33870499814431076]
	TIME [epoch: 205 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29775672898279604		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.29775672898279604 | validation: 0.28564959565023]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29848768899712197		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.29848768899712197 | validation: 0.3076261207012288]
	TIME [epoch: 205 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2982163924855705		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2982163924855705 | validation: 0.2924642979115784]
	TIME [epoch: 205 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28492554282740007		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.28492554282740007 | validation: 0.352115846328077]
	TIME [epoch: 205 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2995725630341274		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.2995725630341274 | validation: 0.3042453787998724]
	TIME [epoch: 205 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28529610148220447		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.28529610148220447 | validation: 0.3795948475473982]
	TIME [epoch: 205 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31215939594173636		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.31215939594173636 | validation: 0.30565792897309374]
	TIME [epoch: 205 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27986470245110867		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.27986470245110867 | validation: 0.2918860849885413]
	TIME [epoch: 205 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.279708261809223		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.279708261809223 | validation: 0.3005173114462131]
	TIME [epoch: 205 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27735985565147003		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.27735985565147003 | validation: 0.3437159421759325]
	TIME [epoch: 205 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2803634215319273		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2803634215319273 | validation: 0.2945354571006826]
	TIME [epoch: 205 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29381653766773164		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.29381653766773164 | validation: 0.3142907033417546]
	TIME [epoch: 205 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27847140364900125		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.27847140364900125 | validation: 0.3264192190973015]
	TIME [epoch: 205 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28051419804257954		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.28051419804257954 | validation: 0.29847493683874726]
	TIME [epoch: 205 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2935099767027227		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2935099767027227 | validation: 0.29177628771245845]
	TIME [epoch: 205 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2765542687940239		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.2765542687940239 | validation: 0.29462170780256663]
	TIME [epoch: 205 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2753980641667182		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2753980641667182 | validation: 0.323924580841335]
	TIME [epoch: 205 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29252294972681575		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.29252294972681575 | validation: 0.3393542740558508]
	TIME [epoch: 205 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2887963158698636		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.2887963158698636 | validation: 0.3045936641379723]
	TIME [epoch: 205 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27028925017701944		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.27028925017701944 | validation: 0.30465852467573423]
	TIME [epoch: 205 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26929721297659603		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.26929721297659603 | validation: 0.2796589346141925]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2673872608404602		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.2673872608404602 | validation: 0.30101132815908166]
	TIME [epoch: 205 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26830106572713763		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.26830106572713763 | validation: 0.2750388361739043]
	TIME [epoch: 205 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v4_20240708_200112/states/model_facs_dec1b_2dpca_v4_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2685079038144791		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.2685079038144791 | validation: 0.303637711241912]
	TIME [epoch: 205 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27267189259448776		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.27267189259448776 | validation: 0.3226794198733026]
	TIME [epoch: 205 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28214687476581807		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.28214687476581807 | validation: 0.28455900712495785]
	TIME [epoch: 205 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27193958053340567		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.27193958053340567 | validation: 0.30140562786421204]
	TIME [epoch: 205 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26170138554082106		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.26170138554082106 | validation: 0.2870979825449419]
	TIME [epoch: 205 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26665551777070357		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.26665551777070357 | validation: 0.29562003766878564]
	TIME [epoch: 205 sec]
EPOCH 316/2000:
	Training over batches...
