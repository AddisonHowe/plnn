Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v9', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v9', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3922062488

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.191201074635584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.191201074635584 | validation: 1.1020488815267802]
	TIME [epoch: 45.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2001235745655718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2001235745655718 | validation: 1.0220032755616448]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0088780499483399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0088780499483399 | validation: 0.9008480865109236]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9962934398487155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9962934398487155 | validation: 0.8975183511272367]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9060910419576919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9060910419576919 | validation: 0.8638885428266004]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8676299575755926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8676299575755926 | validation: 0.8276745415831034]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8501503218658089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8501503218658089 | validation: 0.7562490869532107]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8263876121837506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8263876121837506 | validation: 0.7042329006230645]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7977901773296565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7977901773296565 | validation: 0.7018809853735968]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.812779532704462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.812779532704462 | validation: 0.6838297557544223]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7348496502354339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7348496502354339 | validation: 0.7009146687347]
	TIME [epoch: 9.77 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7024896151071033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7024896151071033 | validation: 0.7241394659412852]
	TIME [epoch: 9.76 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6585802281165937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6585802281165937 | validation: 0.5810622945312108]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6226183264249995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6226183264249995 | validation: 0.5439015434375181]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5490527197765418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5490527197765418 | validation: 0.5046679837691225]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5989791871003011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5989791871003011 | validation: 0.6606801831910047]
	TIME [epoch: 9.79 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5317376372360364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5317376372360364 | validation: 0.6405684487675873]
	TIME [epoch: 9.78 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6606816131773731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6606816131773731 | validation: 0.4924991487839484]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49926599692126256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49926599692126256 | validation: 0.5596595803384269]
	TIME [epoch: 9.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.483360790247338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.483360790247338 | validation: 0.46909067547418637]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5582645979503826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5582645979503826 | validation: 0.5958729004224195]
	TIME [epoch: 9.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5529562222997485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5529562222997485 | validation: 0.5016097058262428]
	TIME [epoch: 9.78 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4899836498711329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4899836498711329 | validation: 0.5011330559697057]
	TIME [epoch: 9.77 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5534690138547145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5534690138547145 | validation: 0.5639484554426355]
	TIME [epoch: 9.79 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4515331312216695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4515331312216695 | validation: 0.43111764731326874]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48063112748474945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48063112748474945 | validation: 0.4134492638967292]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4368920428044761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4368920428044761 | validation: 0.5647340865810151]
	TIME [epoch: 9.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5254769089927126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5254769089927126 | validation: 0.5239169568428703]
	TIME [epoch: 9.77 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.460848322543417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.460848322543417 | validation: 0.4483517247439462]
	TIME [epoch: 9.77 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.431691488564199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.431691488564199 | validation: 0.4821275935021765]
	TIME [epoch: 9.77 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4465871194843025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4465871194843025 | validation: 0.5129828922269374]
	TIME [epoch: 9.79 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4418392862440271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4418392862440271 | validation: 0.485124218483665]
	TIME [epoch: 9.77 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48801862042237737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48801862042237737 | validation: 0.450728224468471]
	TIME [epoch: 9.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43011483964278163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43011483964278163 | validation: 0.4321071288478614]
	TIME [epoch: 9.79 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4376837719608122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4376837719608122 | validation: 0.5680221333014214]
	TIME [epoch: 9.78 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4755405013937916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4755405013937916 | validation: 0.4592391016295408]
	TIME [epoch: 9.78 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.408320045937723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.408320045937723 | validation: 0.4201877051816993]
	TIME [epoch: 9.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41661076666976293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41661076666976293 | validation: 0.46394792890319697]
	TIME [epoch: 9.79 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4386629267639138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4386629267639138 | validation: 0.40606810713710895]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42028554305373783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42028554305373783 | validation: 0.4759516229533315]
	TIME [epoch: 9.78 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4108244743879642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4108244743879642 | validation: 0.4157738537868152]
	TIME [epoch: 9.78 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47159412188946104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47159412188946104 | validation: 0.40162929840608275]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4049037412148935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4049037412148935 | validation: 0.480243108711492]
	TIME [epoch: 9.78 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4086337973724018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4086337973724018 | validation: 0.38578322024388256]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4029699221952952		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4029699221952952 | validation: 0.43228252162828984]
	TIME [epoch: 9.79 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4170520913567887		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.4170520913567887 | validation: 0.4356423909257702]
	TIME [epoch: 9.77 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40044528627758186		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.40044528627758186 | validation: 0.4053648415071624]
	TIME [epoch: 9.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41867371488920757		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.41867371488920757 | validation: 0.4043209101101448]
	TIME [epoch: 9.78 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4933681038849037		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.4933681038849037 | validation: 0.3966380276327398]
	TIME [epoch: 9.78 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3961855420453195		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.3961855420453195 | validation: 0.4195905651673824]
	TIME [epoch: 9.77 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40265075783926524		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.40265075783926524 | validation: 0.44163591324775836]
	TIME [epoch: 9.77 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3789858324315012		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.3789858324315012 | validation: 0.3899932079881666]
	TIME [epoch: 9.78 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3952903294370676		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.3952903294370676 | validation: 0.3938159977800614]
	TIME [epoch: 9.78 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4076239665138255		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.4076239665138255 | validation: 0.5668239692182986]
	TIME [epoch: 9.77 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4340924656928832		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.4340924656928832 | validation: 0.41842473213681897]
	TIME [epoch: 9.77 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38962458275641404		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.38962458275641404 | validation: 0.4074193749359852]
	TIME [epoch: 9.79 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4200691887926836		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.4200691887926836 | validation: 0.3954673061153967]
	TIME [epoch: 9.77 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37506615517852165		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.37506615517852165 | validation: 0.40931906168175214]
	TIME [epoch: 9.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4083417304643381		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.4083417304643381 | validation: 0.39945410161974654]
	TIME [epoch: 9.77 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37230439672224397		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.37230439672224397 | validation: 0.36068944744114256]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44445363763060164		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.44445363763060164 | validation: 0.46980260930747075]
	TIME [epoch: 9.77 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5303275208888727		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.5303275208888727 | validation: 0.4256717192297129]
	TIME [epoch: 9.77 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4768845646444442		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.4768845646444442 | validation: 0.40390298743845515]
	TIME [epoch: 9.78 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48170343542616867		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.48170343542616867 | validation: 0.6833432765588677]
	TIME [epoch: 9.78 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4722944927848201		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.4722944927848201 | validation: 0.3502820870762515]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38142859866001644		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.38142859866001644 | validation: 0.34726593227687486]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4809285175028147		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.4809285175028147 | validation: 0.4836373064829299]
	TIME [epoch: 9.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5690182703698469		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.5690182703698469 | validation: 0.4147362661463226]
	TIME [epoch: 9.78 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4682161346892144		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.4682161346892144 | validation: 0.39472766935195785]
	TIME [epoch: 9.78 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4594436364529612		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.4594436364529612 | validation: 0.38454166589368255]
	TIME [epoch: 9.79 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4559284892626332		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4559284892626332 | validation: 0.3703068174890765]
	TIME [epoch: 9.79 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38571779805104317		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.38571779805104317 | validation: 0.4541476906769063]
	TIME [epoch: 9.78 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.534023217229747		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.534023217229747 | validation: 0.40687220537943397]
	TIME [epoch: 9.77 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45009529654418284		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.45009529654418284 | validation: 0.3797423590204266]
	TIME [epoch: 9.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4519560617447857		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.4519560617447857 | validation: 0.389032909828427]
	TIME [epoch: 9.78 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39617746863471115		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.39617746863471115 | validation: 0.39660426790954356]
	TIME [epoch: 9.77 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4639480904495		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.4639480904495 | validation: 0.48692131379567777]
	TIME [epoch: 9.78 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4694869389608758		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.4694869389608758 | validation: 0.3716366194436259]
	TIME [epoch: 9.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3631179824160694		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3631179824160694 | validation: 0.3319547141736297]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45812110057429223		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.45812110057429223 | validation: 0.4848845538120341]
	TIME [epoch: 9.78 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4129567743856126		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.4129567743856126 | validation: 0.38982755431414745]
	TIME [epoch: 9.78 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3671805028487883		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3671805028487883 | validation: 0.3813516754907923]
	TIME [epoch: 9.78 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37236496580420275		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.37236496580420275 | validation: 0.4114191506012254]
	TIME [epoch: 9.76 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3892544767369954		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.3892544767369954 | validation: 0.3441206411716451]
	TIME [epoch: 9.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3607688645042959		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3607688645042959 | validation: 0.3689119800691106]
	TIME [epoch: 9.79 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3664059897438676		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.3664059897438676 | validation: 0.37891285044591755]
	TIME [epoch: 9.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36237263643589934		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.36237263643589934 | validation: 0.5996138213523607]
	TIME [epoch: 9.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5246099421141754		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.5246099421141754 | validation: 0.44211734878158904]
	TIME [epoch: 9.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40352416480238645		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.40352416480238645 | validation: 0.38556220102733396]
	TIME [epoch: 9.78 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3728461418462068		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3728461418462068 | validation: 0.38882780207072914]
	TIME [epoch: 9.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35351136976938674		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.35351136976938674 | validation: 0.35346891230980104]
	TIME [epoch: 9.76 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36921282265978433		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.36921282265978433 | validation: 0.343061330498737]
	TIME [epoch: 9.78 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.357820651560743		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.357820651560743 | validation: 0.3437255286599043]
	TIME [epoch: 9.77 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3932852505300092		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.3932852505300092 | validation: 0.3738424106902076]
	TIME [epoch: 9.77 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3781339931820659		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3781339931820659 | validation: 0.36426019885334404]
	TIME [epoch: 9.76 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36519997280933525		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.36519997280933525 | validation: 0.46361851455692393]
	TIME [epoch: 9.79 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3576002231836223		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.3576002231836223 | validation: 0.3773190481634013]
	TIME [epoch: 9.77 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34196940220321914		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.34196940220321914 | validation: 0.3270059681289399]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3434036300977972		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.3434036300977972 | validation: 0.4067074558259984]
	TIME [epoch: 9.77 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3510539433430362		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.3510539433430362 | validation: 0.3795952565018552]
	TIME [epoch: 9.78 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34719840524304496		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.34719840524304496 | validation: 0.3798841603967017]
	TIME [epoch: 9.78 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33079255767274063		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.33079255767274063 | validation: 0.33938763854548526]
	TIME [epoch: 9.78 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3201866504032405		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3201866504032405 | validation: 0.36197056883050777]
	TIME [epoch: 9.79 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33633754195508403		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.33633754195508403 | validation: 0.5403300348294795]
	TIME [epoch: 9.78 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6975386182673488		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.6975386182673488 | validation: 0.473637107394817]
	TIME [epoch: 9.77 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5172222617102175		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.5172222617102175 | validation: 0.4756122648557346]
	TIME [epoch: 9.78 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5104006141050609		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.5104006141050609 | validation: 0.4822769275471619]
	TIME [epoch: 9.79 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44818272030548606		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.44818272030548606 | validation: 0.4157158054087434]
	TIME [epoch: 9.78 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4173455492022817		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.4173455492022817 | validation: 0.36615658631788733]
	TIME [epoch: 9.77 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37952771942189334		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.37952771942189334 | validation: 0.37790099279382383]
	TIME [epoch: 9.78 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7156437742906028		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.7156437742906028 | validation: 0.5808125621163172]
	TIME [epoch: 9.78 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4413868141635346		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.4413868141635346 | validation: 0.38761616614127237]
	TIME [epoch: 9.77 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39312686343891784		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.39312686343891784 | validation: 0.45229004840054576]
	TIME [epoch: 9.78 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5277766097361734		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.5277766097361734 | validation: 0.389164520845147]
	TIME [epoch: 9.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3787566744190417		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.3787566744190417 | validation: 0.37221660209183516]
	TIME [epoch: 9.78 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37369294727330377		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.37369294727330377 | validation: 0.38706957099145267]
	TIME [epoch: 9.78 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3532657179513954		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.3532657179513954 | validation: 0.791872510188462]
	TIME [epoch: 9.77 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5289608411490963		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.5289608411490963 | validation: 0.38503570171482243]
	TIME [epoch: 9.79 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3401919824387061		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3401919824387061 | validation: 0.32347501372911075]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4483357554526306		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.4483357554526306 | validation: 0.4554210425815822]
	TIME [epoch: 9.78 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3792989808072069		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.3792989808072069 | validation: 0.37338193251609164]
	TIME [epoch: 9.78 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3443588239572583		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3443588239572583 | validation: 0.3825011140500862]
	TIME [epoch: 9.78 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3663754816697249		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3663754816697249 | validation: 0.3673281542469952]
	TIME [epoch: 9.77 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36887783051585865		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.36887783051585865 | validation: 0.3655105311285246]
	TIME [epoch: 9.78 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35251029169866643		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.35251029169866643 | validation: 0.5174418286274196]
	TIME [epoch: 9.79 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48734014527262975		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.48734014527262975 | validation: 0.41537876777680055]
	TIME [epoch: 9.77 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3478630520045888		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3478630520045888 | validation: 0.3270220920167364]
	TIME [epoch: 9.77 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7113837376622384		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.7113837376622384 | validation: 0.8376819163214717]
	TIME [epoch: 9.78 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5907992567586745		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.5907992567586745 | validation: 0.39383336289095416]
	TIME [epoch: 9.78 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35961191344124216		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.35961191344124216 | validation: 0.34722220127240183]
	TIME [epoch: 9.77 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33361189242716544		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.33361189242716544 | validation: 0.32075619726333254]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3717919733541086		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.3717919733541086 | validation: 0.35248415820435774]
	TIME [epoch: 9.79 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3638498530360589		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3638498530360589 | validation: 0.35897872436126155]
	TIME [epoch: 9.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33992273767157527		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.33992273767157527 | validation: 0.42885346407313707]
	TIME [epoch: 9.77 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3662626548873662		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3662626548873662 | validation: 0.3792320325093622]
	TIME [epoch: 9.77 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32644726275720415		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.32644726275720415 | validation: 0.3839961190268067]
	TIME [epoch: 9.79 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3416117955662592		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.3416117955662592 | validation: 0.37532705787808973]
	TIME [epoch: 9.77 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3456021286316844		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3456021286316844 | validation: 0.7452886140042216]
	TIME [epoch: 9.77 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.502358847403679		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.502358847403679 | validation: 0.34204967813351655]
	TIME [epoch: 9.78 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4798654757062287		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.4798654757062287 | validation: 0.410892291837757]
	TIME [epoch: 9.78 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8043224334448983		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.8043224334448983 | validation: 3.392001218520948]
	TIME [epoch: 9.77 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.16564033770627		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 2.16564033770627 | validation: 1.2699621638574428]
	TIME [epoch: 9.77 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4303462912853364		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.4303462912853364 | validation: 0.8239153238662361]
	TIME [epoch: 9.79 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0235143579686936		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 1.0235143579686936 | validation: 0.6491330362513085]
	TIME [epoch: 9.77 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7210680174001549		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.7210680174001549 | validation: 0.9061670197093503]
	TIME [epoch: 9.77 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8630081773240235		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.8630081773240235 | validation: 0.5901347809589739]
	TIME [epoch: 9.77 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6241776557627738		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.6241776557627738 | validation: 0.48639284880321754]
	TIME [epoch: 9.79 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5502554529112967		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.5502554529112967 | validation: 0.41921966434735564]
	TIME [epoch: 9.77 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5095010255454588		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.5095010255454588 | validation: 0.40847886162538877]
	TIME [epoch: 9.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4756853869186241		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.4756853869186241 | validation: 0.383134408172917]
	TIME [epoch: 9.78 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4713486848861894		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.4713486848861894 | validation: 0.3960319744727008]
	TIME [epoch: 9.77 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7475188962011365		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.7475188962011365 | validation: 1.5888973175898695]
	TIME [epoch: 9.77 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.835194356776589		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.835194356776589 | validation: 0.8688853461790227]
	TIME [epoch: 9.77 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1877177120533537		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 1.1877177120533537 | validation: 1.8033255436610698]
	TIME [epoch: 9.79 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5559908073469642		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 1.5559908073469642 | validation: 1.4775516518461775]
	TIME [epoch: 9.77 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8466761158738727		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.8466761158738727 | validation: 0.4140123041730931]
	TIME [epoch: 9.77 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.640273784845231		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.640273784845231 | validation: 1.4648428394402817]
	TIME [epoch: 9.77 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8096601933255876		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 1.8096601933255876 | validation: 0.8536481070497288]
	TIME [epoch: 9.79 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.944204389550818		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.944204389550818 | validation: 0.8944081870646778]
	TIME [epoch: 9.77 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7700326272950527		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.7700326272950527 | validation: 0.558389157110638]
	TIME [epoch: 9.77 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48479087490814166		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.48479087490814166 | validation: 0.34432995893260465]
	TIME [epoch: 9.78 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5114941173021809		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.5114941173021809 | validation: 0.44036357965189143]
	TIME [epoch: 9.77 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45158475449347485		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.45158475449347485 | validation: 0.4704880292909423]
	TIME [epoch: 9.77 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4608801814234292		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.4608801814234292 | validation: 0.501012556659685]
	TIME [epoch: 9.77 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46069842276430045		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.46069842276430045 | validation: 0.39953985665681635]
	TIME [epoch: 9.78 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3681662612149259		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.3681662612149259 | validation: 0.3594005809952046]
	TIME [epoch: 9.77 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44366144018725306		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.44366144018725306 | validation: 0.3492869396653623]
	TIME [epoch: 9.77 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3425517452248269		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.3425517452248269 | validation: 0.34956271833328134]
	TIME [epoch: 9.78 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4465113232483472		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.4465113232483472 | validation: 0.43968103455190144]
	TIME [epoch: 9.79 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3880263284407232		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3880263284407232 | validation: 0.3742151722332929]
	TIME [epoch: 9.77 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3488668234663371		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3488668234663371 | validation: 0.354659746493999]
	TIME [epoch: 9.77 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3375244016181573		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.3375244016181573 | validation: 0.34739288048747075]
	TIME [epoch: 9.78 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33592576311085337		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.33592576311085337 | validation: 0.3550710668863375]
	TIME [epoch: 9.77 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3345209396893641		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.3345209396893641 | validation: 0.34989077621414144]
	TIME [epoch: 9.77 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32689224991068594		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.32689224991068594 | validation: 0.36498335906716095]
	TIME [epoch: 9.76 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35392831131454183		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.35392831131454183 | validation: 0.3281141575653265]
	TIME [epoch: 9.78 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31940245235340275		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.31940245235340275 | validation: 0.33659040812974467]
	TIME [epoch: 9.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36741942131761257		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.36741942131761257 | validation: 0.40320430713468214]
	TIME [epoch: 9.76 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3475486622802364		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.3475486622802364 | validation: 0.3428489987890936]
	TIME [epoch: 9.77 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.329755889383384		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.329755889383384 | validation: 0.3318225473203498]
	TIME [epoch: 9.78 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3132478586896034		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.3132478586896034 | validation: 0.3136572197707025]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31710883997820394		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.31710883997820394 | validation: 0.36694463317653014]
	TIME [epoch: 9.77 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33061271332042547		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.33061271332042547 | validation: 0.3315900351598647]
	TIME [epoch: 9.78 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3167078203406413		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.3167078203406413 | validation: 0.30383067869461167]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3098976468288514		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3098976468288514 | validation: 0.3435189406201492]
	TIME [epoch: 9.77 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3217908784490906		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3217908784490906 | validation: 0.30898098093402443]
	TIME [epoch: 9.77 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3174261346444815		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.3174261346444815 | validation: 0.31255015068214653]
	TIME [epoch: 9.79 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2975834725534345		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.2975834725534345 | validation: 0.3094250153181764]
	TIME [epoch: 9.77 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31369010646146195		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.31369010646146195 | validation: 0.3072037884856117]
	TIME [epoch: 9.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0287903093304012		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 1.0287903093304012 | validation: 3.8141496927473875]
	TIME [epoch: 9.77 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.8222797700327793		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.8222797700327793 | validation: 1.533777761659658]
	TIME [epoch: 9.78 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8783758156761876		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.8783758156761876 | validation: 0.5890482583477066]
	TIME [epoch: 9.77 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7283513217269714		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.7283513217269714 | validation: 0.9366983580306428]
	TIME [epoch: 9.77 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6949104827132518		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.6949104827132518 | validation: 1.482231890885039]
	TIME [epoch: 9.79 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8958016341152368		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 1.8958016341152368 | validation: 1.3678633167930045]
	TIME [epoch: 9.76 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1619378988465026		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 2.1619378988465026 | validation: 3.1424180082021067]
	TIME [epoch: 9.76 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.917004060622511		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 1.917004060622511 | validation: 0.5593076469867118]
	TIME [epoch: 9.76 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7016904482445738		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.7016904482445738 | validation: 0.4670683664594115]
	TIME [epoch: 9.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6404880036116265		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6404880036116265 | validation: 0.4319403983925917]
	TIME [epoch: 9.77 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5777574590238567		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.5777574590238567 | validation: 0.41433097489257315]
	TIME [epoch: 9.77 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4978873778672565		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.4978873778672565 | validation: 0.39257331571370907]
	TIME [epoch: 9.79 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35580535589953266		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.35580535589953266 | validation: 0.3643883328693434]
	TIME [epoch: 9.78 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4103389441425204		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.4103389441425204 | validation: 1.9009318948050455]
	TIME [epoch: 9.77 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3697113596774324		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 2.3697113596774324 | validation: 2.851352999126714]
	TIME [epoch: 9.77 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3701685914421224		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 2.3701685914421224 | validation: 2.859264561794918]
	TIME [epoch: 9.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1218812581693984		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 2.1218812581693984 | validation: 1.5222148491124832]
	TIME [epoch: 9.77 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3299469245598832		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.3299469245598832 | validation: 0.8269680724868262]
	TIME [epoch: 9.77 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6289249718296029		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.6289249718296029 | validation: 0.4710533596030427]
	TIME [epoch: 9.77 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42300800487531465		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.42300800487531465 | validation: 0.4022196109009476]
	TIME [epoch: 9.78 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4054701110872026		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.4054701110872026 | validation: 0.3676427925969435]
	TIME [epoch: 9.77 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35797142545684163		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.35797142545684163 | validation: 0.3537161986770468]
	TIME [epoch: 9.77 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3841635195261991		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.3841635195261991 | validation: 0.5424206934702257]
	TIME [epoch: 9.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43462085443187953		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.43462085443187953 | validation: 0.375704626902799]
	TIME [epoch: 9.77 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3663658628580111		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.3663658628580111 | validation: 0.33464032893711576]
	TIME [epoch: 9.77 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34591230087186564		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.34591230087186564 | validation: 0.3410083829919617]
	TIME [epoch: 9.77 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34810911834479435		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.34810911834479435 | validation: 0.3211176769471652]
	TIME [epoch: 9.78 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3637659897375366		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.3637659897375366 | validation: 0.4525390166427979]
	TIME [epoch: 9.76 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3514969587099738		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.3514969587099738 | validation: 0.3323737945976074]
	TIME [epoch: 9.76 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34054936815766096		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.34054936815766096 | validation: 0.3878080093366412]
	TIME [epoch: 9.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3969282160973277		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3969282160973277 | validation: 0.4147655928034566]
	TIME [epoch: 9.77 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3500862646544639		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.3500862646544639 | validation: 0.33672033844340366]
	TIME [epoch: 9.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3357985430504171		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.3357985430504171 | validation: 0.3201224250068485]
	TIME [epoch: 9.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35413066860778986		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.35413066860778986 | validation: 0.338292924944167]
	TIME [epoch: 9.78 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32601527187215124		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.32601527187215124 | validation: 0.3125703624160801]
	TIME [epoch: 9.77 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32588813690087565		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.32588813690087565 | validation: 0.3197970283777824]
	TIME [epoch: 9.76 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32258347976486623		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.32258347976486623 | validation: 0.32801725520609315]
	TIME [epoch: 9.76 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3274281024501599		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.3274281024501599 | validation: 0.32647526428611656]
	TIME [epoch: 9.78 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3205941371868863		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.3205941371868863 | validation: 0.3017778640035995]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3297940054377528		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.3297940054377528 | validation: 0.31485369063309915]
	TIME [epoch: 9.77 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30789546341941665		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.30789546341941665 | validation: 0.3117121696192793]
	TIME [epoch: 9.77 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31364999145503386		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.31364999145503386 | validation: 0.3888790940083252]
	TIME [epoch: 9.77 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35053698946683404		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.35053698946683404 | validation: 0.3090783683129349]
	TIME [epoch: 9.76 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3153247776368361		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.3153247776368361 | validation: 0.317333844397625]
	TIME [epoch: 9.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3159935002595734		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.3159935002595734 | validation: 0.29297455443316306]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34507637265979446		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.34507637265979446 | validation: 0.32395680871534893]
	TIME [epoch: 9.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31469507217146653		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.31469507217146653 | validation: 0.2972258032044738]
	TIME [epoch: 9.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29541806185525193		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.29541806185525193 | validation: 0.2870290712516716]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2991085853067785		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2991085853067785 | validation: 0.3042183485022338]
	TIME [epoch: 9.79 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29571897553862353		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.29571897553862353 | validation: 0.3068831194038727]
	TIME [epoch: 9.76 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29905348756497274		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.29905348756497274 | validation: 0.352741674981425]
	TIME [epoch: 9.75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3268122909004634		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.3268122909004634 | validation: 0.28668270762588915]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3283741311363913		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.3283741311363913 | validation: 0.2973109158420474]
	TIME [epoch: 9.77 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32424837937039347		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.32424837937039347 | validation: 0.28231923019697003]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32051534480632626		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.32051534480632626 | validation: 0.28404703351174876]
	TIME [epoch: 9.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3334749175025864		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.3334749175025864 | validation: 0.29474179323568755]
	TIME [epoch: 9.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29949920330174473		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.29949920330174473 | validation: 0.3128032389083192]
	TIME [epoch: 9.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3095602957792152		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3095602957792152 | validation: 0.3103222505243606]
	TIME [epoch: 9.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3244743489296905		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3244743489296905 | validation: 0.30028091155388287]
	TIME [epoch: 9.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32221017805080726		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.32221017805080726 | validation: 0.5433342597826589]
	TIME [epoch: 9.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3136049910635152		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 1.3136049910635152 | validation: 1.5554188262843618]
	TIME [epoch: 9.78 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8784782520822243		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 1.8784782520822243 | validation: 2.562317948554342]
	TIME [epoch: 9.78 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6782678503453323		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 2.6782678503453323 | validation: 2.380645638889129]
	TIME [epoch: 9.79 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.414125439422912		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 2.414125439422912 | validation: 2.395606781528742]
	TIME [epoch: 9.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3496178823063905		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 2.3496178823063905 | validation: 2.092807770588453]
	TIME [epoch: 9.75 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6996482138573432		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.6996482138573432 | validation: 0.8870061692235456]
	TIME [epoch: 9.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0819889166017531		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 1.0819889166017531 | validation: 1.3602929053390178]
	TIME [epoch: 9.77 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9827308134962107		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.9827308134962107 | validation: 0.6451904972789475]
	TIME [epoch: 9.77 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5787723730063455		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.5787723730063455 | validation: 0.5394260389534167]
	TIME [epoch: 9.76 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47440742725793406		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.47440742725793406 | validation: 0.4825743943567642]
	TIME [epoch: 9.78 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.033789241116942		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 1.033789241116942 | validation: 2.0434979507094075]
	TIME [epoch: 9.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.2635265744642967		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 2.2635265744642967 | validation: 1.7595345441124408]
	TIME [epoch: 9.76 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2925469311028857		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 1.2925469311028857 | validation: 1.300401421190386]
	TIME [epoch: 9.76 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9572148596506689		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.9572148596506689 | validation: 2.3276927846313207]
	TIME [epoch: 9.78 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.564230935758898		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 1.564230935758898 | validation: 1.5348263357121532]
	TIME [epoch: 9.75 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.152740125846798		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 1.152740125846798 | validation: 0.8018494678097549]
	TIME [epoch: 9.75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0248258582628216		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 1.0248258582628216 | validation: 1.1358880371695759]
	TIME [epoch: 9.75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6574817723514914		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 1.6574817723514914 | validation: 1.5473955259262597]
	TIME [epoch: 9.78 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.2165764402196273		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 2.2165764402196273 | validation: 2.5160155390640506]
	TIME [epoch: 9.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.440000626955025		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 2.440000626955025 | validation: 2.196188975252105]
	TIME [epoch: 9.75 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.916347140072585		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 1.916347140072585 | validation: 1.454034169872454]
	TIME [epoch: 9.77 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5397366004117155		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.5397366004117155 | validation: 1.1457103836188787]
	TIME [epoch: 9.77 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0078447987911963		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 1.0078447987911963 | validation: 0.7408663745418199]
	TIME [epoch: 9.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8358016304279564		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.8358016304279564 | validation: 0.724016069112229]
	TIME [epoch: 9.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6521606385811897		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.6521606385811897 | validation: 0.5185629046822232]
	TIME [epoch: 9.79 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5369018428007726		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.5369018428007726 | validation: 0.45017312612613464]
	TIME [epoch: 9.76 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45864092476704027		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.45864092476704027 | validation: 0.43331651340916794]
	TIME [epoch: 9.76 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5231243273693593		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.5231243273693593 | validation: 0.44619710220650594]
	TIME [epoch: 9.77 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4617723096076042		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.4617723096076042 | validation: 0.6230069349605133]
	TIME [epoch: 9.78 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49585677702674297		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.49585677702674297 | validation: 0.4532524395036416]
	TIME [epoch: 9.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44155602983752207		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.44155602983752207 | validation: 0.51958000057467]
	TIME [epoch: 9.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46391744671892154		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.46391744671892154 | validation: 0.42842398442956914]
	TIME [epoch: 9.77 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4541870691970622		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.4541870691970622 | validation: 0.4131139525780704]
	TIME [epoch: 9.77 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4452153240450822		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.4452153240450822 | validation: 0.39928340516879934]
	TIME [epoch: 9.78 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41927608797437993		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.41927608797437993 | validation: 0.41488734082701273]
	TIME [epoch: 9.78 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4067582145763251		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.4067582145763251 | validation: 0.39952849574444615]
	TIME [epoch: 9.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4238178157138075		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.4238178157138075 | validation: 0.42396425903725843]
	TIME [epoch: 9.76 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3851769972430163		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3851769972430163 | validation: 0.4533656475107085]
	TIME [epoch: 9.76 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.408467912182631		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.408467912182631 | validation: 0.3940562458546563]
	TIME [epoch: 9.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4021712837920409		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.4021712837920409 | validation: 0.3742120969178028]
	TIME [epoch: 9.78 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.354763371903034		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.354763371903034 | validation: 0.40495542867012924]
	TIME [epoch: 9.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4015215797359739		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.4015215797359739 | validation: 0.35453661600591696]
	TIME [epoch: 9.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3809890976913506		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.3809890976913506 | validation: 0.360514524533539]
	TIME [epoch: 9.77 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38185717636708777		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.38185717636708777 | validation: 0.35995488367306583]
	TIME [epoch: 9.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3719462037091279		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.3719462037091279 | validation: 0.37360192334486403]
	TIME [epoch: 9.75 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35528331184039275		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.35528331184039275 | validation: 0.33069735028595093]
	TIME [epoch: 9.77 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37360395664294727		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.37360395664294727 | validation: 0.47553639623226857]
	TIME [epoch: 9.78 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8635860822074439		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.8635860822074439 | validation: 1.0411782113439585]
	TIME [epoch: 9.76 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.356891046329339		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 1.356891046329339 | validation: 1.0710659650971808]
	TIME [epoch: 9.76 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0639650047431102		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 1.0639650047431102 | validation: 1.3882517572197948]
	TIME [epoch: 9.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8680154061742981		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.8680154061742981 | validation: 0.617305955498936]
	TIME [epoch: 9.77 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9228354164929916		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.9228354164929916 | validation: 1.636241288323884]
	TIME [epoch: 9.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1771429019681876		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 2.1771429019681876 | validation: 2.076144784887779]
	TIME [epoch: 9.74 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4555375721970956		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.4555375721970956 | validation: 2.43037799156874]
	TIME [epoch: 9.76 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5951984585751662		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 1.5951984585751662 | validation: 1.0024725096896698]
	TIME [epoch: 9.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9688089690140124		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.9688089690140124 | validation: 0.5694335608215197]
	TIME [epoch: 9.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2413900270893767		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 1.2413900270893767 | validation: 1.3419238170672012]
	TIME [epoch: 9.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1458899843483659		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 1.1458899843483659 | validation: 0.8821510788220435]
	TIME [epoch: 9.76 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6951946408075903		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.6951946408075903 | validation: 0.4527390601060972]
	TIME [epoch: 9.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5912842662508754		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.5912842662508754 | validation: 0.5447339297400352]
	TIME [epoch: 9.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7013324220842984		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.7013324220842984 | validation: 0.6070081754339863]
	TIME [epoch: 9.76 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6841107652308837		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6841107652308837 | validation: 0.5141509177369785]
	TIME [epoch: 9.75 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5788647451230774		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.5788647451230774 | validation: 0.49634109068976284]
	TIME [epoch: 9.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7348162600580649		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.7348162600580649 | validation: 0.5462414929342867]
	TIME [epoch: 9.74 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6165980765711192		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.6165980765711192 | validation: 0.4845019163862451]
	TIME [epoch: 9.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49728565599031754		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.49728565599031754 | validation: 0.4147328499241708]
	TIME [epoch: 9.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.564668712029989		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.564668712029989 | validation: 1.0430964495993567]
	TIME [epoch: 9.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.799117510495421		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 1.799117510495421 | validation: 2.778968670783045]
	TIME [epoch: 9.77 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.18821263152257		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 2.18821263152257 | validation: 2.1603470961217743]
	TIME [epoch: 9.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3926676634716761		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.3926676634716761 | validation: 0.9847022345472958]
	TIME [epoch: 9.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7847708501850135		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.7847708501850135 | validation: 0.9888299631915715]
	TIME [epoch: 9.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.800636787708306		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.800636787708306 | validation: 0.8985277475403031]
	TIME [epoch: 9.81 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.667206335942629		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.667206335942629 | validation: 0.6935600380101925]
	TIME [epoch: 9.77 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5285507280565196		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.5285507280565196 | validation: 0.4055345510028431]
	TIME [epoch: 9.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48811566241536597		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.48811566241536597 | validation: 0.4334636907250192]
	TIME [epoch: 9.76 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4522329808221117		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.4522329808221117 | validation: 0.39991911827854393]
	TIME [epoch: 9.78 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.537672569005124		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.537672569005124 | validation: 1.414912645226065]
	TIME [epoch: 9.76 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4191628741064335		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.4191628741064335 | validation: 2.2681575203179163]
	TIME [epoch: 9.76 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.340236298581309		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 2.340236298581309 | validation: 1.7589778764850972]
	TIME [epoch: 9.76 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7766209446015526		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 1.7766209446015526 | validation: 2.0726963624612287]
	TIME [epoch: 9.78 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8347918170041164		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 1.8347918170041164 | validation: 1.8946197197431052]
	TIME [epoch: 9.77 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4690861407546878		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 1.4690861407546878 | validation: 1.087850179116802]
	TIME [epoch: 9.77 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6926880600362256		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.6926880600362256 | validation: 0.48121137097820715]
	TIME [epoch: 9.78 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5958550283496732		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.5958550283496732 | validation: 0.533435189497123]
	TIME [epoch: 9.77 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5807234798298503		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.5807234798298503 | validation: 0.7992386899946368]
	TIME [epoch: 9.77 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.732387048082219		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.732387048082219 | validation: 0.5113605063854754]
	TIME [epoch: 9.76 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5442470283390536		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.5442470283390536 | validation: 0.5111182948317301]
	TIME [epoch: 9.78 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4853900166530958		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.4853900166530958 | validation: 0.459125617952351]
	TIME [epoch: 9.77 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4823322974782472		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.4823322974782472 | validation: 0.3519386364530769]
	TIME [epoch: 9.77 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5801660371474523		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.5801660371474523 | validation: 0.4979224592402193]
	TIME [epoch: 9.77 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47014972691145807		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.47014972691145807 | validation: 0.5166428029544525]
	TIME [epoch: 9.78 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46601290569865633		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.46601290569865633 | validation: 0.7052464684230515]
	TIME [epoch: 9.77 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5448462914904594		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.5448462914904594 | validation: 0.44076393810925546]
	TIME [epoch: 9.77 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5619671016833456		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5619671016833456 | validation: 1.034498608672726]
	TIME [epoch: 9.78 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7112632079598753		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.7112632079598753 | validation: 0.5512611010621796]
	TIME [epoch: 9.78 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6678606356460577		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.6678606356460577 | validation: 0.4647274402133494]
	TIME [epoch: 9.76 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5613920896426604		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.5613920896426604 | validation: 0.4995694518616821]
	TIME [epoch: 9.77 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5115880069865348		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.5115880069865348 | validation: 0.5723074314799308]
	TIME [epoch: 9.79 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.581053117263852		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.581053117263852 | validation: 0.6550309985106069]
	TIME [epoch: 9.77 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7694202736425825		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.7694202736425825 | validation: 0.7710048486066675]
	TIME [epoch: 9.77 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.767495726061826		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.767495726061826 | validation: 0.813412335010861]
	TIME [epoch: 9.77 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8126884253441761		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.8126884253441761 | validation: 0.8604722110047323]
	TIME [epoch: 9.78 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8131099917426625		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.8131099917426625 | validation: 0.7871621441586155]
	TIME [epoch: 9.77 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9501314869422183		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.9501314869422183 | validation: 1.4556353610296822]
	TIME [epoch: 9.76 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6567514996224035		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 1.6567514996224035 | validation: 1.9946823399242586]
	TIME [epoch: 9.78 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0094335594047537		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 2.0094335594047537 | validation: 1.8424333660725811]
	TIME [epoch: 9.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8291101180559315		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 1.8291101180559315 | validation: 2.053253209699513]
	TIME [epoch: 9.76 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1056004626424047		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 2.1056004626424047 | validation: 1.999484163175803]
	TIME [epoch: 9.76 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6130552051867737		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 1.6130552051867737 | validation: 1.578270709489445]
	TIME [epoch: 9.78 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2509722393262843		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.2509722393262843 | validation: 0.9381516014917238]
	TIME [epoch: 9.77 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3125227209600334		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 1.3125227209600334 | validation: 1.5175554689601556]
	TIME [epoch: 9.76 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4103234261965385		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 1.4103234261965385 | validation: 1.3181283841827542]
	TIME [epoch: 9.78 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9743164180307315		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.9743164180307315 | validation: 0.8508806434608396]
	TIME [epoch: 9.78 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.242635509081912		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 1.242635509081912 | validation: 1.1373851675065296]
	TIME [epoch: 9.77 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0979702852494528		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 1.0979702852494528 | validation: 0.8546716589337189]
	TIME [epoch: 9.77 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8014048270443507		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.8014048270443507 | validation: 0.6360164402841771]
	TIME [epoch: 9.78 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7829622650278929		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.7829622650278929 | validation: 0.8600662820427617]
	TIME [epoch: 9.77 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.731361272211458		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.731361272211458 | validation: 0.5543701485445196]
	TIME [epoch: 9.77 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5982503276656009		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.5982503276656009 | validation: 0.5048828998796641]
	TIME [epoch: 9.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8147412584310215		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.8147412584310215 | validation: 0.7206665616684764]
	TIME [epoch: 9.79 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8909990445861165		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.8909990445861165 | validation: 0.6804158477238011]
	TIME [epoch: 9.78 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8300455296328505		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.8300455296328505 | validation: 0.7607497184877486]
	TIME [epoch: 9.78 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9561820857718328		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.9561820857718328 | validation: 0.7218617188230312]
	TIME [epoch: 9.77 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9104462577259054		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.9104462577259054 | validation: 0.6508915922896115]
	TIME [epoch: 9.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8474270555761056		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.8474270555761056 | validation: 0.6613855955605347]
	TIME [epoch: 9.79 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8304669170912253		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8304669170912253 | validation: 0.5907138384495993]
	TIME [epoch: 9.77 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7432643780863274		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.7432643780863274 | validation: 0.4815611200908987]
	TIME [epoch: 9.79 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.708649983289639		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.708649983289639 | validation: 0.5547705982512816]
	TIME [epoch: 9.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8831565014470326		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.8831565014470326 | validation: 1.7874866486529128]
	TIME [epoch: 9.77 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6325368579967845		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 1.6325368579967845 | validation: 1.4332643457099672]
	TIME [epoch: 9.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6593889613772546		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 1.6593889613772546 | validation: 1.7983105850743528]
	TIME [epoch: 9.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4168299278705165		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 1.4168299278705165 | validation: 1.3103737788202587]
	TIME [epoch: 9.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0921392102556933		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 1.0921392102556933 | validation: 1.1317432338580038]
	TIME [epoch: 9.78 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.081466671369722		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.081466671369722 | validation: 1.239904489551962]
	TIME [epoch: 9.78 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.182850325147621		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 1.182850325147621 | validation: 1.0479491295916252]
	TIME [epoch: 9.78 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9085236137737314		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.9085236137737314 | validation: 0.7259582558478768]
	TIME [epoch: 9.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8797305946524219		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.8797305946524219 | validation: 0.8390040476332798]
	TIME [epoch: 9.77 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8882360191316127		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.8882360191316127 | validation: 0.6715358429406099]
	TIME [epoch: 9.79 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.869764297399951		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.869764297399951 | validation: 0.6964629775205511]
	TIME [epoch: 9.77 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.885375376868501		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.885375376868501 | validation: 0.6091487143507701]
	TIME [epoch: 9.78 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8086119027314704		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.8086119027314704 | validation: 0.5812930367868161]
	TIME [epoch: 9.77 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.861460160977011		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.861460160977011 | validation: 0.6458886797947334]
	TIME [epoch: 9.78 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7804366044861696		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.7804366044861696 | validation: 0.5440375166447885]
	TIME [epoch: 9.76 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7333150911968878		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.7333150911968878 | validation: 0.51882575245368]
	TIME [epoch: 9.77 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8709494707646496		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.8709494707646496 | validation: 0.6829477090465291]
	TIME [epoch: 9.77 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8284948403032791		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.8284948403032791 | validation: 0.6154817158600135]
	TIME [epoch: 9.77 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8187102696423947		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.8187102696423947 | validation: 0.8459251447973785]
	TIME [epoch: 9.77 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9198993931387712		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.9198993931387712 | validation: 0.770060193118983]
	TIME [epoch: 9.76 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.795605038386443		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.795605038386443 | validation: 0.527260362220284]
	TIME [epoch: 9.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7683186879668473		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7683186879668473 | validation: 0.5476408356077054]
	TIME [epoch: 9.76 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7155638820288528		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.7155638820288528 | validation: 0.5294256416883937]
	TIME [epoch: 9.76 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7248469520965882		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.7248469520965882 | validation: 0.5264156774131875]
	TIME [epoch: 9.77 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7235489871009839		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.7235489871009839 | validation: 0.5339001255065225]
	TIME [epoch: 9.78 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7717224861712599		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.7717224861712599 | validation: 0.6454416442473556]
	TIME [epoch: 9.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.837780356422394		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.837780356422394 | validation: 0.5885576017277209]
	TIME [epoch: 9.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7779373034790766		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.7779373034790766 | validation: 0.5873378135815934]
	TIME [epoch: 9.77 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7786687480969976		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.7786687480969976 | validation: 0.5589902112684937]
	TIME [epoch: 9.76 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.767350187819405		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.767350187819405 | validation: 0.5324788232942964]
	TIME [epoch: 9.75 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7431362383066715		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.7431362383066715 | validation: 0.5508879846340028]
	TIME [epoch: 9.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7159487528951739		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.7159487528951739 | validation: 0.524687922690634]
	TIME [epoch: 9.79 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7275472741324855		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.7275472741324855 | validation: 0.5360105798066651]
	TIME [epoch: 9.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7071255480566304		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.7071255480566304 | validation: 0.5662891135573822]
	TIME [epoch: 9.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8590190348685289		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.8590190348685289 | validation: 0.563648485247768]
	TIME [epoch: 9.76 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6830035945633027		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.6830035945633027 | validation: 0.4621995569396461]
	TIME [epoch: 9.77 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6426363867214935		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.6426363867214935 | validation: 0.4428202631315431]
	TIME [epoch: 9.76 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5826833734952443		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5826833734952443 | validation: 0.4290101864054279]
	TIME [epoch: 9.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5545518202231112		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.5545518202231112 | validation: 0.4123694709731682]
	TIME [epoch: 9.77 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5554321270986728		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.5554321270986728 | validation: 0.4339043472359504]
	TIME [epoch: 9.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5707656926136122		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.5707656926136122 | validation: 0.42938554436765075]
	TIME [epoch: 9.76 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5260975803654672		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.5260975803654672 | validation: 0.4245437159789064]
	TIME [epoch: 9.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5239288364092916		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.5239288364092916 | validation: 0.4170083403011864]
	TIME [epoch: 9.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5575504352573493		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.5575504352573493 | validation: 0.4792508147534396]
	TIME [epoch: 9.77 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5267985752451038		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.5267985752451038 | validation: 0.3908282082186313]
	TIME [epoch: 9.77 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5157437493954194		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5157437493954194 | validation: 0.41961505829735907]
	TIME [epoch: 9.77 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5092480054585544		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.5092480054585544 | validation: 0.40944047236763154]
	TIME [epoch: 9.79 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5283538527779215		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.5283538527779215 | validation: 0.49622055994623454]
	TIME [epoch: 9.77 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5174088069389621		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.5174088069389621 | validation: 0.4471845485096192]
	TIME [epoch: 9.77 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5619554005663177		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.5619554005663177 | validation: 0.43951390255576317]
	TIME [epoch: 9.79 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49845351602142884		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.49845351602142884 | validation: 0.4519099210011401]
	TIME [epoch: 9.78 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.521819676844119		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.521819676844119 | validation: 0.44125092156798174]
	TIME [epoch: 9.77 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5067184037286651		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.5067184037286651 | validation: 0.4058205058708347]
	TIME [epoch: 9.78 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6102705969832408		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6102705969832408 | validation: 0.4168917134780862]
	TIME [epoch: 9.79 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5143783768117154		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.5143783768117154 | validation: 0.3838207309142246]
	TIME [epoch: 9.78 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6382317400349199		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.6382317400349199 | validation: 0.49352251763501176]
	TIME [epoch: 9.77 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.598198085919793		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.598198085919793 | validation: 0.45088371761555646]
	TIME [epoch: 9.79 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6071583562352489		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.6071583562352489 | validation: 0.49349986950378033]
	TIME [epoch: 9.78 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6279369765078868		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.6279369765078868 | validation: 0.461481513690258]
	TIME [epoch: 9.77 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6695340963809361		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.6695340963809361 | validation: 0.5782859013385685]
	TIME [epoch: 9.77 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6410690384069835		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.6410690384069835 | validation: 0.4491447055766269]
	TIME [epoch: 9.79 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.585924052027909		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.585924052027909 | validation: 0.5720960355072486]
	TIME [epoch: 9.76 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6527126728299844		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.6527126728299844 | validation: 0.4805640903720854]
	TIME [epoch: 9.77 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5816375600246949		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.5816375600246949 | validation: 0.46352034154425914]
	TIME [epoch: 9.76 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5560403874371854		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.5560403874371854 | validation: 0.4479986359063421]
	TIME [epoch: 9.79 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5473401287866531		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.5473401287866531 | validation: 0.42339490540697755]
	TIME [epoch: 9.76 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6199812800019535		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.6199812800019535 | validation: 0.5161320237326136]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v9_20240711_163446/states/model_facs_v2_dec1b_2dpca_v9_444.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4408.358 seconds.
