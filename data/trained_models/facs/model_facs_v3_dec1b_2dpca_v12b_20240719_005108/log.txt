Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v12b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v12b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2267095346

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.7529229478506008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7529229478506008 | validation: 1.1879444933404408]
	TIME [epoch: 28.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.3179785390069918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3179785390069918 | validation: 1.125026342639815]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2611819289568864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2611819289568864 | validation: 1.1113680964217973]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2587193324193784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2587193324193784 | validation: 1.0731599727523122]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.251677464632391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.251677464632391 | validation: 1.0961998260136991]
	TIME [epoch: 9.8 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2171935378497627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2171935378497627 | validation: 1.0236175652373825]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1887757898735394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1887757898735394 | validation: 0.9972080808759166]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1746298985079329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1746298985079329 | validation: 0.968591120414916]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.129099820137599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.129099820137599 | validation: 0.9149149902201372]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.10067194043747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.10067194043747 | validation: 0.9073516309079969]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.0340258605148516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0340258605148516 | validation: 0.8635676845263017]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.9581574638618121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9581574638618121 | validation: 0.8024746403740604]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.8499363667732692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8499363667732692 | validation: 0.7413317053367905]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.7631538256717363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7631538256717363 | validation: 0.8334812598460679]
	TIME [epoch: 9.78 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.7164636749453698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7164636749453698 | validation: 0.5843039240021011]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6110802531574373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6110802531574373 | validation: 0.5581762820886309]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6411953770283257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6411953770283257 | validation: 0.48442621809773734]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5474765765009165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5474765765009165 | validation: 0.4613222343846594]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5027698376403401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5027698376403401 | validation: 0.42398125086340804]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5000220394403073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5000220394403073 | validation: 0.4209682498722101]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5633780143987216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5633780143987216 | validation: 0.3719262689640303]
	TIME [epoch: 9.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.44707871465478904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44707871465478904 | validation: 0.34630200557302687]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4369659770882995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4369659770882995 | validation: 0.3412967369435679]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.42673444602749866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42673444602749866 | validation: 0.3660704840955466]
	TIME [epoch: 9.75 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3872601707777865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3872601707777865 | validation: 0.31311573643946805]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3927530359640927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3927530359640927 | validation: 0.3183554907919137]
	TIME [epoch: 9.77 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.37703625923689615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37703625923689615 | validation: 0.3106971385795846]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3797953847866249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3797953847866249 | validation: 0.2976242600648632]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3571845266057787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3571845266057787 | validation: 0.34771944561200385]
	TIME [epoch: 9.8 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.40142896209356055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40142896209356055 | validation: 0.29259665668690815]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3591004498844084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3591004498844084 | validation: 0.3155176485688987]
	TIME [epoch: 9.81 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3478665147417402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3478665147417402 | validation: 0.3376443987653223]
	TIME [epoch: 9.82 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3285503139953685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3285503139953685 | validation: 0.2698541132688719]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3650653118800329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3650653118800329 | validation: 0.2762980676455156]
	TIME [epoch: 9.74 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.33111700033367114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33111700033367114 | validation: 0.29111851138530487]
	TIME [epoch: 9.74 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3382051821212247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3382051821212247 | validation: 0.30913776921198055]
	TIME [epoch: 9.76 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.36186235050997845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36186235050997845 | validation: 0.2640884664250596]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32736033738232767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32736033738232767 | validation: 0.2685512687728897]
	TIME [epoch: 9.79 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3199742612819366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3199742612819366 | validation: 0.26645778053945335]
	TIME [epoch: 9.8 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32533661522931484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32533661522931484 | validation: 0.3132656945872591]
	TIME [epoch: 9.79 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.33380487655726787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33380487655726787 | validation: 0.2665032696562374]
	TIME [epoch: 9.79 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3122898159304387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3122898159304387 | validation: 0.3322652653093302]
	TIME [epoch: 9.81 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3414139828615001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3414139828615001 | validation: 0.26326452517836096]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31095370416051965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31095370416051965 | validation: 0.2557743676492302]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31820586638549747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31820586638549747 | validation: 0.25820460168191417]
	TIME [epoch: 9.78 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.35483073325157966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35483073325157966 | validation: 0.25552652741440646]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32184033133718726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32184033133718726 | validation: 0.2569774642449195]
	TIME [epoch: 9.77 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.312397907768412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.312397907768412 | validation: 0.2641101367592064]
	TIME [epoch: 9.81 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32103221934415077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32103221934415077 | validation: 0.25083005392406144]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31127106586083714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31127106586083714 | validation: 0.24418136816141103]
	TIME [epoch: 9.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3115615114292667		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.3115615114292667 | validation: 0.253076106114014]
	TIME [epoch: 35.3 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29867231193155813		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.29867231193155813 | validation: 0.2855728598863645]
	TIME [epoch: 18.8 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31943467798687397		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.31943467798687397 | validation: 0.24269687430159084]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.30778266561154927		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.30778266561154927 | validation: 0.24377184227572876]
	TIME [epoch: 18.8 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31372277316862707		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.31372277316862707 | validation: 0.24098970527146774]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2997760573054557		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.2997760573054557 | validation: 0.2515042797649544]
	TIME [epoch: 18.8 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3036399976268424		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.3036399976268424 | validation: 0.29101248622973125]
	TIME [epoch: 18.8 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3101556697263956		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.3101556697263956 | validation: 0.2433522097889605]
	TIME [epoch: 18.8 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3051689920128296		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.3051689920128296 | validation: 0.23498517628703194]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28762212697290723		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.28762212697290723 | validation: 0.24080305517646017]
	TIME [epoch: 18.7 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31382142106991345		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.31382142106991345 | validation: 0.2526924854274749]
	TIME [epoch: 18.7 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29956776416963066		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.29956776416963066 | validation: 0.25142624581695205]
	TIME [epoch: 18.8 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29301697326566994		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.29301697326566994 | validation: 0.2338769211983422]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31152627260336513		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.31152627260336513 | validation: 0.2333369167088227]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29745993535234955		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.29745993535234955 | validation: 0.23565881522032753]
	TIME [epoch: 18.9 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2898795989381587		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.2898795989381587 | validation: 0.23910514560789609]
	TIME [epoch: 18.8 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29121826343847623		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.29121826343847623 | validation: 0.24693349287513738]
	TIME [epoch: 18.7 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.296400746287609		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.296400746287609 | validation: 0.22735742702240458]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31075814820228626		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.31075814820228626 | validation: 0.24470921211909052]
	TIME [epoch: 18.8 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2889926723750022		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.2889926723750022 | validation: 0.23076618946992572]
	TIME [epoch: 18.9 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854628161186624		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.2854628161186624 | validation: 0.2264776272282017]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2927029725678984		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.2927029725678984 | validation: 0.22622343879849094]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29150655573587275		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.29150655573587275 | validation: 0.22877261339774332]
	TIME [epoch: 18.8 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2832852937939038		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.2832852937939038 | validation: 0.22620558423746528]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28975373077681305		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.28975373077681305 | validation: 0.22551020293257035]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3017863368548103		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.3017863368548103 | validation: 0.23490961147585057]
	TIME [epoch: 18.7 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2859469360134677		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.2859469360134677 | validation: 0.2358194848393766]
	TIME [epoch: 18.7 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28276946018697807		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.28276946018697807 | validation: 0.22475522324692326]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2899492811677673		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.2899492811677673 | validation: 0.23177014921338718]
	TIME [epoch: 18.8 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2888480459325578		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.2888480459325578 | validation: 0.22066708565514315]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2819739989317305		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.2819739989317305 | validation: 0.23618552874514132]
	TIME [epoch: 18.8 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27390940662124463		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.27390940662124463 | validation: 0.23185293024451498]
	TIME [epoch: 18.8 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29471788628748924		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.29471788628748924 | validation: 0.22265412448518623]
	TIME [epoch: 18.8 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2876186723394519		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.2876186723394519 | validation: 0.2344136434356196]
	TIME [epoch: 18.8 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28334680756883635		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.28334680756883635 | validation: 0.22292249498838396]
	TIME [epoch: 18.8 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28175477620530587		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.28175477620530587 | validation: 0.22378754704217654]
	TIME [epoch: 18.8 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799130817209689		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.2799130817209689 | validation: 0.22599049560222295]
	TIME [epoch: 18.8 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28295063727943986		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.28295063727943986 | validation: 0.2337461419132679]
	TIME [epoch: 18.8 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27655129933959094		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.27655129933959094 | validation: 0.22526324892788704]
	TIME [epoch: 18.8 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2890607500572883		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.2890607500572883 | validation: 0.2257313059152934]
	TIME [epoch: 18.7 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2772226881785148		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.2772226881785148 | validation: 0.23038679225970332]
	TIME [epoch: 18.9 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2785716050772777		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.2785716050772777 | validation: 0.23173266624439956]
	TIME [epoch: 18.7 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28289424192562745		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.28289424192562745 | validation: 0.25813582324520695]
	TIME [epoch: 18.8 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.30090504567197757		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.30090504567197757 | validation: 0.22071465139481355]
	TIME [epoch: 18.7 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689308760451573		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.2689308760451573 | validation: 0.2177265276552441]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2718294003755908		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.2718294003755908 | validation: 0.22475095190254007]
	TIME [epoch: 18.7 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27956535395901705		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.27956535395901705 | validation: 0.21934383788790773]
	TIME [epoch: 18.7 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27136128494598494		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.27136128494598494 | validation: 0.2364598741865155]
	TIME [epoch: 18.8 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28446856098966816		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.28446856098966816 | validation: 0.23019738445818927]
	TIME [epoch: 18.8 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2757500033502085		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.2757500033502085 | validation: 0.22792346224259225]
	TIME [epoch: 18.9 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2776073334783978		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.2776073334783978 | validation: 0.2294068218566029]
	TIME [epoch: 56.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27447173356564986		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.27447173356564986 | validation: 0.22652740541664346]
	TIME [epoch: 40 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2736039602044142		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.2736039602044142 | validation: 0.24203130694265979]
	TIME [epoch: 40 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29054902911927544		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.29054902911927544 | validation: 0.2225232986803852]
	TIME [epoch: 40 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28161542926933875		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.28161542926933875 | validation: 0.23835204174135902]
	TIME [epoch: 40 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27670670165302536		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.27670670165302536 | validation: 0.22273038186368624]
	TIME [epoch: 40 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26586399329518573		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.26586399329518573 | validation: 0.2217479773830827]
	TIME [epoch: 40 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2720042000459168		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.2720042000459168 | validation: 0.22288331472854606]
	TIME [epoch: 40 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26773414961371217		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.26773414961371217 | validation: 0.21853830718940914]
	TIME [epoch: 40 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.283388280554222		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.283388280554222 | validation: 0.21829594689619958]
	TIME [epoch: 40 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668762929228102		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.2668762929228102 | validation: 0.22032064092857823]
	TIME [epoch: 40 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2764336206666889		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.2764336206666889 | validation: 0.22056461303348945]
	TIME [epoch: 39.9 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28551848558653453		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.28551848558653453 | validation: 0.22395196685766555]
	TIME [epoch: 40 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716708010601753		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.2716708010601753 | validation: 0.22132651795268438]
	TIME [epoch: 39.9 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27321117113548504		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.27321117113548504 | validation: 0.21921502303705656]
	TIME [epoch: 40 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674172211400627		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.2674172211400627 | validation: 0.22094571560774495]
	TIME [epoch: 40 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25862813023544234		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.25862813023544234 | validation: 0.22385222480631145]
	TIME [epoch: 40 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27768001684766946		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.27768001684766946 | validation: 0.2268354154010846]
	TIME [epoch: 40 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2739584382497247		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.2739584382497247 | validation: 0.22279571300235154]
	TIME [epoch: 40 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26699099871159826		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.26699099871159826 | validation: 0.21965428895247863]
	TIME [epoch: 39.9 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26386051871237776		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.26386051871237776 | validation: 0.21096305382870778]
	TIME [epoch: 39.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26445575563141827		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.26445575563141827 | validation: 0.2164910838746034]
	TIME [epoch: 39.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.264630178674823		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.264630178674823 | validation: 0.22189779394919357]
	TIME [epoch: 40 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25697739222826393		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.25697739222826393 | validation: 0.21486995107942386]
	TIME [epoch: 40.1 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27043501730416336		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.27043501730416336 | validation: 0.233191567748124]
	TIME [epoch: 40.1 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27467262781378887		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.27467262781378887 | validation: 0.21674267211136705]
	TIME [epoch: 40.1 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26981349368808577		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.26981349368808577 | validation: 0.22228359988309002]
	TIME [epoch: 40.1 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670890756012218		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.2670890756012218 | validation: 0.21966210439240239]
	TIME [epoch: 40 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2723073597572135		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.2723073597572135 | validation: 0.2174508252434058]
	TIME [epoch: 40 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27137813706632047		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.27137813706632047 | validation: 0.21705655518335715]
	TIME [epoch: 40.1 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26667811251303025		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.26667811251303025 | validation: 0.21482168518248593]
	TIME [epoch: 40.1 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629941532643432		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.2629941532643432 | validation: 0.21282419155123575]
	TIME [epoch: 40.1 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25824086926248263		[learning rate: 0.0054755]
	Learning Rate: 0.00547546
	LOSS [training: 0.25824086926248263 | validation: 0.21578043781177264]
	TIME [epoch: 40 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2831670883268725		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.2831670883268725 | validation: 0.21616389926050816]
	TIME [epoch: 40 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26289476539832757		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.26289476539832757 | validation: 0.20865912666254677]
	TIME [epoch: 40 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670708781856717		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.2670708781856717 | validation: 0.22171421160623064]
	TIME [epoch: 39.9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26707464664945746		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.26707464664945746 | validation: 0.21519894307537174]
	TIME [epoch: 40 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26361192509662734		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.26361192509662734 | validation: 0.217186712713597]
	TIME [epoch: 40 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27029606409246804		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.27029606409246804 | validation: 0.21395896775266915]
	TIME [epoch: 40.1 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639001863289973		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.2639001863289973 | validation: 0.21319147887393278]
	TIME [epoch: 40 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26483014573499486		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.26483014573499486 | validation: 0.22062976448664867]
	TIME [epoch: 40 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26542799162053055		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.26542799162053055 | validation: 0.2149848031298803]
	TIME [epoch: 40 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669706765061421		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.2669706765061421 | validation: 0.2151982801230358]
	TIME [epoch: 40 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26126560066947435		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.26126560066947435 | validation: 0.21477717854553754]
	TIME [epoch: 40 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26085910657439565		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.26085910657439565 | validation: 0.21902617736263993]
	TIME [epoch: 40 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597886924572533		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.2597886924572533 | validation: 0.21872452398852923]
	TIME [epoch: 40 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26846882070603845		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.26846882070603845 | validation: 0.2165628351070601]
	TIME [epoch: 40 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26975071249454924		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.26975071249454924 | validation: 0.2118357039610151]
	TIME [epoch: 40 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653560304408435		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.2653560304408435 | validation: 0.21343342719120492]
	TIME [epoch: 40.1 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627917747768456		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.2627917747768456 | validation: 0.21239870766655972]
	TIME [epoch: 39.9 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559290316161749		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.2559290316161749 | validation: 0.22048745564160663]
	TIME [epoch: 40 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690637811477164		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.2690637811477164 | validation: 0.2151570625630347]
	TIME [epoch: 40.1 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26794550882474305		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.26794550882474305 | validation: 0.21507123882903395]
	TIME [epoch: 40 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590044673329197		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.2590044673329197 | validation: 0.21107413886341755]
	TIME [epoch: 40 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25633950486243867		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.25633950486243867 | validation: 0.21501905784235187]
	TIME [epoch: 40 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2686913366419745		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.2686913366419745 | validation: 0.21219288061682445]
	TIME [epoch: 40 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625440390872664		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.2625440390872664 | validation: 0.22198995188487566]
	TIME [epoch: 40 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26317595968072893		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.26317595968072893 | validation: 0.21694978369373122]
	TIME [epoch: 40 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25910329817898775		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.25910329817898775 | validation: 0.20872005517061076]
	TIME [epoch: 40 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557514810187485		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.2557514810187485 | validation: 0.2327522219221047]
	TIME [epoch: 40 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26845354598749477		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.26845354598749477 | validation: 0.21988230425300062]
	TIME [epoch: 40 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.258982705051937		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.258982705051937 | validation: 0.21776185364752573]
	TIME [epoch: 40 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.256474557964653		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.256474557964653 | validation: 0.21009065974196778]
	TIME [epoch: 39.9 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26749006226613137		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.26749006226613137 | validation: 0.2112263524741882]
	TIME [epoch: 40 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25799444254184994		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.25799444254184994 | validation: 0.21291498764411726]
	TIME [epoch: 40.1 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566854548779636		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.2566854548779636 | validation: 0.21966179738787966]
	TIME [epoch: 39.9 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592950691719183		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.2592950691719183 | validation: 0.2114331190100957]
	TIME [epoch: 40.1 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2722668924458639		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.2722668924458639 | validation: 0.2185269217190481]
	TIME [epoch: 40 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644741325226265		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.2644741325226265 | validation: 0.22035780984194578]
	TIME [epoch: 40 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25908303680584105		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.25908303680584105 | validation: 0.20941139732298172]
	TIME [epoch: 40 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540230537162582		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.2540230537162582 | validation: 0.21460481497663708]
	TIME [epoch: 40 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.263721314244784		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.263721314244784 | validation: 0.21133404829013416]
	TIME [epoch: 40.1 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2615508484633427		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.2615508484633427 | validation: 0.21823958554275533]
	TIME [epoch: 40 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556684990502512		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.2556684990502512 | validation: 0.21453791412997333]
	TIME [epoch: 40 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25923129277875884		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.25923129277875884 | validation: 0.21690009286934445]
	TIME [epoch: 39.9 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25482283296194913		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.25482283296194913 | validation: 0.21568323585800306]
	TIME [epoch: 39.9 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26258784728644474		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.26258784728644474 | validation: 0.21440516035864862]
	TIME [epoch: 40 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25548261727621385		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.25548261727621385 | validation: 0.21300224494207817]
	TIME [epoch: 40 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.262258097073373		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.262258097073373 | validation: 0.21048874973534995]
	TIME [epoch: 39.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508132523853406		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.2508132523853406 | validation: 0.2224143352450903]
	TIME [epoch: 40 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26046503469410937		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.26046503469410937 | validation: 0.2167196372149413]
	TIME [epoch: 40 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25736089460734585		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.25736089460734585 | validation: 0.21250683722385078]
	TIME [epoch: 39.9 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2748129955115351		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.2748129955115351 | validation: 0.2476950894492366]
	TIME [epoch: 40 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27744970031623434		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.27744970031623434 | validation: 0.21532189452836653]
	TIME [epoch: 40 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559766012042939		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.2559766012042939 | validation: 0.2109929195348157]
	TIME [epoch: 40.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25862137866726675		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.25862137866726675 | validation: 0.21483193664101155]
	TIME [epoch: 40 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576378912689537		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.2576378912689537 | validation: 0.2116574832187757]
	TIME [epoch: 40 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25326985755961456		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.25326985755961456 | validation: 0.2118235127338119]
	TIME [epoch: 40.1 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.256764567653968		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.256764567653968 | validation: 0.21590016511904184]
	TIME [epoch: 40.1 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576416958274434		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.2576416958274434 | validation: 0.2108534971153647]
	TIME [epoch: 40 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25608052988067875		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.25608052988067875 | validation: 0.21379668384973693]
	TIME [epoch: 40 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26203705796007726		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.26203705796007726 | validation: 0.20841732710422273]
	TIME [epoch: 40 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_192.pth
	Model improved!!!
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533295047035043		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.2533295047035043 | validation: 0.20973910586883662]
	TIME [epoch: 39.9 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25376112201155027		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.25376112201155027 | validation: 0.21452274293808227]
	TIME [epoch: 39.9 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25682500157260924		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.25682500157260924 | validation: 0.2233246921961065]
	TIME [epoch: 40 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654201406820111		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.2654201406820111 | validation: 0.21526411300603326]
	TIME [epoch: 40 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552644491747958		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.2552644491747958 | validation: 0.21109264990348242]
	TIME [epoch: 40 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25418524255581243		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.25418524255581243 | validation: 0.21566821060744035]
	TIME [epoch: 40 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.256191780744019		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.256191780744019 | validation: 0.20672207891560798]
	TIME [epoch: 40 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542434419093462		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.2542434419093462 | validation: 0.21495940844131317]
	TIME [epoch: 40 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25890139451474153		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.25890139451474153 | validation: 0.2110836434718902]
	TIME [epoch: 102 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547091743146701		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.2547091743146701 | validation: 0.2119213701370822]
	TIME [epoch: 85.2 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25785250148117517		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.25785250148117517 | validation: 0.21657722434511834]
	TIME [epoch: 85.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25600564808163634		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.25600564808163634 | validation: 0.21517426228191897]
	TIME [epoch: 85.2 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684031642964881		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.2684031642964881 | validation: 0.217104246750222]
	TIME [epoch: 85.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.260687278854826		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.260687278854826 | validation: 0.21454561111075882]
	TIME [epoch: 85.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642515041744276		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.2642515041744276 | validation: 0.21294036825024248]
	TIME [epoch: 85.2 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534529515482334		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.2534529515482334 | validation: 0.2095720710949116]
	TIME [epoch: 85.2 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25376873001423456		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.25376873001423456 | validation: 0.2110441629608109]
	TIME [epoch: 85.2 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25829277653660715		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.25829277653660715 | validation: 0.21422044177921723]
	TIME [epoch: 85.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568058716991061		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.2568058716991061 | validation: 0.22142628976072984]
	TIME [epoch: 85.2 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26038386500333893		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.26038386500333893 | validation: 0.21173430148620515]
	TIME [epoch: 85.1 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25015736649004133		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.25015736649004133 | validation: 0.21002891988651626]
	TIME [epoch: 85.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25101918878633406		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.25101918878633406 | validation: 0.21432236497507104]
	TIME [epoch: 85.2 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25192177527215437		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.25192177527215437 | validation: 0.2177962339050204]
	TIME [epoch: 85.4 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25499791057554005		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.25499791057554005 | validation: 0.216266758183834]
	TIME [epoch: 85.2 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586040945885389		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.2586040945885389 | validation: 0.20755748948621947]
	TIME [epoch: 85.4 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584647469908667		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.2584647469908667 | validation: 0.21772612053263568]
	TIME [epoch: 85.2 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25845329743316164		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.25845329743316164 | validation: 0.2085500911255674]
	TIME [epoch: 85.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25274875881343545		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.25274875881343545 | validation: 0.2141439562937249]
	TIME [epoch: 85.1 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25816395397799907		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.25816395397799907 | validation: 0.20909180594721133]
	TIME [epoch: 85.2 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25316155892452064		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.25316155892452064 | validation: 0.20863976024730319]
	TIME [epoch: 85.4 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546198325560009		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.2546198325560009 | validation: 0.21270447402335982]
	TIME [epoch: 85.2 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565235050304172		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.2565235050304172 | validation: 0.209626881575448]
	TIME [epoch: 85.4 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562314416377151		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.2562314416377151 | validation: 0.2178959908299003]
	TIME [epoch: 85.2 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541389340268385		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.2541389340268385 | validation: 0.21340516691878197]
	TIME [epoch: 85.2 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628278791665698		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.2628278791665698 | validation: 0.2156157830705217]
	TIME [epoch: 85.2 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.258672672016184		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.258672672016184 | validation: 0.2096563510744783]
	TIME [epoch: 85.2 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527360033556492		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.2527360033556492 | validation: 0.20998830920904837]
	TIME [epoch: 85.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539719777491772		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.2539719777491772 | validation: 0.21130153754710929]
	TIME [epoch: 85.3 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592948272873687		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.2592948272873687 | validation: 0.20988707767664563]
	TIME [epoch: 85.1 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526688742944941		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.2526688742944941 | validation: 0.21212671045829828]
	TIME [epoch: 85.2 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557729708889314		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.2557729708889314 | validation: 0.2090214533286323]
	TIME [epoch: 85.4 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24931623845718118		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.24931623845718118 | validation: 0.20933965278284078]
	TIME [epoch: 85.1 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577931652312144		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.2577931652312144 | validation: 0.21458314638171067]
	TIME [epoch: 85.2 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25517026301550333		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.25517026301550333 | validation: 0.21191016813321312]
	TIME [epoch: 85.3 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567851684588893		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.2567851684588893 | validation: 0.21241997236558663]
	TIME [epoch: 85.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525388379371916		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.2525388379371916 | validation: 0.211600492358431]
	TIME [epoch: 85.1 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25541586086948254		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.25541586086948254 | validation: 0.21146042652694064]
	TIME [epoch: 85.3 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25438556094465536		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.25438556094465536 | validation: 0.212515311031296]
	TIME [epoch: 85.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25419919868783897		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.25419919868783897 | validation: 0.21417152723624716]
	TIME [epoch: 85.2 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25396643687595677		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.25396643687595677 | validation: 0.20813865692443206]
	TIME [epoch: 85.1 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510212005587007		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.2510212005587007 | validation: 0.20849989326599716]
	TIME [epoch: 85.2 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862273595670023		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.24862273595670023 | validation: 0.21831198104995794]
	TIME [epoch: 85.1 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25466189072046586		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.25466189072046586 | validation: 0.21125385561714136]
	TIME [epoch: 85 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520570674327965		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.2520570674327965 | validation: 0.21048588327713666]
	TIME [epoch: 85.2 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25609158407237204		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.25609158407237204 | validation: 0.2115055414333958]
	TIME [epoch: 85.1 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540429320411968		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.2540429320411968 | validation: 0.20972233848739844]
	TIME [epoch: 85.2 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24801197401302733		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.24801197401302733 | validation: 0.20910884753620312]
	TIME [epoch: 85.2 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24721601498695392		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.24721601498695392 | validation: 0.20748092594023584]
	TIME [epoch: 85.1 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25169628813851946		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.25169628813851946 | validation: 0.20827507492374764]
	TIME [epoch: 85.1 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524328764509886		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.2524328764509886 | validation: 0.21194730508656145]
	TIME [epoch: 85.2 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24629141127783574		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.24629141127783574 | validation: 0.21568541547487508]
	TIME [epoch: 85.1 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564024006147329		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.2564024006147329 | validation: 0.21228935123120157]
	TIME [epoch: 85.1 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25241220854501023		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.25241220854501023 | validation: 0.21117269640256336]
	TIME [epoch: 85 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25375537660745895		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.25375537660745895 | validation: 0.21057924570073352]
	TIME [epoch: 85 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535754377056419		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.2535754377056419 | validation: 0.20686136561553847]
	TIME [epoch: 85.1 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545179675414356		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.2545179675414356 | validation: 0.21122392778860685]
	TIME [epoch: 85.2 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552085045333065		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.2552085045333065 | validation: 0.20998215478879664]
	TIME [epoch: 85 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523727565335189		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.2523727565335189 | validation: 0.20868349162386574]
	TIME [epoch: 85.1 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571826643206287		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.2571826643206287 | validation: 0.20915284018422273]
	TIME [epoch: 85.1 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458341272649381		[learning rate: 0.0021432]
	Learning Rate: 0.00214315
	LOSS [training: 0.2458341272649381 | validation: 0.212565205339114]
	TIME [epoch: 85 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554055561419389		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.2554055561419389 | validation: 0.2122525206969374]
	TIME [epoch: 84.9 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25565429142651874		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.25565429142651874 | validation: 0.20908088486795937]
	TIME [epoch: 85 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470393443357433		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.2470393443357433 | validation: 0.21257436828696155]
	TIME [epoch: 85 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942884851026437		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.24942884851026437 | validation: 0.2164303353521999]
	TIME [epoch: 85 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509865002474988		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.2509865002474988 | validation: 0.21238821269504946]
	TIME [epoch: 85.1 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24959562595042573		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.24959562595042573 | validation: 0.20527001763705915]
	TIME [epoch: 85.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25265871591601385		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.25265871591601385 | validation: 0.214338389017226]
	TIME [epoch: 85 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24887487745721468		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.24887487745721468 | validation: 0.20867564342972353]
	TIME [epoch: 85 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506429601353456		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.2506429601353456 | validation: 0.20874354298779624]
	TIME [epoch: 85.2 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521958923375039		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.2521958923375039 | validation: 0.2162310909935557]
	TIME [epoch: 85.2 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.255222842650127		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.255222842650127 | validation: 0.20985471195989955]
	TIME [epoch: 85 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507028541457221		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.2507028541457221 | validation: 0.21151714603817923]
	TIME [epoch: 85.1 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523978115735926		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.2523978115735926 | validation: 0.20813551887669535]
	TIME [epoch: 85.1 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504157542981453		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.2504157542981453 | validation: 0.20697408170000262]
	TIME [epoch: 85.1 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24559095422472596		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.24559095422472596 | validation: 0.21247278340487125]
	TIME [epoch: 85.1 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24922554543515477		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.24922554543515477 | validation: 0.20958281890277236]
	TIME [epoch: 85.2 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25508914915470593		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.25508914915470593 | validation: 0.20980696509171345]
	TIME [epoch: 85.1 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25028243685608015		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.25028243685608015 | validation: 0.20821302710982117]
	TIME [epoch: 85.2 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25470657148146797		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.25470657148146797 | validation: 0.21198909473640154]
	TIME [epoch: 85.2 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491821707449147		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.2491821707449147 | validation: 0.20743401061663924]
	TIME [epoch: 85.1 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554169340193873		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.2554169340193873 | validation: 0.2141987910994143]
	TIME [epoch: 85.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25026866975252443		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.25026866975252443 | validation: 0.20811271615772978]
	TIME [epoch: 85.1 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25188355342341046		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.25188355342341046 | validation: 0.20886143562438547]
	TIME [epoch: 85.1 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486047422779193		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.2486047422779193 | validation: 0.20841431300479565]
	TIME [epoch: 84.9 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578448442869166		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.2578448442869166 | validation: 0.20488377697726862]
	TIME [epoch: 85.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25026286608029075		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.25026286608029075 | validation: 0.2068653594836721]
	TIME [epoch: 84.4 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25184588437824834		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.25184588437824834 | validation: 0.21398030067310855]
	TIME [epoch: 84.4 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24889872386871778		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.24889872386871778 | validation: 0.2130240084363873]
	TIME [epoch: 84.6 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565036965050087		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.2565036965050087 | validation: 0.21126668578902996]
	TIME [epoch: 85.1 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24730795594919666		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.24730795594919666 | validation: 0.20673562943517937]
	TIME [epoch: 85 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24734374150192526		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.24734374150192526 | validation: 0.2091953585210981]
	TIME [epoch: 85 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554005003019285		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.2554005003019285 | validation: 0.21087641580859023]
	TIME [epoch: 85.2 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522575074284424		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.2522575074284424 | validation: 0.20352969040889426]
	TIME [epoch: 85.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_295.pth
	Model improved!!!
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532200952215394		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.2532200952215394 | validation: 0.21148564443605816]
	TIME [epoch: 84.9 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25277786689016896		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.25277786689016896 | validation: 0.2086182369748419]
	TIME [epoch: 84.7 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25069750307838695		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.25069750307838695 | validation: 0.20807738006148]
	TIME [epoch: 84.8 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526191486245046		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.2526191486245046 | validation: 0.20993953552900071]
	TIME [epoch: 84.8 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25067335749679676		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.25067335749679676 | validation: 0.20656317517115402]
	TIME [epoch: 84.8 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522445334494355		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.2522445334494355 | validation: 0.21030349070606427]
	TIME [epoch: 193 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486972971741365		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.2486972971741365 | validation: 0.2101483245692694]
	TIME [epoch: 175 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521415450368251		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.2521415450368251 | validation: 0.2104799950149779]
	TIME [epoch: 175 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507028254201326		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.2507028254201326 | validation: 0.2114274837243733]
	TIME [epoch: 175 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540892989108043		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.2540892989108043 | validation: 0.2114809433311921]
	TIME [epoch: 175 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25408927624887123		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.25408927624887123 | validation: 0.20757845982015405]
	TIME [epoch: 175 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24956024229979537		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.24956024229979537 | validation: 0.207711650705654]
	TIME [epoch: 175 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508055260368793		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.2508055260368793 | validation: 0.20960438781449392]
	TIME [epoch: 175 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.251070141019249		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.251070141019249 | validation: 0.2086838714525352]
	TIME [epoch: 175 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2499505184865769		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.2499505184865769 | validation: 0.2094125943006801]
	TIME [epoch: 175 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509872383561246		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.2509872383561246 | validation: 0.20984525303531826]
	TIME [epoch: 175 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24443076797019958		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.24443076797019958 | validation: 0.20832176597971658]
	TIME [epoch: 175 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511943216066757		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.2511943216066757 | validation: 0.21181573446935226]
	TIME [epoch: 175 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573432282824358		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.2573432282824358 | validation: 0.20702128599499203]
	TIME [epoch: 175 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24909857782970737		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.24909857782970737 | validation: 0.21040774060059367]
	TIME [epoch: 175 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25188430470222317		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.25188430470222317 | validation: 0.20760192881249678]
	TIME [epoch: 175 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501456096862344		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.2501456096862344 | validation: 0.20407125285441322]
	TIME [epoch: 175 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876505219671508		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.24876505219671508 | validation: 0.2068720300131878]
	TIME [epoch: 175 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514649373052051		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.2514649373052051 | validation: 0.21214498550389754]
	TIME [epoch: 175 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25162416704849716		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.25162416704849716 | validation: 0.2112346000436839]
	TIME [epoch: 175 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25014022387057305		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.25014022387057305 | validation: 0.20888193765043095]
	TIME [epoch: 174 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.252096964848137		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.252096964848137 | validation: 0.20897692850466437]
	TIME [epoch: 175 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24605368332687635		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.24605368332687635 | validation: 0.2095761423199764]
	TIME [epoch: 175 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807466738177156		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.24807466738177156 | validation: 0.20998014201419216]
	TIME [epoch: 174 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.251390795831316		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.251390795831316 | validation: 0.2132793612908704]
	TIME [epoch: 175 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24890859087239395		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.24890859087239395 | validation: 0.2097854134680175]
	TIME [epoch: 174 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24980750907997162		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.24980750907997162 | validation: 0.2075871365405008]
	TIME [epoch: 174 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24662517588089983		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.24662517588089983 | validation: 0.20897923616295416]
	TIME [epoch: 175 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24973179553311883		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.24973179553311883 | validation: 0.21119441094211186]
	TIME [epoch: 175 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961438615335507		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.24961438615335507 | validation: 0.20899809401771288]
	TIME [epoch: 175 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24652039432553985		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.24652039432553985 | validation: 0.21085739984448618]
	TIME [epoch: 175 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24936034362049606		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.24936034362049606 | validation: 0.2059094621999124]
	TIME [epoch: 175 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686579477384363		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.24686579477384363 | validation: 0.20916269092557807]
	TIME [epoch: 175 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511468430130177		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.2511468430130177 | validation: 0.21434657242441646]
	TIME [epoch: 175 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.251297361115723		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.251297361115723 | validation: 0.2087959215515785]
	TIME [epoch: 175 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.252610823480239		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.252610823480239 | validation: 0.21147308265333303]
	TIME [epoch: 175 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466002036618392		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.24466002036618392 | validation: 0.20847440794601466]
	TIME [epoch: 175 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24647103101614265		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.24647103101614265 | validation: 0.2078274347744867]
	TIME [epoch: 175 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475582376747476		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.2475582376747476 | validation: 0.21062665698200705]
	TIME [epoch: 175 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486392681216049		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.2486392681216049 | validation: 0.20774100074770335]
	TIME [epoch: 175 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24606281482511508		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.24606281482511508 | validation: 0.208386815731455]
	TIME [epoch: 175 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25179843654345974		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.25179843654345974 | validation: 0.20204402553071907]
	TIME [epoch: 175 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12b_20240719_005108/states/model_facs_v3_dec1b_2dpca_v12b_342.pth
	Model improved!!!
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24731475606912193		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.24731475606912193 | validation: 0.2081912842743363]
	TIME [epoch: 175 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24894681733034787		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.24894681733034787 | validation: 0.21032750917924653]
	TIME [epoch: 175 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876383994538834		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.24876383994538834 | validation: 0.20596694357327677]
	TIME [epoch: 175 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493853887860901		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.2493853887860901 | validation: 0.2083132587852437]
	TIME [epoch: 174 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525663856312553		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.2525663856312553 | validation: 0.20722511281850292]
	TIME [epoch: 175 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448398468500934		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.2448398468500934 | validation: 0.20728696310802883]
	TIME [epoch: 175 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24671238303201945		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.24671238303201945 | validation: 0.20961702436550084]
	TIME [epoch: 175 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25198693817115825		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.25198693817115825 | validation: 0.2077741793866668]
	TIME [epoch: 174 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24936315648332208		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.24936315648332208 | validation: 0.21321603569959297]
	TIME [epoch: 175 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463680173064823		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.2463680173064823 | validation: 0.20757577122046583]
	TIME [epoch: 175 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24573458807027357		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.24573458807027357 | validation: 0.2032813071213496]
	TIME [epoch: 175 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514539713653589		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.2514539713653589 | validation: 0.21357552291874243]
	TIME [epoch: 175 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504485081040278		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.2504485081040278 | validation: 0.2094742175409706]
	TIME [epoch: 174 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24877112042167446		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.24877112042167446 | validation: 0.2074903574904999]
	TIME [epoch: 175 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25048466166368843		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.25048466166368843 | validation: 0.20963859002917934]
	TIME [epoch: 174 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24755652123287927		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.24755652123287927 | validation: 0.20879849632784264]
	TIME [epoch: 175 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25072657332225384		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.25072657332225384 | validation: 0.21073471184527254]
	TIME [epoch: 175 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24830681345108863		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.24830681345108863 | validation: 0.20791984512436237]
	TIME [epoch: 175 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24706046140887925		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.24706046140887925 | validation: 0.20725907484216996]
	TIME [epoch: 175 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.250954029191161		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.250954029191161 | validation: 0.21247332745229128]
	TIME [epoch: 175 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24409671486160925		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.24409671486160925 | validation: 0.20727495859319606]
	TIME [epoch: 175 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655554574143657		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.24655554574143657 | validation: 0.20804314948205777]
	TIME [epoch: 175 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504854712429347		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.2504854712429347 | validation: 0.2102502561914247]
	TIME [epoch: 175 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501550193291491		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.2501550193291491 | validation: 0.20954976476638504]
	TIME [epoch: 175 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24832616699066046		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.24832616699066046 | validation: 0.21187823211462614]
	TIME [epoch: 175 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24844419270700568		[learning rate: 0.00099155]
	Learning Rate: 0.000991553
	LOSS [training: 0.24844419270700568 | validation: 0.2076234706062307]
	TIME [epoch: 175 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735364595790377		[learning rate: 0.00098437]
	Learning Rate: 0.000984369
	LOSS [training: 0.24735364595790377 | validation: 0.2096977888190063]
	TIME [epoch: 175 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462625958729968		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.2462625958729968 | validation: 0.20953448103516878]
	TIME [epoch: 174 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24971446303809694		[learning rate: 0.00097016]
	Learning Rate: 0.000970157
	LOSS [training: 0.24971446303809694 | validation: 0.2078781906245938]
	TIME [epoch: 175 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24940646967126298		[learning rate: 0.00096313]
	Learning Rate: 0.000963128
	LOSS [training: 0.24940646967126298 | validation: 0.20730336455509168]
	TIME [epoch: 175 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24533021407213426		[learning rate: 0.00095615]
	Learning Rate: 0.00095615
	LOSS [training: 0.24533021407213426 | validation: 0.20980078424895296]
	TIME [epoch: 175 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.246749122542973		[learning rate: 0.00094922]
	Learning Rate: 0.000949223
	LOSS [training: 0.246749122542973 | validation: 0.2045709480885093]
	TIME [epoch: 175 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782219408236308		[learning rate: 0.00094235]
	Learning Rate: 0.000942346
	LOSS [training: 0.24782219408236308 | validation: 0.21357386145105656]
	TIME [epoch: 175 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644205637435823		[learning rate: 0.00093552]
	Learning Rate: 0.000935519
	LOSS [training: 0.24644205637435823 | validation: 0.21245720955149192]
	TIME [epoch: 175 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862729507047218		[learning rate: 0.00092874]
	Learning Rate: 0.000928741
	LOSS [training: 0.24862729507047218 | validation: 0.20722249594518924]
	TIME [epoch: 175 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431770444790625		[learning rate: 0.00092201]
	Learning Rate: 0.000922012
	LOSS [training: 0.2431770444790625 | validation: 0.21305868556453494]
	TIME [epoch: 175 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501800102246459		[learning rate: 0.00091533]
	Learning Rate: 0.000915333
	LOSS [training: 0.2501800102246459 | validation: 0.20987769802684514]
	TIME [epoch: 175 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24829387675123482		[learning rate: 0.0009087]
	Learning Rate: 0.000908701
	LOSS [training: 0.24829387675123482 | validation: 0.20644159102212312]
	TIME [epoch: 175 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24856295115406912		[learning rate: 0.00090212]
	Learning Rate: 0.000902118
	LOSS [training: 0.24856295115406912 | validation: 0.20995464744580397]
	TIME [epoch: 175 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24766624083905583		[learning rate: 0.00089558]
	Learning Rate: 0.000895582
	LOSS [training: 0.24766624083905583 | validation: 0.21035124405009187]
	TIME [epoch: 175 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463659972455784		[learning rate: 0.00088909]
	Learning Rate: 0.000889093
	LOSS [training: 0.2463659972455784 | validation: 0.21028083785630022]
	TIME [epoch: 175 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24845354883931678		[learning rate: 0.00088265]
	Learning Rate: 0.000882652
	LOSS [training: 0.24845354883931678 | validation: 0.2118954952061367]
	TIME [epoch: 175 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24823742728620476		[learning rate: 0.00087626]
	Learning Rate: 0.000876257
	LOSS [training: 0.24823742728620476 | validation: 0.209458604572548]
	TIME [epoch: 175 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962975654439526		[learning rate: 0.00086991]
	Learning Rate: 0.000869909
	LOSS [training: 0.24962975654439526 | validation: 0.20669268273617844]
	TIME [epoch: 175 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24881154997309418		[learning rate: 0.00086361]
	Learning Rate: 0.000863606
	LOSS [training: 0.24881154997309418 | validation: 0.20741633182841737]
	TIME [epoch: 175 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456487772129877		[learning rate: 0.00085735]
	Learning Rate: 0.000857349
	LOSS [training: 0.2456487772129877 | validation: 0.20856170016104353]
	TIME [epoch: 175 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488073601232783		[learning rate: 0.00085114]
	Learning Rate: 0.000851138
	LOSS [training: 0.2488073601232783 | validation: 0.20920707915385978]
	TIME [epoch: 175 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500171198443474		[learning rate: 0.00084497]
	Learning Rate: 0.000844972
	LOSS [training: 0.2500171198443474 | validation: 0.2080093688976253]
	TIME [epoch: 175 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24170494763552708		[learning rate: 0.00083885]
	Learning Rate: 0.00083885
	LOSS [training: 0.24170494763552708 | validation: 0.2098767864503403]
	TIME [epoch: 175 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583091521376021		[learning rate: 0.00083277]
	Learning Rate: 0.000832772
	LOSS [training: 0.24583091521376021 | validation: 0.20918083914239202]
	TIME [epoch: 175 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796069951685715		[learning rate: 0.00082674]
	Learning Rate: 0.000826739
	LOSS [training: 0.24796069951685715 | validation: 0.20822919184852032]
	TIME [epoch: 175 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474741641436844		[learning rate: 0.00082075]
	Learning Rate: 0.000820749
	LOSS [training: 0.2474741641436844 | validation: 0.20936103828429284]
	TIME [epoch: 175 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24736859998102298		[learning rate: 0.0008148]
	Learning Rate: 0.000814803
	LOSS [training: 0.24736859998102298 | validation: 0.2091103611929633]
	TIME [epoch: 175 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327906807254132		[learning rate: 0.0008089]
	Learning Rate: 0.0008089
	LOSS [training: 0.24327906807254132 | validation: 0.2064536273588405]
	TIME [epoch: 175 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644448640308012		[learning rate: 0.00080304]
	Learning Rate: 0.000803039
	LOSS [training: 0.24644448640308012 | validation: 0.21075175978228272]
	TIME [epoch: 175 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24972021599884375		[learning rate: 0.00079722]
	Learning Rate: 0.000797221
	LOSS [training: 0.24972021599884375 | validation: 0.2103321205795345]
	TIME [epoch: 174 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493129395143333		[learning rate: 0.00079145]
	Learning Rate: 0.000791446
	LOSS [training: 0.2493129395143333 | validation: 0.2050878400541781]
	TIME [epoch: 175 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24565887295552744		[learning rate: 0.00078571]
	Learning Rate: 0.000785712
	LOSS [training: 0.24565887295552744 | validation: 0.21052458392974996]
	TIME [epoch: 175 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479784872139986		[learning rate: 0.00078002]
	Learning Rate: 0.000780019
	LOSS [training: 0.2479784872139986 | validation: 0.20915861342453548]
	TIME [epoch: 175 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904401321439198		[learning rate: 0.00077437]
	Learning Rate: 0.000774368
	LOSS [training: 0.24904401321439198 | validation: 0.2087743161402921]
	TIME [epoch: 175 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24953366434300453		[learning rate: 0.00076876]
	Learning Rate: 0.000768758
	LOSS [training: 0.24953366434300453 | validation: 0.20471066355053869]
	TIME [epoch: 175 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479105238570475		[learning rate: 0.00076319]
	Learning Rate: 0.000763188
	LOSS [training: 0.2479105238570475 | validation: 0.20976828679740822]
	TIME [epoch: 175 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455351950630433		[learning rate: 0.00075766]
	Learning Rate: 0.000757659
	LOSS [training: 0.2455351950630433 | validation: 0.21086621261407545]
	TIME [epoch: 175 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628911699292402		[learning rate: 0.00075217]
	Learning Rate: 0.000752169
	LOSS [training: 0.24628911699292402 | validation: 0.2102808401836925]
	TIME [epoch: 175 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475270508696403		[learning rate: 0.00074672]
	Learning Rate: 0.00074672
	LOSS [training: 0.24475270508696403 | validation: 0.20626412787790502]
	TIME [epoch: 176 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453801035195676		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.2453801035195676 | validation: 0.2054672909707104]
	TIME [epoch: 175 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24435639195333717		[learning rate: 0.00073594]
	Learning Rate: 0.000735939
	LOSS [training: 0.24435639195333717 | validation: 0.2099029748389895]
	TIME [epoch: 175 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504738658774781		[learning rate: 0.00073061]
	Learning Rate: 0.000730608
	LOSS [training: 0.2504738658774781 | validation: 0.20407898148550868]
	TIME [epoch: 175 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880078416304155		[learning rate: 0.00072531]
	Learning Rate: 0.000725314
	LOSS [training: 0.24880078416304155 | validation: 0.20734842318891927]
	TIME [epoch: 175 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24912579880964603		[learning rate: 0.00072006]
	Learning Rate: 0.000720059
	LOSS [training: 0.24912579880964603 | validation: 0.2068340332934806]
	TIME [epoch: 175 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467728304499763		[learning rate: 0.00071484]
	Learning Rate: 0.000714843
	LOSS [training: 0.2467728304499763 | validation: 0.21164753161340938]
	TIME [epoch: 175 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24650939485308077		[learning rate: 0.00070966]
	Learning Rate: 0.000709664
	LOSS [training: 0.24650939485308077 | validation: 0.21230549706447704]
	TIME [epoch: 175 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24906228466635674		[learning rate: 0.00070452]
	Learning Rate: 0.000704522
	LOSS [training: 0.24906228466635674 | validation: 0.20925981340218605]
	TIME [epoch: 175 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24806940194845783		[learning rate: 0.00069942]
	Learning Rate: 0.000699418
	LOSS [training: 0.24806940194845783 | validation: 0.20747022668193535]
	TIME [epoch: 175 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24703340067048207		[learning rate: 0.00069435]
	Learning Rate: 0.000694351
	LOSS [training: 0.24703340067048207 | validation: 0.20967218203686094]
	TIME [epoch: 175 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708293358925834		[learning rate: 0.00068932]
	Learning Rate: 0.00068932
	LOSS [training: 0.24708293358925834 | validation: 0.2094759914500429]
	TIME [epoch: 175 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588736850746548		[learning rate: 0.00068433]
	Learning Rate: 0.000684326
	LOSS [training: 0.24588736850746548 | validation: 0.21304425483231637]
	TIME [epoch: 175 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24401700942942148		[learning rate: 0.00067937]
	Learning Rate: 0.000679368
	LOSS [training: 0.24401700942942148 | validation: 0.2057093444491101]
	TIME [epoch: 175 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24633686590966022		[learning rate: 0.00067445]
	Learning Rate: 0.000674446
	LOSS [training: 0.24633686590966022 | validation: 0.21052473898181995]
	TIME [epoch: 175 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24742298944652516		[learning rate: 0.00066956]
	Learning Rate: 0.00066956
	LOSS [training: 0.24742298944652516 | validation: 0.20859196348233805]
	TIME [epoch: 175 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24902051056348473		[learning rate: 0.00066471]
	Learning Rate: 0.000664709
	LOSS [training: 0.24902051056348473 | validation: 0.20589265951447394]
	TIME [epoch: 175 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24843642408064628		[learning rate: 0.00065989]
	Learning Rate: 0.000659893
	LOSS [training: 0.24843642408064628 | validation: 0.20805941666735853]
	TIME [epoch: 175 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456994441397253		[learning rate: 0.00065511]
	Learning Rate: 0.000655112
	LOSS [training: 0.2456994441397253 | validation: 0.20807405990819397]
	TIME [epoch: 174 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25067436366316326		[learning rate: 0.00065037]
	Learning Rate: 0.000650366
	LOSS [training: 0.25067436366316326 | validation: 0.2062993562048411]
	TIME [epoch: 174 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24543270869322545		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.24543270869322545 | validation: 0.21042880683071258]
	TIME [epoch: 174 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24619606717414969		[learning rate: 0.00064098]
	Learning Rate: 0.000640976
	LOSS [training: 0.24619606717414969 | validation: 0.20752585023558695]
	TIME [epoch: 174 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826873280199735		[learning rate: 0.00063633]
	Learning Rate: 0.000636333
	LOSS [training: 0.24826873280199735 | validation: 0.20658332755783637]
	TIME [epoch: 174 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24852882659803888		[learning rate: 0.00063172]
	Learning Rate: 0.000631722
	LOSS [training: 0.24852882659803888 | validation: 0.2092238491734239]
	TIME [epoch: 174 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24820424975085678		[learning rate: 0.00062715]
	Learning Rate: 0.000627146
	LOSS [training: 0.24820424975085678 | validation: 0.20977291738222603]
	TIME [epoch: 174 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24544777493222936		[learning rate: 0.0006226]
	Learning Rate: 0.000622602
	LOSS [training: 0.24544777493222936 | validation: 0.21143428218731541]
	TIME [epoch: 174 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24734772754461373		[learning rate: 0.00061809]
	Learning Rate: 0.000618091
	LOSS [training: 0.24734772754461373 | validation: 0.2075896596887561]
	TIME [epoch: 174 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468860016206358		[learning rate: 0.00061361]
	Learning Rate: 0.000613613
	LOSS [training: 0.2468860016206358 | validation: 0.20770325061877984]
	TIME [epoch: 174 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378924001190425		[learning rate: 0.00060917]
	Learning Rate: 0.000609168
	LOSS [training: 0.24378924001190425 | validation: 0.20527827529080028]
	TIME [epoch: 174 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24304029792419346		[learning rate: 0.00060475]
	Learning Rate: 0.000604754
	LOSS [training: 0.24304029792419346 | validation: 0.2092547477547227]
	TIME [epoch: 174 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685699114200688		[learning rate: 0.00060037]
	Learning Rate: 0.000600373
	LOSS [training: 0.24685699114200688 | validation: 0.2092280465230998]
	TIME [epoch: 174 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24743502132102843		[learning rate: 0.00059602]
	Learning Rate: 0.000596023
	LOSS [training: 0.24743502132102843 | validation: 0.20764053516569878]
	TIME [epoch: 174 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463799302768008		[learning rate: 0.0005917]
	Learning Rate: 0.000591705
	LOSS [training: 0.2463799302768008 | validation: 0.2032171960956844]
	TIME [epoch: 174 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501644897316061		[learning rate: 0.00058742]
	Learning Rate: 0.000587418
	LOSS [training: 0.2501644897316061 | validation: 0.2087356130693573]
	TIME [epoch: 174 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517529669632772		[learning rate: 0.00058316]
	Learning Rate: 0.000583162
	LOSS [training: 0.2517529669632772 | validation: 0.20618461791953316]
	TIME [epoch: 174 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24527338751470926		[learning rate: 0.00057894]
	Learning Rate: 0.000578937
	LOSS [training: 0.24527338751470926 | validation: 0.20618550360720134]
	TIME [epoch: 174 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24409772112844366		[learning rate: 0.00057474]
	Learning Rate: 0.000574743
	LOSS [training: 0.24409772112844366 | validation: 0.2092600563971941]
	TIME [epoch: 174 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24746227102712245		[learning rate: 0.00057058]
	Learning Rate: 0.000570579
	LOSS [training: 0.24746227102712245 | validation: 0.2069284854224025]
	TIME [epoch: 174 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24712400797987089		[learning rate: 0.00056645]
	Learning Rate: 0.000566445
	LOSS [training: 0.24712400797987089 | validation: 0.20400054387268107]
	TIME [epoch: 174 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628606451685042		[learning rate: 0.00056234]
	Learning Rate: 0.000562341
	LOSS [training: 0.24628606451685042 | validation: 0.20714122435083696]
	TIME [epoch: 174 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761219270106075		[learning rate: 0.00055827]
	Learning Rate: 0.000558267
	LOSS [training: 0.24761219270106075 | validation: 0.21045430590139888]
	TIME [epoch: 174 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465867301296911		[learning rate: 0.00055422]
	Learning Rate: 0.000554222
	LOSS [training: 0.2465867301296911 | validation: 0.21075730897861694]
	TIME [epoch: 174 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475479295521278		[learning rate: 0.00055021]
	Learning Rate: 0.000550207
	LOSS [training: 0.2475479295521278 | validation: 0.20857827677017698]
	TIME [epoch: 174 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24800519981239774		[learning rate: 0.00054622]
	Learning Rate: 0.000546221
	LOSS [training: 0.24800519981239774 | validation: 0.2038384643034087]
	TIME [epoch: 174 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24312863978584		[learning rate: 0.00054226]
	Learning Rate: 0.000542264
	LOSS [training: 0.24312863978584 | validation: 0.2073908273152168]
	TIME [epoch: 174 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24429593782383976		[learning rate: 0.00053833]
	Learning Rate: 0.000538335
	LOSS [training: 0.24429593782383976 | validation: 0.20571206025693595]
	TIME [epoch: 174 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24426967378471945		[learning rate: 0.00053443]
	Learning Rate: 0.000534435
	LOSS [training: 0.24426967378471945 | validation: 0.20946457032261598]
	TIME [epoch: 174 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446473024095004		[learning rate: 0.00053056]
	Learning Rate: 0.000530563
	LOSS [training: 0.2446473024095004 | validation: 0.2055680245103205]
	TIME [epoch: 174 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427757484633383		[learning rate: 0.00052672]
	Learning Rate: 0.000526719
	LOSS [training: 0.2427757484633383 | validation: 0.20784190344738263]
	TIME [epoch: 174 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656441783255337		[learning rate: 0.0005229]
	Learning Rate: 0.000522903
	LOSS [training: 0.24656441783255337 | validation: 0.2058861111906174]
	TIME [epoch: 174 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475593249538515		[learning rate: 0.00051911]
	Learning Rate: 0.000519114
	LOSS [training: 0.2475593249538515 | validation: 0.2080528845687506]
	TIME [epoch: 174 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24564315843460963		[learning rate: 0.00051535]
	Learning Rate: 0.000515353
	LOSS [training: 0.24564315843460963 | validation: 0.20708792530033793]
	TIME [epoch: 174 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24612256663763296		[learning rate: 0.00051162]
	Learning Rate: 0.00051162
	LOSS [training: 0.24612256663763296 | validation: 0.2039574845481354]
	TIME [epoch: 174 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473553566773216		[learning rate: 0.00050791]
	Learning Rate: 0.000507913
	LOSS [training: 0.2473553566773216 | validation: 0.20357108915015046]
	TIME [epoch: 174 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735354581437904		[learning rate: 0.00050423]
	Learning Rate: 0.000504233
	LOSS [training: 0.24735354581437904 | validation: 0.211421123596684]
	TIME [epoch: 174 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24912845671377318		[learning rate: 0.00050058]
	Learning Rate: 0.00050058
	LOSS [training: 0.24912845671377318 | validation: 0.21075708391877174]
	TIME [epoch: 174 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494375275908017		[learning rate: 0.00049695]
	Learning Rate: 0.000496953
	LOSS [training: 0.2494375275908017 | validation: 0.20792925422661437]
	TIME [epoch: 174 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24819195892412294		[learning rate: 0.00049335]
	Learning Rate: 0.000493353
	LOSS [training: 0.24819195892412294 | validation: 0.2058560625403827]
	TIME [epoch: 175 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24705839870418445		[learning rate: 0.00048978]
	Learning Rate: 0.000489779
	LOSS [training: 0.24705839870418445 | validation: 0.20723835556610232]
	TIME [epoch: 175 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24755075791449907		[learning rate: 0.00048623]
	Learning Rate: 0.00048623
	LOSS [training: 0.24755075791449907 | validation: 0.2096667714103151]
	TIME [epoch: 174 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24823814282043846		[learning rate: 0.00048271]
	Learning Rate: 0.000482708
	LOSS [training: 0.24823814282043846 | validation: 0.20665062900450484]
	TIME [epoch: 175 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24487320247656885		[learning rate: 0.00047921]
	Learning Rate: 0.00047921
	LOSS [training: 0.24487320247656885 | validation: 0.20859946282866884]
	TIME [epoch: 174 sec]
EPOCH 469/1000:
	Training over batches...
