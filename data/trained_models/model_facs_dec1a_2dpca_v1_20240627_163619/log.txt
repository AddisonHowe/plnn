Args:
Namespace(name='model_facs_dec1a_2dpca_v1', outdir='out/model_training/model_facs_dec1a_2dpca_v1', training_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 460218130

Training model...

Saving initial model state to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7869803146869746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7869803146869746 | validation: 0.6142252883422561]
	TIME [epoch: 87 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6575801733094521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6575801733094521 | validation: 0.5904682385909149]
	TIME [epoch: 62.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6117218318656898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6117218318656898 | validation: 0.5685496413707642]
	TIME [epoch: 62.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6041672144398272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6041672144398272 | validation: 0.5535177230998087]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.604327214445022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.604327214445022 | validation: 0.5249500695916635]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5606494032909466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606494032909466 | validation: 0.5002115668542181]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5279399112965603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5279399112965603 | validation: 0.46976013251364135]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4937996887498226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4937996887498226 | validation: 0.4503496694871987]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45097205189034184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45097205189034184 | validation: 0.3879442646858085]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4225341585527363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4225341585527363 | validation: 0.3505937302977081]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39591830977124687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39591830977124687 | validation: 0.306738867661961]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3389676660058122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3389676660058122 | validation: 0.3037068673110113]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2807659270826888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2807659270826888 | validation: 0.2082653240174218]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22302839396604568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22302839396604568 | validation: 0.1780824614685603]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2183519522878407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2183519522878407 | validation: 0.17227072063116208]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18173648999176212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18173648999176212 | validation: 0.17298638517435702]
	TIME [epoch: 62.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18438136559351564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18438136559351564 | validation: 0.1710692524802379]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18132149631066236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18132149631066236 | validation: 0.15670676165102176]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16983943032110743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16983943032110743 | validation: 0.1477852406023871]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15973366547322543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15973366547322543 | validation: 0.14514043566788354]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16303849549453917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16303849549453917 | validation: 0.14642723676282443]
	TIME [epoch: 62.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15365513143790155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15365513143790155 | validation: 0.1711390515481185]
	TIME [epoch: 62.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1591482475824648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1591482475824648 | validation: 0.14593455322057194]
	TIME [epoch: 62.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.147343871012918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.147343871012918 | validation: 0.12121940710256902]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1435286147893804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1435286147893804 | validation: 0.1372340691378104]
	TIME [epoch: 62.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15314595957890748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15314595957890748 | validation: 0.12225303389995763]
	TIME [epoch: 62.3 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1356280600609628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1356280600609628 | validation: 0.12227185320408591]
	TIME [epoch: 62.4 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13951027361166524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13951027361166524 | validation: 0.12484695683231772]
	TIME [epoch: 62.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13916715142663627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13916715142663627 | validation: 0.13337302942470408]
	TIME [epoch: 62.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14067577555385694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14067577555385694 | validation: 0.1306526030891549]
	TIME [epoch: 62.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13874654361270655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13874654361270655 | validation: 0.1372050964271514]
	TIME [epoch: 62.4 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14693155921509365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14693155921509365 | validation: 0.14127911310409016]
	TIME [epoch: 62.4 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1390711428945019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1390711428945019 | validation: 0.11280117013235318]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1353761919893446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1353761919893446 | validation: 0.11614300521663908]
	TIME [epoch: 62.4 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13530106591066515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13530106591066515 | validation: 0.12108579348646628]
	TIME [epoch: 62.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1350936109552465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1350936109552465 | validation: 0.1184385494946792]
	TIME [epoch: 62.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13601949353484427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13601949353484427 | validation: 0.11717059298207658]
	TIME [epoch: 62.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13330725462248388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13330725462248388 | validation: 0.10808841988444351]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12764518478587342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12764518478587342 | validation: 0.1288681616637318]
	TIME [epoch: 62.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13297813828703853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13297813828703853 | validation: 0.11200196147934915]
	TIME [epoch: 62.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1273488483920052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1273488483920052 | validation: 0.11540234675192888]
	TIME [epoch: 62.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1323023174015165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1323023174015165 | validation: 0.1322118990824413]
	TIME [epoch: 62.4 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13166110291686978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13166110291686978 | validation: 0.1094539414514109]
	TIME [epoch: 62.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12882740923949731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12882740923949731 | validation: 0.1165898824701708]
	TIME [epoch: 62.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13766766352829882		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.13766766352829882 | validation: 0.10896876716909905]
	TIME [epoch: 62.4 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12288792998646818		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.12288792998646818 | validation: 0.11485700546675512]
	TIME [epoch: 62.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12310566659019367		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.12310566659019367 | validation: 0.13741964863679318]
	TIME [epoch: 62.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13086395496484166		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.13086395496484166 | validation: 0.11761917385584013]
	TIME [epoch: 62.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12849672489688432		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.12849672489688432 | validation: 0.1041640206407541]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1269190646445832		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.1269190646445832 | validation: 0.13369785399085388]
	TIME [epoch: 62.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.127590037211587		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.127590037211587 | validation: 0.11452727428814682]
	TIME [epoch: 62.4 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12111307056324987		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.12111307056324987 | validation: 0.10404588935059247]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12829087235149395		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.12829087235149395 | validation: 0.11032120753581234]
	TIME [epoch: 62.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1378927365973275		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.1378927365973275 | validation: 0.1179961107231314]
	TIME [epoch: 62.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12566343231183835		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.12566343231183835 | validation: 0.10877288465276524]
	TIME [epoch: 62.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12868493203538475		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.12868493203538475 | validation: 0.09930362039911209]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12167441105726651		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.12167441105726651 | validation: 0.10525919327861018]
	TIME [epoch: 62.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12059546976858448		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.12059546976858448 | validation: 0.12437701508857542]
	TIME [epoch: 62.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13015019081844345		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.13015019081844345 | validation: 0.10426851902528984]
	TIME [epoch: 62.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12277824728487434		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.12277824728487434 | validation: 0.11349008341559623]
	TIME [epoch: 62.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13052849023861815		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.13052849023861815 | validation: 0.12277476239972565]
	TIME [epoch: 62.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12386934778408001		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.12386934778408001 | validation: 0.103708590092112]
	TIME [epoch: 62.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11868951342592157		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.11868951342592157 | validation: 0.13376321439647484]
	TIME [epoch: 62.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13060540944252164		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.13060540944252164 | validation: 0.10398372737268964]
	TIME [epoch: 62.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11617646346164763		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.11617646346164763 | validation: 0.10902545738284382]
	TIME [epoch: 62.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12993462955931007		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.12993462955931007 | validation: 0.11328347900285358]
	TIME [epoch: 62.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12074447482374152		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.12074447482374152 | validation: 0.0979341007366832]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1185089798447769		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.1185089798447769 | validation: 0.10280858476489778]
	TIME [epoch: 62.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1207407888661007		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.1207407888661007 | validation: 0.10596107958268916]
	TIME [epoch: 62.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12676919874983478		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.12676919874983478 | validation: 0.10513746337000802]
	TIME [epoch: 62.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12145112258124308		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.12145112258124308 | validation: 0.10748269115603575]
	TIME [epoch: 62.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1176290297263009		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.1176290297263009 | validation: 0.10695900835958452]
	TIME [epoch: 62.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11944074269195301		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.11944074269195301 | validation: 0.10600000537913068]
	TIME [epoch: 62.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12093725378388541		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.12093725378388541 | validation: 0.1089317155101274]
	TIME [epoch: 62.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12179330698141556		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.12179330698141556 | validation: 0.10057401921397391]
	TIME [epoch: 62.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12945269243578864		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.12945269243578864 | validation: 0.10259383263189181]
	TIME [epoch: 62.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11974760470228392		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.11974760470228392 | validation: 0.1005036276224384]
	TIME [epoch: 62.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1175204576736165		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.1175204576736165 | validation: 0.10434216025586578]
	TIME [epoch: 62.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12378162017091797		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.12378162017091797 | validation: 0.1018915194539461]
	TIME [epoch: 62.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11999558719679		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.11999558719679 | validation: 0.0997573144508537]
	TIME [epoch: 62.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11531665301802906		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11531665301802906 | validation: 0.09687315977947364]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11708753599988876		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.11708753599988876 | validation: 0.11574705175388426]
	TIME [epoch: 62.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12190599994886767		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.12190599994886767 | validation: 0.10546194498961341]
	TIME [epoch: 62.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1231810880542631		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.1231810880542631 | validation: 0.1060250870950917]
	TIME [epoch: 62.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.116690743821885		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.116690743821885 | validation: 0.09583835763418692]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11548733524164762		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.11548733524164762 | validation: 0.09849826500721005]
	TIME [epoch: 62.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11461523020655252		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.11461523020655252 | validation: 0.1015831229512747]
	TIME [epoch: 62.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11879754754231536		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.11879754754231536 | validation: 0.10047162390975513]
	TIME [epoch: 62.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12128540383143613		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.12128540383143613 | validation: 0.09929786814864965]
	TIME [epoch: 62.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11364852903550011		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.11364852903550011 | validation: 0.10804600737531309]
	TIME [epoch: 62.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12202003816588164		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12202003816588164 | validation: 0.09985711434602507]
	TIME [epoch: 62.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11873042480010532		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.11873042480010532 | validation: 0.10576055010393001]
	TIME [epoch: 62.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12270245389331803		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12270245389331803 | validation: 0.09924194151665439]
	TIME [epoch: 62.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11493019312242275		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.11493019312242275 | validation: 0.11437817594639661]
	TIME [epoch: 62.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11952441199310254		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.11952441199310254 | validation: 0.09596938548602828]
	TIME [epoch: 62.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255711996943746		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.11255711996943746 | validation: 0.1037904028511903]
	TIME [epoch: 62.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11369529220902932		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.11369529220902932 | validation: 0.1051751938261833]
	TIME [epoch: 62.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12343113397996913		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.12343113397996913 | validation: 0.10861893449355824]
	TIME [epoch: 62.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12143007477357919		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.12143007477357919 | validation: 0.10252090107677984]
	TIME [epoch: 62.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11885932551366338		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.11885932551366338 | validation: 0.095269959411617]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11441806532856819		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.11441806532856819 | validation: 0.09759592335420433]
	TIME [epoch: 62.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11008075412411557		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.11008075412411557 | validation: 0.09859292113682877]
	TIME [epoch: 62.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11990845372319463		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.11990845372319463 | validation: 0.09992244039544182]
	TIME [epoch: 62.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1209955141686888		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.1209955141686888 | validation: 0.09574410174237497]
	TIME [epoch: 62.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11317182223698016		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.11317182223698016 | validation: 0.10065588151918632]
	TIME [epoch: 62.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11761798618938418		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.11761798618938418 | validation: 0.094704724364566]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1160432179405654		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.1160432179405654 | validation: 0.09375219613429618]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11850330775901578		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.11850330775901578 | validation: 0.11017961122510682]
	TIME [epoch: 62.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11424660100219586		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.11424660100219586 | validation: 0.09786953334776777]
	TIME [epoch: 62.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11534583275803634		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.11534583275803634 | validation: 0.09836032320582143]
	TIME [epoch: 62.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11467300261481994		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11467300261481994 | validation: 0.09725058825860695]
	TIME [epoch: 62.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11938111914923473		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.11938111914923473 | validation: 0.10497819093697565]
	TIME [epoch: 62.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1168613113995956		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.1168613113995956 | validation: 0.09441977491432405]
	TIME [epoch: 62.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1109069300064662		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.1109069300064662 | validation: 0.11058195639013464]
	TIME [epoch: 62.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12184237325994128		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.12184237325994128 | validation: 0.10543227273141428]
	TIME [epoch: 62.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1200755041516515		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.1200755041516515 | validation: 0.10283084089854011]
	TIME [epoch: 62.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11997566157653379		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.11997566157653379 | validation: 0.09652672975381063]
	TIME [epoch: 62.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1151607391982443		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.1151607391982443 | validation: 0.11087375774826136]
	TIME [epoch: 62.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11986200052387214		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.11986200052387214 | validation: 0.09499416878023897]
	TIME [epoch: 62.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11270914761164039		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.11270914761164039 | validation: 0.09731656678352882]
	TIME [epoch: 62.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.114519232541821		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.114519232541821 | validation: 0.10962770616165249]
	TIME [epoch: 62.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11871803706975191		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.11871803706975191 | validation: 0.09605570657678489]
	TIME [epoch: 62.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1150968880620471		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.1150968880620471 | validation: 0.09791331171502252]
	TIME [epoch: 62.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11078871325591011		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.11078871325591011 | validation: 0.1026385010341512]
	TIME [epoch: 62.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12003739113941442		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.12003739113941442 | validation: 0.10267831450073292]
	TIME [epoch: 62.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11338529055814922		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.11338529055814922 | validation: 0.09269644700077226]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10945170653020155		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.10945170653020155 | validation: 0.10084091920796256]
	TIME [epoch: 62.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11599163386309967		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.11599163386309967 | validation: 0.10672499793504678]
	TIME [epoch: 62.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11610565462812075		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.11610565462812075 | validation: 0.09969990189994099]
	TIME [epoch: 62.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1172305629427324		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.1172305629427324 | validation: 0.1010531421146766]
	TIME [epoch: 62.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11136780102563078		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.11136780102563078 | validation: 0.10856412956382085]
	TIME [epoch: 62.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1190177265457794		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.1190177265457794 | validation: 0.09826019817643272]
	TIME [epoch: 62.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1154473618587844		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.1154473618587844 | validation: 0.09732054040635349]
	TIME [epoch: 62.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11392078721436641		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.11392078721436641 | validation: 0.09581977893447505]
	TIME [epoch: 62.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11203540180515519		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.11203540180515519 | validation: 0.09671899272637059]
	TIME [epoch: 62.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11567207305036104		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.11567207305036104 | validation: 0.1033894003111387]
	TIME [epoch: 62.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11395364342198581		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.11395364342198581 | validation: 0.09906646236073782]
	TIME [epoch: 62.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11367073743935824		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.11367073743935824 | validation: 0.0918351119296025]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11106349142470089		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.11106349142470089 | validation: 0.10756127578431193]
	TIME [epoch: 62.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421489489337845		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.11421489489337845 | validation: 0.09595040641799919]
	TIME [epoch: 62.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11107733785675335		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11107733785675335 | validation: 0.09352998710594435]
	TIME [epoch: 62.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095077119501729		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.1095077119501729 | validation: 0.09163716144274363]
	TIME [epoch: 62.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11042848782360785		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.11042848782360785 | validation: 0.10282030426822189]
	TIME [epoch: 62.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11244261957951486		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.11244261957951486 | validation: 0.09845802157532743]
	TIME [epoch: 62.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11289371884717991		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.11289371884717991 | validation: 0.09557290508391496]
	TIME [epoch: 62.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11054294902241721		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.11054294902241721 | validation: 0.09356174047618936]
	TIME [epoch: 62.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10864943252753301		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.10864943252753301 | validation: 0.09520236455934769]
	TIME [epoch: 62.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11263336966631199		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.11263336966631199 | validation: 0.10035723755488149]
	TIME [epoch: 62.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11032546940897112		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.11032546940897112 | validation: 0.09245344275927557]
	TIME [epoch: 62.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10960164148533422		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.10960164148533422 | validation: 0.10339441506254084]
	TIME [epoch: 62.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11592660384616758		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11592660384616758 | validation: 0.0979045492359751]
	TIME [epoch: 62.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11665738366396333		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.11665738366396333 | validation: 0.09629387083841795]
	TIME [epoch: 62.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11332088490500099		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.11332088490500099 | validation: 0.0989826578991109]
	TIME [epoch: 62.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11400181961246066		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.11400181961246066 | validation: 0.09789120305561648]
	TIME [epoch: 62.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11548221419781766		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.11548221419781766 | validation: 0.10307376289894059]
	TIME [epoch: 62.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11979646516491191		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.11979646516491191 | validation: 0.0936438801879109]
	TIME [epoch: 62.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11700706805786382		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.11700706805786382 | validation: 0.09892065344128773]
	TIME [epoch: 62.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11265154468233263		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.11265154468233263 | validation: 0.10026869798126299]
	TIME [epoch: 62.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11432332551222668		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.11432332551222668 | validation: 0.09655380226980834]
	TIME [epoch: 62.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11274860160120065		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.11274860160120065 | validation: 0.09565197179904131]
	TIME [epoch: 62.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11685179542366811		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11685179542366811 | validation: 0.10105478636251912]
	TIME [epoch: 62.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11281770881483756		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.11281770881483756 | validation: 0.09605434103600616]
	TIME [epoch: 62.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11047023204939749		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.11047023204939749 | validation: 0.10163070631491251]
	TIME [epoch: 62.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11203482375863653		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.11203482375863653 | validation: 0.10236151916724437]
	TIME [epoch: 62.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11536685591553135		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.11536685591553135 | validation: 0.09620040438840584]
	TIME [epoch: 62.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11211164780749971		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.11211164780749971 | validation: 0.09513258423444555]
	TIME [epoch: 62.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11552662329991148		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.11552662329991148 | validation: 0.10140569821289114]
	TIME [epoch: 62.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11562444577852965		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.11562444577852965 | validation: 0.09250945182132422]
	TIME [epoch: 62.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11156243980044825		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.11156243980044825 | validation: 0.10616482051966955]
	TIME [epoch: 62.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11705953298642739		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.11705953298642739 | validation: 0.0946841440413637]
	TIME [epoch: 62.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092902641539844		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11092902641539844 | validation: 0.0996783839887426]
	TIME [epoch: 62.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11212449083785403		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.11212449083785403 | validation: 0.10263439606060314]
	TIME [epoch: 62.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11054936270619282		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.11054936270619282 | validation: 0.09160793956587646]
	TIME [epoch: 62.8 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124258341575495		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.11124258341575495 | validation: 0.0914930133233969]
	TIME [epoch: 62.7 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11093607947675392		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.11093607947675392 | validation: 0.10163181737019418]
	TIME [epoch: 62.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.113915353934881		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.113915353934881 | validation: 0.09780912999049102]
	TIME [epoch: 62.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11644346860541559		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.11644346860541559 | validation: 0.09490345788849328]
	TIME [epoch: 62.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100096127549926		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.1100096127549926 | validation: 0.10396459074047655]
	TIME [epoch: 62.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11357715138150236		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.11357715138150236 | validation: 0.09531357591715625]
	TIME [epoch: 62.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898208264418266		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.10898208264418266 | validation: 0.09526896331050774]
	TIME [epoch: 62.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11074715751491052		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.11074715751491052 | validation: 0.09221029807330024]
	TIME [epoch: 62.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10813489018721961		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.10813489018721961 | validation: 0.09815622542566874]
	TIME [epoch: 62.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11460062782703281		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.11460062782703281 | validation: 0.09758703371730346]
	TIME [epoch: 62.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11327846388236495		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.11327846388236495 | validation: 0.09073175434654876]
	TIME [epoch: 62.7 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10731830310590566		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.10731830310590566 | validation: 0.09467706693233072]
	TIME [epoch: 62.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11088111531373118		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.11088111531373118 | validation: 0.09552613006623803]
	TIME [epoch: 62.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11330543220725556		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.11330543220725556 | validation: 0.09427396638375227]
	TIME [epoch: 62.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10503763905971475		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.10503763905971475 | validation: 0.10302569950665266]
	TIME [epoch: 62.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1129751835831016		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.1129751835831016 | validation: 0.09307425503558706]
	TIME [epoch: 62.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10985502305189793		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.10985502305189793 | validation: 0.09480146057223424]
	TIME [epoch: 62.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11087210831590584		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11087210831590584 | validation: 0.09111369014320772]
	TIME [epoch: 62.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10692774309609679		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.10692774309609679 | validation: 0.0928889036363251]
	TIME [epoch: 62.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155259768646338		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.11155259768646338 | validation: 0.09646718687489365]
	TIME [epoch: 62.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067601198707885		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.1067601198707885 | validation: 0.09401366598554925]
	TIME [epoch: 62.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11186723676450648		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.11186723676450648 | validation: 0.0946069284514752]
	TIME [epoch: 62.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10973576454814006		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.10973576454814006 | validation: 0.09114413904318366]
	TIME [epoch: 62.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11030989275384624		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.11030989275384624 | validation: 0.10178792393224842]
	TIME [epoch: 62.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280538420408392		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.11280538420408392 | validation: 0.09179556934785378]
	TIME [epoch: 62.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1110527536261208		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.1110527536261208 | validation: 0.09340745568378983]
	TIME [epoch: 62.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11640826240156442		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.11640826240156442 | validation: 0.09152812473724448]
	TIME [epoch: 62.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11414240862840323		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11414240862840323 | validation: 0.09131215754632531]
	TIME [epoch: 62.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11432283974334487		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.11432283974334487 | validation: 0.09344462156373429]
	TIME [epoch: 62.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10918430377329512		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.10918430377329512 | validation: 0.0957037498556286]
	TIME [epoch: 62.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389780275561691		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.11389780275561691 | validation: 0.0928091712369752]
	TIME [epoch: 62.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11017611320694057		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.11017611320694057 | validation: 0.10230693687208565]
	TIME [epoch: 62.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11486155324763869		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.11486155324763869 | validation: 0.09589429968719906]
	TIME [epoch: 62.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114786108204362		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.11114786108204362 | validation: 0.0956416389958013]
	TIME [epoch: 62.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10915038402012599		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.10915038402012599 | validation: 0.09634828506086414]
	TIME [epoch: 62.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11392670245710589		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.11392670245710589 | validation: 0.09305449031243586]
	TIME [epoch: 62.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11207332545858645		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.11207332545858645 | validation: 0.09413279510338521]
	TIME [epoch: 62.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10924030191849077		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.10924030191849077 | validation: 0.09307588434996142]
	TIME [epoch: 62.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11332564959419875		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.11332564959419875 | validation: 0.10152014900100319]
	TIME [epoch: 62.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11128285804707187		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.11128285804707187 | validation: 0.09412065865989079]
	TIME [epoch: 62.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11363636270980049		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.11363636270980049 | validation: 0.09723195041121226]
	TIME [epoch: 62.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11555714188411291		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11555714188411291 | validation: 0.09161755301337235]
	TIME [epoch: 62.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11189717382532652		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.11189717382532652 | validation: 0.09482282152305979]
	TIME [epoch: 62.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750717893726805		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.10750717893726805 | validation: 0.0947815362049218]
	TIME [epoch: 62.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10943221442624124		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.10943221442624124 | validation: 0.09887306974260926]
	TIME [epoch: 62.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124851135592231		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.11124851135592231 | validation: 0.10115142746900721]
	TIME [epoch: 62.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10904740774157383		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.10904740774157383 | validation: 0.08994595468873755]
	TIME [epoch: 62.8 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10936921444600596		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10936921444600596 | validation: 0.09699563452311401]
	TIME [epoch: 62.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1082593995602836		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.1082593995602836 | validation: 0.09689813871493266]
	TIME [epoch: 62.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907864348910856		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.10907864348910856 | validation: 0.09105389486212964]
	TIME [epoch: 62.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10773048196370133		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.10773048196370133 | validation: 0.09837264617045126]
	TIME [epoch: 62.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10659132935408798		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.10659132935408798 | validation: 0.09706377053674738]
	TIME [epoch: 62.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11083736701693829		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.11083736701693829 | validation: 0.09201506127246202]
	TIME [epoch: 62.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11087951150432256		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.11087951150432256 | validation: 0.09810936681785007]
	TIME [epoch: 62.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10713398712800026		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.10713398712800026 | validation: 0.10025262789950425]
	TIME [epoch: 62.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280664346804653		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.11280664346804653 | validation: 0.09171114093588109]
	TIME [epoch: 62.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11131058480293582		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.11131058480293582 | validation: 0.09174527781034401]
	TIME [epoch: 62.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11082912666879145		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.11082912666879145 | validation: 0.09226616807438548]
	TIME [epoch: 62.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105322083179006		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.1105322083179006 | validation: 0.09434948650278568]
	TIME [epoch: 62.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1086861993316471		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.1086861993316471 | validation: 0.09611308858302534]
	TIME [epoch: 62.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181451547491533		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.11181451547491533 | validation: 0.09212241232574538]
	TIME [epoch: 62.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10923145733254656		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.10923145733254656 | validation: 0.0976170711810674]
	TIME [epoch: 62.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10993997803490599		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.10993997803490599 | validation: 0.09178827383411234]
	TIME [epoch: 62.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010228980331639		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.11010228980331639 | validation: 0.09884275078025356]
	TIME [epoch: 62.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11343728778592088		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.11343728778592088 | validation: 0.09414449360961145]
	TIME [epoch: 62.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10617202414903194		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.10617202414903194 | validation: 0.09671402596329438]
	TIME [epoch: 62.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11142439188524328		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.11142439188524328 | validation: 0.09314551446558669]
	TIME [epoch: 62.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10951276010340498		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.10951276010340498 | validation: 0.09479295139158447]
	TIME [epoch: 62.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11027127752210823		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.11027127752210823 | validation: 0.09216877865964568]
	TIME [epoch: 62.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10504588476717777		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.10504588476717777 | validation: 0.10604321089853748]
	TIME [epoch: 62.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11308361884295508		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.11308361884295508 | validation: 0.09330816849839647]
	TIME [epoch: 62.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10900900587364434		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.10900900587364434 | validation: 0.09396914026412172]
	TIME [epoch: 62.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10969867583311492		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.10969867583311492 | validation: 0.09669998199918264]
	TIME [epoch: 62.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11086808587725178		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.11086808587725178 | validation: 0.09453488221953908]
	TIME [epoch: 62.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1092111621572604		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.1092111621572604 | validation: 0.09276082510969422]
	TIME [epoch: 62.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10708987702087906		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.10708987702087906 | validation: 0.0949100441117063]
	TIME [epoch: 62.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11168602426706964		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.11168602426706964 | validation: 0.09378694448283988]
	TIME [epoch: 62.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10869685315842506		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.10869685315842506 | validation: 0.09154231209226057]
	TIME [epoch: 62.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10917881937714852		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.10917881937714852 | validation: 0.09337155050541825]
	TIME [epoch: 62.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167139078956129		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.11167139078956129 | validation: 0.09243579397301928]
	TIME [epoch: 62.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10837049683861383		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.10837049683861383 | validation: 0.09496926223434332]
	TIME [epoch: 62.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10831698438766868		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.10831698438766868 | validation: 0.0986302743930557]
	TIME [epoch: 62.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10759223622191551		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.10759223622191551 | validation: 0.10022122906919215]
	TIME [epoch: 62.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1085577586748589		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.1085577586748589 | validation: 0.09332268186638482]
	TIME [epoch: 62.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11026413326776627		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.11026413326776627 | validation: 0.09519922342010331]
	TIME [epoch: 62.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132618796454403		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.11132618796454403 | validation: 0.09797084167685681]
	TIME [epoch: 62.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10831359877804486		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.10831359877804486 | validation: 0.09304006636727126]
	TIME [epoch: 62.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11022110730148195		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.11022110730148195 | validation: 0.0973320994245638]
	TIME [epoch: 62.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10551291626189677		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.10551291626189677 | validation: 0.09365542317506012]
	TIME [epoch: 62.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11027324405340565		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.11027324405340565 | validation: 0.0936378086336734]
	TIME [epoch: 62.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10805193561286075		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.10805193561286075 | validation: 0.09393826932685181]
	TIME [epoch: 62.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10599141552611205		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.10599141552611205 | validation: 0.09672753157277793]
	TIME [epoch: 62.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10688029062541865		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.10688029062541865 | validation: 0.0977475621327983]
	TIME [epoch: 62.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11176690997195214		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.11176690997195214 | validation: 0.09334459955212511]
	TIME [epoch: 62.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11422737411760465		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.11422737411760465 | validation: 0.0909211920974081]
	TIME [epoch: 62.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10912526503498723		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.10912526503498723 | validation: 0.0904114470558057]
	TIME [epoch: 62.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10753293283101986		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.10753293283101986 | validation: 0.09363566053233992]
	TIME [epoch: 62.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10913939070396338		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.10913939070396338 | validation: 0.09490610771264565]
	TIME [epoch: 62.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10513144146154287		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.10513144146154287 | validation: 0.0955553614412796]
	TIME [epoch: 62.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118518366612633		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.11118518366612633 | validation: 0.09459801423340408]
	TIME [epoch: 62.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10518639081749505		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.10518639081749505 | validation: 0.09566309147282252]
	TIME [epoch: 62.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11093853577015386		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.11093853577015386 | validation: 0.08965698281962417]
	TIME [epoch: 62.8 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10758848297474705		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.10758848297474705 | validation: 0.0934276843468698]
	TIME [epoch: 62.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11140304711320916		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.11140304711320916 | validation: 0.09446435546199215]
	TIME [epoch: 62.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999241701737182		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.10999241701737182 | validation: 0.09590645462620022]
	TIME [epoch: 62.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975842029641193		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.10975842029641193 | validation: 0.09440127763201897]
	TIME [epoch: 62.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10773924823754807		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.10773924823754807 | validation: 0.09229608599267983]
	TIME [epoch: 62.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118027760911232		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.11118027760911232 | validation: 0.09391143188434384]
	TIME [epoch: 62.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10759264527062426		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.10759264527062426 | validation: 0.09120073403114805]
	TIME [epoch: 62.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909982369873727		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.10909982369873727 | validation: 0.0980241804643511]
	TIME [epoch: 62.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079577555360909		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.1079577555360909 | validation: 0.09075763721429118]
	TIME [epoch: 62.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10412380758554707		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.10412380758554707 | validation: 0.09616638208779318]
	TIME [epoch: 62.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10748584564114089		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.10748584564114089 | validation: 0.09442890824285248]
	TIME [epoch: 62.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10843455130298484		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.10843455130298484 | validation: 0.09159559659806085]
	TIME [epoch: 62.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112328930378281		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.112328930378281 | validation: 0.10361559940709934]
	TIME [epoch: 62.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11099976277114415		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.11099976277114415 | validation: 0.09305169411951908]
	TIME [epoch: 62.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10627558496264304		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.10627558496264304 | validation: 0.0901759698231632]
	TIME [epoch: 62.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10918332289418436		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.10918332289418436 | validation: 0.09337334221981922]
	TIME [epoch: 62.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10587875648811614		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.10587875648811614 | validation: 0.09586486498391564]
	TIME [epoch: 62.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10789462056303455		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.10789462056303455 | validation: 0.09194319305591389]
	TIME [epoch: 62.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10933593054603757		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.10933593054603757 | validation: 0.09723481522029641]
	TIME [epoch: 62.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10662345532652955		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.10662345532652955 | validation: 0.09075690352056062]
	TIME [epoch: 62.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10594419113448919		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.10594419113448919 | validation: 0.09230097809996828]
	TIME [epoch: 62.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1083359862572954		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.1083359862572954 | validation: 0.09497154004344242]
	TIME [epoch: 62.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10941336454551027		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.10941336454551027 | validation: 0.09309613191669124]
	TIME [epoch: 62.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10861966797075619		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.10861966797075619 | validation: 0.09233006596504086]
	TIME [epoch: 62.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1087571196743497		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.1087571196743497 | validation: 0.09199125425077383]
	TIME [epoch: 62.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1117364196979614		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1117364196979614 | validation: 0.10074923416462116]
	TIME [epoch: 62.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11180359446425633		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.11180359446425633 | validation: 0.09205328165178894]
	TIME [epoch: 62.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728317329059246		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.10728317329059246 | validation: 0.09160846148448372]
	TIME [epoch: 62.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11175835727366078		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.11175835727366078 | validation: 0.09018056070108067]
	TIME [epoch: 62.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11021730442299918		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.11021730442299918 | validation: 0.09417267508752535]
	TIME [epoch: 62.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1081635495573176		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.1081635495573176 | validation: 0.09519222495493943]
	TIME [epoch: 62.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10662113646155608		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.10662113646155608 | validation: 0.09501894023387629]
	TIME [epoch: 62.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1054515967718065		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.1054515967718065 | validation: 0.09451833381853927]
	TIME [epoch: 62.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10842023073735113		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.10842023073735113 | validation: 0.09347128125036817]
	TIME [epoch: 62.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898670202494155		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.10898670202494155 | validation: 0.09383404846302476]
	TIME [epoch: 62.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10758145896690657		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.10758145896690657 | validation: 0.09276890564314459]
	TIME [epoch: 62.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10764793017533915		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.10764793017533915 | validation: 0.09390910634715095]
	TIME [epoch: 62.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10820468871724002		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.10820468871724002 | validation: 0.09465027071481327]
	TIME [epoch: 62.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10543435981147348		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.10543435981147348 | validation: 0.09511265140927642]
	TIME [epoch: 62.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1092383846572004		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.1092383846572004 | validation: 0.09150899270272314]
	TIME [epoch: 62.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11006346815493649		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.11006346815493649 | validation: 0.09484446056903764]
	TIME [epoch: 62.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10692805795571372		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.10692805795571372 | validation: 0.09121023589873659]
	TIME [epoch: 62.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10705592132591951		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.10705592132591951 | validation: 0.09286683344868114]
	TIME [epoch: 62.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10752049022178195		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.10752049022178195 | validation: 0.09033360653639567]
	TIME [epoch: 62.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10457021465105562		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.10457021465105562 | validation: 0.09507231445075368]
	TIME [epoch: 62.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10758822094171622		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.10758822094171622 | validation: 0.09638306140518885]
	TIME [epoch: 62.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10695526261750216		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.10695526261750216 | validation: 0.09338233787937805]
	TIME [epoch: 62.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10908306963130401		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.10908306963130401 | validation: 0.09141622298629193]
	TIME [epoch: 62.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1074793832405926		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.1074793832405926 | validation: 0.09273791248493214]
	TIME [epoch: 62.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010413164487762		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.11010413164487762 | validation: 0.09533249830736802]
	TIME [epoch: 62.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10615474073352274		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.10615474073352274 | validation: 0.09358059871193933]
	TIME [epoch: 62.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11028968962617168		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.11028968962617168 | validation: 0.0951929892556828]
	TIME [epoch: 62.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10742566350905441		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.10742566350905441 | validation: 0.09066275426750023]
	TIME [epoch: 62.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10832552271157783		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.10832552271157783 | validation: 0.09409769866827551]
	TIME [epoch: 62.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076701282689691		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.1076701282689691 | validation: 0.09401162837614807]
	TIME [epoch: 62.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10893232536217858		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.10893232536217858 | validation: 0.09327759602279719]
	TIME [epoch: 62.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10886399350646064		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.10886399350646064 | validation: 0.08910530422390195]
	TIME [epoch: 62.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10466754631817093		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.10466754631817093 | validation: 0.09368176523620957]
	TIME [epoch: 62.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10786243649667929		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.10786243649667929 | validation: 0.09343549363821047]
	TIME [epoch: 62.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10810946015255506		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.10810946015255506 | validation: 0.0925756509044335]
	TIME [epoch: 62.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10667120445317578		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.10667120445317578 | validation: 0.09386666742804528]
	TIME [epoch: 62.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10624610062146199		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.10624610062146199 | validation: 0.09148750207413756]
	TIME [epoch: 62.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10893337731254027		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.10893337731254027 | validation: 0.09541765547466116]
	TIME [epoch: 62.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10937484032315131		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.10937484032315131 | validation: 0.09013265102931499]
	TIME [epoch: 62.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108495482565504		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.108495482565504 | validation: 0.09587544998951049]
	TIME [epoch: 62.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10908157632562528		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.10908157632562528 | validation: 0.09607985054366479]
	TIME [epoch: 62.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10596901501774675		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.10596901501774675 | validation: 0.0916398949320553]
	TIME [epoch: 62.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728779376883953		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.10728779376883953 | validation: 0.09635620038462575]
	TIME [epoch: 62.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10392507330095525		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.10392507330095525 | validation: 0.09310189994406295]
	TIME [epoch: 62.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10550654404672016		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.10550654404672016 | validation: 0.09327356976550129]
	TIME [epoch: 62.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10602337865760464		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.10602337865760464 | validation: 0.09203204134027707]
	TIME [epoch: 62.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10916482601668331		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.10916482601668331 | validation: 0.09366239461216176]
	TIME [epoch: 62.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10723593733134304		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.10723593733134304 | validation: 0.09473409697096422]
	TIME [epoch: 62.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10632394907637034		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.10632394907637034 | validation: 0.09526206045097764]
	TIME [epoch: 62.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10510830417044191		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.10510830417044191 | validation: 0.09108510069192817]
	TIME [epoch: 62.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10938717690847152		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.10938717690847152 | validation: 0.09549785977156866]
	TIME [epoch: 62.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10602223252557949		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.10602223252557949 | validation: 0.09291574690628047]
	TIME [epoch: 62.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10558541926895265		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.10558541926895265 | validation: 0.09322287002188967]
	TIME [epoch: 62.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10584576314439093		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.10584576314439093 | validation: 0.09456858120137143]
	TIME [epoch: 62.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10770394244475723		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.10770394244475723 | validation: 0.09334796268207955]
	TIME [epoch: 62.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10579205505193572		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.10579205505193572 | validation: 0.09347902727968789]
	TIME [epoch: 62.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11022675713778662		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.11022675713778662 | validation: 0.09803492858091127]
	TIME [epoch: 62.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10863641274350332		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.10863641274350332 | validation: 0.09212019760352516]
	TIME [epoch: 62.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10776021947733638		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.10776021947733638 | validation: 0.09497587545997359]
	TIME [epoch: 62.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1064655033586453		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.1064655033586453 | validation: 0.09277282961536651]
	TIME [epoch: 62.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10768745696188914		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.10768745696188914 | validation: 0.09160133199837742]
	TIME [epoch: 62.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10420061528286056		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.10420061528286056 | validation: 0.09460632904093748]
	TIME [epoch: 62.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10649139826657586		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.10649139826657586 | validation: 0.0932977058014154]
	TIME [epoch: 62.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728545746057236		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.10728545746057236 | validation: 0.09300069789339047]
	TIME [epoch: 62.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750443404022605		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.10750443404022605 | validation: 0.0920242054983759]
	TIME [epoch: 62.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10799610776149822		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.10799610776149822 | validation: 0.09118604681007872]
	TIME [epoch: 62.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10745552833659419		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.10745552833659419 | validation: 0.09156378020645901]
	TIME [epoch: 62.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10891900713315913		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.10891900713315913 | validation: 0.09367839184978607]
	TIME [epoch: 62.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10652554066367052		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.10652554066367052 | validation: 0.09226339967511578]
	TIME [epoch: 62.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10767370179689711		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.10767370179689711 | validation: 0.09624173463891117]
	TIME [epoch: 62.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1132750354101703		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.1132750354101703 | validation: 0.09357765118771745]
	TIME [epoch: 62.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619239119599402		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.10619239119599402 | validation: 0.08992255305735163]
	TIME [epoch: 62.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10766802491453889		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.10766802491453889 | validation: 0.09137825062275756]
	TIME [epoch: 62.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10598351431786884		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.10598351431786884 | validation: 0.09408428981027016]
	TIME [epoch: 62.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10554461901528445		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.10554461901528445 | validation: 0.0902325898142544]
	TIME [epoch: 62.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10613397288163023		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.10613397288163023 | validation: 0.09284527869996956]
	TIME [epoch: 62.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1064872726667546		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.1064872726667546 | validation: 0.09357827583542769]
	TIME [epoch: 62.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10794713565486491		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.10794713565486491 | validation: 0.08998336876741234]
	TIME [epoch: 62.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10766124805226059		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.10766124805226059 | validation: 0.09500872491543919]
	TIME [epoch: 62.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10817678815040672		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.10817678815040672 | validation: 0.09050393443358858]
	TIME [epoch: 62.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10615068802563224		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.10615068802563224 | validation: 0.09131861582899808]
	TIME [epoch: 62.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10446103782170146		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.10446103782170146 | validation: 0.09372718299091228]
	TIME [epoch: 62.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10485653453464863		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.10485653453464863 | validation: 0.08998618034061938]
	TIME [epoch: 62.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10806862056752295		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.10806862056752295 | validation: 0.09339734322888008]
	TIME [epoch: 62.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10567956522870299		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.10567956522870299 | validation: 0.09494789426449209]
	TIME [epoch: 62.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10468952422556115		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.10468952422556115 | validation: 0.09496736596956047]
	TIME [epoch: 62.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10390192279709758		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.10390192279709758 | validation: 0.0939939447701166]
	TIME [epoch: 62.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10598884101438337		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.10598884101438337 | validation: 0.09315609222040584]
	TIME [epoch: 62.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10722365370777799		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.10722365370777799 | validation: 0.09416916613754867]
	TIME [epoch: 62.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867144621852592		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.10867144621852592 | validation: 0.0922137778774109]
	TIME [epoch: 62.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10554133111655918		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.10554133111655918 | validation: 0.0949739363280045]
	TIME [epoch: 62.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10802119280136603		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.10802119280136603 | validation: 0.09170513430195582]
	TIME [epoch: 62.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10616994438411019		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.10616994438411019 | validation: 0.09293602127767445]
	TIME [epoch: 62.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10854701915627694		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.10854701915627694 | validation: 0.09409279084157399]
	TIME [epoch: 62.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10341202990928992		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.10341202990928992 | validation: 0.09383063938921551]
	TIME [epoch: 62.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10960737586312934		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.10960737586312934 | validation: 0.09607841012456671]
	TIME [epoch: 62.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10607809714152432		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.10607809714152432 | validation: 0.09520718429616891]
	TIME [epoch: 62.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10612945410768775		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.10612945410768775 | validation: 0.09350667068507937]
	TIME [epoch: 62.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10605271915409213		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.10605271915409213 | validation: 0.09324608759393908]
	TIME [epoch: 62.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10682507768709475		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.10682507768709475 | validation: 0.09527356033298015]
	TIME [epoch: 62.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11129879356347169		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.11129879356347169 | validation: 0.08988584670151163]
	TIME [epoch: 62.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10513270585831151		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.10513270585831151 | validation: 0.09350638849532258]
	TIME [epoch: 62.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10382399851004817		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.10382399851004817 | validation: 0.09454837727910069]
	TIME [epoch: 62.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1057179908383888		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.1057179908383888 | validation: 0.09106041878153412]
	TIME [epoch: 62.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1047790999280316		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.1047790999280316 | validation: 0.09358546218578098]
	TIME [epoch: 62.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1068673641100894		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.1068673641100894 | validation: 0.09139893374091393]
	TIME [epoch: 62.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10719463419318616		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.10719463419318616 | validation: 0.09319025764582962]
	TIME [epoch: 62.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10657984681190694		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.10657984681190694 | validation: 0.09100535111717166]
	TIME [epoch: 62.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10462094041705874		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.10462094041705874 | validation: 0.09154097582938586]
	TIME [epoch: 62.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814919643034943		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.10814919643034943 | validation: 0.09155187702963578]
	TIME [epoch: 62.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1047802815434252		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1047802815434252 | validation: 0.09271885980045025]
	TIME [epoch: 62.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10688143046284854		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.10688143046284854 | validation: 0.0916981242100395]
	TIME [epoch: 62.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10666202395435859		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.10666202395435859 | validation: 0.09364146947705984]
	TIME [epoch: 62.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1120424025373327		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.1120424025373327 | validation: 0.09846928452700557]
	TIME [epoch: 62.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10856467527214904		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.10856467527214904 | validation: 0.09289909069685273]
	TIME [epoch: 62.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10530897227381059		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.10530897227381059 | validation: 0.08984093963383613]
	TIME [epoch: 62.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10624957453960046		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.10624957453960046 | validation: 0.09485508519586829]
	TIME [epoch: 62.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10647683843122824		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.10647683843122824 | validation: 0.09311203892776243]
	TIME [epoch: 62.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1054282540250257		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.1054282540250257 | validation: 0.09635853532903481]
	TIME [epoch: 62.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10818675375906525		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.10818675375906525 | validation: 0.09013003881170858]
	TIME [epoch: 62.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10420961654987601		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.10420961654987601 | validation: 0.09058705500408018]
	TIME [epoch: 62.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589198219312108		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.10589198219312108 | validation: 0.0917695958441144]
	TIME [epoch: 62.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10735927856699473		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.10735927856699473 | validation: 0.09185786900315362]
	TIME [epoch: 62.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10713474439531512		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.10713474439531512 | validation: 0.09094200174917313]
	TIME [epoch: 62.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10805963140660024		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.10805963140660024 | validation: 0.09108401196833797]
	TIME [epoch: 62.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10451362754141234		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.10451362754141234 | validation: 0.09372378308827133]
	TIME [epoch: 62.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10803454405216871		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.10803454405216871 | validation: 0.08964020344594131]
	TIME [epoch: 62.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10454609031632395		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.10454609031632395 | validation: 0.08879127215253697]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10607842532865316		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.10607842532865316 | validation: 0.09974101435903455]
	TIME [epoch: 62.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10574016596525586		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.10574016596525586 | validation: 0.09419099659194823]
	TIME [epoch: 62.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10356885931635959		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10356885931635959 | validation: 0.09661935622211557]
	TIME [epoch: 62.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10456662073186902		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.10456662073186902 | validation: 0.09144796649987383]
	TIME [epoch: 62.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10772546982178022		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.10772546982178022 | validation: 0.09342389879285186]
	TIME [epoch: 62.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10388763971977102		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.10388763971977102 | validation: 0.09183679305139184]
	TIME [epoch: 62.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10762729233008612		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.10762729233008612 | validation: 0.08960065610042071]
	TIME [epoch: 62.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10550522910698218		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.10550522910698218 | validation: 0.09209956496987123]
	TIME [epoch: 62.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10355472024618953		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.10355472024618953 | validation: 0.09388274206693875]
	TIME [epoch: 62.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10789831702294528		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.10789831702294528 | validation: 0.09076992009144288]
	TIME [epoch: 62.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10454632085625318		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10454632085625318 | validation: 0.09321165789302283]
	TIME [epoch: 62.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11284598801191935		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.11284598801191935 | validation: 0.092076560889284]
	TIME [epoch: 62.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1065649926842315		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1065649926842315 | validation: 0.09182431511938358]
	TIME [epoch: 62.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10438558728271558		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.10438558728271558 | validation: 0.09132584508208437]
	TIME [epoch: 62.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10743999699741422		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.10743999699741422 | validation: 0.09145321211114563]
	TIME [epoch: 62.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11015537834433413		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.11015537834433413 | validation: 0.09442324448895437]
	TIME [epoch: 62.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10693681796327871		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.10693681796327871 | validation: 0.0924800754084685]
	TIME [epoch: 62.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1055315035013333		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.1055315035013333 | validation: 0.09261568813551971]
	TIME [epoch: 62.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10489792273663985		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.10489792273663985 | validation: 0.09516173058113381]
	TIME [epoch: 62.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10470996034342933		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.10470996034342933 | validation: 0.09506532981673413]
	TIME [epoch: 62.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10659102374932182		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.10659102374932182 | validation: 0.08990894787540694]
	TIME [epoch: 62.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10781959090305662		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.10781959090305662 | validation: 0.09116806259067851]
	TIME [epoch: 62.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10897812289038729		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.10897812289038729 | validation: 0.09008007825437192]
	TIME [epoch: 62.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10236053739797538		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.10236053739797538 | validation: 0.09325415447497112]
	TIME [epoch: 62.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10621226392679373		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.10621226392679373 | validation: 0.08980230183929747]
	TIME [epoch: 62.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10520680548020893		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.10520680548020893 | validation: 0.0937466659239731]
	TIME [epoch: 62.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10508971780523829		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10508971780523829 | validation: 0.0908889039286429]
	TIME [epoch: 62.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10778525654563552		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.10778525654563552 | validation: 0.09173000197298586]
	TIME [epoch: 62.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108019820004638		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.108019820004638 | validation: 0.09032197967275298]
	TIME [epoch: 62.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10580702666285127		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.10580702666285127 | validation: 0.09364008414840085]
	TIME [epoch: 62.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10846769248463219		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.10846769248463219 | validation: 0.09261100043917209]
	TIME [epoch: 62.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10558066214230474		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.10558066214230474 | validation: 0.09196385336180199]
	TIME [epoch: 62.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10552152324495301		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.10552152324495301 | validation: 0.09410494751606671]
	TIME [epoch: 62.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10712410369056007		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.10712410369056007 | validation: 0.08895842645472077]
	TIME [epoch: 62.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10401428663478351		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.10401428663478351 | validation: 0.0939971915183359]
	TIME [epoch: 62.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1053040733276196		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.1053040733276196 | validation: 0.09417456949068462]
	TIME [epoch: 62.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10414372269410692		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.10414372269410692 | validation: 0.09215239541376977]
	TIME [epoch: 62.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10428409243574993		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.10428409243574993 | validation: 0.08878962396410048]
	TIME [epoch: 62.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10883598680196784		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.10883598680196784 | validation: 0.09382637328835547]
	TIME [epoch: 62.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10679408263006784		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.10679408263006784 | validation: 0.09364445775664336]
	TIME [epoch: 62.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10650379319037519		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.10650379319037519 | validation: 0.09074914623707987]
	TIME [epoch: 62.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10399122362625018		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.10399122362625018 | validation: 0.0940346945698182]
	TIME [epoch: 62.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1058300532261525		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1058300532261525 | validation: 0.09318854572304902]
	TIME [epoch: 62.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782441451344413		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.10782441451344413 | validation: 0.08980760717054866]
	TIME [epoch: 62.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10385291157425482		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.10385291157425482 | validation: 0.09180671789809218]
	TIME [epoch: 62.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10380095249420483		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.10380095249420483 | validation: 0.09131116265277507]
	TIME [epoch: 62.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10451155735485669		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.10451155735485669 | validation: 0.09242116305334078]
	TIME [epoch: 62.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10302007550146546		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.10302007550146546 | validation: 0.0922033345329315]
	TIME [epoch: 62.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10410885130852174		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.10410885130852174 | validation: 0.09152382609131568]
	TIME [epoch: 62.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098135353866525		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.1098135353866525 | validation: 0.08925713212452761]
	TIME [epoch: 62.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10575955736907869		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10575955736907869 | validation: 0.09187936914739754]
	TIME [epoch: 62.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10501973924959282		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.10501973924959282 | validation: 0.09315963836235287]
	TIME [epoch: 62.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10707846174328695		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.10707846174328695 | validation: 0.09114912444704484]
	TIME [epoch: 62.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10400747891870167		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.10400747891870167 | validation: 0.09477463428592053]
	TIME [epoch: 62.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10724936157486219		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.10724936157486219 | validation: 0.09383900174542097]
	TIME [epoch: 62.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10618308910735841		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.10618308910735841 | validation: 0.09078468690490418]
	TIME [epoch: 62.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10668480983839163		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.10668480983839163 | validation: 0.0917765193163258]
	TIME [epoch: 62.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10216663679580751		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.10216663679580751 | validation: 0.09132370121716543]
	TIME [epoch: 62.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1062091481833299		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.1062091481833299 | validation: 0.09192693141237361]
	TIME [epoch: 62.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10368916917790606		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.10368916917790606 | validation: 0.0938607060196294]
	TIME [epoch: 62.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10530541374480516		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.10530541374480516 | validation: 0.09326206086447016]
	TIME [epoch: 62.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10498504051143652		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.10498504051143652 | validation: 0.09359956839852523]
	TIME [epoch: 62.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10723041887172186		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.10723041887172186 | validation: 0.09382549639895284]
	TIME [epoch: 62.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10671472142219231		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.10671472142219231 | validation: 0.09322845010572908]
	TIME [epoch: 62.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10794725780309242		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.10794725780309242 | validation: 0.09816068840122752]
	TIME [epoch: 62.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10793517736960975		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.10793517736960975 | validation: 0.09563221710666633]
	TIME [epoch: 62.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10260879574832349		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.10260879574832349 | validation: 0.09227664037938678]
	TIME [epoch: 62.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10570061355846885		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.10570061355846885 | validation: 0.09247955088282897]
	TIME [epoch: 62.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10459215809711006		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.10459215809711006 | validation: 0.09221799700266033]
	TIME [epoch: 62.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10079172008332055		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.10079172008332055 | validation: 0.09323619272893667]
	TIME [epoch: 62.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1055316023418874		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.1055316023418874 | validation: 0.092315048951267]
	TIME [epoch: 62.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10342357002552825		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.10342357002552825 | validation: 0.09118779142150084]
	TIME [epoch: 62.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10578648226818571		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.10578648226818571 | validation: 0.08939680171517105]
	TIME [epoch: 62.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10565803586406157		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.10565803586406157 | validation: 0.09064690402686434]
	TIME [epoch: 62.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10540569574968542		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.10540569574968542 | validation: 0.09052583980885376]
	TIME [epoch: 62.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10667171696731612		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.10667171696731612 | validation: 0.09231673899940443]
	TIME [epoch: 62.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10802000695159353		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.10802000695159353 | validation: 0.09081514209937552]
	TIME [epoch: 62.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10754214844124267		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.10754214844124267 | validation: 0.09032163469736484]
	TIME [epoch: 62.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10546024056037798		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.10546024056037798 | validation: 0.09299712408233965]
	TIME [epoch: 62.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10578885592428675		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.10578885592428675 | validation: 0.09307166344881942]
	TIME [epoch: 62.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10829491519081832		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.10829491519081832 | validation: 0.09238294605891845]
	TIME [epoch: 62.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10393108552542114		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.10393108552542114 | validation: 0.09257494621098566]
	TIME [epoch: 62.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10631882595096506		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10631882595096506 | validation: 0.09400419334712376]
	TIME [epoch: 62.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1030396194689655		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.1030396194689655 | validation: 0.08951107915909488]
	TIME [epoch: 62.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10493477240382984		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.10493477240382984 | validation: 0.0937095295965569]
	TIME [epoch: 62.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619345615777219		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.10619345615777219 | validation: 0.09340182656944863]
	TIME [epoch: 62.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10662219055418584		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.10662219055418584 | validation: 0.09163667538210915]
	TIME [epoch: 62.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1063206180479638		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.1063206180479638 | validation: 0.09084868363052674]
	TIME [epoch: 62.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1050960927232681		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.1050960927232681 | validation: 0.09281567712234186]
	TIME [epoch: 62.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1060975771471383		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.1060975771471383 | validation: 0.09316750696042839]
	TIME [epoch: 62.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595006763202879		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.10595006763202879 | validation: 0.09375753717709526]
	TIME [epoch: 62.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1038686007537302		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.1038686007537302 | validation: 0.09331962961348488]
	TIME [epoch: 62.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1037863639443741		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1037863639443741 | validation: 0.0905806498332089]
	TIME [epoch: 62.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10542256706263348		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.10542256706263348 | validation: 0.09250505957918205]
	TIME [epoch: 62.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10669164068325555		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.10669164068325555 | validation: 0.09348941686254374]
	TIME [epoch: 62.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10584036436284722		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.10584036436284722 | validation: 0.09185575376147351]
	TIME [epoch: 62.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10367046438654161		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.10367046438654161 | validation: 0.09054051841398825]
	TIME [epoch: 62.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10379854958332374		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.10379854958332374 | validation: 0.09263312356657283]
	TIME [epoch: 62.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10630291595403914		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.10630291595403914 | validation: 0.09264041650790246]
	TIME [epoch: 62.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10378177709387507		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.10378177709387507 | validation: 0.09123750912289876]
	TIME [epoch: 62.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10465329142873749		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.10465329142873749 | validation: 0.08971232849660402]
	TIME [epoch: 62.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10646640375410645		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.10646640375410645 | validation: 0.0897217496314377]
	TIME [epoch: 62.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10623648655211715		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.10623648655211715 | validation: 0.09068755711993368]
	TIME [epoch: 62.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10280886703198094		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.10280886703198094 | validation: 0.09128667381460148]
	TIME [epoch: 62.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10703540960972328		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.10703540960972328 | validation: 0.09146749176982012]
	TIME [epoch: 62.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1057193788385669		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.1057193788385669 | validation: 0.09139476787439357]
	TIME [epoch: 62.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10627663799429493		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.10627663799429493 | validation: 0.09232156982529391]
	TIME [epoch: 62.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10542090496507758		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.10542090496507758 | validation: 0.09259765189638296]
	TIME [epoch: 62.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11640765428623359		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.11640765428623359 | validation: 0.09052764001807681]
	TIME [epoch: 62.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10273778535429694		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.10273778535429694 | validation: 0.09298504896668547]
	TIME [epoch: 62.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10434935817437124		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.10434935817437124 | validation: 0.09042851423833212]
	TIME [epoch: 62.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10384357531847009		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.10384357531847009 | validation: 0.09315299242252077]
	TIME [epoch: 62.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10464751990987946		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.10464751990987946 | validation: 0.09124171318204327]
	TIME [epoch: 62.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10364973415342195		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.10364973415342195 | validation: 0.0904458391265129]
	TIME [epoch: 62.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10462918997523084		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.10462918997523084 | validation: 0.0925596069458213]
	TIME [epoch: 62.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.105048622219205		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.105048622219205 | validation: 0.09552201394210666]
	TIME [epoch: 62.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10856368386644932		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.10856368386644932 | validation: 0.09017951613373387]
	TIME [epoch: 62.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10377571509776372		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.10377571509776372 | validation: 0.09207818070791368]
	TIME [epoch: 62.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10541023908208622		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.10541023908208622 | validation: 0.09304709055029899]
	TIME [epoch: 62.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10436293993349945		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.10436293993349945 | validation: 0.0933125830610419]
	TIME [epoch: 62.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10802523556094129		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.10802523556094129 | validation: 0.09242744693808125]
	TIME [epoch: 62.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10702153485339466		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.10702153485339466 | validation: 0.0925838287701527]
	TIME [epoch: 62.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10579158270834849		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.10579158270834849 | validation: 0.09158312494992092]
	TIME [epoch: 62.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10677960619188456		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.10677960619188456 | validation: 0.09307995778656973]
	TIME [epoch: 62.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10453482233847781		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.10453482233847781 | validation: 0.09268773455482714]
	TIME [epoch: 62.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10607439822717965		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.10607439822717965 | validation: 0.09263033677930785]
	TIME [epoch: 62.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10439875765845325		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.10439875765845325 | validation: 0.09422138828830443]
	TIME [epoch: 62.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10531273417028052		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.10531273417028052 | validation: 0.09440950364748282]
	TIME [epoch: 62.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1063808341047765		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.1063808341047765 | validation: 0.09171985687680516]
	TIME [epoch: 62.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10673935573937549		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.10673935573937549 | validation: 0.09410785595244453]
	TIME [epoch: 62.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10413428462752813		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.10413428462752813 | validation: 0.0927874067091535]
	TIME [epoch: 62.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10497867819095301		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.10497867819095301 | validation: 0.09345060891946888]
	TIME [epoch: 62.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10551216550236169		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.10551216550236169 | validation: 0.09417166697484539]
	TIME [epoch: 62.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1050853538055177		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.1050853538055177 | validation: 0.09367706421654293]
	TIME [epoch: 62.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10822261035716688		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.10822261035716688 | validation: 0.09437417836143087]
	TIME [epoch: 62.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10493877701313836		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.10493877701313836 | validation: 0.08954698190340922]
	TIME [epoch: 62.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10489279274364616		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.10489279274364616 | validation: 0.090449706381911]
	TIME [epoch: 62.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10544023277013895		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.10544023277013895 | validation: 0.09120936325152904]
	TIME [epoch: 62.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10326489764193125		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.10326489764193125 | validation: 0.09166676353798656]
	TIME [epoch: 62.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1061866051738851		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.1061866051738851 | validation: 0.09275166135465372]
	TIME [epoch: 62.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10320008293100108		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.10320008293100108 | validation: 0.09101612950625274]
	TIME [epoch: 62.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10413678221497663		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.10413678221497663 | validation: 0.0923171215556]
	TIME [epoch: 62.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10659513349532941		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.10659513349532941 | validation: 0.09157876181800231]
	TIME [epoch: 62.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10550128558584877		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.10550128558584877 | validation: 0.09052401143222125]
	TIME [epoch: 62.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1021208667969863		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.1021208667969863 | validation: 0.09149668170126929]
	TIME [epoch: 62.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1044479706243038		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.1044479706243038 | validation: 0.0924990669414095]
	TIME [epoch: 62.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10557619934309541		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10557619934309541 | validation: 0.09378606557439315]
	TIME [epoch: 62.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10528840894872771		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.10528840894872771 | validation: 0.09035943475566363]
	TIME [epoch: 62.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10756633980305427		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.10756633980305427 | validation: 0.0915937831355915]
	TIME [epoch: 62.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10339499611532971		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.10339499611532971 | validation: 0.09449426379283818]
	TIME [epoch: 62.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10469966578998573		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.10469966578998573 | validation: 0.09232310567882632]
	TIME [epoch: 62.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10387083986504383		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.10387083986504383 | validation: 0.08997985782223344]
	TIME [epoch: 62.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1033200744935291		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.1033200744935291 | validation: 0.0929433405384066]
	TIME [epoch: 62.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1043414539806601		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.1043414539806601 | validation: 0.09051879359691334]
	TIME [epoch: 62.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10493789991366226		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.10493789991366226 | validation: 0.09095511601783655]
	TIME [epoch: 62.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10282161712748954		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.10282161712748954 | validation: 0.0923963289678332]
	TIME [epoch: 62.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10421329077167095		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.10421329077167095 | validation: 0.09115959183048003]
	TIME [epoch: 62.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1033470354392528		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.1033470354392528 | validation: 0.09219577455313557]
	TIME [epoch: 62.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10273002070714758		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.10273002070714758 | validation: 0.09223994738542064]
	TIME [epoch: 62.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1051956500765977		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.1051956500765977 | validation: 0.0926687039262496]
	TIME [epoch: 62.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1044292652775707		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.1044292652775707 | validation: 0.09177645617294869]
	TIME [epoch: 62.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784326747248489		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.10784326747248489 | validation: 0.09308029104815933]
	TIME [epoch: 62.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10434426453673104		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10434426453673104 | validation: 0.09232746828754751]
	TIME [epoch: 62.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10521295154591866		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.10521295154591866 | validation: 0.09208656512149176]
	TIME [epoch: 62.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10291014602080711		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.10291014602080711 | validation: 0.09252741042019522]
	TIME [epoch: 62.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10580120425242422		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.10580120425242422 | validation: 0.09144134627393061]
	TIME [epoch: 62.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10598886670437388		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.10598886670437388 | validation: 0.09322220949909951]
	TIME [epoch: 62.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10450486412430969		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.10450486412430969 | validation: 0.09265266999607885]
	TIME [epoch: 62.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595244091374245		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.10595244091374245 | validation: 0.09297197778673147]
	TIME [epoch: 62.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1027046901363732		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.1027046901363732 | validation: 0.0923594556214993]
	TIME [epoch: 62.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10527804566319691		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.10527804566319691 | validation: 0.09019303570743131]
	TIME [epoch: 62.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1056223454573064		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.1056223454573064 | validation: 0.09168016386772067]
	TIME [epoch: 62.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10487269665176074		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.10487269665176074 | validation: 0.09253812539746788]
	TIME [epoch: 62.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10320182918747224		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.10320182918747224 | validation: 0.08959217442745507]
	TIME [epoch: 62.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10429096516908974		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.10429096516908974 | validation: 0.09064094992042848]
	TIME [epoch: 62.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10336219007955		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.10336219007955 | validation: 0.09198709224619601]
	TIME [epoch: 62.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10640156740059903		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.10640156740059903 | validation: 0.09201737923372855]
	TIME [epoch: 62.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10607263046429072		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.10607263046429072 | validation: 0.0913393026220601]
	TIME [epoch: 62.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1059730096910251		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1059730096910251 | validation: 0.08932294743238922]
	TIME [epoch: 62.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10361698874859206		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.10361698874859206 | validation: 0.09253537749211288]
	TIME [epoch: 62.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10457254895234819		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.10457254895234819 | validation: 0.0910035888704608]
	TIME [epoch: 62.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.105265838604514		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.105265838604514 | validation: 0.09072995824157097]
	TIME [epoch: 62.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10181226275417032		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.10181226275417032 | validation: 0.09131606279321461]
	TIME [epoch: 62.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10770473460889009		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.10770473460889009 | validation: 0.0882623490545813]
	TIME [epoch: 62.7 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_163619/states/model_facs_dec1a_2dpca_v1_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1071075015442204		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.1071075015442204 | validation: 0.08993497608378652]
	TIME [epoch: 62.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10496269941389565		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.10496269941389565 | validation: 0.09014969377280888]
	TIME [epoch: 62.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10680313380484509		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.10680313380484509 | validation: 0.09198307550741787]
	TIME [epoch: 62.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10984967066497944		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.10984967066497944 | validation: 0.09111585813423938]
	TIME [epoch: 62.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10554198290628092		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.10554198290628092 | validation: 0.08832382849073642]
	TIME [epoch: 62.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10561076625763083		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.10561076625763083 | validation: 0.08980228102644727]
	TIME [epoch: 62.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10097030665002586		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.10097030665002586 | validation: 0.08936362758694949]
	TIME [epoch: 62.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10548780856315115		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.10548780856315115 | validation: 0.09011751634867618]
	TIME [epoch: 62.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10661163516261579		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.10661163516261579 | validation: 0.09011458636001468]
	TIME [epoch: 62.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10412784502540973		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.10412784502540973 | validation: 0.09061653752971437]
	TIME [epoch: 62.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814080041841216		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10814080041841216 | validation: 0.09283442830489849]
	TIME [epoch: 62.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10380483558172537		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.10380483558172537 | validation: 0.09223083561644607]
	TIME [epoch: 62.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10455454517460112		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.10455454517460112 | validation: 0.09169664210730002]
	TIME [epoch: 62.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10414045621245813		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.10414045621245813 | validation: 0.09200481830989522]
	TIME [epoch: 62.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10608840746903617		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.10608840746903617 | validation: 0.09212752263997331]
	TIME [epoch: 62.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10691210082222714		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.10691210082222714 | validation: 0.08841153299673918]
	TIME [epoch: 62.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10486775215839904		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.10486775215839904 | validation: 0.08983490262460125]
	TIME [epoch: 62.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10480281171011856		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.10480281171011856 | validation: 0.09160310830290046]
	TIME [epoch: 62.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10544333746669654		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.10544333746669654 | validation: 0.0919578055612075]
	TIME [epoch: 62.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10363702291854798		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.10363702291854798 | validation: 0.09002783560464901]
	TIME [epoch: 62.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10479953223524113		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.10479953223524113 | validation: 0.09004217186689709]
	TIME [epoch: 62.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10404021058971734		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.10404021058971734 | validation: 0.08890620535703102]
	TIME [epoch: 62.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10574129638752873		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.10574129638752873 | validation: 0.09298005053888421]
	TIME [epoch: 62.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10697168768447916		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.10697168768447916 | validation: 0.0904547360596901]
	TIME [epoch: 62.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10527456773782229		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.10527456773782229 | validation: 0.09076935866508275]
	TIME [epoch: 62.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10687350721576487		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.10687350721576487 | validation: 0.09034789368032767]
	TIME [epoch: 62.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10783856774044581		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.10783856774044581 | validation: 0.09130666308118005]
	TIME [epoch: 62.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1043022273593506		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.1043022273593506 | validation: 0.08900815607303303]
	TIME [epoch: 62.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10591737734925427		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.10591737734925427 | validation: 0.08904374724612509]
	TIME [epoch: 62.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10779534462665147		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.10779534462665147 | validation: 0.09070935484100082]
	TIME [epoch: 62.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10475450460723101		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.10475450460723101 | validation: 0.09106221058532166]
	TIME [epoch: 62.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10448925541300311		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.10448925541300311 | validation: 0.09135695426469802]
	TIME [epoch: 62.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10755698689967473		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.10755698689967473 | validation: 0.09282369794776713]
	TIME [epoch: 62.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10493974627289368		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.10493974627289368 | validation: 0.09014680068894759]
	TIME [epoch: 62.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906162800107441		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.10906162800107441 | validation: 0.09127635854489254]
	TIME [epoch: 62.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10375963275831637		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.10375963275831637 | validation: 0.08980162322043816]
	TIME [epoch: 62.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10505755513817243		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.10505755513817243 | validation: 0.09110146377946718]
	TIME [epoch: 62.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10482336353636891		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.10482336353636891 | validation: 0.09172411486665766]
	TIME [epoch: 62.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10576511202286923		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.10576511202286923 | validation: 0.09119667752943875]
	TIME [epoch: 62.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10527317590913769		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.10527317590913769 | validation: 0.09116549503208426]
	TIME [epoch: 62.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10398067566060072		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.10398067566060072 | validation: 0.08953948459162382]
	TIME [epoch: 62.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10451206558472055		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.10451206558472055 | validation: 0.08990108633610044]
	TIME [epoch: 62.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10532734830719945		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10532734830719945 | validation: 0.09089272695321661]
	TIME [epoch: 62.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10273366478305411		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.10273366478305411 | validation: 0.08833590165249744]
	TIME [epoch: 62.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10257753380337148		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.10257753380337148 | validation: 0.09177402497916576]
	TIME [epoch: 62.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10638857059408172		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.10638857059408172 | validation: 0.09042012991399559]
	TIME [epoch: 62.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10405192876202388		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.10405192876202388 | validation: 0.09131174978132542]
	TIME [epoch: 62.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10547992110177384		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.10547992110177384 | validation: 0.09197132161967624]
	TIME [epoch: 62.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10606873940574646		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.10606873940574646 | validation: 0.09078450502709436]
	TIME [epoch: 62.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10359982916584068		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.10359982916584068 | validation: 0.09091937751253458]
	TIME [epoch: 62.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10532427300143418		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.10532427300143418 | validation: 0.09037124276816876]
	TIME [epoch: 62.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1031929380510231		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.1031929380510231 | validation: 0.09058529727351398]
	TIME [epoch: 62.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10436338060369632		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.10436338060369632 | validation: 0.09003835188078135]
	TIME [epoch: 62.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.105708318227636		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.105708318227636 | validation: 0.09147193081579445]
	TIME [epoch: 62.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10349522788747495		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.10349522788747495 | validation: 0.0920377731993446]
	TIME [epoch: 62.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10264969969996177		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.10264969969996177 | validation: 0.09098666285199626]
	TIME [epoch: 62.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10558119558677899		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.10558119558677899 | validation: 0.09009160924566714]
	TIME [epoch: 62.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10244985336565207		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.10244985336565207 | validation: 0.08974319603299921]
	TIME [epoch: 62.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10617613947112928		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10617613947112928 | validation: 0.09231579307482574]
	TIME [epoch: 62.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10444533861289289		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.10444533861289289 | validation: 0.09058567642592985]
	TIME [epoch: 62.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11048302493089268		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.11048302493089268 | validation: 0.09118772883350439]
	TIME [epoch: 62.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10143127629072		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.10143127629072 | validation: 0.09235606791935318]
	TIME [epoch: 62.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10412956531705538		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.10412956531705538 | validation: 0.08984293494862873]
	TIME [epoch: 62.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10431062733735133		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.10431062733735133 | validation: 0.08991802568101889]
	TIME [epoch: 62.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10419171981487842		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.10419171981487842 | validation: 0.09049357640425343]
	TIME [epoch: 62.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10468506950490707		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.10468506950490707 | validation: 0.09170321633510743]
	TIME [epoch: 62.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10411970093661249		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10411970093661249 | validation: 0.09134832671590953]
	TIME [epoch: 62.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10269064850118889		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.10269064850118889 | validation: 0.09036872586207131]
	TIME [epoch: 62.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10111578784945127		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.10111578784945127 | validation: 0.09016646600049188]
	TIME [epoch: 62.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10405674747842829		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.10405674747842829 | validation: 0.09130648938915166]
	TIME [epoch: 62.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10231440282023832		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.10231440282023832 | validation: 0.09078970531921635]
	TIME [epoch: 62.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10397066193893051		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.10397066193893051 | validation: 0.08920341042874111]
	TIME [epoch: 62.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10505154985819704		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.10505154985819704 | validation: 0.09019505893065158]
	TIME [epoch: 62.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10353589184443544		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.10353589184443544 | validation: 0.09121054741374982]
	TIME [epoch: 62.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10228728197869719		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.10228728197869719 | validation: 0.09156868916829108]
	TIME [epoch: 62.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10335242889943677		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.10335242889943677 | validation: 0.09138657208098509]
	TIME [epoch: 62.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10239755756790367		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.10239755756790367 | validation: 0.09327501242936917]
	TIME [epoch: 62.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10590876269334577		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.10590876269334577 | validation: 0.09186232004457151]
	TIME [epoch: 62.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10358664030044028		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.10358664030044028 | validation: 0.09109671161441131]
	TIME [epoch: 62.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10399356231018235		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.10399356231018235 | validation: 0.0900455595771884]
	TIME [epoch: 62.6 sec]
EPOCH 693/2000:
	Training over batches...
