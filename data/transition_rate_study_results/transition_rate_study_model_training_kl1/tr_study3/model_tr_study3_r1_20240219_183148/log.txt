Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 382803814

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.445095981253726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.445095981253726 | validation: 11.626362951217363]
	TIME [epoch: 53.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.962672733267087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.962672733267087 | validation: 10.998361618092645]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.236385832792566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.236385832792566 | validation: 10.950017549699409]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.389757439698808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.389757439698808 | validation: 7.552710452185462]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.650122543907417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.650122543907417 | validation: 7.336039568948238]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.621468118247675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.621468118247675 | validation: 7.068658095411318]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.455078428648652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.455078428648652 | validation: 6.992691637073444]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.479527563019287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.479527563019287 | validation: 6.9190009933779315]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.331448019284074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.331448019284074 | validation: 6.867173020626476]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.307814810171526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.307814810171526 | validation: 6.8340376774095635]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.296254291356083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.296254291356083 | validation: 6.8258554681454155]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.2165897665402685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2165897665402685 | validation: 6.698355397606607]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.197430913595559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.197430913595559 | validation: 6.6666809071610675]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.1581672652111825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1581672652111825 | validation: 6.7864994664474025]
	TIME [epoch: 8.35 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.072533038624613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.072533038624613 | validation: 6.87140970843044]
	TIME [epoch: 8.34 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.156547816814158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.156547816814158 | validation: 6.759394104878423]
	TIME [epoch: 8.36 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.090347949013795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.090347949013795 | validation: 6.632574024671907]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.106287769298623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.106287769298623 | validation: 6.639333125361519]
	TIME [epoch: 8.35 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.050660548049768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.050660548049768 | validation: 6.824607917743936]
	TIME [epoch: 8.35 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.976949905925887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.976949905925887 | validation: 6.418989308268232]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.999386224355314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.999386224355314 | validation: 6.364713157754538]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.975865720118555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.975865720118555 | validation: 6.282992077500787]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.966038349075315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966038349075315 | validation: 6.242030293630638]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.723792735505803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.723792735505803 | validation: 6.038776815719537]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.68401612341538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.68401612341538 | validation: 5.910998844946652]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.577829863550223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.577829863550223 | validation: 5.627050256402276]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.284440194252426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.284440194252426 | validation: 4.032293141706043]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0274528813277986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0274528813277986 | validation: 4.279636509386707]
	TIME [epoch: 8.37 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.435429410540129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.435429410540129 | validation: 4.145198791609248]
	TIME [epoch: 8.34 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.597895428013558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.597895428013558 | validation: 4.697361987097965]
	TIME [epoch: 8.34 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.386165748328069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.386165748328069 | validation: 3.983793437128924]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.275293963470274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.275293963470274 | validation: 3.8204367648907125]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.137927406044565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.137927406044565 | validation: 3.5758356753004064]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.240448310714808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.240448310714808 | validation: 3.617642578743302]
	TIME [epoch: 8.34 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.420828568705306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.420828568705306 | validation: 3.817766712061302]
	TIME [epoch: 8.34 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.121250741191238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.121250741191238 | validation: 4.33204287791044]
	TIME [epoch: 8.36 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.246063169439212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.246063169439212 | validation: 3.6324410191489753]
	TIME [epoch: 8.34 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.027772150622398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.027772150622398 | validation: 3.55392311868559]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9349177167107485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9349177167107485 | validation: 3.9711713050592934]
	TIME [epoch: 8.36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.142502647509079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.142502647509079 | validation: 3.462842800016138]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.841908612262668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.841908612262668 | validation: 3.401566925951422]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.227538849397685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.227538849397685 | validation: 6.836778869532958]
	TIME [epoch: 8.37 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.87008164762436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.87008164762436 | validation: 3.832345270473735]
	TIME [epoch: 8.36 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9477571469154205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9477571469154205 | validation: 3.543951464828718]
	TIME [epoch: 8.39 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8379937577551813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8379937577551813 | validation: 3.3927623216992058]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8198253286882164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8198253286882164 | validation: 4.7852004304004305]
	TIME [epoch: 8.36 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8144974345962543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8144974345962543 | validation: 3.317879432517099]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.774236222049042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.774236222049042 | validation: 3.1448501175097805]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4580573940292596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4580573940292596 | validation: 2.943398149169134]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3111255983972017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3111255983972017 | validation: 2.718148981336644]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6589146056529733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6589146056529733 | validation: 1.8442035905185503]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.146104293510237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.146104293510237 | validation: 5.294773992197407]
	TIME [epoch: 8.38 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3961474502550986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3961474502550986 | validation: 1.3316585460384682]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4726781517574226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4726781517574226 | validation: 3.0334105180459936]
	TIME [epoch: 8.35 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.638531261921944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.638531261921944 | validation: 1.3460491912640395]
	TIME [epoch: 8.35 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.503299223002439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.503299223002439 | validation: 1.2530471082009693]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.333707769760374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.333707769760374 | validation: 1.181183468135882]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6932359578309124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6932359578309124 | validation: 1.5170054523205092]
	TIME [epoch: 8.36 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4441080274175744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4441080274175744 | validation: 1.3635638584225422]
	TIME [epoch: 8.36 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2811874215070955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2811874215070955 | validation: 0.9534447873554344]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1417492893012038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1417492893012038 | validation: 1.9587528273102683]
	TIME [epoch: 8.36 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1582033869093957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1582033869093957 | validation: 1.1763098058002384]
	TIME [epoch: 8.35 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.115252090500635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.115252090500635 | validation: 0.90579049702823]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0151136939979286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0151136939979286 | validation: 0.8116897137596084]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.151881870966108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.151881870966108 | validation: 1.4081829575295255]
	TIME [epoch: 8.35 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1520517230362444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1520517230362444 | validation: 1.0290102756307444]
	TIME [epoch: 8.35 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8154911316776556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8154911316776556 | validation: 1.0764690882047434]
	TIME [epoch: 8.35 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0043679816028397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0043679816028397 | validation: 0.8246267220859032]
	TIME [epoch: 8.37 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670335673846811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8670335673846811 | validation: 1.151221615880527]
	TIME [epoch: 8.35 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2608505741937917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2608505741937917 | validation: 0.7624606584327691]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0315293867299526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0315293867299526 | validation: 1.0731583304733687]
	TIME [epoch: 8.35 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9010403396188883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9010403396188883 | validation: 1.4205972502954822]
	TIME [epoch: 8.36 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9488289803747285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9488289803747285 | validation: 1.1708551311930222]
	TIME [epoch: 8.36 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9045637696321733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9045637696321733 | validation: 0.992454590251683]
	TIME [epoch: 8.35 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1398254045006897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1398254045006897 | validation: 0.8339352074568234]
	TIME [epoch: 8.35 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8133407210417044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8133407210417044 | validation: 0.7894055384446779]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7960804177869119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7960804177869119 | validation: 0.6606557915166622]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.030130655672466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.030130655672466 | validation: 0.6441185811471134]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8473432782533543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8473432782533543 | validation: 0.7318420286969702]
	TIME [epoch: 8.35 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0113794663718236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0113794663718236 | validation: 1.3824171604764108]
	TIME [epoch: 8.34 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9697698762004563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9697698762004563 | validation: 0.7642129591760535]
	TIME [epoch: 8.37 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8722645748290239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8722645748290239 | validation: 1.5441002405528295]
	TIME [epoch: 8.34 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9522072409598545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9522072409598545 | validation: 2.1075855030520603]
	TIME [epoch: 8.34 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1158360652464665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1158360652464665 | validation: 0.8168560768438732]
	TIME [epoch: 8.34 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8234384969934461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8234384969934461 | validation: 0.9957061205191899]
	TIME [epoch: 8.37 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9943831475778431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9943831475778431 | validation: 0.6479172017765968]
	TIME [epoch: 8.35 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9737946382358096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9737946382358096 | validation: 0.7732875670816858]
	TIME [epoch: 8.34 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8906037310621603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8906037310621603 | validation: 0.6413359480196082]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9262762955689491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9262762955689491 | validation: 0.9537777442214661]
	TIME [epoch: 8.36 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.830828282528541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.830828282528541 | validation: 0.5031588029345305]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9175957356211228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9175957356211228 | validation: 1.3912011625170622]
	TIME [epoch: 8.35 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9271410013392074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9271410013392074 | validation: 0.5629007218121531]
	TIME [epoch: 8.34 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8826702248185512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8826702248185512 | validation: 0.758764690401106]
	TIME [epoch: 8.36 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8224302586140407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8224302586140407 | validation: 0.5126021345072674]
	TIME [epoch: 8.34 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7565151351652485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7565151351652485 | validation: 0.8511501250295836]
	TIME [epoch: 8.34 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8266703608847505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8266703608847505 | validation: 1.2491163099612135]
	TIME [epoch: 8.34 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8644961828263347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8644961828263347 | validation: 0.846028808719332]
	TIME [epoch: 8.36 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9035560235915522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9035560235915522 | validation: 0.5423460289777728]
	TIME [epoch: 8.35 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7414461797716012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7414461797716012 | validation: 1.7622977511778397]
	TIME [epoch: 8.34 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8547507648175439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8547507648175439 | validation: 1.0647442385592418]
	TIME [epoch: 8.35 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8172631678260898		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.8172631678260898 | validation: 1.0833475642374362]
	TIME [epoch: 8.36 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.831109123554372		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.831109123554372 | validation: 0.5631866854011238]
	TIME [epoch: 8.36 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8754463604681595		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 0.8754463604681595 | validation: 0.5887343070656268]
	TIME [epoch: 8.35 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7551958690990482		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.7551958690990482 | validation: 1.1794630968754294]
	TIME [epoch: 8.35 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.809930880330002		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.809930880330002 | validation: 0.6418889790512629]
	TIME [epoch: 8.35 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8156201014799143		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.8156201014799143 | validation: 0.952096276238442]
	TIME [epoch: 8.37 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0051826617485655		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 1.0051826617485655 | validation: 0.7201029099396878]
	TIME [epoch: 8.35 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7300985463366958		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.7300985463366958 | validation: 0.5055599705061783]
	TIME [epoch: 8.35 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7403017913373182		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.7403017913373182 | validation: 0.663970165600408]
	TIME [epoch: 8.35 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6782630661589485		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.6782630661589485 | validation: 0.6821588012511615]
	TIME [epoch: 8.36 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8692450942936523		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.8692450942936523 | validation: 0.8978675423337716]
	TIME [epoch: 8.35 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8848148143016413		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.8848148143016413 | validation: 0.9377919748796675]
	TIME [epoch: 8.35 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6620321515890819		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.6620321515890819 | validation: 0.5130429470350761]
	TIME [epoch: 8.35 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6727280674119841		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.6727280674119841 | validation: 0.6423041530469835]
	TIME [epoch: 8.37 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6851562369673311		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 0.6851562369673311 | validation: 0.3026547455056152]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9262944545782963		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.9262944545782963 | validation: 0.5472750799329139]
	TIME [epoch: 8.36 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6920883186178031		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.6920883186178031 | validation: 0.6161872026187114]
	TIME [epoch: 8.36 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6284927028934463		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.6284927028934463 | validation: 0.47841007903241195]
	TIME [epoch: 8.38 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6337890963771021		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.6337890963771021 | validation: 0.36213731938481974]
	TIME [epoch: 8.37 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6599466824570037		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.6599466824570037 | validation: 0.36806771014112305]
	TIME [epoch: 8.36 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.714904257159874		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.714904257159874 | validation: 1.120434920832723]
	TIME [epoch: 8.36 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8645458093743162		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.8645458093743162 | validation: 0.5005777120493614]
	TIME [epoch: 8.38 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6940051039927269		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.6940051039927269 | validation: 0.8999860933012052]
	TIME [epoch: 8.36 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6690114140065583		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.6690114140065583 | validation: 0.7807652430012845]
	TIME [epoch: 8.36 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7483953016396722		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.7483953016396722 | validation: 1.128046197537281]
	TIME [epoch: 8.36 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7408161927213648		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.7408161927213648 | validation: 0.6487837556661651]
	TIME [epoch: 8.37 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7818500081137626		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.7818500081137626 | validation: 0.8830391407120299]
	TIME [epoch: 8.37 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7998243035591743		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.7998243035591743 | validation: 0.6316205530705147]
	TIME [epoch: 8.36 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6932347164150093		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.6932347164150093 | validation: 0.754836419491498]
	TIME [epoch: 8.36 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.949606983483517		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.949606983483517 | validation: 0.568082989579376]
	TIME [epoch: 8.36 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7557854874713622		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.7557854874713622 | validation: 1.0450737817382039]
	TIME [epoch: 8.38 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8711941575915125		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.8711941575915125 | validation: 0.6569818814413964]
	TIME [epoch: 8.36 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6762592308087974		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.6762592308087974 | validation: 0.5709345301916859]
	TIME [epoch: 8.36 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6401464068412899		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.6401464068412899 | validation: 0.543456390474193]
	TIME [epoch: 8.36 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6870535874123418		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.6870535874123418 | validation: 0.9975916477770563]
	TIME [epoch: 8.38 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9036003419422765		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.9036003419422765 | validation: 0.8199830954966807]
	TIME [epoch: 8.36 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7551195718463528		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.7551195718463528 | validation: 1.3543760572731092]
	TIME [epoch: 8.35 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6817390629796913		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.6817390629796913 | validation: 0.48051082300766473]
	TIME [epoch: 8.36 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6543031577356946		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.6543031577356946 | validation: 0.8741155769914589]
	TIME [epoch: 8.38 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7050063189919001		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.7050063189919001 | validation: 0.9300273503788044]
	TIME [epoch: 8.36 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6401810837533288		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.6401810837533288 | validation: 0.6775077320023322]
	TIME [epoch: 8.36 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6253986198825082		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.6253986198825082 | validation: 0.9118751830101246]
	TIME [epoch: 8.36 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8153526825685861		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.8153526825685861 | validation: 0.5519014864572644]
	TIME [epoch: 8.38 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282231728927202		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.5282231728927202 | validation: 0.9795645538998707]
	TIME [epoch: 8.36 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8080801310148548		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.8080801310148548 | validation: 0.5867364027496318]
	TIME [epoch: 8.36 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513117064697324		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.5513117064697324 | validation: 0.7843985220755005]
	TIME [epoch: 8.36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5777755779276179		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.5777755779276179 | validation: 0.5583314433178721]
	TIME [epoch: 8.38 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6777316079755227		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.6777316079755227 | validation: 0.463974008572154]
	TIME [epoch: 8.36 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.743948557936102		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.743948557936102 | validation: 0.49594887610770166]
	TIME [epoch: 8.36 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7494436061882037		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.7494436061882037 | validation: 0.6395745737314635]
	TIME [epoch: 8.35 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5823159227031914		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.5823159227031914 | validation: 0.5764469533740378]
	TIME [epoch: 8.36 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7075118216071274		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.7075118216071274 | validation: 0.8441804953499923]
	TIME [epoch: 8.37 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5577194727452064		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.5577194727452064 | validation: 0.5116248249335597]
	TIME [epoch: 8.35 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7809086289124593		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.7809086289124593 | validation: 0.4142567311160147]
	TIME [epoch: 8.35 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6011917672601313		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.6011917672601313 | validation: 0.6643115696139095]
	TIME [epoch: 8.36 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6170828469083247		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.6170828469083247 | validation: 0.5171078448943982]
	TIME [epoch: 8.37 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6365684521320156		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.6365684521320156 | validation: 0.42698807288114615]
	TIME [epoch: 8.36 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5701659846089131		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.5701659846089131 | validation: 0.5480083660930731]
	TIME [epoch: 8.35 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49404471321210786		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.49404471321210786 | validation: 0.4127512247299145]
	TIME [epoch: 8.35 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.59888046436561		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.59888046436561 | validation: 0.4335333948990354]
	TIME [epoch: 8.38 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5425758970405521		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.5425758970405521 | validation: 0.46154005811526533]
	TIME [epoch: 8.36 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5809645979791972		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.5809645979791972 | validation: 0.7498194403457872]
	TIME [epoch: 8.35 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.504433936564886		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.504433936564886 | validation: 0.3751008669850873]
	TIME [epoch: 8.35 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5336361266574058		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.5336361266574058 | validation: 0.446322083017757]
	TIME [epoch: 8.37 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6355435145950702		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.6355435145950702 | validation: 0.6415835141339195]
	TIME [epoch: 8.36 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5226741316646563		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.5226741316646563 | validation: 0.6156879619284599]
	TIME [epoch: 8.35 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.293376497747769		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 1.293376497747769 | validation: 0.6682435746976931]
	TIME [epoch: 8.35 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7913463604827478		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.7913463604827478 | validation: 0.9621290646120538]
	TIME [epoch: 8.38 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.840904640251153		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.840904640251153 | validation: 0.4981024957571176]
	TIME [epoch: 8.35 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6226163341436353		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.6226163341436353 | validation: 0.4259433058722551]
	TIME [epoch: 8.35 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5457104030171447		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.5457104030171447 | validation: 0.7292116876936836]
	TIME [epoch: 8.35 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7836494602867095		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.7836494602867095 | validation: 0.22143510837621058]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4507970098340669		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.4507970098340669 | validation: 0.5727239237171375]
	TIME [epoch: 8.36 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5210304261270043		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.5210304261270043 | validation: 0.9057003183970529]
	TIME [epoch: 8.35 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5198917078368003		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.5198917078368003 | validation: 0.8071318294891697]
	TIME [epoch: 8.35 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8872806220283789		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.8872806220283789 | validation: 0.46355015371603336]
	TIME [epoch: 8.35 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6053233226009428		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.6053233226009428 | validation: 0.43434349033541464]
	TIME [epoch: 8.37 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.609474600953069		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.609474600953069 | validation: 0.9636936194771382]
	TIME [epoch: 8.35 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.626787056095704		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.626787056095704 | validation: 0.4823929809235127]
	TIME [epoch: 8.35 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6502773577678853		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.6502773577678853 | validation: 0.620732314452513]
	TIME [epoch: 8.35 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6654926877666598		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.6654926877666598 | validation: 1.4698084941225336]
	TIME [epoch: 8.37 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7849794079328427		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.7849794079328427 | validation: 0.6302618383264189]
	TIME [epoch: 8.35 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4868096685089574		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.4868096685089574 | validation: 0.32094908581297416]
	TIME [epoch: 8.35 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5459690023609489		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.5459690023609489 | validation: 1.2861231965658044]
	TIME [epoch: 8.35 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.601279769888124		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.601279769888124 | validation: 0.2732425240941219]
	TIME [epoch: 8.37 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6139660569073557		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.6139660569073557 | validation: 0.6826045223079188]
	TIME [epoch: 8.35 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6265968171887575		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.6265968171887575 | validation: 0.9936864571413937]
	TIME [epoch: 8.35 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6008354675824524		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.6008354675824524 | validation: 0.3810341176759515]
	TIME [epoch: 8.35 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5038869364305764		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.5038869364305764 | validation: 0.36041410311296124]
	TIME [epoch: 8.37 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.780218574559862		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.780218574559862 | validation: 0.6076576842473047]
	TIME [epoch: 8.35 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5828055981026715		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.5828055981026715 | validation: 1.199088987814192]
	TIME [epoch: 8.35 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7186570347055911		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.7186570347055911 | validation: 0.37149633122202297]
	TIME [epoch: 8.34 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5532071049270515		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.5532071049270515 | validation: 0.4212469838056887]
	TIME [epoch: 8.37 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49588624876071713		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.49588624876071713 | validation: 0.6606299801421935]
	TIME [epoch: 8.35 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6846573813233052		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.6846573813233052 | validation: 0.3413287378674549]
	TIME [epoch: 8.34 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46923216555622604		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.46923216555622604 | validation: 0.46018102835397856]
	TIME [epoch: 8.34 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6422418605573257		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.6422418605573257 | validation: 1.0873611978579099]
	TIME [epoch: 8.36 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5761224778613666		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.5761224778613666 | validation: 0.792035186898417]
	TIME [epoch: 8.35 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5567596610368019		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.5567596610368019 | validation: 0.4566783768043702]
	TIME [epoch: 8.35 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952107307946632		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.5952107307946632 | validation: 0.5660338521260113]
	TIME [epoch: 8.34 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5470967266563629		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.5470967266563629 | validation: 0.41963595377503293]
	TIME [epoch: 8.35 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4705655436413778		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.4705655436413778 | validation: 0.30234462568459397]
	TIME [epoch: 8.37 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4643427020565844		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.4643427020565844 | validation: 0.2330413988962578]
	TIME [epoch: 8.35 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5670982407990789		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.5670982407990789 | validation: 0.657762347371132]
	TIME [epoch: 8.35 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6007256300533224		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.6007256300533224 | validation: 0.49810178254920445]
	TIME [epoch: 8.35 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.486814704988646		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.486814704988646 | validation: 0.32907280012592904]
	TIME [epoch: 8.37 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5105732450608856		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.5105732450608856 | validation: 0.41500752496457805]
	TIME [epoch: 8.35 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6878826046286199		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.6878826046286199 | validation: 1.0016782797164392]
	TIME [epoch: 8.35 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5901704320266394		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.5901704320266394 | validation: 0.8410995091081634]
	TIME [epoch: 8.34 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48699693902594443		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.48699693902594443 | validation: 0.26849395193753234]
	TIME [epoch: 8.37 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5019760714900476		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.5019760714900476 | validation: 0.4472631568648559]
	TIME [epoch: 8.35 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4748618756160182		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.4748618756160182 | validation: 0.8234069485517619]
	TIME [epoch: 8.34 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4749709660490282		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.4749709660490282 | validation: 0.32305418375535805]
	TIME [epoch: 8.34 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5422265094902399		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.5422265094902399 | validation: 0.43114218972320983]
	TIME [epoch: 8.37 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5276971348175852		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.5276971348175852 | validation: 0.5802104311832406]
	TIME [epoch: 8.35 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5878676749541925		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.5878676749541925 | validation: 0.4118533378714234]
	TIME [epoch: 8.35 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5628798536253179		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.5628798536253179 | validation: 0.7473604434182095]
	TIME [epoch: 8.34 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.590186413956289		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.590186413956289 | validation: 0.6744094132476737]
	TIME [epoch: 8.36 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4579245940385509		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.4579245940385509 | validation: 0.3502484319206032]
	TIME [epoch: 8.35 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5319974753057163		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.5319974753057163 | validation: 0.7414298705177516]
	TIME [epoch: 8.34 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.602729574753437		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.602729574753437 | validation: 0.4529860448982397]
	TIME [epoch: 8.34 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5348400731502935		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.5348400731502935 | validation: 0.8471654009967791]
	TIME [epoch: 8.36 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.520419581728951		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.520419581728951 | validation: 0.3865706522163413]
	TIME [epoch: 8.36 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.593107918435704		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.593107918435704 | validation: 0.5598485261367661]
	TIME [epoch: 8.35 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7429213124472486		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.7429213124472486 | validation: 0.4786356077323195]
	TIME [epoch: 8.35 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6200409154049553		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.6200409154049553 | validation: 0.3798505917680926]
	TIME [epoch: 8.35 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4639497678508261		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.4639497678508261 | validation: 0.6030509984200532]
	TIME [epoch: 8.37 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.761251483726541		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.761251483726541 | validation: 0.639483072330201]
	TIME [epoch: 8.34 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5316770300438878		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.5316770300438878 | validation: 0.5728179533113835]
	TIME [epoch: 8.35 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5226526846342179		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.5226526846342179 | validation: 0.24297950320981204]
	TIME [epoch: 8.34 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4090587940234364		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.4090587940234364 | validation: 0.5443392442250501]
	TIME [epoch: 8.36 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6035269038645035		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.6035269038645035 | validation: 0.5710501004704108]
	TIME [epoch: 8.35 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4863405321310026		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.4863405321310026 | validation: 0.5550416346150712]
	TIME [epoch: 8.35 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.539059238489283		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.539059238489283 | validation: 0.6583010209905886]
	TIME [epoch: 8.35 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47034164341519347		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.47034164341519347 | validation: 0.42152313485108284]
	TIME [epoch: 8.36 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5112023034811135		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.5112023034811135 | validation: 1.1410741927143855]
	TIME [epoch: 8.35 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5852883920467338		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.5852883920467338 | validation: 0.8653536111859106]
	TIME [epoch: 8.35 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6122606267668133		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.6122606267668133 | validation: 0.44240548808316693]
	TIME [epoch: 8.35 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4802696430761789		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.4802696430761789 | validation: 0.3960763314662325]
	TIME [epoch: 8.37 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433436439083642		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.433436439083642 | validation: 0.3750205064735138]
	TIME [epoch: 8.35 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45592637856998025		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.45592637856998025 | validation: 0.7011448393115163]
	TIME [epoch: 8.35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43710719263554215		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.43710719263554215 | validation: 0.21566354102496255]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5772300819902958		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.5772300819902958 | validation: 0.5314441024993442]
	TIME [epoch: 8.37 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4829191642124934		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.4829191642124934 | validation: 0.4612916714594103]
	TIME [epoch: 8.35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4816199491160115		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.4816199491160115 | validation: 1.0191818945241942]
	TIME [epoch: 8.34 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5431679681493637		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.5431679681493637 | validation: 0.7573188570153788]
	TIME [epoch: 8.34 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4914634729003911		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.4914634729003911 | validation: 0.7472353512610156]
	TIME [epoch: 8.35 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4540302369147855		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.4540302369147855 | validation: 0.28975782806114975]
	TIME [epoch: 8.37 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42296527992834304		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.42296527992834304 | validation: 0.6050568855104445]
	TIME [epoch: 8.34 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49832532019804		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.49832532019804 | validation: 0.44083282460713386]
	TIME [epoch: 8.34 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5749316135247587		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.5749316135247587 | validation: 0.4884687652948192]
	TIME [epoch: 8.35 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4146805188293496		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.4146805188293496 | validation: 0.5910968556466132]
	TIME [epoch: 8.37 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567423939427789		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.4567423939427789 | validation: 0.434175136763908]
	TIME [epoch: 8.35 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5425766914040684		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.5425766914040684 | validation: 0.32393779023693814]
	TIME [epoch: 8.35 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5159801048227688		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.5159801048227688 | validation: 0.43405487140531906]
	TIME [epoch: 8.35 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4398665002045788		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.4398665002045788 | validation: 0.584133606918716]
	TIME [epoch: 8.37 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.512930680935342		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.512930680935342 | validation: 0.2925891343162805]
	TIME [epoch: 8.35 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4185506489292923		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.4185506489292923 | validation: 0.35484134704775006]
	TIME [epoch: 8.35 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.757087140854992		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.757087140854992 | validation: 0.5569890689676402]
	TIME [epoch: 8.35 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4760586959103521		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.4760586959103521 | validation: 0.4194147730843297]
	TIME [epoch: 8.37 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3839277194476447		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.3839277194476447 | validation: 0.5731943832465622]
	TIME [epoch: 8.35 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42421300000412066		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.42421300000412066 | validation: 0.5559216971308187]
	TIME [epoch: 8.35 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4201864120570365		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.4201864120570365 | validation: 0.27763416319682555]
	TIME [epoch: 8.35 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4451059058029553		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.4451059058029553 | validation: 0.31221331420974896]
	TIME [epoch: 8.37 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47475206120631563		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.47475206120631563 | validation: 0.28007498820764487]
	TIME [epoch: 8.35 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45763766765380576		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.45763766765380576 | validation: 0.33644977832323575]
	TIME [epoch: 8.35 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45857329924379525		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.45857329924379525 | validation: 0.6619969820551166]
	TIME [epoch: 8.35 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6506386641424263		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.6506386641424263 | validation: 0.42815861676887956]
	TIME [epoch: 8.36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41579492049413425		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.41579492049413425 | validation: 0.260101657643651]
	TIME [epoch: 8.36 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3673555283238639		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.3673555283238639 | validation: 0.21750708836089874]
	TIME [epoch: 8.35 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5240421793379675		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.5240421793379675 | validation: 0.5030816086348019]
	TIME [epoch: 8.35 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47440727709116537		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.47440727709116537 | validation: 0.36822018628174036]
	TIME [epoch: 8.35 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39037356884590935		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.39037356884590935 | validation: 0.2470096113401425]
	TIME [epoch: 8.37 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4403218930062945		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.4403218930062945 | validation: 0.5517148049479422]
	TIME [epoch: 8.35 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42337867152611386		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.42337867152611386 | validation: 0.6198710236067664]
	TIME [epoch: 8.35 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44225517859981955		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.44225517859981955 | validation: 0.23341980220748368]
	TIME [epoch: 8.35 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3837835985236005		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.3837835985236005 | validation: 0.17728046869438888]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43619607156652346		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.43619607156652346 | validation: 0.25830757722276887]
	TIME [epoch: 8.35 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4018148980458167		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.4018148980458167 | validation: 0.36168450935754526]
	TIME [epoch: 8.35 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4229853937294454		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.4229853937294454 | validation: 0.3541101936087622]
	TIME [epoch: 8.35 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5387697289013849		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.5387697289013849 | validation: 0.8252978616240465]
	TIME [epoch: 8.37 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48945117547849615		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.48945117547849615 | validation: 0.8495644085764248]
	TIME [epoch: 8.35 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43817253499880876		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.43817253499880876 | validation: 0.20740084620597077]
	TIME [epoch: 8.35 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39194572309073505		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.39194572309073505 | validation: 0.2515708226726677]
	TIME [epoch: 8.35 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3409394093844034		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.3409394093844034 | validation: 0.2517675802690524]
	TIME [epoch: 8.37 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33465660642692224		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.33465660642692224 | validation: 0.2240644326128167]
	TIME [epoch: 8.35 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3978082183150774		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.3978082183150774 | validation: 0.5935320718859343]
	TIME [epoch: 8.35 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49880969337412157		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.49880969337412157 | validation: 0.5102438438843818]
	TIME [epoch: 8.35 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35898443682289055		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.35898443682289055 | validation: 0.31083377796719974]
	TIME [epoch: 8.37 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3711538517127934		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.3711538517127934 | validation: 0.8367505402372388]
	TIME [epoch: 8.36 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6472376281429381		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.6472376281429381 | validation: 0.28536433846294657]
	TIME [epoch: 8.35 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3887233043330232		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.3887233043330232 | validation: 0.8402582329946765]
	TIME [epoch: 8.35 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4420845602798396		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.4420845602798396 | validation: 0.7012704299081143]
	TIME [epoch: 8.36 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6289679947394292		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.6289679947394292 | validation: 0.5825967167761228]
	TIME [epoch: 8.36 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4666542566716984		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.4666542566716984 | validation: 0.5596935746454322]
	TIME [epoch: 8.35 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47543148553109293		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.47543148553109293 | validation: 0.7181258009361725]
	TIME [epoch: 8.36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46084390093845135		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.46084390093845135 | validation: 0.2459387750280272]
	TIME [epoch: 8.35 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4091625565700954		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.4091625565700954 | validation: 0.3872193989352388]
	TIME [epoch: 8.37 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3267552143981426		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.3267552143981426 | validation: 0.17258540280033657]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.365537342430252		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.365537342430252 | validation: 0.38722727510795185]
	TIME [epoch: 8.34 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3574554382576139		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.3574554382576139 | validation: 0.8155997687278878]
	TIME [epoch: 8.34 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44551415470775657		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.44551415470775657 | validation: 0.324840456017236]
	TIME [epoch: 8.36 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5297043892894224		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.5297043892894224 | validation: 0.28000955088469665]
	TIME [epoch: 8.34 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3931844739337833		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.3931844739337833 | validation: 0.30112463113064075]
	TIME [epoch: 8.34 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132531806169239		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.3132531806169239 | validation: 0.4852762805139672]
	TIME [epoch: 8.34 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3588120036946298		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.3588120036946298 | validation: 0.22540838251311385]
	TIME [epoch: 8.36 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45566220442142535		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.45566220442142535 | validation: 0.5150866713440391]
	TIME [epoch: 8.34 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45099647520956043		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.45099647520956043 | validation: 0.43294152975175415]
	TIME [epoch: 8.34 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45542661403081225		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.45542661403081225 | validation: 0.62289750536847]
	TIME [epoch: 8.34 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44496315618621607		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.44496315618621607 | validation: 0.2260017087801602]
	TIME [epoch: 8.36 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3198763630703522		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.3198763630703522 | validation: 0.3037913446804966]
	TIME [epoch: 8.34 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3783700811075001		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.3783700811075001 | validation: 0.18313304340382508]
	TIME [epoch: 8.34 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30639060699248805		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.30639060699248805 | validation: 0.25685247085907603]
	TIME [epoch: 8.34 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4843385981041923		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.4843385981041923 | validation: 0.2688659071547168]
	TIME [epoch: 8.36 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43342459942965245		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.43342459942965245 | validation: 0.4816628880855285]
	TIME [epoch: 8.35 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42270238911598457		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.42270238911598457 | validation: 0.3123490230590954]
	TIME [epoch: 8.34 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38877525203853364		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.38877525203853364 | validation: 0.40356366194452664]
	TIME [epoch: 8.34 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4854976655389037		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.4854976655389037 | validation: 0.1848842393989859]
	TIME [epoch: 8.35 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3110045208448217		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.3110045208448217 | validation: 0.28469767560544984]
	TIME [epoch: 8.35 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29651986122148377		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.29651986122148377 | validation: 0.46327460730876097]
	TIME [epoch: 8.34 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4490717052269746		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.4490717052269746 | validation: 0.5408569207133826]
	TIME [epoch: 8.34 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3991028723103967		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.3991028723103967 | validation: 0.35463623833773883]
	TIME [epoch: 8.34 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42499519512784695		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.42499519512784695 | validation: 0.6064940923493618]
	TIME [epoch: 8.36 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3797534700847017		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.3797534700847017 | validation: 0.37653975922054156]
	TIME [epoch: 8.34 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2953890601486684		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.2953890601486684 | validation: 0.4220894789813986]
	TIME [epoch: 8.34 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3408779545718833		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.3408779545718833 | validation: 0.4331078078778846]
	TIME [epoch: 8.34 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46945940032990024		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.46945940032990024 | validation: 0.33997506085465856]
	TIME [epoch: 8.36 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3714544824924909		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.3714544824924909 | validation: 0.30171805672705065]
	TIME [epoch: 8.35 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684602744608091		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.3684602744608091 | validation: 0.2669018590249393]
	TIME [epoch: 8.35 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.328688905905426		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.328688905905426 | validation: 0.2582638347521542]
	TIME [epoch: 8.34 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3269328690355688		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.3269328690355688 | validation: 0.26205399985606087]
	TIME [epoch: 8.36 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3092074343671406		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.3092074343671406 | validation: 0.2576590339528673]
	TIME [epoch: 8.35 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38911031631933296		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.38911031631933296 | validation: 0.37630535293433426]
	TIME [epoch: 8.34 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34441765650016337		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.34441765650016337 | validation: 0.6685315747259417]
	TIME [epoch: 8.35 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30445345626413023		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.30445345626413023 | validation: 0.39065515593242905]
	TIME [epoch: 8.36 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2688184631778153		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.2688184631778153 | validation: 0.23607132764758398]
	TIME [epoch: 8.35 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34794554559358387		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.34794554559358387 | validation: 0.36312202392971715]
	TIME [epoch: 8.35 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36300370137766685		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.36300370137766685 | validation: 0.7942330150182166]
	TIME [epoch: 8.35 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3518485045641893		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.3518485045641893 | validation: 0.20971954861644654]
	TIME [epoch: 8.37 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32865742721333424		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.32865742721333424 | validation: 0.30601006470813213]
	TIME [epoch: 8.35 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36246132008233994		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.36246132008233994 | validation: 0.4296480291751118]
	TIME [epoch: 8.35 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3237390011216813		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.3237390011216813 | validation: 0.19379959305945352]
	TIME [epoch: 8.35 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2655115271028216		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.2655115271028216 | validation: 0.5265333646287085]
	TIME [epoch: 8.34 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4570978541300076		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.4570978541300076 | validation: 0.3732184519159647]
	TIME [epoch: 8.37 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35296663784597576		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.35296663784597576 | validation: 0.32561640511120105]
	TIME [epoch: 8.35 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28213709860230324		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.28213709860230324 | validation: 0.22581679204132138]
	TIME [epoch: 8.34 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3455480877445706		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.3455480877445706 | validation: 0.604976976572185]
	TIME [epoch: 8.34 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3847177188971542		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.3847177188971542 | validation: 0.5882691151449833]
	TIME [epoch: 8.37 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39262976713380165		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.39262976713380165 | validation: 0.2226837478367421]
	TIME [epoch: 8.35 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3502170538125031		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.3502170538125031 | validation: 0.38334998451313473]
	TIME [epoch: 8.34 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45450112360828676		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.45450112360828676 | validation: 0.9203420223470551]
	TIME [epoch: 8.34 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45000495872212243		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.45000495872212243 | validation: 0.8458257513551275]
	TIME [epoch: 8.36 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39736548484588397		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.39736548484588397 | validation: 0.37655803545567723]
	TIME [epoch: 8.35 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31059085852025553		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.31059085852025553 | validation: 0.3664057349982951]
	TIME [epoch: 8.34 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172521877160828		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.3172521877160828 | validation: 0.5139721952337963]
	TIME [epoch: 8.35 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46911045237646665		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.46911045237646665 | validation: 0.3762289161496964]
	TIME [epoch: 8.37 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32883149470381967		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.32883149470381967 | validation: 0.5364785375556491]
	TIME [epoch: 8.35 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34510681113352426		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.34510681113352426 | validation: 0.4635109425748045]
	TIME [epoch: 8.34 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3463710032238369		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.3463710032238369 | validation: 0.26960797427197597]
	TIME [epoch: 8.34 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144431114691206		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.3144431114691206 | validation: 0.28251062347497513]
	TIME [epoch: 8.37 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25417948680410973		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.25417948680410973 | validation: 0.19632139426700063]
	TIME [epoch: 8.36 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42638624164356964		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.42638624164356964 | validation: 0.3595591769858281]
	TIME [epoch: 8.35 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36536720018577706		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.36536720018577706 | validation: 0.5744826449524689]
	TIME [epoch: 8.35 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302807765540275		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.302807765540275 | validation: 0.20367100632598967]
	TIME [epoch: 8.37 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28873837826661275		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.28873837826661275 | validation: 0.19968872948091396]
	TIME [epoch: 8.37 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2716380865583379		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.2716380865583379 | validation: 0.3808016845067137]
	TIME [epoch: 8.36 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39891815213094406		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.39891815213094406 | validation: 0.23227908166220257]
	TIME [epoch: 8.35 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3153740779417981		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.3153740779417981 | validation: 0.2009679503353908]
	TIME [epoch: 8.36 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35278246797005275		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.35278246797005275 | validation: 0.3843596414174]
	TIME [epoch: 8.38 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984225724473026		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.2984225724473026 | validation: 0.33010770246719146]
	TIME [epoch: 8.36 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193239026738046		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.3193239026738046 | validation: 0.19399928479083622]
	TIME [epoch: 8.36 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348263756562205		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.2348263756562205 | validation: 0.20211055486884033]
	TIME [epoch: 8.36 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34522006308235487		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.34522006308235487 | validation: 0.3781809832739875]
	TIME [epoch: 8.37 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3543412635042745		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.3543412635042745 | validation: 0.26015314233209885]
	TIME [epoch: 8.35 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3391974093670863		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.3391974093670863 | validation: 0.2273616186739803]
	TIME [epoch: 8.37 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2660952226702876		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.2660952226702876 | validation: 0.6478027026559728]
	TIME [epoch: 8.37 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5128227725985256		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.5128227725985256 | validation: 0.7949003358340756]
	TIME [epoch: 8.38 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3751548371002416		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.3751548371002416 | validation: 0.3828766074859252]
	TIME [epoch: 8.36 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3495793932673881		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.3495793932673881 | validation: 0.17868679574122193]
	TIME [epoch: 8.35 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.293244885163768		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.293244885163768 | validation: 0.14987511734690614]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30577520599428476		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.30577520599428476 | validation: 0.4626146962037455]
	TIME [epoch: 8.39 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3199550366217186		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.3199550366217186 | validation: 0.9368395846598123]
	TIME [epoch: 8.35 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32191391592151514		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.32191391592151514 | validation: 0.14976274188116434]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46290098817291553		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.46290098817291553 | validation: 0.4780322380136005]
	TIME [epoch: 8.34 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3608031051615753		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.3608031051615753 | validation: 0.4038332574590245]
	TIME [epoch: 8.36 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995575138314613		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.2995575138314613 | validation: 0.28731481175752205]
	TIME [epoch: 8.34 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3205203937914237		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.3205203937914237 | validation: 0.24593360599809916]
	TIME [epoch: 8.34 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725095355616268		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.2725095355616268 | validation: 0.3816498489163145]
	TIME [epoch: 8.33 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29375558562860615		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.29375558562860615 | validation: 0.1778113264032921]
	TIME [epoch: 8.36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3562809652114221		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.3562809652114221 | validation: 0.205598619051198]
	TIME [epoch: 8.34 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23213266453936074		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.23213266453936074 | validation: 0.5013890766166359]
	TIME [epoch: 8.34 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42539829315079086		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.42539829315079086 | validation: 0.34973726539043604]
	TIME [epoch: 8.34 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144214160531509		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.3144214160531509 | validation: 0.3169300212670049]
	TIME [epoch: 8.34 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942481364874985		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2942481364874985 | validation: 0.17060528012286763]
	TIME [epoch: 8.36 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513779008647351		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.2513779008647351 | validation: 0.21505158763739257]
	TIME [epoch: 8.33 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959176885836754		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.2959176885836754 | validation: 0.14372930144149]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37239890928037866		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.37239890928037866 | validation: 0.5458379804931393]
	TIME [epoch: 8.35 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30749363568180305		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.30749363568180305 | validation: 0.4219311451479463]
	TIME [epoch: 8.37 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3372243689341436		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.3372243689341436 | validation: 0.6748674253017404]
	TIME [epoch: 8.34 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4009191650795033		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.4009191650795033 | validation: 0.2905347614693863]
	TIME [epoch: 8.34 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37592586578077114		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.37592586578077114 | validation: 0.306646329609944]
	TIME [epoch: 8.34 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26344650870958086		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.26344650870958086 | validation: 0.21512505194542142]
	TIME [epoch: 8.36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2764190096271224		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.2764190096271224 | validation: 0.3322114516869795]
	TIME [epoch: 8.35 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30356994313446845		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.30356994313446845 | validation: 0.2501280443694016]
	TIME [epoch: 8.34 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970938043360561		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.2970938043360561 | validation: 0.1662973853201508]
	TIME [epoch: 8.34 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24992382939316257		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.24992382939316257 | validation: 0.2959761781959515]
	TIME [epoch: 8.36 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31966545813473457		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.31966545813473457 | validation: 0.43473660940098857]
	TIME [epoch: 8.35 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23903046273596393		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.23903046273596393 | validation: 0.2111359065603109]
	TIME [epoch: 8.35 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27051575004592227		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.27051575004592227 | validation: 0.24245286373232267]
	TIME [epoch: 8.34 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37863406705705077		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.37863406705705077 | validation: 0.4317371296674555]
	TIME [epoch: 8.37 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31348227595681266		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.31348227595681266 | validation: 0.2944781855940588]
	TIME [epoch: 8.35 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044797299425322		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.3044797299425322 | validation: 0.26400812945515534]
	TIME [epoch: 8.34 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2503278120213329		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.2503278120213329 | validation: 0.34247497612533095]
	TIME [epoch: 8.34 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3491296078140075		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.3491296078140075 | validation: 0.27001748843137396]
	TIME [epoch: 8.36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22879746133366802		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.22879746133366802 | validation: 0.15262989551375644]
	TIME [epoch: 8.35 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2237582236680574		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.2237582236680574 | validation: 0.3595530714262926]
	TIME [epoch: 8.35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2815850230435171		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.2815850230435171 | validation: 0.1541393190370227]
	TIME [epoch: 8.34 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929813159783866		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.2929813159783866 | validation: 0.20648834503552496]
	TIME [epoch: 8.34 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2553121677023722		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.2553121677023722 | validation: 0.2680336704910014]
	TIME [epoch: 8.36 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24857817435318158		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.24857817435318158 | validation: 0.29757869651379376]
	TIME [epoch: 8.34 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25211794471317545		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.25211794471317545 | validation: 0.2843434678429948]
	TIME [epoch: 8.34 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.282373254326999		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.282373254326999 | validation: 0.49399156879981587]
	TIME [epoch: 8.34 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32348604967174416		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.32348604967174416 | validation: 0.2145860250626655]
	TIME [epoch: 8.36 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27128792596355955		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.27128792596355955 | validation: 0.6923755525524495]
	TIME [epoch: 8.34 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24745703477078362		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.24745703477078362 | validation: 0.21088261389109797]
	TIME [epoch: 8.34 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24803397306142352		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.24803397306142352 | validation: 0.15275558101443368]
	TIME [epoch: 8.34 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2674375923024456		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.2674375923024456 | validation: 0.37739603283832446]
	TIME [epoch: 8.37 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25537952919185275		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.25537952919185275 | validation: 0.2559929575760866]
	TIME [epoch: 8.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22147565146584275		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.22147565146584275 | validation: 0.28203928775422277]
	TIME [epoch: 8.34 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21866993480265656		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.21866993480265656 | validation: 0.2714386956785412]
	TIME [epoch: 8.34 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25407479548265355		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.25407479548265355 | validation: 0.1740741812307739]
	TIME [epoch: 8.36 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17890416873096243		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.17890416873096243 | validation: 0.2503620774168147]
	TIME [epoch: 8.34 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22503728231937137		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.22503728231937137 | validation: 0.20705528805824958]
	TIME [epoch: 8.34 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.366429609482292		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.366429609482292 | validation: 0.2776081466460625]
	TIME [epoch: 8.34 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3001591894249718		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.3001591894249718 | validation: 0.11209669508801046]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2302205597617007		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.2302205597617007 | validation: 0.3173487645319457]
	TIME [epoch: 8.36 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29893223767385696		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.29893223767385696 | validation: 0.20454319294580772]
	TIME [epoch: 8.35 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2265033106981876		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.2265033106981876 | validation: 0.2810780877087996]
	TIME [epoch: 8.35 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23718794881455904		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.23718794881455904 | validation: 0.2669197781475119]
	TIME [epoch: 8.37 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25624870970998964		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.25624870970998964 | validation: 0.28392020957392433]
	TIME [epoch: 8.36 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500138663272263		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.3500138663272263 | validation: 0.4082922028456092]
	TIME [epoch: 8.35 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26390187781655794		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.26390187781655794 | validation: 0.2735165966033715]
	TIME [epoch: 8.35 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27167750581176053		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.27167750581176053 | validation: 0.4892397036684102]
	TIME [epoch: 8.36 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28743239949432053		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.28743239949432053 | validation: 0.2648891572196125]
	TIME [epoch: 8.38 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2749862631034897		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.2749862631034897 | validation: 0.16060281292807332]
	TIME [epoch: 8.35 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22289429729143562		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.22289429729143562 | validation: 0.1523540090728881]
	TIME [epoch: 8.35 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456026348816147		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.2456026348816147 | validation: 0.11303849974160557]
	TIME [epoch: 8.36 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22090487381168594		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.22090487381168594 | validation: 0.33205893871695713]
	TIME [epoch: 8.37 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29794357864666543		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.29794357864666543 | validation: 0.44536277628233817]
	TIME [epoch: 8.35 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3111860443660656		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.3111860443660656 | validation: 0.24929631652704204]
	TIME [epoch: 8.35 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20938972231699976		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.20938972231699976 | validation: 0.253410689146835]
	TIME [epoch: 8.34 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2183053972082837		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.2183053972082837 | validation: 0.12962585162147283]
	TIME [epoch: 8.37 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2868275070920451		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.2868275070920451 | validation: 0.2392607441025184]
	TIME [epoch: 8.36 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21582113616723028		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.21582113616723028 | validation: 0.21270278849536428]
	TIME [epoch: 8.35 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31919245609501135		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.31919245609501135 | validation: 0.27663403711356316]
	TIME [epoch: 8.35 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4343974274475573		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.4343974274475573 | validation: 0.14973639993266832]
	TIME [epoch: 8.37 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.169686846819063		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.169686846819063 | validation: 0.14180114431865953]
	TIME [epoch: 8.35 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3432830597201251		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.3432830597201251 | validation: 0.32522531334559024]
	TIME [epoch: 8.35 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2791370637711752		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.2791370637711752 | validation: 0.2588129919604615]
	TIME [epoch: 8.35 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31694640495599746		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.31694640495599746 | validation: 0.32029649792083903]
	TIME [epoch: 8.37 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2592986612781843		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.2592986612781843 | validation: 0.47497109117495545]
	TIME [epoch: 8.35 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25537458771042576		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.25537458771042576 | validation: 0.25475388804727683]
	TIME [epoch: 8.35 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21919064622690682		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.21919064622690682 | validation: 0.1755363989816193]
	TIME [epoch: 8.35 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2578413327011798		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.2578413327011798 | validation: 0.2204139642550994]
	TIME [epoch: 8.37 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1873732996022545		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.1873732996022545 | validation: 0.2145106041095167]
	TIME [epoch: 8.36 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2575534270030747		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.2575534270030747 | validation: 0.14466116833990972]
	TIME [epoch: 8.35 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2284121088184242		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.2284121088184242 | validation: 0.3604604559414329]
	TIME [epoch: 8.35 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2732784401277088		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.2732784401277088 | validation: 0.14314120285523751]
	TIME [epoch: 8.35 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069720354605918		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.3069720354605918 | validation: 0.15697761453272951]
	TIME [epoch: 8.37 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2787762181826924		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.2787762181826924 | validation: 0.33521573465601545]
	TIME [epoch: 8.35 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3544837454345255		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.3544837454345255 | validation: 0.2291119379455832]
	TIME [epoch: 8.35 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24806775003845657		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.24806775003845657 | validation: 0.24726163630059006]
	TIME [epoch: 8.35 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24504824309756906		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.24504824309756906 | validation: 0.3517708857986394]
	TIME [epoch: 8.38 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2368105295233968		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.2368105295233968 | validation: 0.18802651644894344]
	TIME [epoch: 8.36 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19464842252950704		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.19464842252950704 | validation: 0.2463627215373258]
	TIME [epoch: 8.35 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25331274125535075		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.25331274125535075 | validation: 0.20037861553330683]
	TIME [epoch: 8.35 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22849147148330537		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.22849147148330537 | validation: 0.15586225926568104]
	TIME [epoch: 8.37 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23985683149785636		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.23985683149785636 | validation: 0.19521391162830332]
	TIME [epoch: 8.35 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26740867529591983		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.26740867529591983 | validation: 0.3320714826651173]
	TIME [epoch: 8.35 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22720523150557326		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.22720523150557326 | validation: 0.1816955014955191]
	TIME [epoch: 8.35 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22406395669940243		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.22406395669940243 | validation: 0.34680823298808106]
	TIME [epoch: 8.37 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2577602042752144		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.2577602042752144 | validation: 0.19793665859392295]
	TIME [epoch: 8.35 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29660871973125214		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.29660871973125214 | validation: 0.3838176522102952]
	TIME [epoch: 8.35 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389710723396198		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.2389710723396198 | validation: 0.15278298343067317]
	TIME [epoch: 8.35 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21362124179717337		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.21362124179717337 | validation: 0.14966222692065745]
	TIME [epoch: 8.37 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17983403706020598		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.17983403706020598 | validation: 0.128547030647166]
	TIME [epoch: 8.36 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20841786098500886		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.20841786098500886 | validation: 0.269980569192596]
	TIME [epoch: 8.35 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2494165264196117		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.2494165264196117 | validation: 0.24188899151037987]
	TIME [epoch: 8.35 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19389635816403566		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.19389635816403566 | validation: 0.18116952531984323]
	TIME [epoch: 8.36 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19543821878443837		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.19543821878443837 | validation: 0.12603728208937084]
	TIME [epoch: 8.37 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19233566652707001		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.19233566652707001 | validation: 0.24025447528207883]
	TIME [epoch: 8.36 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24521458182488637		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.24521458182488637 | validation: 0.2835776578803537]
	TIME [epoch: 8.35 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769808326286546		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.2769808326286546 | validation: 0.3645202928470001]
	TIME [epoch: 8.36 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19604116540161606		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.19604116540161606 | validation: 0.19671600219794672]
	TIME [epoch: 8.38 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19246345106237028		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.19246345106237028 | validation: 0.2464309647060523]
	TIME [epoch: 8.35 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2321213212139924		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.2321213212139924 | validation: 0.2371379543014363]
	TIME [epoch: 8.35 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19535984787951777		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.19535984787951777 | validation: 0.09638941527684212]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17856778923246872		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.17856778923246872 | validation: 0.3209986905203317]
	TIME [epoch: 8.37 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.237889764780912		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.237889764780912 | validation: 0.11974967497415695]
	TIME [epoch: 8.36 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22645782617098753		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.22645782617098753 | validation: 0.40865419543441406]
	TIME [epoch: 8.35 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19997599919847348		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.19997599919847348 | validation: 0.2809391359903302]
	TIME [epoch: 8.36 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20412706526618538		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.20412706526618538 | validation: 0.18923477081699114]
	TIME [epoch: 8.37 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1451520178712216		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.1451520178712216 | validation: 0.2369043584896522]
	TIME [epoch: 8.36 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22125873813746727		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.22125873813746727 | validation: 0.23486652574847156]
	TIME [epoch: 8.35 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16722344296611788		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.16722344296611788 | validation: 0.38756535621267385]
	TIME [epoch: 8.35 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19425948332218287		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.19425948332218287 | validation: 0.3577609284970581]
	TIME [epoch: 8.38 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661400309340626		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.2661400309340626 | validation: 0.2602777203701965]
	TIME [epoch: 8.35 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2438123513618326		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.2438123513618326 | validation: 0.20404718843183878]
	TIME [epoch: 8.36 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18721491242991375		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.18721491242991375 | validation: 0.169192326319339]
	TIME [epoch: 8.35 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20050919336936693		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.20050919336936693 | validation: 0.18138495040021904]
	TIME [epoch: 8.37 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269139379840792		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.269139379840792 | validation: 0.17028154353899244]
	TIME [epoch: 8.36 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24597855952595582		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.24597855952595582 | validation: 0.21862472796103993]
	TIME [epoch: 8.35 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24896783124334462		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.24896783124334462 | validation: 0.27380195931219786]
	TIME [epoch: 8.35 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1932485131564094		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.1932485131564094 | validation: 0.23276673911352852]
	TIME [epoch: 8.36 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23443478437127432		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.23443478437127432 | validation: 0.16504805000234554]
	TIME [epoch: 8.36 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18317723199720487		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.18317723199720487 | validation: 0.19897191697470407]
	TIME [epoch: 8.35 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295615109481292		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.2295615109481292 | validation: 0.36331299852686705]
	TIME [epoch: 8.35 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18987583227835533		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.18987583227835533 | validation: 0.45837726612068774]
	TIME [epoch: 8.35 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33715873227910154		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.33715873227910154 | validation: 0.34537956724222346]
	TIME [epoch: 8.38 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627462761175627		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.2627462761175627 | validation: 0.28514403238774044]
	TIME [epoch: 8.35 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22416294190623298		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.22416294190623298 | validation: 0.15958775705471656]
	TIME [epoch: 8.35 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22230817511232584		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.22230817511232584 | validation: 0.18860900202731076]
	TIME [epoch: 8.35 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921068131956361		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.1921068131956361 | validation: 0.3482514621439966]
	TIME [epoch: 8.37 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530337442493888		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.2530337442493888 | validation: 0.6496355894897479]
	TIME [epoch: 8.35 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21419901829981863		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.21419901829981863 | validation: 0.335805423177922]
	TIME [epoch: 8.35 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24522740019067246		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.24522740019067246 | validation: 0.25083713521787593]
	TIME [epoch: 8.35 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22931854733165916		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.22931854733165916 | validation: 0.12308824081604859]
	TIME [epoch: 8.37 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18512436845629623		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.18512436845629623 | validation: 0.24497648328253213]
	TIME [epoch: 8.35 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518496541156659		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.2518496541156659 | validation: 0.4140106739491992]
	TIME [epoch: 8.35 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22812748485491116		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.22812748485491116 | validation: 0.14604272863980738]
	TIME [epoch: 8.35 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21051836824516137		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.21051836824516137 | validation: 0.19942574734975588]
	TIME [epoch: 8.37 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24655215075357956		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.24655215075357956 | validation: 0.11791611273462517]
	TIME [epoch: 8.35 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21787071918576437		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.21787071918576437 | validation: 0.12514935390743848]
	TIME [epoch: 8.35 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1758902247255325		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.1758902247255325 | validation: 0.19338345864703532]
	TIME [epoch: 8.35 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16638849347695145		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.16638849347695145 | validation: 0.22800082123231824]
	TIME [epoch: 8.37 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21705938271862818		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.21705938271862818 | validation: 0.17956342742954867]
	TIME [epoch: 8.35 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21881605933451312		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.21881605933451312 | validation: 0.20623193826991953]
	TIME [epoch: 8.35 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.237069809688694		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.237069809688694 | validation: 0.18083946790250527]
	TIME [epoch: 8.35 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22938085177181128		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.22938085177181128 | validation: 0.23925303089365954]
	TIME [epoch: 8.35 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.172759381338141		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.172759381338141 | validation: 0.23620939603170762]
	TIME [epoch: 8.37 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18263832183107653		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.18263832183107653 | validation: 0.16867751224337274]
	TIME [epoch: 8.35 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29960843997663844		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.29960843997663844 | validation: 0.22472559631011377]
	TIME [epoch: 8.35 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2538612684590372		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.2538612684590372 | validation: 0.19076201282123606]
	TIME [epoch: 8.35 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16752693911045854		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.16752693911045854 | validation: 0.2887141104970419]
	TIME [epoch: 8.37 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21075801945288922		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.21075801945288922 | validation: 0.2257438358004554]
	TIME [epoch: 8.35 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20738997826539102		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.20738997826539102 | validation: 0.31272647782291624]
	TIME [epoch: 8.35 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20936696462180432		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.20936696462180432 | validation: 0.13302634394334475]
	TIME [epoch: 8.35 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20391738426431036		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.20391738426431036 | validation: 0.2039935917509083]
	TIME [epoch: 8.37 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19516638884170956		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.19516638884170956 | validation: 0.18364322678716405]
	TIME [epoch: 8.35 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2075438153384442		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.2075438153384442 | validation: 0.23699103908058958]
	TIME [epoch: 8.35 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3012658365691342		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.3012658365691342 | validation: 0.29489524465804795]
	TIME [epoch: 8.34 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26461368870169183		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.26461368870169183 | validation: 0.20217786686298578]
	TIME [epoch: 8.37 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16665113916393845		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.16665113916393845 | validation: 0.2717520979375244]
	TIME [epoch: 8.35 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18531397547387599		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.18531397547387599 | validation: 0.3251178013256011]
	TIME [epoch: 8.35 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2299209527665083		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.2299209527665083 | validation: 0.2201025143807705]
	TIME [epoch: 8.35 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18126312436627315		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.18126312436627315 | validation: 0.16149972730565898]
	TIME [epoch: 8.37 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2915177169537468		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.2915177169537468 | validation: 0.26221632694774]
	TIME [epoch: 8.35 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2377960476630593		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.2377960476630593 | validation: 0.2588779504813795]
	TIME [epoch: 8.35 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1983624728465413		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.1983624728465413 | validation: 0.15958440446565814]
	TIME [epoch: 8.35 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26879799390898196		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.26879799390898196 | validation: 0.37956291547843984]
	TIME [epoch: 8.36 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18377351682515014		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.18377351682515014 | validation: 0.10593652802251004]
	TIME [epoch: 8.36 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20874161964606794		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.20874161964606794 | validation: 0.17010536942901733]
	TIME [epoch: 8.35 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18547215282157162		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.18547215282157162 | validation: 0.13151657291590457]
	TIME [epoch: 8.34 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1761307484171247		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.1761307484171247 | validation: 0.20428378120876184]
	TIME [epoch: 8.34 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1723558047857175		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.1723558047857175 | validation: 0.29518709666685294]
	TIME [epoch: 8.37 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2140327343818073		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.2140327343818073 | validation: 0.13841041075091498]
	TIME [epoch: 8.35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22466652210313004		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.22466652210313004 | validation: 0.1291094458611322]
	TIME [epoch: 8.34 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623782449570287		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.1623782449570287 | validation: 0.22162119299557864]
	TIME [epoch: 8.35 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22591742212432148		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.22591742212432148 | validation: 0.3283437731696653]
	TIME [epoch: 8.37 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26340439597049203		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.26340439597049203 | validation: 0.37818688124197253]
	TIME [epoch: 8.35 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28753918297046943		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.28753918297046943 | validation: 0.4196553706706561]
	TIME [epoch: 8.35 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21815775783195668		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.21815775783195668 | validation: 0.1576491394435529]
	TIME [epoch: 8.35 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.183165175481302		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.183165175481302 | validation: 0.14955997780600905]
	TIME [epoch: 8.37 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15033927884320394		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.15033927884320394 | validation: 0.1144955208020639]
	TIME [epoch: 8.35 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16327324123134118		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.16327324123134118 | validation: 0.207611246303532]
	TIME [epoch: 8.35 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21616406976558103		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.21616406976558103 | validation: 0.10825817915027258]
	TIME [epoch: 8.35 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23514905194483354		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.23514905194483354 | validation: 0.11060952929117368]
	TIME [epoch: 8.37 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367385035454715		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.1367385035454715 | validation: 0.11317853483326998]
	TIME [epoch: 8.35 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14191270734574013		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.14191270734574013 | validation: 0.16296586188194764]
	TIME [epoch: 8.35 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14533086006992696		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.14533086006992696 | validation: 0.20178876584905237]
	TIME [epoch: 8.35 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1903408854746049		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.1903408854746049 | validation: 0.30945150345012157]
	TIME [epoch: 8.37 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28278236446269384		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.28278236446269384 | validation: 0.216430211323328]
	TIME [epoch: 8.36 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16423875832390653		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.16423875832390653 | validation: 0.26141446720077055]
	TIME [epoch: 8.35 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844011629714317		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.1844011629714317 | validation: 0.34514350285663964]
	TIME [epoch: 8.35 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22455662417756456		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.22455662417756456 | validation: 0.16705975288238212]
	TIME [epoch: 8.37 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17604514646292238		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.17604514646292238 | validation: 0.19858083375495683]
	TIME [epoch: 8.36 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289020661601523		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.1289020661601523 | validation: 0.1531835208485562]
	TIME [epoch: 8.36 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16669467412813874		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.16669467412813874 | validation: 0.26158448278063823]
	TIME [epoch: 8.36 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456040468141532		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.2456040468141532 | validation: 0.13203495227254552]
	TIME [epoch: 8.35 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1747129131041982		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.1747129131041982 | validation: 0.21842630853751388]
	TIME [epoch: 8.38 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19629657590569577		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.19629657590569577 | validation: 0.2849338574599075]
	TIME [epoch: 8.35 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21306685519471097		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.21306685519471097 | validation: 0.21487236184502762]
	TIME [epoch: 8.35 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21281277664301745		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.21281277664301745 | validation: 0.17531157397962324]
	TIME [epoch: 8.36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25106602538644307		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.25106602538644307 | validation: 0.2657383237870011]
	TIME [epoch: 8.38 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21083225638731506		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.21083225638731506 | validation: 0.5196729117640484]
	TIME [epoch: 8.36 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25597326714730473		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.25597326714730473 | validation: 0.23691027569632636]
	TIME [epoch: 8.35 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16446724141015537		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.16446724141015537 | validation: 0.41737073281775505]
	TIME [epoch: 8.35 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1876187271048913		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.1876187271048913 | validation: 0.19489309556292844]
	TIME [epoch: 8.38 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29268976003849095		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.29268976003849095 | validation: 0.2577375020901189]
	TIME [epoch: 8.35 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20394492475345335		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.20394492475345335 | validation: 0.35604400678265347]
	TIME [epoch: 8.35 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.341382801576754		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.341382801576754 | validation: 0.13451395218365875]
	TIME [epoch: 8.36 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15802596647810394		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.15802596647810394 | validation: 0.1424322831197215]
	TIME [epoch: 8.37 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16265306682230646		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.16265306682230646 | validation: 0.42793806332640383]
	TIME [epoch: 8.36 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2233227250735192		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.2233227250735192 | validation: 0.2852140376824156]
	TIME [epoch: 8.35 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21091868273277328		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.21091868273277328 | validation: 0.18341873637735517]
	TIME [epoch: 8.35 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17477875473775062		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.17477875473775062 | validation: 0.1725840524538234]
	TIME [epoch: 8.37 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26294900043876707		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.26294900043876707 | validation: 0.10521980118785554]
	TIME [epoch: 8.36 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13758599653287648		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.13758599653287648 | validation: 0.08415048641511116]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16309025268609748		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.16309025268609748 | validation: 0.1928656968202361]
	TIME [epoch: 8.35 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16874294358909322		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.16874294358909322 | validation: 0.2525358087122581]
	TIME [epoch: 8.35 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19929818178009023		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.19929818178009023 | validation: 0.2616972620754012]
	TIME [epoch: 8.35 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18306172297622636		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.18306172297622636 | validation: 0.1993840343497984]
	TIME [epoch: 8.34 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1901796455009112		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.1901796455009112 | validation: 0.10076707980503438]
	TIME [epoch: 8.34 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14579006818837908		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.14579006818837908 | validation: 0.14097009375732417]
	TIME [epoch: 8.34 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1728189048339859		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.1728189048339859 | validation: 0.1252537620721813]
	TIME [epoch: 8.37 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1846348624905001		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.1846348624905001 | validation: 0.11127395047406832]
	TIME [epoch: 8.34 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17618944584470703		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.17618944584470703 | validation: 0.14965575796160505]
	TIME [epoch: 8.34 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15755129679250224		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.15755129679250224 | validation: 0.12969301806125158]
	TIME [epoch: 8.34 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16205862303957005		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.16205862303957005 | validation: 0.19094428543625805]
	TIME [epoch: 8.36 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22738678597473122		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.22738678597473122 | validation: 0.28247894898401854]
	TIME [epoch: 8.35 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040785145462493		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.2040785145462493 | validation: 0.19957396236402813]
	TIME [epoch: 8.34 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14486438633435553		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.14486438633435553 | validation: 0.12107231051693648]
	TIME [epoch: 8.34 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16571313210003663		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.16571313210003663 | validation: 0.18296014765856466]
	TIME [epoch: 8.36 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21174195280971228		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.21174195280971228 | validation: 0.19273215591137438]
	TIME [epoch: 8.34 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1959580694017114		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.1959580694017114 | validation: 0.1246513648355712]
	TIME [epoch: 8.34 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15416621367055333		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.15416621367055333 | validation: 0.14837556149966585]
	TIME [epoch: 8.34 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16549123175950203		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.16549123175950203 | validation: 0.13408302004486267]
	TIME [epoch: 8.37 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17458724038023252		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.17458724038023252 | validation: 0.13525691975061288]
	TIME [epoch: 8.35 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16412637475578598		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.16412637475578598 | validation: 0.19102888800040743]
	TIME [epoch: 8.34 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20321715896257192		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.20321715896257192 | validation: 0.2993032619176637]
	TIME [epoch: 8.34 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23883550464411218		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.23883550464411218 | validation: 0.16394894355888967]
	TIME [epoch: 8.36 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15551292961427682		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.15551292961427682 | validation: 0.13260660199416885]
	TIME [epoch: 8.34 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1696272943776734		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.1696272943776734 | validation: 0.35479939590372633]
	TIME [epoch: 8.34 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1711957266271527		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.1711957266271527 | validation: 0.08080967664181961]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20269465966095274		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.20269465966095274 | validation: 0.1770566465527347]
	TIME [epoch: 8.35 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17660769990013647		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.17660769990013647 | validation: 0.11277520055658433]
	TIME [epoch: 8.35 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12087516657320843		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.12087516657320843 | validation: 0.14437047730617159]
	TIME [epoch: 8.34 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14372039969734568		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.14372039969734568 | validation: 0.2158214497447728]
	TIME [epoch: 8.34 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1549490378990284		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.1549490378990284 | validation: 0.2215556178871459]
	TIME [epoch: 8.34 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19950218243938503		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.19950218243938503 | validation: 0.09415628241353796]
	TIME [epoch: 8.36 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16663012774679378		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.16663012774679378 | validation: 0.2767301688423385]
	TIME [epoch: 8.34 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240294577161301		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.2240294577161301 | validation: 0.1874039079829246]
	TIME [epoch: 8.33 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18492313920568176		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.18492313920568176 | validation: 0.14545948432543954]
	TIME [epoch: 8.33 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17416374542094745		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.17416374542094745 | validation: 0.19385615408133933]
	TIME [epoch: 8.35 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20023494446383303		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.20023494446383303 | validation: 0.14846363851260458]
	TIME [epoch: 8.34 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1586222676703446		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.1586222676703446 | validation: 0.12459934760066939]
	TIME [epoch: 8.34 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18080986666289997		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.18080986666289997 | validation: 0.1683156020300823]
	TIME [epoch: 8.34 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15775555534205873		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.15775555534205873 | validation: 0.0899577624008645]
	TIME [epoch: 8.36 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1580953924336845		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.1580953924336845 | validation: 0.123416703238973]
	TIME [epoch: 8.34 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18981858276466765		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.18981858276466765 | validation: 0.20132471932902982]
	TIME [epoch: 8.34 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291085857486227		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.1291085857486227 | validation: 0.12439227557313332]
	TIME [epoch: 8.33 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15806859274333723		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.15806859274333723 | validation: 0.17882551558094678]
	TIME [epoch: 8.36 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16651575009680392		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.16651575009680392 | validation: 0.5251685201765532]
	TIME [epoch: 8.34 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21404933997590966		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.21404933997590966 | validation: 0.30784907079274426]
	TIME [epoch: 8.34 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16851945476157254		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.16851945476157254 | validation: 0.1429174177229393]
	TIME [epoch: 8.34 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16791458885398902		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.16791458885398902 | validation: 0.11119481849547573]
	TIME [epoch: 8.36 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12832339718537047		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.12832339718537047 | validation: 0.09949965545666611]
	TIME [epoch: 8.34 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11401385513634894		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.11401385513634894 | validation: 0.15575362669660475]
	TIME [epoch: 8.34 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1495492244080865		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.1495492244080865 | validation: 0.1490415365994623]
	TIME [epoch: 8.33 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15097475548517156		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.15097475548517156 | validation: 0.156471369960094]
	TIME [epoch: 8.34 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19027187838527554		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.19027187838527554 | validation: 0.3586333502975099]
	TIME [epoch: 8.35 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19138042098218405		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.19138042098218405 | validation: 0.18049862890947982]
	TIME [epoch: 8.34 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16297569842601511		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.16297569842601511 | validation: 0.177837373811654]
	TIME [epoch: 8.34 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14341265079131102		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.14341265079131102 | validation: 0.15220748090960565]
	TIME [epoch: 8.34 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13402316477236723		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.13402316477236723 | validation: 0.1948567725738056]
	TIME [epoch: 8.35 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16023632503046817		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.16023632503046817 | validation: 0.1790362213981882]
	TIME [epoch: 8.34 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20317276379024038		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.20317276379024038 | validation: 0.11859850699132701]
	TIME [epoch: 8.34 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12282457318963438		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.12282457318963438 | validation: 0.23187312582422273]
	TIME [epoch: 8.34 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16755498250287937		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.16755498250287937 | validation: 0.38864801176633434]
	TIME [epoch: 8.36 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23638335355162426		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.23638335355162426 | validation: 0.11020829152703374]
	TIME [epoch: 8.34 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14109376741747523		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.14109376741747523 | validation: 0.1938838302084227]
	TIME [epoch: 8.34 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16998270524650866		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.16998270524650866 | validation: 0.2040815204668888]
	TIME [epoch: 8.34 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1725146338140964		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.1725146338140964 | validation: 0.15478232015663873]
	TIME [epoch: 8.36 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16144006299765395		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.16144006299765395 | validation: 0.09413124865359279]
	TIME [epoch: 8.34 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13821876967109578		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.13821876967109578 | validation: 0.16644065977571093]
	TIME [epoch: 8.34 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11055612298043964		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.11055612298043964 | validation: 0.1102350373126129]
	TIME [epoch: 8.34 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1468333154995809		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.1468333154995809 | validation: 0.2402366592049623]
	TIME [epoch: 8.36 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12414377403918961		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.12414377403918961 | validation: 0.13568565942204475]
	TIME [epoch: 8.34 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1408401441745248		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.1408401441745248 | validation: 0.17661116169726349]
	TIME [epoch: 8.34 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15051831873388427		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.15051831873388427 | validation: 0.13218704397241765]
	TIME [epoch: 8.33 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13224460110996766		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.13224460110996766 | validation: 0.09661914965191395]
	TIME [epoch: 8.35 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14124575053425528		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.14124575053425528 | validation: 0.11120485514233994]
	TIME [epoch: 8.34 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15675751692365264		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.15675751692365264 | validation: 0.11677831703356807]
	TIME [epoch: 8.34 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13250884213525724		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.13250884213525724 | validation: 0.12075126663230673]
	TIME [epoch: 8.34 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12473654835802066		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.12473654835802066 | validation: 0.18533927937763411]
	TIME [epoch: 8.33 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14182332888415888		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.14182332888415888 | validation: 0.18995047005948631]
	TIME [epoch: 8.36 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15023729258657512		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.15023729258657512 | validation: 0.14897772724318475]
	TIME [epoch: 8.33 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14219275290368322		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.14219275290368322 | validation: 0.22424052385235377]
	TIME [epoch: 8.33 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13507219791562858		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.13507219791562858 | validation: 0.15303330313550262]
	TIME [epoch: 8.33 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13202228958198284		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.13202228958198284 | validation: 0.13932261656059747]
	TIME [epoch: 8.35 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15706987373842438		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.15706987373842438 | validation: 0.11214264829924614]
	TIME [epoch: 8.34 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10877261481108833		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.10877261481108833 | validation: 0.0896348548262191]
	TIME [epoch: 8.34 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12688458280775564		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.12688458280775564 | validation: 0.1892673032985994]
	TIME [epoch: 8.33 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16462930444504745		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.16462930444504745 | validation: 0.1384249298724315]
	TIME [epoch: 8.35 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2070296487716054		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.2070296487716054 | validation: 0.09796129380045471]
	TIME [epoch: 8.34 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250259503356775		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.1250259503356775 | validation: 0.1448257387712477]
	TIME [epoch: 8.33 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.243670327637537		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.243670327637537 | validation: 0.11637859517930893]
	TIME [epoch: 8.33 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1319818468025455		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.1319818468025455 | validation: 0.17626951559737009]
	TIME [epoch: 8.35 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16775509883494966		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.16775509883494966 | validation: 0.17970536828824601]
	TIME [epoch: 8.34 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16318255040225313		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.16318255040225313 | validation: 0.15036455618231098]
	TIME [epoch: 8.33 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11803837244019569		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.11803837244019569 | validation: 0.36370631402245673]
	TIME [epoch: 8.33 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20265382686298067		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.20265382686298067 | validation: 0.13046427947764727]
	TIME [epoch: 8.33 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.175197800446553		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.175197800446553 | validation: 0.13979616661081995]
	TIME [epoch: 8.35 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16845569603120733		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.16845569603120733 | validation: 0.10981604099444989]
	TIME [epoch: 8.33 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18905938247483506		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.18905938247483506 | validation: 0.08775934631978077]
	TIME [epoch: 8.33 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13896347658634328		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.13896347658634328 | validation: 0.19729561830482595]
	TIME [epoch: 8.34 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14885749969274395		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.14885749969274395 | validation: 0.36944137342782657]
	TIME [epoch: 8.35 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20445366143186572		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.20445366143186572 | validation: 0.0910510872297682]
	TIME [epoch: 8.33 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13122788097946952		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.13122788097946952 | validation: 0.10722585945307356]
	TIME [epoch: 8.33 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10709272459663091		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.10709272459663091 | validation: 0.14471340577448805]
	TIME [epoch: 8.34 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12958282329277787		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.12958282329277787 | validation: 0.10610801989316815]
	TIME [epoch: 8.34 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.145909374884655		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.145909374884655 | validation: 0.1253534174065735]
	TIME [epoch: 8.33 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15791601795505975		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.15791601795505975 | validation: 0.12014680761868601]
	TIME [epoch: 8.34 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15009730030135404		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.15009730030135404 | validation: 0.21880931029231224]
	TIME [epoch: 8.35 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1565758681952348		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.1565758681952348 | validation: 0.1042160803858318]
	TIME [epoch: 8.34 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17792508574149934		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.17792508574149934 | validation: 0.21091449640427465]
	TIME [epoch: 8.34 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1678660008517523		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.1678660008517523 | validation: 0.13543100649346942]
	TIME [epoch: 8.34 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11618397217214158		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.11618397217214158 | validation: 0.18498791690272215]
	TIME [epoch: 8.35 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14389175875042803		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.14389175875042803 | validation: 0.1015455856756616]
	TIME [epoch: 8.34 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13409809273749404		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.13409809273749404 | validation: 0.1163280476716734]
	TIME [epoch: 8.34 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10558037290358253		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.10558037290358253 | validation: 0.1212867858390238]
	TIME [epoch: 8.34 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1278274631188557		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.1278274631188557 | validation: 0.12357341942077324]
	TIME [epoch: 8.34 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13853114463169686		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.13853114463169686 | validation: 0.0931208065834769]
	TIME [epoch: 8.34 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11007081526472777		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.11007081526472777 | validation: 0.06909391517167529]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11522876809254483		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.11522876809254483 | validation: 0.07084213869078648]
	TIME [epoch: 8.33 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13591892683733806		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.13591892683733806 | validation: 0.08298297801270503]
	TIME [epoch: 8.35 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18184386742914518		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.18184386742914518 | validation: 0.12853051148924702]
	TIME [epoch: 8.34 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516505709968801		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.1516505709968801 | validation: 0.09369734554568296]
	TIME [epoch: 8.33 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14606500065438197		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.14606500065438197 | validation: 0.09549918869529739]
	TIME [epoch: 8.33 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14492636452248833		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.14492636452248833 | validation: 0.12625275837631258]
	TIME [epoch: 8.35 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13158649480393686		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.13158649480393686 | validation: 0.07980971711314538]
	TIME [epoch: 8.34 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10942959377392061		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.10942959377392061 | validation: 0.1829353439949522]
	TIME [epoch: 8.33 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14629934661497404		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.14629934661497404 | validation: 0.12676305051526562]
	TIME [epoch: 8.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14183025196914498		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.14183025196914498 | validation: 0.07924254892674326]
	TIME [epoch: 8.35 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743911908790062		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.12743911908790062 | validation: 0.2153928777090855]
	TIME [epoch: 8.34 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18419235489403188		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.18419235489403188 | validation: 0.10390560342545355]
	TIME [epoch: 8.34 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19562420349869597		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.19562420349869597 | validation: 0.11973605278005997]
	TIME [epoch: 8.33 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16300696633216855		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.16300696633216855 | validation: 0.28914125380028494]
	TIME [epoch: 8.35 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17461467170226644		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.17461467170226644 | validation: 0.15140210340278054]
	TIME [epoch: 8.34 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13267840313912255		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.13267840313912255 | validation: 0.1700177568926]
	TIME [epoch: 8.34 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17406163889694481		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.17406163889694481 | validation: 0.2662017527155091]
	TIME [epoch: 8.33 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12280393424436578		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.12280393424436578 | validation: 0.15786601786015933]
	TIME [epoch: 8.36 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17281338858568945		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.17281338858568945 | validation: 0.18463660932580445]
	TIME [epoch: 8.34 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14843584146151803		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.14843584146151803 | validation: 0.11872278269824293]
	TIME [epoch: 8.33 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18264381874356053		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.18264381874356053 | validation: 0.1769576706063818]
	TIME [epoch: 8.33 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490254005791011		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.1490254005791011 | validation: 0.08697764461031507]
	TIME [epoch: 8.36 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12918680435816657		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.12918680435816657 | validation: 0.16813980786408994]
	TIME [epoch: 8.34 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14340673905974843		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.14340673905974843 | validation: 0.1393865589044535]
	TIME [epoch: 8.34 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13300308115667003		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.13300308115667003 | validation: 0.2882191247996475]
	TIME [epoch: 8.34 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16185671432115495		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.16185671432115495 | validation: 0.1227903744218026]
	TIME [epoch: 8.36 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.129390253139509		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.129390253139509 | validation: 0.09973079406346255]
	TIME [epoch: 8.34 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289861287181806		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.1289861287181806 | validation: 0.10428917732432688]
	TIME [epoch: 8.33 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09975480080073093		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.09975480080073093 | validation: 0.11709020282113038]
	TIME [epoch: 8.33 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14337104080694146		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.14337104080694146 | validation: 0.19732077431260148]
	TIME [epoch: 8.35 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17152139909829792		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.17152139909829792 | validation: 0.16185051592816677]
	TIME [epoch: 8.33 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281421683741914		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.1281421683741914 | validation: 0.3279926184151648]
	TIME [epoch: 8.34 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17815702324989452		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.17815702324989452 | validation: 0.08907222439071136]
	TIME [epoch: 8.33 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10909960281570164		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.10909960281570164 | validation: 0.10754010409974271]
	TIME [epoch: 8.36 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13466208630706605		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.13466208630706605 | validation: 0.0977612774672878]
	TIME [epoch: 8.34 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1023058015419451		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.1023058015419451 | validation: 0.17496207055684987]
	TIME [epoch: 8.34 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1782226839855126		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.1782226839855126 | validation: 0.17596434564400049]
	TIME [epoch: 8.33 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12363708397804692		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.12363708397804692 | validation: 0.0851879424247485]
	TIME [epoch: 8.35 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10525004892841153		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.10525004892841153 | validation: 0.09223000003809591]
	TIME [epoch: 8.33 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12359164520022155		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.12359164520022155 | validation: 0.13647312281688784]
	TIME [epoch: 8.33 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12764254170348416		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.12764254170348416 | validation: 0.09462907474745891]
	TIME [epoch: 8.33 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07361417696061663		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.07361417696061663 | validation: 0.11921441754614465]
	TIME [epoch: 8.35 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09594892484112166		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.09594892484112166 | validation: 0.0859329029209202]
	TIME [epoch: 8.33 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09991460624607423		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.09991460624607423 | validation: 0.10732804526504816]
	TIME [epoch: 8.33 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695386942663428		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.1695386942663428 | validation: 0.07764795372929349]
	TIME [epoch: 8.33 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11746273965695693		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.11746273965695693 | validation: 0.15842911403146998]
	TIME [epoch: 8.36 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1081263779650002		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.1081263779650002 | validation: 0.153022563048881]
	TIME [epoch: 8.33 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1351889908489404		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.1351889908489404 | validation: 0.12714254989697552]
	TIME [epoch: 8.34 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1294725667977697		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.1294725667977697 | validation: 0.12649221108952785]
	TIME [epoch: 8.34 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12079095843552383		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.12079095843552383 | validation: 0.09146333101194296]
	TIME [epoch: 8.36 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09116051764006165		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.09116051764006165 | validation: 0.12140557478503812]
	TIME [epoch: 8.35 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10789652454544407		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.10789652454544407 | validation: 0.1636837603487829]
	TIME [epoch: 8.34 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12377700128345592		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.12377700128345592 | validation: 0.0835884878343647]
	TIME [epoch: 8.35 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09694907291952753		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.09694907291952753 | validation: 0.1596286343381137]
	TIME [epoch: 8.36 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10565382080086824		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.10565382080086824 | validation: 0.12970431457156562]
	TIME [epoch: 8.35 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10729681612492259		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.10729681612492259 | validation: 0.10256994138524642]
	TIME [epoch: 8.34 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11865386466740871		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.11865386466740871 | validation: 0.19193888798781336]
	TIME [epoch: 8.33 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13554292351464325		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.13554292351464325 | validation: 0.12744228093763343]
	TIME [epoch: 8.36 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10819663572244873		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.10819663572244873 | validation: 0.08456013022718334]
	TIME [epoch: 8.34 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12021265409187092		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.12021265409187092 | validation: 0.13738701212833707]
	TIME [epoch: 8.34 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10594526146683905		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.10594526146683905 | validation: 0.09508446761518102]
	TIME [epoch: 8.33 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0842910313695558		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.0842910313695558 | validation: 0.1276590520902806]
	TIME [epoch: 8.36 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10141501242294926		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.10141501242294926 | validation: 0.1533189631984035]
	TIME [epoch: 8.34 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1436725954533489		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.1436725954533489 | validation: 0.07431214880044498]
	TIME [epoch: 8.34 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10110085093020219		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.10110085093020219 | validation: 0.11142334414783678]
	TIME [epoch: 8.34 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12996249509972388		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.12996249509972388 | validation: 0.1422863094773694]
	TIME [epoch: 8.36 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10382068580023474		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.10382068580023474 | validation: 0.10582513669862084]
	TIME [epoch: 8.34 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12849845118278364		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.12849845118278364 | validation: 0.18214355119226594]
	TIME [epoch: 8.34 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18483348455014265		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.18483348455014265 | validation: 0.19299207960913195]
	TIME [epoch: 8.33 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11203051111044257		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.11203051111044257 | validation: 0.21523880374662802]
	TIME [epoch: 8.36 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09687676662044467		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.09687676662044467 | validation: 0.22566577043027786]
	TIME [epoch: 8.34 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13450393221337686		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.13450393221337686 | validation: 0.1536190249561502]
	TIME [epoch: 8.34 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13797316665528822		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.13797316665528822 | validation: 0.08436631697433151]
	TIME [epoch: 8.34 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10208025048532758		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.10208025048532758 | validation: 0.1482728939320345]
	TIME [epoch: 8.35 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09867437986201344		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.09867437986201344 | validation: 0.15243643181347466]
	TIME [epoch: 8.34 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14038807501931902		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.14038807501931902 | validation: 0.14344292972669545]
	TIME [epoch: 8.34 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11024567085173811		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.11024567085173811 | validation: 0.09900344070794148]
	TIME [epoch: 8.34 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12610873046249022		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.12610873046249022 | validation: 0.11328608057247261]
	TIME [epoch: 8.36 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11647641961764392		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.11647641961764392 | validation: 0.09691309046671565]
	TIME [epoch: 8.35 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10596518405227787		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.10596518405227787 | validation: 0.15786950961211604]
	TIME [epoch: 8.34 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12322933918309471		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.12322933918309471 | validation: 0.06571437445132841]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0980559453460211		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.0980559453460211 | validation: 0.14073944216807552]
	TIME [epoch: 8.36 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1105387581618196		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.1105387581618196 | validation: 0.09106216445577778]
	TIME [epoch: 8.33 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12887300650264583		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.12887300650264583 | validation: 0.13747905632790358]
	TIME [epoch: 8.34 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08531894208951496		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.08531894208951496 | validation: 0.11667411010096262]
	TIME [epoch: 8.34 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13497691172553178		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.13497691172553178 | validation: 0.38922208382545864]
	TIME [epoch: 8.36 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20974666880598739		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.20974666880598739 | validation: 0.10579771411685697]
	TIME [epoch: 8.34 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11295214880915369		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.11295214880915369 | validation: 0.08702024971064781]
	TIME [epoch: 8.33 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12439672003106841		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.12439672003106841 | validation: 0.0985723700574333]
	TIME [epoch: 8.34 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08929615010497989		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.08929615010497989 | validation: 0.1413160935309808]
	TIME [epoch: 8.36 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1044574593808345		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.1044574593808345 | validation: 0.08581358633365083]
	TIME [epoch: 8.34 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936439842753247		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.0936439842753247 | validation: 0.17758034028950748]
	TIME [epoch: 8.34 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14934354619512308		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.14934354619512308 | validation: 0.17142949272726704]
	TIME [epoch: 8.34 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12231005915584747		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.12231005915584747 | validation: 0.11591453175758235]
	TIME [epoch: 8.36 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09749424272676961		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.09749424272676961 | validation: 0.09053409959831873]
	TIME [epoch: 8.34 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08956472257114476		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.08956472257114476 | validation: 0.10428448899998008]
	TIME [epoch: 8.34 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14143449491743326		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.14143449491743326 | validation: 0.1306596588199478]
	TIME [epoch: 8.34 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14737400183987479		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.14737400183987479 | validation: 0.1565616940757461]
	TIME [epoch: 8.35 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17134558824099821		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.17134558824099821 | validation: 0.33457558382004715]
	TIME [epoch: 8.34 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16221417378916292		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.16221417378916292 | validation: 0.118897669514195]
	TIME [epoch: 8.34 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18326562434286503		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.18326562434286503 | validation: 0.1905711320242589]
	TIME [epoch: 8.34 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14075423655146208		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.14075423655146208 | validation: 0.1164944345427878]
	TIME [epoch: 8.36 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1214299965144078		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.1214299965144078 | validation: 0.1402109020664163]
	TIME [epoch: 8.33 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1559641863027222		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.1559641863027222 | validation: 0.12858600387885438]
	TIME [epoch: 8.34 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09899379170305346		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.09899379170305346 | validation: 0.07442791768541518]
	TIME [epoch: 8.34 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11607493294943791		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.11607493294943791 | validation: 0.10763792638414418]
	TIME [epoch: 8.36 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13924811715139102		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.13924811715139102 | validation: 0.21621142754813752]
	TIME [epoch: 8.34 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2335055308307096		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.2335055308307096 | validation: 0.16036509264090598]
	TIME [epoch: 8.34 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12668889748305082		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.12668889748305082 | validation: 0.14756555009122188]
	TIME [epoch: 8.34 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150274022214308		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.11150274022214308 | validation: 0.09493022171720727]
	TIME [epoch: 8.36 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09194360129972458		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.09194360129972458 | validation: 0.11346423655255847]
	TIME [epoch: 8.34 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09322465636338273		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.09322465636338273 | validation: 0.11597459758776853]
	TIME [epoch: 8.34 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1359565196746126		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.1359565196746126 | validation: 0.08738500927677509]
	TIME [epoch: 8.34 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185961530257877		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.10185961530257877 | validation: 0.08883941193234694]
	TIME [epoch: 8.35 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08864124035874285		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.08864124035874285 | validation: 0.1127425444798226]
	TIME [epoch: 8.34 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772420919114616		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.11772420919114616 | validation: 0.21182258981038754]
	TIME [epoch: 8.34 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1434034401443794		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.1434034401443794 | validation: 0.1652329641881159]
	TIME [epoch: 8.35 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10482744949439497		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.10482744949439497 | validation: 0.15679289088413306]
	TIME [epoch: 8.35 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12816186345318897		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.12816186345318897 | validation: 0.317815238592278]
	TIME [epoch: 8.34 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13775601664074907		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.13775601664074907 | validation: 0.0957178501879005]
	TIME [epoch: 8.34 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12281947543392428		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.12281947543392428 | validation: 0.09794437859046304]
	TIME [epoch: 8.35 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07223641316467977		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.07223641316467977 | validation: 0.13154586560157047]
	TIME [epoch: 8.35 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12555310539582115		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.12555310539582115 | validation: 0.09368351356485355]
	TIME [epoch: 8.34 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10567717680172384		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.10567717680172384 | validation: 0.07566750485929694]
	TIME [epoch: 8.34 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09514012815077348		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.09514012815077348 | validation: 0.07947619044353077]
	TIME [epoch: 8.35 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264700678601929		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.1264700678601929 | validation: 0.08226778017437666]
	TIME [epoch: 8.35 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11654969640022188		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.11654969640022188 | validation: 0.11546656503609748]
	TIME [epoch: 8.34 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10872672703240571		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.10872672703240571 | validation: 0.08783401120824469]
	TIME [epoch: 8.34 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12482577343432813		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.12482577343432813 | validation: 0.21184715844615695]
	TIME [epoch: 8.35 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13417319519498516		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.13417319519498516 | validation: 0.124597042348896]
	TIME [epoch: 8.35 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10948435281512199		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.10948435281512199 | validation: 0.152570999426259]
	TIME [epoch: 8.34 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12571002420379213		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.12571002420379213 | validation: 0.13778985000007538]
	TIME [epoch: 8.34 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12561955885967518		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.12561955885967518 | validation: 0.12624421725958]
	TIME [epoch: 8.36 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09164890447855291		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.09164890447855291 | validation: 0.0922797585353056]
	TIME [epoch: 8.34 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09059863414274859		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.09059863414274859 | validation: 0.1110723685687997]
	TIME [epoch: 8.34 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08987142158964974		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.08987142158964974 | validation: 0.06013090410462987]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0911838862543621		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.0911838862543621 | validation: 0.0975864960584304]
	TIME [epoch: 8.36 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11236517872754752		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.11236517872754752 | validation: 0.10998909630271603]
	TIME [epoch: 8.34 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10702610706992459		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.10702610706992459 | validation: 0.0925137898447319]
	TIME [epoch: 8.35 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06929422984462903		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.06929422984462903 | validation: 0.09580224266236852]
	TIME [epoch: 8.34 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09255713099933513		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.09255713099933513 | validation: 0.09187040261208385]
	TIME [epoch: 8.36 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13507757953854552		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.13507757953854552 | validation: 0.11488800288567623]
	TIME [epoch: 8.34 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1157738450264513		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.1157738450264513 | validation: 0.14084527010226605]
	TIME [epoch: 8.34 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11710955049032686		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.11710955049032686 | validation: 0.2083346122661377]
	TIME [epoch: 8.34 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11226900297534018		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.11226900297534018 | validation: 0.07540416239554275]
	TIME [epoch: 8.36 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11524047337447421		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.11524047337447421 | validation: 0.10887165295815401]
	TIME [epoch: 8.34 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08518102946957433		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.08518102946957433 | validation: 0.144938147146126]
	TIME [epoch: 8.35 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08234682318816348		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.08234682318816348 | validation: 0.13461784140864785]
	TIME [epoch: 8.34 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11266247046467588		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.11266247046467588 | validation: 0.06734010973298314]
	TIME [epoch: 8.36 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07527261845838458		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.07527261845838458 | validation: 0.09556693077301028]
	TIME [epoch: 8.34 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09936139660585411		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.09936139660585411 | validation: 0.07387500244240518]
	TIME [epoch: 8.34 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10802994210062322		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.10802994210062322 | validation: 0.07200244962323252]
	TIME [epoch: 8.34 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08694790164923519		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.08694790164923519 | validation: 0.06715062117108629]
	TIME [epoch: 8.36 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09594047462390384		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.09594047462390384 | validation: 0.0844969164821027]
	TIME [epoch: 8.34 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08364453983196918		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.08364453983196918 | validation: 0.04551547044117747]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08234629588339472		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.08234629588339472 | validation: 0.09189051523835656]
	TIME [epoch: 8.34 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12746154822774794		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.12746154822774794 | validation: 0.14627130354615323]
	TIME [epoch: 8.35 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10460276215329833		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.10460276215329833 | validation: 0.08415336536856505]
	TIME [epoch: 8.34 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10717173834568142		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.10717173834568142 | validation: 0.055445367187628464]
	TIME [epoch: 8.33 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878936461641929		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.0878936461641929 | validation: 0.09240536459752242]
	TIME [epoch: 8.33 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08419813497864931		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.08419813497864931 | validation: 0.12485948120845128]
	TIME [epoch: 8.35 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07472745533168945		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.07472745533168945 | validation: 0.13324645838759924]
	TIME [epoch: 8.34 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10601269022998983		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.10601269022998983 | validation: 0.12399132778512495]
	TIME [epoch: 8.33 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07385832565884216		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.07385832565884216 | validation: 0.09479910452202164]
	TIME [epoch: 8.34 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921105567585774		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.0921105567585774 | validation: 0.1685207640848678]
	TIME [epoch: 8.35 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306597728257372		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.1306597728257372 | validation: 0.08100903952162569]
	TIME [epoch: 8.34 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.095533448753731		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.095533448753731 | validation: 0.1718915137948272]
	TIME [epoch: 8.34 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09495105664684055		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.09495105664684055 | validation: 0.1474579239577956]
	TIME [epoch: 8.33 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11241894483600275		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.11241894483600275 | validation: 0.16488231452561508]
	TIME [epoch: 8.35 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11069861730823509		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.11069861730823509 | validation: 0.11073130804400949]
	TIME [epoch: 8.34 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12501977226522917		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.12501977226522917 | validation: 0.1126710839627604]
	TIME [epoch: 8.34 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08813677452167992		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.08813677452167992 | validation: 0.07159703609930133]
	TIME [epoch: 8.33 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13427841543480243		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.13427841543480243 | validation: 0.15999598423574785]
	TIME [epoch: 8.35 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10362941583228173		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.10362941583228173 | validation: 0.1036789964322274]
	TIME [epoch: 8.34 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11821280594178703		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.11821280594178703 | validation: 0.15893131672235808]
	TIME [epoch: 8.34 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18135047179245764		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.18135047179245764 | validation: 0.12295413575828654]
	TIME [epoch: 8.33 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1156796873070857		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.1156796873070857 | validation: 0.08324933021004208]
	TIME [epoch: 8.35 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950152623631145		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.09950152623631145 | validation: 0.10754776664933322]
	TIME [epoch: 8.34 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0870124194621307		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.0870124194621307 | validation: 0.07809486130828786]
	TIME [epoch: 8.33 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08841277813946072		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.08841277813946072 | validation: 0.1284540581395938]
	TIME [epoch: 8.33 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08828162559600838		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.08828162559600838 | validation: 0.15163876280274408]
	TIME [epoch: 8.35 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10355946502935795		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.10355946502935795 | validation: 0.1382961802482276]
	TIME [epoch: 8.34 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11179763629434687		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.11179763629434687 | validation: 0.08619308191936823]
	TIME [epoch: 8.34 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15489382312950345		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.15489382312950345 | validation: 0.148726347451875]
	TIME [epoch: 8.34 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11805385257966443		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.11805385257966443 | validation: 0.0840470122059286]
	TIME [epoch: 8.35 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10865741865503756		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.10865741865503756 | validation: 0.08650524380806833]
	TIME [epoch: 8.34 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09520559381040486		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.09520559381040486 | validation: 0.14448040704246223]
	TIME [epoch: 8.34 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1260185995689376		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.1260185995689376 | validation: 0.07297387104754044]
	TIME [epoch: 8.34 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11522029754049035		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.11522029754049035 | validation: 0.08761254383342203]
	TIME [epoch: 8.35 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705939865403096		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.0705939865403096 | validation: 0.09877477710223341]
	TIME [epoch: 8.34 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0968361722491711		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.0968361722491711 | validation: 0.1596441394062102]
	TIME [epoch: 8.34 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09355884774836153		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.09355884774836153 | validation: 0.06525548698387469]
	TIME [epoch: 8.33 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0901348888229324		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.0901348888229324 | validation: 0.08377590603575463]
	TIME [epoch: 8.35 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14286221223602572		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.14286221223602572 | validation: 0.10315208241814347]
	TIME [epoch: 8.33 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10194989321236687		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.10194989321236687 | validation: 0.08149198833497823]
	TIME [epoch: 8.33 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08138357697500831		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.08138357697500831 | validation: 0.04726699676600289]
	TIME [epoch: 8.34 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10374253508396566		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.10374253508396566 | validation: 0.2076761253396576]
	TIME [epoch: 8.35 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1145525905740156		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.1145525905740156 | validation: 0.08320463524067821]
	TIME [epoch: 8.34 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09050185671396423		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.09050185671396423 | validation: 0.14001383798273326]
	TIME [epoch: 8.34 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10123989502795191		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.10123989502795191 | validation: 0.11167798012788091]
	TIME [epoch: 8.34 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10333392302818689		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.10333392302818689 | validation: 0.10017180257181635]
	TIME [epoch: 8.36 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08437952516956773		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.08437952516956773 | validation: 0.08295419747687317]
	TIME [epoch: 8.33 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526524198450864		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.10526524198450864 | validation: 0.1806041320010877]
	TIME [epoch: 8.34 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1182506566402642		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.1182506566402642 | validation: 0.11694443363432282]
	TIME [epoch: 8.33 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11211137376469435		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.11211137376469435 | validation: 0.16104470672654317]
	TIME [epoch: 8.35 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11323400213672952		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.11323400213672952 | validation: 0.09936637965957303]
	TIME [epoch: 8.33 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08242938583882853		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.08242938583882853 | validation: 0.11214743948434955]
	TIME [epoch: 8.33 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08217563311527305		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.08217563311527305 | validation: 0.1016943730023935]
	TIME [epoch: 8.34 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08635554434070422		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.08635554434070422 | validation: 0.08594035401286332]
	TIME [epoch: 8.36 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12526519286917365		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.12526519286917365 | validation: 0.20839213857976407]
	TIME [epoch: 8.34 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10476472128103238		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.10476472128103238 | validation: 0.11793924629674116]
	TIME [epoch: 8.34 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08376066940788325		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.08376066940788325 | validation: 0.10596503551698888]
	TIME [epoch: 8.33 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11528248073466833		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.11528248073466833 | validation: 0.09444602782109116]
	TIME [epoch: 8.35 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205401482026942		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.06205401482026942 | validation: 0.09815823765576935]
	TIME [epoch: 8.33 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08626636888426373		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.08626636888426373 | validation: 0.11222145657961727]
	TIME [epoch: 8.33 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14747457041636083		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.14747457041636083 | validation: 0.13044222825415563]
	TIME [epoch: 8.34 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12362942046685879		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.12362942046685879 | validation: 0.1076098262656206]
	TIME [epoch: 8.35 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528672038976758		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.10528672038976758 | validation: 0.05136432307875674]
	TIME [epoch: 8.34 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0823683086692011		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.0823683086692011 | validation: 0.10051260662308503]
	TIME [epoch: 8.33 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09478985963802142		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.09478985963802142 | validation: 0.12131369312199043]
	TIME [epoch: 8.33 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08403795975042441		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.08403795975042441 | validation: 0.07732900762314053]
	TIME [epoch: 8.36 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10109703202428903		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.10109703202428903 | validation: 0.09561510600299965]
	TIME [epoch: 8.33 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0660600997820894		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.0660600997820894 | validation: 0.09827460937132965]
	TIME [epoch: 8.34 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1259074904151704		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.1259074904151704 | validation: 0.10545828241284377]
	TIME [epoch: 8.34 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059526512527050414		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.059526512527050414 | validation: 0.10529244177648661]
	TIME [epoch: 8.35 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10124154568530104		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.10124154568530104 | validation: 0.10311333349433621]
	TIME [epoch: 8.33 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07834007402297691		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.07834007402297691 | validation: 0.06392677781592565]
	TIME [epoch: 8.33 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0548276792675341		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.0548276792675341 | validation: 0.061578347832083706]
	TIME [epoch: 8.33 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08573983012775223		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.08573983012775223 | validation: 0.09906487118450857]
	TIME [epoch: 8.35 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656451179808491		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.08656451179808491 | validation: 0.13776076194902784]
	TIME [epoch: 8.33 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14683771496224202		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.14683771496224202 | validation: 0.12371415549978784]
	TIME [epoch: 8.34 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09478580227554903		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.09478580227554903 | validation: 0.08467604014374779]
	TIME [epoch: 8.33 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08565147273918618		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.08565147273918618 | validation: 0.10437115394036273]
	TIME [epoch: 8.35 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09591827123235204		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.09591827123235204 | validation: 0.07851051071214712]
	TIME [epoch: 8.33 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10018179731983672		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.10018179731983672 | validation: 0.08101431166634068]
	TIME [epoch: 8.34 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10845786380760085		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.10845786380760085 | validation: 0.3040876591747544]
	TIME [epoch: 8.34 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13746752550033553		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.13746752550033553 | validation: 0.07486839246456008]
	TIME [epoch: 8.35 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10098314660270706		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.10098314660270706 | validation: 0.0867174686141733]
	TIME [epoch: 8.34 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10135779950215298		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.10135779950215298 | validation: 0.1180534914079569]
	TIME [epoch: 8.34 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11520432754292806		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.11520432754292806 | validation: 0.13828519429226485]
	TIME [epoch: 8.34 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09816353584179474		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.09816353584179474 | validation: 0.07693237529844663]
	TIME [epoch: 8.35 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09844550080358166		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.09844550080358166 | validation: 0.20031062928890253]
	TIME [epoch: 8.33 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10119669861463106		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.10119669861463106 | validation: 0.09548562265707002]
	TIME [epoch: 8.34 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11815658203198882		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.11815658203198882 | validation: 0.11340506574555535]
	TIME [epoch: 8.35 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07824717766132959		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.07824717766132959 | validation: 0.15679156470019723]
	TIME [epoch: 8.35 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07951667916419976		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.07951667916419976 | validation: 0.11761964872362979]
	TIME [epoch: 8.33 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08062993472290515		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.08062993472290515 | validation: 0.06048673857358111]
	TIME [epoch: 8.33 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07872668908831834		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.07872668908831834 | validation: 0.0933047975122239]
	TIME [epoch: 8.34 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08271657112451047		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.08271657112451047 | validation: 0.08697895163830549]
	TIME [epoch: 8.35 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08315092941909692		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.08315092941909692 | validation: 0.11356087396332062]
	TIME [epoch: 8.33 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10348534869097151		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.10348534869097151 | validation: 0.07461561590983788]
	TIME [epoch: 8.33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07108786990622369		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.07108786990622369 | validation: 0.092655338846906]
	TIME [epoch: 8.35 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15052905093437766		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.15052905093437766 | validation: 0.3168879491038135]
	TIME [epoch: 8.34 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13541997802558736		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.13541997802558736 | validation: 0.0973277834861844]
	TIME [epoch: 8.33 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07189784535120297		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.07189784535120297 | validation: 0.12773720647789638]
	TIME [epoch: 8.33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07398356800070523		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.07398356800070523 | validation: 0.12587578431890054]
	TIME [epoch: 8.35 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07557489923760577		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.07557489923760577 | validation: 0.09338987265052873]
	TIME [epoch: 8.34 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0930577419394685		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.0930577419394685 | validation: 0.11407135747366914]
	TIME [epoch: 8.34 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860556883574007		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.06860556883574007 | validation: 0.06265286419660361]
	TIME [epoch: 8.33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08301627018083303		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.08301627018083303 | validation: 0.055207468281713815]
	TIME [epoch: 8.35 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793699329797173		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.0793699329797173 | validation: 0.054908000690240155]
	TIME [epoch: 8.34 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07855566384097502		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.07855566384097502 | validation: 0.11357404240981385]
	TIME [epoch: 8.33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832943685207587		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.0832943685207587 | validation: 0.08486880761304014]
	TIME [epoch: 8.33 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09763896643498454		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.09763896643498454 | validation: 0.06719961492508511]
	TIME [epoch: 8.35 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05680486820516982		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.05680486820516982 | validation: 0.06604853615557874]
	TIME [epoch: 8.34 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07736439413571228		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.07736439413571228 | validation: 0.09897439755696891]
	TIME [epoch: 8.34 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09661727780413872		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.09661727780413872 | validation: 0.12275965033025316]
	TIME [epoch: 8.34 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07904906971317362		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.07904906971317362 | validation: 0.06639301589822483]
	TIME [epoch: 8.35 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10228789974911807		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.10228789974911807 | validation: 0.09985197423744344]
	TIME [epoch: 8.34 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09599900028192651		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.09599900028192651 | validation: 0.14882257675553062]
	TIME [epoch: 8.33 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08904069210511414		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.08904069210511414 | validation: 0.08412112315076045]
	TIME [epoch: 8.33 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07198089010435146		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.07198089010435146 | validation: 0.07825855578331534]
	TIME [epoch: 8.35 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936286392299607		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.0936286392299607 | validation: 0.17603369140011157]
	TIME [epoch: 8.33 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588850176012585		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.09588850176012585 | validation: 0.10198413558258046]
	TIME [epoch: 8.33 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279128251392311		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.1279128251392311 | validation: 0.09648233489849214]
	TIME [epoch: 8.33 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06180958886236805		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.06180958886236805 | validation: 0.05871930620066515]
	TIME [epoch: 8.35 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07308344672495927		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.07308344672495927 | validation: 0.07385584917410418]
	TIME [epoch: 8.33 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06826108565908036		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.06826108565908036 | validation: 0.10637725065851344]
	TIME [epoch: 8.35 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06796852905415203		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.06796852905415203 | validation: 0.04097934076248282]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07447911451469613		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.07447911451469613 | validation: 0.0478590498363299]
	TIME [epoch: 8.35 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978318348669768		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.06978318348669768 | validation: 0.07677680318313328]
	TIME [epoch: 8.33 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06296336975832832		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.06296336975832832 | validation: 0.0952798949426168]
	TIME [epoch: 8.33 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07900457868673873		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.07900457868673873 | validation: 0.07964993521422709]
	TIME [epoch: 8.33 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09911806951995758		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.09911806951995758 | validation: 0.1239556889293458]
	TIME [epoch: 8.35 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07779064197239309		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.07779064197239309 | validation: 0.09559222544759882]
	TIME [epoch: 8.33 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10588343140025944		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.10588343140025944 | validation: 0.1452804082627676]
	TIME [epoch: 8.33 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12108547756748977		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.12108547756748977 | validation: 0.06464643242588722]
	TIME [epoch: 8.33 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06149671079387777		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.06149671079387777 | validation: 0.09573232873376172]
	TIME [epoch: 8.35 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07733889658930007		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.07733889658930007 | validation: 0.06460148736773105]
	TIME [epoch: 8.34 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10544226372704915		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.10544226372704915 | validation: 0.12131196697767332]
	TIME [epoch: 8.33 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793733511321851		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.0793733511321851 | validation: 0.048379464652761994]
	TIME [epoch: 8.33 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436540809429336		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.06436540809429336 | validation: 0.06536567956903346]
	TIME [epoch: 8.35 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06065925357259433		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.06065925357259433 | validation: 0.10370020381477897]
	TIME [epoch: 8.34 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09138614684469394		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.09138614684469394 | validation: 0.23972554649224076]
	TIME [epoch: 8.33 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09475585643438075		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.09475585643438075 | validation: 0.05639015220572348]
	TIME [epoch: 8.33 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0623753648225573		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.0623753648225573 | validation: 0.0643315348784125]
	TIME [epoch: 8.35 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11813919580837787		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.11813919580837787 | validation: 0.09303024071967679]
	TIME [epoch: 8.34 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07350512762913183		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.07350512762913183 | validation: 0.06179249946692528]
	TIME [epoch: 8.33 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07785924894374227		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.07785924894374227 | validation: 0.08114046270387786]
	TIME [epoch: 8.34 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06103993299846742		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.06103993299846742 | validation: 0.17720015274690656]
	TIME [epoch: 8.35 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11987765742468585		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.11987765742468585 | validation: 0.07161937567815137]
	TIME [epoch: 8.34 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0686532099684875		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.0686532099684875 | validation: 0.10023415231121102]
	TIME [epoch: 8.34 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0924333710135162		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.0924333710135162 | validation: 0.07832849143507266]
	TIME [epoch: 8.33 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0738442868488155		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.0738442868488155 | validation: 0.09119700285323518]
	TIME [epoch: 8.35 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07466400305989303		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.07466400305989303 | validation: 0.061900878843901316]
	TIME [epoch: 8.33 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941742225190847		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.06941742225190847 | validation: 0.09491166235972623]
	TIME [epoch: 8.33 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08640064546294425		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.08640064546294425 | validation: 0.10308262067719326]
	TIME [epoch: 8.33 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713237550319009		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.0713237550319009 | validation: 0.10172582687822032]
	TIME [epoch: 8.35 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10201984385705054		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.10201984385705054 | validation: 0.1831708524592981]
	TIME [epoch: 8.34 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0932919576370175		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.0932919576370175 | validation: 0.06827897872114144]
	TIME [epoch: 8.34 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0700356680214336		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.0700356680214336 | validation: 0.04617710031800451]
	TIME [epoch: 8.33 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0518551131157716		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.0518551131157716 | validation: 0.05145225291106602]
	TIME [epoch: 8.36 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06317829619326079		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.06317829619326079 | validation: 0.08996253407025463]
	TIME [epoch: 8.33 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08097150396805061		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.08097150396805061 | validation: 0.0851821642027362]
	TIME [epoch: 8.33 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632876016344243		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.06632876016344243 | validation: 0.05358860601239229]
	TIME [epoch: 8.33 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06296119397412389		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.06296119397412389 | validation: 0.0848951344382756]
	TIME [epoch: 8.35 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11160319279763731		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.11160319279763731 | validation: 0.07848738162468603]
	TIME [epoch: 8.34 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127892261534965		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.07127892261534965 | validation: 0.0670915906783671]
	TIME [epoch: 8.33 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941639180378004		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.06941639180378004 | validation: 0.135503012679735]
	TIME [epoch: 8.33 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07061674629764478		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.07061674629764478 | validation: 0.1016338926641042]
	TIME [epoch: 8.35 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720950057005335		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.0720950057005335 | validation: 0.04964911739867947]
	TIME [epoch: 8.34 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903875232498801		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.05903875232498801 | validation: 0.0577748806048249]
	TIME [epoch: 8.33 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06480287569014166		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.06480287569014166 | validation: 0.061044349356285214]
	TIME [epoch: 8.33 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07292498813135725		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.07292498813135725 | validation: 0.10440534407972513]
	TIME [epoch: 8.35 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08109383451062281		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.08109383451062281 | validation: 0.07854845481429179]
	TIME [epoch: 8.34 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803557569214086		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.0803557569214086 | validation: 0.05194012784009942]
	TIME [epoch: 8.34 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06734838756428682		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.06734838756428682 | validation: 0.08012806550245362]
	TIME [epoch: 8.33 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07634472264932222		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.07634472264932222 | validation: 0.06701549027876032]
	TIME [epoch: 8.35 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0738788472273248		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.0738788472273248 | validation: 0.10556500516184399]
	TIME [epoch: 8.34 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875782505102327		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.07875782505102327 | validation: 0.10131135466605266]
	TIME [epoch: 8.34 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533932856766543		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.06533932856766543 | validation: 0.06841498226952458]
	TIME [epoch: 8.34 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058739756556377455		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.058739756556377455 | validation: 0.08672762528855181]
	TIME [epoch: 8.36 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06795802698050317		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.06795802698050317 | validation: 0.08749574879360461]
	TIME [epoch: 8.34 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07010509545729895		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.07010509545729895 | validation: 0.10600897674658016]
	TIME [epoch: 8.33 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07569236971926219		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.07569236971926219 | validation: 0.0605726980964974]
	TIME [epoch: 8.34 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09970364495687692		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.09970364495687692 | validation: 0.08138049751646409]
	TIME [epoch: 8.35 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06276885802126603		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.06276885802126603 | validation: 0.07321831873338065]
	TIME [epoch: 8.33 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05460061650093978		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.05460061650093978 | validation: 0.10710839783280449]
	TIME [epoch: 8.33 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08605720896382223		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.08605720896382223 | validation: 0.08322664448157036]
	TIME [epoch: 8.33 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057137274908433844		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.057137274908433844 | validation: 0.05155626129585554]
	TIME [epoch: 8.35 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05794535505730593		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.05794535505730593 | validation: 0.062339618385281306]
	TIME [epoch: 8.34 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07700360495571759		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.07700360495571759 | validation: 0.08890486019971422]
	TIME [epoch: 8.34 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08457999827883687		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.08457999827883687 | validation: 0.08687371053638675]
	TIME [epoch: 8.34 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05736109654805188		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.05736109654805188 | validation: 0.08388770942493282]
	TIME [epoch: 8.36 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06742991788629447		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.06742991788629447 | validation: 0.0868619760241039]
	TIME [epoch: 8.34 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05816392185792174		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.05816392185792174 | validation: 0.08754175367828249]
	TIME [epoch: 8.34 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05756595749519855		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.05756595749519855 | validation: 0.0625156117127577]
	TIME [epoch: 8.34 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07474104812518585		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.07474104812518585 | validation: 0.14854070874382785]
	TIME [epoch: 8.36 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11134994201147394		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.11134994201147394 | validation: 0.06384327865022053]
	TIME [epoch: 8.34 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058864319794995665		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.058864319794995665 | validation: 0.11385799976949333]
	TIME [epoch: 8.34 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08854338990492391		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.08854338990492391 | validation: 0.07977673936071793]
	TIME [epoch: 8.34 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06425909141300255		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.06425909141300255 | validation: 0.08647419105980025]
	TIME [epoch: 8.35 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07276632250099482		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.07276632250099482 | validation: 0.10314759672635129]
	TIME [epoch: 8.34 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0879270750340394		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.0879270750340394 | validation: 0.07048546281082514]
	TIME [epoch: 8.34 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06669574850097135		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.06669574850097135 | validation: 0.05490545783477074]
	TIME [epoch: 8.34 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05586639243612138		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.05586639243612138 | validation: 0.07324453732673133]
	TIME [epoch: 8.36 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07355437177783311		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.07355437177783311 | validation: 0.06642052899376312]
	TIME [epoch: 8.34 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06034370885752751		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.06034370885752751 | validation: 0.07310712842174844]
	TIME [epoch: 8.34 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743698805235865		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.09743698805235865 | validation: 0.04913029116828535]
	TIME [epoch: 8.34 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11412165163694436		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.11412165163694436 | validation: 0.07546943264620248]
	TIME [epoch: 8.36 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07204614255735513		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.07204614255735513 | validation: 0.07380497033185447]
	TIME [epoch: 8.34 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06115107236312793		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.06115107236312793 | validation: 0.06682172563062103]
	TIME [epoch: 8.33 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516864858067928		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.06516864858067928 | validation: 0.08144086226137026]
	TIME [epoch: 8.33 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08559406174381003		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.08559406174381003 | validation: 0.1014052114279835]
	TIME [epoch: 8.35 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0744880635604926		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.0744880635604926 | validation: 0.05657005769139818]
	TIME [epoch: 8.33 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874758546689497		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.05874758546689497 | validation: 0.08971622878113107]
	TIME [epoch: 8.33 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07317302906336845		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.07317302906336845 | validation: 0.08780009974945271]
	TIME [epoch: 8.34 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07539941060368398		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.07539941060368398 | validation: 0.13919356315472947]
	TIME [epoch: 8.34 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10581969703488348		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.10581969703488348 | validation: 0.13260995411806187]
	TIME [epoch: 8.34 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07968512408811439		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.07968512408811439 | validation: 0.07396488871413752]
	TIME [epoch: 8.33 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06335259171909048		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.06335259171909048 | validation: 0.07331870535258422]
	TIME [epoch: 8.34 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054553626030029556		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.054553626030029556 | validation: 0.07397748383100641]
	TIME [epoch: 8.35 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.068821818002171		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.068821818002171 | validation: 0.09306212984761564]
	TIME [epoch: 8.33 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07866455850465108		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.07866455850465108 | validation: 0.08065608408041182]
	TIME [epoch: 8.33 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0709004978519842		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.0709004978519842 | validation: 0.08753024007521654]
	TIME [epoch: 8.34 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06287169960475655		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.06287169960475655 | validation: 0.1201018681974623]
	TIME [epoch: 8.35 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06877164190345536		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.06877164190345536 | validation: 0.07240933699238024]
	TIME [epoch: 8.33 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050596781628088304		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.050596781628088304 | validation: 0.05288566186474849]
	TIME [epoch: 8.33 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06484891746635234		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.06484891746635234 | validation: 0.06923996903096372]
	TIME [epoch: 8.34 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0744372386239144		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.0744372386239144 | validation: 0.06447772192891957]
	TIME [epoch: 8.34 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054304405127392874		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.054304405127392874 | validation: 0.06379857393452598]
	TIME [epoch: 8.34 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489246201805854		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.06489246201805854 | validation: 0.09162049607042357]
	TIME [epoch: 8.33 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0857134062832029		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.0857134062832029 | validation: 0.1441390123219905]
	TIME [epoch: 8.34 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136912476225657		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.07136912476225657 | validation: 0.09083031763483845]
	TIME [epoch: 8.34 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07765762303478975		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.07765762303478975 | validation: 0.10891887266399726]
	TIME [epoch: 8.33 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09851796200869951		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.09851796200869951 | validation: 0.07826433217399309]
	TIME [epoch: 8.33 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1084411444288399		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.1084411444288399 | validation: 0.0802783940909384]
	TIME [epoch: 8.35 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06296423864078962		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.06296423864078962 | validation: 0.06427183677942945]
	TIME [epoch: 8.33 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05164297960411315		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.05164297960411315 | validation: 0.0852305184492605]
	TIME [epoch: 8.33 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08485032686201535		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.08485032686201535 | validation: 0.11686389171253643]
	TIME [epoch: 8.33 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778348501372636		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.0778348501372636 | validation: 0.12946275297600301]
	TIME [epoch: 8.35 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566524208964941		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.06566524208964941 | validation: 0.08229152523301249]
	TIME [epoch: 8.33 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215023423952178		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.07215023423952178 | validation: 0.08400111700220945]
	TIME [epoch: 8.33 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0568919495389397		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.0568919495389397 | validation: 0.08321754480902224]
	TIME [epoch: 8.33 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06911384822202783		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.06911384822202783 | validation: 0.18309734426429702]
	TIME [epoch: 8.35 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066068358372277		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.07066068358372277 | validation: 0.06678848422551989]
	TIME [epoch: 8.34 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656274205793968		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.08656274205793968 | validation: 0.09227078122813057]
	TIME [epoch: 8.34 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07261570798691616		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.07261570798691616 | validation: 0.06300082878625382]
	TIME [epoch: 8.33 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07178076623593774		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.07178076623593774 | validation: 0.08191122955645203]
	TIME [epoch: 8.35 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07711117466751241		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.07711117466751241 | validation: 0.08886417836948665]
	TIME [epoch: 8.33 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0620342657083916		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.0620342657083916 | validation: 0.08073455195910584]
	TIME [epoch: 8.33 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0680249999685599		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.0680249999685599 | validation: 0.10515743517424558]
	TIME [epoch: 8.33 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06374403134873279		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.06374403134873279 | validation: 0.07223040898063826]
	TIME [epoch: 8.35 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056315887554102		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.07056315887554102 | validation: 0.15520151648836683]
	TIME [epoch: 8.33 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06593520196575645		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.06593520196575645 | validation: 0.07407442420643244]
	TIME [epoch: 8.33 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868012081125988		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.06868012081125988 | validation: 0.07012980945446645]
	TIME [epoch: 8.33 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06713545856538475		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.06713545856538475 | validation: 0.07705766099087895]
	TIME [epoch: 8.35 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0561392662519302		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.0561392662519302 | validation: 0.12727978612077628]
	TIME [epoch: 8.33 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06368729691978306		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.06368729691978306 | validation: 0.06590198914650341]
	TIME [epoch: 8.33 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245914240792767		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.06245914240792767 | validation: 0.08859218474538061]
	TIME [epoch: 8.33 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07152723520848134		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.07152723520848134 | validation: 0.14390811793499153]
	TIME [epoch: 8.35 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10130488395035045		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.10130488395035045 | validation: 0.08901238497858488]
	TIME [epoch: 8.33 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06572287528918504		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.06572287528918504 | validation: 0.07583814165457825]
	TIME [epoch: 8.33 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08806244857741981		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.08806244857741981 | validation: 0.0750825658058516]
	TIME [epoch: 8.33 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643401119564029		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.0643401119564029 | validation: 0.04994521714537849]
	TIME [epoch: 8.35 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045248153751429085		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.045248153751429085 | validation: 0.05439411718940171]
	TIME [epoch: 8.34 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050620634915661364		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.050620634915661364 | validation: 0.056191310557164184]
	TIME [epoch: 8.33 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045852669237037805		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.045852669237037805 | validation: 0.09494064651523909]
	TIME [epoch: 8.33 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06598260770448247		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.06598260770448247 | validation: 0.09429547927308451]
	TIME [epoch: 8.35 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060464314459394555		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.060464314459394555 | validation: 0.06688644903880454]
	TIME [epoch: 8.34 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054434380737498414		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.054434380737498414 | validation: 0.0653751179385571]
	TIME [epoch: 8.33 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06365412590362006		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.06365412590362006 | validation: 0.10146170166967568]
	TIME [epoch: 8.34 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05302485085964252		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.05302485085964252 | validation: 0.09384813502229843]
	TIME [epoch: 8.35 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06171300196876297		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.06171300196876297 | validation: 0.0673587153225061]
	TIME [epoch: 8.33 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05022021708236376		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.05022021708236376 | validation: 0.04146444008400692]
	TIME [epoch: 8.33 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05015119526134186		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.05015119526134186 | validation: 0.05401091161142013]
	TIME [epoch: 8.34 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04812969194325627		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.04812969194325627 | validation: 0.11388978915789977]
	TIME [epoch: 8.35 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057217287434730243		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.057217287434730243 | validation: 0.04432920829715427]
	TIME [epoch: 8.34 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054915291110018846		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.054915291110018846 | validation: 0.06329159309462104]
	TIME [epoch: 8.33 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057628331003333956		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.057628331003333956 | validation: 0.11823862551818498]
	TIME [epoch: 8.33 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058871642000490776		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.058871642000490776 | validation: 0.08485420367366427]
	TIME [epoch: 8.35 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682666338907093		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.0682666338907093 | validation: 0.09487071177689296]
	TIME [epoch: 8.34 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07293845126385255		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.07293845126385255 | validation: 0.07844320707832696]
	TIME [epoch: 8.33 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0605932087005587		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.0605932087005587 | validation: 0.0796948238508193]
	TIME [epoch: 8.33 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08430767339164218		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.08430767339164218 | validation: 0.05959388992734645]
	TIME [epoch: 8.35 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07751908424068582		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.07751908424068582 | validation: 0.05325802875355471]
	TIME [epoch: 8.34 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819209232803972		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.05819209232803972 | validation: 0.07413654157900107]
	TIME [epoch: 8.33 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06771245914885156		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.06771245914885156 | validation: 0.057310139261984666]
	TIME [epoch: 8.33 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05064787917678772		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.05064787917678772 | validation: 0.06768676053687206]
	TIME [epoch: 8.35 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06079137893778015		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.06079137893778015 | validation: 0.07697575853867068]
	TIME [epoch: 8.33 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430388847526661		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.06430388847526661 | validation: 0.08350739434193039]
	TIME [epoch: 8.33 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897454860024373		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.06897454860024373 | validation: 0.07536898177646553]
	TIME [epoch: 8.33 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06802232647960663		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.06802232647960663 | validation: 0.0876384645570503]
	TIME [epoch: 8.35 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525156682525338		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.06525156682525338 | validation: 0.08628934485146307]
	TIME [epoch: 8.34 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06630117559587353		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.06630117559587353 | validation: 0.07348291540591957]
	TIME [epoch: 8.33 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060019899483091624		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.060019899483091624 | validation: 0.09286494823651124]
	TIME [epoch: 8.33 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061816760399887684		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.061816760399887684 | validation: 0.05522995826234129]
	TIME [epoch: 8.35 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06381439384894075		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.06381439384894075 | validation: 0.06293074206384441]
	TIME [epoch: 8.33 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07107291016209617		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.07107291016209617 | validation: 0.07278240438009632]
	TIME [epoch: 8.33 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08154584931153927		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.08154584931153927 | validation: 0.05536173336687522]
	TIME [epoch: 8.33 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06640918533655182		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.06640918533655182 | validation: 0.07819457056675269]
	TIME [epoch: 8.35 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08625166866440906		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.08625166866440906 | validation: 0.08504572915926864]
	TIME [epoch: 8.33 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07203019063440569		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.07203019063440569 | validation: 0.07634936321611041]
	TIME [epoch: 8.33 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07461772518277789		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.07461772518277789 | validation: 0.0733652762969782]
	TIME [epoch: 8.33 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06728741902424883		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.06728741902424883 | validation: 0.06347278772937322]
	TIME [epoch: 8.35 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07729841173374781		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.07729841173374781 | validation: 0.056789170116626125]
	TIME [epoch: 8.33 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07388041129890328		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.07388041129890328 | validation: 0.07709690398091212]
	TIME [epoch: 8.33 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07138697697721717		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.07138697697721717 | validation: 0.08957500899129477]
	TIME [epoch: 8.33 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06606286179171764		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.06606286179171764 | validation: 0.10466536695512577]
	TIME [epoch: 8.35 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0815234974886125		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.0815234974886125 | validation: 0.3059498112185486]
	TIME [epoch: 8.33 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10604468527352276		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.10604468527352276 | validation: 0.05420765633909132]
	TIME [epoch: 8.33 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038696592816627774		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.038696592816627774 | validation: 0.04411920898421828]
	TIME [epoch: 8.33 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05705238885600765		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.05705238885600765 | validation: 0.09116379275435366]
	TIME [epoch: 8.35 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05731594535849218		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.05731594535849218 | validation: 0.07926434126567725]
	TIME [epoch: 8.33 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06768367877608951		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.06768367877608951 | validation: 0.07516523719022512]
	TIME [epoch: 8.33 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07338371936035551		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.07338371936035551 | validation: 0.07224330464197223]
	TIME [epoch: 8.33 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057226020405131604		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.057226020405131604 | validation: 0.08216157102310956]
	TIME [epoch: 8.35 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042362422498804245		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.042362422498804245 | validation: 0.05558178281523271]
	TIME [epoch: 8.33 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04608125214272911		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.04608125214272911 | validation: 0.09193824241990392]
	TIME [epoch: 8.33 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0574213360959817		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.0574213360959817 | validation: 0.04106773509266996]
	TIME [epoch: 8.33 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042523933426393386		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.042523933426393386 | validation: 0.060377310245917595]
	TIME [epoch: 8.35 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06345285713905893		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.06345285713905893 | validation: 0.04894816710180921]
	TIME [epoch: 8.33 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06196478806577432		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.06196478806577432 | validation: 0.053749743411783985]
	TIME [epoch: 8.33 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05435798218499033		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.05435798218499033 | validation: 0.11678088024600064]
	TIME [epoch: 8.33 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09929391895526683		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.09929391895526683 | validation: 0.09053517312237819]
	TIME [epoch: 8.35 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940783105722949		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.0940783105722949 | validation: 0.07811521825154966]
	TIME [epoch: 8.33 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08582180199806347		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.08582180199806347 | validation: 0.09059109854731334]
	TIME [epoch: 8.34 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460284791456403		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.09460284791456403 | validation: 0.13060968954433338]
	TIME [epoch: 8.33 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0894787689624975		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.0894787689624975 | validation: 0.11431914541847821]
	TIME [epoch: 8.35 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11566387686616297		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.11566387686616297 | validation: 0.13074113635945853]
	TIME [epoch: 8.33 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291175759427437		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.1291175759427437 | validation: 0.09279154086359187]
	TIME [epoch: 8.33 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794052039462596		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.06794052039462596 | validation: 0.0678155784939922]
	TIME [epoch: 8.33 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055913734336383226		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.055913734336383226 | validation: 0.060358901749267446]
	TIME [epoch: 8.35 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05551027370498627		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.05551027370498627 | validation: 0.08097902478821833]
	TIME [epoch: 8.33 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052448499973984965		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.052448499973984965 | validation: 0.04405627801230442]
	TIME [epoch: 8.33 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06026232630981791		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.06026232630981791 | validation: 0.10937593305186885]
	TIME [epoch: 8.33 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06368336848881218		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.06368336848881218 | validation: 0.08930425346739407]
	TIME [epoch: 8.35 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05802779721150728		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.05802779721150728 | validation: 0.07780529666999646]
	TIME [epoch: 8.33 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08017845108470341		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.08017845108470341 | validation: 0.053932686458721735]
	TIME [epoch: 8.33 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062333811332428414		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.062333811332428414 | validation: 0.04264024291380891]
	TIME [epoch: 8.33 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04488104916829392		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.04488104916829392 | validation: 0.04898354929200115]
	TIME [epoch: 8.35 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056420033437799146		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.056420033437799146 | validation: 0.04775800022586736]
	TIME [epoch: 8.33 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05082006141069597		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.05082006141069597 | validation: 0.06522206964080568]
	TIME [epoch: 8.33 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06964820039032546		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.06964820039032546 | validation: 0.06965461601781685]
	TIME [epoch: 8.33 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874133890280282		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.05874133890280282 | validation: 0.06970723677617435]
	TIME [epoch: 8.35 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07146747781970471		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.07146747781970471 | validation: 0.05940973624493276]
	TIME [epoch: 8.33 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05129605996254959		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.05129605996254959 | validation: 0.111543529272431]
	TIME [epoch: 8.33 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04979141737646495		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.04979141737646495 | validation: 0.051552485375383414]
	TIME [epoch: 8.33 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056443166643345886		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.056443166643345886 | validation: 0.07718576903295435]
	TIME [epoch: 8.35 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06396391733561207		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.06396391733561207 | validation: 0.06244072325644548]
	TIME [epoch: 8.33 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051297664054967905		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.051297664054967905 | validation: 0.09091129281703686]
	TIME [epoch: 8.33 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06017578638612484		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.06017578638612484 | validation: 0.05860605162083288]
	TIME [epoch: 8.33 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06841803493394476		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.06841803493394476 | validation: 0.07622952262922067]
	TIME [epoch: 8.35 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0488758747406652		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.0488758747406652 | validation: 0.057562584740344876]
	TIME [epoch: 8.34 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04450122656492845		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.04450122656492845 | validation: 0.06841341344706804]
	TIME [epoch: 8.34 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06520739170773203		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.06520739170773203 | validation: 0.08807742089595685]
	TIME [epoch: 8.34 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06053007944204947		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.06053007944204947 | validation: 0.10167370261172388]
	TIME [epoch: 8.34 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07010847030878244		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.07010847030878244 | validation: 0.08078300344570208]
	TIME [epoch: 8.33 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057264193316162657		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.057264193316162657 | validation: 0.07214566389526174]
	TIME [epoch: 8.33 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059780594177406464		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.059780594177406464 | validation: 0.06111547807919176]
	TIME [epoch: 8.34 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03501783117215289		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.03501783117215289 | validation: 0.059518912402091756]
	TIME [epoch: 8.34 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304163739354654		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.06304163739354654 | validation: 0.05834211632399254]
	TIME [epoch: 8.34 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853770419624832		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.05853770419624832 | validation: 0.06973115332991171]
	TIME [epoch: 8.33 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06248444378729533		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.06248444378729533 | validation: 0.10001784163734187]
	TIME [epoch: 8.34 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046824353217637546		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.046824353217637546 | validation: 0.05611755183014612]
	TIME [epoch: 8.35 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857801121420554		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.06857801121420554 | validation: 0.04462507075106025]
	TIME [epoch: 8.33 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677283240792049		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.0677283240792049 | validation: 0.06848196921820987]
	TIME [epoch: 8.33 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04640776659665506		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.04640776659665506 | validation: 0.0308969552678621]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1242.pth
	Model improved!!!
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053022721831976816		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.053022721831976816 | validation: 0.07091327130010869]
	TIME [epoch: 8.36 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061528209785427744		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.061528209785427744 | validation: 0.07089990361352724]
	TIME [epoch: 8.34 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0556120521714221		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.0556120521714221 | validation: 0.061017877158619435]
	TIME [epoch: 8.35 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04622041137905425		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.04622041137905425 | validation: 0.062242235771762085]
	TIME [epoch: 8.36 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359278791885667		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.05359278791885667 | validation: 0.05945554326957561]
	TIME [epoch: 8.35 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04064797445453398		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.04064797445453398 | validation: 0.05643620534735237]
	TIME [epoch: 8.34 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05182158596062022		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.05182158596062022 | validation: 0.06614224859595504]
	TIME [epoch: 8.34 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04548947962233781		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.04548947962233781 | validation: 0.0490931454764129]
	TIME [epoch: 8.36 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040622094605813494		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.040622094605813494 | validation: 0.0594083054315121]
	TIME [epoch: 8.35 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0404746349379239		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.0404746349379239 | validation: 0.07940694418786516]
	TIME [epoch: 8.34 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041713760687762946		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.041713760687762946 | validation: 0.08589836254518916]
	TIME [epoch: 8.34 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04244039168020937		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.04244039168020937 | validation: 0.04899307699838145]
	TIME [epoch: 8.36 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04886315502713074		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.04886315502713074 | validation: 0.0521029163886485]
	TIME [epoch: 8.35 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0428408811995091		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.0428408811995091 | validation: 0.07188437514000612]
	TIME [epoch: 8.35 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038868307736551026		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.038868307736551026 | validation: 0.06336912918225651]
	TIME [epoch: 8.34 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05453192178379858		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.05453192178379858 | validation: 0.041987830541254406]
	TIME [epoch: 8.36 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04654612199685447		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.04654612199685447 | validation: 0.04351135799274139]
	TIME [epoch: 8.35 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043535946533633886		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.043535946533633886 | validation: 0.06072033192390048]
	TIME [epoch: 8.34 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03407274064989918		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.03407274064989918 | validation: 0.03289008207907051]
	TIME [epoch: 8.35 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04345760337408248		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.04345760337408248 | validation: 0.058805932632028025]
	TIME [epoch: 8.36 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059110173128505195		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.059110173128505195 | validation: 0.04282574407651414]
	TIME [epoch: 8.35 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03549665305767457		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.03549665305767457 | validation: 0.05084212505181432]
	TIME [epoch: 8.34 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047091172324890816		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.047091172324890816 | validation: 0.05937739223270316]
	TIME [epoch: 8.34 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06373939944705903		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.06373939944705903 | validation: 0.059543397904762665]
	TIME [epoch: 8.36 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04742508495951472		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.04742508495951472 | validation: 0.060872828568829376]
	TIME [epoch: 8.35 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06192931409084412		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.06192931409084412 | validation: 0.05893535600652049]
	TIME [epoch: 8.34 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054236223681154175		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.054236223681154175 | validation: 0.03414995609995897]
	TIME [epoch: 8.34 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050574105639984254		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.050574105639984254 | validation: 0.07094651383047133]
	TIME [epoch: 8.36 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05626654317533042		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.05626654317533042 | validation: 0.05755248735168038]
	TIME [epoch: 8.35 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05502630927005538		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.05502630927005538 | validation: 0.06290279756100312]
	TIME [epoch: 8.34 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040881356857544654		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.040881356857544654 | validation: 0.08924501247482397]
	TIME [epoch: 8.35 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04285764993944087		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.04285764993944087 | validation: 0.050857180273419955]
	TIME [epoch: 8.36 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04536825198831419		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.04536825198831419 | validation: 0.0705593129778286]
	TIME [epoch: 8.35 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04276738047707914		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.04276738047707914 | validation: 0.04801447773506026]
	TIME [epoch: 8.35 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0472495159933226		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.0472495159933226 | validation: 0.05555457845594371]
	TIME [epoch: 8.34 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137265830664994		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.05137265830664994 | validation: 0.07798833743607644]
	TIME [epoch: 8.36 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05752145244377038		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.05752145244377038 | validation: 0.07220358362831712]
	TIME [epoch: 8.35 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061232978980247446		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.061232978980247446 | validation: 0.061059732592534485]
	TIME [epoch: 8.35 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054134231559243184		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.054134231559243184 | validation: 0.08094038053285343]
	TIME [epoch: 8.34 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986120554848195		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.0986120554848195 | validation: 0.06645844044135032]
	TIME [epoch: 8.36 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221155608334542		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.06221155608334542 | validation: 0.08732810474985286]
	TIME [epoch: 8.35 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06628622283003179		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.06628622283003179 | validation: 0.04703167905145293]
	TIME [epoch: 8.34 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05328186606313824		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.05328186606313824 | validation: 0.05332908043768863]
	TIME [epoch: 8.34 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04386068207413075		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.04386068207413075 | validation: 0.058709859471626366]
	TIME [epoch: 8.36 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042059997913614776		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.042059997913614776 | validation: 0.04464795438528452]
	TIME [epoch: 8.35 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039540552814297025		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.039540552814297025 | validation: 0.04833169160142903]
	TIME [epoch: 8.34 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054847753864978775		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.054847753864978775 | validation: 0.06721157280122125]
	TIME [epoch: 8.34 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05604254031435689		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.05604254031435689 | validation: 0.04447582306632533]
	TIME [epoch: 8.36 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05731241637691895		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.05731241637691895 | validation: 0.059588108259244335]
	TIME [epoch: 8.35 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04427934434675648		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.04427934434675648 | validation: 0.05786946073675664]
	TIME [epoch: 8.35 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04457123775245277		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.04457123775245277 | validation: 0.05945522549733316]
	TIME [epoch: 8.34 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674562206798468		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.05674562206798468 | validation: 0.07541950916893908]
	TIME [epoch: 8.36 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06527881419076417		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.06527881419076417 | validation: 0.04931450082635172]
	TIME [epoch: 8.35 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05120323232772915		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.05120323232772915 | validation: 0.04113584889346893]
	TIME [epoch: 8.34 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054198483490700985		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.054198483490700985 | validation: 0.03392830218943163]
	TIME [epoch: 8.34 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04462475038166171		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.04462475038166171 | validation: 0.031015950170054908]
	TIME [epoch: 8.36 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032791217686675006		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.032791217686675006 | validation: 0.047132427375167124]
	TIME [epoch: 8.34 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04293048836910081		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.04293048836910081 | validation: 0.03169187235377216]
	TIME [epoch: 8.34 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03421319217568787		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.03421319217568787 | validation: 0.07091045311547747]
	TIME [epoch: 8.34 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04326125546498121		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.04326125546498121 | validation: 0.04757215625603994]
	TIME [epoch: 8.36 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04165309838884292		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.04165309838884292 | validation: 0.050879682200952736]
	TIME [epoch: 8.34 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05634450256049871		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.05634450256049871 | validation: 0.046632405073556496]
	TIME [epoch: 8.34 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052058769907096326		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.052058769907096326 | validation: 0.08030927896758444]
	TIME [epoch: 8.34 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043467204438403254		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.043467204438403254 | validation: 0.04240318503301773]
	TIME [epoch: 8.36 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04109330683442465		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.04109330683442465 | validation: 0.03464793888003728]
	TIME [epoch: 8.34 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0426127021182152		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.0426127021182152 | validation: 0.046866609222405084]
	TIME [epoch: 8.34 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055080174182407446		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.055080174182407446 | validation: 0.06107310623891782]
	TIME [epoch: 8.34 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03807632823454117		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.03807632823454117 | validation: 0.034670888429594454]
	TIME [epoch: 8.36 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05293313256983169		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.05293313256983169 | validation: 0.07316325216396745]
	TIME [epoch: 8.35 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03890358264905988		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.03890358264905988 | validation: 0.051810690066433344]
	TIME [epoch: 8.35 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043163621342432526		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.043163621342432526 | validation: 0.07032665729144782]
	TIME [epoch: 8.34 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04574066247364473		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.04574066247364473 | validation: 0.039969399866352395]
	TIME [epoch: 8.37 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035451986276387966		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.035451986276387966 | validation: 0.03575739937640971]
	TIME [epoch: 8.34 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04531807979563227		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.04531807979563227 | validation: 0.057744452518367045]
	TIME [epoch: 8.34 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05375837095373091		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.05375837095373091 | validation: 0.0493228283398675]
	TIME [epoch: 8.34 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06006140372607642		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.06006140372607642 | validation: 0.03893524464139976]
	TIME [epoch: 8.36 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05121640919924573		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.05121640919924573 | validation: 0.04558097331235966]
	TIME [epoch: 8.34 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0476509521589122		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.0476509521589122 | validation: 0.05902834820955311]
	TIME [epoch: 8.34 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553872643989331		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.06553872643989331 | validation: 0.0542177078759824]
	TIME [epoch: 8.35 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07006243776239716		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.07006243776239716 | validation: 0.05652227942325801]
	TIME [epoch: 8.36 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07412516990719371		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.07412516990719371 | validation: 0.040131023009204854]
	TIME [epoch: 8.34 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0586634335670557		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.0586634335670557 | validation: 0.040531990763390285]
	TIME [epoch: 8.34 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0474268114976686		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.0474268114976686 | validation: 0.043284397013733114]
	TIME [epoch: 8.34 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05064234729301266		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.05064234729301266 | validation: 0.07315349442445489]
	TIME [epoch: 8.36 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663331540375537		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.0663331540375537 | validation: 0.04160251143256766]
	TIME [epoch: 8.35 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05006517748347137		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.05006517748347137 | validation: 0.034718349144639754]
	TIME [epoch: 8.34 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05581404700447819		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.05581404700447819 | validation: 0.07118090269906255]
	TIME [epoch: 8.35 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07898166215534964		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.07898166215534964 | validation: 0.05656544617271358]
	TIME [epoch: 8.36 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04989107330038815		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.04989107330038815 | validation: 0.04077655568471321]
	TIME [epoch: 8.34 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050076914903215995		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.050076914903215995 | validation: 0.044495132714410364]
	TIME [epoch: 8.34 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05038068663080876		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.05038068663080876 | validation: 0.07203404968658937]
	TIME [epoch: 8.35 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04661028378021241		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.04661028378021241 | validation: 0.06233779305468459]
	TIME [epoch: 8.35 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042464738850352825		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.042464738850352825 | validation: 0.036585419826002955]
	TIME [epoch: 8.34 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03563596348589008		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.03563596348589008 | validation: 0.0720449908549297]
	TIME [epoch: 8.34 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04352990751858851		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.04352990751858851 | validation: 0.048118509477794835]
	TIME [epoch: 8.35 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508377720353809		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.03508377720353809 | validation: 0.04553532130823963]
	TIME [epoch: 8.35 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06149128529683199		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.06149128529683199 | validation: 0.07010916361632771]
	TIME [epoch: 8.34 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03816206000743405		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.03816206000743405 | validation: 0.04379896772433282]
	TIME [epoch: 8.34 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0384524047326104		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.0384524047326104 | validation: 0.04201896596647517]
	TIME [epoch: 8.35 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03160257489149939		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.03160257489149939 | validation: 0.0456580759498634]
	TIME [epoch: 8.35 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040068590865986374		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.040068590865986374 | validation: 0.04913031376159313]
	TIME [epoch: 8.34 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04643337027322552		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.04643337027322552 | validation: 0.08497562330699861]
	TIME [epoch: 8.34 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06257667609977266		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.06257667609977266 | validation: 0.04652031369879535]
	TIME [epoch: 8.35 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0391733811304513		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.0391733811304513 | validation: 0.03663175958781514]
	TIME [epoch: 8.35 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032083027006126655		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.032083027006126655 | validation: 0.055714326294318196]
	TIME [epoch: 8.34 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04557309506394811		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.04557309506394811 | validation: 0.045528990418548604]
	TIME [epoch: 8.34 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03542889278356691		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.03542889278356691 | validation: 0.04678363662632627]
	TIME [epoch: 8.36 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043788343010304355		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.043788343010304355 | validation: 0.05464559098564954]
	TIME [epoch: 8.34 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06931209226469795		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.06931209226469795 | validation: 0.04164068146239233]
	TIME [epoch: 8.34 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0366297573175564		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.0366297573175564 | validation: 0.03644501811249266]
	TIME [epoch: 8.34 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04688678695217542		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.04688678695217542 | validation: 0.0805307194029436]
	TIME [epoch: 8.36 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06600103926524732		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.06600103926524732 | validation: 0.05760482815584705]
	TIME [epoch: 8.34 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04431513707441738		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.04431513707441738 | validation: 0.07221202549545971]
	TIME [epoch: 8.34 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06054053259828311		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.06054053259828311 | validation: 0.045314477923024746]
	TIME [epoch: 8.34 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04457787865194189		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.04457787865194189 | validation: 0.05276330200861233]
	TIME [epoch: 8.36 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05561706190643706		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.05561706190643706 | validation: 0.06304239783937303]
	TIME [epoch: 8.34 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05344597530145064		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.05344597530145064 | validation: 0.07044531653866556]
	TIME [epoch: 8.34 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058892740167177396		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.058892740167177396 | validation: 0.10728114766931374]
	TIME [epoch: 8.34 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06047954230693821		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.06047954230693821 | validation: 0.09641834374567293]
	TIME [epoch: 8.35 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05452083064689524		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.05452083064689524 | validation: 0.05757807958839982]
	TIME [epoch: 8.34 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055294504032049385		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.055294504032049385 | validation: 0.06094444717410597]
	TIME [epoch: 8.34 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03660912904533461		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.03660912904533461 | validation: 0.05714742884238717]
	TIME [epoch: 8.34 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04132804031983591		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.04132804031983591 | validation: 0.059853749955759525]
	TIME [epoch: 8.36 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0382369513272859		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.0382369513272859 | validation: 0.04163726422692207]
	TIME [epoch: 8.34 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04373647421568368		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.04373647421568368 | validation: 0.04042280543959016]
	TIME [epoch: 8.34 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03489425819796195		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.03489425819796195 | validation: 0.07312915514531759]
	TIME [epoch: 8.33 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04030565339322799		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.04030565339322799 | validation: 0.05081931329484504]
	TIME [epoch: 8.36 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04516303000214056		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.04516303000214056 | validation: 0.0760554524551614]
	TIME [epoch: 8.34 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03573351006239484		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.03573351006239484 | validation: 0.03626382649740102]
	TIME [epoch: 8.34 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03409327437291172		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.03409327437291172 | validation: 0.058213063256967415]
	TIME [epoch: 8.34 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06468849786062074		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.06468849786062074 | validation: 0.0583193654990421]
	TIME [epoch: 8.35 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04586169822203515		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.04586169822203515 | validation: 0.04693925666369461]
	TIME [epoch: 8.34 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0355139121525863		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.0355139121525863 | validation: 0.052811102296916074]
	TIME [epoch: 8.34 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339188345225102		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.04339188345225102 | validation: 0.04556018993765651]
	TIME [epoch: 8.34 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038393909696044046		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.038393909696044046 | validation: 0.04372962617528868]
	TIME [epoch: 8.35 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04739461196995978		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.04739461196995978 | validation: 0.07760755139044409]
	TIME [epoch: 8.34 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057018174736436		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.057018174736436 | validation: 0.06804098350801481]
	TIME [epoch: 8.34 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05263342847967393		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.05263342847967393 | validation: 0.08226345623414061]
	TIME [epoch: 8.34 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04963087081440086		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.04963087081440086 | validation: 0.04899949685041262]
	TIME [epoch: 8.35 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05207664365690416		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.05207664365690416 | validation: 0.07322910438812037]
	TIME [epoch: 8.34 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04502946852356691		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.04502946852356691 | validation: 0.03521565262701153]
	TIME [epoch: 8.34 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387281285790986		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.05387281285790986 | validation: 0.051664083016720555]
	TIME [epoch: 8.34 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056902496918240675		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.056902496918240675 | validation: 0.07172900996092965]
	TIME [epoch: 8.36 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04912454399259461		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.04912454399259461 | validation: 0.0555331890614022]
	TIME [epoch: 8.34 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03779789180461351		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.03779789180461351 | validation: 0.03263300030432696]
	TIME [epoch: 8.34 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03639103018649046		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.03639103018649046 | validation: 0.05957467026371073]
	TIME [epoch: 8.34 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039887021496150074		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.039887021496150074 | validation: 0.04933276010974311]
	TIME [epoch: 8.36 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03809835406328875		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.03809835406328875 | validation: 0.04668492243492934]
	TIME [epoch: 8.34 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047519110695272856		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.047519110695272856 | validation: 0.050832344115369237]
	TIME [epoch: 8.34 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0415983979798609		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.0415983979798609 | validation: 0.045729165530808816]
	TIME [epoch: 8.33 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041379644736670926		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.041379644736670926 | validation: 0.04393391293139755]
	TIME [epoch: 8.36 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035336093256061726		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.035336093256061726 | validation: 0.045833116635962366]
	TIME [epoch: 8.34 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03323921242394895		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.03323921242394895 | validation: 0.03773226331900631]
	TIME [epoch: 8.34 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028146398677743423		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.028146398677743423 | validation: 0.046233315704514694]
	TIME [epoch: 8.34 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04743662759760204		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.04743662759760204 | validation: 0.037144952908985736]
	TIME [epoch: 8.36 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03721603644012875		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.03721603644012875 | validation: 0.04001957242681588]
	TIME [epoch: 8.34 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038195399420860594		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.038195399420860594 | validation: 0.06299616706837266]
	TIME [epoch: 8.34 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04751852249776837		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.04751852249776837 | validation: 0.06276067191920337]
	TIME [epoch: 8.34 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05647564218190683		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.05647564218190683 | validation: 0.06420171664156227]
	TIME [epoch: 8.36 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04064442017728998		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.04064442017728998 | validation: 0.06236779932436089]
	TIME [epoch: 8.34 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04554262736016383		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.04554262736016383 | validation: 0.054184315325091575]
	TIME [epoch: 8.34 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04270858052733746		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.04270858052733746 | validation: 0.1088646361367614]
	TIME [epoch: 8.34 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053528926206089		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.07053528926206089 | validation: 0.07427852837222637]
	TIME [epoch: 8.36 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04563442906302251		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.04563442906302251 | validation: 0.033628009419120475]
	TIME [epoch: 8.34 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028547803145485263		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.028547803145485263 | validation: 0.033059703593029365]
	TIME [epoch: 8.34 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04582720190459467		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.04582720190459467 | validation: 0.04557367014434697]
	TIME [epoch: 8.34 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031981871216560986		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.031981871216560986 | validation: 0.04348977574003175]
	TIME [epoch: 8.36 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04210601923751571		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.04210601923751571 | validation: 0.046671904118350795]
	TIME [epoch: 8.35 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034541638851725946		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.034541638851725946 | validation: 0.06406580203292775]
	TIME [epoch: 8.34 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04378006935740213		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.04378006935740213 | validation: 0.03422864828808397]
	TIME [epoch: 8.34 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038712288013961996		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.038712288013961996 | validation: 0.052598933430025294]
	TIME [epoch: 8.36 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031592724743403786		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.031592724743403786 | validation: 0.04297954173376628]
	TIME [epoch: 8.34 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03923397053017803		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.03923397053017803 | validation: 0.06268180969437952]
	TIME [epoch: 8.35 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04848510553783808		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.04848510553783808 | validation: 0.04668228310923066]
	TIME [epoch: 8.34 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282975703544591		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.04282975703544591 | validation: 0.053811468872142415]
	TIME [epoch: 8.36 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04240534552386273		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.04240534552386273 | validation: 0.06022967865987823]
	TIME [epoch: 8.34 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04027380795221776		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.04027380795221776 | validation: 0.06216510754037734]
	TIME [epoch: 8.34 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06849516190612921		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.06849516190612921 | validation: 0.06253367930446738]
	TIME [epoch: 8.34 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04513137488388068		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.04513137488388068 | validation: 0.03450974983692156]
	TIME [epoch: 8.36 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03396222920307825		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.03396222920307825 | validation: 0.033579170800801215]
	TIME [epoch: 8.34 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04327391325923781		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.04327391325923781 | validation: 0.05723149854586006]
	TIME [epoch: 8.34 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040445496646547056		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.040445496646547056 | validation: 0.049079103126528356]
	TIME [epoch: 8.34 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986287753841183		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.04986287753841183 | validation: 0.03903588085840114]
	TIME [epoch: 8.36 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036505447849715		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.036505447849715 | validation: 0.05030559748663348]
	TIME [epoch: 8.34 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03617593166470408		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.03617593166470408 | validation: 0.04826772861627836]
	TIME [epoch: 8.34 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04141343646627769		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.04141343646627769 | validation: 0.07111366568629934]
	TIME [epoch: 8.34 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924262958474522		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.04924262958474522 | validation: 0.04680725430844268]
	TIME [epoch: 8.36 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04409935169750527		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.04409935169750527 | validation: 0.06710373182773689]
	TIME [epoch: 8.34 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07130606861684183		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.07130606861684183 | validation: 0.05235864531125784]
	TIME [epoch: 8.34 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057694913976366544		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.057694913976366544 | validation: 0.05421285423684945]
	TIME [epoch: 8.34 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04578136873404675		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.04578136873404675 | validation: 0.05463499027734528]
	TIME [epoch: 8.35 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04887014460553868		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.04887014460553868 | validation: 0.06495754187109018]
	TIME [epoch: 8.34 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04746787421033512		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.04746787421033512 | validation: 0.04065362096079093]
	TIME [epoch: 8.34 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03482077487971971		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.03482077487971971 | validation: 0.04232675392457107]
	TIME [epoch: 8.34 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035680347583522995		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.035680347583522995 | validation: 0.05868881261616066]
	TIME [epoch: 8.36 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043045581176192324		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.043045581176192324 | validation: 0.03375740755250361]
	TIME [epoch: 8.34 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04502307317183268		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.04502307317183268 | validation: 0.03894530755058601]
	TIME [epoch: 8.35 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03549030863675594		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.03549030863675594 | validation: 0.0576219635250009]
	TIME [epoch: 8.34 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03983625044581904		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.03983625044581904 | validation: 0.06051777759265681]
	TIME [epoch: 8.36 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04202025687132106		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.04202025687132106 | validation: 0.038056064936746785]
	TIME [epoch: 8.34 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03722556775552915		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.03722556775552915 | validation: 0.03881061872889056]
	TIME [epoch: 8.34 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03767299421160812		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.03767299421160812 | validation: 0.051640080853733464]
	TIME [epoch: 8.34 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0462562189726346		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.0462562189726346 | validation: 0.033988977022407586]
	TIME [epoch: 8.35 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031141895123365664		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.031141895123365664 | validation: 0.03316260558458123]
	TIME [epoch: 8.34 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03902846757624777		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.03902846757624777 | validation: 0.04134425863438975]
	TIME [epoch: 8.34 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03776511076680847		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.03776511076680847 | validation: 0.06164464051463249]
	TIME [epoch: 8.35 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05455107643867837		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.05455107643867837 | validation: 0.040788962015568926]
	TIME [epoch: 8.34 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036218483717382115		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.036218483717382115 | validation: 0.034103730996075984]
	TIME [epoch: 8.34 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03474314561765499		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.03474314561765499 | validation: 0.040173998221348595]
	TIME [epoch: 8.34 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03582167846960095		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.03582167846960095 | validation: 0.05048164941928691]
	TIME [epoch: 8.35 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05009360907206364		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.05009360907206364 | validation: 0.03673678302937823]
	TIME [epoch: 8.35 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04450677136866986		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.04450677136866986 | validation: 0.0474536538716229]
	TIME [epoch: 8.34 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03909527038558688		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.03909527038558688 | validation: 0.051036558806054996]
	TIME [epoch: 8.34 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04258993319629291		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.04258993319629291 | validation: 0.06704412308988447]
	TIME [epoch: 8.35 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06057697229917106		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.06057697229917106 | validation: 0.0642890174589825]
	TIME [epoch: 8.35 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04292055483930278		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.04292055483930278 | validation: 0.037964045121826266]
	TIME [epoch: 8.34 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04464227839366543		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.04464227839366543 | validation: 0.044325129972290545]
	TIME [epoch: 8.34 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05395920636042863		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.05395920636042863 | validation: 0.039132593007157615]
	TIME [epoch: 8.35 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031640638212129306		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.031640638212129306 | validation: 0.031632154298006504]
	TIME [epoch: 8.35 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034184684965088113		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.034184684965088113 | validation: 0.06241891070381417]
	TIME [epoch: 8.34 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03559521146052187		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.03559521146052187 | validation: 0.029747700253122265]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1463.pth
	Model improved!!!
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03989200494436241		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.03989200494436241 | validation: 0.03346623972820084]
	TIME [epoch: 8.35 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03435993139732044		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.03435993139732044 | validation: 0.044061384844621694]
	TIME [epoch: 8.34 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156207781976387		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.05156207781976387 | validation: 0.04329200890723407]
	TIME [epoch: 8.34 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03238855922550557		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.03238855922550557 | validation: 0.0355434994120996]
	TIME [epoch: 8.34 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030012432459130593		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.030012432459130593 | validation: 0.03618289258365111]
	TIME [epoch: 8.35 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03145204356809911		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.03145204356809911 | validation: 0.03822494123480465]
	TIME [epoch: 8.34 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032179101674201474		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.032179101674201474 | validation: 0.05259842926311353]
	TIME [epoch: 8.33 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03757006493239059		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.03757006493239059 | validation: 0.057506381852180904]
	TIME [epoch: 8.33 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03499788657929904		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.03499788657929904 | validation: 0.04658459071987128]
	TIME [epoch: 8.35 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04773009610809024		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.04773009610809024 | validation: 0.0440718106133576]
	TIME [epoch: 8.34 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029797060207641512		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.029797060207641512 | validation: 0.034614544707062815]
	TIME [epoch: 8.34 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03079850945410123		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.03079850945410123 | validation: 0.05496052218114291]
	TIME [epoch: 8.34 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06593300744794263		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.06593300744794263 | validation: 0.03839613971178142]
	TIME [epoch: 8.35 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924220096452944		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.04924220096452944 | validation: 0.04378323040647704]
	TIME [epoch: 8.34 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032193732856516895		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.032193732856516895 | validation: 0.045487213602205784]
	TIME [epoch: 8.34 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0395016544815766		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.0395016544815766 | validation: 0.046102136978473554]
	TIME [epoch: 8.34 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04277367022927363		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.04277367022927363 | validation: 0.041314936301448266]
	TIME [epoch: 8.35 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04283227598377203		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.04283227598377203 | validation: 0.04425190214308575]
	TIME [epoch: 8.34 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03257170930107697		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.03257170930107697 | validation: 0.0390959641741875]
	TIME [epoch: 8.34 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039648172714304285		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.039648172714304285 | validation: 0.06063779471603836]
	TIME [epoch: 8.34 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04314224425245612		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.04314224425245612 | validation: 0.051259862519349456]
	TIME [epoch: 8.35 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049498541497848755		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.049498541497848755 | validation: 0.0451908051973995]
	TIME [epoch: 8.34 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03774152979296251		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.03774152979296251 | validation: 0.045335994717326536]
	TIME [epoch: 8.33 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03749978914557176		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.03749978914557176 | validation: 0.045814381638400806]
	TIME [epoch: 8.33 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03789349274828214		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.03789349274828214 | validation: 0.03426385273826037]
	TIME [epoch: 8.35 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03974738032690765		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.03974738032690765 | validation: 0.05618946840319443]
	TIME [epoch: 8.34 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03610696131633711		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.03610696131633711 | validation: 0.03402818709093903]
	TIME [epoch: 8.34 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03009425936115214		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.03009425936115214 | validation: 0.036671117315414045]
	TIME [epoch: 8.34 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046267086743750976		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.046267086743750976 | validation: 0.04737400643496269]
	TIME [epoch: 8.35 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03716618039690091		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.03716618039690091 | validation: 0.05674635036532792]
	TIME [epoch: 8.34 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04331475195821627		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.04331475195821627 | validation: 0.04708286634529325]
	TIME [epoch: 8.33 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04809368398107747		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.04809368398107747 | validation: 0.06086776232521203]
	TIME [epoch: 8.33 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04753966328154754		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.04753966328154754 | validation: 0.03768035539608022]
	TIME [epoch: 8.36 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674862619848583		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.05674862619848583 | validation: 0.07317371617286793]
	TIME [epoch: 8.34 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07617325923113687		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.07617325923113687 | validation: 0.06425207748733713]
	TIME [epoch: 8.34 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06733484926229821		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.06733484926229821 | validation: 0.051883688678046706]
	TIME [epoch: 8.33 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049850868006100515		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.049850868006100515 | validation: 0.039433175565458514]
	TIME [epoch: 8.35 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050666127278515674		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.050666127278515674 | validation: 0.06513232758298539]
	TIME [epoch: 8.34 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056076996175428995		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.056076996175428995 | validation: 0.0372614865069533]
	TIME [epoch: 8.33 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035845442229648555		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.035845442229648555 | validation: 0.03977515131221987]
	TIME [epoch: 8.33 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033493128796566615		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.033493128796566615 | validation: 0.03097396572617227]
	TIME [epoch: 8.35 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046418011873415745		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.046418011873415745 | validation: 0.05047307876846491]
	TIME [epoch: 8.34 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0355080399566906		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.0355080399566906 | validation: 0.04152334714497643]
	TIME [epoch: 8.33 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04208515089469574		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.04208515089469574 | validation: 0.04862422749503657]
	TIME [epoch: 8.34 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03821561583198648		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.03821561583198648 | validation: 0.0363891900625729]
	TIME [epoch: 8.37 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03641565511415905		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.03641565511415905 | validation: 0.038824600308994775]
	TIME [epoch: 8.34 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03161349448909089		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.03161349448909089 | validation: 0.03882994974368654]
	TIME [epoch: 8.34 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0423912720521143		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.0423912720521143 | validation: 0.054001423994931366]
	TIME [epoch: 8.33 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03703394051747852		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.03703394051747852 | validation: 0.05731515824197213]
	TIME [epoch: 8.35 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04014446015890602		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.04014446015890602 | validation: 0.05491036166273934]
	TIME [epoch: 8.34 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04134859656647133		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.04134859656647133 | validation: 0.037445110354090774]
	TIME [epoch: 8.33 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028271409478998467		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.028271409478998467 | validation: 0.041305801771849504]
	TIME [epoch: 8.33 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042025215447851684		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.042025215447851684 | validation: 0.035816746042845286]
	TIME [epoch: 8.35 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03851673531341252		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.03851673531341252 | validation: 0.04622987389874408]
	TIME [epoch: 8.33 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04081889468992335		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.04081889468992335 | validation: 0.04369361255783603]
	TIME [epoch: 8.33 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03347916490950129		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.03347916490950129 | validation: 0.036545185368250015]
	TIME [epoch: 8.33 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03989808138226368		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.03989808138226368 | validation: 0.06006570425484601]
	TIME [epoch: 8.35 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0386772022094493		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.0386772022094493 | validation: 0.04105823568128458]
	TIME [epoch: 8.34 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03871444518508786		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.03871444518508786 | validation: 0.03205035912289523]
	TIME [epoch: 8.34 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035626758194580055		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.035626758194580055 | validation: 0.05540644608170248]
	TIME [epoch: 8.34 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05410989367339143		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.05410989367339143 | validation: 0.03921984688452516]
	TIME [epoch: 8.35 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03499196614221041		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.03499196614221041 | validation: 0.04457540622353651]
	TIME [epoch: 8.33 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033948187953416545		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.033948187953416545 | validation: 0.030753816146745487]
	TIME [epoch: 8.33 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027736635187092573		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.027736635187092573 | validation: 0.03524375931544457]
	TIME [epoch: 8.33 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03461822340152685		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.03461822340152685 | validation: 0.06331354194403771]
	TIME [epoch: 8.35 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04273474275064515		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.04273474275064515 | validation: 0.045826637723184495]
	TIME [epoch: 8.33 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049986199624632785		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.049986199624632785 | validation: 0.03743293173276624]
	TIME [epoch: 8.34 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04782496673193713		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.04782496673193713 | validation: 0.06278694728391856]
	TIME [epoch: 8.34 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051778094707873534		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.051778094707873534 | validation: 0.058714100091517465]
	TIME [epoch: 8.35 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04233180883019223		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.04233180883019223 | validation: 0.028862785290553167]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1533.pth
	Model improved!!!
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032101957097048335		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.032101957097048335 | validation: 0.04303802595326437]
	TIME [epoch: 8.33 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03621970797835299		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.03621970797835299 | validation: 0.04715159961098134]
	TIME [epoch: 8.33 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027675709373928416		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.027675709373928416 | validation: 0.03177164246213414]
	TIME [epoch: 8.35 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032151711740559745		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.032151711740559745 | validation: 0.04273505712254992]
	TIME [epoch: 8.33 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040405180147712466		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.040405180147712466 | validation: 0.030993988528877692]
	TIME [epoch: 8.33 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03297030610980132		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.03297030610980132 | validation: 0.0380627074920324]
	TIME [epoch: 8.33 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03292426833880411		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.03292426833880411 | validation: 0.04897536222372266]
	TIME [epoch: 8.35 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03770703007494096		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.03770703007494096 | validation: 0.02657686022660949]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1541.pth
	Model improved!!!
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03577214293306115		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.03577214293306115 | validation: 0.04248787032758063]
	TIME [epoch: 8.34 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03374519384296011		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.03374519384296011 | validation: 0.03332180190326225]
	TIME [epoch: 8.34 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03102086905759493		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.03102086905759493 | validation: 0.045169997487796945]
	TIME [epoch: 8.35 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04440100387383862		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.04440100387383862 | validation: 0.07618034566533284]
	TIME [epoch: 8.34 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0398463510720589		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.0398463510720589 | validation: 0.05455876594917796]
	TIME [epoch: 8.34 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04467300342705073		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.04467300342705073 | validation: 0.06510373453709314]
	TIME [epoch: 8.34 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042827879408416494		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.042827879408416494 | validation: 0.05045061723030709]
	TIME [epoch: 8.34 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04158856847973174		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.04158856847973174 | validation: 0.024997869666180082]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1549.pth
	Model improved!!!
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03489602744174683		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.03489602744174683 | validation: 0.03748585260707887]
	TIME [epoch: 8.33 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03056781151369222		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.03056781151369222 | validation: 0.05470273084960367]
	TIME [epoch: 8.35 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04828391488356202		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.04828391488356202 | validation: 0.043446067016153125]
	TIME [epoch: 8.34 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075688561151898		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.04075688561151898 | validation: 0.038595345649761935]
	TIME [epoch: 8.33 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03142154654181559		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.03142154654181559 | validation: 0.037376771703467565]
	TIME [epoch: 8.33 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022912203008065492		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.022912203008065492 | validation: 0.037859327117109765]
	TIME [epoch: 8.35 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025431967162277042		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.025431967162277042 | validation: 0.038909982337929847]
	TIME [epoch: 8.34 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03272458744294386		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.03272458744294386 | validation: 0.04888556281897162]
	TIME [epoch: 8.33 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03272430373235781		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.03272430373235781 | validation: 0.0325008072872279]
	TIME [epoch: 8.34 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03605516976052843		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.03605516976052843 | validation: 0.03417437089009592]
	TIME [epoch: 8.35 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025283202323300752		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.025283202323300752 | validation: 0.03875229641043083]
	TIME [epoch: 8.34 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037168510100661835		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.037168510100661835 | validation: 0.05365086940816839]
	TIME [epoch: 8.33 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03301982350440675		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.03301982350440675 | validation: 0.037898665455607376]
	TIME [epoch: 8.33 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03391752600042105		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.03391752600042105 | validation: 0.037429083119912665]
	TIME [epoch: 8.35 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03740207156417232		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.03740207156417232 | validation: 0.05016196161245709]
	TIME [epoch: 8.33 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032904911383459454		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.032904911383459454 | validation: 0.04891652830123796]
	TIME [epoch: 8.33 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03838927784335836		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.03838927784335836 | validation: 0.04730538009539897]
	TIME [epoch: 8.33 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054742537408796234		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.054742537408796234 | validation: 0.04782918094564109]
	TIME [epoch: 8.35 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034656637088984324		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.034656637088984324 | validation: 0.03339049798760216]
	TIME [epoch: 8.34 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03262947604574641		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.03262947604574641 | validation: 0.04304328621630514]
	TIME [epoch: 8.33 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0336162252948505		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.0336162252948505 | validation: 0.052557688985802375]
	TIME [epoch: 8.33 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027007570337191266		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.027007570337191266 | validation: 0.029445341943358287]
	TIME [epoch: 8.35 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02653887021550705		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.02653887021550705 | validation: 0.044148592736948725]
	TIME [epoch: 8.34 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03760795581736774		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.03760795581736774 | validation: 0.043849097961623354]
	TIME [epoch: 8.34 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03895492787691521		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.03895492787691521 | validation: 0.0398804539993728]
	TIME [epoch: 8.33 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027244036320064703		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.027244036320064703 | validation: 0.0403405919978517]
	TIME [epoch: 8.35 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037836791368219436		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.037836791368219436 | validation: 0.03863112350868068]
	TIME [epoch: 8.34 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029505111326752403		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.029505111326752403 | validation: 0.04013017029519465]
	TIME [epoch: 8.33 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03595690932752729		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.03595690932752729 | validation: 0.04595014451400346]
	TIME [epoch: 8.33 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027150817469172923		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.027150817469172923 | validation: 0.03496770547398267]
	TIME [epoch: 8.35 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025355102877047918		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.025355102877047918 | validation: 0.03353476342795937]
	TIME [epoch: 8.34 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03584742207414198		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.03584742207414198 | validation: 0.0389580925189171]
	TIME [epoch: 8.34 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02707153899268368		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.02707153899268368 | validation: 0.032835028811162396]
	TIME [epoch: 8.33 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03303787637437929		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.03303787637437929 | validation: 0.04129397101748431]
	TIME [epoch: 8.35 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028497769582131165		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.028497769582131165 | validation: 0.03550104615434882]
	TIME [epoch: 8.34 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022934757490893496		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.022934757490893496 | validation: 0.0630068955166107]
	TIME [epoch: 8.34 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0305515065846585		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.0305515065846585 | validation: 0.0373417618782577]
	TIME [epoch: 8.34 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026215746004983054		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.026215746004983054 | validation: 0.04102010382811126]
	TIME [epoch: 8.35 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03594451964345939		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.03594451964345939 | validation: 0.041517471079905575]
	TIME [epoch: 8.33 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031485296132287184		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.031485296132287184 | validation: 0.034695178234334115]
	TIME [epoch: 8.33 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02865129635604567		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.02865129635604567 | validation: 0.03812295129079057]
	TIME [epoch: 8.33 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03206987136860901		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.03206987136860901 | validation: 0.033391620290069195]
	TIME [epoch: 8.35 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03982648030855697		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.03982648030855697 | validation: 0.038575508084614976]
	TIME [epoch: 8.34 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040992744019967005		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.040992744019967005 | validation: 0.033118583977583764]
	TIME [epoch: 8.33 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02664287238974834		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.02664287238974834 | validation: 0.03006113295251912]
	TIME [epoch: 8.33 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03278740122804895		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.03278740122804895 | validation: 0.030754244115597875]
	TIME [epoch: 8.35 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030585208450092733		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.030585208450092733 | validation: 0.030131637274763513]
	TIME [epoch: 8.34 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032121130793842725		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.032121130793842725 | validation: 0.033893928312329055]
	TIME [epoch: 8.33 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03007215981482737		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.03007215981482737 | validation: 0.04197978348367365]
	TIME [epoch: 8.34 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02687511260132221		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.02687511260132221 | validation: 0.038656876738108685]
	TIME [epoch: 8.35 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03250777678028231		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.03250777678028231 | validation: 0.055063143541669836]
	TIME [epoch: 8.34 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031383871406643074		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.031383871406643074 | validation: 0.03984168217542974]
	TIME [epoch: 8.33 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03463101403866316		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.03463101403866316 | validation: 0.053607574512031124]
	TIME [epoch: 8.33 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03870485811721726		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.03870485811721726 | validation: 0.049884406631581085]
	TIME [epoch: 8.35 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031050708206493628		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.031050708206493628 | validation: 0.05568334707858853]
	TIME [epoch: 8.34 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038376676012353325		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.038376676012353325 | validation: 0.03467219773043961]
	TIME [epoch: 8.34 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028825845367707315		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.028825845367707315 | validation: 0.03329765732974013]
	TIME [epoch: 8.34 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030391287962500596		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.030391287962500596 | validation: 0.03935996347796186]
	TIME [epoch: 8.35 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02953705554382033		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.02953705554382033 | validation: 0.029043730297934663]
	TIME [epoch: 8.33 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031053446166533338		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.031053446166533338 | validation: 0.041796704750731106]
	TIME [epoch: 8.34 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04400979574430812		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.04400979574430812 | validation: 0.04828256382639894]
	TIME [epoch: 8.33 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03429058141889627		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.03429058141889627 | validation: 0.051318278540514906]
	TIME [epoch: 8.35 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03360418696916633		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.03360418696916633 | validation: 0.045218351680341995]
	TIME [epoch: 8.34 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03328568436612138		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.03328568436612138 | validation: 0.04164814729989043]
	TIME [epoch: 8.33 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026684326822555282		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.026684326822555282 | validation: 0.03144492001870797]
	TIME [epoch: 8.33 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04003650037310253		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.04003650037310253 | validation: 0.057802841742724376]
	TIME [epoch: 8.35 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036667692236959384		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.036667692236959384 | validation: 0.03216499910930844]
	TIME [epoch: 8.34 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03033069503874335		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.03033069503874335 | validation: 0.03712322140676946]
	TIME [epoch: 8.34 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031688224474841424		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.031688224474841424 | validation: 0.02856003072307303]
	TIME [epoch: 8.34 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024525568862840564		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.024525568862840564 | validation: 0.02806493504729374]
	TIME [epoch: 8.35 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02761458923755412		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.02761458923755412 | validation: 0.034602886636789995]
	TIME [epoch: 8.33 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026698605434554122		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.026698605434554122 | validation: 0.04205117712760633]
	TIME [epoch: 8.33 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03045655470353522		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.03045655470353522 | validation: 0.042028844830456054]
	TIME [epoch: 8.33 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03712331065801289		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.03712331065801289 | validation: 0.03570453337099759]
	TIME [epoch: 8.36 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03117744302162672		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.03117744302162672 | validation: 0.027889459735108327]
	TIME [epoch: 8.34 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027248494464296186		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.027248494464296186 | validation: 0.038244235042848095]
	TIME [epoch: 8.33 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0341909643739495		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.0341909643739495 | validation: 0.039384371751933434]
	TIME [epoch: 8.34 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03780384146705679		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.03780384146705679 | validation: 0.050681577039744755]
	TIME [epoch: 8.35 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03664428510497889		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.03664428510497889 | validation: 0.03605997147635091]
	TIME [epoch: 8.34 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029165629744905393		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.029165629744905393 | validation: 0.040755086259530796]
	TIME [epoch: 8.34 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04011782713288785		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.04011782713288785 | validation: 0.05156165055352786]
	TIME [epoch: 8.33 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04312909641537289		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.04312909641537289 | validation: 0.038895364584261086]
	TIME [epoch: 8.36 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03599456782125969		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.03599456782125969 | validation: 0.02945444239275031]
	TIME [epoch: 8.34 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03753038099425225		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.03753038099425225 | validation: 0.02669984933329759]
	TIME [epoch: 8.33 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02642806357234485		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.02642806357234485 | validation: 0.04215557471057386]
	TIME [epoch: 8.34 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03732993520326072		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.03732993520326072 | validation: 0.03679066972480399]
	TIME [epoch: 8.36 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03697208670935061		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.03697208670935061 | validation: 0.04883640050533331]
	TIME [epoch: 8.34 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04497781771306724		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.04497781771306724 | validation: 0.04839816269012087]
	TIME [epoch: 8.33 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0475840968678648		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.0475840968678648 | validation: 0.06423123931464746]
	TIME [epoch: 8.34 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04284945716893285		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.04284945716893285 | validation: 0.05427825898485593]
	TIME [epoch: 8.36 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039268321285210676		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.039268321285210676 | validation: 0.051530343794756114]
	TIME [epoch: 8.34 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03198064316504086		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.03198064316504086 | validation: 0.0378290975977047]
	TIME [epoch: 8.34 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031323669563626796		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.031323669563626796 | validation: 0.059618221362255155]
	TIME [epoch: 8.33 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03397796221040977		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.03397796221040977 | validation: 0.035618653925046526]
	TIME [epoch: 8.35 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03252283395820346		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.03252283395820346 | validation: 0.04069500472835935]
	TIME [epoch: 8.34 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030661941824198485		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.030661941824198485 | validation: 0.04701703724005697]
	TIME [epoch: 8.33 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02895934782170853		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.02895934782170853 | validation: 0.04247337821608352]
	TIME [epoch: 8.33 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030912273562457453		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.030912273562457453 | validation: 0.03670404456001383]
	TIME [epoch: 8.35 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0226063980752319		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.0226063980752319 | validation: 0.03913438695037008]
	TIME [epoch: 8.34 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026465771211861368		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.026465771211861368 | validation: 0.030292480295412014]
	TIME [epoch: 8.33 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025600269765080664		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.025600269765080664 | validation: 0.039783156722597184]
	TIME [epoch: 8.34 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03255680185882439		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.03255680185882439 | validation: 0.03851099847871723]
	TIME [epoch: 8.35 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02756645934705364		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.02756645934705364 | validation: 0.04449934256335396]
	TIME [epoch: 8.33 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025659001189678305		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.025659001189678305 | validation: 0.03383199269687434]
	TIME [epoch: 8.33 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0259003903140707		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.0259003903140707 | validation: 0.028237994389018948]
	TIME [epoch: 8.34 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025725611236131873		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.025725611236131873 | validation: 0.03589124711305367]
	TIME [epoch: 8.35 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02997477089120067		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.02997477089120067 | validation: 0.04018400005449363]
	TIME [epoch: 8.34 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020786077873333968		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.020786077873333968 | validation: 0.04835989828638934]
	TIME [epoch: 8.33 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026686329197768012		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.026686329197768012 | validation: 0.044680424095794966]
	TIME [epoch: 8.34 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038263005470168934		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.038263005470168934 | validation: 0.05159157554977239]
	TIME [epoch: 8.34 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03194407000699772		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.03194407000699772 | validation: 0.03655515840620287]
	TIME [epoch: 8.34 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030866967923370958		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.030866967923370958 | validation: 0.03630035530020823]
	TIME [epoch: 8.33 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027726708845946173		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.027726708845946173 | validation: 0.030592196967074506]
	TIME [epoch: 8.35 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024153200593760322		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.024153200593760322 | validation: 0.027443016586016295]
	TIME [epoch: 8.34 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02784732767112838		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.02784732767112838 | validation: 0.028740613236643266]
	TIME [epoch: 8.33 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030480122509933975		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.030480122509933975 | validation: 0.04773476504496048]
	TIME [epoch: 8.33 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04408854414830073		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.04408854414830073 | validation: 0.03819194411762303]
	TIME [epoch: 8.34 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04331507422754434		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.04331507422754434 | validation: 0.034949763204113374]
	TIME [epoch: 8.34 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03238982889017987		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.03238982889017987 | validation: 0.03444733454537905]
	TIME [epoch: 8.33 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03907354818491698		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.03907354818491698 | validation: 0.059288858693622465]
	TIME [epoch: 8.33 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029509196001726558		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.029509196001726558 | validation: 0.03922574259494145]
	TIME [epoch: 8.35 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031150190643975728		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.031150190643975728 | validation: 0.02867720823539219]
	TIME [epoch: 8.34 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03573743776715488		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.03573743776715488 | validation: 0.032132277416928354]
	TIME [epoch: 8.33 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03354730160717354		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.03354730160717354 | validation: 0.03191546801659608]
	TIME [epoch: 8.34 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03282388765286394		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.03282388765286394 | validation: 0.0516690270187753]
	TIME [epoch: 8.35 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034524518403191776		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.034524518403191776 | validation: 0.03962627283647055]
	TIME [epoch: 8.34 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03586677359301468		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.03586677359301468 | validation: 0.03523482686150772]
	TIME [epoch: 8.33 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037707380993527384		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.037707380993527384 | validation: 0.03602274403619566]
	TIME [epoch: 8.33 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03191083609475998		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.03191083609475998 | validation: 0.03504242436796745]
	TIME [epoch: 8.36 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03173432486490507		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.03173432486490507 | validation: 0.04340261047676083]
	TIME [epoch: 8.34 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02964748588658168		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.02964748588658168 | validation: 0.038958515903699496]
	TIME [epoch: 8.33 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026634499637274954		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.026634499637274954 | validation: 0.04437152527780192]
	TIME [epoch: 8.33 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03321650691897089		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.03321650691897089 | validation: 0.05432604080067092]
	TIME [epoch: 8.35 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03400160850712432		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.03400160850712432 | validation: 0.048407841856756145]
	TIME [epoch: 8.34 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03196380522211908		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.03196380522211908 | validation: 0.04596945243739789]
	TIME [epoch: 8.33 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03990603075651808		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.03990603075651808 | validation: 0.04787460246322818]
	TIME [epoch: 8.34 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03208138089184791		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.03208138089184791 | validation: 0.04154276122707545]
	TIME [epoch: 8.35 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030636130171277066		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.030636130171277066 | validation: 0.0363091201233805]
	TIME [epoch: 8.34 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02688536312738727		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.02688536312738727 | validation: 0.04343811885980668]
	TIME [epoch: 8.34 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03163105345214987		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.03163105345214987 | validation: 0.052670369361848615]
	TIME [epoch: 8.34 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03188707410002629		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.03188707410002629 | validation: 0.035286705526166154]
	TIME [epoch: 8.35 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029930667690091554		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.029930667690091554 | validation: 0.04324364157715846]
	TIME [epoch: 8.34 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02916867047703613		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.02916867047703613 | validation: 0.03697611016587965]
	TIME [epoch: 8.34 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029209844912992312		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.029209844912992312 | validation: 0.03931686439427224]
	TIME [epoch: 8.34 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03434786679804634		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.03434786679804634 | validation: 0.04508366880380883]
	TIME [epoch: 8.35 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037099499100089306		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.037099499100089306 | validation: 0.04836500007979604]
	TIME [epoch: 8.34 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03156863855183025		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.03156863855183025 | validation: 0.03695576760399448]
	TIME [epoch: 8.34 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027185173536329536		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.027185173536329536 | validation: 0.039345062814750156]
	TIME [epoch: 8.34 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025296990294671206		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.025296990294671206 | validation: 0.03778152190179949]
	TIME [epoch: 8.36 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0271708764204178		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.0271708764204178 | validation: 0.030987729325106406]
	TIME [epoch: 8.34 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024791700173482967		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.024791700173482967 | validation: 0.04870751814971423]
	TIME [epoch: 8.34 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026335525856453955		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.026335525856453955 | validation: 0.051333163069819776]
	TIME [epoch: 8.33 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030456781702157005		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.030456781702157005 | validation: 0.03744552372419713]
	TIME [epoch: 8.35 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029440066066663634		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.029440066066663634 | validation: 0.040969383001490056]
	TIME [epoch: 8.34 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03922765076284455		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.03922765076284455 | validation: 0.05938613930008664]
	TIME [epoch: 8.34 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032805138753246844		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.032805138753246844 | validation: 0.04040793184201158]
	TIME [epoch: 8.34 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03271882311360211		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.03271882311360211 | validation: 0.04520366043450279]
	TIME [epoch: 8.35 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027810902829410795		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.027810902829410795 | validation: 0.05910238383062276]
	TIME [epoch: 8.34 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030205254450419817		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.030205254450419817 | validation: 0.05010297724590572]
	TIME [epoch: 8.33 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02761554948426038		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.02761554948426038 | validation: 0.05118654652395097]
	TIME [epoch: 8.34 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027970425729605175		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.027970425729605175 | validation: 0.044252435658959345]
	TIME [epoch: 8.35 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034280311911664973		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.034280311911664973 | validation: 0.052837891855546014]
	TIME [epoch: 8.34 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038142962376937116		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.038142962376937116 | validation: 0.051931722707429115]
	TIME [epoch: 8.34 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03132932340377155		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.03132932340377155 | validation: 0.05198263832225591]
	TIME [epoch: 8.34 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028056845154701398		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.028056845154701398 | validation: 0.030911203782125488]
	TIME [epoch: 8.36 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028375845589028566		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.028375845589028566 | validation: 0.0376559082901015]
	TIME [epoch: 8.34 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02214127288397739		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.02214127288397739 | validation: 0.039134113657172225]
	TIME [epoch: 8.33 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027592157474905055		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.027592157474905055 | validation: 0.032963286364384385]
	TIME [epoch: 8.33 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026779275360070916		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.026779275360070916 | validation: 0.038097939646376186]
	TIME [epoch: 8.35 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026379215265198337		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.026379215265198337 | validation: 0.03498981610057922]
	TIME [epoch: 8.34 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025471859719815214		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.025471859719815214 | validation: 0.02619954796263932]
	TIME [epoch: 8.33 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019960644185983964		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.019960644185983964 | validation: 0.03284127726673172]
	TIME [epoch: 8.34 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027011150313793787		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.027011150313793787 | validation: 0.03566738386266071]
	TIME [epoch: 8.35 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02714745835306658		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.02714745835306658 | validation: 0.03363431187448024]
	TIME [epoch: 8.34 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027938988914713088		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.027938988914713088 | validation: 0.03129357463792846]
	TIME [epoch: 8.34 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030290897546469825		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.030290897546469825 | validation: 0.02696377243733417]
	TIME [epoch: 8.34 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03636783548050644		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.03636783548050644 | validation: 0.021853481209001387]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1726.pth
	Model improved!!!
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024545637122297136		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.024545637122297136 | validation: 0.03759316117194844]
	TIME [epoch: 8.34 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030572266474612447		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.030572266474612447 | validation: 0.04333287323544561]
	TIME [epoch: 8.34 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028728760967724455		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.028728760967724455 | validation: 0.02936877245923044]
	TIME [epoch: 8.34 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02624543407270702		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.02624543407270702 | validation: 0.039366211181834386]
	TIME [epoch: 8.37 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028522165910363245		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.028522165910363245 | validation: 0.04404591235621414]
	TIME [epoch: 8.34 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03353155399445941		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.03353155399445941 | validation: 0.05464732236093925]
	TIME [epoch: 8.34 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036656308043872605		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.036656308043872605 | validation: 0.038158022937032]
	TIME [epoch: 8.34 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03457579669157736		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.03457579669157736 | validation: 0.0424172033579706]
	TIME [epoch: 8.36 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025409345884185676		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.025409345884185676 | validation: 0.032621521978711474]
	TIME [epoch: 8.34 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031133493605585955		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.031133493605585955 | validation: 0.0442621384613856]
	TIME [epoch: 8.34 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031718195630182584		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.031718195630182584 | validation: 0.05147857652867087]
	TIME [epoch: 8.34 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02578626094080737		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.02578626094080737 | validation: 0.04590814210947313]
	TIME [epoch: 8.36 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026962820656467427		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.026962820656467427 | validation: 0.024138810518735898]
	TIME [epoch: 8.34 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02138173153940135		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.02138173153940135 | validation: 0.043942907183048545]
	TIME [epoch: 8.34 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03163132279890647		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.03163132279890647 | validation: 0.0477877763084164]
	TIME [epoch: 8.34 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02656965551477174		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.02656965551477174 | validation: 0.03556116832940406]
	TIME [epoch: 8.37 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024242492840190755		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.024242492840190755 | validation: 0.037502634488934414]
	TIME [epoch: 8.35 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026316593660304716		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.026316593660304716 | validation: 0.036486098999748195]
	TIME [epoch: 8.34 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02431914261271782		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.02431914261271782 | validation: 0.03211971172349186]
	TIME [epoch: 8.35 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028994203156919824		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.028994203156919824 | validation: 0.0309362809977723]
	TIME [epoch: 8.36 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02928537518047023		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.02928537518047023 | validation: 0.04259626434155109]
	TIME [epoch: 8.35 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029130626118122466		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.029130626118122466 | validation: 0.03510741051599138]
	TIME [epoch: 8.35 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02750210013198523		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.02750210013198523 | validation: 0.028537129267591853]
	TIME [epoch: 8.35 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03138320365929432		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.03138320365929432 | validation: 0.04213904459858897]
	TIME [epoch: 8.36 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031338689655490845		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.031338689655490845 | validation: 0.04036465647782538]
	TIME [epoch: 8.35 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025227648387913006		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.025227648387913006 | validation: 0.04406174667184691]
	TIME [epoch: 8.35 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02636696413659889		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.02636696413659889 | validation: 0.03537946494048754]
	TIME [epoch: 8.34 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02753773464835857		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.02753773464835857 | validation: 0.028937962123221125]
	TIME [epoch: 8.36 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02616336934594799		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.02616336934594799 | validation: 0.039525604604016315]
	TIME [epoch: 8.34 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02693530094838823		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.02693530094838823 | validation: 0.027507572109871696]
	TIME [epoch: 8.35 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025028559004975266		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.025028559004975266 | validation: 0.031389904645369074]
	TIME [epoch: 8.36 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028757184869257928		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.028757184869257928 | validation: 0.03851536113576706]
	TIME [epoch: 8.36 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026556549633387428		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.026556549633387428 | validation: 0.031728689829623694]
	TIME [epoch: 8.35 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02531801493376932		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.02531801493376932 | validation: 0.027737065043512484]
	TIME [epoch: 8.34 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020199494840091526		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.020199494840091526 | validation: 0.039250786444865404]
	TIME [epoch: 8.36 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023947839733296984		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.023947839733296984 | validation: 0.03129092766933318]
	TIME [epoch: 8.36 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024294535601949822		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.024294535601949822 | validation: 0.03341734950922365]
	TIME [epoch: 8.35 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02289394595998825		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.02289394595998825 | validation: 0.03535127936927772]
	TIME [epoch: 8.34 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028954387335118938		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.028954387335118938 | validation: 0.0414086193200847]
	TIME [epoch: 8.35 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02791374317037764		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.02791374317037764 | validation: 0.039997692496916745]
	TIME [epoch: 8.36 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02441785665522548		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.02441785665522548 | validation: 0.03687564385210934]
	TIME [epoch: 8.33 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021246199041250746		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.021246199041250746 | validation: 0.03020923938201234]
	TIME [epoch: 8.34 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024853017572198054		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.024853017572198054 | validation: 0.03529783267899679]
	TIME [epoch: 8.36 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019413214933282484		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.019413214933282484 | validation: 0.04146443646888584]
	TIME [epoch: 8.35 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025388123053931615		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.025388123053931615 | validation: 0.024073146922440437]
	TIME [epoch: 8.34 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028608114189260958		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.028608114189260958 | validation: 0.04211038169626723]
	TIME [epoch: 8.34 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034702574265526115		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.034702574265526115 | validation: 0.0404093094541196]
	TIME [epoch: 8.36 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023143576817155717		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.023143576817155717 | validation: 0.029617072305260457]
	TIME [epoch: 8.35 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027325656732321697		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.027325656732321697 | validation: 0.038487239492509095]
	TIME [epoch: 8.34 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028600678873032453		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.028600678873032453 | validation: 0.024082639640328092]
	TIME [epoch: 8.34 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024368567423168515		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.024368567423168515 | validation: 0.03039016026809273]
	TIME [epoch: 8.36 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029985336791378863		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.029985336791378863 | validation: 0.03765695180185849]
	TIME [epoch: 8.34 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02862750847838788		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.02862750847838788 | validation: 0.04053626753162279]
	TIME [epoch: 8.34 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03541319234159778		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.03541319234159778 | validation: 0.04924036712588953]
	TIME [epoch: 8.35 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030276051801647504		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.030276051801647504 | validation: 0.04001705362890717]
	TIME [epoch: 8.36 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02903309386390332		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.02903309386390332 | validation: 0.0474184075161956]
	TIME [epoch: 8.35 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026349958189373718		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.026349958189373718 | validation: 0.028102674111761445]
	TIME [epoch: 8.35 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029225225641413517		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.029225225641413517 | validation: 0.03223631993168828]
	TIME [epoch: 8.34 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022725376370769473		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.022725376370769473 | validation: 0.03875463750591705]
	TIME [epoch: 8.37 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03176495184828802		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.03176495184828802 | validation: 0.03695000110400301]
	TIME [epoch: 8.34 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02777523122149709		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.02777523122149709 | validation: 0.03450139770578389]
	TIME [epoch: 8.34 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025139105527127014		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.025139105527127014 | validation: 0.030161018025013395]
	TIME [epoch: 8.33 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023962267742020163		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.023962267742020163 | validation: 0.04063098617707414]
	TIME [epoch: 8.36 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028273293157072228		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.028273293157072228 | validation: 0.027275360781605078]
	TIME [epoch: 8.35 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027536045563536914		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.027536045563536914 | validation: 0.02946371421009185]
	TIME [epoch: 8.35 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02432213173311589		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.02432213173311589 | validation: 0.037689867811093736]
	TIME [epoch: 8.34 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03327650721492085		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.03327650721492085 | validation: 0.03990857813090296]
	TIME [epoch: 8.36 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025682564581173174		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.025682564581173174 | validation: 0.03308397544187902]
	TIME [epoch: 8.36 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023845772091649488		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.023845772091649488 | validation: 0.0385550043521308]
	TIME [epoch: 8.35 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026965321261453033		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.026965321261453033 | validation: 0.027273661359369983]
	TIME [epoch: 8.34 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03342307108375765		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.03342307108375765 | validation: 0.0357586149327833]
	TIME [epoch: 8.36 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03148231087930509		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.03148231087930509 | validation: 0.03571209829471546]
	TIME [epoch: 8.34 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026573049746402698		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.026573049746402698 | validation: 0.03993551068753351]
	TIME [epoch: 8.34 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028442363955959192		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.028442363955959192 | validation: 0.023972042257205155]
	TIME [epoch: 8.36 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018774547013639585		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.018774547013639585 | validation: 0.04271170645602045]
	TIME [epoch: 8.36 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029592206472005583		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.029592206472005583 | validation: 0.03949760686458967]
	TIME [epoch: 8.35 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025371398856417732		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.025371398856417732 | validation: 0.03457990105768369]
	TIME [epoch: 8.34 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022172667203880107		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.022172667203880107 | validation: 0.04027204395149806]
	TIME [epoch: 8.34 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03128943240373079		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.03128943240373079 | validation: 0.04593885723876038]
	TIME [epoch: 8.36 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027122241145457453		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.027122241145457453 | validation: 0.03935751624529796]
	TIME [epoch: 8.35 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03053072190632866		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.03053072190632866 | validation: 0.037044770181857034]
	TIME [epoch: 8.35 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02529979223153394		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.02529979223153394 | validation: 0.037388570450766476]
	TIME [epoch: 8.35 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02647118406599292		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.02647118406599292 | validation: 0.027719636296274948]
	TIME [epoch: 8.37 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022934999719595596		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.022934999719595596 | validation: 0.0291832343954921]
	TIME [epoch: 8.35 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026364920970301825		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.026364920970301825 | validation: 0.03174574427426323]
	TIME [epoch: 8.35 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028993912551971583		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.028993912551971583 | validation: 0.027458823623865015]
	TIME [epoch: 8.34 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02728510555884267		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.02728510555884267 | validation: 0.030830473142218345]
	TIME [epoch: 8.37 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025251822530146552		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.025251822530146552 | validation: 0.0296058871744949]
	TIME [epoch: 8.35 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032020613509781824		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.032020613509781824 | validation: 0.03105403612170228]
	TIME [epoch: 8.35 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03463061236704005		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.03463061236704005 | validation: 0.037875541459882575]
	TIME [epoch: 8.35 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029528531961662698		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.029528531961662698 | validation: 0.023537316182974083]
	TIME [epoch: 8.36 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025113108586956773		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.025113108586956773 | validation: 0.037666553224886296]
	TIME [epoch: 8.35 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024670396112743142		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.024670396112743142 | validation: 0.03300572833468089]
	TIME [epoch: 8.35 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024728182843762048		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.024728182843762048 | validation: 0.05181350073586523]
	TIME [epoch: 8.36 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0272945844782356		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.0272945844782356 | validation: 0.022147871071796717]
	TIME [epoch: 8.36 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024641599304734606		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.024641599304734606 | validation: 0.02634807360260611]
	TIME [epoch: 8.35 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02437495116520916		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.02437495116520916 | validation: 0.031630628589466005]
	TIME [epoch: 8.35 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03956678954135179		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.03956678954135179 | validation: 0.04533692696720437]
	TIME [epoch: 8.35 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024915777230372006		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.024915777230372006 | validation: 0.03662800926382051]
	TIME [epoch: 8.36 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029840605120900913		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.029840605120900913 | validation: 0.030248024519177883]
	TIME [epoch: 8.34 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02766848757068378		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.02766848757068378 | validation: 0.046906991642075624]
	TIME [epoch: 8.35 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03213713737469222		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.03213713737469222 | validation: 0.03497770385721129]
	TIME [epoch: 8.35 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024436601655217986		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.024436601655217986 | validation: 0.036727241078922584]
	TIME [epoch: 8.37 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023213358588337174		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.023213358588337174 | validation: 0.03159349545412757]
	TIME [epoch: 8.34 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03188367919896237		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.03188367919896237 | validation: 0.03361006334505123]
	TIME [epoch: 8.35 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03146777576977332		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.03146777576977332 | validation: 0.039584305599197483]
	TIME [epoch: 8.35 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026140581599949066		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.026140581599949066 | validation: 0.03756202878718448]
	TIME [epoch: 8.36 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018168759167649165		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.018168759167649165 | validation: 0.034540653255741786]
	TIME [epoch: 8.35 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022638152473853573		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.022638152473853573 | validation: 0.03509777091947402]
	TIME [epoch: 8.35 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023452385395618027		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.023452385395618027 | validation: 0.049855221068074336]
	TIME [epoch: 8.34 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029698588199962694		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.029698588199962694 | validation: 0.0465243240563146]
	TIME [epoch: 8.36 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024147101981266794		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.024147101981266794 | validation: 0.03798001541941878]
	TIME [epoch: 8.35 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035460654804886735		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.035460654804886735 | validation: 0.05917909309584134]
	TIME [epoch: 8.34 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03098637336530618		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.03098637336530618 | validation: 0.05314955776585345]
	TIME [epoch: 8.35 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031004968381175724		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.031004968381175724 | validation: 0.03871563912268424]
	TIME [epoch: 8.36 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028789246378042827		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.028789246378042827 | validation: 0.03689112316732868]
	TIME [epoch: 8.35 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024712956175326813		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.024712956175326813 | validation: 0.0356054916448129]
	TIME [epoch: 8.35 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023926517506037283		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.023926517506037283 | validation: 0.039411736583066174]
	TIME [epoch: 8.35 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025276402406303394		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.025276402406303394 | validation: 0.03036293513744131]
	TIME [epoch: 8.36 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03031532787244559		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.03031532787244559 | validation: 0.037129769854749625]
	TIME [epoch: 8.35 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026524526313084988		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.026524526313084988 | validation: 0.04227453841839498]
	TIME [epoch: 8.35 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02470488551853451		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.02470488551853451 | validation: 0.040527732186982565]
	TIME [epoch: 8.35 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021062524815810967		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.021062524815810967 | validation: 0.025610959153779145]
	TIME [epoch: 8.36 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02784184279411046		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.02784184279411046 | validation: 0.02488614594110047]
	TIME [epoch: 8.34 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02327878838796032		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.02327878838796032 | validation: 0.029322586496646187]
	TIME [epoch: 8.34 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02687768255913429		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.02687768255913429 | validation: 0.03682626614916913]
	TIME [epoch: 8.35 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030170861234276168		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.030170861234276168 | validation: 0.03556770667122364]
	TIME [epoch: 8.35 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02595994642062066		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.02595994642062066 | validation: 0.036441291863630744]
	TIME [epoch: 8.34 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024958282265672798		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.024958282265672798 | validation: 0.03440603912453097]
	TIME [epoch: 8.34 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022147024338661392		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.022147024338661392 | validation: 0.04407133745324125]
	TIME [epoch: 8.35 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025655165186386747		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.025655165186386747 | validation: 0.029977389216761827]
	TIME [epoch: 8.35 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02531481279423358		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.02531481279423358 | validation: 0.031982352628910825]
	TIME [epoch: 8.33 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027151727181860947		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.027151727181860947 | validation: 0.03530742124591989]
	TIME [epoch: 8.35 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02517532432567336		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.02517532432567336 | validation: 0.037284795187720786]
	TIME [epoch: 8.35 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02735009200709153		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.02735009200709153 | validation: 0.04661131369409543]
	TIME [epoch: 8.36 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027484436095205032		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.027484436095205032 | validation: 0.04853739082527499]
	TIME [epoch: 8.34 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02446414851073549		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.02446414851073549 | validation: 0.04413613237419731]
	TIME [epoch: 8.34 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026888213392690395		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.026888213392690395 | validation: 0.04423530904464089]
	TIME [epoch: 8.36 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028212301802806317		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.028212301802806317 | validation: 0.04891800260874364]
	TIME [epoch: 8.35 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03006441217771485		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.03006441217771485 | validation: 0.032726968647134765]
	TIME [epoch: 8.35 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030366364645659533		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.030366364645659533 | validation: 0.037585468885029116]
	TIME [epoch: 8.34 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028088880420453044		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.028088880420453044 | validation: 0.046951235011777934]
	TIME [epoch: 8.36 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030958901196054246		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.030958901196054246 | validation: 0.0418913429832464]
	TIME [epoch: 8.35 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03410644597136851		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.03410644597136851 | validation: 0.033511886449621525]
	TIME [epoch: 8.34 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02513508702435096		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.02513508702435096 | validation: 0.04456713089522939]
	TIME [epoch: 8.33 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027126282372043925		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.027126282372043925 | validation: 0.04355148491325296]
	TIME [epoch: 8.36 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024558011980186877		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.024558011980186877 | validation: 0.04185053131118218]
	TIME [epoch: 8.34 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027743223269501478		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.027743223269501478 | validation: 0.05873005893487078]
	TIME [epoch: 8.34 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024745811676254732		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.024745811676254732 | validation: 0.04680285473600787]
	TIME [epoch: 8.35 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028722281313428754		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.028722281313428754 | validation: 0.05156049531769345]
	TIME [epoch: 8.35 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026933200761008913		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.026933200761008913 | validation: 0.035808968584489426]
	TIME [epoch: 8.34 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02805761780720977		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.02805761780720977 | validation: 0.045188022196838915]
	TIME [epoch: 8.34 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03333984256645288		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.03333984256645288 | validation: 0.049460507888361774]
	TIME [epoch: 8.34 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026591650162121262		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.026591650162121262 | validation: 0.04127347560359822]
	TIME [epoch: 8.36 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030204011861694302		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.030204011861694302 | validation: 0.04426256428379999]
	TIME [epoch: 8.34 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029759158774630916		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.029759158774630916 | validation: 0.04150825170407885]
	TIME [epoch: 8.34 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027206438405904136		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.027206438405904136 | validation: 0.06211125209315161]
	TIME [epoch: 8.34 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031554645324273		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.031554645324273 | validation: 0.03498405408592907]
	TIME [epoch: 8.35 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030109774027731663		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.030109774027731663 | validation: 0.04087237138625828]
	TIME [epoch: 8.35 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027194356995466584		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.027194356995466584 | validation: 0.04193869393708758]
	TIME [epoch: 8.34 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025923805844397817		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.025923805844397817 | validation: 0.03229241591041408]
	TIME [epoch: 8.34 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026642680022182126		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.026642680022182126 | validation: 0.04488279609123837]
	TIME [epoch: 8.37 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03195002938109783		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.03195002938109783 | validation: 0.042455197205949334]
	TIME [epoch: 8.34 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02833008778426076		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.02833008778426076 | validation: 0.03462331999161831]
	TIME [epoch: 8.34 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024022641353576096		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.024022641353576096 | validation: 0.03909317314314143]
	TIME [epoch: 8.34 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024082372865501564		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.024082372865501564 | validation: 0.031562203814961054]
	TIME [epoch: 8.36 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020427944027073996		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.020427944027073996 | validation: 0.039694080474182915]
	TIME [epoch: 8.35 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023255861436342527		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.023255861436342527 | validation: 0.038471075878994204]
	TIME [epoch: 8.34 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025953111482075453		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.025953111482075453 | validation: 0.036290150067126416]
	TIME [epoch: 8.34 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022792031181067443		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.022792031181067443 | validation: 0.03917125068586227]
	TIME [epoch: 8.36 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018571355430551474		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.018571355430551474 | validation: 0.04079014657875199]
	TIME [epoch: 8.34 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025553782776293915		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.025553782776293915 | validation: 0.033537499483474724]
	TIME [epoch: 8.34 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023004790355301695		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.023004790355301695 | validation: 0.03155987790439909]
	TIME [epoch: 8.33 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02515226654519311		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.02515226654519311 | validation: 0.043059023634087326]
	TIME [epoch: 8.36 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03182237793882633		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.03182237793882633 | validation: 0.03792563709315397]
	TIME [epoch: 8.35 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030169049960567886		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.030169049960567886 | validation: 0.03628095460591327]
	TIME [epoch: 8.34 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030466946834620007		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.030466946834620007 | validation: 0.033274592594476876]
	TIME [epoch: 8.34 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02814052724964518		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.02814052724964518 | validation: 0.02695651446453437]
	TIME [epoch: 8.37 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022421269716162227		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.022421269716162227 | validation: 0.026642809968366217]
	TIME [epoch: 8.34 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0261240913999229		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.0261240913999229 | validation: 0.035172105579291346]
	TIME [epoch: 8.34 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027601231366640062		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.027601231366640062 | validation: 0.03691992998424984]
	TIME [epoch: 8.34 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02299465796335224		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.02299465796335224 | validation: 0.024797815705097485]
	TIME [epoch: 8.36 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027621554449761686		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.027621554449761686 | validation: 0.038834926844022205]
	TIME [epoch: 8.34 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02482831010058404		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.02482831010058404 | validation: 0.028693288298888064]
	TIME [epoch: 8.34 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021886992790300385		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.021886992790300385 | validation: 0.02474320684672071]
	TIME [epoch: 8.34 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02068921496342064		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.02068921496342064 | validation: 0.03855363751050699]
	TIME [epoch: 8.36 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024137027336674832		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.024137027336674832 | validation: 0.030312097278983242]
	TIME [epoch: 8.34 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026986144315298617		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.026986144315298617 | validation: 0.03001625123257978]
	TIME [epoch: 8.34 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02848595404711555		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.02848595404711555 | validation: 0.04678354080081806]
	TIME [epoch: 8.34 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028895977370570824		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.028895977370570824 | validation: 0.030431763955721988]
	TIME [epoch: 8.36 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02614719577443265		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.02614719577443265 | validation: 0.03069302754011871]
	TIME [epoch: 8.34 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029785048653084706		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.029785048653084706 | validation: 0.042632183177380906]
	TIME [epoch: 8.34 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024077464254379587		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.024077464254379587 | validation: 0.037617791473650665]
	TIME [epoch: 8.34 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025415423098835477		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.025415423098835477 | validation: 0.033709599743987934]
	TIME [epoch: 8.36 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0248378782456963		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.0248378782456963 | validation: 0.02686305400741449]
	TIME [epoch: 8.36 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021478831700733305		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.021478831700733305 | validation: 0.03399528912501405]
	TIME [epoch: 8.34 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026814056387582302		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.026814056387582302 | validation: 0.036029053871903374]
	TIME [epoch: 8.35 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030053392631227794		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.030053392631227794 | validation: 0.03253482196251296]
	TIME [epoch: 8.36 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024168178287699547		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.024168178287699547 | validation: 0.0316487214112743]
	TIME [epoch: 8.35 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03105256880356625		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.03105256880356625 | validation: 0.04198908181242453]
	TIME [epoch: 8.34 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026600848370593615		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.026600848370593615 | validation: 0.027223860767639902]
	TIME [epoch: 8.34 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025100581899841434		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.025100581899841434 | validation: 0.02790765314370427]
	TIME [epoch: 8.37 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022956379739861206		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.022956379739861206 | validation: 0.031200606676031084]
	TIME [epoch: 8.35 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026956651246740147		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.026956651246740147 | validation: 0.04560645078452934]
	TIME [epoch: 8.35 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02429243527043217		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.02429243527043217 | validation: 0.03492164416959903]
	TIME [epoch: 8.34 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022828898230096754		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.022828898230096754 | validation: 0.0272914544121835]
	TIME [epoch: 8.36 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024482992672310293		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.024482992672310293 | validation: 0.04194676724598096]
	TIME [epoch: 8.34 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02711366313654186		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.02711366313654186 | validation: 0.027808001248621268]
	TIME [epoch: 8.34 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021281824960519793		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.021281824960519793 | validation: 0.02120830922532628]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1935.pth
	Model improved!!!
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02237420887552194		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.02237420887552194 | validation: 0.02694145884507878]
	TIME [epoch: 8.37 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03000059905812223		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.03000059905812223 | validation: 0.02911161162163426]
	TIME [epoch: 8.34 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02560448995754159		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.02560448995754159 | validation: 0.027454112910334505]
	TIME [epoch: 8.34 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028945919451153747		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.028945919451153747 | validation: 0.028494547420561282]
	TIME [epoch: 8.34 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025034863651166174		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.025034863651166174 | validation: 0.03022920179384212]
	TIME [epoch: 8.36 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029811246798636025		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.029811246798636025 | validation: 0.027994612660157896]
	TIME [epoch: 8.34 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029250689276780317		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.029250689276780317 | validation: 0.038741757648244134]
	TIME [epoch: 8.34 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02496372951999882		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.02496372951999882 | validation: 0.028377414036962804]
	TIME [epoch: 8.34 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026103864980807346		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.026103864980807346 | validation: 0.031987948135320354]
	TIME [epoch: 8.36 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02421693945992585		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.02421693945992585 | validation: 0.02670010828989525]
	TIME [epoch: 8.34 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022766042335284987		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.022766042335284987 | validation: 0.01963611784850092]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240219_183148/states/model_tr_study3_1946.pth
	Model improved!!!
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021095600054074726		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.021095600054074726 | validation: 0.029166911633212656]
	TIME [epoch: 8.36 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01969609328548435		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.01969609328548435 | validation: 0.03313285264571922]
	TIME [epoch: 8.36 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024301379647883065		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.024301379647883065 | validation: 0.03616329094520902]
	TIME [epoch: 8.34 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025664484861309393		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.025664484861309393 | validation: 0.03117233365770117]
	TIME [epoch: 8.35 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029402075504503626		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.029402075504503626 | validation: 0.03638071461840117]
	TIME [epoch: 8.36 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028686391553513817		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.028686391553513817 | validation: 0.036758332692181234]
	TIME [epoch: 8.35 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031176932260255436		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.031176932260255436 | validation: 0.025393751099859564]
	TIME [epoch: 8.34 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026446189401218723		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.026446189401218723 | validation: 0.022764517264143958]
	TIME [epoch: 8.35 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02920248467250694		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.02920248467250694 | validation: 0.026689552293993175]
	TIME [epoch: 8.37 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028422778330567645		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.028422778330567645 | validation: 0.03117670098822837]
	TIME [epoch: 8.35 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03018663132279264		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.03018663132279264 | validation: 0.032118499963639816]
	TIME [epoch: 8.35 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027288011207067274		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.027288011207067274 | validation: 0.027285249065590312]
	TIME [epoch: 8.35 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030529286587151528		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.030529286587151528 | validation: 0.03890459209649824]
	TIME [epoch: 8.37 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025220455006346752		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.025220455006346752 | validation: 0.035780124068996014]
	TIME [epoch: 8.35 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02564246526123266		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.02564246526123266 | validation: 0.037254202659935454]
	TIME [epoch: 8.35 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026009540509162227		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.026009540509162227 | validation: 0.032242858501331025]
	TIME [epoch: 8.35 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02117629359582602		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.02117629359582602 | validation: 0.03462632847245566]
	TIME [epoch: 8.36 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024302805525509265		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.024302805525509265 | validation: 0.03235493719152838]
	TIME [epoch: 8.35 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020959621943056166		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.020959621943056166 | validation: 0.041342744170033016]
	TIME [epoch: 8.35 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02938892797500938		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.02938892797500938 | validation: 0.027603466354248755]
	TIME [epoch: 8.35 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022163762379914104		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.022163762379914104 | validation: 0.026124929792915412]
	TIME [epoch: 8.36 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02580356785089889		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.02580356785089889 | validation: 0.03212201375865265]
	TIME [epoch: 8.35 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019484285702886173		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.019484285702886173 | validation: 0.029382415451166582]
	TIME [epoch: 8.35 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020904535299353107		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.020904535299353107 | validation: 0.027120541989245885]
	TIME [epoch: 8.35 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030417015624158418		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.030417015624158418 | validation: 0.042375212210935195]
	TIME [epoch: 8.37 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024893414005674384		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.024893414005674384 | validation: 0.029641696000512134]
	TIME [epoch: 8.35 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02166335927102387		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.02166335927102387 | validation: 0.034296442057782706]
	TIME [epoch: 8.35 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02135878163585358		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.02135878163585358 | validation: 0.0435486850382444]
	TIME [epoch: 8.34 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023134641051371703		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.023134641051371703 | validation: 0.03989771955989928]
	TIME [epoch: 8.37 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02611465462684102		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.02611465462684102 | validation: 0.04132500260828485]
	TIME [epoch: 8.35 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024085749711673793		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.024085749711673793 | validation: 0.036255492797590765]
	TIME [epoch: 8.35 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02366214940952544		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.02366214940952544 | validation: 0.039071638467860596]
	TIME [epoch: 8.35 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024264865184887595		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.024264865184887595 | validation: 0.03351078028392266]
	TIME [epoch: 8.37 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023198357110184125		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.023198357110184125 | validation: 0.037359837592205236]
	TIME [epoch: 8.35 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02419043218624406		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.02419043218624406 | validation: 0.024758868232592355]
	TIME [epoch: 8.35 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022959458601950887		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.022959458601950887 | validation: 0.028547264344084132]
	TIME [epoch: 8.35 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02368455784869398		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.02368455784869398 | validation: 0.03013406383452172]
	TIME [epoch: 8.37 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02589581441419016		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.02589581441419016 | validation: 0.034605679436418804]
	TIME [epoch: 8.35 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02595874017647311		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.02595874017647311 | validation: 0.03860436698955431]
	TIME [epoch: 8.35 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02710724260303225		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.02710724260303225 | validation: 0.03253955171281643]
	TIME [epoch: 8.35 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019487804258415415		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.019487804258415415 | validation: 0.03618726210477012]
	TIME [epoch: 8.35 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01694983740131023		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.01694983740131023 | validation: 0.03458787951828905]
	TIME [epoch: 8.35 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023720373358335246		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.023720373358335246 | validation: 0.03421336834977033]
	TIME [epoch: 8.34 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025960233573100032		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.025960233573100032 | validation: 0.04074777016705041]
	TIME [epoch: 8.34 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023645465028408173		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.023645465028408173 | validation: 0.03628230396557826]
	TIME [epoch: 8.36 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016895854046101062		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.016895854046101062 | validation: 0.03901235100587246]
	TIME [epoch: 8.34 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021877665309793876		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.021877665309793876 | validation: 0.04097336979159678]
	TIME [epoch: 8.34 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020799876041829528		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.020799876041829528 | validation: 0.030276738672133832]
	TIME [epoch: 8.35 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020285272185891053		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.020285272185891053 | validation: 0.0270880690876409]
	TIME [epoch: 8.37 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022736919090783497		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.022736919090783497 | validation: 0.02969673829234723]
	TIME [epoch: 8.35 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024289156062058292		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.024289156062058292 | validation: 0.027495870896309855]
	TIME [epoch: 8.35 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021397539383927657		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.021397539383927657 | validation: 0.031717699193839585]
	TIME [epoch: 8.34 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02605049803006264		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.02605049803006264 | validation: 0.0361137381453892]
	TIME [epoch: 8.36 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022778258386220305		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.022778258386220305 | validation: 0.03954156533262057]
	TIME [epoch: 8.35 sec]
Finished training in 16824.840 seconds.
