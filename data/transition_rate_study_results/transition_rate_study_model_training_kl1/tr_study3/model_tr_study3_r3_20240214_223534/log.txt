Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1530252847

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 11.97378551107087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.97378551107087 | validation: 12.07934910402735]
	TIME [epoch: 48.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 11.170768153843792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.170768153843792 | validation: 11.053572042630655]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 10.710397294170857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.710397294170857 | validation: 10.71674682722105]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 10.297093980425801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.297093980425801 | validation: 10.265185003260235]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 9.281670914929133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.281670914929133 | validation: 9.072449722589717]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 7.417829129676255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.417829129676255 | validation: 6.392389927679948]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 6.708287747636139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.708287747636139 | validation: 6.426650247039319]
	TIME [epoch: 9.14 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 6.6409269510532525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6409269510532525 | validation: 6.907018140939036]
	TIME [epoch: 9.11 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 6.731447964616676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.731447964616676 | validation: 6.333448750424998]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 6.674313805140424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.674313805140424 | validation: 6.259247424268028]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 6.563091801055313		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 6.563091801055313 | validation: 6.213687048986721]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 6.573777202273431		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 6.573777202273431 | validation: 6.41615001646317]
	TIME [epoch: 9.14 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 6.366300950129987		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 6.366300950129987 | validation: 6.345761430994617]
	TIME [epoch: 9.11 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 6.488352147905653		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 6.488352147905653 | validation: 6.387289142900024]
	TIME [epoch: 9.12 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 6.345603168652678		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 6.345603168652678 | validation: 6.158256436687218]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 6.522440105210336		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 6.522440105210336 | validation: 5.91311940808729]
	TIME [epoch: 9.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 6.13568484522908		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 6.13568484522908 | validation: 5.7302116441725275]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 5.8535620960215		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 5.8535620960215 | validation: 5.34932000754334]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 6.384462345350655		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 6.384462345350655 | validation: 4.821764153062364]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 5.4255070447296685		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 5.4255070447296685 | validation: 5.126077904134397]
	TIME [epoch: 9.11 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 5.970520014602971		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 5.970520014602971 | validation: 4.908219022367352]
	TIME [epoch: 9.12 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 6.106020828799269		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 6.106020828799269 | validation: 6.154528901812871]
	TIME [epoch: 9.13 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 5.803162003663826		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 5.803162003663826 | validation: 5.238861146455886]
	TIME [epoch: 9.14 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 5.445470375552552		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 5.445470375552552 | validation: 5.068877159142026]
	TIME [epoch: 9.13 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 5.121197157393874		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 5.121197157393874 | validation: 4.822443164167747]
	TIME [epoch: 9.17 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 5.328621240746183		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 5.328621240746183 | validation: 5.364222354302131]
	TIME [epoch: 9.14 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 4.876622703665487		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 4.876622703665487 | validation: 4.44194898442179]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 4.648599366660709		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 4.648599366660709 | validation: 5.495369505724548]
	TIME [epoch: 9.1 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 4.662278260978296		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 4.662278260978296 | validation: 4.352191093236229]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 4.353760673798429		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 4.353760673798429 | validation: 4.630577603086403]
	TIME [epoch: 9.14 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 4.371720543520528		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 4.371720543520528 | validation: 4.798640702181341]
	TIME [epoch: 9.13 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 4.174665677571691		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 4.174665677571691 | validation: 3.9319240615863813]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 3.991091062622435		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 3.991091062622435 | validation: 3.6125624360060185]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 3.9639928184613544		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 3.9639928184613544 | validation: 3.510004411589284]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 3.514691869528445		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 3.514691869528445 | validation: 3.3937037806938353]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 3.2617537101305296		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 3.2617537101305296 | validation: 3.1663939630985727]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 3.0611609797422115		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 3.0611609797422115 | validation: 2.6671494350386205]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 3.1143957924667016		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 3.1143957924667016 | validation: 4.4396730064354895]
	TIME [epoch: 9.12 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 2.924056189259267		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 2.924056189259267 | validation: 2.4714990777479917]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 2.7015378554175364		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 2.7015378554175364 | validation: 4.280064597527839]
	TIME [epoch: 9.11 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 3.205175318584679		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 3.205175318584679 | validation: 2.9486940062303297]
	TIME [epoch: 9.15 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 2.6608198585403002		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 2.6608198585403002 | validation: 2.480099683767993]
	TIME [epoch: 9.14 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 2.659894623541301		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 2.659894623541301 | validation: 2.36056692503098]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 2.785921674040727		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 2.785921674040727 | validation: 3.5305259065179273]
	TIME [epoch: 9.13 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 2.746006056695942		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 2.746006056695942 | validation: 2.181059504329079]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 2.440201035744471		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 2.440201035744471 | validation: 2.9199062739677704]
	TIME [epoch: 9.15 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 3.065476500538881		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 3.065476500538881 | validation: 2.3567858656840817]
	TIME [epoch: 9.12 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3247238036662923		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 2.3247238036662923 | validation: 2.3900987226705492]
	TIME [epoch: 9.13 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 2.332830058969546		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 2.332830058969546 | validation: 1.991175443464464]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3401395144563297		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 2.3401395144563297 | validation: 1.9178180493952517]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 2.397758707752454		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 2.397758707752454 | validation: 2.522163220483163]
	TIME [epoch: 9.12 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 2.090063442233018		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 2.090063442233018 | validation: 1.9764440429409902]
	TIME [epoch: 9.15 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 2.1530775758168956		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 2.1530775758168956 | validation: 1.8806960611444359]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 2.332235764726243		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 2.332235764726243 | validation: 3.0784714562014512]
	TIME [epoch: 9.13 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 2.1135797987923284		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 2.1135797987923284 | validation: 2.1752635892007377]
	TIME [epoch: 9.15 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 2.043490847481467		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 2.043490847481467 | validation: 2.08943931790143]
	TIME [epoch: 9.16 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2354663112510402		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 2.2354663112510402 | validation: 2.012814432228114]
	TIME [epoch: 9.14 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0485588289783054		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 2.0485588289783054 | validation: 1.9956903634013279]
	TIME [epoch: 9.13 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8566685724603125		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 1.8566685724603125 | validation: 1.8580648628663536]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9451111091388058		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 1.9451111091388058 | validation: 1.542970256313756]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0232010928950865		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 2.0232010928950865 | validation: 1.8279759908480697]
	TIME [epoch: 9.1 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7569391848247982		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 1.7569391848247982 | validation: 2.119029710586501]
	TIME [epoch: 9.12 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7631584885669702		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 1.7631584885669702 | validation: 2.039398150700171]
	TIME [epoch: 9.1 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 1.692266728203092		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 1.692266728203092 | validation: 2.416878909888738]
	TIME [epoch: 9.12 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9150866581067294		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 1.9150866581067294 | validation: 1.528390654776679]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9728498327479902		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 1.9728498327479902 | validation: 2.4609341290143565]
	TIME [epoch: 9.09 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 1.768013297930048		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 1.768013297930048 | validation: 2.058459705232043]
	TIME [epoch: 9.1 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9777121167726548		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 1.9777121167726548 | validation: 2.722813799637806]
	TIME [epoch: 9.08 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 1.775294564402244		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 1.775294564402244 | validation: 1.30344383267155]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6838675362922355		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 1.6838675362922355 | validation: 2.650509998259478]
	TIME [epoch: 9.13 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 1.733112471554998		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 1.733112471554998 | validation: 1.72672335353698]
	TIME [epoch: 9.12 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 1.799455221484314		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 1.799455221484314 | validation: 1.5438094548796173]
	TIME [epoch: 9.12 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6680948355601957		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 1.6680948355601957 | validation: 2.3416331185794625]
	TIME [epoch: 9.15 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7742389845760809		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 1.7742389845760809 | validation: 2.4607222079244835]
	TIME [epoch: 9.13 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7885317877888152		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 1.7885317877888152 | validation: 1.2943225458787528]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7824414769980534		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 1.7824414769980534 | validation: 1.5502423683395552]
	TIME [epoch: 9.11 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8371849215187677		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 1.8371849215187677 | validation: 1.5438300864831243]
	TIME [epoch: 9.1 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7964650568713398		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 1.7964650568713398 | validation: 2.207793114979112]
	TIME [epoch: 9.13 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5970367538808456		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 1.5970367538808456 | validation: 1.4904306366194024]
	TIME [epoch: 9.07 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5638344479002049		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 1.5638344479002049 | validation: 1.3663269443856185]
	TIME [epoch: 9.04 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5620772743221116		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 1.5620772743221116 | validation: 1.1688716778338835]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4913656970221454		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 1.4913656970221454 | validation: 1.4946353503955252]
	TIME [epoch: 9.12 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3741890529204985		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 1.3741890529204985 | validation: 1.394128127476364]
	TIME [epoch: 9.1 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3071810335451963		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 1.3071810335451963 | validation: 2.365397134143733]
	TIME [epoch: 9.09 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 1.504515429552677		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 1.504515429552677 | validation: 1.0749928875387993]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3326138845872781		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 1.3326138845872781 | validation: 1.6179875592071373]
	TIME [epoch: 9.12 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7064559940340547		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 1.7064559940340547 | validation: 1.2600757665806874]
	TIME [epoch: 9.13 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4256131611764524		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 1.4256131611764524 | validation: 1.3777860067352568]
	TIME [epoch: 9.13 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 1.278512631554772		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 1.278512631554772 | validation: 1.5650076822275498]
	TIME [epoch: 9.13 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3971637972916295		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 1.3971637972916295 | validation: 1.481087239416465]
	TIME [epoch: 9.14 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7724088965936566		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 1.7724088965936566 | validation: 2.3077047101748187]
	TIME [epoch: 9.13 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7225871277250626		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 1.7225871277250626 | validation: 1.2627614316572846]
	TIME [epoch: 9.14 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5058144402243854		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 1.5058144402243854 | validation: 1.190803612430368]
	TIME [epoch: 9.12 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7743980597370261		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 1.7743980597370261 | validation: 1.2497620741936695]
	TIME [epoch: 9.16 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4160697601807937		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 1.4160697601807937 | validation: 1.34167600178225]
	TIME [epoch: 9.14 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3335695456834151		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 1.3335695456834151 | validation: 1.2536719013319177]
	TIME [epoch: 9.13 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2375793497605643		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 1.2375793497605643 | validation: 1.4339448194558955]
	TIME [epoch: 9.12 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 2.1554576853413483		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 2.1554576853413483 | validation: 1.2357971438369377]
	TIME [epoch: 9.16 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3160672628659953		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 1.3160672628659953 | validation: 1.1633541359865016]
	TIME [epoch: 9.15 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5472834835872888		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 1.5472834835872888 | validation: 1.2112915592606013]
	TIME [epoch: 9.13 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2511688537972656		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 1.2511688537972656 | validation: 1.1808327824552365]
	TIME [epoch: 9.12 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1956501549693825		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 1.1956501549693825 | validation: 1.7129472038566456]
	TIME [epoch: 9.14 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2090357412756632		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 1.2090357412756632 | validation: 1.7533471947945864]
	TIME [epoch: 9.14 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3621928804808303		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 1.3621928804808303 | validation: 1.2939094943676617]
	TIME [epoch: 9.12 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3559701461430276		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 1.3559701461430276 | validation: 1.1728554280096868]
	TIME [epoch: 9.11 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3615607170454032		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 1.3615607170454032 | validation: 1.291483809066781]
	TIME [epoch: 9.13 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3322480255222422		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 1.3322480255222422 | validation: 1.0279162090847085]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2260097556482987		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 1.2260097556482987 | validation: 0.882575019742776]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2825395235079766		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 1.2825395235079766 | validation: 1.5945602982233278]
	TIME [epoch: 9.13 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 1.360655527650243		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 1.360655527650243 | validation: 1.4030657644996687]
	TIME [epoch: 9.15 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2763812535397823		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 1.2763812535397823 | validation: 1.2375031876239742]
	TIME [epoch: 9.14 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2920390589001938		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 1.2920390589001938 | validation: 1.1788828239373779]
	TIME [epoch: 9.11 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1743697467124046		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 1.1743697467124046 | validation: 1.161689668417754]
	TIME [epoch: 9.13 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5022723106382194		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 1.5022723106382194 | validation: 1.7828228207992596]
	TIME [epoch: 9.13 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4169768609852182		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 1.4169768609852182 | validation: 1.1038683733605588]
	TIME [epoch: 9.1 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2923502271106762		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 1.2923502271106762 | validation: 1.1714626098706211]
	TIME [epoch: 9.08 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 1.185203473835187		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 1.185203473835187 | validation: 0.9806112700765686]
	TIME [epoch: 9.09 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 1.396907161845927		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 1.396907161845927 | validation: 0.9485894736881543]
	TIME [epoch: 9.09 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2447424404288006		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 1.2447424404288006 | validation: 1.4060805427668654]
	TIME [epoch: 9.12 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2257192378788324		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 1.2257192378788324 | validation: 0.8754249337308009]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_120.pth
	Model improved!!!
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1156815493539145		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 1.1156815493539145 | validation: 0.9532687593827571]
	TIME [epoch: 9.14 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5441037921215979		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 1.5441037921215979 | validation: 1.8410961173783176]
	TIME [epoch: 9.15 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1871576562899928		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 1.1871576562899928 | validation: 1.651293561729461]
	TIME [epoch: 9.16 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3701247340608966		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 1.3701247340608966 | validation: 1.4130460730774919]
	TIME [epoch: 9.15 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0430058940971332		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 1.0430058940971332 | validation: 0.9951567127836565]
	TIME [epoch: 9.15 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 1.247414553721749		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 1.247414553721749 | validation: 1.138694825663014]
	TIME [epoch: 9.15 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1103794720030349		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 1.1103794720030349 | validation: 1.3083211317370589]
	TIME [epoch: 9.18 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9325767791008384		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.9325767791008384 | validation: 0.933094000960672]
	TIME [epoch: 9.14 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8844618050413929		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.8844618050413929 | validation: 0.8795994884635665]
	TIME [epoch: 9.16 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0803692624624306		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 1.0803692624624306 | validation: 0.69552502668828]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3230079771723333		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 1.3230079771723333 | validation: 0.7566141210674543]
	TIME [epoch: 9.14 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9469803668755598		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.9469803668755598 | validation: 0.6415137677966525]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0449999245297783		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 1.0449999245297783 | validation: 1.037120486926386]
	TIME [epoch: 9.12 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0054308669192928		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 1.0054308669192928 | validation: 0.8696460034198092]
	TIME [epoch: 9.12 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0295643770105058		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 1.0295643770105058 | validation: 0.8989551576245247]
	TIME [epoch: 9.16 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0123796849938327		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 1.0123796849938327 | validation: 0.9218389332299277]
	TIME [epoch: 9.15 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9547591590202587		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.9547591590202587 | validation: 2.1335426707955296]
	TIME [epoch: 9.15 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 1.149932943621908		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 1.149932943621908 | validation: 0.5945167211877388]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_138.pth
	Model improved!!!
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9498305068388386		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.9498305068388386 | validation: 2.8123487371832407]
	TIME [epoch: 9.17 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5526732805701928		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 1.5526732805701928 | validation: 1.0791443099375613]
	TIME [epoch: 9.16 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8930434288115159		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.8930434288115159 | validation: 0.6567164530943497]
	TIME [epoch: 9.15 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8524705188263109		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.8524705188263109 | validation: 1.1666473515288018]
	TIME [epoch: 9.15 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8345936472475362		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.8345936472475362 | validation: 0.7443313971130336]
	TIME [epoch: 9.18 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2703361992874265		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 1.2703361992874265 | validation: 2.01627510244594]
	TIME [epoch: 9.17 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3157072132369776		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 1.3157072132369776 | validation: 0.886572237351615]
	TIME [epoch: 9.17 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8774260621813241		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.8774260621813241 | validation: 0.6514732529619256]
	TIME [epoch: 9.17 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8840642241326501		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.8840642241326501 | validation: 0.623785723873667]
	TIME [epoch: 9.19 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9343592547494378		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.9343592547494378 | validation: 1.1777870708765672]
	TIME [epoch: 9.17 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9861857039025759		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.9861857039025759 | validation: 1.4178863155552155]
	TIME [epoch: 9.19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8670027479277869		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.8670027479277869 | validation: 0.7037031743570914]
	TIME [epoch: 9.19 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0508033605998528		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 1.0508033605998528 | validation: 0.8215945930157029]
	TIME [epoch: 9.2 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8843531328686804		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.8843531328686804 | validation: 1.7310666587207466]
	TIME [epoch: 9.19 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0676669085245027		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 1.0676669085245027 | validation: 0.6835208202841484]
	TIME [epoch: 9.21 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.764466565802868		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.764466565802868 | validation: 2.2600739220672184]
	TIME [epoch: 9.18 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1198746704970586		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 1.1198746704970586 | validation: 1.4021593267933217]
	TIME [epoch: 9.19 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 1.144004992897663		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 1.144004992897663 | validation: 0.6681756079998911]
	TIME [epoch: 9.2 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 1.022402799079409		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 1.022402799079409 | validation: 1.1489021046351946]
	TIME [epoch: 9.2 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9163243792958159		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.9163243792958159 | validation: 1.1566218866226503]
	TIME [epoch: 9.17 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8413004134162435		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.8413004134162435 | validation: 0.5981523278139368]
	TIME [epoch: 9.21 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1477323536884176		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 1.1477323536884176 | validation: 1.3053789050331601]
	TIME [epoch: 9.21 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1353245925782685		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 1.1353245925782685 | validation: 1.5358248323304684]
	TIME [epoch: 9.17 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.983560062398188		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.983560062398188 | validation: 0.8793613955415966]
	TIME [epoch: 9.13 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8163638458064802		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.8163638458064802 | validation: 1.1215572113817385]
	TIME [epoch: 9.19 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1847502487640678		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 1.1847502487640678 | validation: 0.8212527345581206]
	TIME [epoch: 9.18 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0271047594345641		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 1.0271047594345641 | validation: 0.7647726767337447]
	TIME [epoch: 9.17 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.963721980794358		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.963721980794358 | validation: 0.666999823553081]
	TIME [epoch: 9.18 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.804355454877047		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.804355454877047 | validation: 1.856857067371875]
	TIME [epoch: 9.18 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9877915053451337		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.9877915053451337 | validation: 0.6279827860322241]
	TIME [epoch: 9.16 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9867523361883677		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.9867523361883677 | validation: 1.2905802013967573]
	TIME [epoch: 9.16 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7714446616251199		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.7714446616251199 | validation: 0.8611607833184272]
	TIME [epoch: 9.14 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.853580710945069		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.853580710945069 | validation: 0.8687963058925374]
	TIME [epoch: 9.19 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0493121260371188		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 1.0493121260371188 | validation: 0.7285114143989115]
	TIME [epoch: 9.17 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8060933802879168		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.8060933802879168 | validation: 0.8011203416654146]
	TIME [epoch: 9.15 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9159989065150874		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.9159989065150874 | validation: 0.7523464855131129]
	TIME [epoch: 9.13 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 1.137319997305797		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 1.137319997305797 | validation: 0.7552391431749784]
	TIME [epoch: 9.15 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9309210800816213		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.9309210800816213 | validation: 1.1056675372084894]
	TIME [epoch: 9.16 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9411278597863661		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.9411278597863661 | validation: 1.6408777435248734]
	TIME [epoch: 9.18 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8857425623987212		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.8857425623987212 | validation: 1.2142127218119891]
	TIME [epoch: 9.15 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0512082025373801		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 1.0512082025373801 | validation: 0.5912048780364797]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_179.pth
	Model improved!!!
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7836290723110065		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.7836290723110065 | validation: 0.694283182091054]
	TIME [epoch: 9.18 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7309622389831579		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.7309622389831579 | validation: 0.8362280967129418]
	TIME [epoch: 9.18 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9275189680788272		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.9275189680788272 | validation: 1.3252146005591023]
	TIME [epoch: 9.17 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8169699261309189		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.8169699261309189 | validation: 0.7587889455775508]
	TIME [epoch: 9.17 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7656132398783806		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.7656132398783806 | validation: 0.6382768490050197]
	TIME [epoch: 9.14 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9283992451381309		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.9283992451381309 | validation: 0.6857989832680425]
	TIME [epoch: 9.19 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7688907527418207		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.7688907527418207 | validation: 0.7566131650425229]
	TIME [epoch: 9.18 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7153241290694264		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.7153241290694264 | validation: 0.7389269251653918]
	TIME [epoch: 9.18 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8611881264153194		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.8611881264153194 | validation: 0.6900488130788771]
	TIME [epoch: 9.2 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6749908357311559		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.6749908357311559 | validation: 0.7770721027596171]
	TIME [epoch: 9.21 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8092550141960467		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.8092550141960467 | validation: 0.860221175927637]
	TIME [epoch: 9.19 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9535765624515541		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.9535765624515541 | validation: 1.0630445223694713]
	TIME [epoch: 9.2 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7794299638163724		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.7794299638163724 | validation: 0.4818695396084868]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_192.pth
	Model improved!!!
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8082484936721188		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.8082484936721188 | validation: 0.4694806037215171]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_193.pth
	Model improved!!!
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.708839595468198		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.708839595468198 | validation: 0.808989604427746]
	TIME [epoch: 9.17 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8406585484157402		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.8406585484157402 | validation: 1.7731194311971619]
	TIME [epoch: 9.2 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2260710240370183		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 1.2260710240370183 | validation: 0.6654175482775835]
	TIME [epoch: 9.19 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9133082420486899		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.9133082420486899 | validation: 0.990032696182314]
	TIME [epoch: 9.22 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8729204199741337		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.8729204199741337 | validation: 1.1674456766027903]
	TIME [epoch: 9.22 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8419644782268676		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.8419644782268676 | validation: 0.6114540000772689]
	TIME [epoch: 9.18 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6517717383819828		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.6517717383819828 | validation: 0.8418212190154266]
	TIME [epoch: 9.19 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7255419092840871		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.7255419092840871 | validation: 1.3897928312017984]
	TIME [epoch: 9.23 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9095887247626591		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.9095887247626591 | validation: 0.7892001266505122]
	TIME [epoch: 9.21 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7500324900688426		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.7500324900688426 | validation: 0.6807602854250533]
	TIME [epoch: 9.21 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8651325136500336		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.8651325136500336 | validation: 0.7446852999315211]
	TIME [epoch: 9.19 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7546977240673035		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.7546977240673035 | validation: 0.751522071827903]
	TIME [epoch: 9.19 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7338406683174103		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.7338406683174103 | validation: 0.5142379498460206]
	TIME [epoch: 9.18 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6519589409854463		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.6519589409854463 | validation: 0.490092945006933]
	TIME [epoch: 9.18 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7928010210811929		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.7928010210811929 | validation: 0.4879262145887925]
	TIME [epoch: 9.21 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7592805551932407		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.7592805551932407 | validation: 0.9108156087111074]
	TIME [epoch: 9.22 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8743101568827892		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.8743101568827892 | validation: 0.4588755547615475]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_210.pth
	Model improved!!!
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7129319860071412		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.7129319860071412 | validation: 0.45577122921526714]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_211.pth
	Model improved!!!
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8185023388002893		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.8185023388002893 | validation: 0.538806820281224]
	TIME [epoch: 9.19 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8713048202849334		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.8713048202849334 | validation: 0.8256571700960913]
	TIME [epoch: 9.2 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7561443215779111		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.7561443215779111 | validation: 1.4758049090590024]
	TIME [epoch: 9.23 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8256886057345032		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.8256886057345032 | validation: 0.672462209054184]
	TIME [epoch: 9.21 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7338223316320498		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.7338223316320498 | validation: 0.7175056528861767]
	TIME [epoch: 9.21 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8179162192650544		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.8179162192650544 | validation: 0.6316533026677986]
	TIME [epoch: 9.21 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7167611299858788		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.7167611299858788 | validation: 0.6102825236998417]
	TIME [epoch: 9.23 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6436356426419164		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.6436356426419164 | validation: 0.6245428548298944]
	TIME [epoch: 9.21 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3193064792100742		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 1.3193064792100742 | validation: 1.301256993357728]
	TIME [epoch: 9.21 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8802469740038077		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.8802469740038077 | validation: 1.0589483858414526]
	TIME [epoch: 9.19 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7480181758628317		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.7480181758628317 | validation: 0.9810221510830924]
	TIME [epoch: 9.23 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6267499801908951		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.6267499801908951 | validation: 0.6841741195314228]
	TIME [epoch: 9.21 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5061069357219237		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.5061069357219237 | validation: 0.4329246208706139]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_224.pth
	Model improved!!!
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7002219804119262		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.7002219804119262 | validation: 0.5222148836983419]
	TIME [epoch: 9.19 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5909381945256198		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.5909381945256198 | validation: 0.655743075132005]
	TIME [epoch: 9.2 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7380791103532173		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.7380791103532173 | validation: 1.0908601590499396]
	TIME [epoch: 9.17 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7122856457462283		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.7122856457462283 | validation: 0.7579828876596493]
	TIME [epoch: 9.18 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7008706251419569		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.7008706251419569 | validation: 0.51150850492592]
	TIME [epoch: 9.19 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6443700481195143		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.6443700481195143 | validation: 1.3578384422908347]
	TIME [epoch: 9.21 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6726557922812693		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.6726557922812693 | validation: 0.8595127183102788]
	TIME [epoch: 9.18 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5470475854010441		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.5470475854010441 | validation: 1.007975628055561]
	TIME [epoch: 9.19 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6716817366556256		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.6716817366556256 | validation: 0.5785608473034315]
	TIME [epoch: 9.17 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5003036367277671		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.5003036367277671 | validation: 0.3511618841267896]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_234.pth
	Model improved!!!
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6993686952121421		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.6993686952121421 | validation: 0.8547044050622162]
	TIME [epoch: 9.14 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5878905718389625		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.5878905718389625 | validation: 0.8797683435066788]
	TIME [epoch: 9.15 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0545099153767463		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 1.0545099153767463 | validation: 0.809101521445323]
	TIME [epoch: 9.13 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7013083754300271		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.7013083754300271 | validation: 0.8125829097480275]
	TIME [epoch: 9.15 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6376956037531597		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.6376956037531597 | validation: 1.6074205537147392]
	TIME [epoch: 9.11 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8394404946986235		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.8394404946986235 | validation: 0.6139816509041776]
	TIME [epoch: 9.13 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6482783080113339		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.6482783080113339 | validation: 0.7587221384425413]
	TIME [epoch: 9.15 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5921896242538812		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.5921896242538812 | validation: 1.4012801123656877]
	TIME [epoch: 9.16 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8544609339308223		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.8544609339308223 | validation: 0.7611590787809224]
	TIME [epoch: 9.14 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6710002544650923		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.6710002544650923 | validation: 0.4783599405407692]
	TIME [epoch: 9.16 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6313545456880351		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.6313545456880351 | validation: 0.4391662438106532]
	TIME [epoch: 9.16 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6062086900932713		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.6062086900932713 | validation: 0.7793930056668297]
	TIME [epoch: 9.14 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8424620930872038		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.8424620930872038 | validation: 1.9931489385685661]
	TIME [epoch: 9.16 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8853819729571077		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.8853819729571077 | validation: 1.1027683553607188]
	TIME [epoch: 9.13 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7209490708942691		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.7209490708942691 | validation: 0.49418351899305946]
	TIME [epoch: 9.18 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6502381172361749		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.6502381172361749 | validation: 0.6276246363594182]
	TIME [epoch: 9.15 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6750219772401369		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.6750219772401369 | validation: 1.1267467230188584]
	TIME [epoch: 9.17 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6375155835922819		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.6375155835922819 | validation: 0.8376306250301493]
	TIME [epoch: 9.14 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5980457352616924		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.5980457352616924 | validation: 0.44471244965113976]
	TIME [epoch: 9.13 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7022453418774929		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.7022453418774929 | validation: 0.7425066265083099]
	TIME [epoch: 9.11 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5730215289615862		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.5730215289615862 | validation: 0.701601205551079]
	TIME [epoch: 9.15 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5948395602898816		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.5948395602898816 | validation: 0.5602978779244766]
	TIME [epoch: 9.12 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8762685139119766		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.8762685139119766 | validation: 0.6343141270299815]
	TIME [epoch: 9.14 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0215700519209325		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 1.0215700519209325 | validation: 0.7822244626295041]
	TIME [epoch: 9.14 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6224348157025121		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.6224348157025121 | validation: 0.670247537948592]
	TIME [epoch: 9.17 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6050607910851508		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.6050607910851508 | validation: 0.46038349228700104]
	TIME [epoch: 9.14 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9657318677891247		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.9657318677891247 | validation: 0.626335205633507]
	TIME [epoch: 9.15 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7439812973130894		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.7439812973130894 | validation: 0.5920180372733199]
	TIME [epoch: 9.15 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6228334742161475		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.6228334742161475 | validation: 0.5803691769235139]
	TIME [epoch: 9.19 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9324962232866613		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.9324962232866613 | validation: 1.7691802756877055]
	TIME [epoch: 9.14 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8044057004428448		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.8044057004428448 | validation: 0.6849886677043107]
	TIME [epoch: 9.15 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5320535570993469		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.5320535570993469 | validation: 0.5600188838457676]
	TIME [epoch: 9.16 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5309073022897033		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.5309073022897033 | validation: 0.5058040950244493]
	TIME [epoch: 9.18 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5911282371131559		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.5911282371131559 | validation: 0.5612535615886112]
	TIME [epoch: 9.16 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6087213904268031		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.6087213904268031 | validation: 0.46180294675518574]
	TIME [epoch: 9.16 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7306846106364964		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.7306846106364964 | validation: 0.746571456101297]
	TIME [epoch: 9.17 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5502582000984054		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.5502582000984054 | validation: 0.37375652443628304]
	TIME [epoch: 9.18 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5587670562201394		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.5587670562201394 | validation: 0.5218700295774593]
	TIME [epoch: 9.16 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5879906026476455		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.5879906026476455 | validation: 0.8307232515934766]
	TIME [epoch: 9.15 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5238933730173049		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.5238933730173049 | validation: 0.33531171855782427]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_274.pth
	Model improved!!!
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6931324565707471		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.6931324565707471 | validation: 0.4545272007640797]
	TIME [epoch: 9.19 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47728595104554516		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.47728595104554516 | validation: 0.3996594324471682]
	TIME [epoch: 9.16 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5700389648530849		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.5700389648530849 | validation: 1.2229269514691437]
	TIME [epoch: 9.18 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6070570156701052		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.6070570156701052 | validation: 0.37457936936675795]
	TIME [epoch: 9.15 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5775253843334024		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.5775253843334024 | validation: 0.42467466933807974]
	TIME [epoch: 9.18 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4861475161934914		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.4861475161934914 | validation: 0.4877250813103945]
	TIME [epoch: 9.18 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47019677243061214		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.47019677243061214 | validation: 0.5226878415718719]
	TIME [epoch: 9.18 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6271072239927158		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.6271072239927158 | validation: 0.7094516452123987]
	TIME [epoch: 9.16 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5896455890287381		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.5896455890287381 | validation: 0.724049402623227]
	TIME [epoch: 9.19 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5732745745678727		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.5732745745678727 | validation: 0.41909128936854456]
	TIME [epoch: 9.16 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6481929521939296		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.6481929521939296 | validation: 0.38662356815420645]
	TIME [epoch: 9.19 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.428739835440867		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.428739835440867 | validation: 0.6508000124991369]
	TIME [epoch: 9.15 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5868742962212338		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.5868742962212338 | validation: 0.5011375700463895]
	TIME [epoch: 9.17 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8070792839412382		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.8070792839412382 | validation: 0.7859389654634482]
	TIME [epoch: 9.18 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5947940596380992		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.5947940596380992 | validation: 0.483703685895623]
	TIME [epoch: 9.19 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6043052774945348		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.6043052774945348 | validation: 0.45966300590455]
	TIME [epoch: 9.15 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5164385270082421		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.5164385270082421 | validation: 1.5398971487470186]
	TIME [epoch: 9.18 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7625118435526159		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.7625118435526159 | validation: 0.4346718220635024]
	TIME [epoch: 9.16 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4880295712384399		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.4880295712384399 | validation: 0.4917056621664917]
	TIME [epoch: 9.19 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48230012045433857		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.48230012045433857 | validation: 0.5138061808709907]
	TIME [epoch: 9.15 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47620307509130655		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.47620307509130655 | validation: 0.5604094966393255]
	TIME [epoch: 9.18 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5688121475803645		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.5688121475803645 | validation: 0.6309981214310287]
	TIME [epoch: 9.17 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5065675934311893		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.5065675934311893 | validation: 0.5052996164178806]
	TIME [epoch: 9.2 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49425719848857363		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.49425719848857363 | validation: 0.7519834113196918]
	TIME [epoch: 9.15 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5535734474425716		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.5535734474425716 | validation: 0.5505205343757318]
	TIME [epoch: 9.17 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6663091150619651		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.6663091150619651 | validation: 0.5752114767144255]
	TIME [epoch: 9.15 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4910457944746745		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.4910457944746745 | validation: 0.6726051304280602]
	TIME [epoch: 9.2 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6166909192336574		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.6166909192336574 | validation: 0.5529968239150314]
	TIME [epoch: 9.17 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5798406694560476		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.5798406694560476 | validation: 0.4397329703218388]
	TIME [epoch: 9.18 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5784143216112332		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.5784143216112332 | validation: 0.521904471877491]
	TIME [epoch: 9.18 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45430318085098564		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.45430318085098564 | validation: 0.5091855858402492]
	TIME [epoch: 9.18 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5512696527468857		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.5512696527468857 | validation: 0.46524709184915747]
	TIME [epoch: 9.17 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7060200726104378		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.7060200726104378 | validation: 0.4168541683983265]
	TIME [epoch: 9.18 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48230305176949734		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.48230305176949734 | validation: 0.6543105712625762]
	TIME [epoch: 9.19 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5778466418687989		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.5778466418687989 | validation: 0.527324752399932]
	TIME [epoch: 9.2 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5525956640423336		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.5525956640423336 | validation: 0.690395144589067]
	TIME [epoch: 9.15 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5639477208034961		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.5639477208034961 | validation: 0.35060987364716856]
	TIME [epoch: 9.14 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5880245916251288		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.5880245916251288 | validation: 0.5185492620104446]
	TIME [epoch: 9.17 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5159272142353344		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.5159272142353344 | validation: 0.44093733379599337]
	TIME [epoch: 9.19 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5272764710595867		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.5272764710595867 | validation: 0.6176190253714928]
	TIME [epoch: 9.2 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49529079349062927		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.49529079349062927 | validation: 0.509053680358423]
	TIME [epoch: 9.17 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5449046873959108		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.5449046873959108 | validation: 0.5826859890536044]
	TIME [epoch: 9.18 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5111685256183277		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.5111685256183277 | validation: 0.6638622601499123]
	TIME [epoch: 9.18 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6089336289614884		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.6089336289614884 | validation: 0.6040231099171331]
	TIME [epoch: 9.16 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48770686187716394		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.48770686187716394 | validation: 0.8417015184041658]
	TIME [epoch: 9.17 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5441495539972826		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.5441495539972826 | validation: 0.6202431276713933]
	TIME [epoch: 9.16 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46829712292748005		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.46829712292748005 | validation: 0.548128951685431]
	TIME [epoch: 9.19 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48096427227898025		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.48096427227898025 | validation: 0.33315399832053794]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_322.pth
	Model improved!!!
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4169376969285552		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.4169376969285552 | validation: 0.4504545401659241]
	TIME [epoch: 9.17 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5646193709347763		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.5646193709347763 | validation: 0.6389931951889574]
	TIME [epoch: 9.17 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5517889484491484		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.5517889484491484 | validation: 0.3933866041335058]
	TIME [epoch: 9.18 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43135598008577836		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.43135598008577836 | validation: 0.3387412977963714]
	TIME [epoch: 9.19 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.379964820648603		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.379964820648603 | validation: 0.3652229488377514]
	TIME [epoch: 9.17 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5585921090097299		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.5585921090097299 | validation: 0.8916608800888615]
	TIME [epoch: 9.17 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5170188322515733		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.5170188322515733 | validation: 0.47160734982805996]
	TIME [epoch: 9.2 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45940447232995474		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.45940447232995474 | validation: 0.9609977666491027]
	TIME [epoch: 9.19 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5682014825336053		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.5682014825336053 | validation: 0.3331176555555021]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_331.pth
	Model improved!!!
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49796126553304043		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.49796126553304043 | validation: 0.38535340892874625]
	TIME [epoch: 9.17 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5646514166622196		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.5646514166622196 | validation: 0.45068647059780603]
	TIME [epoch: 9.18 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5135570618888884		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.5135570618888884 | validation: 0.47934357712070164]
	TIME [epoch: 9.2 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3686978030927749		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.3686978030927749 | validation: 0.30035084018426206]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_335.pth
	Model improved!!!
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5476707878526005		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.5476707878526005 | validation: 1.5911287824288523]
	TIME [epoch: 9.18 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7181503178120436		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.7181503178120436 | validation: 0.5937147961846361]
	TIME [epoch: 9.21 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5144390820748341		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.5144390820748341 | validation: 0.3633059240032736]
	TIME [epoch: 9.2 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4292254107339836		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.4292254107339836 | validation: 0.29815947511748236]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_339.pth
	Model improved!!!
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5513113956626365		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.5513113956626365 | validation: 0.37802798967857937]
	TIME [epoch: 9.18 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3869050193975726		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.3869050193975726 | validation: 0.37840613765325243]
	TIME [epoch: 9.19 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4224752902146289		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.4224752902146289 | validation: 0.3400293381987072]
	TIME [epoch: 9.21 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36131519758352426		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.36131519758352426 | validation: 0.6211798088075134]
	TIME [epoch: 9.2 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45707236940202883		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.45707236940202883 | validation: 0.628937921837142]
	TIME [epoch: 9.19 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4724702690862605		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.4724702690862605 | validation: 0.3798935174805044]
	TIME [epoch: 9.2 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37007313480164306		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.37007313480164306 | validation: 0.30206578362074554]
	TIME [epoch: 9.21 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4661489322346549		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.4661489322346549 | validation: 0.37596135909554196]
	TIME [epoch: 9.2 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36707657759171863		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.36707657759171863 | validation: 0.35205633774446515]
	TIME [epoch: 9.19 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5340035138227638		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.5340035138227638 | validation: 0.7583661355547642]
	TIME [epoch: 9.19 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45028868980628134		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.45028868980628134 | validation: 0.7277331218317193]
	TIME [epoch: 9.22 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49210456090042054		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.49210456090042054 | validation: 0.39640840320388826]
	TIME [epoch: 9.18 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4593379581714715		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.4593379581714715 | validation: 0.255983004135567]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_352.pth
	Model improved!!!
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3450452858741322		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.3450452858741322 | validation: 0.710280564547084]
	TIME [epoch: 9.18 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6624520730377228		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.6624520730377228 | validation: 0.41664246939738403]
	TIME [epoch: 9.2 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5109197486026191		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.5109197486026191 | validation: 0.4898543611202344]
	TIME [epoch: 9.18 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37506465486312945		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.37506465486312945 | validation: 0.31465621069547867]
	TIME [epoch: 9.19 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34688311214670176		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.34688311214670176 | validation: 0.2944869973154981]
	TIME [epoch: 9.19 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32911488431807046		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.32911488431807046 | validation: 0.5354632780192436]
	TIME [epoch: 9.21 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3677774474000974		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.3677774474000974 | validation: 0.26852143326716327]
	TIME [epoch: 9.22 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3827746909506438		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.3827746909506438 | validation: 0.3863093184232871]
	TIME [epoch: 9.21 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38229716488763255		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.38229716488763255 | validation: 0.33206885289061805]
	TIME [epoch: 9.2 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3591980368865813		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.3591980368865813 | validation: 0.4700324711692714]
	TIME [epoch: 9.22 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3455114098344127		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.3455114098344127 | validation: 0.4807384328223012]
	TIME [epoch: 9.2 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3171494635680462		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.3171494635680462 | validation: 0.46314295876294076]
	TIME [epoch: 9.21 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6004249283389511		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.6004249283389511 | validation: 0.3487479870891234]
	TIME [epoch: 9.19 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3736224028944776		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.3736224028944776 | validation: 0.6124434190797103]
	TIME [epoch: 9.21 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3741814726615675		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.3741814726615675 | validation: 0.3432382246668513]
	TIME [epoch: 9.21 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3348284469576714		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.3348284469576714 | validation: 0.440519679657862]
	TIME [epoch: 9.21 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43803265240409556		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.43803265240409556 | validation: 0.2682877536106192]
	TIME [epoch: 9.21 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3654059961147948		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.3654059961147948 | validation: 0.282034089628424]
	TIME [epoch: 9.21 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3436572634618277		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.3436572634618277 | validation: 0.22368939543655952]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_371.pth
	Model improved!!!
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33011886274440105		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.33011886274440105 | validation: 0.5997360030106769]
	TIME [epoch: 9.2 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46910518950847424		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.46910518950847424 | validation: 0.29459416420980816]
	TIME [epoch: 9.2 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3591608586156135		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.3591608586156135 | validation: 0.43041799717506374]
	TIME [epoch: 9.21 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42444541717516077		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.42444541717516077 | validation: 0.31978865101980786]
	TIME [epoch: 9.22 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4094874862206389		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.4094874862206389 | validation: 0.23029339402205667]
	TIME [epoch: 9.2 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31375679138884577		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.31375679138884577 | validation: 0.3667956844840341]
	TIME [epoch: 9.2 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2978621692066292		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.2978621692066292 | validation: 0.2378080365933906]
	TIME [epoch: 9.19 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37067654140239475		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.37067654140239475 | validation: 0.4381103051696337]
	TIME [epoch: 9.22 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32328126110849476		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.32328126110849476 | validation: 0.1895945744468004]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_380.pth
	Model improved!!!
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38941989236943997		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.38941989236943997 | validation: 0.3594437480035642]
	TIME [epoch: 9.2 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3847965680969225		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.3847965680969225 | validation: 0.25718470545002636]
	TIME [epoch: 9.21 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2670742800282778		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.2670742800282778 | validation: 0.29436185629591505]
	TIME [epoch: 9.23 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4324389837998267		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.4324389837998267 | validation: 0.47240601842940805]
	TIME [epoch: 9.2 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44460602590623033		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.44460602590623033 | validation: 0.3142953002642087]
	TIME [epoch: 9.21 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28232617149654005		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.28232617149654005 | validation: 0.19911037393390826]
	TIME [epoch: 9.2 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29382223422366816		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.29382223422366816 | validation: 0.23883218827002295]
	TIME [epoch: 9.22 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2832982162135139		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.2832982162135139 | validation: 0.19740930296985687]
	TIME [epoch: 9.21 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25387182697650024		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.25387182697650024 | validation: 0.3986108540544913]
	TIME [epoch: 9.2 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33202535848140796		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.33202535848140796 | validation: 0.5148715309648388]
	TIME [epoch: 9.21 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6780824146934863		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.6780824146934863 | validation: 0.49299622834047774]
	TIME [epoch: 9.22 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3060561778584739		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.3060561778584739 | validation: 0.33730516563120616]
	TIME [epoch: 9.21 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30473525911221494		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.30473525911221494 | validation: 0.18684244405166822]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_393.pth
	Model improved!!!
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3268624113636928		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.3268624113636928 | validation: 0.28280002341148286]
	TIME [epoch: 9.18 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2507108035000073		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.2507108035000073 | validation: 0.23209877387632494]
	TIME [epoch: 9.2 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31361138832581015		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.31361138832581015 | validation: 0.3504077209921793]
	TIME [epoch: 9.17 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4509249940884864		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.4509249940884864 | validation: 0.23728977654897396]
	TIME [epoch: 9.17 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34488983649035365		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.34488983649035365 | validation: 0.34622168679495546]
	TIME [epoch: 9.18 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4368450709809332		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.4368450709809332 | validation: 0.3796320600789398]
	TIME [epoch: 9.22 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3341957601412756		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.3341957601412756 | validation: 0.40714919572017405]
	TIME [epoch: 9.18 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3460994477667174		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.3460994477667174 | validation: 0.2969928362313239]
	TIME [epoch: 9.19 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38855922474953164		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.38855922474953164 | validation: 0.3169499383729112]
	TIME [epoch: 9.19 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36370730149696145		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.36370730149696145 | validation: 0.3507102173487972]
	TIME [epoch: 9.21 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3197893031395282		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.3197893031395282 | validation: 0.5583487701707291]
	TIME [epoch: 9.2 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37440773578052255		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.37440773578052255 | validation: 0.3010204858555617]
	TIME [epoch: 9.2 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24556554260141827		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.24556554260141827 | validation: 0.264781046603593]
	TIME [epoch: 9.2 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3401069750338276		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.3401069750338276 | validation: 0.2843233711558475]
	TIME [epoch: 9.21 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2846781124179585		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.2846781124179585 | validation: 0.5283627120083745]
	TIME [epoch: 9.21 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.317686561689695		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.317686561689695 | validation: 0.25338443389095283]
	TIME [epoch: 9.19 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26955254368436493		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.26955254368436493 | validation: 0.19889059228430458]
	TIME [epoch: 9.2 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3807561059902844		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.3807561059902844 | validation: 0.20112234809905588]
	TIME [epoch: 9.21 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26844144775718676		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.26844144775718676 | validation: 0.40079362355085635]
	TIME [epoch: 9.22 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34974109640628137		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.34974109640628137 | validation: 0.37986398837183166]
	TIME [epoch: 9.19 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3159296211263067		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.3159296211263067 | validation: 0.2904081230369293]
	TIME [epoch: 9.19 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27485145955979645		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.27485145955979645 | validation: 0.2412169384507994]
	TIME [epoch: 9.18 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3057499684285611		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.3057499684285611 | validation: 0.3210251639446967]
	TIME [epoch: 9.21 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2983846342898038		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.2983846342898038 | validation: 0.4956447474719628]
	TIME [epoch: 9.17 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3110711759018217		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.3110711759018217 | validation: 0.36817626082464594]
	TIME [epoch: 9.18 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3169726616996071		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.3169726616996071 | validation: 0.23602461274129882]
	TIME [epoch: 9.19 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2623156382810331		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.2623156382810331 | validation: 0.36452371751411716]
	TIME [epoch: 9.23 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3039855649641424		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.3039855649641424 | validation: 0.27366618723777203]
	TIME [epoch: 9.2 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2804770921457685		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.2804770921457685 | validation: 0.3744742223192787]
	TIME [epoch: 9.2 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3443582216838482		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.3443582216838482 | validation: 0.384734872384113]
	TIME [epoch: 9.2 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23821029993189144		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.23821029993189144 | validation: 0.2198891655241042]
	TIME [epoch: 9.23 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21637745089486726		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.21637745089486726 | validation: 0.20336259615094146]
	TIME [epoch: 9.21 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25131481942204253		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.25131481942204253 | validation: 0.3107579174376839]
	TIME [epoch: 9.2 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28418159235584817		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.28418159235584817 | validation: 0.20925227413532066]
	TIME [epoch: 9.21 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22710115148580878		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.22710115148580878 | validation: 0.187769317351559]
	TIME [epoch: 9.24 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2509134143810285		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.2509134143810285 | validation: 0.19291676919172915]
	TIME [epoch: 9.22 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23364508404201292		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.23364508404201292 | validation: 0.20766916218841228]
	TIME [epoch: 9.21 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21648673206554697		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.21648673206554697 | validation: 0.20412722227618385]
	TIME [epoch: 9.21 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2789248183673977		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.2789248183673977 | validation: 0.7884161206966387]
	TIME [epoch: 9.24 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40247409752728525		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.40247409752728525 | validation: 0.13572819131016]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240214_223534/states/model_tr_study3_433.pth
	Model improved!!!
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2776281521491888		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.2776281521491888 | validation: 0.1867231782444412]
	TIME [epoch: 9.2 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.367619631101085		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.367619631101085 | validation: 0.2258458906310167]
	TIME [epoch: 9.2 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.252755998052623		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.252755998052623 | validation: 0.20466733609704515]
	TIME [epoch: 9.22 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26556927098382305		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.26556927098382305 | validation: 0.14201869214991641]
	TIME [epoch: 9.21 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24819623917211248		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.24819623917211248 | validation: 0.27085854620300875]
	TIME [epoch: 9.21 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19562766819760385		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.19562766819760385 | validation: 0.3555547681098541]
	TIME [epoch: 9.21 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26373219041518575		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.26373219041518575 | validation: 0.1893331105275102]
	TIME [epoch: 9.22 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21474069348190689		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.21474069348190689 | validation: 0.4143360135534616]
	TIME [epoch: 9.19 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.289859891052189		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.289859891052189 | validation: 0.1568189400162739]
	TIME [epoch: 9.17 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2645744829170222		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.2645744829170222 | validation: 0.2094067456738951]
	TIME [epoch: 9.18 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2494052988885716		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.2494052988885716 | validation: 0.23875549133248536]
	TIME [epoch: 9.2 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24817164879233697		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.24817164879233697 | validation: 0.2031399076621231]
	TIME [epoch: 9.22 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2498735849828289		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.2498735849828289 | validation: 0.2394782665824689]
	TIME [epoch: 9.19 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.244194595763013		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.244194595763013 | validation: 0.2405809477338843]
	TIME [epoch: 9.19 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19717236358409973		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.19717236358409973 | validation: 0.17785645094079044]
	TIME [epoch: 9.2 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2816152947095712		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.2816152947095712 | validation: 0.2559525749285464]
	TIME [epoch: 9.21 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25889077303418323		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.25889077303418323 | validation: 0.392173244383512]
	TIME [epoch: 9.21 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25745503080262855		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.25745503080262855 | validation: 0.16741782671194613]
	TIME [epoch: 9.19 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2377767189190588		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.2377767189190588 | validation: 0.15366214167826978]
	TIME [epoch: 9.18 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19666815416803962		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.19666815416803962 | validation: 0.1815357818911366]
	TIME [epoch: 9.22 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27014993763227946		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.27014993763227946 | validation: 0.30303709422909786]
	TIME [epoch: 9.19 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23223659157410662		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.23223659157410662 | validation: 0.1801022897789391]
	TIME [epoch: 9.2 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25843857198290904		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.25843857198290904 | validation: 0.2835104678237293]
	TIME [epoch: 9.21 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23317653781294112		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.23317653781294112 | validation: 0.2763753014356996]
	TIME [epoch: 9.23 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25613580042666495		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.25613580042666495 | validation: 0.18507802768787857]
	TIME [epoch: 9.21 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20280223638618064		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.20280223638618064 | validation: 0.1719903295047471]
	TIME [epoch: 9.22 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19227634449531694		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.19227634449531694 | validation: 0.35857271410976677]
	TIME [epoch: 9.2 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2239048453320751		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.2239048453320751 | validation: 0.20040878064029521]
	TIME [epoch: 9.22 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23063723610674539		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.23063723610674539 | validation: 0.3493001661302777]
	TIME [epoch: 9.2 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2789451000786645		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.2789451000786645 | validation: 0.22529881033001598]
	TIME [epoch: 9.21 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2682292749855658		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.2682292749855658 | validation: 0.1672025722460425]
	TIME [epoch: 9.21 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21336100242823028		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.21336100242823028 | validation: 0.2185862576015732]
	TIME [epoch: 9.24 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2194682178651354		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.2194682178651354 | validation: 0.1855776282106532]
	TIME [epoch: 9.23 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2085073810246803		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.2085073810246803 | validation: 0.15983944495583485]
	TIME [epoch: 9.22 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2653921494992032		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.2653921494992032 | validation: 0.3016394954155863]
	TIME [epoch: 9.22 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3543655066307917		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.3543655066307917 | validation: 0.3186309953167724]
	TIME [epoch: 9.24 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28825236113514435		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.28825236113514435 | validation: 0.37759213746459525]
	TIME [epoch: 9.23 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3079332242401075		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.3079332242401075 | validation: 0.28153544852756585]
	TIME [epoch: 9.21 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2318765596517204		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.2318765596517204 | validation: 0.29940403844243635]
	TIME [epoch: 9.21 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23339267662509036		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.23339267662509036 | validation: 0.4114676984937644]
	TIME [epoch: 9.24 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28002491906962707		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.28002491906962707 | validation: 0.3133836110764786]
	TIME [epoch: 9.21 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18018606271893595		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.18018606271893595 | validation: 0.24274010509614008]
	TIME [epoch: 9.19 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19636681688803953		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.19636681688803953 | validation: 0.3537861725275458]
	TIME [epoch: 9.2 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3087718966461463		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.3087718966461463 | validation: 0.1839307216441112]
	TIME [epoch: 9.21 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21321907353962807		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.21321907353962807 | validation: 0.26102419487899886]
	TIME [epoch: 9.21 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23583347438023208		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.23583347438023208 | validation: 0.16823537569943314]
	TIME [epoch: 9.19 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1775588560712598		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.1775588560712598 | validation: 0.13861764066278917]
	TIME [epoch: 9.17 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19053554913545093		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.19053554913545093 | validation: 0.2186717027930128]
	TIME [epoch: 9.19 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20499865513077084		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.20499865513077084 | validation: 0.15301769336741944]
	TIME [epoch: 9.22 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17651166571260096		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.17651166571260096 | validation: 0.1872979197779497]
	TIME [epoch: 9.21 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23855612003767918		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.23855612003767918 | validation: 0.311187746311155]
	TIME [epoch: 9.21 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23407102299048152		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.23407102299048152 | validation: 0.3128128934285882]
	TIME [epoch: 9.21 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19589948934647552		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.19589948934647552 | validation: 0.3177794293852434]
	TIME [epoch: 9.24 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2225173892586379		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.2225173892586379 | validation: 0.17960818149872113]
	TIME [epoch: 9.21 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2529254165128113		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.2529254165128113 | validation: 0.27320157807725515]
	TIME [epoch: 9.21 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30918617865069764		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.30918617865069764 | validation: 0.4370694871103231]
	TIME [epoch: 9.2 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28374593337055665		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.28374593337055665 | validation: 0.17863870282743616]
	TIME [epoch: 9.24 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23319128482283377		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.23319128482283377 | validation: 0.297134579697074]
	TIME [epoch: 9.21 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3348211424025981		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.3348211424025981 | validation: 0.22710357043279789]
	TIME [epoch: 9.2 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.331051567373689		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.331051567373689 | validation: 0.18649235301702]
	TIME [epoch: 9.22 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34517348673867454		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.34517348673867454 | validation: 0.26391967203038036]
	TIME [epoch: 9.24 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2126662805961423		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.2126662805961423 | validation: 0.2205865863742436]
	TIME [epoch: 9.21 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20938946660695107		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.20938946660695107 | validation: 0.2853276624322387]
	TIME [epoch: 9.21 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22285726407005693		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.22285726407005693 | validation: 0.3361338875504134]
	TIME [epoch: 9.2 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31045934982685386		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.31045934982685386 | validation: 0.18393170476088944]
	TIME [epoch: 9.24 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2376425658247535		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.2376425658247535 | validation: 0.20254938086391583]
	TIME [epoch: 9.2 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2601039320847007		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.2601039320847007 | validation: 0.1661383993198614]
	TIME [epoch: 9.21 sec]
Finished training in 4650.483 seconds.
