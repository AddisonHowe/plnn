Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 892620038

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 11.329760594163618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.329760594163618 | validation: 11.751016411510381]
	TIME [epoch: 48.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 11.02762194094012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.02762194094012 | validation: 9.453652385595415]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 9.276960901728858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.276960901728858 | validation: 8.554539671569314]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 8.56089068996518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.56089068996518 | validation: 8.051524029652619]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 7.58827148442757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.58827148442757 | validation: 6.582172140403729]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 7.2478286482285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2478286482285 | validation: 6.24492694452592]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 6.798445553680251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.798445553680251 | validation: 6.319622745896888]
	TIME [epoch: 9.18 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 6.341204541891703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.341204541891703 | validation: 5.85138875180993]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 6.324972416068285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.324972416068285 | validation: 6.108642719179486]
	TIME [epoch: 9.17 sec]
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 6.409210296725607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.409210296725607 | validation: 6.067799805131887]
	TIME [epoch: 9.16 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 6.232561552535458		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 6.232561552535458 | validation: 5.6249603705620626]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 6.142156677263229		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 6.142156677263229 | validation: 5.759502910541075]
	TIME [epoch: 9.17 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 6.13353756720416		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 6.13353756720416 | validation: 5.8853345295576265]
	TIME [epoch: 9.17 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 6.209301406808761		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 6.209301406808761 | validation: 5.788552494675963]
	TIME [epoch: 9.17 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 6.2012855038131365		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 6.2012855038131365 | validation: 5.858361611945851]
	TIME [epoch: 9.19 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 5.93048561969462		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 5.93048561969462 | validation: 5.792343041021098]
	TIME [epoch: 9.17 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 5.710683617389238		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 5.710683617389238 | validation: 5.695250050867635]
	TIME [epoch: 9.16 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 5.657080989726373		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 5.657080989726373 | validation: 5.530304939014263]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 5.49570692079536		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 5.49570692079536 | validation: 5.533579000431299]
	TIME [epoch: 9.18 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 5.364680301340381		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 5.364680301340381 | validation: 5.388761091935204]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 5.251485183922659		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 5.251485183922659 | validation: 4.837806087733615]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 5.02885911453359		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 5.02885911453359 | validation: 4.828003959391699]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 4.255179082922048		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 4.255179082922048 | validation: 4.022442231307984]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 4.324073343141164		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 4.324073343141164 | validation: 3.985795301409535]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 3.9293647697154874		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 3.9293647697154874 | validation: 3.657271557474803]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 3.6502741415000144		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 3.6502741415000144 | validation: 3.5465371888835513]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 3.526738428772975		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 3.526738428772975 | validation: 3.703492351883418]
	TIME [epoch: 9.17 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 4.183813565146582		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 4.183813565146582 | validation: 3.3911795075769526]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 3.432296018047686		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 3.432296018047686 | validation: 3.587454837698995]
	TIME [epoch: 9.17 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 3.542440994990854		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 3.542440994990854 | validation: 3.1943002655756274]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 7.413704840462512		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 7.413704840462512 | validation: 8.878689511438397]
	TIME [epoch: 9.17 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 6.851474377655113		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 6.851474377655113 | validation: 5.283995064798982]
	TIME [epoch: 9.18 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 4.915970542011086		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 4.915970542011086 | validation: 5.172420065130803]
	TIME [epoch: 9.19 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 4.855693332221714		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 4.855693332221714 | validation: 4.420042864722403]
	TIME [epoch: 9.18 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 7.063140141156493		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 7.063140141156493 | validation: 4.811088169200254]
	TIME [epoch: 9.18 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 4.186770335702913		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 4.186770335702913 | validation: 3.879923950632279]
	TIME [epoch: 9.18 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 3.7927816004886603		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 3.7927816004886603 | validation: 3.886595882363571]
	TIME [epoch: 9.21 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 3.9613642053740667		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 3.9613642053740667 | validation: 4.523810882699377]
	TIME [epoch: 9.18 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 3.75392199919819		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 3.75392199919819 | validation: 4.483205017559095]
	TIME [epoch: 9.19 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 3.480723197016405		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 3.480723197016405 | validation: 4.3111914109273]
	TIME [epoch: 9.18 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 3.4223949695210165		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 3.4223949695210165 | validation: 2.9804714743884393]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 3.062848561340934		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 3.062848561340934 | validation: 2.6170014482963007]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 3.0610443729109065		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 3.0610443729109065 | validation: 3.0275957334240458]
	TIME [epoch: 9.18 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 2.649892336696154		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 2.649892336696154 | validation: 2.6334171155888013]
	TIME [epoch: 9.16 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 2.929579421095586		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 2.929579421095586 | validation: 3.171132441007877]
	TIME [epoch: 9.17 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 2.4690099334882807		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 2.4690099334882807 | validation: 2.0052262591612506]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 2.7466362033060485		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 2.7466362033060485 | validation: 2.1859755175674875]
	TIME [epoch: 9.16 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 2.1487428629239513		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 2.1487428629239513 | validation: 1.9133635056525542]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0497604574098074		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 2.0497604574098074 | validation: 2.0677647631343197]
	TIME [epoch: 9.18 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0062280861127624		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 2.0062280861127624 | validation: 3.583441396502912]
	TIME [epoch: 9.19 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 3.0611565549614976		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 3.0611565549614976 | validation: 1.7099735484131018]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8564661303457157		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 1.8564661303457157 | validation: 1.6596857984133315]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 1.830535854268191		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 1.830535854268191 | validation: 1.497072332931038]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5910998919334842		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 1.5910998919334842 | validation: 1.9021747317074278]
	TIME [epoch: 9.17 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2879992416574604		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 2.2879992416574604 | validation: 1.625009001347888]
	TIME [epoch: 9.2 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5279598773921486		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 1.5279598773921486 | validation: 2.8539399233128213]
	TIME [epoch: 9.17 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 2.733508347307008		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 2.733508347307008 | validation: 2.835876996566995]
	TIME [epoch: 9.18 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0736516594054937		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 2.0736516594054937 | validation: 1.6000386869499006]
	TIME [epoch: 9.19 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5794327512275272		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 1.5794327512275272 | validation: 1.1409428850061754]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 1.394925816050216		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 1.394925816050216 | validation: 1.9749605111758104]
	TIME [epoch: 9.19 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7117475272074718		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 1.7117475272074718 | validation: 1.2419455259219903]
	TIME [epoch: 9.17 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3085070550449505		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 1.3085070550449505 | validation: 1.5419938464220169]
	TIME [epoch: 9.18 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4525282955409495		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 1.4525282955409495 | validation: 1.091136896320404]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4561842255062505		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 1.4561842255062505 | validation: 3.2930130996294995]
	TIME [epoch: 9.19 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 1.687915859949373		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 1.687915859949373 | validation: 1.1257843379048658]
	TIME [epoch: 9.19 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2992281012931017		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 1.2992281012931017 | validation: 1.2390928590671155]
	TIME [epoch: 9.22 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1853712732965394		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 1.1853712732965394 | validation: 1.0951124795101097]
	TIME [epoch: 9.22 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3775165253602868		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 1.3775165253602868 | validation: 1.2204378900916124]
	TIME [epoch: 9.22 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3166531530786394		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 1.3166531530786394 | validation: 0.9928125293454935]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4339920926400358		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 1.4339920926400358 | validation: 1.5294119426782102]
	TIME [epoch: 9.2 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2204999304800128		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 1.2204999304800128 | validation: 1.7322060255303047]
	TIME [epoch: 9.2 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3068586098220982		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 1.3068586098220982 | validation: 1.259570861707421]
	TIME [epoch: 9.21 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3910877456129171		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 1.3910877456129171 | validation: 1.0034983599841703]
	TIME [epoch: 9.2 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3195982098729937		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 1.3195982098729937 | validation: 1.2440217005434135]
	TIME [epoch: 9.2 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 1.178118263867894		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 1.178118263867894 | validation: 1.8087142789293778]
	TIME [epoch: 9.19 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0972667768170208		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 1.0972667768170208 | validation: 1.0674524370831646]
	TIME [epoch: 9.19 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0564977123366588		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 1.0564977123366588 | validation: 0.9227668148840621]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2255815720273275		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 1.2255815720273275 | validation: 0.9759976628437425]
	TIME [epoch: 9.19 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0717177701678589		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 1.0717177701678589 | validation: 1.3126723693113689]
	TIME [epoch: 9.19 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 1.541854418231447		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 1.541854418231447 | validation: 0.9532191477285821]
	TIME [epoch: 9.17 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 1.189694225508719		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 1.189694225508719 | validation: 1.3371319389871528]
	TIME [epoch: 9.19 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0885032941644912		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 1.0885032941644912 | validation: 0.9380566073366037]
	TIME [epoch: 9.19 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1251077974528019		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 1.1251077974528019 | validation: 1.9421741869316935]
	TIME [epoch: 9.2 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 1.074344409534398		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 1.074344409534398 | validation: 1.1384689159856283]
	TIME [epoch: 9.18 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0884545033726105		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 1.0884545033726105 | validation: 0.9597955912514301]
	TIME [epoch: 9.19 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0270576700557792		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 1.0270576700557792 | validation: 0.7521246805333228]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0937536435920998		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 1.0937536435920998 | validation: 0.8649683879063913]
	TIME [epoch: 9.17 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 1.005315898972356		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 1.005315898972356 | validation: 0.8046983038368252]
	TIME [epoch: 9.16 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 1.12048954472285		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 1.12048954472285 | validation: 1.1615115061483947]
	TIME [epoch: 9.16 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9914644380618078		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 0.9914644380618078 | validation: 1.3591762603513602]
	TIME [epoch: 9.16 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0495540294738144		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 1.0495540294738144 | validation: 1.3254690752890186]
	TIME [epoch: 9.18 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0773812644944847		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 1.0773812644944847 | validation: 2.185269623435432]
	TIME [epoch: 9.16 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1579619368569944		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 1.1579619368569944 | validation: 2.1591998008455615]
	TIME [epoch: 9.16 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2072315897475188		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 1.2072315897475188 | validation: 1.0646017877633185]
	TIME [epoch: 9.17 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 1.294173251256517		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 1.294173251256517 | validation: 1.3166743949284399]
	TIME [epoch: 9.18 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1894508819454919		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 1.1894508819454919 | validation: 0.8557280437935787]
	TIME [epoch: 9.16 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1045619924867767		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 1.1045619924867767 | validation: 0.9048014701853317]
	TIME [epoch: 9.17 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 1.059249331156172		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 1.059249331156172 | validation: 0.7857283911996469]
	TIME [epoch: 9.17 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.954852328285811		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 0.954852328285811 | validation: 0.8414095978824979]
	TIME [epoch: 9.16 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9170264685162252		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.9170264685162252 | validation: 0.8148185988260577]
	TIME [epoch: 9.18 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 1.063813912790355		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 1.063813912790355 | validation: 0.7029016865452969]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.89169752654894		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 0.89169752654894 | validation: 1.0755369621136928]
	TIME [epoch: 9.15 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9261375030460373		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 0.9261375030460373 | validation: 0.5646996474255532]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0374112184204782		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 1.0374112184204782 | validation: 1.060908603526224]
	TIME [epoch: 9.15 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0750588057864654		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 1.0750588057864654 | validation: 0.74006194736477]
	TIME [epoch: 9.12 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9257923236787831		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 0.9257923236787831 | validation: 0.9642757811502964]
	TIME [epoch: 9.16 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8875507461051397		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.8875507461051397 | validation: 0.8882758760025792]
	TIME [epoch: 9.14 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8839530296456427		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 0.8839530296456427 | validation: 0.6156006990675614]
	TIME [epoch: 9.16 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9239900328688121		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 0.9239900328688121 | validation: 1.3062916385202281]
	TIME [epoch: 9.16 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8210142848105806		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.8210142848105806 | validation: 0.7334774544128384]
	TIME [epoch: 9.15 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0660727092642133		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 1.0660727092642133 | validation: 0.6707431208991255]
	TIME [epoch: 9.16 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6898574230154079		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.6898574230154079 | validation: 0.7611951770159555]
	TIME [epoch: 9.16 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8252896647173851		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.8252896647173851 | validation: 1.03855294149084]
	TIME [epoch: 9.19 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9064998526959919		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.9064998526959919 | validation: 1.0588198755829725]
	TIME [epoch: 9.16 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9219476498511252		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.9219476498511252 | validation: 0.7936667094268431]
	TIME [epoch: 9.17 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8655868175753498		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.8655868175753498 | validation: 0.9142789958192707]
	TIME [epoch: 9.17 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7258096599830599		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.7258096599830599 | validation: 0.7867740438411095]
	TIME [epoch: 9.17 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9287863782815069		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.9287863782815069 | validation: 0.8182290434571264]
	TIME [epoch: 9.19 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7319589390101704		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 0.7319589390101704 | validation: 0.5913899602150822]
	TIME [epoch: 9.18 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7134205482555876		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.7134205482555876 | validation: 0.5988974609183992]
	TIME [epoch: 9.17 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7827312975988076		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.7827312975988076 | validation: 0.771379976703444]
	TIME [epoch: 9.18 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7094686363229037		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 0.7094686363229037 | validation: 0.6837389626356131]
	TIME [epoch: 9.19 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7971758270239653		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.7971758270239653 | validation: 1.423054401456788]
	TIME [epoch: 9.18 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8935926414647575		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.8935926414647575 | validation: 0.8393364068539373]
	TIME [epoch: 9.17 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8433269513560774		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 0.8433269513560774 | validation: 0.6432361415560686]
	TIME [epoch: 9.17 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6961293456599433		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 0.6961293456599433 | validation: 0.7326685806702748]
	TIME [epoch: 9.17 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7177409407496869		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 0.7177409407496869 | validation: 0.5373822640722247]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7865281534756934		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.7865281534756934 | validation: 1.5615822907116286]
	TIME [epoch: 9.17 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9415698139563279		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.9415698139563279 | validation: 1.0242108742986549]
	TIME [epoch: 9.17 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6819046061487283		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.6819046061487283 | validation: 0.5051378944603677]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7214271792211349		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.7214271792211349 | validation: 0.47387411907169175]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6291640817325936		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.6291640817325936 | validation: 0.690712022199935]
	TIME [epoch: 9.16 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8338392601745943		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 0.8338392601745943 | validation: 0.7546557556831157]
	TIME [epoch: 9.16 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6367455455303787		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.6367455455303787 | validation: 0.3975919880801268]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_134.pth
	Model improved!!!
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.703701187666513		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.703701187666513 | validation: 0.6691328760263706]
	TIME [epoch: 9.19 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7317144253595009		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.7317144253595009 | validation: 0.8397357555079048]
	TIME [epoch: 9.21 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7139845417297613		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.7139845417297613 | validation: 0.7091590076501413]
	TIME [epoch: 9.2 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6360409935289051		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.6360409935289051 | validation: 0.7444648846973564]
	TIME [epoch: 9.2 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7520966603055046		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.7520966603055046 | validation: 0.5180221534351787]
	TIME [epoch: 9.2 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.614436764078438		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 0.614436764078438 | validation: 0.7960373237517975]
	TIME [epoch: 9.2 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.791060097772052		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.791060097772052 | validation: 0.46440603232460176]
	TIME [epoch: 9.2 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5190642515969236		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.5190642515969236 | validation: 0.4276805374779029]
	TIME [epoch: 9.2 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7262774291468879		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.7262774291468879 | validation: 0.9232308923087211]
	TIME [epoch: 9.2 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6342842102032231		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.6342842102032231 | validation: 0.7125250998786928]
	TIME [epoch: 9.2 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.787239251572685		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.787239251572685 | validation: 0.8230734842451077]
	TIME [epoch: 9.21 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6708164812271014		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.6708164812271014 | validation: 0.3426281431685484]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5844979925989937		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.5844979925989937 | validation: 0.8166891925214619]
	TIME [epoch: 9.17 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6053688071318283		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.6053688071318283 | validation: 0.6264855524769737]
	TIME [epoch: 9.18 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5739925328439945		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.5739925328439945 | validation: 0.47427248673299444]
	TIME [epoch: 9.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7195723574526035		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.7195723574526035 | validation: 0.6528731162628679]
	TIME [epoch: 9.2 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5807771894353243		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.5807771894353243 | validation: 0.6755287222286128]
	TIME [epoch: 9.19 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6581759581012143		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.6581759581012143 | validation: 1.5231245769858686]
	TIME [epoch: 9.2 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8060115243453204		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.8060115243453204 | validation: 0.5072430160083317]
	TIME [epoch: 9.19 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6510915988366123		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.6510915988366123 | validation: 0.5663439234764032]
	TIME [epoch: 9.2 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5285168374375806		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.5285168374375806 | validation: 1.0390117653044775]
	TIME [epoch: 9.18 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8694633922134802		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.8694633922134802 | validation: 0.7096567977997417]
	TIME [epoch: 9.19 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.558145559484821		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.558145559484821 | validation: 0.61848038177399]
	TIME [epoch: 9.19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6209214007772426		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.6209214007772426 | validation: 0.6890531516282026]
	TIME [epoch: 9.19 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5940798047827671		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.5940798047827671 | validation: 0.47441967481362896]
	TIME [epoch: 9.2 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.633237375265086		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.633237375265086 | validation: 0.8456757288256704]
	TIME [epoch: 9.19 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5760065329543059		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.5760065329543059 | validation: 0.5778964155739367]
	TIME [epoch: 9.18 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6652443854631687		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.6652443854631687 | validation: 0.6326340529005832]
	TIME [epoch: 9.18 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5570083421201056		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.5570083421201056 | validation: 0.472858962923148]
	TIME [epoch: 9.2 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5709764193332844		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.5709764193332844 | validation: 0.829294834625898]
	TIME [epoch: 9.18 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5356816256135095		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.5356816256135095 | validation: 1.2283219427531469]
	TIME [epoch: 9.19 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0790663944469046		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 1.0790663944469046 | validation: 0.4061857846524234]
	TIME [epoch: 9.19 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.536504615074237		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.536504615074237 | validation: 0.7094187194678445]
	TIME [epoch: 9.19 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.541866494419553		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.541866494419553 | validation: 0.6580859699116923]
	TIME [epoch: 9.29 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4742438185982499		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.4742438185982499 | validation: 0.4430627926482382]
	TIME [epoch: 9.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5171863313348086		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.5171863313348086 | validation: 0.24361423255707626]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_170.pth
	Model improved!!!
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4369453929854597		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.4369453929854597 | validation: 0.5575241897401916]
	TIME [epoch: 9.2 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45191130215471337		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.45191130215471337 | validation: 0.6648696254732513]
	TIME [epoch: 9.22 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49037557589950687		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.49037557589950687 | validation: 0.5595370143895733]
	TIME [epoch: 9.21 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5195578166162221		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.5195578166162221 | validation: 0.4820055759558723]
	TIME [epoch: 9.21 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5869637979323357		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.5869637979323357 | validation: 0.6244088019265455]
	TIME [epoch: 9.21 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6397701797886868		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.6397701797886868 | validation: 0.29410605827386305]
	TIME [epoch: 9.2 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6134804516795105		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.6134804516795105 | validation: 0.9059007792903416]
	TIME [epoch: 9.23 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5909046813146532		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.5909046813146532 | validation: 0.29387422786261524]
	TIME [epoch: 9.21 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5722914894225843		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.5722914894225843 | validation: 0.8037611804671336]
	TIME [epoch: 9.2 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45646874573912954		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.45646874573912954 | validation: 0.5909653856864827]
	TIME [epoch: 9.2 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4595364167297841		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.4595364167297841 | validation: 0.4384933403128963]
	TIME [epoch: 9.21 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38862104538016556		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.38862104538016556 | validation: 0.38357870425102475]
	TIME [epoch: 9.21 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5163877525343123		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.5163877525343123 | validation: 0.4026984937248077]
	TIME [epoch: 9.2 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47057372694667743		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.47057372694667743 | validation: 0.5659593839286647]
	TIME [epoch: 9.2 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6250720851061312		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.6250720851061312 | validation: 0.375148357402182]
	TIME [epoch: 9.2 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5152963935873569		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.5152963935873569 | validation: 0.24233160340872473]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_186.pth
	Model improved!!!
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34331562540447047		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.34331562540447047 | validation: 0.5720855320284965]
	TIME [epoch: 9.19 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4266062875048166		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.4266062875048166 | validation: 0.5442222019800966]
	TIME [epoch: 9.19 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.505171428087651		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.505171428087651 | validation: 0.24994463624762892]
	TIME [epoch: 9.19 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5128548433412893		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.5128548433412893 | validation: 0.5242361377268379]
	TIME [epoch: 9.2 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5071681910327415		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.5071681910327415 | validation: 0.5653334708977291]
	TIME [epoch: 9.19 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.425866433818438		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.425866433818438 | validation: 0.3827477686417424]
	TIME [epoch: 9.19 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5292945638913177		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.5292945638913177 | validation: 0.4790442522980539]
	TIME [epoch: 9.19 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4872171385387232		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.4872171385387232 | validation: 0.4859183373875038]
	TIME [epoch: 9.18 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36674767626980087		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.36674767626980087 | validation: 0.27725467324153996]
	TIME [epoch: 9.21 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5091427372178656		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.5091427372178656 | validation: 1.235483323132056]
	TIME [epoch: 9.2 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4865150439917397		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.4865150439917397 | validation: 0.6212658312973025]
	TIME [epoch: 9.19 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.485127048386476		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.485127048386476 | validation: 0.4482498584025297]
	TIME [epoch: 9.19 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46231900834286466		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.46231900834286466 | validation: 1.3993215131784331]
	TIME [epoch: 9.21 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.635231996071042		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.635231996071042 | validation: 1.0994058008192176]
	TIME [epoch: 9.2 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5737689516114485		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.5737689516114485 | validation: 0.26540181960902187]
	TIME [epoch: 9.19 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36804158414514443		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.36804158414514443 | validation: 0.4034949623875942]
	TIME [epoch: 9.19 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37543115718854836		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.37543115718854836 | validation: 0.4216110366896263]
	TIME [epoch: 9.19 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35506094156612067		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.35506094156612067 | validation: 0.6393579650706601]
	TIME [epoch: 9.21 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4263623708594794		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.4263623708594794 | validation: 0.6068234988910498]
	TIME [epoch: 9.2 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5358320502487064		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.5358320502487064 | validation: 0.8638338514911486]
	TIME [epoch: 9.2 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40753662686240605		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.40753662686240605 | validation: 0.3667032961887073]
	TIME [epoch: 9.19 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44089993261034044		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.44089993261034044 | validation: 0.4837293574956685]
	TIME [epoch: 9.22 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45818850757650076		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.45818850757650076 | validation: 0.7824399760998879]
	TIME [epoch: 9.21 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.530656532389487		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.530656532389487 | validation: 0.5127078108373788]
	TIME [epoch: 9.21 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3866596808410946		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.3866596808410946 | validation: 0.5124619729225248]
	TIME [epoch: 9.21 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3415423589889128		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.3415423589889128 | validation: 0.2632599313056908]
	TIME [epoch: 9.2 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4090134693439122		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.4090134693439122 | validation: 0.3625120615305333]
	TIME [epoch: 9.21 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3612486592753251		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.3612486592753251 | validation: 0.26073711289705315]
	TIME [epoch: 9.21 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37704437974980787		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.37704437974980787 | validation: 0.32842309129358854]
	TIME [epoch: 9.2 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33842049140916597		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.33842049140916597 | validation: 0.30601017772386685]
	TIME [epoch: 9.19 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3682270935656894		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.3682270935656894 | validation: 0.46431182987408137]
	TIME [epoch: 9.23 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3682516253994312		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.3682516253994312 | validation: 0.16000725389459414]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_218.pth
	Model improved!!!
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4067676057625594		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.4067676057625594 | validation: 0.36656202309906105]
	TIME [epoch: 9.19 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3127662438748783		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.3127662438748783 | validation: 0.46313506435370255]
	TIME [epoch: 9.19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3610885243325776		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.3610885243325776 | validation: 0.17775993226471712]
	TIME [epoch: 9.2 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3014060952755062		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.3014060952755062 | validation: 0.34287319106944275]
	TIME [epoch: 9.22 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37042827288265523		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.37042827288265523 | validation: 0.2516827683103941]
	TIME [epoch: 9.2 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3659446303494081		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.3659446303494081 | validation: 0.3146475338028874]
	TIME [epoch: 9.2 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30161381810066307		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.30161381810066307 | validation: 0.4814114372818544]
	TIME [epoch: 9.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49179682841815087		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.49179682841815087 | validation: 0.3214277013932354]
	TIME [epoch: 9.23 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34029338488632566		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.34029338488632566 | validation: 0.71188623517159]
	TIME [epoch: 9.21 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38619668255312034		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.38619668255312034 | validation: 0.34662807680460267]
	TIME [epoch: 9.2 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3556872098599193		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.3556872098599193 | validation: 0.3784108861627178]
	TIME [epoch: 9.2 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39042470237782234		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.39042470237782234 | validation: 0.19106368247173883]
	TIME [epoch: 9.22 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32878292601025116		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.32878292601025116 | validation: 0.5114982903726043]
	TIME [epoch: 9.23 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.330559128265625		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.330559128265625 | validation: 0.26654566446511574]
	TIME [epoch: 9.2 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2764606985224131		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.2764606985224131 | validation: 0.1911354638041616]
	TIME [epoch: 9.2 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27608773823304406		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.27608773823304406 | validation: 0.31119649063870447]
	TIME [epoch: 9.23 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40774187369211123		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.40774187369211123 | validation: 0.3415564227301984]
	TIME [epoch: 9.22 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31323190390233113		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.31323190390233113 | validation: 0.20521416307743293]
	TIME [epoch: 9.21 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3340115141812853		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.3340115141812853 | validation: 0.2614717366748246]
	TIME [epoch: 9.21 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3770367761165216		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.3770367761165216 | validation: 0.21553023452490805]
	TIME [epoch: 9.2 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3303659150094302		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.3303659150094302 | validation: 0.1916569143952776]
	TIME [epoch: 9.21 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2886762554001069		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.2886762554001069 | validation: 0.2943000353541213]
	TIME [epoch: 9.22 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30522357066085026		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.30522357066085026 | validation: 0.1779591197985812]
	TIME [epoch: 9.2 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3494458387507002		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.3494458387507002 | validation: 0.2992717111226934]
	TIME [epoch: 9.21 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2890664040990226		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.2890664040990226 | validation: 0.32041076983500827]
	TIME [epoch: 9.19 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30600324035135934		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.30600324035135934 | validation: 0.4835141359120697]
	TIME [epoch: 9.2 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.505004365159069		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.505004365159069 | validation: 0.3902685309660625]
	TIME [epoch: 9.19 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3867210861954506		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.3867210861954506 | validation: 0.41332091099139784]
	TIME [epoch: 9.19 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34286095395938754		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.34286095395938754 | validation: 0.2052368197061744]
	TIME [epoch: 9.19 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30533663352865614		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.30533663352865614 | validation: 0.21416170902349993]
	TIME [epoch: 9.2 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33145772549474006		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.33145772549474006 | validation: 0.5283185258136633]
	TIME [epoch: 9.22 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3992111606529498		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.3992111606529498 | validation: 0.19888460863354593]
	TIME [epoch: 9.2 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27779611767820767		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.27779611767820767 | validation: 0.25681028423603364]
	TIME [epoch: 9.19 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26772989187563623		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.26772989187563623 | validation: 0.2518286672430854]
	TIME [epoch: 9.2 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2197366312310524		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.2197366312310524 | validation: 0.36563038559130956]
	TIME [epoch: 9.2 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3554664926800514		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.3554664926800514 | validation: 0.1405805607665213]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_254.pth
	Model improved!!!
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41918291962539156		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.41918291962539156 | validation: 0.6441063954509996]
	TIME [epoch: 9.21 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.445187578951871		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.445187578951871 | validation: 0.1830467246772435]
	TIME [epoch: 9.21 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24299973478666986		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.24299973478666986 | validation: 0.24621809343345744]
	TIME [epoch: 9.2 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2875507612302589		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.2875507612302589 | validation: 0.2018841132464515]
	TIME [epoch: 9.23 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30453019944225185		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.30453019944225185 | validation: 0.2570707893459375]
	TIME [epoch: 9.21 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25059848147586694		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.25059848147586694 | validation: 0.25445660582879903]
	TIME [epoch: 9.21 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23850566716538069		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.23850566716538069 | validation: 0.21563397024897046]
	TIME [epoch: 9.21 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23478301833013657		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.23478301833013657 | validation: 0.18399187015736929]
	TIME [epoch: 9.23 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27866227233587115		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.27866227233587115 | validation: 0.7054204515175038]
	TIME [epoch: 9.23 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2794552415935344		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.2794552415935344 | validation: 0.31035535406548503]
	TIME [epoch: 9.21 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2406966516655394		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.2406966516655394 | validation: 0.24148378918082547]
	TIME [epoch: 9.21 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.268705779005466		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.268705779005466 | validation: 0.35109834047720606]
	TIME [epoch: 9.22 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28683661581208275		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.28683661581208275 | validation: 0.4275161055746669]
	TIME [epoch: 9.23 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3438387512647447		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.3438387512647447 | validation: 0.19990430189448616]
	TIME [epoch: 9.22 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23042216795463671		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.23042216795463671 | validation: 0.42737603930652657]
	TIME [epoch: 9.22 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23972838120243084		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.23972838120243084 | validation: 0.2741826162514853]
	TIME [epoch: 9.22 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22774811627859753		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.22774811627859753 | validation: 0.09967842239578939]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_271.pth
	Model improved!!!
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23909805328974318		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.23909805328974318 | validation: 0.20467597313519448]
	TIME [epoch: 9.24 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21106661814213862		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.21106661814213862 | validation: 0.09580773141910921]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_273.pth
	Model improved!!!
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3452737285908907		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.3452737285908907 | validation: 0.19065902636330342]
	TIME [epoch: 9.2 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2030576444472651		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.2030576444472651 | validation: 0.220794008462765]
	TIME [epoch: 9.21 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28917260713073256		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.28917260713073256 | validation: 0.18234456437588617]
	TIME [epoch: 9.24 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26542534170744114		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.26542534170744114 | validation: 0.4198047260823067]
	TIME [epoch: 9.21 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37426415809022184		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.37426415809022184 | validation: 0.2025746150244614]
	TIME [epoch: 9.2 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23527051637047483		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.23527051637047483 | validation: 0.24469174692830176]
	TIME [epoch: 9.2 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3776769333883687		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.3776769333883687 | validation: 0.1469646792935903]
	TIME [epoch: 9.21 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2120893477136629		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.2120893477136629 | validation: 0.19305608987828948]
	TIME [epoch: 9.21 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25303950157776234		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.25303950157776234 | validation: 0.11650446308288062]
	TIME [epoch: 9.19 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24452616996016374		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.24452616996016374 | validation: 0.3623925184765407]
	TIME [epoch: 9.21 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23517592654209088		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.23517592654209088 | validation: 0.1988359825483194]
	TIME [epoch: 9.19 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22130182587911004		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.22130182587911004 | validation: 0.3375394527553558]
	TIME [epoch: 9.21 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2149291370051915		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.2149291370051915 | validation: 0.3507767631260689]
	TIME [epoch: 9.18 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22331279183064226		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.22331279183064226 | validation: 0.15930599589384015]
	TIME [epoch: 9.2 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21921118981207552		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.21921118981207552 | validation: 0.4960948398257995]
	TIME [epoch: 9.19 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24696103993175286		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.24696103993175286 | validation: 0.2654467596223748]
	TIME [epoch: 9.2 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26383946286654464		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.26383946286654464 | validation: 0.3004601774307607]
	TIME [epoch: 9.22 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36682244821610216		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.36682244821610216 | validation: 0.2219605330179018]
	TIME [epoch: 9.19 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22057395569076724		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.22057395569076724 | validation: 0.11101301263652466]
	TIME [epoch: 9.19 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2359854022091671		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.2359854022091671 | validation: 0.13411407814281312]
	TIME [epoch: 9.2 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25020754665948525		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.25020754665948525 | validation: 0.3382358181333259]
	TIME [epoch: 9.22 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22292433017751817		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.22292433017751817 | validation: 0.14790921201804963]
	TIME [epoch: 9.19 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2792633925322655		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.2792633925322655 | validation: 0.14846970935582357]
	TIME [epoch: 9.18 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27105807544359867		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.27105807544359867 | validation: 0.2758592405288216]
	TIME [epoch: 9.19 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20614666771616985		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.20614666771616985 | validation: 0.36255145749372175]
	TIME [epoch: 9.2 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21530892906197666		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.21530892906197666 | validation: 0.30906631751016334]
	TIME [epoch: 9.24 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19384049276989404		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.19384049276989404 | validation: 0.29871595013846963]
	TIME [epoch: 9.21 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2301619281816895		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.2301619281816895 | validation: 0.30072694489860163]
	TIME [epoch: 9.21 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2715975386001308		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.2715975386001308 | validation: 0.08376001977174954]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_302.pth
	Model improved!!!
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20870965524699456		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.20870965524699456 | validation: 0.1847881653748723]
	TIME [epoch: 9.2 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2916559009826421		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.2916559009826421 | validation: 0.1544680483812381]
	TIME [epoch: 9.21 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22909894563801023		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.22909894563801023 | validation: 0.20069666181465534]
	TIME [epoch: 9.21 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18960897376166297		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.18960897376166297 | validation: 0.29677347406859167]
	TIME [epoch: 9.21 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21877376629142584		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.21877376629142584 | validation: 0.21261026607560699]
	TIME [epoch: 9.21 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20527705801233748		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.20527705801233748 | validation: 0.17330238176677526]
	TIME [epoch: 9.23 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2459900222204623		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.2459900222204623 | validation: 0.1680545127973424]
	TIME [epoch: 9.21 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2040621098484415		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.2040621098484415 | validation: 0.23869469863649861]
	TIME [epoch: 9.22 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20827493906733788		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.20827493906733788 | validation: 0.25284105059269396]
	TIME [epoch: 9.21 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21493857042702894		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.21493857042702894 | validation: 0.19738063290218805]
	TIME [epoch: 9.24 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23976044308085803		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.23976044308085803 | validation: 0.39563126960862705]
	TIME [epoch: 9.21 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27500689817322055		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.27500689817322055 | validation: 0.2790243635480766]
	TIME [epoch: 9.22 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21988483908035703		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.21988483908035703 | validation: 0.11009800578177086]
	TIME [epoch: 9.2 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24796714810138126		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.24796714810138126 | validation: 0.19212877947673143]
	TIME [epoch: 9.21 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16639230723216897		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.16639230723216897 | validation: 0.13501231989661536]
	TIME [epoch: 9.23 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2033577454799639		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.2033577454799639 | validation: 0.2919340443512708]
	TIME [epoch: 9.21 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15581302363294827		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.15581302363294827 | validation: 0.16333098648907401]
	TIME [epoch: 9.2 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1950421001406475		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.1950421001406475 | validation: 0.16120823958837366]
	TIME [epoch: 9.21 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17314301532465837		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.17314301532465837 | validation: 0.15174370574927037]
	TIME [epoch: 9.23 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2070412471974014		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.2070412471974014 | validation: 0.1797497758311875]
	TIME [epoch: 9.24 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2671902992206833		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.2671902992206833 | validation: 0.32297601738148296]
	TIME [epoch: 9.2 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2877453422024763		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.2877453422024763 | validation: 0.10528465041332849]
	TIME [epoch: 9.2 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1696756913315421		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.1696756913315421 | validation: 0.11769126254944864]
	TIME [epoch: 9.21 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18839434561686463		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.18839434561686463 | validation: 0.275211443341266]
	TIME [epoch: 9.24 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1603283255221866		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.1603283255221866 | validation: 0.1225507505738122]
	TIME [epoch: 9.22 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26272046200372456		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.26272046200372456 | validation: 0.1648168298295411]
	TIME [epoch: 9.21 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22952934383210716		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.22952934383210716 | validation: 0.19976298202179088]
	TIME [epoch: 9.21 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1971109887370132		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.1971109887370132 | validation: 0.27382680697002315]
	TIME [epoch: 9.23 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20250994825731553		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.20250994825731553 | validation: 0.12482192364046639]
	TIME [epoch: 9.22 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1641738819697811		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.1641738819697811 | validation: 0.18434286478140405]
	TIME [epoch: 9.22 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24314054090377427		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.24314054090377427 | validation: 0.14377165075241635]
	TIME [epoch: 9.22 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16389543080474128		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.16389543080474128 | validation: 0.3735823711809533]
	TIME [epoch: 9.22 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25345321969220364		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.25345321969220364 | validation: 0.17165983379917762]
	TIME [epoch: 9.24 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20228886459371548		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.20228886459371548 | validation: 0.1594938051377729]
	TIME [epoch: 9.22 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21573848232313333		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.21573848232313333 | validation: 0.11703355753892365]
	TIME [epoch: 9.21 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20337519615319571		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.20337519615319571 | validation: 0.4807511800601558]
	TIME [epoch: 9.22 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2147247677575538		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.2147247677575538 | validation: 0.22326470378270208]
	TIME [epoch: 9.24 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20800207709671423		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.20800207709671423 | validation: 0.6368420629598013]
	TIME [epoch: 9.22 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34156403799295626		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.34156403799295626 | validation: 0.17874225692585025]
	TIME [epoch: 9.22 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15989440081835796		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.15989440081835796 | validation: 0.15182000360675374]
	TIME [epoch: 9.22 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19971524729288198		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.19971524729288198 | validation: 0.12215890936799285]
	TIME [epoch: 9.21 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21239664872672828		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.21239664872672828 | validation: 0.3515865664307352]
	TIME [epoch: 9.24 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25538416544829035		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.25538416544829035 | validation: 0.27362262261075143]
	TIME [epoch: 9.22 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2000264427354334		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.2000264427354334 | validation: 0.16326238591388081]
	TIME [epoch: 9.22 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15489859713247936		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.15489859713247936 | validation: 0.16843646615171592]
	TIME [epoch: 9.22 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1954288101287136		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.1954288101287136 | validation: 0.15743107767794773]
	TIME [epoch: 9.24 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2292490099641836		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.2292490099641836 | validation: 0.21064547959601454]
	TIME [epoch: 9.22 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16205858628432707		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.16205858628432707 | validation: 0.08791283711977224]
	TIME [epoch: 9.22 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20472776701959874		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.20472776701959874 | validation: 0.1870341879300485]
	TIME [epoch: 9.21 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18385760513529825		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.18385760513529825 | validation: 0.1498916918043635]
	TIME [epoch: 9.22 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19783013678076838		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.19783013678076838 | validation: 0.16724134795379442]
	TIME [epoch: 9.23 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1569101077504856		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.1569101077504856 | validation: 0.2111135892069621]
	TIME [epoch: 9.22 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20527006787672536		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.20527006787672536 | validation: 0.20495383050290938]
	TIME [epoch: 9.23 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2256526343091306		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.2256526343091306 | validation: 0.15388020824742848]
	TIME [epoch: 9.22 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17861965621992382		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.17861965621992382 | validation: 0.19152778977418328]
	TIME [epoch: 9.24 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23418094653241822		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.23418094653241822 | validation: 0.17239866442002577]
	TIME [epoch: 9.22 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15258397861553702		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.15258397861553702 | validation: 0.20489884990389456]
	TIME [epoch: 9.23 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1722229629681866		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.1722229629681866 | validation: 0.22064421591943073]
	TIME [epoch: 9.22 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17394658852814504		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.17394658852814504 | validation: 0.14960480213093721]
	TIME [epoch: 9.22 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17689628865540402		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.17689628865540402 | validation: 0.15696860845279717]
	TIME [epoch: 9.23 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26604984897190076		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.26604984897190076 | validation: 0.1515702032409344]
	TIME [epoch: 9.22 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20660627946812413		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.20660627946812413 | validation: 0.30537571885460985]
	TIME [epoch: 9.22 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16147407390599872		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.16147407390599872 | validation: 0.16173396318551952]
	TIME [epoch: 9.21 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12097423753992635		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.12097423753992635 | validation: 0.15863530783823931]
	TIME [epoch: 9.23 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21094099642313174		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.21094099642313174 | validation: 0.16459977618381427]
	TIME [epoch: 9.22 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1474080606027257		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.1474080606027257 | validation: 0.17517389970091884]
	TIME [epoch: 9.22 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19513605852377053		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.19513605852377053 | validation: 0.16356708043489415]
	TIME [epoch: 9.22 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1690987730214731		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.1690987730214731 | validation: 0.22935921226488093]
	TIME [epoch: 9.22 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20836315118767695		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.20836315118767695 | validation: 0.13359611551426642]
	TIME [epoch: 9.23 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17343686066656455		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.17343686066656455 | validation: 0.21373869380406385]
	TIME [epoch: 9.22 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16032764822418027		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.16032764822418027 | validation: 0.15565170703541845]
	TIME [epoch: 9.21 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1630406836476893		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.1630406836476893 | validation: 0.22085471397025097]
	TIME [epoch: 9.21 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19634038925040534		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.19634038925040534 | validation: 0.22921875176301704]
	TIME [epoch: 9.22 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2019386001816495		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.2019386001816495 | validation: 0.2041483245034257]
	TIME [epoch: 9.23 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16583768723111433		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.16583768723111433 | validation: 0.16441012423000773]
	TIME [epoch: 9.22 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20741683774879802		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.20741683774879802 | validation: 0.3278987614068811]
	TIME [epoch: 9.22 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21869169175519104		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.21869169175519104 | validation: 0.3959085105717347]
	TIME [epoch: 9.22 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17725087462827993		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.17725087462827993 | validation: 0.20521611889847094]
	TIME [epoch: 9.24 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19131945058641847		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.19131945058641847 | validation: 0.23042714210085297]
	TIME [epoch: 9.22 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19440082230401926		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.19440082230401926 | validation: 0.21633243601846172]
	TIME [epoch: 9.22 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17326141971576065		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.17326141971576065 | validation: 0.20362432675435166]
	TIME [epoch: 9.21 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1549294442636885		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.1549294442636885 | validation: 0.16758981385101024]
	TIME [epoch: 9.22 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1623771452992137		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.1623771452992137 | validation: 0.2698794389177356]
	TIME [epoch: 9.24 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20491607711184825		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.20491607711184825 | validation: 0.12798489967323293]
	TIME [epoch: 9.22 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1640665913112514		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.1640665913112514 | validation: 0.07956978553413806]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_387.pth
	Model improved!!!
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1615516053779604		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.1615516053779604 | validation: 0.10724150150134998]
	TIME [epoch: 9.21 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1667652727497061		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.1667652727497061 | validation: 0.2725862649168529]
	TIME [epoch: 9.22 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2455618621310892		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.2455618621310892 | validation: 0.167166002637463]
	TIME [epoch: 9.21 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16406582456548985		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.16406582456548985 | validation: 0.13539187593267712]
	TIME [epoch: 9.21 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15947791457116584		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.15947791457116584 | validation: 0.19847669772001084]
	TIME [epoch: 9.2 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15356492102031352		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.15356492102031352 | validation: 0.14182861567822153]
	TIME [epoch: 9.23 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17411776907796356		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.17411776907796356 | validation: 0.2533092915290739]
	TIME [epoch: 9.21 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1789811985704643		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.1789811985704643 | validation: 0.20368247635595738]
	TIME [epoch: 9.2 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15945858389727366		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.15945858389727366 | validation: 0.2442566146115015]
	TIME [epoch: 9.2 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15526487451894483		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.15526487451894483 | validation: 0.2258871983403835]
	TIME [epoch: 9.2 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2207284654292661		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.2207284654292661 | validation: 0.1002333096714376]
	TIME [epoch: 9.22 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1631622881172043		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.1631622881172043 | validation: 0.10646733829424532]
	TIME [epoch: 9.2 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12913197430375645		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.12913197430375645 | validation: 0.31981527043791635]
	TIME [epoch: 9.2 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19619917293847416		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.19619917293847416 | validation: 0.11452447397154286]
	TIME [epoch: 9.2 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17103670291966652		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.17103670291966652 | validation: 0.09501367603566083]
	TIME [epoch: 9.21 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12914717421171373		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.12914717421171373 | validation: 0.1447374746337077]
	TIME [epoch: 9.21 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1854383714964732		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.1854383714964732 | validation: 0.15219595974580008]
	TIME [epoch: 9.19 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15925022357363178		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.15925022357363178 | validation: 0.23111714074529655]
	TIME [epoch: 9.2 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1269307945109109		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.1269307945109109 | validation: 0.07859557400414408]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_406.pth
	Model improved!!!
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13484302740495618		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.13484302740495618 | validation: 0.1498103199367864]
	TIME [epoch: 9.24 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1412142270838293		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.1412142270838293 | validation: 0.14655236821534995]
	TIME [epoch: 9.22 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11378946617986348		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.11378946617986348 | validation: 0.1347079472790852]
	TIME [epoch: 9.22 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11714975768820372		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.11714975768820372 | validation: 0.24013353154060577]
	TIME [epoch: 9.22 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16353216651982355		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.16353216651982355 | validation: 0.12049190538376466]
	TIME [epoch: 9.22 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16935101394417457		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.16935101394417457 | validation: 0.22519370429488253]
	TIME [epoch: 9.23 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17104307442301386		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.17104307442301386 | validation: 0.16874041242980892]
	TIME [epoch: 9.21 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13950288312169537		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.13950288312169537 | validation: 0.05025982031366916]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240214_223140/states/model_tr_study3_414.pth
	Model improved!!!
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11164988271499728		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.11164988271499728 | validation: 0.22173547913987135]
	TIME [epoch: 9.2 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15594475404451527		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.15594475404451527 | validation: 0.1282450174816599]
	TIME [epoch: 9.23 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.138227690827953		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.138227690827953 | validation: 0.14362615881837582]
	TIME [epoch: 9.21 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14251349503739225		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.14251349503739225 | validation: 0.08184973959165463]
	TIME [epoch: 9.21 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12749979533058314		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.12749979533058314 | validation: 0.11471032544953652]
	TIME [epoch: 9.2 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1404725029076412		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.1404725029076412 | validation: 0.08248346072391563]
	TIME [epoch: 9.21 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11971468289256662		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.11971468289256662 | validation: 0.1812185356278337]
	TIME [epoch: 9.23 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14401320515392363		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.14401320515392363 | validation: 0.12136436464445352]
	TIME [epoch: 9.2 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10272652201717739		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.10272652201717739 | validation: 0.06116245467181174]
	TIME [epoch: 9.21 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14942169540841027		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.14942169540841027 | validation: 0.16943815758667963]
	TIME [epoch: 9.2 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2639777579630466		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.2639777579630466 | validation: 0.1210415021290972]
	TIME [epoch: 9.23 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21022783819965069		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.21022783819965069 | validation: 0.16862030518825177]
	TIME [epoch: 9.2 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1645601445817458		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.1645601445817458 | validation: 0.2053408661708946]
	TIME [epoch: 9.21 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1360513300751131		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.1360513300751131 | validation: 0.13883659222577677]
	TIME [epoch: 9.2 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1551040335359348		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.1551040335359348 | validation: 0.07130384593640526]
	TIME [epoch: 9.21 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11087974943353981		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.11087974943353981 | validation: 0.0928434278109762]
	TIME [epoch: 9.23 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15035812042173252		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.15035812042173252 | validation: 0.1447638992891967]
	TIME [epoch: 9.21 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13501007063153428		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.13501007063153428 | validation: 0.1571563568233943]
	TIME [epoch: 9.21 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.185770967098462		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.185770967098462 | validation: 0.155666713688875]
	TIME [epoch: 9.21 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13083329608264527		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.13083329608264527 | validation: 0.116707861929254]
	TIME [epoch: 9.23 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11634466287040165		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.11634466287040165 | validation: 0.15637139321239227]
	TIME [epoch: 9.21 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12774022805531396		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.12774022805531396 | validation: 0.06597649198454708]
	TIME [epoch: 9.21 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10902421043155486		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.10902421043155486 | validation: 0.05890616446295752]
	TIME [epoch: 9.2 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09164382258771428		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.09164382258771428 | validation: 0.07600632410048366]
	TIME [epoch: 9.21 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10486735342789193		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.10486735342789193 | validation: 0.1421464551415114]
	TIME [epoch: 9.22 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12215087595385658		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.12215087595385658 | validation: 0.07981845699634776]
	TIME [epoch: 9.2 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1405104252783248		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.1405104252783248 | validation: 0.18727698702614154]
	TIME [epoch: 9.19 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11734826505560185		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.11734826505560185 | validation: 0.0783498752775523]
	TIME [epoch: 9.21 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0926916862153341		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.0926916862153341 | validation: 0.12489490692989896]
	TIME [epoch: 9.22 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11369478832215744		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.11369478832215744 | validation: 0.22938426932011788]
	TIME [epoch: 9.21 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19107883451975147		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.19107883451975147 | validation: 0.25399405034647426]
	TIME [epoch: 9.2 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1807386957236172		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.1807386957236172 | validation: 0.11075950334478259]
	TIME [epoch: 9.2 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12350695125323279		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.12350695125323279 | validation: 0.11082030435621196]
	TIME [epoch: 9.21 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1460157271859967		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.1460157271859967 | validation: 0.05893414830143237]
	TIME [epoch: 9.23 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1794403044203986		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.1794403044203986 | validation: 0.10621938526139613]
	TIME [epoch: 9.22 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10775945993560158		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.10775945993560158 | validation: 0.09690610629648408]
	TIME [epoch: 9.22 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16225222031070802		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.16225222031070802 | validation: 0.1237762895673119]
	TIME [epoch: 9.21 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14674451349254256		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.14674451349254256 | validation: 0.2006246099142583]
	TIME [epoch: 9.23 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10540305552391811		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.10540305552391811 | validation: 0.09668227025036095]
	TIME [epoch: 9.21 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11454329796393903		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.11454329796393903 | validation: 0.12474647590677083]
	TIME [epoch: 9.21 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11325268830174218		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.11325268830174218 | validation: 0.1484078833881159]
	TIME [epoch: 9.22 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12258281325374829		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.12258281325374829 | validation: 0.0753508023648886]
	TIME [epoch: 9.22 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1471721921540287		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.1471721921540287 | validation: 0.11636809519589122]
	TIME [epoch: 9.23 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12152038458033891		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.12152038458033891 | validation: 0.0733451696345535]
	TIME [epoch: 9.21 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10120395803726275		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.10120395803726275 | validation: 0.110684137577815]
	TIME [epoch: 9.21 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12813360852125796		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.12813360852125796 | validation: 0.1552471341845711]
	TIME [epoch: 9.22 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1244064034860692		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.1244064034860692 | validation: 0.11011787963712671]
	TIME [epoch: 9.22 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12504994208295256		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.12504994208295256 | validation: 0.2035318146439712]
	TIME [epoch: 9.21 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18809159741172096		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.18809159741172096 | validation: 0.15035534924502186]
	TIME [epoch: 9.21 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17701760756631715		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.17701760756631715 | validation: 0.1634290251115924]
	TIME [epoch: 9.21 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13748975921634005		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.13748975921634005 | validation: 0.09006552364413697]
	TIME [epoch: 9.21 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1357206438838415		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.1357206438838415 | validation: 0.172858188195534]
	TIME [epoch: 9.22 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13471268141304465		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.13471268141304465 | validation: 0.14575501989664602]
	TIME [epoch: 9.21 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1040571349846698		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.1040571349846698 | validation: 0.10661590060317183]
	TIME [epoch: 9.2 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11389570159382198		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.11389570159382198 | validation: 0.1648336907502597]
	TIME [epoch: 9.21 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12740395025877121		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.12740395025877121 | validation: 0.127650642468691]
	TIME [epoch: 9.24 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12532932918389453		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.12532932918389453 | validation: 0.16741525771482707]
	TIME [epoch: 9.21 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12759853927455728		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.12759853927455728 | validation: 0.10142598170419001]
	TIME [epoch: 9.21 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1592150243854035		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.1592150243854035 | validation: 0.07939701373660658]
	TIME [epoch: 9.22 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11725572772165438		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.11725572772165438 | validation: 0.09285789365813116]
	TIME [epoch: 9.21 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11670989935035907		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.11670989935035907 | validation: 0.1369176861633877]
	TIME [epoch: 9.23 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13089763894834985		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.13089763894834985 | validation: 0.09208549493381418]
	TIME [epoch: 9.22 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1584200634804589		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.1584200634804589 | validation: 0.0735537397019134]
	TIME [epoch: 9.21 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08922391658493035		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.08922391658493035 | validation: 0.06531710814059251]
	TIME [epoch: 9.22 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1120404314640319		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.1120404314640319 | validation: 0.15387029385834206]
	TIME [epoch: 9.24 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1041948468885974		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.1041948468885974 | validation: 0.11048540580294552]
	TIME [epoch: 9.22 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13137373001519267		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.13137373001519267 | validation: 0.1426431890292219]
	TIME [epoch: 9.21 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1215159383194919		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.1215159383194919 | validation: 0.19252978589307596]
	TIME [epoch: 9.21 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1377247747637211		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.1377247747637211 | validation: 0.19510605001540232]
	TIME [epoch: 9.22 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12900696695549077		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.12900696695549077 | validation: 0.11832561139245298]
	TIME [epoch: 9.24 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11327017638102269		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.11327017638102269 | validation: 0.07998462151305549]
	TIME [epoch: 9.21 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11025820821005865		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.11025820821005865 | validation: 0.11202970595612058]
	TIME [epoch: 9.21 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16187213303825881		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.16187213303825881 | validation: 0.11452027732803063]
	TIME [epoch: 9.2 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09889464431078009		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.09889464431078009 | validation: 0.11166195306820817]
	TIME [epoch: 9.23 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14680242504670832		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.14680242504670832 | validation: 0.0961143964323257]
	TIME [epoch: 9.21 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11246755531321032		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.11246755531321032 | validation: 0.10208798251465503]
	TIME [epoch: 9.21 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13051377153368443		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.13051377153368443 | validation: 0.08162710674194013]
	TIME [epoch: 9.21 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10723415643094802		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.10723415643094802 | validation: 0.07124743832096313]
	TIME [epoch: 9.21 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10020676413299326		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.10020676413299326 | validation: 0.09699787239262048]
	TIME [epoch: 9.23 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13024964928452443		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.13024964928452443 | validation: 0.13145276126252342]
	TIME [epoch: 9.2 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11103670823553528		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.11103670823553528 | validation: 0.08072769385658557]
	TIME [epoch: 9.2 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1075414898394175		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.1075414898394175 | validation: 0.0627753909134533]
	TIME [epoch: 9.2 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08672809476531006		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.08672809476531006 | validation: 0.05964843573115047]
	TIME [epoch: 9.22 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07816450422598901		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.07816450422598901 | validation: 0.13105705732378578]
	TIME [epoch: 9.2 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09106102470716769		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.09106102470716769 | validation: 0.16432597426513318]
	TIME [epoch: 9.16 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13970820911499343		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.13970820911499343 | validation: 0.08691275878972629]
	TIME [epoch: 9.19 sec]
Finished training in 4661.997 seconds.
