Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r2', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3387363086

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.017941745692093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.017941745692093 | validation: 10.761510355430579]
	TIME [epoch: 89.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.140087724608204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.140087724608204 | validation: 9.903543341591332]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.42171937379192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.42171937379192 | validation: 9.025813792820495]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.158798648721426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.158798648721426 | validation: 8.757013069660408]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.485306838509262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.485306838509262 | validation: 8.445427464768152]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.344025001676762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.344025001676762 | validation: 8.454970413540353]
	TIME [epoch: 13 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.175359310465668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.175359310465668 | validation: 7.942054916015825]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.146338621390374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.146338621390374 | validation: 11.338643765263841]
	TIME [epoch: 12.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.061095782942935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.061095782942935 | validation: 7.132458235154518]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.108617745793927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.108617745793927 | validation: 6.593519109251006]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.683816203249693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.683816203249693 | validation: 6.39644942565269]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.394973995366002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.394973995366002 | validation: 6.023690180508643]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.265033897817618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.265033897817618 | validation: 6.044004705635603]
	TIME [epoch: 12.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.13354404084543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.13354404084543 | validation: 5.945660892059037]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.052285984099055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.052285984099055 | validation: 5.983310087851467]
	TIME [epoch: 12.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.989667735949803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.989667735949803 | validation: 5.867090455926659]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.794049519117274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.794049519117274 | validation: 6.042931065111982]
	TIME [epoch: 12.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002076890195049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002076890195049 | validation: 6.148947663492887]
	TIME [epoch: 12.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.080282051633306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.080282051633306 | validation: 5.750045680559554]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.961171490628878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.961171490628878 | validation: 6.0470884261512445]
	TIME [epoch: 13 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.045298084244152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.045298084244152 | validation: 5.8845902294556325]
	TIME [epoch: 12.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899831849587184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.899831849587184 | validation: 5.882989938800124]
	TIME [epoch: 12.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.876652196220862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.876652196220862 | validation: 6.154022175114553]
	TIME [epoch: 12.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.246333513553822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.246333513553822 | validation: 5.864037302219035]
	TIME [epoch: 12.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.874093384324293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.874093384324293 | validation: 5.745547553008492]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.683356006153545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.683356006153545 | validation: 6.02246691484381]
	TIME [epoch: 13 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.247317583744697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.247317583744697 | validation: 6.520176551996476]
	TIME [epoch: 12.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96449707384435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96449707384435 | validation: 5.8219065857258805]
	TIME [epoch: 12.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.897581770570466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.897581770570466 | validation: 5.7154538062571385]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.816817029504273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.816817029504273 | validation: 5.945177296936718]
	TIME [epoch: 13 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8086297777947955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8086297777947955 | validation: 5.712450561753132]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733753322023862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.733753322023862 | validation: 5.707641855682848]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.689075180372693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.689075180372693 | validation: 5.731832245794266]
	TIME [epoch: 12.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.651721693610397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.651721693610397 | validation: 5.598406296412027]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.717907241090527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.717907241090527 | validation: 5.6221008452238275]
	TIME [epoch: 13 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713940243999405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.713940243999405 | validation: 5.648338362040997]
	TIME [epoch: 12.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.559923402098442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.559923402098442 | validation: 5.57904243229351]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.642871737234133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.642871737234133 | validation: 5.515822045388298]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.443458113671069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.443458113671069 | validation: 5.346483731134684]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.444668167273365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.444668167273365 | validation: 5.317414108083153]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.661517238274752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661517238274752 | validation: 5.439497669359563]
	TIME [epoch: 13 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1335461359144805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1335461359144805 | validation: 4.608271917735446]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.455520608674796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.455520608674796 | validation: 4.783038006906069]
	TIME [epoch: 12.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.813584194576368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.813584194576368 | validation: 7.9144762374152675]
	TIME [epoch: 12.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.44958912895331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.44958912895331 | validation: 8.31099190556095]
	TIME [epoch: 12.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.177583188065503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.177583188065503 | validation: 5.85235154848181]
	TIME [epoch: 12.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.644429388043678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.644429388043678 | validation: 5.565600957928637]
	TIME [epoch: 12.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.508349521452751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.508349521452751 | validation: 5.6490814327599015]
	TIME [epoch: 13 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558868212352625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.558868212352625 | validation: 5.603083660492373]
	TIME [epoch: 12.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.417998061595185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.417998061595185 | validation: 5.260502046684528]
	TIME [epoch: 12.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.235277676983175		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.235277676983175 | validation: 5.045686116056393]
	TIME [epoch: 13 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.092649108495617		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.092649108495617 | validation: 5.013925139016067]
	TIME [epoch: 12.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771091867017606		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.771091867017606 | validation: 4.516696728700079]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4767115030347595		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.4767115030347595 | validation: 4.143129225241573]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.24828776733806		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.24828776733806 | validation: 4.079087567619436]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.633064740072835		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.633064740072835 | validation: 4.343707909531964]
	TIME [epoch: 12.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.093281055763816		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.093281055763816 | validation: 3.9789025726998615]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.305392520097254		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.305392520097254 | validation: 4.19502950106803]
	TIME [epoch: 12.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.191190404359211		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.191190404359211 | validation: 4.138880423155651]
	TIME [epoch: 12.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.231760867614671		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.231760867614671 | validation: 5.316940245279209]
	TIME [epoch: 12.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.344203997866035		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.344203997866035 | validation: 4.050866106713841]
	TIME [epoch: 13 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.421128069473576		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.421128069473576 | validation: 4.060395353668076]
	TIME [epoch: 12.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8755141764314995		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.8755141764314995 | validation: 3.8191104180670545]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.933798362356514		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.933798362356514 | validation: 3.682528051796624]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.901229913424471		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.901229913424471 | validation: 4.029497198954823]
	TIME [epoch: 12.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7538632194756314		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.7538632194756314 | validation: 3.4314050180416906]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5691783725368644		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.5691783725368644 | validation: 3.4156319230537098]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5978317803203037		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.5978317803203037 | validation: 3.6336320692153175]
	TIME [epoch: 12.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5685428941608497		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.5685428941608497 | validation: 3.313778518338875]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.057324596583239		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.057324596583239 | validation: 4.059810782538114]
	TIME [epoch: 12.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7751939837622297		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.7751939837622297 | validation: 3.1723880177192005]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269732117882194		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.269732117882194 | validation: 3.073797470188966]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2256656700300637		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.2256656700300637 | validation: 3.004941938285608]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.198516553504488		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.198516553504488 | validation: 3.2567524527360936]
	TIME [epoch: 12.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.108172765759071		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.108172765759071 | validation: 3.081422888299031]
	TIME [epoch: 12.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.049098406822434		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.049098406822434 | validation: 3.165102648975623]
	TIME [epoch: 12.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2260864502583884		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.2260864502583884 | validation: 3.007215573681012]
	TIME [epoch: 12.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464011267170616		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.464011267170616 | validation: 3.6885088279927483]
	TIME [epoch: 12.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3277102755658445		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.3277102755658445 | validation: 2.988409759338888]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817944051271696		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.817944051271696 | validation: 3.0225101583229743]
	TIME [epoch: 12.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7349849813356855		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.7349849813356855 | validation: 3.4210889534821787]
	TIME [epoch: 12.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0276368576836856		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.0276368576836856 | validation: 2.647206502009374]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7998529955731377		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.7998529955731377 | validation: 2.2852948038577576]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0482743119604176		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.0482743119604176 | validation: 2.4997426815428727]
	TIME [epoch: 12.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6418956661869832		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.6418956661869832 | validation: 2.1065618230112992]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278851052559197		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.278851052559197 | validation: 3.1567556433547503]
	TIME [epoch: 12.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0149475174606337		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.0149475174606337 | validation: 2.354383948402528]
	TIME [epoch: 12.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293031111239257		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.293031111239257 | validation: 2.136720436945613]
	TIME [epoch: 12.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5533421273068324		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.5533421273068324 | validation: 2.2644698067212166]
	TIME [epoch: 12.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3712655989777405		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.3712655989777405 | validation: 3.5853647933574604]
	TIME [epoch: 12.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4312437615623144		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.4312437615623144 | validation: 2.6873312255290718]
	TIME [epoch: 12.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.77857539191111		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.77857539191111 | validation: 3.180412007620976]
	TIME [epoch: 12.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2236455994400064		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.2236455994400064 | validation: 2.133384806731604]
	TIME [epoch: 12.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291024179527961		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.291024179527961 | validation: 2.0691072646656363]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2752891353800773		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.2752891353800773 | validation: 2.546421269510851]
	TIME [epoch: 12.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.208602002103407		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.208602002103407 | validation: 1.8241301889583645]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1080221237408288		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.1080221237408288 | validation: 1.8237486742670523]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097812674762422		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.097812674762422 | validation: 1.7980765307592441]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5089971762294745		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.5089971762294745 | validation: 2.5317317100669317]
	TIME [epoch: 12.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253485022963475		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.253485022963475 | validation: 2.169421954684962]
	TIME [epoch: 12.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2433764581829845		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.2433764581829845 | validation: 2.036196133822338]
	TIME [epoch: 12.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030997305338819		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.030997305338819 | validation: 2.289827221484968]
	TIME [epoch: 12.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2399690961617855		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.2399690961617855 | validation: 1.8157705831475632]
	TIME [epoch: 12.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9594079712550605		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.9594079712550605 | validation: 1.710655124084475]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9796927740978743		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.9796927740978743 | validation: 1.9507231227728452]
	TIME [epoch: 12.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1969672509680063		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.1969672509680063 | validation: 1.4201212883652008]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.661717176469076		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.661717176469076 | validation: 2.054397506455295]
	TIME [epoch: 12.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364389716576406		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.364389716576406 | validation: 1.5005585424522898]
	TIME [epoch: 12.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28181365219378		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.28181365219378 | validation: 3.1482171374092145]
	TIME [epoch: 12.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.574178797588512		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.574178797588512 | validation: 2.778073119234057]
	TIME [epoch: 12.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342368119917654		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.342368119917654 | validation: 1.5794667671405211]
	TIME [epoch: 12.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.882865429914866		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.882865429914866 | validation: 1.609087837619123]
	TIME [epoch: 12.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9211122840446289		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.9211122840446289 | validation: 1.7411392383368098]
	TIME [epoch: 12.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7202927260504093		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.7202927260504093 | validation: 1.817334081096874]
	TIME [epoch: 12.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6989631852995304		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.6989631852995304 | validation: 1.393402520034234]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5920490256738873		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.5920490256738873 | validation: 1.388724283584617]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.136096947381726		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.136096947381726 | validation: 1.5095873409523535]
	TIME [epoch: 12.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6748642926585553		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.6748642926585553 | validation: 1.357406925290989]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7504771952190397		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.7504771952190397 | validation: 1.3095451533700635]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.009748908096479		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.009748908096479 | validation: 1.418081373466949]
	TIME [epoch: 12.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7516874185056701		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.7516874185056701 | validation: 1.7134384163748289]
	TIME [epoch: 12.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7720661220581488		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.7720661220581488 | validation: 1.222825779979757]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6178482386073936		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.6178482386073936 | validation: 1.3524627655349537]
	TIME [epoch: 12.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6914699626462497		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.6914699626462497 | validation: 1.838433622094457]
	TIME [epoch: 12.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505781958946838		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.7505781958946838 | validation: 1.5980716678922426]
	TIME [epoch: 12.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9490113090690544		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.9490113090690544 | validation: 1.2910994972442718]
	TIME [epoch: 12.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.860483437122229		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.860483437122229 | validation: 1.3207249763389082]
	TIME [epoch: 12.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6759866492188933		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.6759866492188933 | validation: 1.1623057737520166]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4701846081423942		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4701846081423942 | validation: 1.2037067940478376]
	TIME [epoch: 12.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6802483866676154		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.6802483866676154 | validation: 2.186925486306451]
	TIME [epoch: 12.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9038522016175239		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.9038522016175239 | validation: 2.7965272060155644]
	TIME [epoch: 12.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2938833554362725		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.2938833554362725 | validation: 1.7493550957592663]
	TIME [epoch: 12.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.629318697342835		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.629318697342835 | validation: 1.9528371038065746]
	TIME [epoch: 12.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7554768316527931		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7554768316527931 | validation: 1.3541763219609124]
	TIME [epoch: 12.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4322544955860481		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.4322544955860481 | validation: 1.7588004008780629]
	TIME [epoch: 12.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5408960112516086		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5408960112516086 | validation: 1.1872536828430618]
	TIME [epoch: 12.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438960510216209		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.438960510216209 | validation: 1.0928293724387164]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3233020923188021		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3233020923188021 | validation: 2.364586085535293]
	TIME [epoch: 12.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7366764432197237		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.7366764432197237 | validation: 1.2409191177915342]
	TIME [epoch: 12.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5092618671289117		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.5092618671289117 | validation: 1.297648125071739]
	TIME [epoch: 12.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4998122591244822		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.4998122591244822 | validation: 1.585676432531022]
	TIME [epoch: 12.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5301881923706733		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.5301881923706733 | validation: 0.9538313860198511]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3578640758084088		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3578640758084088 | validation: 1.0140192926638012]
	TIME [epoch: 13 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3737619468790112		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.3737619468790112 | validation: 1.128637017625136]
	TIME [epoch: 12.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8610445155264723		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.8610445155264723 | validation: 1.0607424519989745]
	TIME [epoch: 12.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356502596473135		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.356502596473135 | validation: 1.244762298434322]
	TIME [epoch: 12.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.489236834451777		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.489236834451777 | validation: 1.3442199682564826]
	TIME [epoch: 12.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5755135327418428		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.5755135327418428 | validation: 1.7722647780784744]
	TIME [epoch: 12.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5163411693422486		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.5163411693422486 | validation: 1.0804914970475137]
	TIME [epoch: 12.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3714617813630847		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.3714617813630847 | validation: 1.3769568001945418]
	TIME [epoch: 12.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4948510599611997		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.4948510599611997 | validation: 1.57884217618028]
	TIME [epoch: 12.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806789779726677		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.2806789779726677 | validation: 1.9793963649970847]
	TIME [epoch: 12.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.938924360365696		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.938924360365696 | validation: 1.0674907703667187]
	TIME [epoch: 12.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5511655173371213		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.5511655173371213 | validation: 1.458674558381964]
	TIME [epoch: 12.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3130527845251296		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.3130527845251296 | validation: 1.5546735950617026]
	TIME [epoch: 12.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7668327957502417		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.7668327957502417 | validation: 1.773871542362406]
	TIME [epoch: 12.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4000984650789585		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.4000984650789585 | validation: 1.4450242259171358]
	TIME [epoch: 12.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3538531652756216		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3538531652756216 | validation: 1.3353596073737686]
	TIME [epoch: 12.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2471090312860065		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.2471090312860065 | validation: 1.1105977843582446]
	TIME [epoch: 12.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.366030309089356		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.366030309089356 | validation: 1.298491379318982]
	TIME [epoch: 12.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.405887800955478		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.405887800955478 | validation: 0.9739569063413499]
	TIME [epoch: 12.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3414585734406814		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3414585734406814 | validation: 1.5172472995993531]
	TIME [epoch: 12.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4452987273189533		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.4452987273189533 | validation: 1.2354002327378775]
	TIME [epoch: 12.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248116162016553		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.248116162016553 | validation: 1.980383180055506]
	TIME [epoch: 12.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7586383567795048		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.7586383567795048 | validation: 1.2983361177287298]
	TIME [epoch: 12.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3725730329414128		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.3725730329414128 | validation: 1.1462140343113962]
	TIME [epoch: 12.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5173462978677081		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.5173462978677081 | validation: 2.270344425249814]
	TIME [epoch: 12.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7497912700634597		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.7497912700634597 | validation: 1.4598398209141275]
	TIME [epoch: 12.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4931730949683135		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.4931730949683135 | validation: 1.0319155309407702]
	TIME [epoch: 12.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2539715428408191		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2539715428408191 | validation: 1.8769888506863615]
	TIME [epoch: 12.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6478888113177423		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.6478888113177423 | validation: 1.1413844188657818]
	TIME [epoch: 12.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2134375826812716		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2134375826812716 | validation: 1.0946018824864898]
	TIME [epoch: 12.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290114303904097		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.290114303904097 | validation: 0.9191297896432675]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7831419919580653		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.7831419919580653 | validation: 1.2025900074321718]
	TIME [epoch: 12.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2294105288405464		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2294105288405464 | validation: 1.1185639082012544]
	TIME [epoch: 12.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266053794198632		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.266053794198632 | validation: 0.9295670754101193]
	TIME [epoch: 12.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1229243673831302		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1229243673831302 | validation: 0.8726788257134237]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1743693472086942		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.1743693472086942 | validation: 1.2275179832397463]
	TIME [epoch: 12.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35692534430926		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.35692534430926 | validation: 0.8485565495246061]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1272494450455754		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.1272494450455754 | validation: 1.2865111604840724]
	TIME [epoch: 12.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180613403536349		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.180613403536349 | validation: 1.2540055479673198]
	TIME [epoch: 12.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.32427046182707		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.32427046182707 | validation: 1.4828605846772749]
	TIME [epoch: 12.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270500149612373		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2270500149612373 | validation: 1.2807401002366556]
	TIME [epoch: 12.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2094600723790567		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.2094600723790567 | validation: 0.9391135079015962]
	TIME [epoch: 12.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982707906484497		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0982707906484497 | validation: 1.3448885988031944]
	TIME [epoch: 12.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2723643929089876		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.2723643929089876 | validation: 0.7852497699167864]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0128161750925		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.0128161750925 | validation: 0.9610873848072946]
	TIME [epoch: 12.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604116358612203		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0604116358612203 | validation: 1.1065139142414946]
	TIME [epoch: 12.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4842748461148993		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.4842748461148993 | validation: 1.2273198687138611]
	TIME [epoch: 12.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2676467399398923		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.2676467399398923 | validation: 0.7227094869718446]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0019934708148928		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0019934708148928 | validation: 1.2228574007999138]
	TIME [epoch: 12.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0962555743302103		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0962555743302103 | validation: 0.7564131297377858]
	TIME [epoch: 12.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0595684423128584		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0595684423128584 | validation: 1.3483733427452724]
	TIME [epoch: 12.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2322635824749382		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.2322635824749382 | validation: 0.9085773829019759]
	TIME [epoch: 12.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0476425603353359		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.0476425603353359 | validation: 1.4112737178959547]
	TIME [epoch: 12.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2248680762048743		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.2248680762048743 | validation: 2.402874104577152]
	TIME [epoch: 12.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5844491292836538		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.5844491292836538 | validation: 1.3026536214091333]
	TIME [epoch: 12.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1229197111911366		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.1229197111911366 | validation: 1.0786530673973718]
	TIME [epoch: 12.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834560694155166		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.0834560694155166 | validation: 1.5724874769063006]
	TIME [epoch: 12.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578972922716233		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1578972922716233 | validation: 0.9149999902239019]
	TIME [epoch: 12.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421359555701808		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8421359555701808 | validation: 1.4386485647030491]
	TIME [epoch: 12.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2197312623112984		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.2197312623112984 | validation: 0.7975363301015719]
	TIME [epoch: 12.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0372105944446721		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.0372105944446721 | validation: 1.3741373238146457]
	TIME [epoch: 12.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26873693218878		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.26873693218878 | validation: 1.0355015366191456]
	TIME [epoch: 12.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9903970277203376		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.9903970277203376 | validation: 0.8556866814795868]
	TIME [epoch: 12.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0112175510358026		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0112175510358026 | validation: 1.2129553062510412]
	TIME [epoch: 12.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023726856035337		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.023726856035337 | validation: 0.7813654594419464]
	TIME [epoch: 12.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822384107194597		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9822384107194597 | validation: 0.9646306149380937]
	TIME [epoch: 12.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157212466067946		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.157212466067946 | validation: 1.3697830966751157]
	TIME [epoch: 12.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08393523105209		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.08393523105209 | validation: 0.811243733229806]
	TIME [epoch: 12.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9349418997206979		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9349418997206979 | validation: 0.8443060565443555]
	TIME [epoch: 12.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832408506917378		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7832408506917378 | validation: 0.9167979198222309]
	TIME [epoch: 12.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053863479339119		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.053863479339119 | validation: 1.4828413256476574]
	TIME [epoch: 12.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3623664634016612		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.3623664634016612 | validation: 0.7193078426480566]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687873389301878		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0687873389301878 | validation: 0.7717959149913028]
	TIME [epoch: 12.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8811440983967687		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8811440983967687 | validation: 0.7276891525512325]
	TIME [epoch: 12.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866421573804871		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9866421573804871 | validation: 1.6673261540899684]
	TIME [epoch: 12.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3449697246509054		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.3449697246509054 | validation: 1.1900472290035904]
	TIME [epoch: 12.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2692305844121003		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.2692305844121003 | validation: 1.1791717556260441]
	TIME [epoch: 12.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.109854428461711		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.109854428461711 | validation: 1.035287695766007]
	TIME [epoch: 12.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9779172050027077		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9779172050027077 | validation: 0.8205579893070347]
	TIME [epoch: 12.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437785079857375		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.9437785079857375 | validation: 0.8744574100670155]
	TIME [epoch: 12.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094023438330058		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1094023438330058 | validation: 0.6976221773714616]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179379664528018		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9179379664528018 | validation: 0.9738213363852947]
	TIME [epoch: 12.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581091114105816		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.0581091114105816 | validation: 0.8887930375245793]
	TIME [epoch: 12.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9918423757506805		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.9918423757506805 | validation: 0.7434329659697315]
	TIME [epoch: 12.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519274803324814		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.9519274803324814 | validation: 1.1234796853011415]
	TIME [epoch: 12.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9627708086651134		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9627708086651134 | validation: 1.2831361036547795]
	TIME [epoch: 12.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0974210848819643		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.0974210848819643 | validation: 1.273782320878598]
	TIME [epoch: 13 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1535431476875913		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.1535431476875913 | validation: 0.9764250209702426]
	TIME [epoch: 12.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92500538150306		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.92500538150306 | validation: 0.7040003347629782]
	TIME [epoch: 12.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8097253106287945		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8097253106287945 | validation: 0.7755914467655314]
	TIME [epoch: 12.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9964147798210115		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9964147798210115 | validation: 0.743475358055321]
	TIME [epoch: 12.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231768924665401		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.231768924665401 | validation: 1.2253696603148005]
	TIME [epoch: 12.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004835197095155		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.004835197095155 | validation: 0.6022424132127994]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853948894744062		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.853948894744062 | validation: 0.988753783070701]
	TIME [epoch: 12.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9792902882457629		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9792902882457629 | validation: 0.6171529318699107]
	TIME [epoch: 12.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647697187852307		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.9647697187852307 | validation: 0.6916804816302081]
	TIME [epoch: 13 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8662318359384874		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8662318359384874 | validation: 0.7218300950140042]
	TIME [epoch: 13 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497271297593101		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8497271297593101 | validation: 0.8008876271767043]
	TIME [epoch: 12.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.768799940741353		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.768799940741353 | validation: 0.9037494928616667]
	TIME [epoch: 12.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9888510120795649		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.9888510120795649 | validation: 0.9054204565049543]
	TIME [epoch: 12.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7550160846320509		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7550160846320509 | validation: 0.6867611733422788]
	TIME [epoch: 12.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8899907442168478		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8899907442168478 | validation: 0.9765855555132317]
	TIME [epoch: 12.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9730293619394924		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.9730293619394924 | validation: 0.8884928711049775]
	TIME [epoch: 13 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077532547751713		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.0077532547751713 | validation: 0.9946761110529494]
	TIME [epoch: 12.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033383005736126		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.033383005736126 | validation: 2.058637202296006]
	TIME [epoch: 12.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2508955210431414		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.2508955210431414 | validation: 1.0244684571686427]
	TIME [epoch: 12.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.916954886593765		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.916954886593765 | validation: 1.1771490458753147]
	TIME [epoch: 12.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5427000155825563		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.5427000155825563 | validation: 0.9294941059883383]
	TIME [epoch: 12.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9412574374750715		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.9412574374750715 | validation: 1.0730435327583783]
	TIME [epoch: 12.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5360633781824804		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.5360633781824804 | validation: 0.9277784609718057]
	TIME [epoch: 13 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8530612203797712		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8530612203797712 | validation: 0.6428960529774312]
	TIME [epoch: 12.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8895291412951255		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.8895291412951255 | validation: 0.8419888994401896]
	TIME [epoch: 12.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995682079391527		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.8995682079391527 | validation: 1.1521164081398536]
	TIME [epoch: 13 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237166098418307		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0237166098418307 | validation: 0.7986652807046281]
	TIME [epoch: 12.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303045837512445		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8303045837512445 | validation: 0.7642026529242822]
	TIME [epoch: 12.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8556301381406204		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8556301381406204 | validation: 1.0609559021736017]
	TIME [epoch: 12.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8666902528604373		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8666902528604373 | validation: 0.9331549796601363]
	TIME [epoch: 12.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661206397630714		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7661206397630714 | validation: 0.641480453599232]
	TIME [epoch: 12.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8024300312833473		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.8024300312833473 | validation: 1.0630468960322081]
	TIME [epoch: 12.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02264714781629		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.02264714781629 | validation: 1.0111996985113476]
	TIME [epoch: 12.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9816085971090351		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.9816085971090351 | validation: 0.7181160539669418]
	TIME [epoch: 12.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233504111385915		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.8233504111385915 | validation: 0.677653045280203]
	TIME [epoch: 12.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.804614693800889		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.804614693800889 | validation: 1.4006845563063803]
	TIME [epoch: 13 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659224056906909		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0659224056906909 | validation: 0.747486312703787]
	TIME [epoch: 12.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9165828208464902		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.9165828208464902 | validation: 0.8948598029388789]
	TIME [epoch: 12.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8718711564159692		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8718711564159692 | validation: 1.1985056603111859]
	TIME [epoch: 12.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9546469496497878		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9546469496497878 | validation: 0.6734973860577148]
	TIME [epoch: 12.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8786115639567768		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8786115639567768 | validation: 0.8965022630467355]
	TIME [epoch: 12.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0726204633949348		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.0726204633949348 | validation: 0.7855579005024231]
	TIME [epoch: 12.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7524798680099154		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7524798680099154 | validation: 0.6921652651679516]
	TIME [epoch: 12.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8617419709627356		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8617419709627356 | validation: 0.6738011964044288]
	TIME [epoch: 12.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8116999875268132		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8116999875268132 | validation: 0.696085302531605]
	TIME [epoch: 12.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8707637425013767		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.8707637425013767 | validation: 0.5940960543237445]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.800748236039768		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.800748236039768 | validation: 0.9639762381067771]
	TIME [epoch: 12.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8897421052827518		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.8897421052827518 | validation: 0.8128136767937659]
	TIME [epoch: 12.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632548316227175		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7632548316227175 | validation: 1.0714202174971965]
	TIME [epoch: 12.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267085135712305		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9267085135712305 | validation: 0.6245057506730638]
	TIME [epoch: 12.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664246806221375		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7664246806221375 | validation: 0.6291835667449117]
	TIME [epoch: 12.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8994438899414888		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.8994438899414888 | validation: 0.6723132811895384]
	TIME [epoch: 12.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240034577552752		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.8240034577552752 | validation: 0.8096929163068367]
	TIME [epoch: 12.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634119962670595		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7634119962670595 | validation: 0.7728691094124005]
	TIME [epoch: 12.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062463568258273		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.8062463568258273 | validation: 0.6142577249280033]
	TIME [epoch: 12.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349213803998368		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7349213803998368 | validation: 0.7494534601651631]
	TIME [epoch: 13 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8773599957434407		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.8773599957434407 | validation: 0.7222459466233626]
	TIME [epoch: 12.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7972412764744916		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.7972412764744916 | validation: 0.6000992294759492]
	TIME [epoch: 12.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833917099662676		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.833917099662676 | validation: 0.6878584934684188]
	TIME [epoch: 12.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038615653520901		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7038615653520901 | validation: 0.6977560433852443]
	TIME [epoch: 12.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9764975296822305		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.9764975296822305 | validation: 1.2990641692994171]
	TIME [epoch: 12.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046807247209412		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.9046807247209412 | validation: 0.5819209310372497]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996498093410697		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.6996498093410697 | validation: 0.70296872793696]
	TIME [epoch: 12.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998136711139346		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7998136711139346 | validation: 0.6285875846734719]
	TIME [epoch: 12.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8489276977150881		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8489276977150881 | validation: 0.6641635541980245]
	TIME [epoch: 12.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401207158996479		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8401207158996479 | validation: 0.5974854860554776]
	TIME [epoch: 12.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8197865139211685		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.8197865139211685 | validation: 0.6386026578065879]
	TIME [epoch: 12.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355171794843126		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7355171794843126 | validation: 0.6765087405601673]
	TIME [epoch: 12.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294894832584828		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7294894832584828 | validation: 0.7697520319092547]
	TIME [epoch: 12.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7654153351870401		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7654153351870401 | validation: 0.9130493055903351]
	TIME [epoch: 12.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8290159172752156		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8290159172752156 | validation: 0.7031684625150652]
	TIME [epoch: 12.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6613564925244877		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6613564925244877 | validation: 0.6398896354578817]
	TIME [epoch: 12.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7950300917767502		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7950300917767502 | validation: 0.9882623706340337]
	TIME [epoch: 12.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094127671965542		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.8094127671965542 | validation: 0.7884234041854751]
	TIME [epoch: 12.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958304728769903		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6958304728769903 | validation: 1.1029835955681675]
	TIME [epoch: 12.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.967315166694689		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.967315166694689 | validation: 1.1104522944105846]
	TIME [epoch: 12.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879501100675655		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8879501100675655 | validation: 1.0435607473298272]
	TIME [epoch: 12.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613057369016663		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7613057369016663 | validation: 1.0846183293830662]
	TIME [epoch: 12.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0674958986892067		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.0674958986892067 | validation: 0.8498650147729668]
	TIME [epoch: 12.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8146902565609966		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8146902565609966 | validation: 0.5345041519467616]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337855631153016		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7337855631153016 | validation: 1.2521911781270265]
	TIME [epoch: 12.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8558167456269713		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.8558167456269713 | validation: 0.6518302514332861]
	TIME [epoch: 12.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303438684616598		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.8303438684616598 | validation: 0.6086234555300647]
	TIME [epoch: 12.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708398126035443		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7708398126035443 | validation: 0.7729456945825206]
	TIME [epoch: 12.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7988303408598001		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7988303408598001 | validation: 0.4997298642934031]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629273031206199		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6629273031206199 | validation: 0.7010679428139355]
	TIME [epoch: 12.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7944603987751647		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7944603987751647 | validation: 0.6044138073571447]
	TIME [epoch: 12.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341418376121596		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7341418376121596 | validation: 0.6962037142418663]
	TIME [epoch: 12.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6634511297251221		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6634511297251221 | validation: 0.953542054833438]
	TIME [epoch: 12.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7599724058954567		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7599724058954567 | validation: 0.5556307785487195]
	TIME [epoch: 12.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462480641738131		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6462480641738131 | validation: 0.4336444116699116]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6387409609149276		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6387409609149276 | validation: 0.6870209789615265]
	TIME [epoch: 12.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220704659216435		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6220704659216435 | validation: 0.6241396488256727]
	TIME [epoch: 12.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724112126273909		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6724112126273909 | validation: 0.5073336109328149]
	TIME [epoch: 12.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6490372963863847		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.6490372963863847 | validation: 0.8333803128766587]
	TIME [epoch: 12.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552051735349508		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6552051735349508 | validation: 1.1245658416237236]
	TIME [epoch: 12.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8424073688245367		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8424073688245367 | validation: 0.5014572958624877]
	TIME [epoch: 12.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678054381336333		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7678054381336333 | validation: 0.8232945029991819]
	TIME [epoch: 12.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292238610948089		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9292238610948089 | validation: 0.8090190217329751]
	TIME [epoch: 12.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8996526145622248		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.8996526145622248 | validation: 0.6599854057110082]
	TIME [epoch: 12.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827938541455867		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6827938541455867 | validation: 0.5127537264195946]
	TIME [epoch: 12.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6510707347593917		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6510707347593917 | validation: 0.4158479304859148]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078211857398522		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7078211857398522 | validation: 0.7476390296840617]
	TIME [epoch: 12.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383911825894133		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.7383911825894133 | validation: 0.7830712920770596]
	TIME [epoch: 12.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9109610903284364		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.9109610903284364 | validation: 0.576637885638834]
	TIME [epoch: 12.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094124665047607		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8094124665047607 | validation: 1.1261733229280046]
	TIME [epoch: 12.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8722658608105214		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.8722658608105214 | validation: 1.4198495557675848]
	TIME [epoch: 12.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.955953217928286		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.955953217928286 | validation: 0.5881497787354658]
	TIME [epoch: 12.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6534429580472549		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6534429580472549 | validation: 0.7851205057234113]
	TIME [epoch: 13 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695724394625951		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.695724394625951 | validation: 0.7054168256840748]
	TIME [epoch: 12.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487362268545079		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6487362268545079 | validation: 0.6899960953571673]
	TIME [epoch: 12.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314350931698361		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7314350931698361 | validation: 0.6209247887418338]
	TIME [epoch: 13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.679282193650138		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.679282193650138 | validation: 0.6661892608337044]
	TIME [epoch: 12.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7647543374737301		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7647543374737301 | validation: 0.5573897238787354]
	TIME [epoch: 12.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412456581074036		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7412456581074036 | validation: 0.657348741111259]
	TIME [epoch: 12.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714275828473295		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7714275828473295 | validation: 0.5769288250726943]
	TIME [epoch: 12.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310834393871841		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7310834393871841 | validation: 0.5010586895763923]
	TIME [epoch: 12.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946378313790512		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5946378313790512 | validation: 0.8039439177973259]
	TIME [epoch: 13 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741079900916487		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.741079900916487 | validation: 0.6145536227081556]
	TIME [epoch: 12.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656086903981939		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.656086903981939 | validation: 0.600916112396259]
	TIME [epoch: 13 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943127264427893		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5943127264427893 | validation: 1.5281179399524003]
	TIME [epoch: 13 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8498637940140996		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.8498637940140996 | validation: 0.812425067147053]
	TIME [epoch: 13 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6196463323659441		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.6196463323659441 | validation: 0.5507967219008779]
	TIME [epoch: 12.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427372780603203		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7427372780603203 | validation: 0.46603973830937717]
	TIME [epoch: 12.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7724765540115859		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7724765540115859 | validation: 0.43126698312099915]
	TIME [epoch: 13 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263987650943498		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6263987650943498 | validation: 0.45908896343593597]
	TIME [epoch: 12.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091011460118373		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7091011460118373 | validation: 0.7646150901464015]
	TIME [epoch: 12.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8541950525750074		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.8541950525750074 | validation: 0.6691538328559549]
	TIME [epoch: 13 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432479081602301		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.7432479081602301 | validation: 0.6118928232177305]
	TIME [epoch: 12.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565025261231612		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6565025261231612 | validation: 0.8151584825635397]
	TIME [epoch: 12.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397694101718713		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7397694101718713 | validation: 0.5473577185133456]
	TIME [epoch: 12.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185240294282237		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6185240294282237 | validation: 0.45481092124632555]
	TIME [epoch: 13 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130271575230287		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5130271575230287 | validation: 0.42685824134427663]
	TIME [epoch: 13 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6005680615139106		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6005680615139106 | validation: 0.6428033231571985]
	TIME [epoch: 13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7970720306850487		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7970720306850487 | validation: 1.0578771353991758]
	TIME [epoch: 13 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9577089419449545		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.9577089419449545 | validation: 0.8977315614599141]
	TIME [epoch: 13 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466077082809292		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6466077082809292 | validation: 0.49451489388837544]
	TIME [epoch: 12.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6744740711778126		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6744740711778126 | validation: 0.6744245694238431]
	TIME [epoch: 13 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052338602889809		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6052338602889809 | validation: 0.6115520351934159]
	TIME [epoch: 12.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5919722044876593		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5919722044876593 | validation: 0.6133649516832641]
	TIME [epoch: 12.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5539782535271427		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5539782535271427 | validation: 0.5181048263485052]
	TIME [epoch: 12.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464348118686522		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5464348118686522 | validation: 0.5281001623104511]
	TIME [epoch: 13 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476122837036495		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6476122837036495 | validation: 0.38951745949181]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6094001539966656		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6094001539966656 | validation: 0.40977736656270425]
	TIME [epoch: 12.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849425487577191		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7849425487577191 | validation: 0.4686314103946316]
	TIME [epoch: 12.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.892539665750387		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.892539665750387 | validation: 1.0909805805710002]
	TIME [epoch: 12.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1709452627257049		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.1709452627257049 | validation: 0.8107374465465601]
	TIME [epoch: 12.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8580159300033172		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8580159300033172 | validation: 0.46092900429266564]
	TIME [epoch: 13 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440668204657016		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8440668204657016 | validation: 0.4803593912403696]
	TIME [epoch: 12.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8350495725322454		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8350495725322454 | validation: 0.5442827127503792]
	TIME [epoch: 12.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.860374578294526		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.860374578294526 | validation: 0.5813601924047803]
	TIME [epoch: 12.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805845814524044		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.805845814524044 | validation: 0.5855244188198201]
	TIME [epoch: 12.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492856817449371		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.7492856817449371 | validation: 0.5679631172612852]
	TIME [epoch: 12.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311325639609459		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5311325639609459 | validation: 0.5518913303612121]
	TIME [epoch: 12.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299128340536384		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7299128340536384 | validation: 0.6881175060407813]
	TIME [epoch: 13 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8119835792161387		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8119835792161387 | validation: 0.844220202466283]
	TIME [epoch: 12.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562205983381227		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7562205983381227 | validation: 0.42709488484357067]
	TIME [epoch: 12.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099498813837251		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7099498813837251 | validation: 0.4874407494137145]
	TIME [epoch: 13 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6182189779028296		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6182189779028296 | validation: 0.687241809624826]
	TIME [epoch: 12.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890420281115577		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5890420281115577 | validation: 0.4924383855607345]
	TIME [epoch: 12.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773716509884095		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5773716509884095 | validation: 0.3924542320672839]
	TIME [epoch: 12.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5880057782548221		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5880057782548221 | validation: 0.43893121218414743]
	TIME [epoch: 12.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5701673318535503		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5701673318535503 | validation: 0.4608188303345682]
	TIME [epoch: 12.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145475680415723		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5145475680415723 | validation: 0.5218196884354482]
	TIME [epoch: 12.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.537731675226271		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.537731675226271 | validation: 0.8643897639978789]
	TIME [epoch: 13 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7622887483014645		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7622887483014645 | validation: 1.1952771632465216]
	TIME [epoch: 12.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8274877983899469		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8274877983899469 | validation: 0.5885177375600964]
	TIME [epoch: 12.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378024417020535		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5378024417020535 | validation: 0.5626882540757341]
	TIME [epoch: 12.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446604125056207		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5446604125056207 | validation: 0.62511259099383]
	TIME [epoch: 12.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874756780106942		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5874756780106942 | validation: 0.5897161924682459]
	TIME [epoch: 12.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458235894200024		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6458235894200024 | validation: 1.062195701674476]
	TIME [epoch: 12.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221933888212474		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.9221933888212474 | validation: 0.5026828952866378]
	TIME [epoch: 12.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547139697037644		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5547139697037644 | validation: 0.6252248955587979]
	TIME [epoch: 12.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4825229674734348		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.4825229674734348 | validation: 0.4667693484250418]
	TIME [epoch: 13 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7695505278042215		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7695505278042215 | validation: 0.6658477898781894]
	TIME [epoch: 13 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701815176478168		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.7701815176478168 | validation: 0.5107811114683627]
	TIME [epoch: 12.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483377081951986		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5483377081951986 | validation: 0.30967721123085307]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4083398357757675		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.4083398357757675 | validation: 0.7643252891731018]
	TIME [epoch: 13 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.918971190255987		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.918971190255987 | validation: 0.3963329225188625]
	TIME [epoch: 12.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054640046075304		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5054640046075304 | validation: 0.4083968180180686]
	TIME [epoch: 12.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44217144548618953		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.44217144548618953 | validation: 0.3489167915194396]
	TIME [epoch: 12.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5530935243112803		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5530935243112803 | validation: 0.5872308231457679]
	TIME [epoch: 12.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082898786507029		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6082898786507029 | validation: 0.44783102701318356]
	TIME [epoch: 12.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187151828335033		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.8187151828335033 | validation: 0.5606338704300965]
	TIME [epoch: 13 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302186344452378		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5302186344452378 | validation: 0.4351421272962579]
	TIME [epoch: 12.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459586637740509		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4459586637740509 | validation: 0.5890955185724639]
	TIME [epoch: 12.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6170553695843026		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6170553695843026 | validation: 0.4833240119406744]
	TIME [epoch: 12.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567694516550832		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5567694516550832 | validation: 0.6778198050210427]
	TIME [epoch: 13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652057747624347		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.652057747624347 | validation: 0.9492639837158093]
	TIME [epoch: 12.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7942229841370021		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7942229841370021 | validation: 0.42961961670679527]
	TIME [epoch: 12.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4261482019780775		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4261482019780775 | validation: 0.434958232220543]
	TIME [epoch: 12.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500076661755248		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.500076661755248 | validation: 0.361144365638108]
	TIME [epoch: 12.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43369206797877063		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.43369206797877063 | validation: 0.3891827180709202]
	TIME [epoch: 12.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40498420359554094		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.40498420359554094 | validation: 0.4242660433627449]
	TIME [epoch: 13 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688937960452687		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4688937960452687 | validation: 0.7445072981117449]
	TIME [epoch: 13 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156715784219989		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.6156715784219989 | validation: 0.5948281235270114]
	TIME [epoch: 12.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6412869691725795		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6412869691725795 | validation: 0.4900556689342584]
	TIME [epoch: 12.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490789357544595		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5490789357544595 | validation: 0.4034443758822133]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190569298813147		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5190569298813147 | validation: 0.507572904274828]
	TIME [epoch: 12.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49998063339435406		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.49998063339435406 | validation: 0.4386453094175049]
	TIME [epoch: 12.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.859393467180374		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.859393467180374 | validation: 0.3896026187185855]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668318850725464		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5668318850725464 | validation: 0.342154159708542]
	TIME [epoch: 13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508123842120257		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5508123842120257 | validation: 0.3902523132725344]
	TIME [epoch: 13 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539323637047018		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.539323637047018 | validation: 0.41253284340625807]
	TIME [epoch: 13 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41641523956563065		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.41641523956563065 | validation: 0.5620875501275094]
	TIME [epoch: 12.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326807008667805		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4326807008667805 | validation: 0.6910477656449001]
	TIME [epoch: 13 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392042822420451		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.5392042822420451 | validation: 0.5389955445467117]
	TIME [epoch: 13 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934612743202978		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5934612743202978 | validation: 0.45125949458554976]
	TIME [epoch: 13 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4770554395072		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4770554395072 | validation: 0.39131926777096043]
	TIME [epoch: 13 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980295601895418		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3980295601895418 | validation: 0.35009840300963185]
	TIME [epoch: 13 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49881495943434456		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.49881495943434456 | validation: 0.7418943588201278]
	TIME [epoch: 13 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5283248893138457		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.5283248893138457 | validation: 0.3762684916829155]
	TIME [epoch: 13 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5114563337262504		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5114563337262504 | validation: 0.382850722093869]
	TIME [epoch: 13 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46039668571793596		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.46039668571793596 | validation: 0.31387778175202335]
	TIME [epoch: 13 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185182076572799		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5185182076572799 | validation: 0.5880899700828581]
	TIME [epoch: 12.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5610003410806104		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5610003410806104 | validation: 0.7105315156143069]
	TIME [epoch: 12.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6632874306875418		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6632874306875418 | validation: 0.5368989787585262]
	TIME [epoch: 13 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043843462566788		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5043843462566788 | validation: 0.26545876137554125]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4494452765425795		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4494452765425795 | validation: 0.5115109296653207]
	TIME [epoch: 12.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4347720573676098		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.4347720573676098 | validation: 0.5921226984816912]
	TIME [epoch: 13 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988016013205737		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.6988016013205737 | validation: 1.5843884541244038]
	TIME [epoch: 13 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108001345172045		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.108001345172045 | validation: 0.45650045641676057]
	TIME [epoch: 12.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685751210019046		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.685751210019046 | validation: 0.7546518931465653]
	TIME [epoch: 12.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598995188428628		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.5598995188428628 | validation: 0.29888607931379424]
	TIME [epoch: 13 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420475415104114		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.420475415104114 | validation: 0.3727904617700073]
	TIME [epoch: 13 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5344684262470022		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5344684262470022 | validation: 0.3813514706311979]
	TIME [epoch: 12.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675656945595257		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.4675656945595257 | validation: 0.31982813732251375]
	TIME [epoch: 13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5750632847399035		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5750632847399035 | validation: 0.3049528690949281]
	TIME [epoch: 12.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058629481248433		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7058629481248433 | validation: 0.470551502677823]
	TIME [epoch: 12.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144811481799006		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.5144811481799006 | validation: 0.36784599668486223]
	TIME [epoch: 12.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4275936912669348		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.4275936912669348 | validation: 0.7004016328572651]
	TIME [epoch: 13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607500038246177		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.5607500038246177 | validation: 0.6584739480828401]
	TIME [epoch: 12.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043659111249291		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5043659111249291 | validation: 0.4955603600326225]
	TIME [epoch: 12.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47515096241045696		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.47515096241045696 | validation: 0.43596279494214407]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46415068164420903		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.46415068164420903 | validation: 0.5738260500785253]
	TIME [epoch: 12.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726393574332224		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4726393574332224 | validation: 0.48938893970854497]
	TIME [epoch: 12.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4815143856993147		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4815143856993147 | validation: 0.47125878965742274]
	TIME [epoch: 12.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147064416927691		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6147064416927691 | validation: 0.42337725280012695]
	TIME [epoch: 12.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46860951474746837		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.46860951474746837 | validation: 0.30203921152702423]
	TIME [epoch: 12.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3966398283001607		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3966398283001607 | validation: 0.26934282997877473]
	TIME [epoch: 13 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034638879003893		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5034638879003893 | validation: 0.6368337777365164]
	TIME [epoch: 12.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065481885370989		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.5065481885370989 | validation: 0.6377776035307268]
	TIME [epoch: 12.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124982864753063		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5124982864753063 | validation: 0.3258877942320622]
	TIME [epoch: 12.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46123556346878347		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.46123556346878347 | validation: 0.2647786949515654]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351360268603153		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4351360268603153 | validation: 0.3270168078033123]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116814598040338		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5116814598040338 | validation: 0.3624854590398624]
	TIME [epoch: 13 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171175725605932		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4171175725605932 | validation: 0.4911145002622466]
	TIME [epoch: 13 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634681291034834		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4634681291034834 | validation: 0.43425485592779217]
	TIME [epoch: 13 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40886190729759675		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.40886190729759675 | validation: 0.3010647008872303]
	TIME [epoch: 13 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3912311404314533		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3912311404314533 | validation: 0.4531030154824353]
	TIME [epoch: 13 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066950053043633		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.4066950053043633 | validation: 0.7413975046778103]
	TIME [epoch: 13 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47867922786354106		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.47867922786354106 | validation: 0.39422908386982014]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45435082548696043		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.45435082548696043 | validation: 0.24828927038165455]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085302743251693		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4085302743251693 | validation: 0.5725772715592851]
	TIME [epoch: 13 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069167530601979		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.6069167530601979 | validation: 0.6669434146300875]
	TIME [epoch: 12.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386586384944073		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5386586384944073 | validation: 0.6409218112215865]
	TIME [epoch: 12.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083596732191201		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5083596732191201 | validation: 0.5880000921105795]
	TIME [epoch: 13 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057218965568318		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6057218965568318 | validation: 0.5137723548234966]
	TIME [epoch: 12.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4421201834334184		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.4421201834334184 | validation: 0.4706585520546288]
	TIME [epoch: 12.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44953614937975656		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.44953614937975656 | validation: 0.6125999847704304]
	TIME [epoch: 13 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295100964811933		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5295100964811933 | validation: 0.4445486738952197]
	TIME [epoch: 12.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39145489447395654		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.39145489447395654 | validation: 0.4485946346429113]
	TIME [epoch: 12.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4655003066675664		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4655003066675664 | validation: 0.525571375507004]
	TIME [epoch: 13 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879704175667142		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4879704175667142 | validation: 0.3428145814354803]
	TIME [epoch: 12.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206787493709717		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4206787493709717 | validation: 0.5539902657261186]
	TIME [epoch: 12.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453605696829332		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6453605696829332 | validation: 0.6443292683580663]
	TIME [epoch: 12.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6172466181287408		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6172466181287408 | validation: 0.4568826653409404]
	TIME [epoch: 13 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168545882131266		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5168545882131266 | validation: 0.3344413242226588]
	TIME [epoch: 12.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34363158173090136		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.34363158173090136 | validation: 0.25446262923419094]
	TIME [epoch: 13 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43505112461020096		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.43505112461020096 | validation: 0.2866099673719603]
	TIME [epoch: 13 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112684414470282		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5112684414470282 | validation: 0.4125386557362892]
	TIME [epoch: 12.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961000020684063		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5961000020684063 | validation: 1.032675280241012]
	TIME [epoch: 12.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786820654558334		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5786820654558334 | validation: 0.6293589491735483]
	TIME [epoch: 12.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370361402780491		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5370361402780491 | validation: 0.7232745395120205]
	TIME [epoch: 13 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582853444510418		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5582853444510418 | validation: 0.4490025903140981]
	TIME [epoch: 12.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717919302270328		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4717919302270328 | validation: 0.35424214020453276]
	TIME [epoch: 12.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295079383402855		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.5295079383402855 | validation: 0.35927681591990124]
	TIME [epoch: 13 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46436460952822656		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.46436460952822656 | validation: 0.575520586326385]
	TIME [epoch: 12.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476774170493236		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5476774170493236 | validation: 0.3566735701292021]
	TIME [epoch: 12.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453285731297416		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.4453285731297416 | validation: 0.37515296619787775]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7666875282320937		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.7666875282320937 | validation: 0.4849537454025723]
	TIME [epoch: 12.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237498628094531		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5237498628094531 | validation: 0.39688654494738734]
	TIME [epoch: 12.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45200091440961954		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.45200091440961954 | validation: 0.3353316592401035]
	TIME [epoch: 13 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4286517607851103		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.4286517607851103 | validation: 0.2749982978987623]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34109310754501426		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.34109310754501426 | validation: 0.3624788841642666]
	TIME [epoch: 12.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174344884787817		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.4174344884787817 | validation: 0.2835185181799349]
	TIME [epoch: 12.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547056491948701		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.4547056491948701 | validation: 0.38874970850006096]
	TIME [epoch: 12.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654046826992417		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.654046826992417 | validation: 0.3900948868957059]
	TIME [epoch: 12.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45505146473928965		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.45505146473928965 | validation: 0.5302545552387234]
	TIME [epoch: 12.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257691069266098		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5257691069266098 | validation: 0.3076108544935496]
	TIME [epoch: 13 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899544864065111		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.4899544864065111 | validation: 0.7028108052245936]
	TIME [epoch: 12.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154033459514384		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5154033459514384 | validation: 0.6115616390708999]
	TIME [epoch: 12.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47079070344270413		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.47079070344270413 | validation: 0.2428056400953649]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896991062070127		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3896991062070127 | validation: 0.2634590276914611]
	TIME [epoch: 12.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599387001829002		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.4599387001829002 | validation: 0.30903978741906374]
	TIME [epoch: 12.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4666096638006442		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4666096638006442 | validation: 0.3444975640381738]
	TIME [epoch: 12.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823641032266466		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3823641032266466 | validation: 0.30094091002451767]
	TIME [epoch: 13 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411657422409908		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.4411657422409908 | validation: 0.29715729185037165]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786632758197043		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3786632758197043 | validation: 0.5197298087371371]
	TIME [epoch: 13 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494747141955172		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.494747141955172 | validation: 0.2537847857156948]
	TIME [epoch: 13 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33832724502007117		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.33832724502007117 | validation: 0.3223504416509377]
	TIME [epoch: 12.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48182273897691597		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.48182273897691597 | validation: 0.38155046209996196]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437276584157123		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4437276584157123 | validation: 0.30448777602305577]
	TIME [epoch: 13 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068663794410298		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.4068663794410298 | validation: 0.3507412022822558]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34027672377415497		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.34027672377415497 | validation: 0.32586983844410305]
	TIME [epoch: 12.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320999753503493		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5320999753503493 | validation: 0.3852000210366541]
	TIME [epoch: 13 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35662449641876515		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.35662449641876515 | validation: 0.2936344902889283]
	TIME [epoch: 13 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985749807055791		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2985749807055791 | validation: 0.45355748090580394]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628725422588814		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.3628725422588814 | validation: 0.226211007743004]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623977049285695		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3623977049285695 | validation: 0.22760085649656567]
	TIME [epoch: 13 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35322909778965705		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.35322909778965705 | validation: 0.26908086969262784]
	TIME [epoch: 12.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602054929765972		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.4602054929765972 | validation: 0.4012028307412778]
	TIME [epoch: 12.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648208554484146		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.3648208554484146 | validation: 0.2697957980054365]
	TIME [epoch: 12.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297201466885846		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.297201466885846 | validation: 0.2609689909584946]
	TIME [epoch: 12.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946407482526586		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3946407482526586 | validation: 0.4814407652271823]
	TIME [epoch: 12.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39397635304409445		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.39397635304409445 | validation: 0.2730333128678837]
	TIME [epoch: 12.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3227567529316404		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3227567529316404 | validation: 0.281563649049737]
	TIME [epoch: 12.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3347425723957025		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.3347425723957025 | validation: 0.3008195094788973]
	TIME [epoch: 12.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278794322679749		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.4278794322679749 | validation: 0.26801359612889064]
	TIME [epoch: 12.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3827503668528755		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3827503668528755 | validation: 0.2961164756577074]
	TIME [epoch: 12.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784687047375086		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3784687047375086 | validation: 0.35072626770837845]
	TIME [epoch: 12.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39572992257478246		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.39572992257478246 | validation: 0.36706856083703626]
	TIME [epoch: 12.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34026202602411854		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.34026202602411854 | validation: 0.3680422491026848]
	TIME [epoch: 12.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35664941443438		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.35664941443438 | validation: 0.26763106007126075]
	TIME [epoch: 12.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349784744468198		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3349784744468198 | validation: 0.2514883929717231]
	TIME [epoch: 12.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034310280458561		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3034310280458561 | validation: 0.31320010659034203]
	TIME [epoch: 13 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314097662435149		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.4314097662435149 | validation: 0.29742781110169125]
	TIME [epoch: 12.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33270029148268654		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.33270029148268654 | validation: 0.36457495932301004]
	TIME [epoch: 12.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41626760526700257		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.41626760526700257 | validation: 0.45857774307081556]
	TIME [epoch: 12.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39695127611112085		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.39695127611112085 | validation: 0.32095842000924607]
	TIME [epoch: 12.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32388362920941766		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.32388362920941766 | validation: 0.30264038833323553]
	TIME [epoch: 12.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708801788637383		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2708801788637383 | validation: 0.32934605538683315]
	TIME [epoch: 12.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307422874907552		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3307422874907552 | validation: 0.2457350038903404]
	TIME [epoch: 13 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961097870051982		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3961097870051982 | validation: 0.5164336279218716]
	TIME [epoch: 12.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41700975217788505		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.41700975217788505 | validation: 0.2249542908220511]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143157674394899		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3143157674394899 | validation: 0.39762262512728314]
	TIME [epoch: 13 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407398069663087		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3407398069663087 | validation: 0.3001747507970844]
	TIME [epoch: 12.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504854209323437		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3504854209323437 | validation: 0.23277609081120892]
	TIME [epoch: 12.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090392373885827		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.3090392373885827 | validation: 0.25170438701555775]
	TIME [epoch: 12.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41922461194215854		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.41922461194215854 | validation: 0.2614122966329785]
	TIME [epoch: 13 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36381523834403273		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.36381523834403273 | validation: 0.2496929063584506]
	TIME [epoch: 12.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33510716696576837		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.33510716696576837 | validation: 0.5376440164107273]
	TIME [epoch: 12.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616800896207064		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.4616800896207064 | validation: 0.3012209469836932]
	TIME [epoch: 13 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39571614444694836		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.39571614444694836 | validation: 0.30909381341445236]
	TIME [epoch: 12.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40061658930187993		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.40061658930187993 | validation: 0.2360272751834111]
	TIME [epoch: 12.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292918583120841		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3292918583120841 | validation: 0.21349580896383452]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2661296144191718		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.2661296144191718 | validation: 0.2805802218966403]
	TIME [epoch: 12.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066766652298716		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.3066766652298716 | validation: 0.21946838512729153]
	TIME [epoch: 12.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28559156998558416		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.28559156998558416 | validation: 0.25475793718791023]
	TIME [epoch: 12.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661739440116261		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.3661739440116261 | validation: 0.32575249762904734]
	TIME [epoch: 12.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405882807233968		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3405882807233968 | validation: 0.29729443499407754]
	TIME [epoch: 12.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30773082615862474		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.30773082615862474 | validation: 0.33434396538885336]
	TIME [epoch: 13 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33584373379451504		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.33584373379451504 | validation: 0.3561829991653862]
	TIME [epoch: 13 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33482074101328174		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.33482074101328174 | validation: 0.32728417802698645]
	TIME [epoch: 13 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086184077908893		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3086184077908893 | validation: 0.3645499839112027]
	TIME [epoch: 13 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141460812492426		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3141460812492426 | validation: 0.24878813234141653]
	TIME [epoch: 13 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593410786897592		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3593410786897592 | validation: 0.27407851158061847]
	TIME [epoch: 13 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858825430389442		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.2858825430389442 | validation: 0.41991829053179563]
	TIME [epoch: 13 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37044485322083776		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.37044485322083776 | validation: 0.312447462503087]
	TIME [epoch: 13 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41416455089366466		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.41416455089366466 | validation: 0.3837248857329436]
	TIME [epoch: 13 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30902999527649905		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.30902999527649905 | validation: 0.33145613787810296]
	TIME [epoch: 13 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32722025506078556		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.32722025506078556 | validation: 0.3290325687969584]
	TIME [epoch: 13 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345831037444669		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.345831037444669 | validation: 0.4106543463534837]
	TIME [epoch: 13 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370931169032543		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3370931169032543 | validation: 0.2688242388086289]
	TIME [epoch: 12.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868026761461148		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2868026761461148 | validation: 0.2855219954015846]
	TIME [epoch: 13 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686280275531314		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.3686280275531314 | validation: 0.36006085964780726]
	TIME [epoch: 13 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357473120393136		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3357473120393136 | validation: 0.20096812520414375]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30088188979193686		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.30088188979193686 | validation: 0.39050343043938285]
	TIME [epoch: 13 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42974300353806616		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.42974300353806616 | validation: 0.29015023990313477]
	TIME [epoch: 13 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308769566565418		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3308769566565418 | validation: 0.2935033711258575]
	TIME [epoch: 13 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411080436283205		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3411080436283205 | validation: 0.4318650251331679]
	TIME [epoch: 13 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916187878105881		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3916187878105881 | validation: 0.35752781859899485]
	TIME [epoch: 13 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33944581657082207		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.33944581657082207 | validation: 0.23486820735473452]
	TIME [epoch: 12.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29994012145479404		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.29994012145479404 | validation: 0.285393736316549]
	TIME [epoch: 12.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29790524873269936		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.29790524873269936 | validation: 0.28820692715555135]
	TIME [epoch: 13 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561548913536885		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.3561548913536885 | validation: 0.35906621841739106]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41589327350029487		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.41589327350029487 | validation: 0.2607041610918212]
	TIME [epoch: 12.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922987921615468		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2922987921615468 | validation: 0.2389098159617079]
	TIME [epoch: 12.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139020594386529		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3139020594386529 | validation: 0.2406665190359735]
	TIME [epoch: 13 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33536837576038236		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.33536837576038236 | validation: 0.36385008402479313]
	TIME [epoch: 12.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740193220774826		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.3740193220774826 | validation: 0.2279491154964083]
	TIME [epoch: 12.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37456631922815964		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.37456631922815964 | validation: 0.3661232179320597]
	TIME [epoch: 12.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31565518222832484		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.31565518222832484 | validation: 0.45809617178605944]
	TIME [epoch: 13 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35594991488561417		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.35594991488561417 | validation: 0.3220179589332327]
	TIME [epoch: 13 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36767289982764995		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.36767289982764995 | validation: 0.37909218739201395]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295303527656993		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3295303527656993 | validation: 0.3514549580310795]
	TIME [epoch: 13 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3120180432424917		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3120180432424917 | validation: 0.1973695624462154]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2264199043359045		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2264199043359045 | validation: 0.20829886005183723]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29597136539481145		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.29597136539481145 | validation: 0.2523245582291471]
	TIME [epoch: 13 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32716124241652034		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.32716124241652034 | validation: 0.2669114224761393]
	TIME [epoch: 13 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32061557571913246		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.32061557571913246 | validation: 0.2239697202866767]
	TIME [epoch: 12.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28175695635505904		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.28175695635505904 | validation: 0.4386117193888684]
	TIME [epoch: 13 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385622795273484		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3385622795273484 | validation: 0.18921255834247336]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22396591630696544		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.22396591630696544 | validation: 0.25402532097029284]
	TIME [epoch: 13 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906961864667993		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.2906961864667993 | validation: 0.362351500100841]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28834025051701484		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.28834025051701484 | validation: 0.2610177841991014]
	TIME [epoch: 13 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900797825922407		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3900797825922407 | validation: 0.3442785556368915]
	TIME [epoch: 12.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996167249397529		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2996167249397529 | validation: 0.26387204686299626]
	TIME [epoch: 12.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838383114128185		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.2838383114128185 | validation: 0.2544214740406305]
	TIME [epoch: 12.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23239357626418095		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23239357626418095 | validation: 0.21908657604988108]
	TIME [epoch: 12.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32929962285472597		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.32929962285472597 | validation: 0.24820487474534006]
	TIME [epoch: 12.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331285275984978		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.331285275984978 | validation: 0.2841612334993046]
	TIME [epoch: 13 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772578575068473		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2772578575068473 | validation: 0.21839269288788843]
	TIME [epoch: 12.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101438247495111		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3101438247495111 | validation: 0.38333852742558394]
	TIME [epoch: 12.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38381174996972645		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.38381174996972645 | validation: 0.24419480583206288]
	TIME [epoch: 13 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884173611895688		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.2884173611895688 | validation: 0.3099757549805582]
	TIME [epoch: 12.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26154591217252054		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.26154591217252054 | validation: 0.2664607869731447]
	TIME [epoch: 13 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739496841219181		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3739496841219181 | validation: 0.3478827030057461]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843466979864596		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2843466979864596 | validation: 0.1931390056831603]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27536870897799026		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.27536870897799026 | validation: 0.22168947912644282]
	TIME [epoch: 12.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038686848314452		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3038686848314452 | validation: 0.1853355495361508]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26884459388656656		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.26884459388656656 | validation: 0.20129522822607712]
	TIME [epoch: 13 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25030187226662926		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.25030187226662926 | validation: 0.4558933644322785]
	TIME [epoch: 12.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34827054342199804		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.34827054342199804 | validation: 0.27071540465141153]
	TIME [epoch: 12.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41433349244137907		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.41433349244137907 | validation: 0.30530230195069774]
	TIME [epoch: 13 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574988665563356		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.3574988665563356 | validation: 0.3718065523814401]
	TIME [epoch: 12.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37998889779595024		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.37998889779595024 | validation: 0.4413891820534444]
	TIME [epoch: 12.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382969192925999		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.4382969192925999 | validation: 0.2583466754319135]
	TIME [epoch: 13 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261720322450516		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3261720322450516 | validation: 0.29094345767714946]
	TIME [epoch: 13 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28075130368662515		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.28075130368662515 | validation: 0.2406352450104333]
	TIME [epoch: 13 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507559923857589		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2507559923857589 | validation: 0.2719164119554284]
	TIME [epoch: 13 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832677928260256		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2832677928260256 | validation: 0.28677641002168885]
	TIME [epoch: 13 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974598923182261		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2974598923182261 | validation: 0.5116053253391979]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37041745055421066		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.37041745055421066 | validation: 0.20396553891505803]
	TIME [epoch: 12.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234654149754691		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3234654149754691 | validation: 0.26604045693756395]
	TIME [epoch: 13 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3021470325371262		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3021470325371262 | validation: 0.21595878161472926]
	TIME [epoch: 12.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867665016296056		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3867665016296056 | validation: 0.30469807687464984]
	TIME [epoch: 12.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418848481909328		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3418848481909328 | validation: 0.38061516028533915]
	TIME [epoch: 13 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406498811301303		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.3406498811301303 | validation: 0.22749088849739033]
	TIME [epoch: 13 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857654066027568		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.2857654066027568 | validation: 0.44455064790632465]
	TIME [epoch: 12.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37931337622031		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.37931337622031 | validation: 0.24474605757099774]
	TIME [epoch: 13 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3073636522932766		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3073636522932766 | validation: 0.36681649361995183]
	TIME [epoch: 12.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3283544184666358		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3283544184666358 | validation: 0.31497049667404464]
	TIME [epoch: 12.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30223340673798516		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.30223340673798516 | validation: 0.22012703244811932]
	TIME [epoch: 12.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297322019789101		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.3297322019789101 | validation: 0.2760506141310772]
	TIME [epoch: 13 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30376215946985763		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.30376215946985763 | validation: 0.2318334049896221]
	TIME [epoch: 12.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597106863840381		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.2597106863840381 | validation: 0.2808685537538208]
	TIME [epoch: 12.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010722406631786		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.3010722406631786 | validation: 0.2118025221704035]
	TIME [epoch: 13 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22130075427992432		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.22130075427992432 | validation: 0.1857826143742386]
	TIME [epoch: 12.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620052804554363		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.2620052804554363 | validation: 0.21587458842968268]
	TIME [epoch: 12.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29794943274634944		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.29794943274634944 | validation: 0.18250656393120637]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32874658993492734		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.32874658993492734 | validation: 0.2924542557842023]
	TIME [epoch: 13 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23797621575853062		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.23797621575853062 | validation: 0.37826878172569794]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482410735826075		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3482410735826075 | validation: 0.29292659944119237]
	TIME [epoch: 13 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903443024303348		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2903443024303348 | validation: 0.31510525640367293]
	TIME [epoch: 13 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28917663170544866		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.28917663170544866 | validation: 0.3427076012755827]
	TIME [epoch: 12.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29964190869608687		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.29964190869608687 | validation: 0.3183585379715118]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28179203858259216		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.28179203858259216 | validation: 0.39894789676246706]
	TIME [epoch: 13 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34330893433785525		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.34330893433785525 | validation: 0.2820540574613969]
	TIME [epoch: 12.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349638788120473		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.2349638788120473 | validation: 0.2065749089968278]
	TIME [epoch: 12.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28855259834012326		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.28855259834012326 | validation: 0.2866712987751283]
	TIME [epoch: 12.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24110664204310644		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.24110664204310644 | validation: 0.20496924448842502]
	TIME [epoch: 12.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32670872820603014		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.32670872820603014 | validation: 0.26098098304743356]
	TIME [epoch: 12.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27790456758539894		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.27790456758539894 | validation: 0.47419693658861456]
	TIME [epoch: 13 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30784039849660266		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.30784039849660266 | validation: 0.22714158528111242]
	TIME [epoch: 12.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507880543089177		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2507880543089177 | validation: 0.2113425143640792]
	TIME [epoch: 12.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32575892004541185		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.32575892004541185 | validation: 0.24160473021445333]
	TIME [epoch: 12.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36673147245680554		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.36673147245680554 | validation: 0.2690666942504097]
	TIME [epoch: 12.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115952637125502		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.3115952637125502 | validation: 0.25754251078892787]
	TIME [epoch: 12.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3265750298975022		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.3265750298975022 | validation: 0.2795517130299714]
	TIME [epoch: 12.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313302150653903		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.3313302150653903 | validation: 0.22721527187592908]
	TIME [epoch: 13 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29829357497080106		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.29829357497080106 | validation: 0.29046268678119985]
	TIME [epoch: 12.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25329572327587213		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.25329572327587213 | validation: 0.2901444307707513]
	TIME [epoch: 12.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24510333911391102		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.24510333911391102 | validation: 0.26438268578408475]
	TIME [epoch: 13 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30150582969228235		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.30150582969228235 | validation: 0.26881271135095736]
	TIME [epoch: 13 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695108014813551		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2695108014813551 | validation: 0.1806664059930942]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266391865412078		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.266391865412078 | validation: 0.15369537378750459]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521054846101116		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.2521054846101116 | validation: 0.2040007008036023]
	TIME [epoch: 13 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710720685881595		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2710720685881595 | validation: 0.18218880411673932]
	TIME [epoch: 13 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556130082520437		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2556130082520437 | validation: 0.2151159553695726]
	TIME [epoch: 13 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268377046673072		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.268377046673072 | validation: 0.21367662780949512]
	TIME [epoch: 13 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821053391450745		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2821053391450745 | validation: 0.19457957838930157]
	TIME [epoch: 13 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23794463453254883		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.23794463453254883 | validation: 0.3133326729556958]
	TIME [epoch: 12.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24471697923491492		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.24471697923491492 | validation: 0.20351981997231952]
	TIME [epoch: 13 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33732549787011795		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.33732549787011795 | validation: 0.1772006903289416]
	TIME [epoch: 13 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23195597063244577		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.23195597063244577 | validation: 0.20896569953409228]
	TIME [epoch: 13 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26945822065097136		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.26945822065097136 | validation: 0.28275118983627695]
	TIME [epoch: 13 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23943456906483707		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.23943456906483707 | validation: 0.19769723474923775]
	TIME [epoch: 13 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26745728502948607		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.26745728502948607 | validation: 0.20618191359994723]
	TIME [epoch: 13 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2714893439567097		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.2714893439567097 | validation: 0.34453586638065725]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645419601008749		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2645419601008749 | validation: 0.2461733078988494]
	TIME [epoch: 13 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692525381783223		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2692525381783223 | validation: 0.16482756732046447]
	TIME [epoch: 13 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146647656815015		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2146647656815015 | validation: 0.16047103896941703]
	TIME [epoch: 13 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24100105547164233		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.24100105547164233 | validation: 0.19198381004353018]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21832904046172072		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.21832904046172072 | validation: 0.16606839737386025]
	TIME [epoch: 13 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348123141684909		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.2348123141684909 | validation: 0.3640351165448881]
	TIME [epoch: 13 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851956962068673		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.2851956962068673 | validation: 0.16997694171810993]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22625674970965493		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.22625674970965493 | validation: 0.14653910436731812]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20698226834340824		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.20698226834340824 | validation: 0.22249364166214547]
	TIME [epoch: 13 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773184982650053		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.2773184982650053 | validation: 0.23023512121580403]
	TIME [epoch: 13 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647394077855658		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2647394077855658 | validation: 0.2623585968581495]
	TIME [epoch: 13 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552596845068386		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2552596845068386 | validation: 0.1779619693944392]
	TIME [epoch: 13 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459775000116275		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.2459775000116275 | validation: 0.32611512445132074]
	TIME [epoch: 13 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095426760903463		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.3095426760903463 | validation: 0.17518321453586608]
	TIME [epoch: 13 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22446635901815581		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.22446635901815581 | validation: 0.24503561431791723]
	TIME [epoch: 13 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19990254108745753		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.19990254108745753 | validation: 0.17363791062556658]
	TIME [epoch: 13 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20698767126065426		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.20698767126065426 | validation: 0.2590130476778447]
	TIME [epoch: 13 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28068235875445413		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.28068235875445413 | validation: 0.19900097744945255]
	TIME [epoch: 13 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20929554475304243		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.20929554475304243 | validation: 0.2727305848016599]
	TIME [epoch: 13 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634321834650177		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.2634321834650177 | validation: 0.26392675299396134]
	TIME [epoch: 13 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22323724635084755		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.22323724635084755 | validation: 0.26832923625551053]
	TIME [epoch: 13 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23953782517295819		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.23953782517295819 | validation: 0.18782653712329989]
	TIME [epoch: 13 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23844600171518518		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.23844600171518518 | validation: 0.2501419980624657]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680715192958354		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2680715192958354 | validation: 0.21122326711605033]
	TIME [epoch: 13 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25301620782396733		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.25301620782396733 | validation: 0.16293521476897352]
	TIME [epoch: 13 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2216049643451778		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.2216049643451778 | validation: 0.25508168896536404]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23154568802910777		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.23154568802910777 | validation: 0.28853522118247876]
	TIME [epoch: 13 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32257774104258785		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.32257774104258785 | validation: 0.4086059195750247]
	TIME [epoch: 13 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33754151718371433		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.33754151718371433 | validation: 0.23269530765464785]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20636890685732778		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.20636890685732778 | validation: 0.22000037969892589]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2345387243072549		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2345387243072549 | validation: 0.1839965581090964]
	TIME [epoch: 13 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24934021008068846		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.24934021008068846 | validation: 0.1468663997457231]
	TIME [epoch: 13 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887946391651036		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1887946391651036 | validation: 0.294142143445739]
	TIME [epoch: 13 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220325581817919		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3220325581817919 | validation: 0.1399891390335802]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_743.pth
	Model improved!!!
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919623744859898		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1919623744859898 | validation: 0.16053744500108913]
	TIME [epoch: 13 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18750611927823535		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.18750611927823535 | validation: 0.20484989695129524]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209200637819376		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2209200637819376 | validation: 0.19375872680377185]
	TIME [epoch: 13 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19639877880159667		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19639877880159667 | validation: 0.2085120897738944]
	TIME [epoch: 13 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18485779132042424		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.18485779132042424 | validation: 0.15483484000409806]
	TIME [epoch: 13 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142417738446255		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.2142417738446255 | validation: 0.41081057675255495]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30517284258663063		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.30517284258663063 | validation: 0.1712386580066658]
	TIME [epoch: 13 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964846414760031		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1964846414760031 | validation: 0.16193563253852744]
	TIME [epoch: 13 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23574213960532792		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.23574213960532792 | validation: 0.15673539026990946]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20961221050865414		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.20961221050865414 | validation: 0.27180182893734184]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814463770849065		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2814463770849065 | validation: 0.216676875027798]
	TIME [epoch: 13 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24485393036491973		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.24485393036491973 | validation: 0.25977104118985195]
	TIME [epoch: 13 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27975955135377806		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.27975955135377806 | validation: 0.21994011989587478]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108627717492922		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.2108627717492922 | validation: 0.14882787502508302]
	TIME [epoch: 13 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18493772615064247		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.18493772615064247 | validation: 0.15559361489308893]
	TIME [epoch: 13 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21475137069258074		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.21475137069258074 | validation: 0.22027118748546962]
	TIME [epoch: 13 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21107330155538095		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.21107330155538095 | validation: 0.17281333923319694]
	TIME [epoch: 13 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706929981317828		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1706929981317828 | validation: 0.19363113705002946]
	TIME [epoch: 13 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165709366460366		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.2165709366460366 | validation: 0.39266931442966974]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28808230612612806		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.28808230612612806 | validation: 0.1567407745257914]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21927618645838676		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.21927618645838676 | validation: 0.33631325589936256]
	TIME [epoch: 13 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746460784689281		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.2746460784689281 | validation: 0.2931225110335669]
	TIME [epoch: 13 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26928098496262365		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.26928098496262365 | validation: 0.15316312536121918]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028015066446077		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.2028015066446077 | validation: 0.16290896354230414]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200092156558474		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.200092156558474 | validation: 0.22758160529727767]
	TIME [epoch: 13 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27696017401844797		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.27696017401844797 | validation: 0.18588454117989514]
	TIME [epoch: 13 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20117057586229375		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.20117057586229375 | validation: 0.17712151246364186]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871730179613599		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.1871730179613599 | validation: 0.19348022910053253]
	TIME [epoch: 13 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2052581576999757		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.2052581576999757 | validation: 0.3747036903608094]
	TIME [epoch: 13 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24550853112092452		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.24550853112092452 | validation: 0.16615114429398298]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24286757290374889		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.24286757290374889 | validation: 0.18269868607627185]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939788803810652		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1939788803810652 | validation: 0.17901878439270077]
	TIME [epoch: 13 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229556479108033		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.2229556479108033 | validation: 0.22257632798647373]
	TIME [epoch: 13 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19480962276460181		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.19480962276460181 | validation: 0.2144714541276078]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20429552193181535		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.20429552193181535 | validation: 0.3494234338375678]
	TIME [epoch: 13 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660348392973419		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2660348392973419 | validation: 0.17580218419818863]
	TIME [epoch: 13 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23219640040515427		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.23219640040515427 | validation: 0.23599869946946805]
	TIME [epoch: 13 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2116457395180838		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.2116457395180838 | validation: 0.17609814549331]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19571797815860525		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.19571797815860525 | validation: 0.1834249091147653]
	TIME [epoch: 13 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19618724652297587		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.19618724652297587 | validation: 0.16555847453790748]
	TIME [epoch: 13 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16847113864160002		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.16847113864160002 | validation: 0.15374613665082845]
	TIME [epoch: 13 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750354158071111		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.1750354158071111 | validation: 0.14011822614544714]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090895658653661		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.2090895658653661 | validation: 0.15194445234658635]
	TIME [epoch: 13 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17534892499576019		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.17534892499576019 | validation: 0.17968494200877957]
	TIME [epoch: 13 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19959881615446637		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.19959881615446637 | validation: 0.2925422570259218]
	TIME [epoch: 13 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772031376769305		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.3772031376769305 | validation: 0.1827735246595778]
	TIME [epoch: 13 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20515712453981444		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.20515712453981444 | validation: 0.3292930210123423]
	TIME [epoch: 13 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25978312123432135		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.25978312123432135 | validation: 0.17371710173446264]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098185624299144		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.2098185624299144 | validation: 0.1651399168939486]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19709259518954522		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.19709259518954522 | validation: 0.18231546736809748]
	TIME [epoch: 13 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19771701370481942		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.19771701370481942 | validation: 0.2077320623045573]
	TIME [epoch: 13 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018418152847528		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.2018418152847528 | validation: 0.14869873768344619]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22062407441727777		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.22062407441727777 | validation: 0.19247765038106246]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20412668421217037		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.20412668421217037 | validation: 0.20083377131359595]
	TIME [epoch: 13 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2282423663275974		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.2282423663275974 | validation: 0.18578069703049327]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20121400405670253		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.20121400405670253 | validation: 0.18218154157226898]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19448616798695753		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.19448616798695753 | validation: 0.16717973246357418]
	TIME [epoch: 13 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19562291490093797		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.19562291490093797 | validation: 0.1348448851398891]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1649494473374705		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.1649494473374705 | validation: 0.2309494902010607]
	TIME [epoch: 12.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19123046624690587		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.19123046624690587 | validation: 0.1245592758154514]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20032293218470773		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.20032293218470773 | validation: 0.3535983462262315]
	TIME [epoch: 12.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203557107460584		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2203557107460584 | validation: 0.15886366757926154]
	TIME [epoch: 13 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17557284580006732		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.17557284580006732 | validation: 0.1424996735279217]
	TIME [epoch: 12.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541823441539681		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2541823441539681 | validation: 0.19807684804785466]
	TIME [epoch: 12.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3019317124637405		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3019317124637405 | validation: 0.2519656222538204]
	TIME [epoch: 13 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22778720569873004		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.22778720569873004 | validation: 0.18766750216082564]
	TIME [epoch: 12.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538025521707932		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2538025521707932 | validation: 0.1856390482550219]
	TIME [epoch: 12.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24746748792542467		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.24746748792542467 | validation: 0.16850451322393434]
	TIME [epoch: 13 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17696193183767317		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.17696193183767317 | validation: 0.16085438331602014]
	TIME [epoch: 13 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20723355922083794		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.20723355922083794 | validation: 0.1755668903108507]
	TIME [epoch: 13 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715475109918938		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.1715475109918938 | validation: 0.1456423928407709]
	TIME [epoch: 12.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1969277163052386		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1969277163052386 | validation: 0.2322046104038273]
	TIME [epoch: 13 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22935746406246743		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.22935746406246743 | validation: 0.17288747236709207]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17781512437762526		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.17781512437762526 | validation: 0.17919691169883628]
	TIME [epoch: 13 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19583902043746193		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.19583902043746193 | validation: 0.21287151841974633]
	TIME [epoch: 13 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206121202614528		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.206121202614528 | validation: 0.2536718513176807]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2201254680264871		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2201254680264871 | validation: 0.1455353052124449]
	TIME [epoch: 12.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18693406412772534		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.18693406412772534 | validation: 0.17938472940247713]
	TIME [epoch: 13 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21617029964340567		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.21617029964340567 | validation: 0.22390066066417105]
	TIME [epoch: 13 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2384883185127072		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.2384883185127072 | validation: 0.15579471154826158]
	TIME [epoch: 12.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16976593256867284		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.16976593256867284 | validation: 0.15234023125818472]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243508172736381		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.2243508172736381 | validation: 0.15474946525126926]
	TIME [epoch: 13 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21382249304007894		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.21382249304007894 | validation: 0.1528320117204271]
	TIME [epoch: 13 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19996595789426702		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.19996595789426702 | validation: 0.18872687995780035]
	TIME [epoch: 13 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18662158931082878		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.18662158931082878 | validation: 0.16842105897997506]
	TIME [epoch: 13 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17099632037539958		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.17099632037539958 | validation: 0.17698225583755803]
	TIME [epoch: 13 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19022315464732414		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.19022315464732414 | validation: 0.17723851636004134]
	TIME [epoch: 13 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19813017725077156		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.19813017725077156 | validation: 0.17548918248567624]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17987265398013783		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.17987265398013783 | validation: 0.14386824072682458]
	TIME [epoch: 13 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053336381272511		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.2053336381272511 | validation: 0.2135169750472899]
	TIME [epoch: 12.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22998349063655324		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.22998349063655324 | validation: 0.1349895660279877]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21593196257770003		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.21593196257770003 | validation: 0.16318988696106548]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19012003069104288		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.19012003069104288 | validation: 0.21329724724880506]
	TIME [epoch: 12.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23364877898411565		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.23364877898411565 | validation: 0.21419105299478594]
	TIME [epoch: 13 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19367169635320586		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.19367169635320586 | validation: 0.1478055812549443]
	TIME [epoch: 13 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18612535256963614		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.18612535256963614 | validation: 0.13215651172254575]
	TIME [epoch: 13 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16981894276217555		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.16981894276217555 | validation: 0.17250351776730097]
	TIME [epoch: 12.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21114305029674607		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.21114305029674607 | validation: 0.1671296930494188]
	TIME [epoch: 13 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18978687072317585		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.18978687072317585 | validation: 0.15747697844366787]
	TIME [epoch: 12.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088439977670135		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.2088439977670135 | validation: 0.15807414552118676]
	TIME [epoch: 12.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950467177687502		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.1950467177687502 | validation: 0.18074500744025593]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19681052854565653		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.19681052854565653 | validation: 0.25235789018792654]
	TIME [epoch: 13 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21070080996625132		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.21070080996625132 | validation: 0.13787514873120643]
	TIME [epoch: 12.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16580309046610336		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.16580309046610336 | validation: 0.19801222515212466]
	TIME [epoch: 12.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18061339782041314		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.18061339782041314 | validation: 0.21279142643672888]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27320478119579666		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.27320478119579666 | validation: 0.21049630944708086]
	TIME [epoch: 12.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21387110147293142		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.21387110147293142 | validation: 0.18630504793463168]
	TIME [epoch: 12.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24116563371642352		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.24116563371642352 | validation: 0.1475911960622938]
	TIME [epoch: 13 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703968551479937		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1703968551479937 | validation: 0.16175889822219436]
	TIME [epoch: 13 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2004726934319921		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2004726934319921 | validation: 0.16198291529148698]
	TIME [epoch: 13 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20413590539247828		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.20413590539247828 | validation: 0.2340463072725536]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20539808067197646		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.20539808067197646 | validation: 0.14594551455585297]
	TIME [epoch: 13 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290523944735971		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.2290523944735971 | validation: 0.38864948025470497]
	TIME [epoch: 13 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26895335570683865		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.26895335570683865 | validation: 0.12741904628398454]
	TIME [epoch: 13 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21075493831802172		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.21075493831802172 | validation: 0.1690866794255967]
	TIME [epoch: 13 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24886461275569646		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.24886461275569646 | validation: 0.2178257521603704]
	TIME [epoch: 13 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21442398418953756		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.21442398418953756 | validation: 0.15319027219605116]
	TIME [epoch: 13 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22058664661029764		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.22058664661029764 | validation: 0.1661532094318871]
	TIME [epoch: 13 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18694905566100253		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.18694905566100253 | validation: 0.17302711294730194]
	TIME [epoch: 13 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929826237531116		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.1929826237531116 | validation: 0.15447445075275304]
	TIME [epoch: 13 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19875967861227065		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.19875967861227065 | validation: 0.18784975293899564]
	TIME [epoch: 13 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19519994357335202		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.19519994357335202 | validation: 0.22907778661808686]
	TIME [epoch: 13 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20317295958329085		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.20317295958329085 | validation: 0.23168381783426514]
	TIME [epoch: 13 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20206096104025856		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.20206096104025856 | validation: 0.1864656399541978]
	TIME [epoch: 13 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16982460757596768		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.16982460757596768 | validation: 0.16527357012999375]
	TIME [epoch: 13 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646302419072447		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.1646302419072447 | validation: 0.18133870315916784]
	TIME [epoch: 13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21675799310440708		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.21675799310440708 | validation: 0.17435789095822507]
	TIME [epoch: 12.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2135634249756536		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.2135634249756536 | validation: 0.16826507966582335]
	TIME [epoch: 13 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17273040746458201		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.17273040746458201 | validation: 0.16447124347856296]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16683992284881077		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.16683992284881077 | validation: 0.16180346134695422]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216898099059807		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.19216898099059807 | validation: 0.1590431535662627]
	TIME [epoch: 13 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18597261156356856		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.18597261156356856 | validation: 0.18411829533235158]
	TIME [epoch: 12.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617607458417935		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2617607458417935 | validation: 0.20314631590281632]
	TIME [epoch: 12.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22090122510116453		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.22090122510116453 | validation: 0.18983397399392615]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050382294364711		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2050382294364711 | validation: 0.13580721447794006]
	TIME [epoch: 13 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17924241339410624		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.17924241339410624 | validation: 0.15392216646617413]
	TIME [epoch: 12.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819661889815836		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.1819661889815836 | validation: 0.19475256732176732]
	TIME [epoch: 13 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22159910174099803		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.22159910174099803 | validation: 0.15280749902101495]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17930459982442215		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.17930459982442215 | validation: 0.15450103802833987]
	TIME [epoch: 13 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181142128465826		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.181142128465826 | validation: 0.1436831612430751]
	TIME [epoch: 12.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170886946480505		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.170886946480505 | validation: 0.13263195795238844]
	TIME [epoch: 13 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17572202823732794		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.17572202823732794 | validation: 0.1824941224015688]
	TIME [epoch: 12.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19011593967523258		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.19011593967523258 | validation: 0.15274378735442656]
	TIME [epoch: 12.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18608070523488487		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.18608070523488487 | validation: 0.16111388194178425]
	TIME [epoch: 13 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303255173727976		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.2303255173727976 | validation: 0.2113246384782923]
	TIME [epoch: 12.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1946850973632793		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.1946850973632793 | validation: 0.15634540576152894]
	TIME [epoch: 12.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17960755438461642		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.17960755438461642 | validation: 0.14109162948891016]
	TIME [epoch: 13 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538114951351894		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1538114951351894 | validation: 0.17611683367058034]
	TIME [epoch: 13 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259169646150397		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.18259169646150397 | validation: 0.1488658025835991]
	TIME [epoch: 12.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18400602700461452		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.18400602700461452 | validation: 0.15267962175228766]
	TIME [epoch: 12.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16039070265532654		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.16039070265532654 | validation: 0.13164364106753979]
	TIME [epoch: 12.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17585896634137474		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.17585896634137474 | validation: 0.2348828971358905]
	TIME [epoch: 12.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150204705443047		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.2150204705443047 | validation: 0.17098386142991026]
	TIME [epoch: 12.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19030168033799302		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.19030168033799302 | validation: 0.1326733246749493]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548564793618817		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.1548564793618817 | validation: 0.13308753193657494]
	TIME [epoch: 12.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19180202969051866		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.19180202969051866 | validation: 0.16559406710243668]
	TIME [epoch: 12.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16842296443296814		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.16842296443296814 | validation: 0.1406436943380567]
	TIME [epoch: 12.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16493493025140987		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.16493493025140987 | validation: 0.12907165704869708]
	TIME [epoch: 12.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16064452119792264		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.16064452119792264 | validation: 0.18803450860491006]
	TIME [epoch: 12.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18051325800144685		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.18051325800144685 | validation: 0.17207008791871256]
	TIME [epoch: 13 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17368230633300796		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.17368230633300796 | validation: 0.12659470762650232]
	TIME [epoch: 13 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15955225040331023		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.15955225040331023 | validation: 0.1369463199082657]
	TIME [epoch: 13 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16175517863784672		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.16175517863784672 | validation: 0.15710145992380425]
	TIME [epoch: 13 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065067115327108		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.2065067115327108 | validation: 0.17533596116120215]
	TIME [epoch: 13 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18830061757578284		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.18830061757578284 | validation: 0.12241240853609639]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415730130171421		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.16415730130171421 | validation: 0.1430021725940064]
	TIME [epoch: 12.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17206233752905403		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.17206233752905403 | validation: 0.16106116596908274]
	TIME [epoch: 13 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865539637286629		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1865539637286629 | validation: 0.13559057719165443]
	TIME [epoch: 12.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800789222210402		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.16800789222210402 | validation: 0.12689516520925093]
	TIME [epoch: 12.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17678406717829714		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.17678406717829714 | validation: 0.16114473591665718]
	TIME [epoch: 13 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190191121072695		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.16190191121072695 | validation: 0.15273390191198735]
	TIME [epoch: 12.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20888307314135973		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.20888307314135973 | validation: 0.27939209128887554]
	TIME [epoch: 12.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20855325784864445		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.20855325784864445 | validation: 0.13907601124609195]
	TIME [epoch: 12.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725116995053783		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.14725116995053783 | validation: 0.15751457840168384]
	TIME [epoch: 12.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19555514438094357		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.19555514438094357 | validation: 0.19780707105586562]
	TIME [epoch: 13 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747130530829666		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.1747130530829666 | validation: 0.1318062536845508]
	TIME [epoch: 13 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16667884967645133		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.16667884967645133 | validation: 0.155580225532407]
	TIME [epoch: 13 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17830667362594008		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.17830667362594008 | validation: 0.1212451194227856]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18135303348472878		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.18135303348472878 | validation: 0.13874023154107845]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20311325440952846		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.20311325440952846 | validation: 0.18376615411795208]
	TIME [epoch: 13 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138035850520495		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2138035850520495 | validation: 0.1182244996737079]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_924.pth
	Model improved!!!
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917509693848863		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.17917509693848863 | validation: 0.15818976084511693]
	TIME [epoch: 12.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19495188091614118		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.19495188091614118 | validation: 0.1582464766523511]
	TIME [epoch: 13 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18417238984609868		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.18417238984609868 | validation: 0.18358268000147043]
	TIME [epoch: 13 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874546574553506		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.1874546574553506 | validation: 0.1269186183489176]
	TIME [epoch: 13 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549224445313544		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.1549224445313544 | validation: 0.20837462088537811]
	TIME [epoch: 13 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20293187759773534		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.20293187759773534 | validation: 0.12254460727374344]
	TIME [epoch: 13 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15545439841529263		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.15545439841529263 | validation: 0.17010107427551202]
	TIME [epoch: 12.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133847836402089		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2133847836402089 | validation: 0.15621114793939309]
	TIME [epoch: 13 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660185425392971		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.1660185425392971 | validation: 0.14029927101610257]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15171361001215664		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.15171361001215664 | validation: 0.13447658986823408]
	TIME [epoch: 13 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15717010203427262		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.15717010203427262 | validation: 0.110848471887288]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_935.pth
	Model improved!!!
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16558436623175574		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.16558436623175574 | validation: 0.10077418009717524]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_936.pth
	Model improved!!!
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15308896919796733		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.15308896919796733 | validation: 0.10841462883576698]
	TIME [epoch: 13 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15645621246579894		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.15645621246579894 | validation: 0.1671282357726676]
	TIME [epoch: 13 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724691977082171		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1724691977082171 | validation: 0.12919665051473533]
	TIME [epoch: 13 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133094177817806		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.17133094177817806 | validation: 0.1320635616807926]
	TIME [epoch: 13 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16533306475980838		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.16533306475980838 | validation: 0.1360011165956186]
	TIME [epoch: 13 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14788049779670925		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.14788049779670925 | validation: 0.11366649669566835]
	TIME [epoch: 13 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150648079473993		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.150648079473993 | validation: 0.1238966816537203]
	TIME [epoch: 13 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501987807744064		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.1501987807744064 | validation: 0.11453620728579109]
	TIME [epoch: 13 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390647306508874		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.16390647306508874 | validation: 0.13464619632555874]
	TIME [epoch: 13 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695199133504437		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.15695199133504437 | validation: 0.16815827380737344]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21964906450984792		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.21964906450984792 | validation: 0.16657748128265443]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20316168579408497		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.20316168579408497 | validation: 0.12474956277048911]
	TIME [epoch: 13 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18481563790923433		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.18481563790923433 | validation: 0.19951134189438688]
	TIME [epoch: 13 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21866124407703535		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.21866124407703535 | validation: 0.12762568098855095]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20605245057442997		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.20605245057442997 | validation: 0.1388892055746063]
	TIME [epoch: 13 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18582244444192125		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.18582244444192125 | validation: 0.11465746534246585]
	TIME [epoch: 13 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14736346816478024		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.14736346816478024 | validation: 0.15547772986003236]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17397060423205796		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.17397060423205796 | validation: 0.11399996650221197]
	TIME [epoch: 13 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434123574166688		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1434123574166688 | validation: 0.1215202093974278]
	TIME [epoch: 12.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14355067661795276		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.14355067661795276 | validation: 0.11464021367758392]
	TIME [epoch: 13 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14690210562576805		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.14690210562576805 | validation: 0.1573690482052992]
	TIME [epoch: 13 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958847946008702		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.1958847946008702 | validation: 0.1173344382067199]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557763168289722		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.1557763168289722 | validation: 0.2479955001318766]
	TIME [epoch: 13 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2180133652800708		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2180133652800708 | validation: 0.14866540092346234]
	TIME [epoch: 13 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17059152723147167		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.17059152723147167 | validation: 0.12842878117721868]
	TIME [epoch: 13 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14523847057980985		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.14523847057980985 | validation: 0.1206646067400894]
	TIME [epoch: 13 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824923248227097		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1824923248227097 | validation: 0.16952407821113]
	TIME [epoch: 13 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1773667063869768		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1773667063869768 | validation: 0.1344583846240805]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15369831456225533		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.15369831456225533 | validation: 0.12915873545058953]
	TIME [epoch: 13 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16061845157336704		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.16061845157336704 | validation: 0.12590429737552356]
	TIME [epoch: 13 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16929708195806784		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.16929708195806784 | validation: 0.13261905148598468]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532003592596847		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1532003592596847 | validation: 0.12032554098816281]
	TIME [epoch: 12.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14960770447123195		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.14960770447123195 | validation: 0.17959010596527533]
	TIME [epoch: 13 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15290630391342427		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.15290630391342427 | validation: 0.11477915137448308]
	TIME [epoch: 13 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16884128663774942		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.16884128663774942 | validation: 0.1430197698324013]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19259823903612977		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.19259823903612977 | validation: 0.1405761135009112]
	TIME [epoch: 13 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16996375955070553		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.16996375955070553 | validation: 0.12681156783519185]
	TIME [epoch: 13 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17732214733346124		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.17732214733346124 | validation: 0.13551318241815996]
	TIME [epoch: 12.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15858892326084206		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.15858892326084206 | validation: 0.15210047713065483]
	TIME [epoch: 13 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16676778656404617		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.16676778656404617 | validation: 0.15507842249088147]
	TIME [epoch: 13 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19920570815905633		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.19920570815905633 | validation: 0.152226859636645]
	TIME [epoch: 13 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15531677034680422		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.15531677034680422 | validation: 0.13506298081917326]
	TIME [epoch: 13 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15985568049190987		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.15985568049190987 | validation: 0.12668001217885091]
	TIME [epoch: 13 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489449272928377		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1489449272928377 | validation: 0.15202306154472894]
	TIME [epoch: 13 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14993750972798728		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.14993750972798728 | validation: 0.1335758832102316]
	TIME [epoch: 13 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17117275490344713		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.17117275490344713 | validation: 0.16289089298382398]
	TIME [epoch: 13 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708727961030866		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.1708727961030866 | validation: 0.15501473018092055]
	TIME [epoch: 13 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15596175118840655		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.15596175118840655 | validation: 0.1356250943298157]
	TIME [epoch: 13 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17389609666906145		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.17389609666906145 | validation: 0.16487681393598141]
	TIME [epoch: 13 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17866004568208832		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.17866004568208832 | validation: 0.12353388688419877]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14964589665266767		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.14964589665266767 | validation: 0.14295299104969206]
	TIME [epoch: 13 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18677800415800594		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.18677800415800594 | validation: 0.163836117395026]
	TIME [epoch: 12.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840295351380417		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.1840295351380417 | validation: 0.13615601643591543]
	TIME [epoch: 13 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15953549924074417		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.15953549924074417 | validation: 0.1301171487882807]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18677390215862263		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.18677390215862263 | validation: 0.13946885198984135]
	TIME [epoch: 12.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535543772546414		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.1535543772546414 | validation: 0.12038393986262787]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420764139970913		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.1420764139970913 | validation: 0.19038004710479178]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19505545535839555		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.19505545535839555 | validation: 0.11943182669193171]
	TIME [epoch: 13 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496846753692084		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1496846753692084 | validation: 0.11543709958750614]
	TIME [epoch: 12.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341199390860682		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.1341199390860682 | validation: 0.10556885083380031]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868103827022507		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.13868103827022507 | validation: 0.19345629016876392]
	TIME [epoch: 12.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20208264528207218		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.20208264528207218 | validation: 0.1652633980735745]
	TIME [epoch: 13 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18045050805681004		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.18045050805681004 | validation: 0.16598961092962058]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19984000182152786		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.19984000182152786 | validation: 0.14495251835452214]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155904299808062		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.155904299808062 | validation: 0.15780872507890326]
	TIME [epoch: 12.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622733776450953		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.1622733776450953 | validation: 0.12203845154693933]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16185779148094948		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.16185779148094948 | validation: 0.12104905935607954]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15838693398386844		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.15838693398386844 | validation: 0.14622825218671384]
	TIME [epoch: 12.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16019643859177934		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.16019643859177934 | validation: 0.1453416844349947]
	TIME [epoch: 13 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16257609596428566		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.16257609596428566 | validation: 0.18334972241313033]
	TIME [epoch: 13 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1971785739771111		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.1971785739771111 | validation: 0.14716321097902152]
	TIME [epoch: 12.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16929282451211514		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.16929282451211514 | validation: 0.1470597953961738]
	TIME [epoch: 13 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15693926046989062		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.15693926046989062 | validation: 0.12969945533337573]
	TIME [epoch: 13 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304944325177985		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.14304944325177985 | validation: 0.1356481281256293]
	TIME [epoch: 12.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549629261065372		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1549629261065372 | validation: 0.16145586282534446]
	TIME [epoch: 12.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18244343199540422		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.18244343199540422 | validation: 0.21580135780780274]
	TIME [epoch: 12.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829147563539389		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.1829147563539389 | validation: 0.12442301885591313]
	TIME [epoch: 12.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18342578781530167		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.18342578781530167 | validation: 0.17002107475720396]
	TIME [epoch: 12.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17684582473862479		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.17684582473862479 | validation: 0.11622422252670137]
	TIME [epoch: 13 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640682104297003		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.13640682104297003 | validation: 0.13332094033821157]
	TIME [epoch: 13 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15339436855295757		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.15339436855295757 | validation: 0.11847958522309124]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15430244712934232		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.15430244712934232 | validation: 0.10545821396006254]
	TIME [epoch: 13 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624752765216663		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.13624752765216663 | validation: 0.12399866992340833]
	TIME [epoch: 13 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197624163222778		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.15197624163222778 | validation: 0.1216526215341445]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15770564598731385		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.15770564598731385 | validation: 0.1372513426746256]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15848613178840742		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.15848613178840742 | validation: 0.1338948483718853]
	TIME [epoch: 13 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766975036331906		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.14766975036331906 | validation: 0.1339511240247969]
	TIME [epoch: 13 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16746282309463678		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.16746282309463678 | validation: 0.11124639770971698]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072465557336244		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.14072465557336244 | validation: 0.1277573473142033]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634487345422131		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.1634487345422131 | validation: 0.1175783136994664]
	TIME [epoch: 13 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15019718729966594		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.15019718729966594 | validation: 0.10443468319383226]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13841837609983648		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.13841837609983648 | validation: 0.1337113234657646]
	TIME [epoch: 13 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15481428474985398		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.15481428474985398 | validation: 0.16913185991737933]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17069068282870029		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.17069068282870029 | validation: 0.1403496295576726]
	TIME [epoch: 13 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16269073919445942		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.16269073919445942 | validation: 0.12581511375121188]
	TIME [epoch: 13 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675257724266585		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.14675257724266585 | validation: 0.13119237302239856]
	TIME [epoch: 13 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16539067386904957		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.16539067386904957 | validation: 0.14609005999317326]
	TIME [epoch: 13 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19054962697346886		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.19054962697346886 | validation: 0.13196137877039682]
	TIME [epoch: 13 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14477280387619504		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.14477280387619504 | validation: 0.1312415676859791]
	TIME [epoch: 13 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13795858864058172		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.13795858864058172 | validation: 0.14002183852412242]
	TIME [epoch: 12.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446357747988295		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.1446357747988295 | validation: 0.111719955164855]
	TIME [epoch: 12.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14178327753972983		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.14178327753972983 | validation: 0.14048896319988255]
	TIME [epoch: 13 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1737941910663195		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.1737941910663195 | validation: 0.22929420845624765]
	TIME [epoch: 12.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16773456003641254		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.16773456003641254 | validation: 0.14161332536579363]
	TIME [epoch: 12.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522357368123058		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.1522357368123058 | validation: 0.1333427804969056]
	TIME [epoch: 12.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088613690001174		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.15088613690001174 | validation: 0.13941283773038157]
	TIME [epoch: 13 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588729259438975		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.1588729259438975 | validation: 0.16616218326920074]
	TIME [epoch: 12.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158130569628017		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.158130569628017 | validation: 0.15840905495681099]
	TIME [epoch: 12.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800831500936356		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.16800831500936356 | validation: 0.14527452962338078]
	TIME [epoch: 13 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15903528424324198		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.15903528424324198 | validation: 0.1579910076702537]
	TIME [epoch: 12.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18985309185413718		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.18985309185413718 | validation: 0.1340810458177219]
	TIME [epoch: 12.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15771733380026004		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.15771733380026004 | validation: 0.12442861799260033]
	TIME [epoch: 13 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329717457364328		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1329717457364328 | validation: 0.12690457995096643]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713278648486066		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.13713278648486066 | validation: 0.11322914339246244]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16286113326813106		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.16286113326813106 | validation: 0.16503095807191642]
	TIME [epoch: 13 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692372949848877		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.1692372949848877 | validation: 0.13006980919169564]
	TIME [epoch: 13 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139951416029883		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.139951416029883 | validation: 0.11918934493398683]
	TIME [epoch: 13 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558076835799329		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1558076835799329 | validation: 0.14306995224361338]
	TIME [epoch: 13 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16343940553185426		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.16343940553185426 | validation: 0.15372919874209576]
	TIME [epoch: 13 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808401471812898		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.1808401471812898 | validation: 0.2303746801028744]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19444463975822052		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.19444463975822052 | validation: 0.16010866494124287]
	TIME [epoch: 13 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14733183633395272		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.14733183633395272 | validation: 0.1277386493908395]
	TIME [epoch: 13 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14003231842664882		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.14003231842664882 | validation: 0.13332079799463625]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520375539621455		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.1520375539621455 | validation: 0.13712585336769728]
	TIME [epoch: 13 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987761117964803		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.13987761117964803 | validation: 0.11634009160702354]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721809298942164		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.13721809298942164 | validation: 0.12713805339167045]
	TIME [epoch: 13 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526885563032111		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.1526885563032111 | validation: 0.17281417571819532]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555880020028026		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.1555880020028026 | validation: 0.14279788915036318]
	TIME [epoch: 13 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647463029246634		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1647463029246634 | validation: 0.1403041062286621]
	TIME [epoch: 13 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322296763601087		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.15322296763601087 | validation: 0.12322958080172657]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360134676659202		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1360134676659202 | validation: 0.13733465373460121]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16570488700559965		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.16570488700559965 | validation: 0.11399504011785791]
	TIME [epoch: 13 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13367323198760686		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.13367323198760686 | validation: 0.10273307082819885]
	TIME [epoch: 13 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13015125292268867		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.13015125292268867 | validation: 0.10671584413576904]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044816270924303		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.13044816270924303 | validation: 0.1129182748651195]
	TIME [epoch: 13 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587277563762368		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.1587277563762368 | validation: 0.17666993060827152]
	TIME [epoch: 13 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475555847042718		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.14475555847042718 | validation: 0.12435605414806744]
	TIME [epoch: 13 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13973909498390144		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.13973909498390144 | validation: 0.14198471429425427]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239777686603966		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.14239777686603966 | validation: 0.13111847259009574]
	TIME [epoch: 13 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490460198255635		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.13490460198255635 | validation: 0.10615984869328998]
	TIME [epoch: 13 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564246959102544		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.1564246959102544 | validation: 0.1599991924838056]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452835134418558		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.1452835134418558 | validation: 0.11821419250783272]
	TIME [epoch: 13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12774359642048425		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.12774359642048425 | validation: 0.12712198291177157]
	TIME [epoch: 13 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112031389478235		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.13112031389478235 | validation: 0.12819524482209527]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136959277087577		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.136959277087577 | validation: 0.12669201966634835]
	TIME [epoch: 13 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13482341265947712		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.13482341265947712 | validation: 0.14340936802180304]
	TIME [epoch: 12.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486167666801854		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.1486167666801854 | validation: 0.11238745120522252]
	TIME [epoch: 12.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15591962110788726		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.15591962110788726 | validation: 0.18214109273101117]
	TIME [epoch: 13 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15874471021883177		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.15874471021883177 | validation: 0.12598752327698556]
	TIME [epoch: 12.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367529835542236		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1367529835542236 | validation: 0.11561914249852594]
	TIME [epoch: 12.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14372244738260012		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.14372244738260012 | validation: 0.10996222804280129]
	TIME [epoch: 12.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15573721536328514		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.15573721536328514 | validation: 0.10883136029955173]
	TIME [epoch: 13 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14133745983005658		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.14133745983005658 | validation: 0.11262705026871953]
	TIME [epoch: 12.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13881766263018777		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.13881766263018777 | validation: 0.12399133276994008]
	TIME [epoch: 12.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13309670006546728		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.13309670006546728 | validation: 0.1172548426882695]
	TIME [epoch: 13 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883244658115506		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.12883244658115506 | validation: 0.12998812261451367]
	TIME [epoch: 13 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363680547115324		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1363680547115324 | validation: 0.10492011964341]
	TIME [epoch: 13 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317686457032568		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.13317686457032568 | validation: 0.10266377549595564]
	TIME [epoch: 13 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859507911127356		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.13859507911127356 | validation: 0.1194666987600358]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12943817692163676		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.12943817692163676 | validation: 0.11846061102381387]
	TIME [epoch: 13 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13092544734283657		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.13092544734283657 | validation: 0.10220180267919755]
	TIME [epoch: 13 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13864102257896452		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.13864102257896452 | validation: 0.12733178366639153]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452405450349612		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.1452405450349612 | validation: 0.12918511438675068]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365388701196616		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.14365388701196616 | validation: 0.12774561183822403]
	TIME [epoch: 13 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458263455045466		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.13458263455045466 | validation: 0.1155318787650505]
	TIME [epoch: 13 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276309213773967		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.1276309213773967 | validation: 0.11675488013807915]
	TIME [epoch: 13 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13679678497753628		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.13679678497753628 | validation: 0.11842378379999165]
	TIME [epoch: 13 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424588029394764		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.1424588029394764 | validation: 0.13531839798335432]
	TIME [epoch: 13 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460410594518931		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.1460410594518931 | validation: 0.1503747164375097]
	TIME [epoch: 13 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405913056255037		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1405913056255037 | validation: 0.13504897978697666]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15612811006282395		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.15612811006282395 | validation: 0.12549777796884556]
	TIME [epoch: 13 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15473894799399898		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.15473894799399898 | validation: 0.15038952872000005]
	TIME [epoch: 13 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15033087865617348		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.15033087865617348 | validation: 0.12188851744286185]
	TIME [epoch: 13 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785189660197612		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.14785189660197612 | validation: 0.12138734979896423]
	TIME [epoch: 13 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14507451829477086		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.14507451829477086 | validation: 0.10864813295431912]
	TIME [epoch: 13 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828774534164164		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.12828774534164164 | validation: 0.11508430403405459]
	TIME [epoch: 13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522413906369351		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1522413906369351 | validation: 0.12647134789546194]
	TIME [epoch: 13 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13936200825256878		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.13936200825256878 | validation: 0.10819102095505306]
	TIME [epoch: 13 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809084433868873		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.12809084433868873 | validation: 0.10706998195658757]
	TIME [epoch: 13 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624154070478056		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.13624154070478056 | validation: 0.11554637873812496]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13526275362542595		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.13526275362542595 | validation: 0.10609548545381593]
	TIME [epoch: 13 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878157872178558		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.12878157872178558 | validation: 0.1409772262840187]
	TIME [epoch: 13 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15586434458514065		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.15586434458514065 | validation: 0.12379388248138085]
	TIME [epoch: 13 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378609452191284		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.13378609452191284 | validation: 0.11840338844012642]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986800108123178		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.12986800108123178 | validation: 0.09787306272885372]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1121.pth
	Model improved!!!
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278811824634828		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.1278811824634828 | validation: 0.09997326384373204]
	TIME [epoch: 12.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284460586391597		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.1284460586391597 | validation: 0.14903441875034865]
	TIME [epoch: 12.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13589292357929317		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.13589292357929317 | validation: 0.11503362386146031]
	TIME [epoch: 13.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14327781859651706		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.14327781859651706 | validation: 0.1081358690160586]
	TIME [epoch: 13 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15007527414224542		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.15007527414224542 | validation: 0.1422446705526499]
	TIME [epoch: 13 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13341300646084514		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.13341300646084514 | validation: 0.10230888556456329]
	TIME [epoch: 13 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267941228154115		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.13267941228154115 | validation: 0.12946538808570385]
	TIME [epoch: 13 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324947542018447		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.1324947542018447 | validation: 0.12423512253946761]
	TIME [epoch: 13 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13308233223514115		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.13308233223514115 | validation: 0.16710233931190466]
	TIME [epoch: 13 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17545875378750392		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.17545875378750392 | validation: 0.13837014841273124]
	TIME [epoch: 13 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493856374076364		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.1493856374076364 | validation: 0.11777200242169097]
	TIME [epoch: 13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14207722540053083		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.14207722540053083 | validation: 0.11363689854125149]
	TIME [epoch: 13 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929022991345102		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.12929022991345102 | validation: 0.10389307128358034]
	TIME [epoch: 13 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444686236689158		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.12444686236689158 | validation: 0.12198199243204648]
	TIME [epoch: 13 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13943028187524759		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.13943028187524759 | validation: 0.11184963847321441]
	TIME [epoch: 13 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402557761573464		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1402557761573464 | validation: 0.12421858349023429]
	TIME [epoch: 13 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13352635477924119		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.13352635477924119 | validation: 0.142215487842475]
	TIME [epoch: 13 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848147982164913		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.13848147982164913 | validation: 0.13226835681700239]
	TIME [epoch: 13 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15262678454847423		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.15262678454847423 | validation: 0.11804735054218274]
	TIME [epoch: 13 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13072304210631217		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.13072304210631217 | validation: 0.10959380144683559]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386608229291365		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.1386608229291365 | validation: 0.14701368252962202]
	TIME [epoch: 13 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13017746643757128		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.13017746643757128 | validation: 0.10792257591940466]
	TIME [epoch: 13 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12530725695870776		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.12530725695870776 | validation: 0.11437830902338625]
	TIME [epoch: 13 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279461609464746		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.1279461609464746 | validation: 0.11112870147094636]
	TIME [epoch: 13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13043077759836408		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.13043077759836408 | validation: 0.11770913420559868]
	TIME [epoch: 13 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349048898273864		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.1349048898273864 | validation: 0.10621345201061502]
	TIME [epoch: 13 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770501562625093		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.13770501562625093 | validation: 0.10199305186816879]
	TIME [epoch: 13 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12601475559485042		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.12601475559485042 | validation: 0.10919915224249344]
	TIME [epoch: 13 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758570102716021		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.12758570102716021 | validation: 0.11872631555937112]
	TIME [epoch: 13 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164778527578538		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.12164778527578538 | validation: 0.11086588541477771]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12184645386068571		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.12184645386068571 | validation: 0.10671441992052148]
	TIME [epoch: 13 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282783894365397		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.14282783894365397 | validation: 0.12308055220638828]
	TIME [epoch: 13 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255813809862123		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.1255813809862123 | validation: 0.11791259419226517]
	TIME [epoch: 13 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13354558305006364		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.13354558305006364 | validation: 0.12266071054095971]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778093247501976		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.12778093247501976 | validation: 0.13591161660280401]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13625715041212874		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.13625715041212874 | validation: 0.126308563637587]
	TIME [epoch: 13 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530737353159638		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.1530737353159638 | validation: 0.12713887405680574]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564549441885276		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.13564549441885276 | validation: 0.1069919170054474]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12753223655190568		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.12753223655190568 | validation: 0.1225961513933625]
	TIME [epoch: 13 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933218702513688		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.12933218702513688 | validation: 0.11690288104160686]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137093762438025		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.137093762438025 | validation: 0.12727650099792454]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12602319038779045		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.12602319038779045 | validation: 0.10369051161408713]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295559220635527		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1295559220635527 | validation: 0.10382266399547085]
	TIME [epoch: 13 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372272936745105		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.1372272936745105 | validation: 0.10289400987266291]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576422625657865		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.12576422625657865 | validation: 0.09342300307414314]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1166.pth
	Model improved!!!
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308454692708482		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.1308454692708482 | validation: 0.11669411377698713]
	TIME [epoch: 13 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322028793087891		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.1322028793087891 | validation: 0.11060733972611463]
	TIME [epoch: 13 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14129299433676595		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.14129299433676595 | validation: 0.11112092403019207]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781082537947234		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.13781082537947234 | validation: 0.1266188467927232]
	TIME [epoch: 13 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14359526004267698		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.14359526004267698 | validation: 0.12294304219704122]
	TIME [epoch: 13 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13794213969080915		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.13794213969080915 | validation: 0.11275671789472032]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14134994889272762		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.14134994889272762 | validation: 0.1672377575740021]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17303044836017226		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.17303044836017226 | validation: 0.17269248374770305]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572212110176949		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.1572212110176949 | validation: 0.13577491297295127]
	TIME [epoch: 13 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157405942129588		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.13157405942129588 | validation: 0.10526787424058924]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427020378297413		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.12427020378297413 | validation: 0.09837969514605074]
	TIME [epoch: 13 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343933479915064		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.1343933479915064 | validation: 0.13308948464447026]
	TIME [epoch: 13 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13068822367999317		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.13068822367999317 | validation: 0.11139487121546358]
	TIME [epoch: 13 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13347419878030822		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.13347419878030822 | validation: 0.10585248878264537]
	TIME [epoch: 13 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1237975788112989		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.1237975788112989 | validation: 0.11859141694314417]
	TIME [epoch: 13 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286532265205241		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.1286532265205241 | validation: 0.10890989241192467]
	TIME [epoch: 13 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482981064974362		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.12482981064974362 | validation: 0.11124568108190877]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304809424962102		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.13304809424962102 | validation: 0.1334943418631662]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346006655293493		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.15346006655293493 | validation: 0.12404016365000196]
	TIME [epoch: 13 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091292741383087		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.13091292741383087 | validation: 0.09031908021891774]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1186.pth
	Model improved!!!
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13767038949879484		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.13767038949879484 | validation: 0.10567593600527979]
	TIME [epoch: 12.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542741090014448		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.1542741090014448 | validation: 0.10451962800667407]
	TIME [epoch: 12.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280936987954288		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.1280936987954288 | validation: 0.08713972890293988]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1189.pth
	Model improved!!!
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252546588949237		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.12252546588949237 | validation: 0.12946125943018477]
	TIME [epoch: 12.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14834738041165801		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.14834738041165801 | validation: 0.11281919925403645]
	TIME [epoch: 12.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13065180139801316		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.13065180139801316 | validation: 0.1103400671482453]
	TIME [epoch: 12.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13236946967705307		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.13236946967705307 | validation: 0.1263565858254205]
	TIME [epoch: 13 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572238570149817		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.1572238570149817 | validation: 0.16384009102698768]
	TIME [epoch: 12.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16610168464443162		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.16610168464443162 | validation: 0.14565623412128947]
	TIME [epoch: 12.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13832987638013727		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.13832987638013727 | validation: 0.1287121250961597]
	TIME [epoch: 13 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704671962140413		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.12704671962140413 | validation: 0.11008935512047739]
	TIME [epoch: 13 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13142765018584407		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.13142765018584407 | validation: 0.11978546622999219]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685785506193775		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.12685785506193775 | validation: 0.11184203881825708]
	TIME [epoch: 13 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13445739159873996		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.13445739159873996 | validation: 0.1251679876071786]
	TIME [epoch: 13 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429408247172512		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.1429408247172512 | validation: 0.11760215859704876]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109302396338205		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.14109302396338205 | validation: 0.11976278185987277]
	TIME [epoch: 13 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13438036750237314		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.13438036750237314 | validation: 0.11286674575257495]
	TIME [epoch: 13 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13505013802370963		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.13505013802370963 | validation: 0.10747992721489323]
	TIME [epoch: 13 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048719383559135		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.13048719383559135 | validation: 0.10294252007972872]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243791940999034		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.1243791940999034 | validation: 0.12281953147538417]
	TIME [epoch: 13 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12393713234577428		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.12393713234577428 | validation: 0.10566755537214255]
	TIME [epoch: 13 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12560914511969906		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.12560914511969906 | validation: 0.1064150334940383]
	TIME [epoch: 13 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389953729112493		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.12389953729112493 | validation: 0.10384517796209868]
	TIME [epoch: 13 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268171171462723		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.1268171171462723 | validation: 0.0876253692821091]
	TIME [epoch: 13 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333556388120397		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.1333556388120397 | validation: 0.09593366184353003]
	TIME [epoch: 13 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462841258788002		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.12462841258788002 | validation: 0.10230517235219001]
	TIME [epoch: 13 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13235239466006143		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.13235239466006143 | validation: 0.12683285933995397]
	TIME [epoch: 13 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448889082686225		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1448889082686225 | validation: 0.11177541120482117]
	TIME [epoch: 13 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13259022885438582		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.13259022885438582 | validation: 0.12847626782892912]
	TIME [epoch: 13 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14159995573508066		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.14159995573508066 | validation: 0.0887504887367588]
	TIME [epoch: 13 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283595886750734		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.1283595886750734 | validation: 0.11123089515203315]
	TIME [epoch: 13 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882175918329664		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.12882175918329664 | validation: 0.10401712731009326]
	TIME [epoch: 13 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12256762738573193		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.12256762738573193 | validation: 0.11581353360095914]
	TIME [epoch: 13 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264521654848206		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.1264521654848206 | validation: 0.11190952591861437]
	TIME [epoch: 13 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12565865903594417		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.12565865903594417 | validation: 0.12138045455992365]
	TIME [epoch: 12.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129174186972427		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.129174186972427 | validation: 0.10994180953518029]
	TIME [epoch: 13 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13224900269513204		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.13224900269513204 | validation: 0.12170255696718521]
	TIME [epoch: 13 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944255073705346		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.12944255073705346 | validation: 0.1227343407503133]
	TIME [epoch: 13 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998197398925266		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.13998197398925266 | validation: 0.11934700642027439]
	TIME [epoch: 13 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007211340315344		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.13007211340315344 | validation: 0.12700971484622586]
	TIME [epoch: 13 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693020272282982		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.12693020272282982 | validation: 0.1038591530120571]
	TIME [epoch: 13 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508552887136343		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.12508552887136343 | validation: 0.12417939527755036]
	TIME [epoch: 13 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201104278454402		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.1201104278454402 | validation: 0.12711944906905567]
	TIME [epoch: 13 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332741786314549		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.1332741786314549 | validation: 0.10560688743682767]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281822577188042		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.12281822577188042 | validation: 0.10753680461058332]
	TIME [epoch: 13 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371072134306537		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.1371072134306537 | validation: 0.13403525130662744]
	TIME [epoch: 13 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13611581474916942		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.13611581474916942 | validation: 0.1377323765874976]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147969461433159		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.147969461433159 | validation: 0.12465756860106446]
	TIME [epoch: 13 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379709758705106		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.1379709758705106 | validation: 0.11429452885040016]
	TIME [epoch: 13 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12790722263373133		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.12790722263373133 | validation: 0.10978413640011002]
	TIME [epoch: 13 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12791814569492385		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.12791814569492385 | validation: 0.10612802094804198]
	TIME [epoch: 13 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042951674269349		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.13042951674269349 | validation: 0.11084099470977192]
	TIME [epoch: 13 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234681528577288		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.12234681528577288 | validation: 0.13147672703456045]
	TIME [epoch: 13 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12319464810987561		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.12319464810987561 | validation: 0.13009212122296682]
	TIME [epoch: 13 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13767084663214518		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.13767084663214518 | validation: 0.13601972406229923]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14130508395604074		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.14130508395604074 | validation: 0.12061588802932287]
	TIME [epoch: 13 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985639608391772		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.12985639608391772 | validation: 0.12287662213711048]
	TIME [epoch: 13 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13385532561827573		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.13385532561827573 | validation: 0.11857571923563268]
	TIME [epoch: 12.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14358027683509458		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.14358027683509458 | validation: 0.1459875105375876]
	TIME [epoch: 13 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460997254439947		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.1460997254439947 | validation: 0.1122131191815306]
	TIME [epoch: 13 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081651583567944		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.13081651583567944 | validation: 0.10382525465209273]
	TIME [epoch: 13 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12680962268118062		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.12680962268118062 | validation: 0.11234781392652324]
	TIME [epoch: 13 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12770604719740702		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.12770604719740702 | validation: 0.09213836413757548]
	TIME [epoch: 13 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12032707092766512		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.12032707092766512 | validation: 0.10309145155246291]
	TIME [epoch: 13 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291513943879434		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.1291513943879434 | validation: 0.10664300884464176]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12507764615331926		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.12507764615331926 | validation: 0.10985564645542621]
	TIME [epoch: 13 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367919239788173		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.1367919239788173 | validation: 0.11001133670874737]
	TIME [epoch: 13 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870406901784232		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.12870406901784232 | validation: 0.11343411037736295]
	TIME [epoch: 13 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13139871092629873		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.13139871092629873 | validation: 0.10192721648719476]
	TIME [epoch: 13 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12315304939172042		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.12315304939172042 | validation: 0.10072345438705876]
	TIME [epoch: 13 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272200097404163		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.1272200097404163 | validation: 0.10887983798766553]
	TIME [epoch: 13 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13347052319605102		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.13347052319605102 | validation: 0.11234033865802118]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12744452401017534		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.12744452401017534 | validation: 0.12508695554547827]
	TIME [epoch: 13 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633046271756532		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.12633046271756532 | validation: 0.12198854374507004]
	TIME [epoch: 13 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12542313580703593		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.12542313580703593 | validation: 0.12369792341337717]
	TIME [epoch: 13 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259318659711982		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.12259318659711982 | validation: 0.1278075505654041]
	TIME [epoch: 13 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383113680116363		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.1383113680116363 | validation: 0.12370845334530776]
	TIME [epoch: 13 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236971667082854		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.1236971667082854 | validation: 0.09916678911479637]
	TIME [epoch: 13 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917232962972077		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.11917232962972077 | validation: 0.0950252852313183]
	TIME [epoch: 13 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141426693332932		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.12141426693332932 | validation: 0.10853941120929865]
	TIME [epoch: 12.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438826976862828		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1438826976862828 | validation: 0.12167192516728793]
	TIME [epoch: 13 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13895524938881296		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.13895524938881296 | validation: 0.10783047464301207]
	TIME [epoch: 13 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12017355531169271		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.12017355531169271 | validation: 0.10524356370963595]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11576745065288532		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.11576745065288532 | validation: 0.10186207863862937]
	TIME [epoch: 12.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423738068660837		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.1423738068660837 | validation: 0.11676375797156872]
	TIME [epoch: 13 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15370270926256419		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.15370270926256419 | validation: 0.10774748953634307]
	TIME [epoch: 13 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849872034968918		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.11849872034968918 | validation: 0.10929799098230905]
	TIME [epoch: 13 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11720229059379955		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.11720229059379955 | validation: 0.10392703863009156]
	TIME [epoch: 13 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366623864963152		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.11366623864963152 | validation: 0.10469566448360709]
	TIME [epoch: 13 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298478268983838		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.12298478268983838 | validation: 0.11223015890351393]
	TIME [epoch: 12.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178877548021706		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.12178877548021706 | validation: 0.1125968761634292]
	TIME [epoch: 12.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12269040748399312		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.12269040748399312 | validation: 0.11118341135274658]
	TIME [epoch: 13 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12564553523776917		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.12564553523776917 | validation: 0.12168747519681272]
	TIME [epoch: 13 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12635968343655532		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.12635968343655532 | validation: 0.1247763142460724]
	TIME [epoch: 13 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13189937132756102		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.13189937132756102 | validation: 0.1404764879722025]
	TIME [epoch: 13 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13543842730479552		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.13543842730479552 | validation: 0.10068942854916696]
	TIME [epoch: 13 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12282316959787234		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.12282316959787234 | validation: 0.10177643568911393]
	TIME [epoch: 13 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311006587654716		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.12311006587654716 | validation: 0.10532122058321211]
	TIME [epoch: 13 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208266268615425		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.1208266268615425 | validation: 0.1027570973073648]
	TIME [epoch: 13 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11514098261332076		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.11514098261332076 | validation: 0.08562507586321409]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1286.pth
	Model improved!!!
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970248187106783		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.11970248187106783 | validation: 0.1077787324534184]
	TIME [epoch: 13 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11943636951591106		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.11943636951591106 | validation: 0.10251006064324145]
	TIME [epoch: 13 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12033648652046944		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.12033648652046944 | validation: 0.11351506370858333]
	TIME [epoch: 13 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250982972084546		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.1250982972084546 | validation: 0.10853235130368959]
	TIME [epoch: 13 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12302483322782269		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.12302483322782269 | validation: 0.1139087863907115]
	TIME [epoch: 13 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.117756444385608		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.117756444385608 | validation: 0.09932421341150946]
	TIME [epoch: 13 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709764150275176		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.11709764150275176 | validation: 0.09581701284848443]
	TIME [epoch: 12.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535916721855656		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.11535916721855656 | validation: 0.11863960127899831]
	TIME [epoch: 13 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737177767319		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.14737177767319 | validation: 0.1679927240573153]
	TIME [epoch: 13 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15415981968953008		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.15415981968953008 | validation: 0.11343453051821285]
	TIME [epoch: 13 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12416148144693225		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.12416148144693225 | validation: 0.10341287794147064]
	TIME [epoch: 13 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12245366772841418		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.12245366772841418 | validation: 0.0961945938872574]
	TIME [epoch: 13 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294299044278114		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.1294299044278114 | validation: 0.08965194783585982]
	TIME [epoch: 13 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12035215248561033		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.12035215248561033 | validation: 0.10701126131302417]
	TIME [epoch: 13 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296973202002846		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.12296973202002846 | validation: 0.10738486928703146]
	TIME [epoch: 13 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12187894365657945		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.12187894365657945 | validation: 0.09818823088646457]
	TIME [epoch: 13 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949452659240516		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.11949452659240516 | validation: 0.12438337600332254]
	TIME [epoch: 13 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12393482996816449		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.12393482996816449 | validation: 0.1011207141446597]
	TIME [epoch: 13 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11784411889579219		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.11784411889579219 | validation: 0.09206391235530474]
	TIME [epoch: 13 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849505455090575		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.11849505455090575 | validation: 0.09157935269990272]
	TIME [epoch: 13 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186321988979664		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.1186321988979664 | validation: 0.09385455696902463]
	TIME [epoch: 13 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12230902797578536		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.12230902797578536 | validation: 0.10270403385239227]
	TIME [epoch: 13 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283934844480171		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.1283934844480171 | validation: 0.09328701702438537]
	TIME [epoch: 13 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851781543213562		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.13851781543213562 | validation: 0.10110493979324167]
	TIME [epoch: 13 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13314031537135224		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.13314031537135224 | validation: 0.09807161773056948]
	TIME [epoch: 13 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010653553517829		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.13010653553517829 | validation: 0.10604777455738176]
	TIME [epoch: 13 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289183023817368		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.1289183023817368 | validation: 0.11583881094833988]
	TIME [epoch: 13 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13258692193923088		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.13258692193923088 | validation: 0.11426976715109115]
	TIME [epoch: 13 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276572991517811		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.1276572991517811 | validation: 0.1086299929578954]
	TIME [epoch: 13 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12348379099184736		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.12348379099184736 | validation: 0.112256290124163]
	TIME [epoch: 13 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169343142072767		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.1169343142072767 | validation: 0.12481263149709772]
	TIME [epoch: 13 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115235006433835		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.14115235006433835 | validation: 0.15919083867663472]
	TIME [epoch: 13 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175162368947645		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.15175162368947645 | validation: 0.13629400155162258]
	TIME [epoch: 13 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13128937615329003		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.13128937615329003 | validation: 0.10919894271870736]
	TIME [epoch: 13 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299767370815773		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.12299767370815773 | validation: 0.11291327976357865]
	TIME [epoch: 13 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12112990381167793		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.12112990381167793 | validation: 0.11274187800480963]
	TIME [epoch: 13 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793984145129533		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.12793984145129533 | validation: 0.10473255717613349]
	TIME [epoch: 12.9 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1175902635016493		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.1175902635016493 | validation: 0.0938655833098263]
	TIME [epoch: 13 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11898961237922766		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.11898961237922766 | validation: 0.0983506653439865]
	TIME [epoch: 13 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154725391555755		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.12154725391555755 | validation: 0.10664267235765719]
	TIME [epoch: 13 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861087700226147		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.11861087700226147 | validation: 0.09859427230114236]
	TIME [epoch: 13 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11304058492155093		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.11304058492155093 | validation: 0.11684167520146495]
	TIME [epoch: 13 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436602890580402		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.12436602890580402 | validation: 0.12006404712104195]
	TIME [epoch: 13 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12616137362152594		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.12616137362152594 | validation: 0.0986898883294775]
	TIME [epoch: 13 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11937682833027446		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.11937682833027446 | validation: 0.11180767360482854]
	TIME [epoch: 13 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277481432504029		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.1277481432504029 | validation: 0.10203804880034785]
	TIME [epoch: 13 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162466104181625		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.1162466104181625 | validation: 0.10633235567431842]
	TIME [epoch: 13 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11800255473848413		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.11800255473848413 | validation: 0.10393584041061975]
	TIME [epoch: 13 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422323693525084		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.12422323693525084 | validation: 0.11494945094713976]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127234549745287		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.13127234549745287 | validation: 0.1209806371307267]
	TIME [epoch: 13 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12781533431713146		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.12781533431713146 | validation: 0.1006553789160753]
	TIME [epoch: 13 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1237617452491047		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.1237617452491047 | validation: 0.08707041071072848]
	TIME [epoch: 13 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331720077415202		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.12331720077415202 | validation: 0.0945862435562679]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374897773975814		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.11374897773975814 | validation: 0.08690021848062703]
	TIME [epoch: 13 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11471436887299145		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.11471436887299145 | validation: 0.09617081321233795]
	TIME [epoch: 13 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12653873482649702		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.12653873482649702 | validation: 0.09743948338806538]
	TIME [epoch: 13 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12357004411708036		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.12357004411708036 | validation: 0.10046810552463149]
	TIME [epoch: 13 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262687998890961		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.1262687998890961 | validation: 0.09391397078155019]
	TIME [epoch: 13 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807802943355073		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.12807802943355073 | validation: 0.10288279770264289]
	TIME [epoch: 13 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862504457969332		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.13862504457969332 | validation: 0.1277521505709583]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13937419757323846		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.13937419757323846 | validation: 0.10670413541864238]
	TIME [epoch: 13 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279196793608311		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.1279196793608311 | validation: 0.10383056643522107]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12145775313401283		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.12145775313401283 | validation: 0.11867965520584797]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849471018068702		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.11849471018068702 | validation: 0.10754346830948107]
	TIME [epoch: 13 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930700648925845		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.11930700648925845 | validation: 0.08957083450066312]
	TIME [epoch: 13 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757268802731435		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.11757268802731435 | validation: 0.10712723574209891]
	TIME [epoch: 12.9 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12098531042018795		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.12098531042018795 | validation: 0.09822764513121751]
	TIME [epoch: 13 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974566779689459		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.11974566779689459 | validation: 0.09844475678211684]
	TIME [epoch: 13 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11919132953340417		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.11919132953340417 | validation: 0.10469074338720664]
	TIME [epoch: 13 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12189490670989707		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.12189490670989707 | validation: 0.09240467160138756]
	TIME [epoch: 13 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11411153689872863		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.11411153689872863 | validation: 0.09831726656417032]
	TIME [epoch: 13 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251291825028163		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.12251291825028163 | validation: 0.10050734018573579]
	TIME [epoch: 13 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947515003753378		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.11947515003753378 | validation: 0.10373962003755044]
	TIME [epoch: 13 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12742377380836736		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.12742377380836736 | validation: 0.12038814393271627]
	TIME [epoch: 13 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563658429774295		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.13563658429774295 | validation: 0.14291311764262976]
	TIME [epoch: 13 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14129705104328644		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.14129705104328644 | validation: 0.14275099700945096]
	TIME [epoch: 13 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13509314935316616		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.13509314935316616 | validation: 0.1125477961887151]
	TIME [epoch: 13 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13587472400639122		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.13587472400639122 | validation: 0.15092980609530549]
	TIME [epoch: 13 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354805181708347		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.1354805181708347 | validation: 0.11310553761956857]
	TIME [epoch: 13 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11996996763502027		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.11996996763502027 | validation: 0.08737228119355699]
	TIME [epoch: 13 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775529249150477		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.12775529249150477 | validation: 0.09739552316582913]
	TIME [epoch: 13 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939479400187442		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.11939479400187442 | validation: 0.09401061210087563]
	TIME [epoch: 13 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228881731703412		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.12228881731703412 | validation: 0.1036971908554321]
	TIME [epoch: 13 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180230676490389		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.12180230676490389 | validation: 0.09398503616103822]
	TIME [epoch: 13 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842927416798732		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.11842927416798732 | validation: 0.09482336467894698]
	TIME [epoch: 13 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262628080077856		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.1262628080077856 | validation: 0.11407330571830601]
	TIME [epoch: 13 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243888681216769		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.1243888681216769 | validation: 0.12755789530669728]
	TIME [epoch: 13 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13897166664616348		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.13897166664616348 | validation: 0.11674449012885521]
	TIME [epoch: 13 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690095397820302		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.11690095397820302 | validation: 0.09901131918642105]
	TIME [epoch: 13 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12175024890433278		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.12175024890433278 | validation: 0.10130518274604683]
	TIME [epoch: 13 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656523524233418		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.12656523524233418 | validation: 0.11499655579117514]
	TIME [epoch: 13 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12886060985437134		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.12886060985437134 | validation: 0.14055541445712255]
	TIME [epoch: 13 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213279424504804		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.13213279424504804 | validation: 0.1090100906972377]
	TIME [epoch: 13 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11361639899347786		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.11361639899347786 | validation: 0.10646912784891586]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11453993686253122		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.11453993686253122 | validation: 0.09932485829767015]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11608993061537587		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.11608993061537587 | validation: 0.10482234917661742]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503215678826266		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.12503215678826266 | validation: 0.10649002857198012]
	TIME [epoch: 13 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089903361176262		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.12089903361176262 | validation: 0.1126145070073422]
	TIME [epoch: 13 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304471943598865		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.1304471943598865 | validation: 0.11793882243701767]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471423311352725		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.12471423311352725 | validation: 0.11129432059863888]
	TIME [epoch: 13 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12044310896216398		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.12044310896216398 | validation: 0.10188603525147485]
	TIME [epoch: 13 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215592210857043		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.12215592210857043 | validation: 0.10620522580615947]
	TIME [epoch: 12.9 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222891520931322		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.1222891520931322 | validation: 0.11263012982155945]
	TIME [epoch: 12.9 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12485102357993028		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.12485102357993028 | validation: 0.11267460089725852]
	TIME [epoch: 13 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310743941197613		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.12310743941197613 | validation: 0.10433583124850145]
	TIME [epoch: 12.9 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11864291142974004		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.11864291142974004 | validation: 0.11858559000555893]
	TIME [epoch: 12.9 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12175178977178358		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.12175178977178358 | validation: 0.09528596446834076]
	TIME [epoch: 13 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1150576998990788		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1150576998990788 | validation: 0.09364765803290485]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11618584343607335		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.11618584343607335 | validation: 0.09867745641505636]
	TIME [epoch: 13 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225629614456108		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.1225629614456108 | validation: 0.10175334321231035]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785654041181994		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.11785654041181994 | validation: 0.10471260470135964]
	TIME [epoch: 13 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679697018285233		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.11679697018285233 | validation: 0.10118469652760691]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709951139030171		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.11709951139030171 | validation: 0.09913420532818366]
	TIME [epoch: 13 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793975591698955		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.11793975591698955 | validation: 0.08628712851541474]
	TIME [epoch: 13 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354910716337901		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.11354910716337901 | validation: 0.1014874683456865]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331674170522211		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.12331674170522211 | validation: 0.10483938141317901]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236048000052382		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.1236048000052382 | validation: 0.11335622252126402]
	TIME [epoch: 13 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063535935239379		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.12063535935239379 | validation: 0.10565102038277328]
	TIME [epoch: 13 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178223443923676		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.12178223443923676 | validation: 0.09693149699212349]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11599633721464336		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.11599633721464336 | validation: 0.08766312160721611]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810756942447766		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.11810756942447766 | validation: 0.10376019033926002]
	TIME [epoch: 13 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255044579939732		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.1255044579939732 | validation: 0.12440636383415274]
	TIME [epoch: 13 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12400549902960886		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.12400549902960886 | validation: 0.10867081495285319]
	TIME [epoch: 13 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12033811911038306		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.12033811911038306 | validation: 0.10854714641992606]
	TIME [epoch: 13 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12181214216706729		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.12181214216706729 | validation: 0.09820311267758434]
	TIME [epoch: 13 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11491326826178846		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.11491326826178846 | validation: 0.10282882478442541]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11653128820905076		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.11653128820905076 | validation: 0.11245457197352465]
	TIME [epoch: 13 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538616287782016		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.11538616287782016 | validation: 0.09590445305069002]
	TIME [epoch: 13 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747508745162893		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.11747508745162893 | validation: 0.11022370845395331]
	TIME [epoch: 12.9 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712804682690446		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.11712804682690446 | validation: 0.10219286705007061]
	TIME [epoch: 13 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116650625691894		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.12116650625691894 | validation: 0.11325060926820028]
	TIME [epoch: 13 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259993182756457		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.12259993182756457 | validation: 0.13072527208714485]
	TIME [epoch: 12.9 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12863142214281825		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.12863142214281825 | validation: 0.10250625244301538]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11404255912396047		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.11404255912396047 | validation: 0.10224278996523012]
	TIME [epoch: 12.9 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11761058591917137		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.11761058591917137 | validation: 0.09822862594181649]
	TIME [epoch: 12.9 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185395577121777		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.1185395577121777 | validation: 0.12140199355969673]
	TIME [epoch: 12.9 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12511950337993397		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.12511950337993397 | validation: 0.1056519365138587]
	TIME [epoch: 13 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11867570154338122		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.11867570154338122 | validation: 0.09841646462421581]
	TIME [epoch: 12.9 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570789310082251		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.11570789310082251 | validation: 0.09442581483598214]
	TIME [epoch: 12.9 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11649309523942222		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.11649309523942222 | validation: 0.09156653217258681]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067123940029026		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.12067123940029026 | validation: 0.08695959782797953]
	TIME [epoch: 13 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724906798978608		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.12724906798978608 | validation: 0.09348410536330849]
	TIME [epoch: 13 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11372335044788993		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.11372335044788993 | validation: 0.09023902257069388]
	TIME [epoch: 13 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418800167285387		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.11418800167285387 | validation: 0.10673741921146529]
	TIME [epoch: 13 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11782781478408327		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.11782781478408327 | validation: 0.1160842707220202]
	TIME [epoch: 13 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974531970966411		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.11974531970966411 | validation: 0.1006383853013993]
	TIME [epoch: 13 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11689287457727326		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.11689287457727326 | validation: 0.10198657139147312]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698229883685355		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.12698229883685355 | validation: 0.11110374704325357]
	TIME [epoch: 12.9 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597365441204855		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.12597365441204855 | validation: 0.11944736106731528]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543566742752943		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.12543566742752943 | validation: 0.1024155837614806]
	TIME [epoch: 13 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381853611788585		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.12381853611788585 | validation: 0.09629659791979062]
	TIME [epoch: 13 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954243706754566		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.11954243706754566 | validation: 0.0885262555516058]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441718588715313		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.11441718588715313 | validation: 0.09053791445359366]
	TIME [epoch: 13 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501764184654138		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.11501764184654138 | validation: 0.08509630590935911]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1440.pth
	Model improved!!!
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11580760473770446		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.11580760473770446 | validation: 0.10270857878670014]
	TIME [epoch: 13 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287509491449924		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.1287509491449924 | validation: 0.10380846029888098]
	TIME [epoch: 13 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12582232132709767		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.12582232132709767 | validation: 0.08613990358140054]
	TIME [epoch: 13 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987973865968107		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.11987973865968107 | validation: 0.09525122671629052]
	TIME [epoch: 13 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11711917808701121		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.11711917808701121 | validation: 0.09961568447586797]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11343832085572603		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.11343832085572603 | validation: 0.0981541181149667]
	TIME [epoch: 13 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504364387066252		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.11504364387066252 | validation: 0.09954285841642073]
	TIME [epoch: 12.9 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015194669123767		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.12015194669123767 | validation: 0.09426445550050545]
	TIME [epoch: 13 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181492341388288		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.1181492341388288 | validation: 0.10794421995976056]
	TIME [epoch: 13 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127758951723406		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.1127758951723406 | validation: 0.09604588604485305]
	TIME [epoch: 13 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138902061121313		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.1138902061121313 | validation: 0.0967551315039772]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11565660794645259		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.11565660794645259 | validation: 0.09965287554288345]
	TIME [epoch: 13 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11389300664717628		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.11389300664717628 | validation: 0.09230225531260032]
	TIME [epoch: 13 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1165921466939818		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.1165921466939818 | validation: 0.1066684717338232]
	TIME [epoch: 13 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271258042288768		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.1271258042288768 | validation: 0.1095769042826259]
	TIME [epoch: 13 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259782773240453		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.1259782773240453 | validation: 0.10799844651462931]
	TIME [epoch: 13 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13307995498229214		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.13307995498229214 | validation: 0.11808885921144505]
	TIME [epoch: 13 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305683702796264		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.1305683702796264 | validation: 0.12576105847926874]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13362113173818269		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.13362113173818269 | validation: 0.11004782410000476]
	TIME [epoch: 13 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159802320583016		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.1159802320583016 | validation: 0.10173481514949391]
	TIME [epoch: 13 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11454397214727505		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.11454397214727505 | validation: 0.09401871077142439]
	TIME [epoch: 13 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11303925229506803		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.11303925229506803 | validation: 0.08441609311472249]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1462.pth
	Model improved!!!
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11754102940170887		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.11754102940170887 | validation: 0.0937170143261314]
	TIME [epoch: 13 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890476611223774		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.11890476611223774 | validation: 0.10448461041112551]
	TIME [epoch: 13 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11510416718736655		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.11510416718736655 | validation: 0.1128600803206076]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776188963572079		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.11776188963572079 | validation: 0.0974641896924642]
	TIME [epoch: 13 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421926864169132		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.11421926864169132 | validation: 0.09833132493879677]
	TIME [epoch: 13 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11325688695386757		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.11325688695386757 | validation: 0.10573214475664415]
	TIME [epoch: 13 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11463921087366968		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.11463921087366968 | validation: 0.10340167821928878]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001898207920172		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.12001898207920172 | validation: 0.10844664605663516]
	TIME [epoch: 12.9 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810100557478867		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.11810100557478867 | validation: 0.11633384660667663]
	TIME [epoch: 13 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11913986834295912		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.11913986834295912 | validation: 0.10877226336883675]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215607776358828		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.1215607776358828 | validation: 0.10253908369353638]
	TIME [epoch: 13 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11708859182642913		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.11708859182642913 | validation: 0.10167770756179487]
	TIME [epoch: 13 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11625299279342009		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.11625299279342009 | validation: 0.09316393018438213]
	TIME [epoch: 13 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114319325092413		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.114319325092413 | validation: 0.09807553939924869]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1155968094259323		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.1155968094259323 | validation: 0.09489709057381561]
	TIME [epoch: 12.9 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061143502501719		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.11061143502501719 | validation: 0.09938272419035729]
	TIME [epoch: 13 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11830481845017726		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.11830481845017726 | validation: 0.09359744318037164]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12011721729623076		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.12011721729623076 | validation: 0.10677497618747374]
	TIME [epoch: 12.9 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902895833518809		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.11902895833518809 | validation: 0.1156801516227049]
	TIME [epoch: 13 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527000146360326		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.12527000146360326 | validation: 0.10360007999004957]
	TIME [epoch: 13 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359269066238031		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.11359269066238031 | validation: 0.09757194294250099]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441192925966155		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.11441192925966155 | validation: 0.09943034591160146]
	TIME [epoch: 13 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11787671936370844		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.11787671936370844 | validation: 0.09480880521775205]
	TIME [epoch: 13 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11972136568774079		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.11972136568774079 | validation: 0.08967431487195068]
	TIME [epoch: 13 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489039558560364		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.12489039558560364 | validation: 0.08164249425226433]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1487.pth
	Model improved!!!
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790295744950302		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.11790295744950302 | validation: 0.09189463970274385]
	TIME [epoch: 13 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555395166521147		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.11555395166521147 | validation: 0.08345389856044413]
	TIME [epoch: 13 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11622018735699458		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.11622018735699458 | validation: 0.09081199405992806]
	TIME [epoch: 13 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195136216410523		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.11195136216410523 | validation: 0.09620393548469183]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162008492057628		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1162008492057628 | validation: 0.09848503797338083]
	TIME [epoch: 13 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907366793893339		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.10907366793893339 | validation: 0.08840329884067785]
	TIME [epoch: 13 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11659238297330478		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.11659238297330478 | validation: 0.09666173663734816]
	TIME [epoch: 13 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12314335048319403		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.12314335048319403 | validation: 0.10812243570851944]
	TIME [epoch: 13 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11761077526152497		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.11761077526152497 | validation: 0.10415199535070997]
	TIME [epoch: 13 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168863650279714		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.1168863650279714 | validation: 0.09550159228866807]
	TIME [epoch: 13 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231858905319703		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.11231858905319703 | validation: 0.09294330141882128]
	TIME [epoch: 13 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364633678594144		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.11364633678594144 | validation: 0.1128460283279409]
	TIME [epoch: 13 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596981185113342		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.11596981185113342 | validation: 0.08985383777436683]
	TIME [epoch: 13 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898587473829702		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.10898587473829702 | validation: 0.08811380253841966]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190882934442985		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.11190882934442985 | validation: 0.08495002828458496]
	TIME [epoch: 13 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10645994167925533		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.10645994167925533 | validation: 0.09554243497366503]
	TIME [epoch: 13 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116285197794642		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.1116285197794642 | validation: 0.10274480399079859]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11415655644596547		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.11415655644596547 | validation: 0.11103106651203443]
	TIME [epoch: 13 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827399197334276		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.11827399197334276 | validation: 0.10369931973242283]
	TIME [epoch: 13 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11353783506203549		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.11353783506203549 | validation: 0.1007492341888745]
	TIME [epoch: 13 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146346083693563		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.1146346083693563 | validation: 0.10701404061832281]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11698722001895193		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.11698722001895193 | validation: 0.0992119541198718]
	TIME [epoch: 13 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394427588436916		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.11394427588436916 | validation: 0.09773712539003875]
	TIME [epoch: 13 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333435620340834		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.11333435620340834 | validation: 0.12021465214283086]
	TIME [epoch: 13 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11972534961488032		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.11972534961488032 | validation: 0.10265302660317158]
	TIME [epoch: 13 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11182110225305317		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.11182110225305317 | validation: 0.10705607829033603]
	TIME [epoch: 13 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960376498011258		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.11960376498011258 | validation: 0.11519091823410954]
	TIME [epoch: 13 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185621787013279		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1185621787013279 | validation: 0.1029316362299943]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285407726070976		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.11285407726070976 | validation: 0.10037086935460028]
	TIME [epoch: 13 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11262989729887102		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.11262989729887102 | validation: 0.10240113071472201]
	TIME [epoch: 13 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273234452281207		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.11273234452281207 | validation: 0.0978037363209332]
	TIME [epoch: 13 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11563823977246292		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.11563823977246292 | validation: 0.10452858004766079]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1132711043112659		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.1132711043112659 | validation: 0.0948567277772122]
	TIME [epoch: 13 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098707392415966		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.11098707392415966 | validation: 0.10184907570888437]
	TIME [epoch: 13 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497491875159532		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.11497491875159532 | validation: 0.0999309464247511]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11599680940792924		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.11599680940792924 | validation: 0.10888620092497135]
	TIME [epoch: 13 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582769073385552		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.11582769073385552 | validation: 0.10527703628435563]
	TIME [epoch: 13 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11737689498310669		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.11737689498310669 | validation: 0.09333283509130987]
	TIME [epoch: 13 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550921718277239		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.11550921718277239 | validation: 0.11272373272591057]
	TIME [epoch: 13 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11382868749750888		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.11382868749750888 | validation: 0.09840144086332397]
	TIME [epoch: 13 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180343372498728		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.12180343372498728 | validation: 0.10258484136251998]
	TIME [epoch: 13 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237182761616966		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.12237182761616966 | validation: 0.11347450019552117]
	TIME [epoch: 13 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12528220314268823		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.12528220314268823 | validation: 0.09643118881834711]
	TIME [epoch: 13 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11991598736164036		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.11991598736164036 | validation: 0.10639273057666772]
	TIME [epoch: 13 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11563226765979477		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.11563226765979477 | validation: 0.10080847466474314]
	TIME [epoch: 13 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060298526989551		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.11060298526989551 | validation: 0.08884211989338749]
	TIME [epoch: 13 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448076465847866		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.11448076465847866 | validation: 0.09602479675311756]
	TIME [epoch: 13 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047917607761255		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.11047917607761255 | validation: 0.10431612894323741]
	TIME [epoch: 13 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11134897963787062		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.11134897963787062 | validation: 0.10932494595629175]
	TIME [epoch: 13 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980272032290429		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.11980272032290429 | validation: 0.12137025762442463]
	TIME [epoch: 13 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12008348427057765		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.12008348427057765 | validation: 0.09841723636025965]
	TIME [epoch: 13 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11798395941701956		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.11798395941701956 | validation: 0.09406172565940858]
	TIME [epoch: 13 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461039561405019		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.11461039561405019 | validation: 0.1036337906734641]
	TIME [epoch: 13 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11381772059006146		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.11381772059006146 | validation: 0.09571569741662966]
	TIME [epoch: 13 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12301111168285953		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.12301111168285953 | validation: 0.10840238212958916]
	TIME [epoch: 13 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227214604571024		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.1227214604571024 | validation: 0.10762719566655111]
	TIME [epoch: 13 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13246886364633548		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.13246886364633548 | validation: 0.12178156446222094]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14695056072685844		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.14695056072685844 | validation: 0.11534458354480094]
	TIME [epoch: 13 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622978934642926		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.13622978934642926 | validation: 0.09237294900069759]
	TIME [epoch: 13 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193021921651704		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.1193021921651704 | validation: 0.09759134550260724]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11388924156569111		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.11388924156569111 | validation: 0.09677271733544679]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341741369817925		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.11341741369817925 | validation: 0.0971828974438932]
	TIME [epoch: 13 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11309925243312595		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.11309925243312595 | validation: 0.09772954631203551]
	TIME [epoch: 13 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871141633055575		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.10871141633055575 | validation: 0.09209395927970893]
	TIME [epoch: 13 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11436128263761478		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.11436128263761478 | validation: 0.09094859588741912]
	TIME [epoch: 13 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073636747398535		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.1073636747398535 | validation: 0.10221745991597254]
	TIME [epoch: 13 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106917239343017		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.11106917239343017 | validation: 0.10594741844452585]
	TIME [epoch: 13 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975439416770195		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.10975439416770195 | validation: 0.09707767647299996]
	TIME [epoch: 13 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209038862545621		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.11209038862545621 | validation: 0.08988194986628775]
	TIME [epoch: 13 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11229042194938324		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.11229042194938324 | validation: 0.09335628615609849]
	TIME [epoch: 13 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197231174351738		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.11197231174351738 | validation: 0.09499715786787022]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207073436559917		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.1207073436559917 | validation: 0.09694998436865784]
	TIME [epoch: 13 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133811988183014		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.1133811988183014 | validation: 0.10508680285318174]
	TIME [epoch: 13 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756495790903583		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.11756495790903583 | validation: 0.09831231813038543]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11384877073141778		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.11384877073141778 | validation: 0.09292697258435823]
	TIME [epoch: 13 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014099869450902		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.11014099869450902 | validation: 0.0895624478938895]
	TIME [epoch: 13 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090417023305965		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.11090417023305965 | validation: 0.10070105063130398]
	TIME [epoch: 13 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11494372093363661		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.11494372093363661 | validation: 0.0859718674442932]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11145420561339466		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.11145420561339466 | validation: 0.09337942054726477]
	TIME [epoch: 13 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11531545111642294		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.11531545111642294 | validation: 0.09724135431625515]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1223150100047485		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.1223150100047485 | validation: 0.09276894933876684]
	TIME [epoch: 13 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110343234589118		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.11110343234589118 | validation: 0.09950542139715182]
	TIME [epoch: 13 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11449644704408249		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.11449644704408249 | validation: 0.0965930518328616]
	TIME [epoch: 13 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11517318286171957		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.11517318286171957 | validation: 0.09713958122922835]
	TIME [epoch: 13 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374052025695092		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.11374052025695092 | validation: 0.09439493469012188]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869485430443683		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.10869485430443683 | validation: 0.08757467558488585]
	TIME [epoch: 13 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11484526228443269		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.11484526228443269 | validation: 0.09119166033642465]
	TIME [epoch: 13 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11081848000426292		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.11081848000426292 | validation: 0.10022609411546522]
	TIME [epoch: 13 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11593135187466926		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.11593135187466926 | validation: 0.08677568127875157]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10776055078856064		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.10776055078856064 | validation: 0.09674320135677966]
	TIME [epoch: 13 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11442725229738765		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.11442725229738765 | validation: 0.0939383641822884]
	TIME [epoch: 13 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241026600194734		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.11241026600194734 | validation: 0.09798968080967406]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11666799977323625		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.11666799977323625 | validation: 0.09141599050090378]
	TIME [epoch: 13 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11647771059857905		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.11647771059857905 | validation: 0.08954642692199942]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335783452423598		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.11335783452423598 | validation: 0.08448148794734778]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11641740260118136		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.11641740260118136 | validation: 0.08067219699800608]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1583.pth
	Model improved!!!
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11559738998295505		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.11559738998295505 | validation: 0.09655610275385272]
	TIME [epoch: 12.9 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11765786154056919		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.11765786154056919 | validation: 0.09174165436775952]
	TIME [epoch: 12.9 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11445453712907935		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.11445453712907935 | validation: 0.08865826906425416]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11484619764772988		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.11484619764772988 | validation: 0.0957934275440225]
	TIME [epoch: 13 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257162073451558		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.11257162073451558 | validation: 0.08556547150723699]
	TIME [epoch: 13 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921315305511084		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.10921315305511084 | validation: 0.08858378451984088]
	TIME [epoch: 13 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117445613880936		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.11117445613880936 | validation: 0.09106712143919073]
	TIME [epoch: 13 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776452258999184		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.11776452258999184 | validation: 0.1077820663849833]
	TIME [epoch: 13 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446413397305252		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.11446413397305252 | validation: 0.09270798693836999]
	TIME [epoch: 13 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125434543428098		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.11125434543428098 | validation: 0.10052277987137387]
	TIME [epoch: 13 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206324987164526		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.11206324987164526 | validation: 0.094533116599352]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10842399808268163		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.10842399808268163 | validation: 0.08515059331895809]
	TIME [epoch: 13 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126625228927026		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.11126625228927026 | validation: 0.08303577322216059]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291655812248198		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.11291655812248198 | validation: 0.08980486360697464]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285294110589303		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.11285294110589303 | validation: 0.09783205489062517]
	TIME [epoch: 13 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11266886064721839		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.11266886064721839 | validation: 0.09692570114739216]
	TIME [epoch: 13 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110175278260019		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.1110175278260019 | validation: 0.09313856169889469]
	TIME [epoch: 13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1129635971857582		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.1129635971857582 | validation: 0.09521543552502318]
	TIME [epoch: 13 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131034438446342		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.1131034438446342 | validation: 0.09305746688953541]
	TIME [epoch: 13 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949905476446482		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.11949905476446482 | validation: 0.0926247565688041]
	TIME [epoch: 13 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612937137530763		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.11612937137530763 | validation: 0.08715780351964217]
	TIME [epoch: 13 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092417201508869		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1092417201508869 | validation: 0.08966066608123086]
	TIME [epoch: 13 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11323205067941133		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.11323205067941133 | validation: 0.09899964838718812]
	TIME [epoch: 13 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11127757803493014		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.11127757803493014 | validation: 0.10078660685141479]
	TIME [epoch: 13 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168827644090712		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.11168827644090712 | validation: 0.09920404200920593]
	TIME [epoch: 13 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900438604949014		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.10900438604949014 | validation: 0.10181628996005182]
	TIME [epoch: 13 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454199098182747		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.10454199098182747 | validation: 0.09178631327623975]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1115905219296879		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1115905219296879 | validation: 0.09336496420983617]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054213539248478		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.11054213539248478 | validation: 0.09529540925284233]
	TIME [epoch: 13 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241583474293743		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.11241583474293743 | validation: 0.09445380929872511]
	TIME [epoch: 13 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102875764247991		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.11102875764247991 | validation: 0.0969332629801863]
	TIME [epoch: 13 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894116434295958		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.10894116434295958 | validation: 0.08667196518345394]
	TIME [epoch: 13 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10852788587169156		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.10852788587169156 | validation: 0.09763175113117932]
	TIME [epoch: 13 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164811081259724		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.1164811081259724 | validation: 0.09526692234089329]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110477202779573		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.110477202779573 | validation: 0.09682449805399905]
	TIME [epoch: 13 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397562877909642		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.11397562877909642 | validation: 0.11183941527308067]
	TIME [epoch: 13 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11627696714694084		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.11627696714694084 | validation: 0.10103242273683244]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106445812177407		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.11106445812177407 | validation: 0.09615299918872569]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10772217299443679		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.10772217299443679 | validation: 0.09235541960475156]
	TIME [epoch: 13 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11507859453397695		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.11507859453397695 | validation: 0.10843354587164877]
	TIME [epoch: 13 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179894347913187		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.1179894347913187 | validation: 0.11788054135332843]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12051358140410837		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.12051358140410837 | validation: 0.09485416592682992]
	TIME [epoch: 13 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142746042334091		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.11142746042334091 | validation: 0.1036304033532992]
	TIME [epoch: 13 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154661141247164		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.1154661141247164 | validation: 0.10672349186644028]
	TIME [epoch: 13 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360439259808605		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.11360439259808605 | validation: 0.09690648735302933]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114737963309466		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.1114737963309466 | validation: 0.10325966221476743]
	TIME [epoch: 13 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117460364055475		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.1117460364055475 | validation: 0.09388989406388375]
	TIME [epoch: 13 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118962405825088		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.11118962405825088 | validation: 0.08768530798077925]
	TIME [epoch: 13 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228656186657504		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.11228656186657504 | validation: 0.10071662189690697]
	TIME [epoch: 13 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11188179943938888		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.11188179943938888 | validation: 0.10242183288921088]
	TIME [epoch: 13 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255690705732033		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.11255690705732033 | validation: 0.09414135811191539]
	TIME [epoch: 13 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11157314339652016		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.11157314339652016 | validation: 0.09881909150225239]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089676604090574		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.1089676604090574 | validation: 0.09550350324147931]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10716418888333575		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.10716418888333575 | validation: 0.10120013969547235]
	TIME [epoch: 13 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11609564420745348		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.11609564420745348 | validation: 0.10515422959176089]
	TIME [epoch: 13 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11330623865160619		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.11330623865160619 | validation: 0.10319975502124816]
	TIME [epoch: 13 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10971236952961946		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.10971236952961946 | validation: 0.10549871841029702]
	TIME [epoch: 13 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10776449090750795		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.10776449090750795 | validation: 0.1012045910224075]
	TIME [epoch: 13 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167358303564066		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.11167358303564066 | validation: 0.09661121382656102]
	TIME [epoch: 13 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102104510783038		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.11102104510783038 | validation: 0.09865731199452853]
	TIME [epoch: 13 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10919666432055014		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.10919666432055014 | validation: 0.09310297251926024]
	TIME [epoch: 13 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104483510349045		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.1104483510349045 | validation: 0.08924186265639125]
	TIME [epoch: 13 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091467247213514		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.1091467247213514 | validation: 0.08942080459129863]
	TIME [epoch: 13 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962511280282466		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.10962511280282466 | validation: 0.09159470998447496]
	TIME [epoch: 13 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11074492763304317		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.11074492763304317 | validation: 0.09336021726000862]
	TIME [epoch: 13 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10964698457039995		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.10964698457039995 | validation: 0.09365561947853096]
	TIME [epoch: 13 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161907859119452		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.11161907859119452 | validation: 0.09847726825933645]
	TIME [epoch: 13 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11188432007198079		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.11188432007198079 | validation: 0.09278913086049974]
	TIME [epoch: 13 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767366772331288		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.10767366772331288 | validation: 0.09603242728281522]
	TIME [epoch: 13 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086545481836834		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.1086545481836834 | validation: 0.09883736457007021]
	TIME [epoch: 13 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069773042519439		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.11069773042519439 | validation: 0.0956705408847682]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11549731789639237		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.11549731789639237 | validation: 0.08791436187214764]
	TIME [epoch: 13 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11541825190040475		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.11541825190040475 | validation: 0.09673802635109027]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954439648456273		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.10954439648456273 | validation: 0.098447374190241]
	TIME [epoch: 13 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10882436838480383		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.10882436838480383 | validation: 0.09544511525859553]
	TIME [epoch: 13 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10939462559866882		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.10939462559866882 | validation: 0.08908283056934548]
	TIME [epoch: 13 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11000893832484422		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.11000893832484422 | validation: 0.09368280978494835]
	TIME [epoch: 13 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151393907589954		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.11151393907589954 | validation: 0.09500802484314413]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11437893042356247		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.11437893042356247 | validation: 0.10292047245242271]
	TIME [epoch: 13 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124546123848185		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.1124546123848185 | validation: 0.09386908087840444]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928441177529713		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.10928441177529713 | validation: 0.09185242206358556]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105030606611655		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.105030606611655 | validation: 0.09470241097906908]
	TIME [epoch: 13 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348126249499556		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.11348126249499556 | validation: 0.09699000962772733]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11372083109259717		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.11372083109259717 | validation: 0.08497383314347962]
	TIME [epoch: 13 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11120466411469106		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.11120466411469106 | validation: 0.09324617693523343]
	TIME [epoch: 13 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079583360543137		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.1079583360543137 | validation: 0.09658377689171056]
	TIME [epoch: 13 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022719813890786		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.11022719813890786 | validation: 0.09770242726403876]
	TIME [epoch: 13 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10859203193718713		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.10859203193718713 | validation: 0.09687674314824847]
	TIME [epoch: 13 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10885653315049948		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.10885653315049948 | validation: 0.09461034341194563]
	TIME [epoch: 13 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883726923774456		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.10883726923774456 | validation: 0.09081593001859783]
	TIME [epoch: 13 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235754980082499		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.11235754980082499 | validation: 0.08772278112687552]
	TIME [epoch: 13 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11307394913284832		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.11307394913284832 | validation: 0.08883477139334227]
	TIME [epoch: 13 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11036524897200689		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.11036524897200689 | validation: 0.08883418845991752]
	TIME [epoch: 13 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244215342615196		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.11244215342615196 | validation: 0.09231710293388627]
	TIME [epoch: 13 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11486244402982046		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.11486244402982046 | validation: 0.08714108440015483]
	TIME [epoch: 13 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11092538459128709		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.11092538459128709 | validation: 0.09638289487047642]
	TIME [epoch: 13 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11467408213895697		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.11467408213895697 | validation: 0.08729909427289698]
	TIME [epoch: 13 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10723386967381282		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.10723386967381282 | validation: 0.0840729079977487]
	TIME [epoch: 13 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189929895727976		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.11189929895727976 | validation: 0.09142727254571625]
	TIME [epoch: 13 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175839790307164		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.11175839790307164 | validation: 0.0796287981302092]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240310_003030/states/model_tr_study3_1683.pth
	Model improved!!!
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11123618759539522		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.11123618759539522 | validation: 0.09470810566255242]
	TIME [epoch: 13 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776354412257148		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.11776354412257148 | validation: 0.09121151882502126]
	TIME [epoch: 13 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903545241537744		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.11903545241537744 | validation: 0.10114387262892884]
	TIME [epoch: 13 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11542033209645927		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.11542033209645927 | validation: 0.09040394308573899]
	TIME [epoch: 13 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11604667732033183		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.11604667732033183 | validation: 0.09170529594817417]
	TIME [epoch: 13 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11100264098407293		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.11100264098407293 | validation: 0.09161617632890766]
	TIME [epoch: 13 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11529625542833788		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.11529625542833788 | validation: 0.09489848500393451]
	TIME [epoch: 13 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11386411315303506		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.11386411315303506 | validation: 0.09441403265026024]
	TIME [epoch: 13 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11510236154741535		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.11510236154741535 | validation: 0.09311397329479075]
	TIME [epoch: 13 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887649447525277		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.10887649447525277 | validation: 0.08524661006686418]
	TIME [epoch: 13 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10782456408639206		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.10782456408639206 | validation: 0.09363492343845761]
	TIME [epoch: 13 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11215405909817652		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.11215405909817652 | validation: 0.10155361423254061]
	TIME [epoch: 13 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090221673611586		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.11090221673611586 | validation: 0.08411067934422775]
	TIME [epoch: 13 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040199992054385		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.11040199992054385 | validation: 0.08366652581149857]
	TIME [epoch: 13 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785952784990624		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.10785952784990624 | validation: 0.09479457784740056]
	TIME [epoch: 13 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10927244915014252		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.10927244915014252 | validation: 0.08180608234035507]
	TIME [epoch: 13 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1137932639348184		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.1137932639348184 | validation: 0.08584684100168889]
	TIME [epoch: 13 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11130530988211562		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.11130530988211562 | validation: 0.08772542850388688]
	TIME [epoch: 13 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11369664721543025		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.11369664721543025 | validation: 0.08632640508080507]
	TIME [epoch: 13 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198384593150387		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.11198384593150387 | validation: 0.08778383062740922]
	TIME [epoch: 13 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118487357330249		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.11118487357330249 | validation: 0.09086244645163609]
	TIME [epoch: 13 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11176715455330569		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.11176715455330569 | validation: 0.0946825363534029]
	TIME [epoch: 13 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109153351795918		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.1109153351795918 | validation: 0.10163038770244864]
	TIME [epoch: 13 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907242889272563		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.10907242889272563 | validation: 0.09268261079917471]
	TIME [epoch: 13 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11403436846270136		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.11403436846270136 | validation: 0.09610122838349561]
	TIME [epoch: 13 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434026218891918		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.11434026218891918 | validation: 0.09365073035124301]
	TIME [epoch: 13 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227525254889523		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.11227525254889523 | validation: 0.08029226826047327]
	TIME [epoch: 13 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131987447503304		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.11131987447503304 | validation: 0.09613738874832428]
	TIME [epoch: 13 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11527498938221598		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.11527498938221598 | validation: 0.08254927812242267]
	TIME [epoch: 13 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11572659597114676		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.11572659597114676 | validation: 0.08826736349529096]
	TIME [epoch: 13 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11588912927062703		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.11588912927062703 | validation: 0.08682621628833274]
	TIME [epoch: 13 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374871129386228		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.11374871129386228 | validation: 0.09216783175079828]
	TIME [epoch: 13 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206532698886296		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.11206532698886296 | validation: 0.08649527094160461]
	TIME [epoch: 13 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11613958584892278		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.11613958584892278 | validation: 0.0896597146207149]
	TIME [epoch: 13 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460173414425284		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.11460173414425284 | validation: 0.0944014976267114]
	TIME [epoch: 13 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11554479449089164		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.11554479449089164 | validation: 0.098066797461672]
	TIME [epoch: 13 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11205847725549645		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.11205847725549645 | validation: 0.09549332033631774]
	TIME [epoch: 13 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192017948076803		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.11192017948076803 | validation: 0.08753099168004984]
	TIME [epoch: 13 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024282269546343		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.11024282269546343 | validation: 0.08698842337635934]
	TIME [epoch: 13 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035807848737611		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.11035807848737611 | validation: 0.08759140853207527]
	TIME [epoch: 13 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605616029504979		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.10605616029504979 | validation: 0.09385718828281568]
	TIME [epoch: 13 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11029800839940788		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.11029800839940788 | validation: 0.10054651134832632]
	TIME [epoch: 13 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033546349114608		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.11033546349114608 | validation: 0.09709061855389652]
	TIME [epoch: 13 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123255785958309		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.1123255785958309 | validation: 0.09478711296273393]
	TIME [epoch: 13 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912763248389958		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.10912763248389958 | validation: 0.09035563114275309]
	TIME [epoch: 13 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10858103546168997		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.10858103546168997 | validation: 0.09495428057032995]
	TIME [epoch: 13 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10765073445570661		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.10765073445570661 | validation: 0.08778289718294748]
	TIME [epoch: 13 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812480502171368		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.10812480502171368 | validation: 0.09998770579129827]
	TIME [epoch: 13 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699971302293627		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.10699971302293627 | validation: 0.09242151844312792]
	TIME [epoch: 13 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111351826968192		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.11111351826968192 | validation: 0.08733852030593951]
	TIME [epoch: 13 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11180810153526967		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.11180810153526967 | validation: 0.09650636635980644]
	TIME [epoch: 13 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10893008051471814		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.10893008051471814 | validation: 0.08828753549668861]
	TIME [epoch: 13 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102073564441627		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.11102073564441627 | validation: 0.08582106679095915]
	TIME [epoch: 13 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915922985198413		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.10915922985198413 | validation: 0.09287849680624202]
	TIME [epoch: 13 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624346222568672		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.10624346222568672 | validation: 0.0906236778832948]
	TIME [epoch: 13 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848358673095818		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.10848358673095818 | validation: 0.09220878222558401]
	TIME [epoch: 13 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11050878307008652		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.11050878307008652 | validation: 0.09927022201566021]
	TIME [epoch: 13 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131017488709354		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.1131017488709354 | validation: 0.09459206643398109]
	TIME [epoch: 13 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10815050103344936		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.10815050103344936 | validation: 0.09308806694402919]
	TIME [epoch: 13 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748227516891581		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.10748227516891581 | validation: 0.083064832336967]
	TIME [epoch: 13 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973148110877871		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.10973148110877871 | validation: 0.09428222031020812]
	TIME [epoch: 13 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833518007182455		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.10833518007182455 | validation: 0.08485470545601104]
	TIME [epoch: 13 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10851443426446417		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.10851443426446417 | validation: 0.08833565706454911]
	TIME [epoch: 13 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686216236411948		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.10686216236411948 | validation: 0.08523440323819013]
	TIME [epoch: 13 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11037079241258826		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.11037079241258826 | validation: 0.08718243201421903]
	TIME [epoch: 13 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469424648007469		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.11469424648007469 | validation: 0.10020069755669692]
	TIME [epoch: 13 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11316919029667934		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.11316919029667934 | validation: 0.092507923376526]
	TIME [epoch: 13 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109069162802304		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.109069162802304 | validation: 0.09924635310551555]
	TIME [epoch: 13 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848284713866099		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.10848284713866099 | validation: 0.1021274199127117]
	TIME [epoch: 13 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397047951193892		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.11397047951193892 | validation: 0.09732423922610135]
	TIME [epoch: 13 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832241530061122		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.10832241530061122 | validation: 0.09941895458418142]
	TIME [epoch: 13 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10743438789979903		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.10743438789979903 | validation: 0.08434032252860556]
	TIME [epoch: 13 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10997336039465518		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.10997336039465518 | validation: 0.09825796344072772]
	TIME [epoch: 13 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072347258046064		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.11072347258046064 | validation: 0.09780765929161465]
	TIME [epoch: 13 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912067199263129		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.10912067199263129 | validation: 0.08613589743308701]
	TIME [epoch: 13 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956390520367308		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.10956390520367308 | validation: 0.08190747230649169]
	TIME [epoch: 13 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11180909902626021		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.11180909902626021 | validation: 0.08386255334906807]
	TIME [epoch: 13 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11371369585055496		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.11371369585055496 | validation: 0.09167501177555402]
	TIME [epoch: 13 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630926845884582		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.10630926845884582 | validation: 0.08234259434375557]
	TIME [epoch: 13 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112672297908629		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.1112672297908629 | validation: 0.08996568705036205]
	TIME [epoch: 13 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730567928862203		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.10730567928862203 | validation: 0.08939376488008524]
	TIME [epoch: 13 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11074401934726436		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.11074401934726436 | validation: 0.09122623608550028]
	TIME [epoch: 13 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161454345072775		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.1161454345072775 | validation: 0.08491499587098762]
	TIME [epoch: 13 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244839318161505		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.11244839318161505 | validation: 0.08884378392763427]
	TIME [epoch: 13 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114750606277849		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.114750606277849 | validation: 0.08784950211915636]
	TIME [epoch: 13 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11217148396017286		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.11217148396017286 | validation: 0.09812912137663407]
	TIME [epoch: 13 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009416859388335		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.11009416859388335 | validation: 0.08356705197067443]
	TIME [epoch: 13 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412404123397998		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.11412404123397998 | validation: 0.08738247087933834]
	TIME [epoch: 13 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613226237730108		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.10613226237730108 | validation: 0.08533250267428924]
	TIME [epoch: 13 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10593514703671865		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.10593514703671865 | validation: 0.08584156304496339]
	TIME [epoch: 13 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041250499303427		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.11041250499303427 | validation: 0.08937998394589419]
	TIME [epoch: 13 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490890919509303		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.11490890919509303 | validation: 0.08955582384549166]
	TIME [epoch: 13 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096577394788232		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.11096577394788232 | validation: 0.08908354508020859]
	TIME [epoch: 13 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11045413760638845		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.11045413760638845 | validation: 0.0885533619107131]
	TIME [epoch: 13 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10873467272711942		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.10873467272711942 | validation: 0.09813489794879506]
	TIME [epoch: 13 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212554407479294		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.11212554407479294 | validation: 0.09500023999637995]
	TIME [epoch: 13 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169127547978741		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.11169127547978741 | validation: 0.10431129918159819]
	TIME [epoch: 13 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175678918133551		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.11175678918133551 | validation: 0.08857195269776544]
	TIME [epoch: 13 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460520254136385		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.11460520254136385 | validation: 0.09825958357485182]
	TIME [epoch: 13 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10661425670896253		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.10661425670896253 | validation: 0.09007000218736944]
	TIME [epoch: 13 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11071906121607628		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.11071906121607628 | validation: 0.08597760749602497]
	TIME [epoch: 13 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10978735682299384		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.10978735682299384 | validation: 0.08916246974787942]
	TIME [epoch: 13 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11055877573904052		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.11055877573904052 | validation: 0.08275555019159755]
	TIME [epoch: 13 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10774742159817241		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.10774742159817241 | validation: 0.09165128177821075]
	TIME [epoch: 13 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096564571534873		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.1096564571534873 | validation: 0.09425517170502207]
	TIME [epoch: 13 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628370383814026		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.10628370383814026 | validation: 0.09465587021207313]
	TIME [epoch: 13 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11134962073760656		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.11134962073760656 | validation: 0.09077914913243079]
	TIME [epoch: 13 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10579924960120032		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.10579924960120032 | validation: 0.09007063561004966]
	TIME [epoch: 13 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10580246120294737		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.10580246120294737 | validation: 0.08728645351441067]
	TIME [epoch: 13 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167402321051997		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.11167402321051997 | validation: 0.0924570266992594]
	TIME [epoch: 13 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227927512702038		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.11227927512702038 | validation: 0.09613384976196322]
	TIME [epoch: 13 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298056867312062		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.11298056867312062 | validation: 0.09076567457237734]
	TIME [epoch: 13 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064015133018207		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.11064015133018207 | validation: 0.08533502075529543]
	TIME [epoch: 13 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920034053852606		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.10920034053852606 | validation: 0.09441569410758036]
	TIME [epoch: 13 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10914204615962969		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.10914204615962969 | validation: 0.08721647705316801]
	TIME [epoch: 13 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902915539287687		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.10902915539287687 | validation: 0.08836811016421373]
	TIME [epoch: 13 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10817627008922749		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.10817627008922749 | validation: 0.09035830943682507]
	TIME [epoch: 13 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639849360908134		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.10639849360908134 | validation: 0.09230250391291535]
	TIME [epoch: 13 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11224420476027114		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.11224420476027114 | validation: 0.09947499239004096]
	TIME [epoch: 13 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10969101991593358		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.10969101991593358 | validation: 0.09272038354778328]
	TIME [epoch: 13 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11018107403328764		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.11018107403328764 | validation: 0.09599105487518354]
	TIME [epoch: 13 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099785551203449		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.1099785551203449 | validation: 0.09661617899357242]
	TIME [epoch: 13 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750497003178172		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.10750497003178172 | validation: 0.09092248254666889]
	TIME [epoch: 13 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752952944648092		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.10752952944648092 | validation: 0.09075887220690908]
	TIME [epoch: 13 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024007092113261		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.11024007092113261 | validation: 0.09515428458280706]
	TIME [epoch: 13 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911844879729726		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.10911844879729726 | validation: 0.09719529089568696]
	TIME [epoch: 13 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963608263543553		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.10963608263543553 | validation: 0.10126350793381157]
	TIME [epoch: 13 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11063259446574199		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.11063259446574199 | validation: 0.08826766010731252]
	TIME [epoch: 13 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096851096610072		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.1096851096610072 | validation: 0.09051525030905128]
	TIME [epoch: 13 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10905558051581911		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.10905558051581911 | validation: 0.09815173906505165]
	TIME [epoch: 13 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966687242636104		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.10966687242636104 | validation: 0.08936377545039313]
	TIME [epoch: 13 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076250534120002		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.1076250534120002 | validation: 0.08822358775477884]
	TIME [epoch: 13 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894626468846988		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.10894626468846988 | validation: 0.091740544707556]
	TIME [epoch: 13 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970232466011412		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.10970232466011412 | validation: 0.10023288367167624]
	TIME [epoch: 13 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051904638330366		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.11051904638330366 | validation: 0.0914862828088027]
	TIME [epoch: 13 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321410110888028		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.11321410110888028 | validation: 0.10563176903805116]
	TIME [epoch: 13 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10967943930167805		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.10967943930167805 | validation: 0.09050836116784872]
	TIME [epoch: 13 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870023840092943		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.10870023840092943 | validation: 0.10322271984388914]
	TIME [epoch: 13 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110090123271962		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.11110090123271962 | validation: 0.0840293450734585]
	TIME [epoch: 13 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848771353729006		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.10848771353729006 | validation: 0.0877399571290108]
	TIME [epoch: 13 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10707164427092669		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.10707164427092669 | validation: 0.10000254316782287]
	TIME [epoch: 13 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954769155282906		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.10954769155282906 | validation: 0.08657047229145462]
	TIME [epoch: 13 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114757077953403		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.1114757077953403 | validation: 0.09078438536742503]
	TIME [epoch: 13 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11598427987225095		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.11598427987225095 | validation: 0.08868722596137578]
	TIME [epoch: 13 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048315140259555		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.1048315140259555 | validation: 0.09649546438538957]
	TIME [epoch: 13 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10906573909634998		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.10906573909634998 | validation: 0.09137548591244833]
	TIME [epoch: 13 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11305349785794482		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.11305349785794482 | validation: 0.08972505566023257]
	TIME [epoch: 13 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075371699419065		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.11075371699419065 | validation: 0.08879408073029692]
	TIME [epoch: 13 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11003447108498318		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.11003447108498318 | validation: 0.09247793223620128]
	TIME [epoch: 13 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10680876832672914		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.10680876832672914 | validation: 0.09074192516318769]
	TIME [epoch: 13 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144884444501599		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.11144884444501599 | validation: 0.09085036653144714]
	TIME [epoch: 13 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10672454486345676		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.10672454486345676 | validation: 0.09319134654882212]
	TIME [epoch: 13 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122805275457928		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.11122805275457928 | validation: 0.09255869052015953]
	TIME [epoch: 13 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11284861452830733		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.11284861452830733 | validation: 0.09000033813691466]
	TIME [epoch: 13 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109390770876306		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.109390770876306 | validation: 0.0901543498867348]
	TIME [epoch: 13 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241115031954957		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.11241115031954957 | validation: 0.08870280805448065]
	TIME [epoch: 13 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057316487057844		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.11057316487057844 | validation: 0.09180088257920282]
	TIME [epoch: 13 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956905914606634		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.10956905914606634 | validation: 0.08721066275802825]
	TIME [epoch: 13 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983237150399883		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.10983237150399883 | validation: 0.08922962996269236]
	TIME [epoch: 13 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993921197912436		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.10993921197912436 | validation: 0.09388535569984147]
	TIME [epoch: 13 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11313613865016116		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.11313613865016116 | validation: 0.09096882596256455]
	TIME [epoch: 13 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11577659278723357		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.11577659278723357 | validation: 0.09085565843092455]
	TIME [epoch: 13 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861287587322917		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.10861287587322917 | validation: 0.09332050762601013]
	TIME [epoch: 13 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11032389000784656		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.11032389000784656 | validation: 0.0858564666914781]
	TIME [epoch: 13 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10850181028873261		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.10850181028873261 | validation: 0.08716140255365652]
	TIME [epoch: 13 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10821596965164842		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.10821596965164842 | validation: 0.09224783024681733]
	TIME [epoch: 13 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10839572943876077		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.10839572943876077 | validation: 0.09455221265743667]
	TIME [epoch: 13 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11003186920402992		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.11003186920402992 | validation: 0.09339614328283695]
	TIME [epoch: 13 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111043381058876		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.111043381058876 | validation: 0.09433781674434936]
	TIME [epoch: 13 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090975619384794		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.1090975619384794 | validation: 0.09902045346614331]
	TIME [epoch: 13 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319562058894542		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.10319562058894542 | validation: 0.0934839551254041]
	TIME [epoch: 13 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10782219999206118		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.10782219999206118 | validation: 0.09532092064005189]
	TIME [epoch: 13 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144445616281817		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.11144445616281817 | validation: 0.09432274288409179]
	TIME [epoch: 13 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663422992531335		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.10663422992531335 | validation: 0.09009377488918943]
	TIME [epoch: 13 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10895239448331648		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.10895239448331648 | validation: 0.08958078565107463]
	TIME [epoch: 12.9 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165784758471654		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.11165784758471654 | validation: 0.09736884724087283]
	TIME [epoch: 13 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11292457427448992		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.11292457427448992 | validation: 0.09986177274086426]
	TIME [epoch: 12.9 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917904853239133		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.10917904853239133 | validation: 0.08744044254258969]
	TIME [epoch: 13 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726371004425529		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.10726371004425529 | validation: 0.09318569374319942]
	TIME [epoch: 13 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983306762166045		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.10983306762166045 | validation: 0.09428135099073917]
	TIME [epoch: 13 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089706389959195		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.1089706389959195 | validation: 0.098851466636957]
	TIME [epoch: 13 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105780435369547		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.11105780435369547 | validation: 0.09704158443377477]
	TIME [epoch: 13 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726372284355244		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.10726372284355244 | validation: 0.09429215016942695]
	TIME [epoch: 13 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803996717904936		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.10803996717904936 | validation: 0.09281212202049745]
	TIME [epoch: 13 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854454625360466		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.10854454625360466 | validation: 0.08516012190613864]
	TIME [epoch: 13 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11185634264437674		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.11185634264437674 | validation: 0.08839328978903019]
	TIME [epoch: 13 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10798411310092065		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.10798411310092065 | validation: 0.08943661388849179]
	TIME [epoch: 13 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713517423714615		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.10713517423714615 | validation: 0.09629975167729982]
	TIME [epoch: 13 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848821549780992		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.10848821549780992 | validation: 0.08309215969100162]
	TIME [epoch: 13 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10485041708018068		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.10485041708018068 | validation: 0.09156145963230769]
	TIME [epoch: 13 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11330274499655293		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.11330274499655293 | validation: 0.08855834618698019]
	TIME [epoch: 13 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985255107565275		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.10985255107565275 | validation: 0.09811655501618191]
	TIME [epoch: 13 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078773780981924		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.11078773780981924 | validation: 0.09722325743758287]
	TIME [epoch: 13 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059277692328158		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.1059277692328158 | validation: 0.09941417828446353]
	TIME [epoch: 13 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011349472521678		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.11011349472521678 | validation: 0.08842682131055866]
	TIME [epoch: 13 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10839190881307167		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.10839190881307167 | validation: 0.09337999002313334]
	TIME [epoch: 13 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068142872492032		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.11068142872492032 | validation: 0.09177899014846305]
	TIME [epoch: 13 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963857571298503		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.10963857571298503 | validation: 0.09705641315087196]
	TIME [epoch: 13 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054262002682419		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.11054262002682419 | validation: 0.0948791636346687]
	TIME [epoch: 13 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974318098068292		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.10974318098068292 | validation: 0.09002644675443698]
	TIME [epoch: 13 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10815822192276431		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.10815822192276431 | validation: 0.09612904689991726]
	TIME [epoch: 13 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10896862070631315		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.10896862070631315 | validation: 0.10001154008858265]
	TIME [epoch: 13 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169965292479894		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.11169965292479894 | validation: 0.09263523091885718]
	TIME [epoch: 13 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10766547812010717		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.10766547812010717 | validation: 0.0881445906856584]
	TIME [epoch: 13 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230186428513089		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.11230186428513089 | validation: 0.09904626064235388]
	TIME [epoch: 13 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11199116196637322		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.11199116196637322 | validation: 0.09851215384120046]
	TIME [epoch: 13 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878543321324997		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.10878543321324997 | validation: 0.09406587129999189]
	TIME [epoch: 13 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1044379833636985		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.1044379833636985 | validation: 0.09400457061179704]
	TIME [epoch: 13 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11008757444627622		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.11008757444627622 | validation: 0.09044507937597977]
	TIME [epoch: 13 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981445626965602		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.10981445626965602 | validation: 0.10017875147054667]
	TIME [epoch: 13 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245400152922712		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.11245400152922712 | validation: 0.09472201182865674]
	TIME [epoch: 13 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803409591655491		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.10803409591655491 | validation: 0.09169753452838089]
	TIME [epoch: 13 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735405996866247		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.10735405996866247 | validation: 0.10665360052227207]
	TIME [epoch: 13 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400164585466629		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.10400164585466629 | validation: 0.09059039226839087]
	TIME [epoch: 13 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10885249424564936		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.10885249424564936 | validation: 0.10309779570952188]
	TIME [epoch: 13 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11013688023015414		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.11013688023015414 | validation: 0.10118675281387834]
	TIME [epoch: 13 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060756630771644		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.11060756630771644 | validation: 0.08553309800857922]
	TIME [epoch: 13 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10852595692733813		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.10852595692733813 | validation: 0.1006548599910105]
	TIME [epoch: 13 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934657493183339		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.10934657493183339 | validation: 0.09814132031601065]
	TIME [epoch: 13 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10571186871878194		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.10571186871878194 | validation: 0.09518777000581903]
	TIME [epoch: 13 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902225296156137		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.10902225296156137 | validation: 0.09772744143194657]
	TIME [epoch: 13 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857634304682855		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.10857634304682855 | validation: 0.09528480289449856]
	TIME [epoch: 13 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10208951033658874		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.10208951033658874 | validation: 0.09494381318694275]
	TIME [epoch: 13 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987451542988186		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.10987451542988186 | validation: 0.09518198511600641]
	TIME [epoch: 13 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110212963439388		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.110212963439388 | validation: 0.09701014112368617]
	TIME [epoch: 13 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11002174353745255		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.11002174353745255 | validation: 0.11011609759770505]
	TIME [epoch: 13 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10786410921806158		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.10786410921806158 | validation: 0.09931053420531061]
	TIME [epoch: 13 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11223895020074963		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.11223895020074963 | validation: 0.09664024626975998]
	TIME [epoch: 13 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728946730229097		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.10728946730229097 | validation: 0.09769951992999065]
	TIME [epoch: 13 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11091537534035584		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.11091537534035584 | validation: 0.09140757159423185]
	TIME [epoch: 13 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11249600933771532		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.11249600933771532 | validation: 0.09093605929406959]
	TIME [epoch: 13 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11224263071646018		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.11224263071646018 | validation: 0.09452164079381853]
	TIME [epoch: 13 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050051120490885		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.1050051120490885 | validation: 0.10721405601844562]
	TIME [epoch: 13 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073430719722487		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.11073430719722487 | validation: 0.10037205109019368]
	TIME [epoch: 13 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10768817046420617		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.10768817046420617 | validation: 0.09576214002514032]
	TIME [epoch: 13 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11026103338937071		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.11026103338937071 | validation: 0.08486086033972413]
	TIME [epoch: 13 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062672484502113		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.1062672484502113 | validation: 0.09046104046256825]
	TIME [epoch: 13 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534246463163134		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.10534246463163134 | validation: 0.09243992453301064]
	TIME [epoch: 13 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111327886898983		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.11111327886898983 | validation: 0.09952039092643496]
	TIME [epoch: 13 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767465307999971		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.10767465307999971 | validation: 0.09404130849525749]
	TIME [epoch: 13 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803307190070817		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.10803307190070817 | validation: 0.09065565517288338]
	TIME [epoch: 13 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10662667157619748		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.10662667157619748 | validation: 0.09651944781991473]
	TIME [epoch: 13 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506539608517629		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.10506539608517629 | validation: 0.09471527006152737]
	TIME [epoch: 13 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700493925476737		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.10700493925476737 | validation: 0.09138179923114019]
	TIME [epoch: 13 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11395523899470772		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.11395523899470772 | validation: 0.09571137007268586]
	TIME [epoch: 13 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999987955162728		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.10999987955162728 | validation: 0.08932357321086867]
	TIME [epoch: 13 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10751078859993327		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.10751078859993327 | validation: 0.08808208555346443]
	TIME [epoch: 13 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100733092788286		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.1100733092788286 | validation: 0.08744953370804673]
	TIME [epoch: 13 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125666862354225		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.11125666862354225 | validation: 0.09058996703426107]
	TIME [epoch: 13 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144205606943769		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.11144205606943769 | validation: 0.09824882499736623]
	TIME [epoch: 13 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725818395598483		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.10725818395598483 | validation: 0.08951904548683702]
	TIME [epoch: 13 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124465579171437		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.11124465579171437 | validation: 0.08668514281503335]
	TIME [epoch: 13 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10986844601995262		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.10986844601995262 | validation: 0.0900787483290413]
	TIME [epoch: 13 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10932278446449717		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.10932278446449717 | validation: 0.09667288235462784]
	TIME [epoch: 13 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11001250197335535		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.11001250197335535 | validation: 0.09947041919810691]
	TIME [epoch: 13 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052779198981424		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.11052779198981424 | validation: 0.0860014367791477]
	TIME [epoch: 13 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554910747294599		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.10554910747294599 | validation: 0.08510400809981478]
	TIME [epoch: 13 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087195145608749		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.1087195145608749 | validation: 0.09542571069875454]
	TIME [epoch: 13 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715030238186687		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.10715030238186687 | validation: 0.08981215972747136]
	TIME [epoch: 13 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170082372866769		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.11170082372866769 | validation: 0.09620249640674096]
	TIME [epoch: 13 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581580796303934		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.10581580796303934 | validation: 0.10073203845941953]
	TIME [epoch: 13 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900714218154682		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.10900714218154682 | validation: 0.0882377085454708]
	TIME [epoch: 13 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10843688093341955		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.10843688093341955 | validation: 0.09126854274353535]
	TIME [epoch: 13 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359142240667693		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.10359142240667693 | validation: 0.09201471005306239]
	TIME [epoch: 13 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047414417767279		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.11047414417767279 | validation: 0.09677436923207436]
	TIME [epoch: 13 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11089933280772919		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.11089933280772919 | validation: 0.0915953898931509]
	TIME [epoch: 13 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080062447972924		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.1080062447972924 | validation: 0.10182029362607256]
	TIME [epoch: 13 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044345531700803		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.11044345531700803 | validation: 0.09876040242937548]
	TIME [epoch: 13 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10946738148756299		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.10946738148756299 | validation: 0.10013642200946384]
	TIME [epoch: 13 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10666053263608533		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.10666053263608533 | validation: 0.09284735149389231]
	TIME [epoch: 13 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10708824910919518		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.10708824910919518 | validation: 0.09848832006888081]
	TIME [epoch: 13 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810923096232601		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.10810923096232601 | validation: 0.1032940372584552]
	TIME [epoch: 13 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496092223784974		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.10496092223784974 | validation: 0.10144245391565317]
	TIME [epoch: 13 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10597117916458958		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.10597117916458958 | validation: 0.09743656806991104]
	TIME [epoch: 13 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439630389000216		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.11439630389000216 | validation: 0.10094588404398724]
	TIME [epoch: 13 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679757262919395		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.10679757262919395 | validation: 0.09700431843929185]
	TIME [epoch: 13 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10927318602408459		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.10927318602408459 | validation: 0.09395044925127177]
	TIME [epoch: 13 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300106614014888		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.11300106614014888 | validation: 0.0985049659114945]
	TIME [epoch: 13 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688833001015986		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.10688833001015986 | validation: 0.09353760695381175]
	TIME [epoch: 13 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079766124172814		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.1079766124172814 | validation: 0.09167587260682661]
	TIME [epoch: 13 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848782256737326		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.10848782256737326 | validation: 0.09389954501617624]
	TIME [epoch: 13 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10792092150322347		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.10792092150322347 | validation: 0.0924605440509967]
	TIME [epoch: 13 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105516621163854		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.105516621163854 | validation: 0.09776767944742336]
	TIME [epoch: 13 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1047299585389308		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.1047299585389308 | validation: 0.09401433899041674]
	TIME [epoch: 13 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11146865434896383		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.11146865434896383 | validation: 0.08953115110577858]
	TIME [epoch: 13 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062416270841861		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.1062416270841861 | validation: 0.08806463521975992]
	TIME [epoch: 13 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857423650662573		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.10857423650662573 | validation: 0.09303268544303489]
	TIME [epoch: 13 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090508786446209		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.1090508786446209 | validation: 0.08548538154085143]
	TIME [epoch: 13 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110444348416786		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.11110444348416786 | validation: 0.08668125780179603]
	TIME [epoch: 13 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898675875060543		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.10898675875060543 | validation: 0.10089347994257995]
	TIME [epoch: 13 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10653384566242403		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.10653384566242403 | validation: 0.0945180193611926]
	TIME [epoch: 13 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10592851979562057		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.10592851979562057 | validation: 0.09426581728550432]
	TIME [epoch: 13 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11109464518107677		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.11109464518107677 | validation: 0.08947540108398597]
	TIME [epoch: 13 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365166776777455		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.11365166776777455 | validation: 0.08781161640991726]
	TIME [epoch: 13 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998742122448868		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.10998742122448868 | validation: 0.09589863457595277]
	TIME [epoch: 13 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10877905036472164		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.10877905036472164 | validation: 0.09564067496637371]
	TIME [epoch: 13 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460396616737781		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.10460396616737781 | validation: 0.09967553549554463]
	TIME [epoch: 13 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10904578216012117		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.10904578216012117 | validation: 0.10108247651452479]
	TIME [epoch: 13 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803173282430281		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.10803173282430281 | validation: 0.09808278110585977]
	TIME [epoch: 13 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10283426276969189		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.10283426276969189 | validation: 0.08845773436771094]
	TIME [epoch: 13 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083250331548676		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.11083250331548676 | validation: 0.09459876591751831]
	TIME [epoch: 13 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103737135133366		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.1103737135133366 | validation: 0.09804781668683062]
	TIME [epoch: 13 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940896583932619		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.10940896583932619 | validation: 0.10372926757044254]
	TIME [epoch: 13 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116742746025852		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.1116742746025852 | validation: 0.09512765437344733]
	TIME [epoch: 13 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659705390855749		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.10659705390855749 | validation: 0.10222959543293826]
	TIME [epoch: 13 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10968811222219635		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.10968811222219635 | validation: 0.09401146957968981]
	TIME [epoch: 13 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10930559863671788		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.10930559863671788 | validation: 0.0965145427643275]
	TIME [epoch: 13 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096352671602553		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.1096352671602553 | validation: 0.10132537255036624]
	TIME [epoch: 13 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138352881106845		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.1138352881106845 | validation: 0.10384494862643857]
	TIME [epoch: 13 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039977736213752		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.11039977736213752 | validation: 0.08372803461665568]
	TIME [epoch: 13 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015606096651592		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.11015606096651592 | validation: 0.09300497255741899]
	TIME [epoch: 13 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11037435935338392		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.11037435935338392 | validation: 0.0929037396623243]
	TIME [epoch: 13 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11336186557360746		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.11336186557360746 | validation: 0.09356583826836973]
	TIME [epoch: 13 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081783581951048		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.1081783581951048 | validation: 0.0959862623575254]
	TIME [epoch: 13 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068533498483073		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.1068533498483073 | validation: 0.09297105847519792]
	TIME [epoch: 13 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630745997401571		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.10630745997401571 | validation: 0.09065450014012734]
	TIME [epoch: 13 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975124169014898		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.10975124169014898 | validation: 0.0908209835001956]
	TIME [epoch: 13 sec]
Finished training in 26227.367 seconds.
