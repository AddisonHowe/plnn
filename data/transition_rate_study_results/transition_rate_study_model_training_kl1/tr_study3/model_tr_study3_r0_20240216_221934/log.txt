Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2307450978

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.596249165221948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.596249165221948 | validation: 9.162548851099823]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.84866824574986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.84866824574986 | validation: 8.614995057623773]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.536959761612367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.536959761612367 | validation: 8.497493147469694]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.001604619716783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.001604619716783 | validation: 7.842430997026927]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.446442693649665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.446442693649665 | validation: 7.065724681977416]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.022663684118503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.022663684118503 | validation: 6.70922724741021]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.580307084443002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.580307084443002 | validation: 6.373949181732762]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.499035695437113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.499035695437113 | validation: 6.43045581983286]
	TIME [epoch: 9.08 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.148339566691224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.148339566691224 | validation: 6.174654595962977]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.161054547354658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.161054547354658 | validation: 5.942781641066592]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.756846826853659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.756846826853659 | validation: 5.703060340507566]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6009175923285905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6009175923285905 | validation: 5.6970737871181525]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.669550512224223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.669550512224223 | validation: 5.879064410408867]
	TIME [epoch: 9.07 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.544343404068819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.544343404068819 | validation: 5.760637371515886]
	TIME [epoch: 9.07 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.644279067941427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.644279067941427 | validation: 5.6143805756618494]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.665033190051087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.665033190051087 | validation: 5.7674561124657435]
	TIME [epoch: 9.11 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.569998845139623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.569998845139623 | validation: 5.585644175805772]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.505365032711324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.505365032711324 | validation: 5.456574176979895]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.633416783822025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.633416783822025 | validation: 5.965087280689433]
	TIME [epoch: 9.08 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.732715779115187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.732715779115187 | validation: 5.590901874087386]
	TIME [epoch: 9.09 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.4471867360040696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4471867360040696 | validation: 5.5627906228409785]
	TIME [epoch: 9.08 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.482903430322012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.482903430322012 | validation: 5.479406138041437]
	TIME [epoch: 9.08 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.539821484833847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.539821484833847 | validation: 5.756292453702675]
	TIME [epoch: 9.08 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.672381694248968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.672381694248968 | validation: 5.5276203957475545]
	TIME [epoch: 9.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.529974491667035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529974491667035 | validation: 5.55410592598639]
	TIME [epoch: 9.08 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.522603399256508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.522603399256508 | validation: 5.726889503876268]
	TIME [epoch: 9.08 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.549218563883906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.549218563883906 | validation: 5.541607681441652]
	TIME [epoch: 9.08 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.480250267130112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.480250267130112 | validation: 5.840581144381568]
	TIME [epoch: 9.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.505639189171779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.505639189171779 | validation: 5.592738865883327]
	TIME [epoch: 9.09 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.58133228610909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.58133228610909 | validation: 5.554877122452686]
	TIME [epoch: 9.08 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.473102950198085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.473102950198085 | validation: 5.612468737531824]
	TIME [epoch: 9.08 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.67165458036801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.67165458036801 | validation: 5.778767652311791]
	TIME [epoch: 9.09 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.665991100078761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.665991100078761 | validation: 5.49455449498542]
	TIME [epoch: 9.08 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.476209461875667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.476209461875667 | validation: 5.564168886006842]
	TIME [epoch: 9.08 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.420713223341375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.420713223341375 | validation: 5.53525729187565]
	TIME [epoch: 9.08 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.412708046999911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.412708046999911 | validation: 5.340936319997447]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.368710630385047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.368710630385047 | validation: 5.398158956971647]
	TIME [epoch: 9.09 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.368536190957012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.368536190957012 | validation: 5.499620820540502]
	TIME [epoch: 9.07 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.409126688532456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.409126688532456 | validation: 6.016404136573643]
	TIME [epoch: 9.07 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.8007117821120335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8007117821120335 | validation: 5.2856680669523985]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.300037712710028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.300037712710028 | validation: 5.393740088484276]
	TIME [epoch: 9.08 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.185135371731495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.185135371731495 | validation: 5.332127594075413]
	TIME [epoch: 9.07 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.289688450060142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.289688450060142 | validation: 5.8903139455049525]
	TIME [epoch: 9.07 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.389012190344713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.389012190344713 | validation: 5.302010674101153]
	TIME [epoch: 9.06 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.247022264875128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.247022264875128 | validation: 5.243828658130517]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.147563894233137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.147563894233137 | validation: 5.500545593114881]
	TIME [epoch: 9.07 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.245397636113774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.245397636113774 | validation: 5.402309038097639]
	TIME [epoch: 9.07 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.120977474114522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.120977474114522 | validation: 5.114274438534207]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.913572066488194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.913572066488194 | validation: 4.942624315564724]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.842359424432139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.842359424432139 | validation: 4.901756628097697]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.855776590613051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.855776590613051 | validation: 4.780585115576836]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.760154175938412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.760154175938412 | validation: 5.149291810243568]
	TIME [epoch: 9.07 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.711162117660628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.711162117660628 | validation: 4.795936068153104]
	TIME [epoch: 9.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.572697440198364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.572697440198364 | validation: 4.552856748952562]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.4354901151509765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4354901151509765 | validation: 4.534106756614937]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.889670045143324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.889670045143324 | validation: 3.540965560006489]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5840280111733263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5840280111733263 | validation: 3.145415335281967]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1565486160720044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1565486160720044 | validation: 3.2394248493904074]
	TIME [epoch: 9.08 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.029969673565645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.029969673565645 | validation: 2.6295411632118872]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6872074179291596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6872074179291596 | validation: 2.3521301842186135]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2572201084744825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2572201084744825 | validation: 1.9893537150416294]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.267948273626227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.267948273626227 | validation: 2.5703790862400195]
	TIME [epoch: 9.07 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1369220985427693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1369220985427693 | validation: 2.3888572372387276]
	TIME [epoch: 9.07 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8691738998380707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8691738998380707 | validation: 2.142494806941196]
	TIME [epoch: 9.07 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.449845929474301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.449845929474301 | validation: 1.8953161725502463]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.30408010298703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.30408010298703 | validation: 2.41542515028957]
	TIME [epoch: 9.08 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9431605891387107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9431605891387107 | validation: 1.852667429999288]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.968254693146815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.968254693146815 | validation: 2.717534699063217]
	TIME [epoch: 9.07 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9489678760333284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9489678760333284 | validation: 2.6216519513196213]
	TIME [epoch: 9.09 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.080565871558453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.080565871558453 | validation: 1.6759877723829761]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1398706838974837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1398706838974837 | validation: 2.1388209090069035]
	TIME [epoch: 9.07 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1082977586699365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1082977586699365 | validation: 1.8965197205754776]
	TIME [epoch: 9.07 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7675615455957785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7675615455957785 | validation: 3.520001027703702]
	TIME [epoch: 9.08 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4161210627882914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4161210627882914 | validation: 1.9150268750134838]
	TIME [epoch: 9.08 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9536858605285272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9536858605285272 | validation: 1.554419673449267]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.817531580765441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.817531580765441 | validation: 1.8888213769096835]
	TIME [epoch: 9.08 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.833097176739619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.833097176739619 | validation: 1.8854907676564991]
	TIME [epoch: 9.08 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.876991645909517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.876991645909517 | validation: 2.922544969037901]
	TIME [epoch: 9.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.305610997610855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.305610997610855 | validation: 3.107696238607855]
	TIME [epoch: 9.08 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.82944006158408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.82944006158408 | validation: 1.9112521631151411]
	TIME [epoch: 9.08 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5229395746981247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5229395746981247 | validation: 1.8566012216943915]
	TIME [epoch: 9.07 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6900733915532726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6900733915532726 | validation: 1.5817510843488862]
	TIME [epoch: 9.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9377978511899692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9377978511899692 | validation: 2.160373542507669]
	TIME [epoch: 9.08 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.776259166969389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.776259166969389 | validation: 2.684237275572521]
	TIME [epoch: 9.08 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.933245217976766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.933245217976766 | validation: 1.5328767874177145]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8745672132986477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8745672132986477 | validation: 1.905895970293476]
	TIME [epoch: 9.09 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4125153411476643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4125153411476643 | validation: 1.9112480595984702]
	TIME [epoch: 9.09 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8150313807779757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8150313807779757 | validation: 1.5808069002180618]
	TIME [epoch: 9.08 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.133419563830115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.133419563830115 | validation: 2.118579239290927]
	TIME [epoch: 9.08 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7283865783257781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7283865783257781 | validation: 3.168902432478717]
	TIME [epoch: 9.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1903393824337094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1903393824337094 | validation: 1.578771137870634]
	TIME [epoch: 9.09 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1522887656115492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1522887656115492 | validation: 1.6280538601872356]
	TIME [epoch: 9.08 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6801681694961885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6801681694961885 | validation: 1.6773876567827564]
	TIME [epoch: 9.07 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7190463134777147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7190463134777147 | validation: 2.2340540309286636]
	TIME [epoch: 9.07 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6351904843602267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6351904843602267 | validation: 1.249853402177161]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6633220287673929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6633220287673929 | validation: 1.3834243740350787]
	TIME [epoch: 9.07 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6631893660140904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6631893660140904 | validation: 1.573868042790922]
	TIME [epoch: 9.07 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7689105085642258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7689105085642258 | validation: 1.602141101849429]
	TIME [epoch: 9.07 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7441061483022686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7441061483022686 | validation: 1.9222644357675174]
	TIME [epoch: 9.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.549443726844424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.549443726844424 | validation: 1.2066534620010951]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4185157001822417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4185157001822417 | validation: 1.8654431863962702]
	TIME [epoch: 9.08 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6474946066846734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6474946066846734 | validation: 1.3403510086019765]
	TIME [epoch: 9.07 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7899869752579511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7899869752579511 | validation: 1.4377609033451981]
	TIME [epoch: 9.09 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5013234623080367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5013234623080367 | validation: 1.5387577941630264]
	TIME [epoch: 9.07 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.322871792413432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.322871792413432 | validation: 1.283698172048147]
	TIME [epoch: 9.07 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4524204592111232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4524204592111232 | validation: 1.1803657514230905]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7246099552637388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7246099552637388 | validation: 1.6630690384541054]
	TIME [epoch: 9.09 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.485357261866007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.485357261866007 | validation: 1.1279312528361078]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.547141495464913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.547141495464913 | validation: 1.5398292386037973]
	TIME [epoch: 9.07 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.584277049891875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.584277049891875 | validation: 1.797104775464419]
	TIME [epoch: 9.07 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.521559595973995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.521559595973995 | validation: 1.170183751371726]
	TIME [epoch: 9.08 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.718926294538721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.718926294538721 | validation: 1.0885662914264214]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.102975469634688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.102975469634688 | validation: 1.7421103170790397]
	TIME [epoch: 9.07 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3790487460748149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3790487460748149 | validation: 1.3377332807234188]
	TIME [epoch: 9.07 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2916840889409809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2916840889409809 | validation: 2.2959202261979117]
	TIME [epoch: 9.08 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3779833094999312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3779833094999312 | validation: 1.0572179780597388]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6855415220472374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6855415220472374 | validation: 1.7174345036594247]
	TIME [epoch: 9.07 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3489890314008264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3489890314008264 | validation: 1.2078233789413217]
	TIME [epoch: 9.07 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3588487341818092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3588487341818092 | validation: 2.1301000158810637]
	TIME [epoch: 9.07 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5349994996932934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5349994996932934 | validation: 2.2009480763832467]
	TIME [epoch: 9.09 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5595303844433217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5595303844433217 | validation: 1.1908197764362045]
	TIME [epoch: 9.07 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5711422735552802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5711422735552802 | validation: 1.3812016089320096]
	TIME [epoch: 9.07 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8804226458837985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8804226458837985 | validation: 1.3212498954810652]
	TIME [epoch: 9.07 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4268773839009923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4268773839009923 | validation: 2.0037123250973545]
	TIME [epoch: 9.09 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.392776792009512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.392776792009512 | validation: 1.2710936220306388]
	TIME [epoch: 9.07 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8154420390951067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8154420390951067 | validation: 3.3310539491014852]
	TIME [epoch: 9.07 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.891222105529523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.891222105529523 | validation: 1.4070130553792608]
	TIME [epoch: 9.07 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5562393690073093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5562393690073093 | validation: 1.9967792887069633]
	TIME [epoch: 9.09 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5059888713507432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5059888713507432 | validation: 1.6792230594569468]
	TIME [epoch: 9.08 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6685595081910538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6685595081910538 | validation: 1.6400884776951046]
	TIME [epoch: 9.06 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6644077133543942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6644077133543942 | validation: 1.70786460825958]
	TIME [epoch: 9.07 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5022369902985877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5022369902985877 | validation: 1.2268116955123052]
	TIME [epoch: 9.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.57928205333399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.57928205333399 | validation: 1.1941548354376794]
	TIME [epoch: 9.07 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3170848921125806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3170848921125806 | validation: 1.5561956188553399]
	TIME [epoch: 9.07 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.358409809361294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.358409809361294 | validation: 1.1655803678635612]
	TIME [epoch: 9.07 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.589045754940622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.589045754940622 | validation: 2.1278635548356224]
	TIME [epoch: 9.08 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6033870160467658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6033870160467658 | validation: 1.3316868171044942]
	TIME [epoch: 9.08 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3250929568995273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3250929568995273 | validation: 1.9892788241251251]
	TIME [epoch: 9.07 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3607177132634238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3607177132634238 | validation: 1.245455254873989]
	TIME [epoch: 9.07 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7314623148611712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7314623148611712 | validation: 2.262265022731121]
	TIME [epoch: 9.08 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5255601630992413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5255601630992413 | validation: 1.6701405600273662]
	TIME [epoch: 9.09 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5160340063209667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5160340063209667 | validation: 1.1050099250465628]
	TIME [epoch: 9.07 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.558693688441982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.558693688441982 | validation: 1.2732211141087637]
	TIME [epoch: 9.07 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5918259492240645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5918259492240645 | validation: 1.1548069717713896]
	TIME [epoch: 9.07 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5436680227782407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5436680227782407 | validation: 1.4282369825157808]
	TIME [epoch: 9.09 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4099126392199206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4099126392199206 | validation: 1.204255511266279]
	TIME [epoch: 9.07 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2621761427145346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2621761427145346 | validation: 1.864322150606502]
	TIME [epoch: 9.07 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9397184979844444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9397184979844444 | validation: 1.7111990023404808]
	TIME [epoch: 9.07 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.501794499307371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.501794499307371 | validation: 1.4214201599055438]
	TIME [epoch: 9.09 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4025894165785016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4025894165785016 | validation: 1.2404473934212654]
	TIME [epoch: 9.07 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.456176939234282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.456176939234282 | validation: 1.4985387658916487]
	TIME [epoch: 9.08 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2664978297185516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2664978297185516 | validation: 2.098156424767722]
	TIME [epoch: 9.06 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3594802062665363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3594802062665363 | validation: 1.0599028007559788]
	TIME [epoch: 9.09 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5588234618683465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5588234618683465 | validation: 1.0917279431669211]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3480540336594429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3480540336594429 | validation: 1.7982788077438512]
	TIME [epoch: 9.07 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6364653186537297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6364653186537297 | validation: 2.360814412517138]
	TIME [epoch: 9.07 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.012895391371818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.012895391371818 | validation: 2.1500549753272242]
	TIME [epoch: 9.08 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5642985306839887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5642985306839887 | validation: 1.4069298803765884]
	TIME [epoch: 9.08 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.530187003417507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.530187003417507 | validation: 1.8318353866416963]
	TIME [epoch: 9.06 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8086374038342181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8086374038342181 | validation: 2.200970395031856]
	TIME [epoch: 9.07 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6862226558105182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6862226558105182 | validation: 3.1715853383909844]
	TIME [epoch: 9.08 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.293315057575296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.293315057575296 | validation: 1.943097666347374]
	TIME [epoch: 9.08 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5250450381536695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5250450381536695 | validation: 1.2937920788132666]
	TIME [epoch: 9.07 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6029371606318883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6029371606318883 | validation: 2.176613901206771]
	TIME [epoch: 9.07 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.705808180521687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.705808180521687 | validation: 1.5630879312971748]
	TIME [epoch: 9.07 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6948004761896158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6948004761896158 | validation: 1.3113322155316536]
	TIME [epoch: 9.09 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.428760558783133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.428760558783133 | validation: 1.1970441328507195]
	TIME [epoch: 9.07 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6438231932642018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6438231932642018 | validation: 1.1894358150738547]
	TIME [epoch: 9.07 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.643324350128625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.643324350128625 | validation: 1.2196781451525032]
	TIME [epoch: 9.07 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6632063687708971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6632063687708971 | validation: 1.1880860700389317]
	TIME [epoch: 9.09 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.97852669440415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.97852669440415 | validation: 1.3839410645311707]
	TIME [epoch: 9.07 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5598233832546349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5598233832546349 | validation: 1.5326922263479927]
	TIME [epoch: 9.06 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4169944089868496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4169944089868496 | validation: 1.4047782205612709]
	TIME [epoch: 9.07 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8095465689792913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8095465689792913 | validation: 1.5658206276281619]
	TIME [epoch: 9.09 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4514770888320645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4514770888320645 | validation: 1.6152992946671905]
	TIME [epoch: 9.07 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6848108008267944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6848108008267944 | validation: 1.5158158704459856]
	TIME [epoch: 9.06 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5266860630106278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5266860630106278 | validation: 1.686944998666155]
	TIME [epoch: 9.07 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5609367675992316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5609367675992316 | validation: 1.3975671277317931]
	TIME [epoch: 9.09 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.456775864585759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.456775864585759 | validation: 1.4177121785637916]
	TIME [epoch: 9.08 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.523055223792845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.523055223792845 | validation: 2.0618529226092086]
	TIME [epoch: 9.07 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5809995747185253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5809995747185253 | validation: 1.6887161865341431]
	TIME [epoch: 9.07 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4747950730934405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4747950730934405 | validation: 1.459372570951735]
	TIME [epoch: 9.08 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8201995175134946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8201995175134946 | validation: 1.4619836233937735]
	TIME [epoch: 9.08 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6731485712235958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6731485712235958 | validation: 1.4617235650058478]
	TIME [epoch: 9.07 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5156428403418643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5156428403418643 | validation: 1.3982676845902766]
	TIME [epoch: 9.07 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6577957464624382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6577957464624382 | validation: 1.379960752541383]
	TIME [epoch: 9.07 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3023324297955596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3023324297955596 | validation: 1.240348093446845]
	TIME [epoch: 9.08 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2197394657407385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2197394657407385 | validation: 1.4650001188813304]
	TIME [epoch: 9.07 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6858243675562565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6858243675562565 | validation: 2.0886395357090226]
	TIME [epoch: 9.06 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2232387201546926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2232387201546926 | validation: 1.4002227986377074]
	TIME [epoch: 9.07 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2515828397653601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2515828397653601 | validation: 1.5011715052783146]
	TIME [epoch: 9.09 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.489336825173788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.489336825173788 | validation: 1.9779617386875257]
	TIME [epoch: 9.07 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.719694128964392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.719694128964392 | validation: 1.3787273206496913]
	TIME [epoch: 9.06 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.406992360833467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.406992360833467 | validation: 1.3995825738920047]
	TIME [epoch: 9.06 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.321253268136068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.321253268136068 | validation: 2.101739751229813]
	TIME [epoch: 9.08 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.579547606691188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.579547606691188 | validation: 1.5430183672475013]
	TIME [epoch: 9.07 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4169719151485294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4169719151485294 | validation: 1.0106949388982853]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1179443051815654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1179443051815654 | validation: 0.8095549914431803]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0190149454355473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0190149454355473 | validation: 2.8473568420653215]
	TIME [epoch: 9.08 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6120236170742595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6120236170742595 | validation: 1.3082465294160763]
	TIME [epoch: 9.06 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7616689351642176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7616689351642176 | validation: 3.2809133775465025]
	TIME [epoch: 9.06 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8169562635321057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8169562635321057 | validation: 1.1003343848751252]
	TIME [epoch: 9.06 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.184974014800264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.184974014800264 | validation: 1.3058819097210086]
	TIME [epoch: 9.07 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3822202438902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3822202438902 | validation: 1.0759846060709415]
	TIME [epoch: 9.07 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.583506037967013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.583506037967013 | validation: 1.6466061686592601]
	TIME [epoch: 9.06 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4008374982050273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4008374982050273 | validation: 0.9519425823356151]
	TIME [epoch: 9.06 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.582695986486145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.582695986486145 | validation: 1.050661619759614]
	TIME [epoch: 9.07 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5324250317071813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5324250317071813 | validation: 1.323860330327971]
	TIME [epoch: 9.08 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4874685377852412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4874685377852412 | validation: 1.4388650013250275]
	TIME [epoch: 9.06 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.51311105157439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.51311105157439 | validation: 1.3322988670408829]
	TIME [epoch: 9.06 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3459782471973334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3459782471973334 | validation: 1.2218884854430094]
	TIME [epoch: 9.07 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3788989320606726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3788989320606726 | validation: 1.287656767349754]
	TIME [epoch: 9.09 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.252141501329802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.252141501329802 | validation: 1.0472874596313742]
	TIME [epoch: 9.06 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.077152100260223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.077152100260223 | validation: 3.1334904879809757]
	TIME [epoch: 9.06 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4587682571016527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4587682571016527 | validation: 0.9751782783513564]
	TIME [epoch: 9.06 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3267439920210444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3267439920210444 | validation: 0.9675469994840626]
	TIME [epoch: 9.08 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5384302615469916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5384302615469916 | validation: 1.247274857130574]
	TIME [epoch: 9.06 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3460408890547737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3460408890547737 | validation: 1.7389423849061703]
	TIME [epoch: 9.06 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2904025025375974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2904025025375974 | validation: 2.0617647216404835]
	TIME [epoch: 9.06 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4875411079520695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4875411079520695 | validation: 1.2782384955495154]
	TIME [epoch: 9.08 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4271054608068603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4271054608068603 | validation: 1.8031669041813032]
	TIME [epoch: 9.07 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8143073797861646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8143073797861646 | validation: 1.4180485697183138]
	TIME [epoch: 9.06 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4042748646447194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4042748646447194 | validation: 1.891213657721016]
	TIME [epoch: 9.06 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4360753252989567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4360753252989567 | validation: 1.0576194856072219]
	TIME [epoch: 9.08 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2406288471620384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2406288471620384 | validation: 1.3980152764973344]
	TIME [epoch: 9.07 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4454348222804276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4454348222804276 | validation: 1.452415630683968]
	TIME [epoch: 9.06 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2566632632926384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2566632632926384 | validation: 1.2459409176700857]
	TIME [epoch: 9.06 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2678160782410512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2678160782410512 | validation: 1.395524303694134]
	TIME [epoch: 9.07 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.62793380282323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.62793380282323 | validation: 1.7275638165242568]
	TIME [epoch: 9.08 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3908679129383459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3908679129383459 | validation: 4.028973515030609]
	TIME [epoch: 9.06 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8661344911874607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8661344911874607 | validation: 2.196937949965553]
	TIME [epoch: 9.06 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.16289781121101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.16289781121101 | validation: 1.6197303431410957]
	TIME [epoch: 9.07 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2658532251553687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2658532251553687 | validation: 1.3899197728284163]
	TIME [epoch: 9.08 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1885622206116584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1885622206116584 | validation: 1.3651707720453954]
	TIME [epoch: 9.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2170431440421854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2170431440421854 | validation: 1.0819597777574486]
	TIME [epoch: 9.06 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2615688561893115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2615688561893115 | validation: 1.2706330280143336]
	TIME [epoch: 9.06 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3717396428099842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3717396428099842 | validation: 1.3343476717364946]
	TIME [epoch: 9.09 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1547677615992158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1547677615992158 | validation: 1.0328299326236428]
	TIME [epoch: 9.06 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.786296999475067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.786296999475067 | validation: 1.4714988648296763]
	TIME [epoch: 9.06 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4852784405919461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4852784405919461 | validation: 1.3371506589609963]
	TIME [epoch: 9.06 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5052631795189955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5052631795189955 | validation: 1.8188724723327399]
	TIME [epoch: 9.08 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8278763897660368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8278763897660368 | validation: 1.578959938304087]
	TIME [epoch: 9.07 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3707957612533226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3707957612533226 | validation: 2.1762969985565412]
	TIME [epoch: 9.06 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5367402559103567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5367402559103567 | validation: 1.1409259479785443]
	TIME [epoch: 9.06 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8451770402354797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8451770402354797 | validation: 1.4765435498332882]
	TIME [epoch: 9.08 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6933613209939793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6933613209939793 | validation: 2.0405858837927466]
	TIME [epoch: 9.06 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5065883562697535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5065883562697535 | validation: 1.011532928504501]
	TIME [epoch: 9.06 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.540815958095649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.540815958095649 | validation: 1.7995835326181664]
	TIME [epoch: 9.05 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2642114700427114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2642114700427114 | validation: 0.9778528812365048]
	TIME [epoch: 9.07 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3926512679949377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3926512679949377 | validation: 1.068122060545576]
	TIME [epoch: 9.07 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0555424146282197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0555424146282197 | validation: 1.05326900169445]
	TIME [epoch: 9.06 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0500292810085612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0500292810085612 | validation: 1.1337100078947846]
	TIME [epoch: 9.06 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1725787992545644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1725787992545644 | validation: 0.8346998800114549]
	TIME [epoch: 9.08 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3874066339796385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3874066339796385 | validation: 2.1321672563951104]
	TIME [epoch: 9.07 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3663130928756504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3663130928756504 | validation: 2.226204500167734]
	TIME [epoch: 9.06 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0275326294034994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0275326294034994 | validation: 1.337591840034998]
	TIME [epoch: 9.05 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.684171293230938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.684171293230938 | validation: 1.7923480478899336]
	TIME [epoch: 9.06 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3191012632294417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3191012632294417 | validation: 1.2221105832757924]
	TIME [epoch: 9.08 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1744212402983227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1744212402983227 | validation: 1.073567649669818]
	TIME [epoch: 9.05 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5689897398026038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5689897398026038 | validation: 1.2714584741470536]
	TIME [epoch: 9.06 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4979546464492526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4979546464492526 | validation: 1.691263589090216]
	TIME [epoch: 9.06 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5122567423132762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5122567423132762 | validation: 1.1094658986365769]
	TIME [epoch: 9.08 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.215548766676929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.215548766676929 | validation: 0.9124436063128036]
	TIME [epoch: 9.06 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2659678219764172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2659678219764172 | validation: 1.1114067228979065]
	TIME [epoch: 9.06 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1749949295418227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1749949295418227 | validation: 1.1958573193281932]
	TIME [epoch: 9.06 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0962343315552885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0962343315552885 | validation: 0.6713456991409683]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.238062615168391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.238062615168391 | validation: 1.0571692257312717]
	TIME [epoch: 9.06 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.189538046547063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.189538046547063 | validation: 0.7829672634780471]
	TIME [epoch: 9.06 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.159897327283562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.159897327283562 | validation: 0.7537139331247864]
	TIME [epoch: 9.06 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.238309786083844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.238309786083844 | validation: 0.9323300513304238]
	TIME [epoch: 9.07 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.354354168242574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.354354168242574 | validation: 1.3762278287196543]
	TIME [epoch: 9.07 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.177439006912012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.177439006912012 | validation: 0.8961701896395402]
	TIME [epoch: 9.06 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4525956448780015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4525956448780015 | validation: 1.2714053715772637]
	TIME [epoch: 9.06 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1048025322008563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1048025322008563 | validation: 1.0183611209141952]
	TIME [epoch: 9.07 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.247714771873572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.247714771873572 | validation: 1.4896439955948364]
	TIME [epoch: 9.08 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4606819041005474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4606819041005474 | validation: 0.8976548081881957]
	TIME [epoch: 9.07 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2708160439407443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2708160439407443 | validation: 1.232105328877372]
	TIME [epoch: 9.05 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.335535712180514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.335535712180514 | validation: 1.472327684417352]
	TIME [epoch: 9.05 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1931141012705848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1931141012705848 | validation: 1.018665284854665]
	TIME [epoch: 9.07 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2033208958396777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2033208958396777 | validation: 1.1525391963283436]
	TIME [epoch: 9.05 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.204829059492234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.204829059492234 | validation: 0.8541791615615058]
	TIME [epoch: 9.05 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9993422128305067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9993422128305067 | validation: 1.3096400954926952]
	TIME [epoch: 9.05 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.161494333197239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.161494333197239 | validation: 1.0658731639741927]
	TIME [epoch: 9.08 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3549597484976494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3549597484976494 | validation: 1.2332730816717552]
	TIME [epoch: 9.05 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3903386117580756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3903386117580756 | validation: 1.0398145951628188]
	TIME [epoch: 9.05 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5501296728333174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5501296728333174 | validation: 1.4006438772872696]
	TIME [epoch: 9.05 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.288909565232263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.288909565232263 | validation: 1.5148060629589697]
	TIME [epoch: 9.07 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2862792827281229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2862792827281229 | validation: 0.7119101734188356]
	TIME [epoch: 9.05 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4692404082140247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4692404082140247 | validation: 0.9337001420970441]
	TIME [epoch: 9.05 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2237152052992892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2237152052992892 | validation: 1.695237752188505]
	TIME [epoch: 9.05 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3101187722527419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3101187722527419 | validation: 0.9589492570461533]
	TIME [epoch: 9.06 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1152694253133895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1152694253133895 | validation: 0.9098061823719095]
	TIME [epoch: 9.05 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1563079743420137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1563079743420137 | validation: 1.1396480529459576]
	TIME [epoch: 9.06 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1728648003918836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1728648003918836 | validation: 1.544969314501221]
	TIME [epoch: 9.05 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5768992565731863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5768992565731863 | validation: 1.0307604927525218]
	TIME [epoch: 9.06 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2680029075275554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2680029075275554 | validation: 1.225170252849333]
	TIME [epoch: 9.06 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1994839054804816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1994839054804816 | validation: 1.0412872719038675]
	TIME [epoch: 9.05 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0904193008201613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0904193008201613 | validation: 1.5099790454358866]
	TIME [epoch: 9.04 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5600369292523995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5600369292523995 | validation: 0.978984563896186]
	TIME [epoch: 9.06 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2602807173748922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2602807173748922 | validation: 2.003547896596734]
	TIME [epoch: 9.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.823326820694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.823326820694 | validation: 3.5750147194211683]
	TIME [epoch: 9.05 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7294861468392893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7294861468392893 | validation: 1.0666225002403114]
	TIME [epoch: 9.05 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2202399372489836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2202399372489836 | validation: 1.3435112709306352]
	TIME [epoch: 9.05 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0456584594910017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0456584594910017 | validation: 1.0829765646037202]
	TIME [epoch: 9.08 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9944310532414933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9944310532414933 | validation: 1.3264800379131134]
	TIME [epoch: 9.05 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.20434301832519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.20434301832519 | validation: 1.5084090058842765]
	TIME [epoch: 9.05 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1947939603871571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1947939603871571 | validation: 2.035679289977868]
	TIME [epoch: 9.05 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1396315340753413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1396315340753413 | validation: 1.4281329392418494]
	TIME [epoch: 9.07 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2364657537008503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2364657537008503 | validation: 0.9909324319543806]
	TIME [epoch: 9.06 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.170808838108657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.170808838108657 | validation: 2.0431830476839576]
	TIME [epoch: 9.06 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6373329624178776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6373329624178776 | validation: 1.4684258969570183]
	TIME [epoch: 9.05 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3331200669465804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3331200669465804 | validation: 0.9343178039331853]
	TIME [epoch: 9.07 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.120584619714735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.120584619714735 | validation: 1.1827168631865357]
	TIME [epoch: 9.06 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3972181362858755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3972181362858755 | validation: 1.55645347908543]
	TIME [epoch: 9.05 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3823982014061482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3823982014061482 | validation: 1.9954033938745765]
	TIME [epoch: 9.04 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1996623859752114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1996623859752114 | validation: 1.3847179091183643]
	TIME [epoch: 9.06 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1220892500873512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1220892500873512 | validation: 1.2857350248062844]
	TIME [epoch: 9.07 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.216518141613402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.216518141613402 | validation: 1.176391593016708]
	TIME [epoch: 9.05 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4283773748741777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4283773748741777 | validation: 1.1961554271262407]
	TIME [epoch: 9.05 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1725160733247861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1725160733247861 | validation: 1.41332560524849]
	TIME [epoch: 9.04 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1344700547966178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1344700547966178 | validation: 1.2233294270194586]
	TIME [epoch: 9.07 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1873480972552168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1873480972552168 | validation: 1.365366154518835]
	TIME [epoch: 9.05 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.571850293942317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.571850293942317 | validation: 1.2948599808663306]
	TIME [epoch: 9.05 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9816191680599221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9816191680599221 | validation: 0.7823644915160175]
	TIME [epoch: 9.06 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.015288131268675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.015288131268675 | validation: 1.4834895423239431]
	TIME [epoch: 9.08 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1761422388727358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1761422388727358 | validation: 1.1571034429176041]
	TIME [epoch: 9.07 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3502985067610704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3502985067610704 | validation: 1.4728131470400632]
	TIME [epoch: 9.05 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6610696926315431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6610696926315431 | validation: 1.0473405229916866]
	TIME [epoch: 9.04 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2895336217294902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2895336217294902 | validation: 1.0985692842015022]
	TIME [epoch: 9.08 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3245468928916755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3245468928916755 | validation: 1.0417426895581736]
	TIME [epoch: 9.06 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.070498453391855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.070498453391855 | validation: 0.9973080366630165]
	TIME [epoch: 9.05 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1837148609454595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1837148609454595 | validation: 1.1432586600187786]
	TIME [epoch: 9.04 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.044057141334233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.044057141334233 | validation: 1.0000819060102049]
	TIME [epoch: 9.07 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4171711779334077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4171711779334077 | validation: 0.9177815938926592]
	TIME [epoch: 9.05 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1554898345363966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1554898345363966 | validation: 1.224254071104792]
	TIME [epoch: 9.05 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1417818304978353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1417818304978353 | validation: 2.0705056902488206]
	TIME [epoch: 9.05 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1695389856033924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1695389856033924 | validation: 0.8813702522842219]
	TIME [epoch: 9.07 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0115680972410543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0115680972410543 | validation: 2.2223542900488082]
	TIME [epoch: 9.07 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4650034172882536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4650034172882536 | validation: 0.9410515111386312]
	TIME [epoch: 9.06 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1154791993089357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1154791993089357 | validation: 1.3649657314612664]
	TIME [epoch: 9.05 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.334443396162827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.334443396162827 | validation: 0.8524136912736773]
	TIME [epoch: 9.06 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0046883960281237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0046883960281237 | validation: 0.7021101637213749]
	TIME [epoch: 9.07 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1043711935185483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1043711935185483 | validation: 1.145900103857664]
	TIME [epoch: 9.06 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5862994508984802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5862994508984802 | validation: 0.8704822724866375]
	TIME [epoch: 9.34 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5640970695637069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5640970695637069 | validation: 1.0275825759979145]
	TIME [epoch: 9.07 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2672735363728616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2672735363728616 | validation: 1.440895070695142]
	TIME [epoch: 9.09 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.894469754137584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.894469754137584 | validation: 1.9730127385286473]
	TIME [epoch: 9.06 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5428518571877707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5428518571877707 | validation: 1.0099714529911397]
	TIME [epoch: 9.06 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2581177548104772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2581177548104772 | validation: 1.9163534184814268]
	TIME [epoch: 9.06 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2276103799456781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2276103799456781 | validation: 1.1158269948276558]
	TIME [epoch: 9.08 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3762779089342174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3762779089342174 | validation: 0.9174216974547058]
	TIME [epoch: 9.06 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3217119387456033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3217119387456033 | validation: 2.9550300747590317]
	TIME [epoch: 9.06 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6255154027723964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6255154027723964 | validation: 1.58476395648204]
	TIME [epoch: 9.06 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0967871613879807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0967871613879807 | validation: 1.0485304798625183]
	TIME [epoch: 9.08 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.149354644703439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.149354644703439 | validation: 0.959570510678561]
	TIME [epoch: 9.06 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2576940511200188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2576940511200188 | validation: 1.2304619416796692]
	TIME [epoch: 9.06 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1889284385970602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1889284385970602 | validation: 1.9654058099496654]
	TIME [epoch: 9.05 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2635749225239254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2635749225239254 | validation: 1.067836295056382]
	TIME [epoch: 9.06 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9717504849726856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9717504849726856 | validation: 1.1080113914189074]
	TIME [epoch: 9.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.468465036194282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.468465036194282 | validation: 1.3985327977691497]
	TIME [epoch: 9.06 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.558059266881068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.558059266881068 | validation: 1.2615082633314683]
	TIME [epoch: 9.06 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0650889372703038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0650889372703038 | validation: 1.2896998667551491]
	TIME [epoch: 9.08 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1934663851855614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1934663851855614 | validation: 1.254021163715514]
	TIME [epoch: 9.07 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1787077220548423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1787077220548423 | validation: 1.1718201711310354]
	TIME [epoch: 9.07 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.328157627244215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.328157627244215 | validation: 2.26840358137424]
	TIME [epoch: 9.06 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.536060587946698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.536060587946698 | validation: 1.4068513178621123]
	TIME [epoch: 9.07 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2049338596273658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2049338596273658 | validation: 1.2133115466216964]
	TIME [epoch: 9.09 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3195856780343884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3195856780343884 | validation: 1.0352540340283245]
	TIME [epoch: 9.07 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1508723946706323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1508723946706323 | validation: 0.7901590424568579]
	TIME [epoch: 9.06 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2394004008973991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2394004008973991 | validation: 1.229712365352965]
	TIME [epoch: 9.07 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2645051314366191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2645051314366191 | validation: 1.6786464690010776]
	TIME [epoch: 9.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1369078309638114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1369078309638114 | validation: 1.3497804545001986]
	TIME [epoch: 9.07 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6407303968876068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6407303968876068 | validation: 0.9744810967605447]
	TIME [epoch: 9.07 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9762191529463875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9762191529463875 | validation: 1.4243558091959043]
	TIME [epoch: 9.06 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.333092271948198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.333092271948198 | validation: 2.4712870220922403]
	TIME [epoch: 9.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3252535796776006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3252535796776006 | validation: 1.1536974386823533]
	TIME [epoch: 9.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.159058217684224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.159058217684224 | validation: 1.1682965961425675]
	TIME [epoch: 9.07 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3270240121885746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3270240121885746 | validation: 0.929203136161066]
	TIME [epoch: 9.07 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3190521499456573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3190521499456573 | validation: 1.393160160915989]
	TIME [epoch: 9.09 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1819690623943302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1819690623943302 | validation: 1.185486118084203]
	TIME [epoch: 9.08 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1240461944637992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1240461944637992 | validation: 1.5477038778540004]
	TIME [epoch: 9.07 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0423374888884012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0423374888884012 | validation: 1.1936018545689255]
	TIME [epoch: 9.07 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0353103960876813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0353103960876813 | validation: 1.3315006006070982]
	TIME [epoch: 9.08 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9176504464178168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9176504464178168 | validation: 1.1406489089984078]
	TIME [epoch: 9.08 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3772944760574792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3772944760574792 | validation: 0.8520039399552191]
	TIME [epoch: 9.08 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9814193305745279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9814193305745279 | validation: 1.8158544812814688]
	TIME [epoch: 9.07 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1402441595755766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1402441595755766 | validation: 0.9287883673535178]
	TIME [epoch: 9.07 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0716650084994008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0716650084994008 | validation: 0.7250463631491306]
	TIME [epoch: 9.08 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0982392243005603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0982392243005603 | validation: 0.6633184786664588]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7874168074695594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7874168074695594 | validation: 1.3062440050647135]
	TIME [epoch: 9.07 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0802851423488964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0802851423488964 | validation: 1.2347326429328453]
	TIME [epoch: 9.05 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.96868733443386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.96868733443386 | validation: 1.4132452968155507]
	TIME [epoch: 9.09 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3418122565867716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3418122565867716 | validation: 1.1959464345943762]
	TIME [epoch: 9.07 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3732709651383121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3732709651383121 | validation: 0.7949859874132155]
	TIME [epoch: 9.06 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1300829333186353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1300829333186353 | validation: 0.8548317579850389]
	TIME [epoch: 9.06 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9242572340068611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9242572340068611 | validation: 1.2809938072314666]
	TIME [epoch: 9.08 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0390586397388568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0390586397388568 | validation: 0.7521973860131319]
	TIME [epoch: 9.06 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9179170526347373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9179170526347373 | validation: 0.6696496994511154]
	TIME [epoch: 9.06 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8700734868134099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8700734868134099 | validation: 1.3248596117604312]
	TIME [epoch: 9.05 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0138319871355663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0138319871355663 | validation: 0.5962714110274616]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.264060640886433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.264060640886433 | validation: 1.1872858908839632]
	TIME [epoch: 9.06 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3698342890416255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3698342890416255 | validation: 0.9322670239271206]
	TIME [epoch: 9.05 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2946162690342424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2946162690342424 | validation: 1.194933737277093]
	TIME [epoch: 9.05 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9322718129035051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9322718129035051 | validation: 1.6604177401043436]
	TIME [epoch: 9.07 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5642170171817742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5642170171817742 | validation: 0.8870603535282697]
	TIME [epoch: 9.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3919890713525604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3919890713525604 | validation: 2.428959593800904]
	TIME [epoch: 9.05 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.136344716567427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.136344716567427 | validation: 1.1878126255369312]
	TIME [epoch: 9.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2958290759822426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2958290759822426 | validation: 1.844718648263243]
	TIME [epoch: 9.06 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3576849134440176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3576849134440176 | validation: 1.2473642871260884]
	TIME [epoch: 9.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3876877398533578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3876877398533578 | validation: 1.387517505051693]
	TIME [epoch: 9.06 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2252953094706474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2252953094706474 | validation: 0.7983201066798997]
	TIME [epoch: 9.06 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0129575933188826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0129575933188826 | validation: 0.851357152873096]
	TIME [epoch: 9.07 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1167453616638103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1167453616638103 | validation: 1.1245227840838057]
	TIME [epoch: 9.09 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6935666103890585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6935666103890585 | validation: 1.6214764468692164]
	TIME [epoch: 9.06 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0226438034227274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0226438034227274 | validation: 1.3214787504135577]
	TIME [epoch: 9.06 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0887417136544604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0887417136544604 | validation: 0.9584510955204995]
	TIME [epoch: 9.06 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0461491003157293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0461491003157293 | validation: 1.7044361801370895]
	TIME [epoch: 9.09 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2222634007655209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2222634007655209 | validation: 1.4966408909615216]
	TIME [epoch: 9.06 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.363214618773322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.363214618773322 | validation: 1.302215044054541]
	TIME [epoch: 9.06 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0903828493463175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0903828493463175 | validation: 0.7746902069790502]
	TIME [epoch: 9.06 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0729032362881197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0729032362881197 | validation: 1.1548600648410008]
	TIME [epoch: 9.08 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2787964969109686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2787964969109686 | validation: 1.0954687005654424]
	TIME [epoch: 9.07 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9932026871167267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9932026871167267 | validation: 1.4897464469178994]
	TIME [epoch: 9.06 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1577379433739927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1577379433739927 | validation: 1.6879455263223027]
	TIME [epoch: 9.06 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3227977139051657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3227977139051657 | validation: 0.9121186579301394]
	TIME [epoch: 9.08 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5344959867988777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5344959867988777 | validation: 2.0677587932796375]
	TIME [epoch: 9.06 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.188488109547761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.188488109547761 | validation: 2.0823223159636486]
	TIME [epoch: 9.06 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2776965104870766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2776965104870766 | validation: 0.9969833984454579]
	TIME [epoch: 9.06 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.199161454585527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.199161454585527 | validation: 1.4595312634137199]
	TIME [epoch: 9.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0639794090228931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0639794090228931 | validation: 0.9128146695707765]
	TIME [epoch: 9.07 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1095257832852887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1095257832852887 | validation: 0.8225969365964986]
	TIME [epoch: 9.06 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1107519187020658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1107519187020658 | validation: 1.3180284283552313]
	TIME [epoch: 9.05 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1229447212462262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1229447212462262 | validation: 1.0479725338341124]
	TIME [epoch: 9.07 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.92241598409517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.92241598409517 | validation: 0.7788200998640349]
	TIME [epoch: 9.08 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9259471998220213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9259471998220213 | validation: 0.707157620808911]
	TIME [epoch: 9.06 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9380330513089417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9380330513089417 | validation: 0.8327606033193942]
	TIME [epoch: 9.06 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0856565250838424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0856565250838424 | validation: 0.8532238923842879]
	TIME [epoch: 9.05 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9598335853998021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9598335853998021 | validation: 1.0689607068563827]
	TIME [epoch: 9.09 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2482044059279145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2482044059279145 | validation: 1.690813979949152]
	TIME [epoch: 9.06 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1575537975614423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1575537975614423 | validation: 1.1306609338951303]
	TIME [epoch: 9.06 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9067923291647878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9067923291647878 | validation: 0.9530407016039248]
	TIME [epoch: 9.05 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2369127971239824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2369127971239824 | validation: 1.063809064594654]
	TIME [epoch: 9.08 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9949710334172925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9949710334172925 | validation: 0.7702615827875232]
	TIME [epoch: 9.09 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9554495315162657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9554495315162657 | validation: 1.491916858155554]
	TIME [epoch: 9.06 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0922680509062332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0922680509062332 | validation: 1.2631843129813238]
	TIME [epoch: 9.05 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0877290849410641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0877290849410641 | validation: 0.8068474660552022]
	TIME [epoch: 9.07 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8893437049052286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8893437049052286 | validation: 0.7231288995236393]
	TIME [epoch: 9.06 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9627107511376625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9627107511376625 | validation: 0.6961918763179957]
	TIME [epoch: 9.06 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0534134957224057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0534134957224057 | validation: 1.7234025337545118]
	TIME [epoch: 9.06 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5706757606393427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5706757606393427 | validation: 1.1943142692933624]
	TIME [epoch: 9.07 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1504832264143483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1504832264143483 | validation: 0.9531895479760377]
	TIME [epoch: 9.07 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.720882751369177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.720882751369177 | validation: 0.9136148249280546]
	TIME [epoch: 9.06 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9764805509617827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9764805509617827 | validation: 0.8716834928826812]
	TIME [epoch: 9.06 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0665663735297342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0665663735297342 | validation: 0.9485153073485082]
	TIME [epoch: 9.06 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9097136957889663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9097136957889663 | validation: 0.7017640679911139]
	TIME [epoch: 9.07 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.174012357098881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.174012357098881 | validation: 1.6916381107117335]
	TIME [epoch: 9.06 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9579236108503815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9579236108503815 | validation: 1.1880939026299462]
	TIME [epoch: 9.06 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4473740882323594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4473740882323594 | validation: 1.0579013564889754]
	TIME [epoch: 9.05 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9833152677471546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9833152677471546 | validation: 0.892437994133775]
	TIME [epoch: 9.08 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7766892160251668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7766892160251668 | validation: 0.726109798012073]
	TIME [epoch: 9.06 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9644340329404699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9644340329404699 | validation: 0.9842936361006389]
	TIME [epoch: 9.06 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1843706043684479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1843706043684479 | validation: 1.5586348142503512]
	TIME [epoch: 9.05 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.208974600464303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.208974600464303 | validation: 1.2807670927180888]
	TIME [epoch: 9.08 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2731120404105205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2731120404105205 | validation: 0.9728578157161099]
	TIME [epoch: 9.06 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0721124156527857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0721124156527857 | validation: 1.479426349977468]
	TIME [epoch: 9.06 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2068786377862872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2068786377862872 | validation: 1.3398414396934255]
	TIME [epoch: 9.05 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.061838759003242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.061838759003242 | validation: 0.933602584566918]
	TIME [epoch: 9.08 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.885722259707285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.885722259707285 | validation: 1.8292017280227673]
	TIME [epoch: 9.06 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2161091569565765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2161091569565765 | validation: 0.6415384801925474]
	TIME [epoch: 9.05 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0543972285642094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0543972285642094 | validation: 0.6572527616063017]
	TIME [epoch: 9.06 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9942519563354804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9942519563354804 | validation: 0.7148807500199006]
	TIME [epoch: 9.07 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0048659691808013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0048659691808013 | validation: 0.6493631039282692]
	TIME [epoch: 9.06 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9573561844602461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9573561844602461 | validation: 1.0027445028044275]
	TIME [epoch: 9.06 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8944479254818631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8944479254818631 | validation: 0.7163087786045258]
	TIME [epoch: 9.06 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8827038282714629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8827038282714629 | validation: 1.1893750317607419]
	TIME [epoch: 9.09 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9370582304267042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9370582304267042 | validation: 0.7002545252869484]
	TIME [epoch: 9.07 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8677194701994336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8677194701994336 | validation: 0.977681671784943]
	TIME [epoch: 9.05 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9259953097309055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9259953097309055 | validation: 2.690265356108255]
	TIME [epoch: 9.05 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2485956393383073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2485956393383073 | validation: 1.1413976634546918]
	TIME [epoch: 9.05 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9102588104043543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9102588104043543 | validation: 1.5883497593185032]
	TIME [epoch: 9.08 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0526287742652203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0526287742652203 | validation: 1.0499624621825077]
	TIME [epoch: 9.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.054757175972515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.054757175972515 | validation: 0.8376701785385097]
	TIME [epoch: 9.07 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.838432935238026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.838432935238026 | validation: 0.7316225209443614]
	TIME [epoch: 9.06 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8845462454951021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8845462454951021 | validation: 0.7714312665636953]
	TIME [epoch: 9.08 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7491230005346441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7491230005346441 | validation: 1.559781217258971]
	TIME [epoch: 9.06 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8820307847674116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8820307847674116 | validation: 0.8779638515519299]
	TIME [epoch: 9.05 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0345804006275097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0345804006275097 | validation: 1.075495081963814]
	TIME [epoch: 9.06 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2747480795462707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2747480795462707 | validation: 1.4841863447936927]
	TIME [epoch: 9.08 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2179737169989582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2179737169989582 | validation: 1.1157105216345904]
	TIME [epoch: 9.06 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8817818897261637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8817818897261637 | validation: 0.8351568443969867]
	TIME [epoch: 9.05 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8925343069963322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8925343069963322 | validation: 0.743663041410523]
	TIME [epoch: 9.05 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8425651696593297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8425651696593297 | validation: 0.7873982921424751]
	TIME [epoch: 11.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9269109255373877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9269109255373877 | validation: 0.8274533330285858]
	TIME [epoch: 9.06 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8536237754716746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8536237754716746 | validation: 0.9563199075505489]
	TIME [epoch: 9.05 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9539205267725835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9539205267725835 | validation: 0.6441549794231659]
	TIME [epoch: 9.06 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7269917471240415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7269917471240415 | validation: 1.1229767131967678]
	TIME [epoch: 9.06 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0020985998291287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0020985998291287 | validation: 0.8137159490428787]
	TIME [epoch: 9.07 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8896581071453384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8896581071453384 | validation: 0.8041768032624222]
	TIME [epoch: 9.05 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2772467500999691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2772467500999691 | validation: 1.0747299823780567]
	TIME [epoch: 9.05 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9884652335574895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9884652335574895 | validation: 0.7256316683338001]
	TIME [epoch: 9.06 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8480566524792765		[learning rate: 0.0099724]
	Learning Rate: 0.00997241
	LOSS [training: 0.8480566524792765 | validation: 1.0980582424211254]
	TIME [epoch: 9.06 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9891971608685524		[learning rate: 0.0099418]
	Learning Rate: 0.00994184
	LOSS [training: 0.9891971608685524 | validation: 0.8057442744067922]
	TIME [epoch: 9.06 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8681206769215798		[learning rate: 0.0099114]
	Learning Rate: 0.00991136
	LOSS [training: 0.8681206769215798 | validation: 1.0867819557712668]
	TIME [epoch: 9.05 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9377737723864303		[learning rate: 0.009881]
	Learning Rate: 0.00988098
	LOSS [training: 0.9377737723864303 | validation: 1.4839557802456205]
	TIME [epoch: 9.04 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0056265086986216		[learning rate: 0.0098507]
	Learning Rate: 0.00985069
	LOSS [training: 1.0056265086986216 | validation: 1.593281382639332]
	TIME [epoch: 9.07 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2361627957448578		[learning rate: 0.0098205]
	Learning Rate: 0.00982049
	LOSS [training: 2.2361627957448578 | validation: 4.3072543099727785]
	TIME [epoch: 9.04 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.654520453138457		[learning rate: 0.0097904]
	Learning Rate: 0.00979039
	LOSS [training: 4.654520453138457 | validation: 4.978922291034539]
	TIME [epoch: 9.04 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.919149626153468		[learning rate: 0.0097604]
	Learning Rate: 0.00976038
	LOSS [training: 3.919149626153468 | validation: 1.0247760236561216]
	TIME [epoch: 9.05 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1943953304731358		[learning rate: 0.0097305]
	Learning Rate: 0.00973046
	LOSS [training: 1.1943953304731358 | validation: 0.817165574475449]
	TIME [epoch: 9.07 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9171375134764347		[learning rate: 0.0097006]
	Learning Rate: 0.00970063
	LOSS [training: 0.9171375134764347 | validation: 0.9812949263950015]
	TIME [epoch: 9.05 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.14691711201058		[learning rate: 0.0096709]
	Learning Rate: 0.00967089
	LOSS [training: 1.14691711201058 | validation: 1.1569221316267384]
	TIME [epoch: 9.05 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0181404485129149		[learning rate: 0.0096412]
	Learning Rate: 0.00964125
	LOSS [training: 1.0181404485129149 | validation: 1.125681177498273]
	TIME [epoch: 9.05 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9882396413728823		[learning rate: 0.0096117]
	Learning Rate: 0.0096117
	LOSS [training: 0.9882396413728823 | validation: 0.6832271736341503]
	TIME [epoch: 9.06 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8600703774324463		[learning rate: 0.0095822]
	Learning Rate: 0.00958223
	LOSS [training: 0.8600703774324463 | validation: 0.7978493556138162]
	TIME [epoch: 9.05 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0555188696123194		[learning rate: 0.0095529]
	Learning Rate: 0.00955286
	LOSS [training: 1.0555188696123194 | validation: 1.2566537984422106]
	TIME [epoch: 9.05 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0686256702711492		[learning rate: 0.0095236]
	Learning Rate: 0.00952357
	LOSS [training: 1.0686256702711492 | validation: 1.0597694888106377]
	TIME [epoch: 9.05 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0366698578860345		[learning rate: 0.0094944]
	Learning Rate: 0.00949438
	LOSS [training: 1.0366698578860345 | validation: 0.9018351546163896]
	TIME [epoch: 9.05 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.873865321492679		[learning rate: 0.0094653]
	Learning Rate: 0.00946528
	LOSS [training: 0.873865321492679 | validation: 1.1068020227065172]
	TIME [epoch: 9.05 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9074968578857565		[learning rate: 0.0094363]
	Learning Rate: 0.00943626
	LOSS [training: 0.9074968578857565 | validation: 0.8054454923235819]
	TIME [epoch: 9.05 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8353926430101396		[learning rate: 0.0094073]
	Learning Rate: 0.00940734
	LOSS [training: 0.8353926430101396 | validation: 0.9107480513966837]
	TIME [epoch: 9.05 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7656512133008534		[learning rate: 0.0093785]
	Learning Rate: 0.0093785
	LOSS [training: 0.7656512133008534 | validation: 0.6185387263303921]
	TIME [epoch: 9.06 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.887499220304707		[learning rate: 0.0093497]
	Learning Rate: 0.00934975
	LOSS [training: 0.887499220304707 | validation: 0.726045984671253]
	TIME [epoch: 9.06 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.983472455432079		[learning rate: 0.0093211]
	Learning Rate: 0.00932109
	LOSS [training: 0.983472455432079 | validation: 0.750923235819211]
	TIME [epoch: 9.05 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9411298139549663		[learning rate: 0.0092925]
	Learning Rate: 0.00929252
	LOSS [training: 0.9411298139549663 | validation: 1.028908275196279]
	TIME [epoch: 9.05 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8489352341845876		[learning rate: 0.009264]
	Learning Rate: 0.00926403
	LOSS [training: 0.8489352341845876 | validation: 0.8974442541089269]
	TIME [epoch: 9.05 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8450722727367811		[learning rate: 0.0092356]
	Learning Rate: 0.00923563
	LOSS [training: 0.8450722727367811 | validation: 0.6333788644324734]
	TIME [epoch: 9.07 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8708622586614572		[learning rate: 0.0092073]
	Learning Rate: 0.00920732
	LOSS [training: 0.8708622586614572 | validation: 0.9907328283245376]
	TIME [epoch: 9.05 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8026220606388798		[learning rate: 0.0091791]
	Learning Rate: 0.0091791
	LOSS [training: 0.8026220606388798 | validation: 0.9558933891633352]
	TIME [epoch: 9.05 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1561495829147206		[learning rate: 0.009151]
	Learning Rate: 0.00915096
	LOSS [training: 1.1561495829147206 | validation: 0.7491728260315047]
	TIME [epoch: 9.05 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7262116196480453		[learning rate: 0.0091229]
	Learning Rate: 0.00912291
	LOSS [training: 0.7262116196480453 | validation: 0.46086375036327487]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7391707970115176		[learning rate: 0.0090949]
	Learning Rate: 0.00909494
	LOSS [training: 0.7391707970115176 | validation: 0.9086759242147928]
	TIME [epoch: 9.06 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0435589429868135		[learning rate: 0.0090671]
	Learning Rate: 0.00906706
	LOSS [training: 1.0435589429868135 | validation: 0.7620588571278285]
	TIME [epoch: 9.04 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8927004613189992		[learning rate: 0.0090393]
	Learning Rate: 0.00903927
	LOSS [training: 0.8927004613189992 | validation: 0.5557364744112894]
	TIME [epoch: 9.06 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1196039571239411		[learning rate: 0.0090116]
	Learning Rate: 0.00901156
	LOSS [training: 1.1196039571239411 | validation: 0.7342114596256772]
	TIME [epoch: 9.07 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5741049773357623		[learning rate: 0.0089839]
	Learning Rate: 0.00898394
	LOSS [training: 1.5741049773357623 | validation: 0.6997057928852528]
	TIME [epoch: 9.06 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9138676481983377		[learning rate: 0.0089564]
	Learning Rate: 0.0089564
	LOSS [training: 0.9138676481983377 | validation: 0.873044021462956]
	TIME [epoch: 9.05 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0721516939669191		[learning rate: 0.0089289]
	Learning Rate: 0.00892894
	LOSS [training: 1.0721516939669191 | validation: 0.84889966958965]
	TIME [epoch: 9.05 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9217032417295219		[learning rate: 0.0089016]
	Learning Rate: 0.00890157
	LOSS [training: 0.9217032417295219 | validation: 1.1229788174479693]
	TIME [epoch: 9.07 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9305199092204195		[learning rate: 0.0088743]
	Learning Rate: 0.00887428
	LOSS [training: 0.9305199092204195 | validation: 1.197838275702349]
	TIME [epoch: 9.05 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9700549876031719		[learning rate: 0.0088471]
	Learning Rate: 0.00884708
	LOSS [training: 0.9700549876031719 | validation: 1.1974507012020605]
	TIME [epoch: 9.05 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9085389398768374		[learning rate: 0.00882]
	Learning Rate: 0.00881996
	LOSS [training: 0.9085389398768374 | validation: 0.7169619036511163]
	TIME [epoch: 9.05 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7392761958970873		[learning rate: 0.0087929]
	Learning Rate: 0.00879292
	LOSS [training: 0.7392761958970873 | validation: 0.5006524011548794]
	TIME [epoch: 9.06 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8510870777613626		[learning rate: 0.008766]
	Learning Rate: 0.00876597
	LOSS [training: 0.8510870777613626 | validation: 0.8442812352975082]
	TIME [epoch: 9.07 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8817052678685539		[learning rate: 0.0087391]
	Learning Rate: 0.0087391
	LOSS [training: 0.8817052678685539 | validation: 0.5965918777275715]
	TIME [epoch: 9.05 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8310344930382761		[learning rate: 0.0087123]
	Learning Rate: 0.00871231
	LOSS [training: 0.8310344930382761 | validation: 0.5957811696741488]
	TIME [epoch: 9.05 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3244420804624444		[learning rate: 0.0086856]
	Learning Rate: 0.0086856
	LOSS [training: 1.3244420804624444 | validation: 0.9120417381750434]
	TIME [epoch: 9.05 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2435731590419998		[learning rate: 0.008659]
	Learning Rate: 0.00865898
	LOSS [training: 1.2435731590419998 | validation: 0.7918707614900888]
	TIME [epoch: 9.07 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9852752783130075		[learning rate: 0.0086324]
	Learning Rate: 0.00863244
	LOSS [training: 0.9852752783130075 | validation: 1.4715351457421924]
	TIME [epoch: 9.05 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9857101544666161		[learning rate: 0.008606]
	Learning Rate: 0.00860597
	LOSS [training: 0.9857101544666161 | validation: 0.8281027926695678]
	TIME [epoch: 9.04 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2594409086313625		[learning rate: 0.0085796]
	Learning Rate: 0.00857959
	LOSS [training: 1.2594409086313625 | validation: 0.8185293243922631]
	TIME [epoch: 9.05 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0325122468748873		[learning rate: 0.0085533]
	Learning Rate: 0.00855329
	LOSS [training: 1.0325122468748873 | validation: 1.4871932239096721]
	TIME [epoch: 9.07 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8139349941448337		[learning rate: 0.0085271]
	Learning Rate: 0.00852707
	LOSS [training: 0.8139349941448337 | validation: 0.862212093496364]
	TIME [epoch: 9.05 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8387149999100492		[learning rate: 0.0085009]
	Learning Rate: 0.00850093
	LOSS [training: 0.8387149999100492 | validation: 0.7515360810433558]
	TIME [epoch: 9.05 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6681753649850726		[learning rate: 0.0084749]
	Learning Rate: 0.00847488
	LOSS [training: 0.6681753649850726 | validation: 0.4830068065108024]
	TIME [epoch: 9.05 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0654506554514822		[learning rate: 0.0084489]
	Learning Rate: 0.0084489
	LOSS [training: 1.0654506554514822 | validation: 1.8545229793379585]
	TIME [epoch: 9.07 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0691688500622807		[learning rate: 0.008423]
	Learning Rate: 0.008423
	LOSS [training: 1.0691688500622807 | validation: 0.7936457347039472]
	TIME [epoch: 9.05 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9211654850714869		[learning rate: 0.0083972]
	Learning Rate: 0.00839718
	LOSS [training: 0.9211654850714869 | validation: 0.8824837035501689]
	TIME [epoch: 9.04 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.852042934224493		[learning rate: 0.0083714]
	Learning Rate: 0.00837144
	LOSS [training: 0.852042934224493 | validation: 0.6267585003729383]
	TIME [epoch: 9.05 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7053657997137127		[learning rate: 0.0083458]
	Learning Rate: 0.00834577
	LOSS [training: 0.7053657997137127 | validation: 0.8617342567299218]
	TIME [epoch: 9.06 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.678029162808221		[learning rate: 0.0083202]
	Learning Rate: 0.00832019
	LOSS [training: 0.678029162808221 | validation: 0.4977114520678516]
	TIME [epoch: 9.06 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7552925781275313		[learning rate: 0.0082947]
	Learning Rate: 0.00829469
	LOSS [training: 0.7552925781275313 | validation: 0.8459718818657477]
	TIME [epoch: 9.06 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9692224972408411		[learning rate: 0.0082693]
	Learning Rate: 0.00826926
	LOSS [training: 0.9692224972408411 | validation: 1.2605344226494903]
	TIME [epoch: 9.05 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9407521983770989		[learning rate: 0.0082439]
	Learning Rate: 0.00824391
	LOSS [training: 0.9407521983770989 | validation: 1.4845947802389556]
	TIME [epoch: 9.06 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8368821902094006		[learning rate: 0.0082186]
	Learning Rate: 0.00821864
	LOSS [training: 0.8368821902094006 | validation: 0.8085663901371689]
	TIME [epoch: 9.07 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6378469066975836		[learning rate: 0.0081934]
	Learning Rate: 0.00819345
	LOSS [training: 0.6378469066975836 | validation: 0.3837359849891401]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7723128867396019		[learning rate: 0.0081683]
	Learning Rate: 0.00816833
	LOSS [training: 0.7723128867396019 | validation: 1.0264744980494875]
	TIME [epoch: 9.06 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8335774181134912		[learning rate: 0.0081433]
	Learning Rate: 0.00814329
	LOSS [training: 0.8335774181134912 | validation: 0.5075765250134426]
	TIME [epoch: 9.05 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.799976719040746		[learning rate: 0.0081183]
	Learning Rate: 0.00811833
	LOSS [training: 0.799976719040746 | validation: 0.46766606402962285]
	TIME [epoch: 9.07 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8797537064553793		[learning rate: 0.0080934]
	Learning Rate: 0.00809344
	LOSS [training: 0.8797537064553793 | validation: 1.132065259818219]
	TIME [epoch: 9.05 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.027904634762511		[learning rate: 0.0080686]
	Learning Rate: 0.00806863
	LOSS [training: 1.027904634762511 | validation: 0.5787990693937943]
	TIME [epoch: 9.05 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8163109575065406		[learning rate: 0.0080439]
	Learning Rate: 0.0080439
	LOSS [training: 0.8163109575065406 | validation: 0.7624646162968893]
	TIME [epoch: 9.05 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7723447081257899		[learning rate: 0.0080192]
	Learning Rate: 0.00801924
	LOSS [training: 0.7723447081257899 | validation: 1.566517549192574]
	TIME [epoch: 9.07 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7904804811279323		[learning rate: 0.0079947]
	Learning Rate: 0.00799466
	LOSS [training: 0.7904804811279323 | validation: 0.5325982819642687]
	TIME [epoch: 9.06 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.989264785883573		[learning rate: 0.0079702]
	Learning Rate: 0.00797015
	LOSS [training: 0.989264785883573 | validation: 0.9738390986116692]
	TIME [epoch: 9.05 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.713116209304415		[learning rate: 0.0079457]
	Learning Rate: 0.00794572
	LOSS [training: 0.713116209304415 | validation: 0.7715555771150422]
	TIME [epoch: 9.04 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9099114824202662		[learning rate: 0.0079214]
	Learning Rate: 0.00792136
	LOSS [training: 0.9099114824202662 | validation: 0.8583645027305172]
	TIME [epoch: 9.07 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7337942974196145		[learning rate: 0.0078971]
	Learning Rate: 0.00789708
	LOSS [training: 0.7337942974196145 | validation: 0.6944147374685349]
	TIME [epoch: 9.04 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8519859108541997		[learning rate: 0.0078729]
	Learning Rate: 0.00787287
	LOSS [training: 0.8519859108541997 | validation: 0.9454866845076082]
	TIME [epoch: 9.06 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8394912965471436		[learning rate: 0.0078487]
	Learning Rate: 0.00784874
	LOSS [training: 0.8394912965471436 | validation: 0.8087785016229618]
	TIME [epoch: 9.05 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9323923572679951		[learning rate: 0.0078247]
	Learning Rate: 0.00782468
	LOSS [training: 0.9323923572679951 | validation: 0.6079333067246944]
	TIME [epoch: 9.07 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6822998655902016		[learning rate: 0.0078007]
	Learning Rate: 0.0078007
	LOSS [training: 0.6822998655902016 | validation: 0.5381217957799933]
	TIME [epoch: 9.05 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7550790627711006		[learning rate: 0.0077768]
	Learning Rate: 0.00777678
	LOSS [training: 0.7550790627711006 | validation: 1.0487038061765706]
	TIME [epoch: 9.05 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7234921613395406		[learning rate: 0.0077529]
	Learning Rate: 0.00775294
	LOSS [training: 0.7234921613395406 | validation: 1.0997873659739517]
	TIME [epoch: 9.04 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7713107255404131		[learning rate: 0.0077292]
	Learning Rate: 0.00772918
	LOSS [training: 0.7713107255404131 | validation: 0.5948453761318271]
	TIME [epoch: 9.08 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7901920999024525		[learning rate: 0.0077055]
	Learning Rate: 0.00770548
	LOSS [training: 0.7901920999024525 | validation: 0.7126927242146067]
	TIME [epoch: 9.06 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7634870212788015		[learning rate: 0.0076819]
	Learning Rate: 0.00768186
	LOSS [training: 0.7634870212788015 | validation: 1.1385436647919973]
	TIME [epoch: 9.05 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9468798949998518		[learning rate: 0.0076583]
	Learning Rate: 0.00765832
	LOSS [training: 0.9468798949998518 | validation: 0.7157269108343309]
	TIME [epoch: 9.05 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6642437435635701		[learning rate: 0.0076348]
	Learning Rate: 0.00763484
	LOSS [training: 0.6642437435635701 | validation: 0.7103602759897659]
	TIME [epoch: 9.06 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8382171053554306		[learning rate: 0.0076114]
	Learning Rate: 0.00761144
	LOSS [training: 0.8382171053554306 | validation: 2.0042560258998505]
	TIME [epoch: 9.07 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8647600077814788		[learning rate: 0.0075881]
	Learning Rate: 0.0075881
	LOSS [training: 0.8647600077814788 | validation: 0.9471785956995642]
	TIME [epoch: 9.05 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7042074814363252		[learning rate: 0.0075648]
	Learning Rate: 0.00756484
	LOSS [training: 0.7042074814363252 | validation: 0.7501641482297896]
	TIME [epoch: 9.05 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7485019056767397		[learning rate: 0.0075417]
	Learning Rate: 0.00754165
	LOSS [training: 0.7485019056767397 | validation: 0.674139412799355]
	TIME [epoch: 9.05 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513956214511465		[learning rate: 0.0075185]
	Learning Rate: 0.00751854
	LOSS [training: 0.5513956214511465 | validation: 1.036640462439471]
	TIME [epoch: 9.07 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6666883995554593		[learning rate: 0.0074955]
	Learning Rate: 0.00749549
	LOSS [training: 0.6666883995554593 | validation: 1.0800404609872924]
	TIME [epoch: 9.05 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8124251832804934		[learning rate: 0.0074725]
	Learning Rate: 0.00747251
	LOSS [training: 0.8124251832804934 | validation: 0.6041573234718727]
	TIME [epoch: 9.05 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7700454476224339		[learning rate: 0.0074496]
	Learning Rate: 0.00744961
	LOSS [training: 0.7700454476224339 | validation: 0.7598675709564552]
	TIME [epoch: 9.04 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7079824357044094		[learning rate: 0.0074268]
	Learning Rate: 0.00742677
	LOSS [training: 0.7079824357044094 | validation: 0.6751347263155756]
	TIME [epoch: 9.07 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8382814667267897		[learning rate: 0.007404]
	Learning Rate: 0.007404
	LOSS [training: 0.8382814667267897 | validation: 1.0038530099146576]
	TIME [epoch: 9.04 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8283272000944555		[learning rate: 0.0073813]
	Learning Rate: 0.00738131
	LOSS [training: 0.8283272000944555 | validation: 0.9460771927498357]
	TIME [epoch: 9.05 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8439526336379484		[learning rate: 0.0073587]
	Learning Rate: 0.00735868
	LOSS [training: 0.8439526336379484 | validation: 0.595980834273586]
	TIME [epoch: 9.05 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1706861954647727		[learning rate: 0.0073361]
	Learning Rate: 0.00733612
	LOSS [training: 1.1706861954647727 | validation: 0.9317090380668703]
	TIME [epoch: 9.06 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.113266476944412		[learning rate: 0.0073136]
	Learning Rate: 0.00731364
	LOSS [training: 1.113266476944412 | validation: 0.9189044808892215]
	TIME [epoch: 9.04 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7950090746487963		[learning rate: 0.0072912]
	Learning Rate: 0.00729122
	LOSS [training: 0.7950090746487963 | validation: 0.6699870136037496]
	TIME [epoch: 9.04 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9291885599138704		[learning rate: 0.0072689]
	Learning Rate: 0.00726887
	LOSS [training: 0.9291885599138704 | validation: 1.0375065376214703]
	TIME [epoch: 9.05 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.724174938365843		[learning rate: 0.0072466]
	Learning Rate: 0.00724658
	LOSS [training: 0.724174938365843 | validation: 0.7743726616818396]
	TIME [epoch: 9.06 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7698807896072279		[learning rate: 0.0072244]
	Learning Rate: 0.00722437
	LOSS [training: 0.7698807896072279 | validation: 0.776823323616312]
	TIME [epoch: 9.05 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8872694294985897		[learning rate: 0.0072022]
	Learning Rate: 0.00720222
	LOSS [training: 0.8872694294985897 | validation: 1.1814599122823117]
	TIME [epoch: 9.04 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7900280005958307		[learning rate: 0.0071801]
	Learning Rate: 0.00718015
	LOSS [training: 0.7900280005958307 | validation: 0.671028384135598]
	TIME [epoch: 9.04 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9951738488782931		[learning rate: 0.0071581]
	Learning Rate: 0.00715814
	LOSS [training: 0.9951738488782931 | validation: 0.5016600774685613]
	TIME [epoch: 9.06 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6721455847033148		[learning rate: 0.0071362]
	Learning Rate: 0.00713619
	LOSS [training: 0.6721455847033148 | validation: 0.7966259341755357]
	TIME [epoch: 9.06 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7412994233204355		[learning rate: 0.0071143]
	Learning Rate: 0.00711432
	LOSS [training: 0.7412994233204355 | validation: 0.6782195365305337]
	TIME [epoch: 9.04 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8209794050730345		[learning rate: 0.0070925]
	Learning Rate: 0.00709251
	LOSS [training: 0.8209794050730345 | validation: 0.8215348168165533]
	TIME [epoch: 9.05 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7117528207229233		[learning rate: 0.0070708]
	Learning Rate: 0.00707077
	LOSS [training: 0.7117528207229233 | validation: 1.2630669828217913]
	TIME [epoch: 9.06 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7613576111207118		[learning rate: 0.0070491]
	Learning Rate: 0.00704909
	LOSS [training: 0.7613576111207118 | validation: 0.46494910533022304]
	TIME [epoch: 9.06 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6909854942178768		[learning rate: 0.0070275]
	Learning Rate: 0.00702749
	LOSS [training: 0.6909854942178768 | validation: 0.794413564525482]
	TIME [epoch: 9.04 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9175350603338883		[learning rate: 0.0070059]
	Learning Rate: 0.00700594
	LOSS [training: 0.9175350603338883 | validation: 0.7780978188167065]
	TIME [epoch: 9.06 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7208304823186185		[learning rate: 0.0069845]
	Learning Rate: 0.00698447
	LOSS [training: 0.7208304823186185 | validation: 1.1778350307296623]
	TIME [epoch: 9.06 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7702769066920462		[learning rate: 0.0069631]
	Learning Rate: 0.00696306
	LOSS [training: 0.7702769066920462 | validation: 0.5618120005509968]
	TIME [epoch: 9.08 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8094064483648147		[learning rate: 0.0069417]
	Learning Rate: 0.00694171
	LOSS [training: 0.8094064483648147 | validation: 1.2344806525194818]
	TIME [epoch: 9.06 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9269349195268269		[learning rate: 0.0069204]
	Learning Rate: 0.00692043
	LOSS [training: 0.9269349195268269 | validation: 0.6761046672522384]
	TIME [epoch: 9.05 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6750053557353676		[learning rate: 0.0068992]
	Learning Rate: 0.00689922
	LOSS [training: 0.6750053557353676 | validation: 0.5799822813750046]
	TIME [epoch: 9.05 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7990779372706835		[learning rate: 0.0068781]
	Learning Rate: 0.00687807
	LOSS [training: 0.7990779372706835 | validation: 0.7496213203011894]
	TIME [epoch: 9.07 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7405115499146354		[learning rate: 0.006857]
	Learning Rate: 0.00685699
	LOSS [training: 0.7405115499146354 | validation: 0.9912068541859259]
	TIME [epoch: 9.05 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6513656884119962		[learning rate: 0.006836]
	Learning Rate: 0.00683597
	LOSS [training: 0.6513656884119962 | validation: 0.6106024895127005]
	TIME [epoch: 9.06 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6556385294856658		[learning rate: 0.006815]
	Learning Rate: 0.00681501
	LOSS [training: 0.6556385294856658 | validation: 0.5400899703437921]
	TIME [epoch: 9.05 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6046579365775151		[learning rate: 0.0067941]
	Learning Rate: 0.00679412
	LOSS [training: 0.6046579365775151 | validation: 0.7167952225092102]
	TIME [epoch: 9.08 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6998483063981353		[learning rate: 0.0067733]
	Learning Rate: 0.00677329
	LOSS [training: 0.6998483063981353 | validation: 1.0368013800195863]
	TIME [epoch: 9.05 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8267879882363077		[learning rate: 0.0067525]
	Learning Rate: 0.00675253
	LOSS [training: 0.8267879882363077 | validation: 0.712255677920436]
	TIME [epoch: 9.05 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7558105952739865		[learning rate: 0.0067318]
	Learning Rate: 0.00673183
	LOSS [training: 0.7558105952739865 | validation: 1.457776292051013]
	TIME [epoch: 9.05 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9914221736457286		[learning rate: 0.0067112]
	Learning Rate: 0.0067112
	LOSS [training: 0.9914221736457286 | validation: 0.954320989940154]
	TIME [epoch: 9.06 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8108022436002491		[learning rate: 0.0066906]
	Learning Rate: 0.00669062
	LOSS [training: 0.8108022436002491 | validation: 0.9611571399973837]
	TIME [epoch: 9.06 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8905142988048281		[learning rate: 0.0066701]
	Learning Rate: 0.00667012
	LOSS [training: 0.8905142988048281 | validation: 1.2341183270768106]
	TIME [epoch: 9.04 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5723996739814449		[learning rate: 0.0066497]
	Learning Rate: 0.00664967
	LOSS [training: 0.5723996739814449 | validation: 0.8340578845511841]
	TIME [epoch: 9.05 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5745623756115561		[learning rate: 0.0066293]
	Learning Rate: 0.00662928
	LOSS [training: 0.5745623756115561 | validation: 0.7494631011976428]
	TIME [epoch: 9.06 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7682229191281509		[learning rate: 0.006609]
	Learning Rate: 0.00660896
	LOSS [training: 0.7682229191281509 | validation: 0.5353083874726693]
	TIME [epoch: 9.06 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8257169758328574		[learning rate: 0.0065887]
	Learning Rate: 0.0065887
	LOSS [training: 0.8257169758328574 | validation: 1.0597406035842218]
	TIME [epoch: 9.05 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9132137193753536		[learning rate: 0.0065685]
	Learning Rate: 0.00656851
	LOSS [training: 0.9132137193753536 | validation: 0.7617411603680482]
	TIME [epoch: 9.05 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6070666533836708		[learning rate: 0.0065484]
	Learning Rate: 0.00654837
	LOSS [training: 0.6070666533836708 | validation: 0.5025906823514977]
	TIME [epoch: 9.05 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7094452251235625		[learning rate: 0.0065283]
	Learning Rate: 0.0065283
	LOSS [training: 0.7094452251235625 | validation: 0.6052840602258973]
	TIME [epoch: 9.07 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6495703477875567		[learning rate: 0.0065083]
	Learning Rate: 0.00650829
	LOSS [training: 0.6495703477875567 | validation: 0.842573584870285]
	TIME [epoch: 9.05 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6912939806543789		[learning rate: 0.0064883]
	Learning Rate: 0.00648834
	LOSS [training: 0.6912939806543789 | validation: 0.7675995697207247]
	TIME [epoch: 9.04 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.710278314876031		[learning rate: 0.0064684]
	Learning Rate: 0.00646845
	LOSS [training: 0.710278314876031 | validation: 0.547381750387012]
	TIME [epoch: 9.04 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.573920090256903		[learning rate: 0.0064486]
	Learning Rate: 0.00644862
	LOSS [training: 0.573920090256903 | validation: 0.7605740614422751]
	TIME [epoch: 9.07 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8330943768341259		[learning rate: 0.0064289]
	Learning Rate: 0.00642885
	LOSS [training: 0.8330943768341259 | validation: 1.1509558828813775]
	TIME [epoch: 9.04 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7890173113580328		[learning rate: 0.0064091]
	Learning Rate: 0.00640914
	LOSS [training: 0.7890173113580328 | validation: 1.3911108759838828]
	TIME [epoch: 9.05 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9731141970385687		[learning rate: 0.0063895]
	Learning Rate: 0.0063895
	LOSS [training: 0.9731141970385687 | validation: 0.48506689913843415]
	TIME [epoch: 9.05 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6987196848441284		[learning rate: 0.0063699]
	Learning Rate: 0.00636991
	LOSS [training: 0.6987196848441284 | validation: 0.748308914030904]
	TIME [epoch: 9.07 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7520823754850191		[learning rate: 0.0063504]
	Learning Rate: 0.00635038
	LOSS [training: 0.7520823754850191 | validation: 1.3237048455143627]
	TIME [epoch: 9.05 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0462036710807225		[learning rate: 0.0063309]
	Learning Rate: 0.00633092
	LOSS [training: 1.0462036710807225 | validation: 0.9899461264611571]
	TIME [epoch: 9.05 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8148453080184568		[learning rate: 0.0063115]
	Learning Rate: 0.00631151
	LOSS [training: 0.8148453080184568 | validation: 0.79632861501332]
	TIME [epoch: 9.05 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6930787412944115		[learning rate: 0.0062922]
	Learning Rate: 0.00629216
	LOSS [training: 0.6930787412944115 | validation: 1.0004065158935245]
	TIME [epoch: 9.07 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8722539963772545		[learning rate: 0.0062729]
	Learning Rate: 0.00627288
	LOSS [training: 0.8722539963772545 | validation: 1.0312806028272274]
	TIME [epoch: 9.06 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.747141157017123		[learning rate: 0.0062536]
	Learning Rate: 0.00625365
	LOSS [training: 0.747141157017123 | validation: 0.8507181149314959]
	TIME [epoch: 9.05 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.72573767013292		[learning rate: 0.0062345]
	Learning Rate: 0.00623448
	LOSS [training: 0.72573767013292 | validation: 1.019465305692989]
	TIME [epoch: 9.05 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7802620210971599		[learning rate: 0.0062154]
	Learning Rate: 0.00621536
	LOSS [training: 0.7802620210971599 | validation: 0.7208106037085259]
	TIME [epoch: 9.06 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7736645074441093		[learning rate: 0.0061963]
	Learning Rate: 0.00619631
	LOSS [training: 0.7736645074441093 | validation: 0.5160690664493338]
	TIME [epoch: 9.07 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7298947204380418		[learning rate: 0.0061773]
	Learning Rate: 0.00617732
	LOSS [training: 0.7298947204380418 | validation: 0.6950984557372802]
	TIME [epoch: 9.05 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9141897244934505		[learning rate: 0.0061584]
	Learning Rate: 0.00615838
	LOSS [training: 0.9141897244934505 | validation: 0.7224200656403801]
	TIME [epoch: 9.05 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.734861393234602		[learning rate: 0.0061395]
	Learning Rate: 0.0061395
	LOSS [training: 0.734861393234602 | validation: 0.5184095100945613]
	TIME [epoch: 9.06 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6777421991690884		[learning rate: 0.0061207]
	Learning Rate: 0.00612068
	LOSS [training: 0.6777421991690884 | validation: 0.772811172333467]
	TIME [epoch: 9.07 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7358470532342315		[learning rate: 0.0061019]
	Learning Rate: 0.00610192
	LOSS [training: 0.7358470532342315 | validation: 0.5658975255341072]
	TIME [epoch: 9.05 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8239306388105346		[learning rate: 0.0060832]
	Learning Rate: 0.00608322
	LOSS [training: 0.8239306388105346 | validation: 0.7693888443189717]
	TIME [epoch: 9.05 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6578322089696094		[learning rate: 0.0060646]
	Learning Rate: 0.00606457
	LOSS [training: 0.6578322089696094 | validation: 0.5348457337019097]
	TIME [epoch: 9.05 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5589461690663339		[learning rate: 0.006046]
	Learning Rate: 0.00604598
	LOSS [training: 0.5589461690663339 | validation: 0.5767495444385249]
	TIME [epoch: 9.07 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5806006575355288		[learning rate: 0.0060274]
	Learning Rate: 0.00602745
	LOSS [training: 0.5806006575355288 | validation: 0.4662153720341148]
	TIME [epoch: 9.05 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6654178709624842		[learning rate: 0.006009]
	Learning Rate: 0.00600897
	LOSS [training: 0.6654178709624842 | validation: 0.6795759040025342]
	TIME [epoch: 9.04 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7464082918383728		[learning rate: 0.0059905]
	Learning Rate: 0.00599055
	LOSS [training: 0.7464082918383728 | validation: 0.7362180900115627]
	TIME [epoch: 9.05 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6177782779791013		[learning rate: 0.0059722]
	Learning Rate: 0.00597219
	LOSS [training: 0.6177782779791013 | validation: 1.3700993897249538]
	TIME [epoch: 9.08 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7852713597424363		[learning rate: 0.0059539]
	Learning Rate: 0.00595388
	LOSS [training: 0.7852713597424363 | validation: 0.685395431239711]
	TIME [epoch: 9.06 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5817568738519721		[learning rate: 0.0059356]
	Learning Rate: 0.00593563
	LOSS [training: 0.5817568738519721 | validation: 0.4817801767311442]
	TIME [epoch: 9.05 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7055803934012745		[learning rate: 0.0059174]
	Learning Rate: 0.00591743
	LOSS [training: 0.7055803934012745 | validation: 0.4152600710344272]
	TIME [epoch: 9.05 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5297610699018385		[learning rate: 0.0058993]
	Learning Rate: 0.00589929
	LOSS [training: 0.5297610699018385 | validation: 0.8649932440992192]
	TIME [epoch: 9.06 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6458965845297001		[learning rate: 0.0058812]
	Learning Rate: 0.00588121
	LOSS [training: 0.6458965845297001 | validation: 1.0121676081348217]
	TIME [epoch: 9.05 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7493097818947072		[learning rate: 0.0058632]
	Learning Rate: 0.00586318
	LOSS [training: 0.7493097818947072 | validation: 1.2069209904371134]
	TIME [epoch: 9.05 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6642192226584612		[learning rate: 0.0058452]
	Learning Rate: 0.00584521
	LOSS [training: 0.6642192226584612 | validation: 0.6499282062102202]
	TIME [epoch: 9.06 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9066309091447661		[learning rate: 0.0058273]
	Learning Rate: 0.00582729
	LOSS [training: 0.9066309091447661 | validation: 0.9338691866050259]
	TIME [epoch: 9.06 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9173793351370951		[learning rate: 0.0058094]
	Learning Rate: 0.00580943
	LOSS [training: 0.9173793351370951 | validation: 0.8598765972380475]
	TIME [epoch: 9.06 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9480829810920006		[learning rate: 0.0057916]
	Learning Rate: 0.00579162
	LOSS [training: 0.9480829810920006 | validation: 0.9642570973189994]
	TIME [epoch: 9.05 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8523639171062521		[learning rate: 0.0057739]
	Learning Rate: 0.00577387
	LOSS [training: 0.8523639171062521 | validation: 0.3751116868267764]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5387901180351009		[learning rate: 0.0057562]
	Learning Rate: 0.00575617
	LOSS [training: 0.5387901180351009 | validation: 0.5032433054190746]
	TIME [epoch: 9.06 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7436601142600738		[learning rate: 0.0057385]
	Learning Rate: 0.00573852
	LOSS [training: 0.7436601142600738 | validation: 0.6578136996197572]
	TIME [epoch: 9.06 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6884011078585429		[learning rate: 0.0057209]
	Learning Rate: 0.00572093
	LOSS [training: 0.6884011078585429 | validation: 0.7090210306098395]
	TIME [epoch: 9.07 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6371712687072499		[learning rate: 0.0057034]
	Learning Rate: 0.00570339
	LOSS [training: 0.6371712687072499 | validation: 0.43582304310498077]
	TIME [epoch: 9.05 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4942767687828057		[learning rate: 0.0056859]
	Learning Rate: 0.00568591
	LOSS [training: 0.4942767687828057 | validation: 0.8769450919555274]
	TIME [epoch: 9.05 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5370342939951517		[learning rate: 0.0056685]
	Learning Rate: 0.00566848
	LOSS [training: 0.5370342939951517 | validation: 0.6603156983932909]
	TIME [epoch: 9.07 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5015975068073631		[learning rate: 0.0056511]
	Learning Rate: 0.0056511
	LOSS [training: 0.5015975068073631 | validation: 0.3982924405777809]
	TIME [epoch: 9.05 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7706634377438366		[learning rate: 0.0056338]
	Learning Rate: 0.00563378
	LOSS [training: 0.7706634377438366 | validation: 0.4978645529940324]
	TIME [epoch: 9.05 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5127470291774257		[learning rate: 0.0056165]
	Learning Rate: 0.00561651
	LOSS [training: 0.5127470291774257 | validation: 1.0900888399495727]
	TIME [epoch: 9.05 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.419729800346484		[learning rate: 0.0055993]
	Learning Rate: 0.00559929
	LOSS [training: 1.419729800346484 | validation: 1.1785176784385805]
	TIME [epoch: 9.07 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8722535794298659		[learning rate: 0.0055821]
	Learning Rate: 0.00558213
	LOSS [training: 0.8722535794298659 | validation: 0.7328738767762323]
	TIME [epoch: 9.05 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5815448283951018		[learning rate: 0.005565]
	Learning Rate: 0.00556502
	LOSS [training: 0.5815448283951018 | validation: 0.4198850614382239]
	TIME [epoch: 9.05 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5566731640736186		[learning rate: 0.005548]
	Learning Rate: 0.00554796
	LOSS [training: 0.5566731640736186 | validation: 0.8034086762271502]
	TIME [epoch: 9.06 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5515892508766254		[learning rate: 0.005531]
	Learning Rate: 0.00553095
	LOSS [training: 0.5515892508766254 | validation: 0.420338357694495]
	TIME [epoch: 9.07 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4600639668403059		[learning rate: 0.005514]
	Learning Rate: 0.005514
	LOSS [training: 0.4600639668403059 | validation: 0.45557071087084716]
	TIME [epoch: 9.06 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7022172140138168		[learning rate: 0.0054971]
	Learning Rate: 0.0054971
	LOSS [training: 0.7022172140138168 | validation: 0.6165330615581265]
	TIME [epoch: 9.05 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7200396969109393		[learning rate: 0.0054802]
	Learning Rate: 0.00548025
	LOSS [training: 0.7200396969109393 | validation: 0.5106527133516262]
	TIME [epoch: 9.05 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8153030181257968		[learning rate: 0.0054634]
	Learning Rate: 0.00546345
	LOSS [training: 0.8153030181257968 | validation: 0.39004020236954595]
	TIME [epoch: 9.07 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6004122190013195		[learning rate: 0.0054467]
	Learning Rate: 0.0054467
	LOSS [training: 0.6004122190013195 | validation: 0.78791550509663]
	TIME [epoch: 9.06 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5189980987378375		[learning rate: 0.00543]
	Learning Rate: 0.00543
	LOSS [training: 0.5189980987378375 | validation: 0.4173486725620545]
	TIME [epoch: 9.05 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5238464732246177		[learning rate: 0.0054134]
	Learning Rate: 0.00541336
	LOSS [training: 0.5238464732246177 | validation: 0.6422823120277541]
	TIME [epoch: 9.05 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6030877246350229		[learning rate: 0.0053968]
	Learning Rate: 0.00539676
	LOSS [training: 0.6030877246350229 | validation: 0.6067445967412859]
	TIME [epoch: 9.06 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.588616195758661		[learning rate: 0.0053802]
	Learning Rate: 0.00538022
	LOSS [training: 0.588616195758661 | validation: 2.2925243660409027]
	TIME [epoch: 9.07 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2153617369414174		[learning rate: 0.0053637]
	Learning Rate: 0.00536373
	LOSS [training: 1.2153617369414174 | validation: 0.7739589044148303]
	TIME [epoch: 9.05 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.784081900116267		[learning rate: 0.0053473]
	Learning Rate: 0.00534728
	LOSS [training: 0.784081900116267 | validation: 0.5354333996396087]
	TIME [epoch: 9.05 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6318544738779897		[learning rate: 0.0053309]
	Learning Rate: 0.00533089
	LOSS [training: 0.6318544738779897 | validation: 0.7762347275804826]
	TIME [epoch: 9.06 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6423051015495738		[learning rate: 0.0053146]
	Learning Rate: 0.00531455
	LOSS [training: 0.6423051015495738 | validation: 0.45054220454688565]
	TIME [epoch: 9.08 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5272356821444883		[learning rate: 0.0052983]
	Learning Rate: 0.00529826
	LOSS [training: 0.5272356821444883 | validation: 0.4557096466350433]
	TIME [epoch: 9.04 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5128888268556333		[learning rate: 0.005282]
	Learning Rate: 0.00528202
	LOSS [training: 0.5128888268556333 | validation: 0.4484649261909286]
	TIME [epoch: 9.05 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5940965218882738		[learning rate: 0.0052658]
	Learning Rate: 0.00526583
	LOSS [training: 0.5940965218882738 | validation: 0.47323426044426603]
	TIME [epoch: 9.05 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5110083412312354		[learning rate: 0.0052497]
	Learning Rate: 0.00524969
	LOSS [training: 0.5110083412312354 | validation: 0.5156825226347339]
	TIME [epoch: 9.08 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5697133716511297		[learning rate: 0.0052336]
	Learning Rate: 0.00523359
	LOSS [training: 0.5697133716511297 | validation: 0.9036229387464896]
	TIME [epoch: 9.05 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6009841329970417		[learning rate: 0.0052176]
	Learning Rate: 0.00521755
	LOSS [training: 0.6009841329970417 | validation: 0.35180656444432556]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4388943679628571		[learning rate: 0.0052016]
	Learning Rate: 0.00520156
	LOSS [training: 0.4388943679628571 | validation: 0.25119215059943545]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_713.pth
	Model improved!!!
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47509162359934953		[learning rate: 0.0051856]
	Learning Rate: 0.00518561
	LOSS [training: 0.47509162359934953 | validation: 0.3604763706082681]
	TIME [epoch: 9.08 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5404045076058186		[learning rate: 0.0051697]
	Learning Rate: 0.00516972
	LOSS [training: 0.5404045076058186 | validation: 0.4933088099840707]
	TIME [epoch: 9.05 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7961360243471663		[learning rate: 0.0051539]
	Learning Rate: 0.00515387
	LOSS [training: 0.7961360243471663 | validation: 0.4383267469130471]
	TIME [epoch: 9.05 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4171958630730197		[learning rate: 0.0051381]
	Learning Rate: 0.00513807
	LOSS [training: 0.4171958630730197 | validation: 0.6584019693972577]
	TIME [epoch: 9.05 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7191690082209075		[learning rate: 0.0051223]
	Learning Rate: 0.00512232
	LOSS [training: 0.7191690082209075 | validation: 1.1925337179997015]
	TIME [epoch: 9.08 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7092086364795057		[learning rate: 0.0051066]
	Learning Rate: 0.00510662
	LOSS [training: 0.7092086364795057 | validation: 0.86935425257975]
	TIME [epoch: 9.05 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116666512014248		[learning rate: 0.005091]
	Learning Rate: 0.00509096
	LOSS [training: 0.6116666512014248 | validation: 0.47972161303124583]
	TIME [epoch: 9.04 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7101171446478605		[learning rate: 0.0050754]
	Learning Rate: 0.00507536
	LOSS [training: 0.7101171446478605 | validation: 0.9246972350959517]
	TIME [epoch: 9.05 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7655561806531935		[learning rate: 0.0050598]
	Learning Rate: 0.0050598
	LOSS [training: 0.7655561806531935 | validation: 1.0146271382007501]
	TIME [epoch: 9.06 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5631927991821397		[learning rate: 0.0050443]
	Learning Rate: 0.00504429
	LOSS [training: 0.5631927991821397 | validation: 0.40630139330204007]
	TIME [epoch: 9.07 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47388541577076604		[learning rate: 0.0050288]
	Learning Rate: 0.00502883
	LOSS [training: 0.47388541577076604 | validation: 0.6258922590833951]
	TIME [epoch: 9.04 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.371083113796302		[learning rate: 0.0050134]
	Learning Rate: 0.00501341
	LOSS [training: 0.371083113796302 | validation: 0.2839817280708832]
	TIME [epoch: 9.05 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4224191320872125		[learning rate: 0.004998]
	Learning Rate: 0.00499804
	LOSS [training: 0.4224191320872125 | validation: 0.3175488767149415]
	TIME [epoch: 9.06 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45522076433807773		[learning rate: 0.0049827]
	Learning Rate: 0.00498272
	LOSS [training: 0.45522076433807773 | validation: 0.4392126553409349]
	TIME [epoch: 9.07 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6240618122410515		[learning rate: 0.0049674]
	Learning Rate: 0.00496745
	LOSS [training: 0.6240618122410515 | validation: 0.4260989828448116]
	TIME [epoch: 9.06 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4184073169106116		[learning rate: 0.0049522]
	Learning Rate: 0.00495222
	LOSS [training: 0.4184073169106116 | validation: 0.647566750417174]
	TIME [epoch: 9.06 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4766640906292422		[learning rate: 0.004937]
	Learning Rate: 0.00493704
	LOSS [training: 0.4766640906292422 | validation: 0.38463303585601505]
	TIME [epoch: 9.06 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46981760114880017		[learning rate: 0.0049219]
	Learning Rate: 0.00492191
	LOSS [training: 0.46981760114880017 | validation: 0.34724956729292256]
	TIME [epoch: 9.07 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.437799262426627		[learning rate: 0.0049068]
	Learning Rate: 0.00490682
	LOSS [training: 0.437799262426627 | validation: 0.494188287416676]
	TIME [epoch: 9.06 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4896840027102427		[learning rate: 0.0048918]
	Learning Rate: 0.00489178
	LOSS [training: 0.4896840027102427 | validation: 0.43446166144537274]
	TIME [epoch: 9.05 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48832616510427646		[learning rate: 0.0048768]
	Learning Rate: 0.00487678
	LOSS [training: 0.48832616510427646 | validation: 0.37981348827638717]
	TIME [epoch: 9.06 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3957507706402228		[learning rate: 0.0048618]
	Learning Rate: 0.00486183
	LOSS [training: 0.3957507706402228 | validation: 0.4073555201638108]
	TIME [epoch: 9.09 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4353251620502821		[learning rate: 0.0048469]
	Learning Rate: 0.00484693
	LOSS [training: 0.4353251620502821 | validation: 0.43966406572041405]
	TIME [epoch: 9.06 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4068511448913738		[learning rate: 0.0048321]
	Learning Rate: 0.00483207
	LOSS [training: 0.4068511448913738 | validation: 0.3056110457580228]
	TIME [epoch: 9.05 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4194442396571828		[learning rate: 0.0048173]
	Learning Rate: 0.00481726
	LOSS [training: 0.4194442396571828 | validation: 0.2664304304757632]
	TIME [epoch: 9.06 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31957103352155525		[learning rate: 0.0048025]
	Learning Rate: 0.00480249
	LOSS [training: 0.31957103352155525 | validation: 0.34738659853909554]
	TIME [epoch: 9.08 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44534982863599504		[learning rate: 0.0047878]
	Learning Rate: 0.00478777
	LOSS [training: 0.44534982863599504 | validation: 0.5236247335698614]
	TIME [epoch: 9.07 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43297930705793775		[learning rate: 0.0047731]
	Learning Rate: 0.00477309
	LOSS [training: 0.43297930705793775 | validation: 0.5180988480693093]
	TIME [epoch: 9.06 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.459589002666691		[learning rate: 0.0047585]
	Learning Rate: 0.00475846
	LOSS [training: 0.459589002666691 | validation: 0.4264849602481442]
	TIME [epoch: 9.05 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36307002530988813		[learning rate: 0.0047439]
	Learning Rate: 0.00474388
	LOSS [training: 0.36307002530988813 | validation: 0.8787562807390943]
	TIME [epoch: 9.07 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282483480727499		[learning rate: 0.0047293]
	Learning Rate: 0.00472933
	LOSS [training: 0.5282483480727499 | validation: 0.7445960821795549]
	TIME [epoch: 9.05 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7557595564577817		[learning rate: 0.0047148]
	Learning Rate: 0.00471484
	LOSS [training: 0.7557595564577817 | validation: 0.6079011203937548]
	TIME [epoch: 9.05 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6368648268319747		[learning rate: 0.0047004]
	Learning Rate: 0.00470038
	LOSS [training: 0.6368648268319747 | validation: 0.7232047616751979]
	TIME [epoch: 9.05 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5382215243500753		[learning rate: 0.004686]
	Learning Rate: 0.00468598
	LOSS [training: 0.5382215243500753 | validation: 0.811362911372178]
	TIME [epoch: 9.06 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4836036805304305		[learning rate: 0.0046716]
	Learning Rate: 0.00467161
	LOSS [training: 0.4836036805304305 | validation: 0.36422204716423634]
	TIME [epoch: 9.06 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48034958999397714		[learning rate: 0.0046573]
	Learning Rate: 0.00465729
	LOSS [training: 0.48034958999397714 | validation: 0.5522199924557845]
	TIME [epoch: 9.05 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5025039700041656		[learning rate: 0.004643]
	Learning Rate: 0.00464301
	LOSS [training: 0.5025039700041656 | validation: 0.3004053637016504]
	TIME [epoch: 9.04 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5224108077446707		[learning rate: 0.0046288]
	Learning Rate: 0.00462878
	LOSS [training: 0.5224108077446707 | validation: 0.3918329855900745]
	TIME [epoch: 9.05 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43756019278701314		[learning rate: 0.0046146]
	Learning Rate: 0.00461459
	LOSS [training: 0.43756019278701314 | validation: 0.4288979954442147]
	TIME [epoch: 9.07 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520733877616419		[learning rate: 0.0046004]
	Learning Rate: 0.00460045
	LOSS [training: 0.3520733877616419 | validation: 0.4161693621148189]
	TIME [epoch: 9.05 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5888072384803595		[learning rate: 0.0045863]
	Learning Rate: 0.00458634
	LOSS [training: 0.5888072384803595 | validation: 0.639891131515973]
	TIME [epoch: 9.05 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3374022220612729		[learning rate: 0.0045723]
	Learning Rate: 0.00457229
	LOSS [training: 0.3374022220612729 | validation: 0.34542214223594114]
	TIME [epoch: 9.06 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3780175877742335		[learning rate: 0.0045583]
	Learning Rate: 0.00455827
	LOSS [training: 0.3780175877742335 | validation: 0.6446183274500232]
	TIME [epoch: 9.08 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36576938405324355		[learning rate: 0.0045443]
	Learning Rate: 0.0045443
	LOSS [training: 0.36576938405324355 | validation: 0.36919556681771215]
	TIME [epoch: 9.06 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5579761655318787		[learning rate: 0.0045304]
	Learning Rate: 0.00453037
	LOSS [training: 0.5579761655318787 | validation: 0.22521676018706233]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35435637122383723		[learning rate: 0.0045165]
	Learning Rate: 0.00451648
	LOSS [training: 0.35435637122383723 | validation: 0.32059048716264826]
	TIME [epoch: 9.06 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3414793101606074		[learning rate: 0.0045026]
	Learning Rate: 0.00450263
	LOSS [training: 0.3414793101606074 | validation: 0.28587033308085397]
	TIME [epoch: 9.09 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5507040536606607		[learning rate: 0.0044888]
	Learning Rate: 0.00448883
	LOSS [training: 0.5507040536606607 | validation: 0.4288539334394075]
	TIME [epoch: 9.07 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4876781932716591		[learning rate: 0.0044751]
	Learning Rate: 0.00447507
	LOSS [training: 0.4876781932716591 | validation: 0.24585614043279624]
	TIME [epoch: 9.07 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757309714219648		[learning rate: 0.0044614]
	Learning Rate: 0.00446135
	LOSS [training: 0.3757309714219648 | validation: 0.349556909234917]
	TIME [epoch: 9.07 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3185083961404767		[learning rate: 0.0044477]
	Learning Rate: 0.00444768
	LOSS [training: 0.3185083961404767 | validation: 0.2539167943412459]
	TIME [epoch: 9.07 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3429461696167439		[learning rate: 0.004434]
	Learning Rate: 0.00443404
	LOSS [training: 0.3429461696167439 | validation: 0.16416956318487294]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_765.pth
	Model improved!!!
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2829492209900295		[learning rate: 0.0044205]
	Learning Rate: 0.00442045
	LOSS [training: 0.2829492209900295 | validation: 0.4616786356422278]
	TIME [epoch: 9.07 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36360315029654944		[learning rate: 0.0044069]
	Learning Rate: 0.0044069
	LOSS [training: 0.36360315029654944 | validation: 0.25305797631235283]
	TIME [epoch: 9.06 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24991741151148875		[learning rate: 0.0043934]
	Learning Rate: 0.00439339
	LOSS [training: 0.24991741151148875 | validation: 0.46717476842291017]
	TIME [epoch: 9.07 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30867458192410885		[learning rate: 0.0043799]
	Learning Rate: 0.00437992
	LOSS [training: 0.30867458192410885 | validation: 0.16673451959536398]
	TIME [epoch: 9.09 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40616714995162484		[learning rate: 0.0043665]
	Learning Rate: 0.0043665
	LOSS [training: 0.40616714995162484 | validation: 0.26307604290797454]
	TIME [epoch: 9.07 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4977481597150531		[learning rate: 0.0043531]
	Learning Rate: 0.00435311
	LOSS [training: 0.4977481597150531 | validation: 0.5333803126325773]
	TIME [epoch: 9.06 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37981122166362313		[learning rate: 0.0043398]
	Learning Rate: 0.00433977
	LOSS [training: 0.37981122166362313 | validation: 0.3433304890133332]
	TIME [epoch: 9.07 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33534618404096966		[learning rate: 0.0043265]
	Learning Rate: 0.00432647
	LOSS [training: 0.33534618404096966 | validation: 0.2950007425870357]
	TIME [epoch: 9.09 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29771772509553995		[learning rate: 0.0043132]
	Learning Rate: 0.0043132
	LOSS [training: 0.29771772509553995 | validation: 0.2379732252633391]
	TIME [epoch: 9.07 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29218720093916695		[learning rate: 0.0043]
	Learning Rate: 0.00429998
	LOSS [training: 0.29218720093916695 | validation: 0.2350532624323969]
	TIME [epoch: 9.07 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5710920916116311		[learning rate: 0.0042868]
	Learning Rate: 0.0042868
	LOSS [training: 0.5710920916116311 | validation: 0.43894714939867246]
	TIME [epoch: 9.09 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38807510158319847		[learning rate: 0.0042737]
	Learning Rate: 0.00427366
	LOSS [training: 0.38807510158319847 | validation: 0.18177995944212152]
	TIME [epoch: 9.08 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3207901024763674		[learning rate: 0.0042606]
	Learning Rate: 0.00426056
	LOSS [training: 0.3207901024763674 | validation: 0.3050440355580846]
	TIME [epoch: 9.07 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33474949887494126		[learning rate: 0.0042475]
	Learning Rate: 0.0042475
	LOSS [training: 0.33474949887494126 | validation: 0.4035556536248719]
	TIME [epoch: 9.06 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3314058378982608		[learning rate: 0.0042345]
	Learning Rate: 0.00423448
	LOSS [training: 0.3314058378982608 | validation: 0.19901159790148937]
	TIME [epoch: 9.07 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3966719872638925		[learning rate: 0.0042215]
	Learning Rate: 0.0042215
	LOSS [training: 0.3966719872638925 | validation: 0.22686508129006588]
	TIME [epoch: 9.09 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27811237667407		[learning rate: 0.0042086]
	Learning Rate: 0.00420856
	LOSS [training: 0.27811237667407 | validation: 0.20688598157303828]
	TIME [epoch: 9.07 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3038384509008221		[learning rate: 0.0041957]
	Learning Rate: 0.00419566
	LOSS [training: 0.3038384509008221 | validation: 0.21234717848563872]
	TIME [epoch: 9.07 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32221708040324715		[learning rate: 0.0041828]
	Learning Rate: 0.0041828
	LOSS [training: 0.32221708040324715 | validation: 0.2661201378183405]
	TIME [epoch: 9.07 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3087298126211276		[learning rate: 0.00417]
	Learning Rate: 0.00416997
	LOSS [training: 0.3087298126211276 | validation: 0.19215902141710078]
	TIME [epoch: 9.07 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31658866766126686		[learning rate: 0.0041572]
	Learning Rate: 0.00415719
	LOSS [training: 0.31658866766126686 | validation: 0.8390344812864933]
	TIME [epoch: 9.08 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3619214941288384		[learning rate: 0.0041444]
	Learning Rate: 0.00414445
	LOSS [training: 0.3619214941288384 | validation: 0.2907031855941971]
	TIME [epoch: 9.07 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31461665105996206		[learning rate: 0.0041317]
	Learning Rate: 0.00413174
	LOSS [training: 0.31461665105996206 | validation: 0.40753596416684457]
	TIME [epoch: 9.07 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27991500387336093		[learning rate: 0.0041191]
	Learning Rate: 0.00411908
	LOSS [training: 0.27991500387336093 | validation: 0.46136674850943293]
	TIME [epoch: 9.08 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2568442322540133		[learning rate: 0.0041065]
	Learning Rate: 0.00410645
	LOSS [training: 0.2568442322540133 | validation: 0.27635156866676214]
	TIME [epoch: 9.08 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28503605828620515		[learning rate: 0.0040939]
	Learning Rate: 0.00409386
	LOSS [training: 0.28503605828620515 | validation: 0.24844022015830386]
	TIME [epoch: 9.07 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28184027969918757		[learning rate: 0.0040813]
	Learning Rate: 0.00408131
	LOSS [training: 0.28184027969918757 | validation: 0.34656921502536653]
	TIME [epoch: 9.07 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3420867998283987		[learning rate: 0.0040688]
	Learning Rate: 0.0040688
	LOSS [training: 0.3420867998283987 | validation: 0.4673308666775118]
	TIME [epoch: 9.07 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3572078962044313		[learning rate: 0.0040563]
	Learning Rate: 0.00405633
	LOSS [training: 0.3572078962044313 | validation: 0.2779731802486984]
	TIME [epoch: 9.09 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059470943273026		[learning rate: 0.0040439]
	Learning Rate: 0.0040439
	LOSS [training: 0.3059470943273026 | validation: 0.3725498563649584]
	TIME [epoch: 9.07 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35474606497085853		[learning rate: 0.0040315]
	Learning Rate: 0.0040315
	LOSS [training: 0.35474606497085853 | validation: 0.41384798448455307]
	TIME [epoch: 9.07 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30594704272509265		[learning rate: 0.0040191]
	Learning Rate: 0.00401914
	LOSS [training: 0.30594704272509265 | validation: 0.5848763885405348]
	TIME [epoch: 9.07 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4477374355963053		[learning rate: 0.0040068]
	Learning Rate: 0.00400682
	LOSS [training: 0.4477374355963053 | validation: 0.40723092127624827]
	TIME [epoch: 9.09 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4874651795502176		[learning rate: 0.0039945]
	Learning Rate: 0.00399454
	LOSS [training: 0.4874651795502176 | validation: 0.5416600776381355]
	TIME [epoch: 9.07 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35203605352153355		[learning rate: 0.0039823]
	Learning Rate: 0.00398229
	LOSS [training: 0.35203605352153355 | validation: 0.43482547644489394]
	TIME [epoch: 9.07 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4582745336715407		[learning rate: 0.0039701]
	Learning Rate: 0.00397009
	LOSS [training: 0.4582745336715407 | validation: 0.5047577032429705]
	TIME [epoch: 9.07 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3869956823810179		[learning rate: 0.0039579]
	Learning Rate: 0.00395792
	LOSS [training: 0.3869956823810179 | validation: 0.2140018219348372]
	TIME [epoch: 9.09 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3750581670951346		[learning rate: 0.0039458]
	Learning Rate: 0.00394578
	LOSS [training: 0.3750581670951346 | validation: 0.41520559721406763]
	TIME [epoch: 9.07 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2872924630040855		[learning rate: 0.0039337]
	Learning Rate: 0.00393369
	LOSS [training: 0.2872924630040855 | validation: 0.17337691186129162]
	TIME [epoch: 9.07 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956429533676009		[learning rate: 0.0039216]
	Learning Rate: 0.00392163
	LOSS [training: 0.2956429533676009 | validation: 0.45304006826705195]
	TIME [epoch: 9.07 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3773085503551098		[learning rate: 0.0039096]
	Learning Rate: 0.00390961
	LOSS [training: 0.3773085503551098 | validation: 0.5266549201756189]
	TIME [epoch: 9.08 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36978367486916275		[learning rate: 0.0038976]
	Learning Rate: 0.00389762
	LOSS [training: 0.36978367486916275 | validation: 0.4729168974753226]
	TIME [epoch: 9.07 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684429414027433		[learning rate: 0.0038857]
	Learning Rate: 0.00388568
	LOSS [training: 0.3684429414027433 | validation: 0.38492264281465893]
	TIME [epoch: 9.07 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3459157644189948		[learning rate: 0.0038738]
	Learning Rate: 0.00387377
	LOSS [training: 0.3459157644189948 | validation: 0.26146375790684356]
	TIME [epoch: 9.07 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34825497959162866		[learning rate: 0.0038619]
	Learning Rate: 0.00386189
	LOSS [training: 0.34825497959162866 | validation: 0.21593311094121617]
	TIME [epoch: 9.08 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2934753758328137		[learning rate: 0.0038501]
	Learning Rate: 0.00385005
	LOSS [training: 0.2934753758328137 | validation: 0.29313947860708056]
	TIME [epoch: 9.08 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30835396497761947		[learning rate: 0.0038383]
	Learning Rate: 0.00383825
	LOSS [training: 0.30835396497761947 | validation: 0.20713531300746252]
	TIME [epoch: 9.07 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28522659840036946		[learning rate: 0.0038265]
	Learning Rate: 0.00382648
	LOSS [training: 0.28522659840036946 | validation: 0.23216115257885878]
	TIME [epoch: 9.06 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3620092402446079		[learning rate: 0.0038148]
	Learning Rate: 0.00381476
	LOSS [training: 0.3620092402446079 | validation: 0.16675135241470262]
	TIME [epoch: 9.07 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23488449067630696		[learning rate: 0.0038031]
	Learning Rate: 0.00380306
	LOSS [training: 0.23488449067630696 | validation: 0.21359015565314798]
	TIME [epoch: 9.09 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2651101334894208		[learning rate: 0.0037914]
	Learning Rate: 0.0037914
	LOSS [training: 0.2651101334894208 | validation: 0.22092028941694955]
	TIME [epoch: 9.07 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24667601789465637		[learning rate: 0.0037798]
	Learning Rate: 0.00377978
	LOSS [training: 0.24667601789465637 | validation: 0.2645616742049445]
	TIME [epoch: 9.07 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34038460258357356		[learning rate: 0.0037682]
	Learning Rate: 0.00376819
	LOSS [training: 0.34038460258357356 | validation: 0.3499242696043938]
	TIME [epoch: 9.07 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3553251200731176		[learning rate: 0.0037566]
	Learning Rate: 0.00375664
	LOSS [training: 0.3553251200731176 | validation: 0.2124373464126258]
	TIME [epoch: 9.09 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3240331190563216		[learning rate: 0.0037451]
	Learning Rate: 0.00374513
	LOSS [training: 0.3240331190563216 | validation: 0.37416587050774897]
	TIME [epoch: 9.06 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691453128827943		[learning rate: 0.0037336]
	Learning Rate: 0.00373365
	LOSS [training: 0.3691453128827943 | validation: 0.22401053761487263]
	TIME [epoch: 9.07 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24204351839335878		[learning rate: 0.0037222]
	Learning Rate: 0.0037222
	LOSS [training: 0.24204351839335878 | validation: 0.37456749148167345]
	TIME [epoch: 9.07 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28158970748860995		[learning rate: 0.0037108]
	Learning Rate: 0.00371079
	LOSS [training: 0.28158970748860995 | validation: 0.25776849546145986]
	TIME [epoch: 9.09 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26615508421108525		[learning rate: 0.0036994]
	Learning Rate: 0.00369942
	LOSS [training: 0.26615508421108525 | validation: 0.15684906873664112]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27446358455450953		[learning rate: 0.0036881]
	Learning Rate: 0.00368808
	LOSS [training: 0.27446358455450953 | validation: 0.1574399595974876]
	TIME [epoch: 9.08 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28893316930653384		[learning rate: 0.0036768]
	Learning Rate: 0.00367677
	LOSS [training: 0.28893316930653384 | validation: 0.2230274913638972]
	TIME [epoch: 9.07 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22583626318491584		[learning rate: 0.0036655]
	Learning Rate: 0.0036655
	LOSS [training: 0.22583626318491584 | validation: 0.25061029133358004]
	TIME [epoch: 9.09 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33152376291160374		[learning rate: 0.0036543]
	Learning Rate: 0.00365426
	LOSS [training: 0.33152376291160374 | validation: 0.3468174289402469]
	TIME [epoch: 9.07 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29206556137141176		[learning rate: 0.0036431]
	Learning Rate: 0.00364306
	LOSS [training: 0.29206556137141176 | validation: 0.3092644990154232]
	TIME [epoch: 9.07 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33526111289231664		[learning rate: 0.0036319]
	Learning Rate: 0.0036319
	LOSS [training: 0.33526111289231664 | validation: 0.23328614239323744]
	TIME [epoch: 9.07 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31731073743578964		[learning rate: 0.0036208]
	Learning Rate: 0.00362076
	LOSS [training: 0.31731073743578964 | validation: 0.34175646275466676]
	TIME [epoch: 9.09 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5198203507365986		[learning rate: 0.0036097]
	Learning Rate: 0.00360966
	LOSS [training: 0.5198203507365986 | validation: 0.26656949094923826]
	TIME [epoch: 9.08 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2407598596371669		[learning rate: 0.0035986]
	Learning Rate: 0.0035986
	LOSS [training: 0.2407598596371669 | validation: 0.31411988448550965]
	TIME [epoch: 9.07 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29316445831445703		[learning rate: 0.0035876]
	Learning Rate: 0.00358757
	LOSS [training: 0.29316445831445703 | validation: 0.1676449937169652]
	TIME [epoch: 9.07 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23456978086164848		[learning rate: 0.0035766]
	Learning Rate: 0.00357657
	LOSS [training: 0.23456978086164848 | validation: 0.24928029706791555]
	TIME [epoch: 9.08 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27929588959395224		[learning rate: 0.0035656]
	Learning Rate: 0.00356561
	LOSS [training: 0.27929588959395224 | validation: 0.2180521245062999]
	TIME [epoch: 9.09 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4111390675243527		[learning rate: 0.0035547]
	Learning Rate: 0.00355468
	LOSS [training: 0.4111390675243527 | validation: 0.28011731239956317]
	TIME [epoch: 9.07 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350889490547977		[learning rate: 0.0035438]
	Learning Rate: 0.00354378
	LOSS [training: 0.3350889490547977 | validation: 0.2580344804598321]
	TIME [epoch: 9.07 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.329003614161335		[learning rate: 0.0035329]
	Learning Rate: 0.00353292
	LOSS [training: 0.329003614161335 | validation: 0.25631606135321083]
	TIME [epoch: 9.07 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24393543710063503		[learning rate: 0.0035221]
	Learning Rate: 0.00352209
	LOSS [training: 0.24393543710063503 | validation: 0.19044816046451385]
	TIME [epoch: 9.09 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2442732194056751		[learning rate: 0.0035113]
	Learning Rate: 0.00351129
	LOSS [training: 0.2442732194056751 | validation: 0.23317975158153803]
	TIME [epoch: 9.06 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.286963722687985		[learning rate: 0.0035005]
	Learning Rate: 0.00350053
	LOSS [training: 0.286963722687985 | validation: 0.26779170878457303]
	TIME [epoch: 9.07 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3480526444187432		[learning rate: 0.0034898]
	Learning Rate: 0.0034898
	LOSS [training: 0.3480526444187432 | validation: 0.34869030465624673]
	TIME [epoch: 9.08 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27505294728326585		[learning rate: 0.0034791]
	Learning Rate: 0.0034791
	LOSS [training: 0.27505294728326585 | validation: 0.1665200457045381]
	TIME [epoch: 9.11 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20509547641219564		[learning rate: 0.0034684]
	Learning Rate: 0.00346843
	LOSS [training: 0.20509547641219564 | validation: 0.1825352570454074]
	TIME [epoch: 9.07 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21049400131702303		[learning rate: 0.0034578]
	Learning Rate: 0.0034578
	LOSS [training: 0.21049400131702303 | validation: 0.24590199174866373]
	TIME [epoch: 9.08 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35367162469871644		[learning rate: 0.0034472]
	Learning Rate: 0.0034472
	LOSS [training: 0.35367162469871644 | validation: 0.4470842718783197]
	TIME [epoch: 9.06 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34100203587741834		[learning rate: 0.0034366]
	Learning Rate: 0.00343663
	LOSS [training: 0.34100203587741834 | validation: 0.23522869063773869]
	TIME [epoch: 9.09 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40266753014361567		[learning rate: 0.0034261]
	Learning Rate: 0.0034261
	LOSS [training: 0.40266753014361567 | validation: 0.7024172364520902]
	TIME [epoch: 9.07 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.463827656334614		[learning rate: 0.0034156]
	Learning Rate: 0.0034156
	LOSS [training: 0.463827656334614 | validation: 0.24738937215875406]
	TIME [epoch: 9.06 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30960149962150474		[learning rate: 0.0034051]
	Learning Rate: 0.00340513
	LOSS [training: 0.30960149962150474 | validation: 0.24240253520707336]
	TIME [epoch: 9.06 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27180880025882703		[learning rate: 0.0033947]
	Learning Rate: 0.00339469
	LOSS [training: 0.27180880025882703 | validation: 0.24220051553266073]
	TIME [epoch: 9.08 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24232310540866214		[learning rate: 0.0033843]
	Learning Rate: 0.00338428
	LOSS [training: 0.24232310540866214 | validation: 0.22153019772491048]
	TIME [epoch: 9.06 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2420142742476245		[learning rate: 0.0033739]
	Learning Rate: 0.00337391
	LOSS [training: 0.2420142742476245 | validation: 0.3069377252097434]
	TIME [epoch: 9.06 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1883878051919834		[learning rate: 0.0033636]
	Learning Rate: 0.00336357
	LOSS [training: 0.1883878051919834 | validation: 0.35442017723789826]
	TIME [epoch: 9.06 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4873386264624447		[learning rate: 0.0033533]
	Learning Rate: 0.00335326
	LOSS [training: 0.4873386264624447 | validation: 0.5634309704164508]
	TIME [epoch: 9.07 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2039188831897049		[learning rate: 0.003343]
	Learning Rate: 0.00334298
	LOSS [training: 0.2039188831897049 | validation: 0.1513745619567501]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19360256031847312		[learning rate: 0.0033327]
	Learning Rate: 0.00333273
	LOSS [training: 0.19360256031847312 | validation: 0.6135491528989652]
	TIME [epoch: 9.06 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31271801771273133		[learning rate: 0.0033225]
	Learning Rate: 0.00332251
	LOSS [training: 0.31271801771273133 | validation: 0.13832463369488363]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970420479646416		[learning rate: 0.0033123]
	Learning Rate: 0.00331233
	LOSS [training: 0.2970420479646416 | validation: 0.15173124958095013]
	TIME [epoch: 9.08 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20625160524251643		[learning rate: 0.0033022]
	Learning Rate: 0.00330217
	LOSS [training: 0.20625160524251643 | validation: 0.46637479317669284]
	TIME [epoch: 9.08 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30831027450081666		[learning rate: 0.0032921]
	Learning Rate: 0.00329205
	LOSS [training: 0.30831027450081666 | validation: 0.5597931407838352]
	TIME [epoch: 9.07 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3337138165423735		[learning rate: 0.003282]
	Learning Rate: 0.00328196
	LOSS [training: 0.3337138165423735 | validation: 0.16141262544235738]
	TIME [epoch: 9.06 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22497182733518972		[learning rate: 0.0032719]
	Learning Rate: 0.0032719
	LOSS [training: 0.22497182733518972 | validation: 0.2613723191917209]
	TIME [epoch: 9.07 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28992113672555797		[learning rate: 0.0032619]
	Learning Rate: 0.00326187
	LOSS [training: 0.28992113672555797 | validation: 0.34181798370227817]
	TIME [epoch: 9.09 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28021213508888093		[learning rate: 0.0032519]
	Learning Rate: 0.00325187
	LOSS [training: 0.28021213508888093 | validation: 0.2052095823783306]
	TIME [epoch: 9.06 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36797614344532387		[learning rate: 0.0032419]
	Learning Rate: 0.0032419
	LOSS [training: 0.36797614344532387 | validation: 0.6374815788200427]
	TIME [epoch: 9.06 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044704953080165		[learning rate: 0.003232]
	Learning Rate: 0.00323197
	LOSS [training: 0.3044704953080165 | validation: 0.1609437948711393]
	TIME [epoch: 9.06 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26468072942113746		[learning rate: 0.0032221]
	Learning Rate: 0.00322206
	LOSS [training: 0.26468072942113746 | validation: 0.32529214577569426]
	TIME [epoch: 9.07 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540623819056199		[learning rate: 0.0032122]
	Learning Rate: 0.00321218
	LOSS [training: 0.2540623819056199 | validation: 0.1983416811234325]
	TIME [epoch: 9.06 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26480607733617906		[learning rate: 0.0032023]
	Learning Rate: 0.00320233
	LOSS [training: 0.26480607733617906 | validation: 0.24191445204789702]
	TIME [epoch: 9.06 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3909916730511571		[learning rate: 0.0031925]
	Learning Rate: 0.00319252
	LOSS [training: 0.3909916730511571 | validation: 0.38173874061594126]
	TIME [epoch: 9.05 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3692722205853905		[learning rate: 0.0031827]
	Learning Rate: 0.00318273
	LOSS [training: 0.3692722205853905 | validation: 0.39841716849568753]
	TIME [epoch: 9.07 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2259775446473285		[learning rate: 0.003173]
	Learning Rate: 0.00317297
	LOSS [training: 0.2259775446473285 | validation: 0.21142259229790505]
	TIME [epoch: 9.06 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426361182135397		[learning rate: 0.0031632]
	Learning Rate: 0.00316325
	LOSS [training: 0.2426361182135397 | validation: 0.46192946374261357]
	TIME [epoch: 9.06 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258491756970455		[learning rate: 0.0031536]
	Learning Rate: 0.00315355
	LOSS [training: 0.3258491756970455 | validation: 0.1597065670005468]
	TIME [epoch: 9.06 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3813500367771288		[learning rate: 0.0031439]
	Learning Rate: 0.00314389
	LOSS [training: 0.3813500367771288 | validation: 0.4844917820975694]
	TIME [epoch: 9.08 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40850012733555907		[learning rate: 0.0031342]
	Learning Rate: 0.00313425
	LOSS [training: 0.40850012733555907 | validation: 0.5765609782501712]
	TIME [epoch: 9.06 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3914278835929955		[learning rate: 0.0031246]
	Learning Rate: 0.00312464
	LOSS [training: 0.3914278835929955 | validation: 0.2450074332542566]
	TIME [epoch: 9.06 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2409893164223448		[learning rate: 0.0031151]
	Learning Rate: 0.00311506
	LOSS [training: 0.2409893164223448 | validation: 0.23511410044247036]
	TIME [epoch: 9.06 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18882314432456182		[learning rate: 0.0031055]
	Learning Rate: 0.00310551
	LOSS [training: 0.18882314432456182 | validation: 0.22826680072427175]
	TIME [epoch: 9.07 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20984727900742609		[learning rate: 0.003096]
	Learning Rate: 0.00309599
	LOSS [training: 0.20984727900742609 | validation: 0.17092988415104138]
	TIME [epoch: 9.07 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1788343718480504		[learning rate: 0.0030865]
	Learning Rate: 0.0030865
	LOSS [training: 0.1788343718480504 | validation: 0.37477578379517584]
	TIME [epoch: 9.06 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3822647451813967		[learning rate: 0.003077]
	Learning Rate: 0.00307704
	LOSS [training: 0.3822647451813967 | validation: 0.38734698945187723]
	TIME [epoch: 9.06 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830590300945981		[learning rate: 0.0030676]
	Learning Rate: 0.00306761
	LOSS [training: 0.2830590300945981 | validation: 0.09364840915439204]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_885.pth
	Model improved!!!
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29073368475930034		[learning rate: 0.0030582]
	Learning Rate: 0.00305821
	LOSS [training: 0.29073368475930034 | validation: 0.1925922104718772]
	TIME [epoch: 9.07 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25225382630865484		[learning rate: 0.0030488]
	Learning Rate: 0.00304883
	LOSS [training: 0.25225382630865484 | validation: 0.2730606712184271]
	TIME [epoch: 9.05 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30558272269370446		[learning rate: 0.0030395]
	Learning Rate: 0.00303948
	LOSS [training: 0.30558272269370446 | validation: 0.16288419650347058]
	TIME [epoch: 9.06 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23815436379665184		[learning rate: 0.0030302]
	Learning Rate: 0.00303017
	LOSS [training: 0.23815436379665184 | validation: 0.17141300172607168]
	TIME [epoch: 9.06 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2070988285584256		[learning rate: 0.0030209]
	Learning Rate: 0.00302088
	LOSS [training: 0.2070988285584256 | validation: 0.13042066895211402]
	TIME [epoch: 9.07 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.217806427918367		[learning rate: 0.0030116]
	Learning Rate: 0.00301162
	LOSS [training: 0.217806427918367 | validation: 0.40346730395529873]
	TIME [epoch: 9.06 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32834764619394585		[learning rate: 0.0030024]
	Learning Rate: 0.00300239
	LOSS [training: 0.32834764619394585 | validation: 0.22616381832611138]
	TIME [epoch: 9.06 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27674540275900006		[learning rate: 0.0029932]
	Learning Rate: 0.00299318
	LOSS [training: 0.27674540275900006 | validation: 0.1493703093284649]
	TIME [epoch: 9.05 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23972272801708558		[learning rate: 0.002984]
	Learning Rate: 0.00298401
	LOSS [training: 0.23972272801708558 | validation: 0.17614077206797293]
	TIME [epoch: 9.07 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21061281383253694		[learning rate: 0.0029749]
	Learning Rate: 0.00297486
	LOSS [training: 0.21061281383253694 | validation: 0.15332114365549815]
	TIME [epoch: 9.05 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3467603325225329		[learning rate: 0.0029657]
	Learning Rate: 0.00296574
	LOSS [training: 0.3467603325225329 | validation: 0.18688132022235732]
	TIME [epoch: 9.06 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32663036571220994		[learning rate: 0.0029567]
	Learning Rate: 0.00295665
	LOSS [training: 0.32663036571220994 | validation: 0.3135062013373663]
	TIME [epoch: 9.06 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19567534322040517		[learning rate: 0.0029476]
	Learning Rate: 0.00294759
	LOSS [training: 0.19567534322040517 | validation: 0.2174435669286257]
	TIME [epoch: 9.08 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20700045983349308		[learning rate: 0.0029386]
	Learning Rate: 0.00293855
	LOSS [training: 0.20700045983349308 | validation: 0.1576241751181548]
	TIME [epoch: 9.06 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22967654443853416		[learning rate: 0.0029295]
	Learning Rate: 0.00292954
	LOSS [training: 0.22967654443853416 | validation: 0.38912469048780507]
	TIME [epoch: 9.05 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22260641150332106		[learning rate: 0.0029206]
	Learning Rate: 0.00292056
	LOSS [training: 0.22260641150332106 | validation: 0.16212493999665395]
	TIME [epoch: 9.06 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18977701359245175		[learning rate: 0.0029116]
	Learning Rate: 0.00291161
	LOSS [training: 0.18977701359245175 | validation: 0.18558031611452297]
	TIME [epoch: 9.07 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25099616445304007		[learning rate: 0.0029027]
	Learning Rate: 0.00290269
	LOSS [training: 0.25099616445304007 | validation: 0.23214481796366115]
	TIME [epoch: 9.07 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19940987211016012		[learning rate: 0.0028938]
	Learning Rate: 0.00289379
	LOSS [training: 0.19940987211016012 | validation: 0.3424279141683597]
	TIME [epoch: 9.05 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23671766245671083		[learning rate: 0.0028849]
	Learning Rate: 0.00288492
	LOSS [training: 0.23671766245671083 | validation: 0.7002136410482173]
	TIME [epoch: 9.94 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208727169871519		[learning rate: 0.0028761]
	Learning Rate: 0.00287607
	LOSS [training: 0.3208727169871519 | validation: 0.2343065792363468]
	TIME [epoch: 9.07 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3060696454919145		[learning rate: 0.0028673]
	Learning Rate: 0.00286726
	LOSS [training: 0.3060696454919145 | validation: 0.9663451495923188]
	TIME [epoch: 9.07 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.489234346979735		[learning rate: 0.0028585]
	Learning Rate: 0.00285847
	LOSS [training: 0.489234346979735 | validation: 0.1620818517820714]
	TIME [epoch: 9.05 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21655983328564932		[learning rate: 0.0028497]
	Learning Rate: 0.00284971
	LOSS [training: 0.21655983328564932 | validation: 0.22699412259084295]
	TIME [epoch: 9.05 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22444759719018062		[learning rate: 0.002841]
	Learning Rate: 0.00284097
	LOSS [training: 0.22444759719018062 | validation: 0.1405581973070859]
	TIME [epoch: 9.06 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20178703743445645		[learning rate: 0.0028323]
	Learning Rate: 0.00283226
	LOSS [training: 0.20178703743445645 | validation: 0.4321532439826492]
	TIME [epoch: 9.06 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2857387246005564		[learning rate: 0.0028236]
	Learning Rate: 0.00282358
	LOSS [training: 0.2857387246005564 | validation: 0.2909834554469044]
	TIME [epoch: 9.05 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2905829483044944		[learning rate: 0.0028149]
	Learning Rate: 0.00281492
	LOSS [training: 0.2905829483044944 | validation: 0.2670267450787608]
	TIME [epoch: 9.05 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24248864939520126		[learning rate: 0.0028063]
	Learning Rate: 0.0028063
	LOSS [training: 0.24248864939520126 | validation: 0.23205381110706302]
	TIME [epoch: 9.05 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2934773818111762		[learning rate: 0.0027977]
	Learning Rate: 0.00279769
	LOSS [training: 0.2934773818111762 | validation: 0.3801590315820693]
	TIME [epoch: 9.07 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2987623656781683		[learning rate: 0.0027891]
	Learning Rate: 0.00278912
	LOSS [training: 0.2987623656781683 | validation: 0.34255973919587857]
	TIME [epoch: 9.06 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727011839410675		[learning rate: 0.0027806]
	Learning Rate: 0.00278057
	LOSS [training: 0.2727011839410675 | validation: 0.34361220271826404]
	TIME [epoch: 9.06 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30894393070351905		[learning rate: 0.002772]
	Learning Rate: 0.00277204
	LOSS [training: 0.30894393070351905 | validation: 0.32477963087980677]
	TIME [epoch: 9.05 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2320697909975297		[learning rate: 0.0027635]
	Learning Rate: 0.00276355
	LOSS [training: 0.2320697909975297 | validation: 0.3098191587336152]
	TIME [epoch: 9.08 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34057080641554166		[learning rate: 0.0027551]
	Learning Rate: 0.00275507
	LOSS [training: 0.34057080641554166 | validation: 0.5358373589283388]
	TIME [epoch: 9.05 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3315462092757757		[learning rate: 0.0027466]
	Learning Rate: 0.00274663
	LOSS [training: 0.3315462092757757 | validation: 0.18646167415025883]
	TIME [epoch: 9.05 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296376788890672		[learning rate: 0.0027382]
	Learning Rate: 0.00273821
	LOSS [training: 0.2296376788890672 | validation: 0.24957905314909262]
	TIME [epoch: 9.05 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2704940874815443		[learning rate: 0.0027298]
	Learning Rate: 0.00272982
	LOSS [training: 0.2704940874815443 | validation: 0.5891845191014493]
	TIME [epoch: 9.07 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3212291431611798		[learning rate: 0.0027214]
	Learning Rate: 0.00272145
	LOSS [training: 0.3212291431611798 | validation: 0.3136604265970169]
	TIME [epoch: 9.06 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2098809232144792		[learning rate: 0.0027131]
	Learning Rate: 0.00271311
	LOSS [training: 0.2098809232144792 | validation: 0.19963253091680205]
	TIME [epoch: 9.05 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3115059576534865		[learning rate: 0.0027048]
	Learning Rate: 0.00270479
	LOSS [training: 0.3115059576534865 | validation: 0.25048500196592804]
	TIME [epoch: 9.05 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21790333293998004		[learning rate: 0.0026965]
	Learning Rate: 0.0026965
	LOSS [training: 0.21790333293998004 | validation: 0.1681341349496866]
	TIME [epoch: 9.06 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17360591599861158		[learning rate: 0.0026882]
	Learning Rate: 0.00268823
	LOSS [training: 0.17360591599861158 | validation: 0.18942929793034924]
	TIME [epoch: 9.07 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16421325718482316		[learning rate: 0.00268]
	Learning Rate: 0.00267999
	LOSS [training: 0.16421325718482316 | validation: 0.09376570254594505]
	TIME [epoch: 9.06 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1813133687272278		[learning rate: 0.0026718]
	Learning Rate: 0.00267178
	LOSS [training: 0.1813133687272278 | validation: 0.17281096813658192]
	TIME [epoch: 9.06 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21578107892256831		[learning rate: 0.0026636]
	Learning Rate: 0.00266359
	LOSS [training: 0.21578107892256831 | validation: 0.20349977809253025]
	TIME [epoch: 9.07 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662794849402866		[learning rate: 0.0026554]
	Learning Rate: 0.00265542
	LOSS [training: 0.1662794849402866 | validation: 0.11999196836651539]
	TIME [epoch: 9.07 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20933226975207622		[learning rate: 0.0026473]
	Learning Rate: 0.00264728
	LOSS [training: 0.20933226975207622 | validation: 0.14345258530740268]
	TIME [epoch: 9.06 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27758621110632403		[learning rate: 0.0026392]
	Learning Rate: 0.00263917
	LOSS [training: 0.27758621110632403 | validation: 0.22146904338167808]
	TIME [epoch: 9.05 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20772720911585033		[learning rate: 0.0026311]
	Learning Rate: 0.00263108
	LOSS [training: 0.20772720911585033 | validation: 0.2308479483491024]
	TIME [epoch: 9.06 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26802666073417286		[learning rate: 0.002623]
	Learning Rate: 0.00262301
	LOSS [training: 0.26802666073417286 | validation: 0.1400794404435443]
	TIME [epoch: 9.08 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19590143362210372		[learning rate: 0.002615]
	Learning Rate: 0.00261497
	LOSS [training: 0.19590143362210372 | validation: 0.14509033289370635]
	TIME [epoch: 9.06 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14826162054211564		[learning rate: 0.002607]
	Learning Rate: 0.00260695
	LOSS [training: 0.14826162054211564 | validation: 0.26219909030473154]
	TIME [epoch: 9.06 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1896817163197617		[learning rate: 0.002599]
	Learning Rate: 0.00259896
	LOSS [training: 0.1896817163197617 | validation: 0.5458953783764293]
	TIME [epoch: 9.06 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37977747362915604		[learning rate: 0.002591]
	Learning Rate: 0.002591
	LOSS [training: 0.37977747362915604 | validation: 0.22348836687055496]
	TIME [epoch: 9.08 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18107171545977463		[learning rate: 0.0025831]
	Learning Rate: 0.00258305
	LOSS [training: 0.18107171545977463 | validation: 0.1681609796616044]
	TIME [epoch: 9.06 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2046439123966842		[learning rate: 0.0025751]
	Learning Rate: 0.00257513
	LOSS [training: 0.2046439123966842 | validation: 0.1643232532570672]
	TIME [epoch: 9.05 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1665401386255116		[learning rate: 0.0025672]
	Learning Rate: 0.00256724
	LOSS [training: 0.1665401386255116 | validation: 0.17993649300403936]
	TIME [epoch: 9.05 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18113447658949838		[learning rate: 0.0025594]
	Learning Rate: 0.00255937
	LOSS [training: 0.18113447658949838 | validation: 0.35053799719316436]
	TIME [epoch: 9.08 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23884116299722935		[learning rate: 0.0025515]
	Learning Rate: 0.00255153
	LOSS [training: 0.23884116299722935 | validation: 0.12209663244457522]
	TIME [epoch: 9.06 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21189756225849674		[learning rate: 0.0025437]
	Learning Rate: 0.0025437
	LOSS [training: 0.21189756225849674 | validation: 0.17387197692101608]
	TIME [epoch: 9.05 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22665834129630338		[learning rate: 0.0025359]
	Learning Rate: 0.00253591
	LOSS [training: 0.22665834129630338 | validation: 0.16645585266337543]
	TIME [epoch: 9.06 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1737669317996577		[learning rate: 0.0025281]
	Learning Rate: 0.00252813
	LOSS [training: 0.1737669317996577 | validation: 0.1354646971348687]
	TIME [epoch: 9.07 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15291341597055866		[learning rate: 0.0025204]
	Learning Rate: 0.00252038
	LOSS [training: 0.15291341597055866 | validation: 0.21984122641788784]
	TIME [epoch: 9.06 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18930777064914578		[learning rate: 0.0025127]
	Learning Rate: 0.00251266
	LOSS [training: 0.18930777064914578 | validation: 0.15562286731466785]
	TIME [epoch: 9.05 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643966399924099		[learning rate: 0.002505]
	Learning Rate: 0.00250496
	LOSS [training: 0.2643966399924099 | validation: 0.39680303566901753]
	TIME [epoch: 9.05 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36117126643153274		[learning rate: 0.0024973]
	Learning Rate: 0.00249728
	LOSS [training: 0.36117126643153274 | validation: 0.2610640332928377]
	TIME [epoch: 9.06 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39770210720813226		[learning rate: 0.0024896]
	Learning Rate: 0.00248962
	LOSS [training: 0.39770210720813226 | validation: 0.3853621631670924]
	TIME [epoch: 9.07 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27141207102780085		[learning rate: 0.002482]
	Learning Rate: 0.00248199
	LOSS [training: 0.27141207102780085 | validation: 0.5754014326197838]
	TIME [epoch: 9.05 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982442341842778		[learning rate: 0.0024744]
	Learning Rate: 0.00247438
	LOSS [training: 0.2982442341842778 | validation: 0.19956839204840165]
	TIME [epoch: 9.06 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30622833182033965		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.30622833182033965 | validation: 0.20582727347179008]
	TIME [epoch: 9.07 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18660570295948303		[learning rate: 0.0024592]
	Learning Rate: 0.00245923
	LOSS [training: 0.18660570295948303 | validation: 0.26474804823566356]
	TIME [epoch: 9.07 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2303498932106674		[learning rate: 0.0024517]
	Learning Rate: 0.0024517
	LOSS [training: 0.2303498932106674 | validation: 0.13996705865005823]
	TIME [epoch: 9.05 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534019447798213		[learning rate: 0.0024442]
	Learning Rate: 0.00244418
	LOSS [training: 0.2534019447798213 | validation: 0.1869993188259882]
	TIME [epoch: 9.05 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17479681423738067		[learning rate: 0.0024367]
	Learning Rate: 0.00243669
	LOSS [training: 0.17479681423738067 | validation: 0.13630154253089488]
	TIME [epoch: 9.05 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15623841608023165		[learning rate: 0.0024292]
	Learning Rate: 0.00242922
	LOSS [training: 0.15623841608023165 | validation: 0.1393013564174997]
	TIME [epoch: 9.08 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19022337323096106		[learning rate: 0.0024218]
	Learning Rate: 0.00242177
	LOSS [training: 0.19022337323096106 | validation: 0.21884344800718641]
	TIME [epoch: 9.06 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22123503397682281		[learning rate: 0.0024143]
	Learning Rate: 0.00241435
	LOSS [training: 0.22123503397682281 | validation: 0.15087410352419242]
	TIME [epoch: 9.05 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14394984827114296		[learning rate: 0.0024069]
	Learning Rate: 0.00240695
	LOSS [training: 0.14394984827114296 | validation: 0.12423987864981045]
	TIME [epoch: 9.05 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490771822996249		[learning rate: 0.0023996]
	Learning Rate: 0.00239957
	LOSS [training: 0.1490771822996249 | validation: 0.1497100330704766]
	TIME [epoch: 9.07 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525193447536856		[learning rate: 0.0023922]
	Learning Rate: 0.00239221
	LOSS [training: 0.1525193447536856 | validation: 0.17967819930665288]
	TIME [epoch: 9.06 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21943638192644407		[learning rate: 0.0023849]
	Learning Rate: 0.00238488
	LOSS [training: 0.21943638192644407 | validation: 0.08506880245375874]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_967.pth
	Model improved!!!
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18759742149056274		[learning rate: 0.0023776]
	Learning Rate: 0.00237757
	LOSS [training: 0.18759742149056274 | validation: 0.1595777854957293]
	TIME [epoch: 9.06 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3803353107643398		[learning rate: 0.0023703]
	Learning Rate: 0.00237028
	LOSS [training: 0.3803353107643398 | validation: 0.21875181366504695]
	TIME [epoch: 9.07 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21020368574081524		[learning rate: 0.002363]
	Learning Rate: 0.00236302
	LOSS [training: 0.21020368574081524 | validation: 0.2909700436669067]
	TIME [epoch: 9.06 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2237130089842292		[learning rate: 0.0023558]
	Learning Rate: 0.00235577
	LOSS [training: 0.2237130089842292 | validation: 0.27867270799401056]
	TIME [epoch: 9.06 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2126958953225734		[learning rate: 0.0023486]
	Learning Rate: 0.00234855
	LOSS [training: 0.2126958953225734 | validation: 0.1913413919604473]
	TIME [epoch: 9.05 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18152687423765723		[learning rate: 0.0023414]
	Learning Rate: 0.00234135
	LOSS [training: 0.18152687423765723 | validation: 0.26820481310009786]
	TIME [epoch: 9.07 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39301774699936304		[learning rate: 0.0023342]
	Learning Rate: 0.00233417
	LOSS [training: 0.39301774699936304 | validation: 0.5232613124423207]
	TIME [epoch: 9.06 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20961550341744534		[learning rate: 0.002327]
	Learning Rate: 0.00232702
	LOSS [training: 0.20961550341744534 | validation: 0.11975261086042235]
	TIME [epoch: 9.06 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18029019815175643		[learning rate: 0.0023199]
	Learning Rate: 0.00231989
	LOSS [training: 0.18029019815175643 | validation: 0.25603438332106115]
	TIME [epoch: 9.05 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612427008824288		[learning rate: 0.0023128]
	Learning Rate: 0.00231277
	LOSS [training: 0.2612427008824288 | validation: 0.22574795525861222]
	TIME [epoch: 9.06 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17810707265315362		[learning rate: 0.0023057]
	Learning Rate: 0.00230569
	LOSS [training: 0.17810707265315362 | validation: 0.08440711871209919]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_978.pth
	Model improved!!!
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2114038368569146		[learning rate: 0.0022986]
	Learning Rate: 0.00229862
	LOSS [training: 0.2114038368569146 | validation: 0.2705052900721732]
	TIME [epoch: 9.05 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3047875338459153		[learning rate: 0.0022916]
	Learning Rate: 0.00229157
	LOSS [training: 0.3047875338459153 | validation: 0.13732304707344026]
	TIME [epoch: 9.05 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22234228673529097		[learning rate: 0.0022845]
	Learning Rate: 0.00228455
	LOSS [training: 0.22234228673529097 | validation: 0.22510604885466898]
	TIME [epoch: 9.06 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22730856695084922		[learning rate: 0.0022775]
	Learning Rate: 0.00227754
	LOSS [training: 0.22730856695084922 | validation: 0.26923734587203285]
	TIME [epoch: 9.07 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24396463016344364		[learning rate: 0.0022706]
	Learning Rate: 0.00227056
	LOSS [training: 0.24396463016344364 | validation: 0.1844297443337537]
	TIME [epoch: 9.05 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17895965863794716		[learning rate: 0.0022636]
	Learning Rate: 0.0022636
	LOSS [training: 0.17895965863794716 | validation: 0.1590742877997929]
	TIME [epoch: 9.05 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21386956358104267		[learning rate: 0.0022567]
	Learning Rate: 0.00225666
	LOSS [training: 0.21386956358104267 | validation: 0.19105631032279377]
	TIME [epoch: 9.05 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2509519569741574		[learning rate: 0.0022497]
	Learning Rate: 0.00224975
	LOSS [training: 0.2509519569741574 | validation: 0.13816815191221188]
	TIME [epoch: 9.08 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15634057838622545		[learning rate: 0.0022428]
	Learning Rate: 0.00224285
	LOSS [training: 0.15634057838622545 | validation: 0.20422866449149418]
	TIME [epoch: 9.05 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16996528579106873		[learning rate: 0.002236]
	Learning Rate: 0.00223597
	LOSS [training: 0.16996528579106873 | validation: 0.1335101050832176]
	TIME [epoch: 9.05 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20843713524882568		[learning rate: 0.0022291]
	Learning Rate: 0.00222912
	LOSS [training: 0.20843713524882568 | validation: 0.16490883215500152]
	TIME [epoch: 9.05 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302179198854754		[learning rate: 0.0022223]
	Learning Rate: 0.00222229
	LOSS [training: 0.1302179198854754 | validation: 0.2825848971492998]
	TIME [epoch: 9.07 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20184939817793354		[learning rate: 0.0022155]
	Learning Rate: 0.00221547
	LOSS [training: 0.20184939817793354 | validation: 0.2713556085358326]
	TIME [epoch: 9.06 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34866954894662194		[learning rate: 0.0022087]
	Learning Rate: 0.00220868
	LOSS [training: 0.34866954894662194 | validation: 0.2049545938712095]
	TIME [epoch: 9.05 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14593035590037143		[learning rate: 0.0022019]
	Learning Rate: 0.00220191
	LOSS [training: 0.14593035590037143 | validation: 0.11053309119480006]
	TIME [epoch: 9.06 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14616933462719625		[learning rate: 0.0021952]
	Learning Rate: 0.00219516
	LOSS [training: 0.14616933462719625 | validation: 0.11803316640519784]
	TIME [epoch: 9.07 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519244228898456		[learning rate: 0.0021884]
	Learning Rate: 0.00218843
	LOSS [training: 0.1519244228898456 | validation: 0.1549087865201192]
	TIME [epoch: 9.06 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13693717643945155		[learning rate: 0.0021817]
	Learning Rate: 0.00218173
	LOSS [training: 0.13693717643945155 | validation: 0.18182977288456326]
	TIME [epoch: 9.05 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16802120745632734		[learning rate: 0.002175]
	Learning Rate: 0.00217504
	LOSS [training: 0.16802120745632734 | validation: 0.21330588208917942]
	TIME [epoch: 9.06 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18087276769569077		[learning rate: 0.0021684]
	Learning Rate: 0.00216837
	LOSS [training: 0.18087276769569077 | validation: 0.07160775264827579]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_998.pth
	Model improved!!!
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13964240774494677		[learning rate: 0.0021617]
	Learning Rate: 0.00216172
	LOSS [training: 0.13964240774494677 | validation: 0.13282915152018573]
	TIME [epoch: 9.07 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442645778322667		[learning rate: 0.0021551]
	Learning Rate: 0.0021551
	LOSS [training: 0.1442645778322667 | validation: 0.27550521085071233]
	TIME [epoch: 9.06 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21669586974218466		[learning rate: 0.0021485]
	Learning Rate: 0.00214849
	LOSS [training: 0.21669586974218466 | validation: 0.2145764518475965]
	TIME [epoch: 9.06 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26514876865949344		[learning rate: 0.0021419]
	Learning Rate: 0.0021419
	LOSS [training: 0.26514876865949344 | validation: 0.10327035723144852]
	TIME [epoch: 9.06 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17151280855631645		[learning rate: 0.0021353]
	Learning Rate: 0.00213534
	LOSS [training: 0.17151280855631645 | validation: 0.20681528186072823]
	TIME [epoch: 9.07 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16645430016576507		[learning rate: 0.0021288]
	Learning Rate: 0.00212879
	LOSS [training: 0.16645430016576507 | validation: 0.2702020473081792]
	TIME [epoch: 9.05 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18463956943801818		[learning rate: 0.0021223]
	Learning Rate: 0.00212227
	LOSS [training: 0.18463956943801818 | validation: 0.08552631140624933]
	TIME [epoch: 9.05 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490856842675379		[learning rate: 0.0021158]
	Learning Rate: 0.00211576
	LOSS [training: 0.1490856842675379 | validation: 0.15769337742756262]
	TIME [epoch: 9.05 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15693362627697727		[learning rate: 0.0021093]
	Learning Rate: 0.00210928
	LOSS [training: 0.15693362627697727 | validation: 0.18204358559510198]
	TIME [epoch: 9.07 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25822411071745605		[learning rate: 0.0021028]
	Learning Rate: 0.00210281
	LOSS [training: 0.25822411071745605 | validation: 0.2264978633982126]
	TIME [epoch: 9.05 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1498881879744787		[learning rate: 0.0020964]
	Learning Rate: 0.00209636
	LOSS [training: 0.1498881879744787 | validation: 0.16493979440810141]
	TIME [epoch: 9.05 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14053760221412584		[learning rate: 0.0020899]
	Learning Rate: 0.00208994
	LOSS [training: 0.14053760221412584 | validation: 0.08399934836154659]
	TIME [epoch: 9.05 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16093480800555782		[learning rate: 0.0020835]
	Learning Rate: 0.00208353
	LOSS [training: 0.16093480800555782 | validation: 0.14413329392322982]
	TIME [epoch: 9.08 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1689187630658678		[learning rate: 0.0020771]
	Learning Rate: 0.00207714
	LOSS [training: 0.1689187630658678 | validation: 0.23798402895612936]
	TIME [epoch: 9.05 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17720487187875106		[learning rate: 0.0020708]
	Learning Rate: 0.00207078
	LOSS [training: 0.17720487187875106 | validation: 0.09896442959763357]
	TIME [epoch: 9.06 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16250639418472962		[learning rate: 0.0020644]
	Learning Rate: 0.00206443
	LOSS [training: 0.16250639418472962 | validation: 0.3386835373948917]
	TIME [epoch: 9.06 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1969779681146135		[learning rate: 0.0020581]
	Learning Rate: 0.0020581
	LOSS [training: 0.1969779681146135 | validation: 0.25308488953797215]
	TIME [epoch: 9.07 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16183197189176063		[learning rate: 0.0020518]
	Learning Rate: 0.00205179
	LOSS [training: 0.16183197189176063 | validation: 0.11851560551841853]
	TIME [epoch: 9.06 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326999987478213		[learning rate: 0.0020455]
	Learning Rate: 0.0020455
	LOSS [training: 0.1326999987478213 | validation: 0.20129256225413433]
	TIME [epoch: 9.05 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20147145050141244		[learning rate: 0.0020392]
	Learning Rate: 0.00203923
	LOSS [training: 0.20147145050141244 | validation: 0.21306301644500103]
	TIME [epoch: 9.05 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25821145778353877		[learning rate: 0.002033]
	Learning Rate: 0.00203298
	LOSS [training: 0.25821145778353877 | validation: 0.14118035980343407]
	TIME [epoch: 9.07 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14805246200718802		[learning rate: 0.0020267]
	Learning Rate: 0.00202675
	LOSS [training: 0.14805246200718802 | validation: 0.09734270431502817]
	TIME [epoch: 9.06 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15156213151005546		[learning rate: 0.0020205]
	Learning Rate: 0.00202054
	LOSS [training: 0.15156213151005546 | validation: 0.3355490984337214]
	TIME [epoch: 9.05 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874732106064263		[learning rate: 0.0020143]
	Learning Rate: 0.00201434
	LOSS [training: 0.2874732106064263 | validation: 0.1945069480960465]
	TIME [epoch: 9.05 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16139906494114462		[learning rate: 0.0020082]
	Learning Rate: 0.00200817
	LOSS [training: 0.16139906494114462 | validation: 0.10901651934433182]
	TIME [epoch: 9.06 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17257857593864456		[learning rate: 0.002002]
	Learning Rate: 0.00200201
	LOSS [training: 0.17257857593864456 | validation: 0.16570366658532962]
	TIME [epoch: 9.06 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14577753029962365		[learning rate: 0.0019959]
	Learning Rate: 0.00199587
	LOSS [training: 0.14577753029962365 | validation: 0.09302513369256193]
	TIME [epoch: 9.05 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18235570826000091		[learning rate: 0.0019898]
	Learning Rate: 0.00198976
	LOSS [training: 0.18235570826000091 | validation: 0.24895763896413814]
	TIME [epoch: 9.05 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22312684837343327		[learning rate: 0.0019837]
	Learning Rate: 0.00198366
	LOSS [training: 0.22312684837343327 | validation: 0.09572354467417821]
	TIME [epoch: 9.06 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13890652523917144		[learning rate: 0.0019776]
	Learning Rate: 0.00197758
	LOSS [training: 0.13890652523917144 | validation: 0.42990259972148315]
	TIME [epoch: 9.07 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19576592181207256		[learning rate: 0.0019715]
	Learning Rate: 0.00197151
	LOSS [training: 0.19576592181207256 | validation: 0.31758029577647184]
	TIME [epoch: 9.06 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22485011860474424		[learning rate: 0.0019655]
	Learning Rate: 0.00196547
	LOSS [training: 0.22485011860474424 | validation: 0.08599040950611458]
	TIME [epoch: 9.06 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1308385963838655		[learning rate: 0.0019594]
	Learning Rate: 0.00195945
	LOSS [training: 0.1308385963838655 | validation: 0.15267546947985033]
	TIME [epoch: 9.05 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14039003017746013		[learning rate: 0.0019534]
	Learning Rate: 0.00195344
	LOSS [training: 0.14039003017746013 | validation: 0.11669118766466599]
	TIME [epoch: 9.08 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1475396741791882		[learning rate: 0.0019475]
	Learning Rate: 0.00194745
	LOSS [training: 0.1475396741791882 | validation: 0.1666670912662494]
	TIME [epoch: 9.05 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16668886590519164		[learning rate: 0.0019415]
	Learning Rate: 0.00194148
	LOSS [training: 0.16668886590519164 | validation: 0.1609708038141383]
	TIME [epoch: 9.06 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17039209356843604		[learning rate: 0.0019355]
	Learning Rate: 0.00193553
	LOSS [training: 0.17039209356843604 | validation: 0.14855439199990259]
	TIME [epoch: 9.05 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19595747619064804		[learning rate: 0.0019296]
	Learning Rate: 0.0019296
	LOSS [training: 0.19595747619064804 | validation: 0.13801846619454425]
	TIME [epoch: 9.08 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11035071074301692		[learning rate: 0.0019237]
	Learning Rate: 0.00192368
	LOSS [training: 0.11035071074301692 | validation: 0.14414647496706678]
	TIME [epoch: 9.06 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19848060542485366		[learning rate: 0.0019178]
	Learning Rate: 0.00191779
	LOSS [training: 0.19848060542485366 | validation: 0.18104012109934908]
	TIME [epoch: 9.06 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1925799947530727		[learning rate: 0.0019119]
	Learning Rate: 0.00191191
	LOSS [training: 0.1925799947530727 | validation: 0.2467854640188037]
	TIME [epoch: 9.05 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18094003754642735		[learning rate: 0.001906]
	Learning Rate: 0.00190605
	LOSS [training: 0.18094003754642735 | validation: 0.09520217225148825]
	TIME [epoch: 9.08 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11193492917232292		[learning rate: 0.0019002]
	Learning Rate: 0.0019002
	LOSS [training: 0.11193492917232292 | validation: 0.18793092258369493]
	TIME [epoch: 9.06 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12647851322519774		[learning rate: 0.0018944]
	Learning Rate: 0.00189438
	LOSS [training: 0.12647851322519774 | validation: 0.06569672158525415]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11928391330445802		[learning rate: 0.0018886]
	Learning Rate: 0.00188857
	LOSS [training: 0.11928391330445802 | validation: 0.15801443997273024]
	TIME [epoch: 9.06 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18541329224056194		[learning rate: 0.0018828]
	Learning Rate: 0.00188278
	LOSS [training: 0.18541329224056194 | validation: 0.12915687026025935]
	TIME [epoch: 9.07 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18486494345069304		[learning rate: 0.001877]
	Learning Rate: 0.00187701
	LOSS [training: 0.18486494345069304 | validation: 0.12022609589017699]
	TIME [epoch: 9.06 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24190163527646852		[learning rate: 0.0018713]
	Learning Rate: 0.00187126
	LOSS [training: 0.24190163527646852 | validation: 0.10852962794307414]
	TIME [epoch: 9.05 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355834539556644		[learning rate: 0.0018655]
	Learning Rate: 0.00186552
	LOSS [training: 0.1355834539556644 | validation: 0.146314525090462]
	TIME [epoch: 9.06 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1538522068623851		[learning rate: 0.0018598]
	Learning Rate: 0.0018598
	LOSS [training: 0.1538522068623851 | validation: 0.169770207316351]
	TIME [epoch: 9.06 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22905040260343035		[learning rate: 0.0018541]
	Learning Rate: 0.0018541
	LOSS [training: 0.22905040260343035 | validation: 0.19296332089431878]
	TIME [epoch: 9.07 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14127171971509908		[learning rate: 0.0018484]
	Learning Rate: 0.00184842
	LOSS [training: 0.14127171971509908 | validation: 0.14552422410115398]
	TIME [epoch: 9.05 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407433415305997		[learning rate: 0.0018428]
	Learning Rate: 0.00184275
	LOSS [training: 0.1407433415305997 | validation: 0.23849163975080362]
	TIME [epoch: 9.06 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23463980071551452		[learning rate: 0.0018371]
	Learning Rate: 0.0018371
	LOSS [training: 0.23463980071551452 | validation: 0.14103939383244207]
	TIME [epoch: 9.06 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15876385091819475		[learning rate: 0.0018315]
	Learning Rate: 0.00183147
	LOSS [training: 0.15876385091819475 | validation: 0.09493236663773955]
	TIME [epoch: 9.08 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16523487845114077		[learning rate: 0.0018259]
	Learning Rate: 0.00182586
	LOSS [training: 0.16523487845114077 | validation: 0.06732410695585392]
	TIME [epoch: 9.05 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15986782297351973		[learning rate: 0.0018203]
	Learning Rate: 0.00182026
	LOSS [training: 0.15986782297351973 | validation: 0.29379390576009934]
	TIME [epoch: 9.06 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18619596144754563		[learning rate: 0.0018147]
	Learning Rate: 0.00181468
	LOSS [training: 0.18619596144754563 | validation: 0.09572189994858685]
	TIME [epoch: 9.06 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1222501256715389		[learning rate: 0.0018091]
	Learning Rate: 0.00180912
	LOSS [training: 0.1222501256715389 | validation: 0.07091705157801816]
	TIME [epoch: 9.08 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216936236574602		[learning rate: 0.0018036]
	Learning Rate: 0.00180357
	LOSS [training: 0.1216936236574602 | validation: 0.14218221666202188]
	TIME [epoch: 9.05 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10030831838276469		[learning rate: 0.001798]
	Learning Rate: 0.00179804
	LOSS [training: 0.10030831838276469 | validation: 0.12749160833421253]
	TIME [epoch: 9.05 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16189243106289286		[learning rate: 0.0017925]
	Learning Rate: 0.00179253
	LOSS [training: 0.16189243106289286 | validation: 0.18338050408855355]
	TIME [epoch: 9.05 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.138590794176155		[learning rate: 0.001787]
	Learning Rate: 0.00178704
	LOSS [training: 0.138590794176155 | validation: 0.09392433998278812]
	TIME [epoch: 9.08 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13216573488881594		[learning rate: 0.0017816]
	Learning Rate: 0.00178156
	LOSS [training: 0.13216573488881594 | validation: 0.13636933397041745]
	TIME [epoch: 9.06 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13075976434602146		[learning rate: 0.0017761]
	Learning Rate: 0.0017761
	LOSS [training: 0.13075976434602146 | validation: 0.13752424595099838]
	TIME [epoch: 9.05 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14319097811782372		[learning rate: 0.0017707]
	Learning Rate: 0.00177065
	LOSS [training: 0.14319097811782372 | validation: 0.22083299262513262]
	TIME [epoch: 9.06 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24895171247666886		[learning rate: 0.0017652]
	Learning Rate: 0.00176522
	LOSS [training: 0.24895171247666886 | validation: 0.19819392183920906]
	TIME [epoch: 9.07 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14577009567775684		[learning rate: 0.0017598]
	Learning Rate: 0.00175981
	LOSS [training: 0.14577009567775684 | validation: 0.1624094136008811]
	TIME [epoch: 9.05 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16338607991946477		[learning rate: 0.0017544]
	Learning Rate: 0.00175442
	LOSS [training: 0.16338607991946477 | validation: 0.1563684910271253]
	TIME [epoch: 9.06 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15974945990929573		[learning rate: 0.001749]
	Learning Rate: 0.00174904
	LOSS [training: 0.15974945990929573 | validation: 0.13195671932548875]
	TIME [epoch: 9.05 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15331653710665244		[learning rate: 0.0017437]
	Learning Rate: 0.00174368
	LOSS [training: 0.15331653710665244 | validation: 0.11131764169295502]
	TIME [epoch: 9.06 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17183514098850594		[learning rate: 0.0017383]
	Learning Rate: 0.00173833
	LOSS [training: 0.17183514098850594 | validation: 0.170995404389723]
	TIME [epoch: 9.07 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21661249844173242		[learning rate: 0.001733]
	Learning Rate: 0.00173301
	LOSS [training: 0.21661249844173242 | validation: 0.19294172646324687]
	TIME [epoch: 9.05 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16112395154258313		[learning rate: 0.0017277]
	Learning Rate: 0.00172769
	LOSS [training: 0.16112395154258313 | validation: 0.10333756065441511]
	TIME [epoch: 9.05 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12925906302466456		[learning rate: 0.0017224]
	Learning Rate: 0.0017224
	LOSS [training: 0.12925906302466456 | validation: 0.09602422362939127]
	TIME [epoch: 9.06 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16468015372688205		[learning rate: 0.0017171]
	Learning Rate: 0.00171712
	LOSS [training: 0.16468015372688205 | validation: 0.21449959501795518]
	TIME [epoch: 9.07 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2873323290617297		[learning rate: 0.0017119]
	Learning Rate: 0.00171185
	LOSS [training: 0.2873323290617297 | validation: 0.19743930361188816]
	TIME [epoch: 9.05 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23319504651800843		[learning rate: 0.0017066]
	Learning Rate: 0.00170661
	LOSS [training: 0.23319504651800843 | validation: 0.1586936092410727]
	TIME [epoch: 9.05 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16041288968783296		[learning rate: 0.0017014]
	Learning Rate: 0.00170137
	LOSS [training: 0.16041288968783296 | validation: 0.25114405709866783]
	TIME [epoch: 9.06 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12477538647673544		[learning rate: 0.0016962]
	Learning Rate: 0.00169616
	LOSS [training: 0.12477538647673544 | validation: 0.0685830113004121]
	TIME [epoch: 9.08 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2159488504952071		[learning rate: 0.001691]
	Learning Rate: 0.00169096
	LOSS [training: 0.2159488504952071 | validation: 0.40246276166304396]
	TIME [epoch: 9.06 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16477990189892477		[learning rate: 0.0016858]
	Learning Rate: 0.00168578
	LOSS [training: 0.16477990189892477 | validation: 0.15192907754587356]
	TIME [epoch: 9.05 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13023181270499315		[learning rate: 0.0016806]
	Learning Rate: 0.00168061
	LOSS [training: 0.13023181270499315 | validation: 0.16146073746107512]
	TIME [epoch: 9.05 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1858076403078528		[learning rate: 0.0016755]
	Learning Rate: 0.00167546
	LOSS [training: 0.1858076403078528 | validation: 0.12154211944227364]
	TIME [epoch: 9.08 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15639526091300643		[learning rate: 0.0016703]
	Learning Rate: 0.00167032
	LOSS [training: 0.15639526091300643 | validation: 0.10829130467392892]
	TIME [epoch: 9.05 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15415367533704247		[learning rate: 0.0016652]
	Learning Rate: 0.0016652
	LOSS [training: 0.15415367533704247 | validation: 0.13804331495443994]
	TIME [epoch: 9.05 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1715607184175087		[learning rate: 0.0016601]
	Learning Rate: 0.0016601
	LOSS [training: 0.1715607184175087 | validation: 0.14898528459229457]
	TIME [epoch: 9.05 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2531348833841081		[learning rate: 0.001655]
	Learning Rate: 0.00165501
	LOSS [training: 0.2531348833841081 | validation: 0.1749966075095199]
	TIME [epoch: 9.06 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23777548951571242		[learning rate: 0.0016499]
	Learning Rate: 0.00164993
	LOSS [training: 0.23777548951571242 | validation: 0.2162048291210528]
	TIME [epoch: 9.04 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19235154277340977		[learning rate: 0.0016449]
	Learning Rate: 0.00164488
	LOSS [training: 0.19235154277340977 | validation: 0.1165773350902922]
	TIME [epoch: 9.05 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15835187851574628		[learning rate: 0.0016398]
	Learning Rate: 0.00163983
	LOSS [training: 0.15835187851574628 | validation: 0.1477064062807591]
	TIME [epoch: 9.05 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17923242310540882		[learning rate: 0.0016348]
	Learning Rate: 0.00163481
	LOSS [training: 0.17923242310540882 | validation: 0.23336020408463187]
	TIME [epoch: 9.07 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22002606351182238		[learning rate: 0.0016298]
	Learning Rate: 0.0016298
	LOSS [training: 0.22002606351182238 | validation: 0.2657770015329967]
	TIME [epoch: 9.06 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26526044005400357		[learning rate: 0.0016248]
	Learning Rate: 0.0016248
	LOSS [training: 0.26526044005400357 | validation: 0.21746504467811045]
	TIME [epoch: 9.06 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18882473642398712		[learning rate: 0.0016198]
	Learning Rate: 0.00161982
	LOSS [training: 0.18882473642398712 | validation: 0.149219225644364]
	TIME [epoch: 9.07 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17623738822074322		[learning rate: 0.0016149]
	Learning Rate: 0.00161485
	LOSS [training: 0.17623738822074322 | validation: 0.19633143003936301]
	TIME [epoch: 9.08 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18003298373511106		[learning rate: 0.0016099]
	Learning Rate: 0.0016099
	LOSS [training: 0.18003298373511106 | validation: 0.20996006394948097]
	TIME [epoch: 9.08 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1773361784239002		[learning rate: 0.001605]
	Learning Rate: 0.00160497
	LOSS [training: 0.1773361784239002 | validation: 0.13900669444877667]
	TIME [epoch: 9.06 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1887518047000157		[learning rate: 0.0016]
	Learning Rate: 0.00160005
	LOSS [training: 0.1887518047000157 | validation: 0.09703565131331562]
	TIME [epoch: 9.06 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13042427742280205		[learning rate: 0.0015951]
	Learning Rate: 0.00159514
	LOSS [training: 0.13042427742280205 | validation: 0.10982490704660085]
	TIME [epoch: 9.06 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1447984064619347		[learning rate: 0.0015903]
	Learning Rate: 0.00159025
	LOSS [training: 0.1447984064619347 | validation: 0.13349059754187598]
	TIME [epoch: 9.08 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09917847373615547		[learning rate: 0.0015854]
	Learning Rate: 0.00158538
	LOSS [training: 0.09917847373615547 | validation: 0.1409492752345594]
	TIME [epoch: 9.06 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19448018265569028		[learning rate: 0.0015805]
	Learning Rate: 0.00158052
	LOSS [training: 0.19448018265569028 | validation: 0.12406975025196376]
	TIME [epoch: 9.06 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1363310083969922		[learning rate: 0.0015757]
	Learning Rate: 0.00157568
	LOSS [training: 0.1363310083969922 | validation: 0.1612167244288341]
	TIME [epoch: 9.05 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1556511773503458		[learning rate: 0.0015708]
	Learning Rate: 0.00157084
	LOSS [training: 0.1556511773503458 | validation: 0.15176916894489223]
	TIME [epoch: 9.08 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2002499180041785		[learning rate: 0.001566]
	Learning Rate: 0.00156603
	LOSS [training: 0.2002499180041785 | validation: 0.1516157173556753]
	TIME [epoch: 9.05 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14635550479553858		[learning rate: 0.0015612]
	Learning Rate: 0.00156123
	LOSS [training: 0.14635550479553858 | validation: 0.16110517729428844]
	TIME [epoch: 9.06 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21433736203952378		[learning rate: 0.0015564]
	Learning Rate: 0.00155644
	LOSS [training: 0.21433736203952378 | validation: 0.13563785405112597]
	TIME [epoch: 9.06 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1569640036386543		[learning rate: 0.0015517]
	Learning Rate: 0.00155167
	LOSS [training: 0.1569640036386543 | validation: 0.22222155117755432]
	TIME [epoch: 9.07 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1536924150341423		[learning rate: 0.0015469]
	Learning Rate: 0.00154692
	LOSS [training: 0.1536924150341423 | validation: 0.16149659839046876]
	TIME [epoch: 9.06 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1352122538660463		[learning rate: 0.0015422]
	Learning Rate: 0.00154217
	LOSS [training: 0.1352122538660463 | validation: 0.09471839987813663]
	TIME [epoch: 9.05 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11685289229126902		[learning rate: 0.0015374]
	Learning Rate: 0.00153745
	LOSS [training: 0.11685289229126902 | validation: 0.21442229287884151]
	TIME [epoch: 9.06 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1097777370600153		[learning rate: 0.0015327]
	Learning Rate: 0.00153273
	LOSS [training: 0.1097777370600153 | validation: 0.05945656873620053]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1111.pth
	Model improved!!!
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10816770915014243		[learning rate: 0.001528]
	Learning Rate: 0.00152804
	LOSS [training: 0.10816770915014243 | validation: 0.24833614442724566]
	TIME [epoch: 9.06 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13657813068188493		[learning rate: 0.0015234]
	Learning Rate: 0.00152335
	LOSS [training: 0.13657813068188493 | validation: 0.11711831868263532]
	TIME [epoch: 9.04 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1202322878047083		[learning rate: 0.0015187]
	Learning Rate: 0.00151868
	LOSS [training: 0.1202322878047083 | validation: 0.1015471225489969]
	TIME [epoch: 9.05 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14493104561574005		[learning rate: 0.001514]
	Learning Rate: 0.00151403
	LOSS [training: 0.14493104561574005 | validation: 0.10708004156414666]
	TIME [epoch: 9.05 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1176941790460175		[learning rate: 0.0015094]
	Learning Rate: 0.00150938
	LOSS [training: 0.1176941790460175 | validation: 0.09811287514568443]
	TIME [epoch: 9.07 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08801011917961522		[learning rate: 0.0015048]
	Learning Rate: 0.00150476
	LOSS [training: 0.08801011917961522 | validation: 0.10718316473581299]
	TIME [epoch: 9.05 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09912711439006873		[learning rate: 0.0015001]
	Learning Rate: 0.00150015
	LOSS [training: 0.09912711439006873 | validation: 0.12728777755629475]
	TIME [epoch: 9.05 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09845402108015489		[learning rate: 0.0014955]
	Learning Rate: 0.00149555
	LOSS [training: 0.09845402108015489 | validation: 0.06210889054338853]
	TIME [epoch: 9.05 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1241129930267997		[learning rate: 0.001491]
	Learning Rate: 0.00149096
	LOSS [training: 0.1241129930267997 | validation: 0.16746085689132778]
	TIME [epoch: 9.07 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1418695637443455		[learning rate: 0.0014864]
	Learning Rate: 0.00148639
	LOSS [training: 0.1418695637443455 | validation: 0.08503532681544135]
	TIME [epoch: 9.05 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13941772096291188		[learning rate: 0.0014818]
	Learning Rate: 0.00148184
	LOSS [training: 0.13941772096291188 | validation: 0.10558129190322119]
	TIME [epoch: 9.05 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15783030344987872		[learning rate: 0.0014773]
	Learning Rate: 0.00147729
	LOSS [training: 0.15783030344987872 | validation: 0.07255847279611283]
	TIME [epoch: 9.05 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10057665632169174		[learning rate: 0.0014728]
	Learning Rate: 0.00147276
	LOSS [training: 0.10057665632169174 | validation: 0.07038954346470669]
	TIME [epoch: 9.07 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13129794749464024		[learning rate: 0.0014682]
	Learning Rate: 0.00146825
	LOSS [training: 0.13129794749464024 | validation: 0.1565110033352157]
	TIME [epoch: 9.05 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09572196007016201		[learning rate: 0.0014637]
	Learning Rate: 0.00146375
	LOSS [training: 0.09572196007016201 | validation: 0.1408399118226396]
	TIME [epoch: 9.04 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12389258647242266		[learning rate: 0.0014593]
	Learning Rate: 0.00145926
	LOSS [training: 0.12389258647242266 | validation: 0.09837875903905317]
	TIME [epoch: 9.05 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1423580043541182		[learning rate: 0.0014548]
	Learning Rate: 0.00145479
	LOSS [training: 0.1423580043541182 | validation: 0.09418787555065403]
	TIME [epoch: 9.07 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0805485906176828		[learning rate: 0.0014503]
	Learning Rate: 0.00145033
	LOSS [training: 0.0805485906176828 | validation: 0.10231389214366238]
	TIME [epoch: 9.05 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415371704156985		[learning rate: 0.0014459]
	Learning Rate: 0.00144588
	LOSS [training: 0.1415371704156985 | validation: 0.16009949607210264]
	TIME [epoch: 9.05 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1296317641637421		[learning rate: 0.0014415]
	Learning Rate: 0.00144145
	LOSS [training: 0.1296317641637421 | validation: 0.03750316814643854]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1131.pth
	Model improved!!!
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10729441666710304		[learning rate: 0.001437]
	Learning Rate: 0.00143703
	LOSS [training: 0.10729441666710304 | validation: 0.11856331192917084]
	TIME [epoch: 9.08 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09870459971193463		[learning rate: 0.0014326]
	Learning Rate: 0.00143263
	LOSS [training: 0.09870459971193463 | validation: 0.1589407958300289]
	TIME [epoch: 9.05 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16098144564272274		[learning rate: 0.0014282]
	Learning Rate: 0.00142824
	LOSS [training: 0.16098144564272274 | validation: 0.33926706889749214]
	TIME [epoch: 9.05 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13828692766910772		[learning rate: 0.0014239]
	Learning Rate: 0.00142386
	LOSS [training: 0.13828692766910772 | validation: 0.17679384012089686]
	TIME [epoch: 9.05 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11073086779392319		[learning rate: 0.0014195]
	Learning Rate: 0.00141949
	LOSS [training: 0.11073086779392319 | validation: 0.16085999176270716]
	TIME [epoch: 9.07 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1274581360221752		[learning rate: 0.0014151]
	Learning Rate: 0.00141514
	LOSS [training: 0.1274581360221752 | validation: 0.053172440358212905]
	TIME [epoch: 9.05 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11327447497991558		[learning rate: 0.0014108]
	Learning Rate: 0.0014108
	LOSS [training: 0.11327447497991558 | validation: 0.16713546504985582]
	TIME [epoch: 9.05 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11113578307894116		[learning rate: 0.0014065]
	Learning Rate: 0.00140648
	LOSS [training: 0.11113578307894116 | validation: 0.05333182168581167]
	TIME [epoch: 9.05 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12904916190441537		[learning rate: 0.0014022]
	Learning Rate: 0.00140217
	LOSS [training: 0.12904916190441537 | validation: 0.08591787412329654]
	TIME [epoch: 9.06 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11930433145823324		[learning rate: 0.0013979]
	Learning Rate: 0.00139787
	LOSS [training: 0.11930433145823324 | validation: 0.13781146443917072]
	TIME [epoch: 9.05 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322471973176655		[learning rate: 0.0013936]
	Learning Rate: 0.00139358
	LOSS [training: 0.1322471973176655 | validation: 0.06396550100097464]
	TIME [epoch: 9.05 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10374230557629197		[learning rate: 0.0013893]
	Learning Rate: 0.00138931
	LOSS [training: 0.10374230557629197 | validation: 0.09507182953179165]
	TIME [epoch: 9.05 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09476708054742308		[learning rate: 0.0013851]
	Learning Rate: 0.00138505
	LOSS [training: 0.09476708054742308 | validation: 0.1853607764140021]
	TIME [epoch: 9.05 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15926550180970783		[learning rate: 0.0013808]
	Learning Rate: 0.00138081
	LOSS [training: 0.15926550180970783 | validation: 0.10558297709336623]
	TIME [epoch: 9.06 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14547365830332876		[learning rate: 0.0013766]
	Learning Rate: 0.00137658
	LOSS [training: 0.14547365830332876 | validation: 0.1088485732843816]
	TIME [epoch: 9.04 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14309561264858728		[learning rate: 0.0013724]
	Learning Rate: 0.00137236
	LOSS [training: 0.14309561264858728 | validation: 0.06416011546238154]
	TIME [epoch: 9.05 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040101795629552		[learning rate: 0.0013681]
	Learning Rate: 0.00136815
	LOSS [training: 0.2040101795629552 | validation: 0.1516922451697003]
	TIME [epoch: 9.05 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11309221029925398		[learning rate: 0.001364]
	Learning Rate: 0.00136395
	LOSS [training: 0.11309221029925398 | validation: 0.12325309257074676]
	TIME [epoch: 9.07 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11187382201026001		[learning rate: 0.0013598]
	Learning Rate: 0.00135977
	LOSS [training: 0.11187382201026001 | validation: 0.06824549797930778]
	TIME [epoch: 9.05 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09405553179432491		[learning rate: 0.0013556]
	Learning Rate: 0.00135561
	LOSS [training: 0.09405553179432491 | validation: 0.09146157933061977]
	TIME [epoch: 9.05 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11187517069713271		[learning rate: 0.0013515]
	Learning Rate: 0.00135145
	LOSS [training: 0.11187517069713271 | validation: 0.06324491448020181]
	TIME [epoch: 9.06 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09077945056346436		[learning rate: 0.0013473]
	Learning Rate: 0.00134731
	LOSS [training: 0.09077945056346436 | validation: 0.13173737618370668]
	TIME [epoch: 9.06 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07682854065528456		[learning rate: 0.0013432]
	Learning Rate: 0.00134318
	LOSS [training: 0.07682854065528456 | validation: 0.09437790694712601]
	TIME [epoch: 9.05 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12147893350623067		[learning rate: 0.0013391]
	Learning Rate: 0.00133906
	LOSS [training: 0.12147893350623067 | validation: 0.24042319312061822]
	TIME [epoch: 9.04 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14241736302910496		[learning rate: 0.001335]
	Learning Rate: 0.00133496
	LOSS [training: 0.14241736302910496 | validation: 0.1380780097113299]
	TIME [epoch: 9.04 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0886347914592935		[learning rate: 0.0013309]
	Learning Rate: 0.00133086
	LOSS [training: 0.0886347914592935 | validation: 0.048768426591224226]
	TIME [epoch: 9.07 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08665186804689455		[learning rate: 0.0013268]
	Learning Rate: 0.00132678
	LOSS [training: 0.08665186804689455 | validation: 0.06814377513786496]
	TIME [epoch: 9.05 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09190634247192278		[learning rate: 0.0013227]
	Learning Rate: 0.00132272
	LOSS [training: 0.09190634247192278 | validation: 0.09316403000820342]
	TIME [epoch: 9.05 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09605176701427079		[learning rate: 0.0013187]
	Learning Rate: 0.00131866
	LOSS [training: 0.09605176701427079 | validation: 0.051625530786320664]
	TIME [epoch: 9.05 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.117035311646151		[learning rate: 0.0013146]
	Learning Rate: 0.00131462
	LOSS [training: 0.117035311646151 | validation: 0.19631735599749495]
	TIME [epoch: 9.05 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20051014338759693		[learning rate: 0.0013106]
	Learning Rate: 0.00131059
	LOSS [training: 0.20051014338759693 | validation: 0.24365277344863803]
	TIME [epoch: 9.05 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1475772105069808		[learning rate: 0.0013066]
	Learning Rate: 0.00130657
	LOSS [training: 0.1475772105069808 | validation: 0.06883218557048082]
	TIME [epoch: 9.05 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09314922714734518		[learning rate: 0.0013026]
	Learning Rate: 0.00130257
	LOSS [training: 0.09314922714734518 | validation: 0.11824636316677034]
	TIME [epoch: 9.05 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09961536544306328		[learning rate: 0.0012986]
	Learning Rate: 0.00129857
	LOSS [training: 0.09961536544306328 | validation: 0.07463631330711383]
	TIME [epoch: 9.06 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08051841733392855		[learning rate: 0.0012946]
	Learning Rate: 0.00129459
	LOSS [training: 0.08051841733392855 | validation: 0.07759289543130823]
	TIME [epoch: 9.07 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003193540802666		[learning rate: 0.0012906]
	Learning Rate: 0.00129062
	LOSS [training: 0.12003193540802666 | validation: 0.0568946237579251]
	TIME [epoch: 9.05 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1084223299096245		[learning rate: 0.0012867]
	Learning Rate: 0.00128667
	LOSS [training: 0.1084223299096245 | validation: 0.11720406234726563]
	TIME [epoch: 9.05 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11159293558775754		[learning rate: 0.0012827]
	Learning Rate: 0.00128272
	LOSS [training: 0.11159293558775754 | validation: 0.07684856093736456]
	TIME [epoch: 9.05 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09158565200226211		[learning rate: 0.0012788]
	Learning Rate: 0.00127879
	LOSS [training: 0.09158565200226211 | validation: 0.0833976928322532]
	TIME [epoch: 9.07 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10536518052643909		[learning rate: 0.0012749]
	Learning Rate: 0.00127487
	LOSS [training: 0.10536518052643909 | validation: 0.05519257096891722]
	TIME [epoch: 9.04 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11275666516083098		[learning rate: 0.001271]
	Learning Rate: 0.00127096
	LOSS [training: 0.11275666516083098 | validation: 0.21141028709819648]
	TIME [epoch: 9.05 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08839938931790127		[learning rate: 0.0012671]
	Learning Rate: 0.00126707
	LOSS [training: 0.08839938931790127 | validation: 0.06879879216897536]
	TIME [epoch: 9.05 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07362659597939636		[learning rate: 0.0012632]
	Learning Rate: 0.00126318
	LOSS [training: 0.07362659597939636 | validation: 0.05208182874794022]
	TIME [epoch: 9.07 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12136042105651768		[learning rate: 0.0012593]
	Learning Rate: 0.00125931
	LOSS [training: 0.12136042105651768 | validation: 0.05788417444821428]
	TIME [epoch: 9.05 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10467802809494717		[learning rate: 0.0012555]
	Learning Rate: 0.00125545
	LOSS [training: 0.10467802809494717 | validation: 0.08925503607616586]
	TIME [epoch: 9.04 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12215570169522964		[learning rate: 0.0012516]
	Learning Rate: 0.0012516
	LOSS [training: 0.12215570169522964 | validation: 0.09877148865467307]
	TIME [epoch: 9.05 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1102830269400065		[learning rate: 0.0012478]
	Learning Rate: 0.00124777
	LOSS [training: 0.1102830269400065 | validation: 0.18836217093122115]
	TIME [epoch: 9.08 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1349547387882021		[learning rate: 0.0012439]
	Learning Rate: 0.00124394
	LOSS [training: 0.1349547387882021 | validation: 0.17398854369642638]
	TIME [epoch: 9.05 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289349116043785		[learning rate: 0.0012401]
	Learning Rate: 0.00124013
	LOSS [training: 0.1289349116043785 | validation: 0.08020527813637354]
	TIME [epoch: 9.05 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08766878518573176		[learning rate: 0.0012363]
	Learning Rate: 0.00123633
	LOSS [training: 0.08766878518573176 | validation: 0.06016154327214497]
	TIME [epoch: 9.04 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07481263771139263		[learning rate: 0.0012325]
	Learning Rate: 0.00123254
	LOSS [training: 0.07481263771139263 | validation: 0.09984927139458649]
	TIME [epoch: 9.06 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1051131769566949		[learning rate: 0.0012288]
	Learning Rate: 0.00122876
	LOSS [training: 0.1051131769566949 | validation: 0.18348503405022187]
	TIME [epoch: 9.05 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15398598635809155		[learning rate: 0.001225]
	Learning Rate: 0.00122499
	LOSS [training: 0.15398598635809155 | validation: 0.15196659186407022]
	TIME [epoch: 9.05 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11907495419336953		[learning rate: 0.0012212]
	Learning Rate: 0.00122124
	LOSS [training: 0.11907495419336953 | validation: 0.05645917804597063]
	TIME [epoch: 9.04 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266313850101304		[learning rate: 0.0012175]
	Learning Rate: 0.00121749
	LOSS [training: 0.12266313850101304 | validation: 0.1135787775953245]
	TIME [epoch: 9.06 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09130856412673925		[learning rate: 0.0012138]
	Learning Rate: 0.00121376
	LOSS [training: 0.09130856412673925 | validation: 0.07549256160753812]
	TIME [epoch: 9.06 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08413278421043784		[learning rate: 0.00121]
	Learning Rate: 0.00121004
	LOSS [training: 0.08413278421043784 | validation: 0.03940521188256434]
	TIME [epoch: 9.06 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09283775529356575		[learning rate: 0.0012063]
	Learning Rate: 0.00120633
	LOSS [training: 0.09283775529356575 | validation: 0.06767148619779742]
	TIME [epoch: 9.05 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08636743055577922		[learning rate: 0.0012026]
	Learning Rate: 0.00120263
	LOSS [training: 0.08636743055577922 | validation: 0.09923091552937438]
	TIME [epoch: 9.06 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12255568803610992		[learning rate: 0.0011989]
	Learning Rate: 0.00119895
	LOSS [training: 0.12255568803610992 | validation: 0.09079646911103131]
	TIME [epoch: 9.07 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10277301168520733		[learning rate: 0.0011953]
	Learning Rate: 0.00119527
	LOSS [training: 0.10277301168520733 | validation: 0.11377296163053616]
	TIME [epoch: 9.04 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11310106197563638		[learning rate: 0.0011916]
	Learning Rate: 0.00119161
	LOSS [training: 0.11310106197563638 | validation: 0.09596340943044587]
	TIME [epoch: 9.05 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11091970307064333		[learning rate: 0.001188]
	Learning Rate: 0.00118795
	LOSS [training: 0.11091970307064333 | validation: 0.16892427430477933]
	TIME [epoch: 9.04 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09755432321618081		[learning rate: 0.0011843]
	Learning Rate: 0.00118431
	LOSS [training: 0.09755432321618081 | validation: 0.10062498646030718]
	TIME [epoch: 9.06 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10073261411128501		[learning rate: 0.0011807]
	Learning Rate: 0.00118068
	LOSS [training: 0.10073261411128501 | validation: 0.22959267948321027]
	TIME [epoch: 9.04 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09883401196277072		[learning rate: 0.0011771]
	Learning Rate: 0.00117706
	LOSS [training: 0.09883401196277072 | validation: 0.1039934545215449]
	TIME [epoch: 9.05 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09760186468552014		[learning rate: 0.0011735]
	Learning Rate: 0.00117346
	LOSS [training: 0.09760186468552014 | validation: 0.05311878274980472]
	TIME [epoch: 9.05 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07328667373237477		[learning rate: 0.0011699]
	Learning Rate: 0.00116986
	LOSS [training: 0.07328667373237477 | validation: 0.07590035387840477]
	TIME [epoch: 9.07 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09687689507614036		[learning rate: 0.0011663]
	Learning Rate: 0.00116627
	LOSS [training: 0.09687689507614036 | validation: 0.17836493905457118]
	TIME [epoch: 9.05 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1605945994207628		[learning rate: 0.0011627]
	Learning Rate: 0.0011627
	LOSS [training: 0.1605945994207628 | validation: 0.05577248229966078]
	TIME [epoch: 9.05 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07418144737576783		[learning rate: 0.0011591]
	Learning Rate: 0.00115913
	LOSS [training: 0.07418144737576783 | validation: 0.12353066316860527]
	TIME [epoch: 9.04 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12889222471296455		[learning rate: 0.0011556]
	Learning Rate: 0.00115558
	LOSS [training: 0.12889222471296455 | validation: 0.11205531787432059]
	TIME [epoch: 9.07 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09675989521515058		[learning rate: 0.001152]
	Learning Rate: 0.00115204
	LOSS [training: 0.09675989521515058 | validation: 0.13069630456325124]
	TIME [epoch: 9.04 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0987516182808801		[learning rate: 0.0011485]
	Learning Rate: 0.00114851
	LOSS [training: 0.0987516182808801 | validation: 0.1313979020287287]
	TIME [epoch: 9.04 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15080957733098063		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.15080957733098063 | validation: 0.11706848999474945]
	TIME [epoch: 9.05 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11742559968345893		[learning rate: 0.0011415]
	Learning Rate: 0.00114148
	LOSS [training: 0.11742559968345893 | validation: 0.07167444017916186]
	TIME [epoch: 9.06 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11889192165957148		[learning rate: 0.001138]
	Learning Rate: 0.00113798
	LOSS [training: 0.11889192165957148 | validation: 0.16106254099572465]
	TIME [epoch: 9.06 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13080081291455886		[learning rate: 0.0011345]
	Learning Rate: 0.00113449
	LOSS [training: 0.13080081291455886 | validation: 0.07813647766970691]
	TIME [epoch: 9.04 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09664187536387844		[learning rate: 0.001131]
	Learning Rate: 0.00113101
	LOSS [training: 0.09664187536387844 | validation: 0.05600834105080993]
	TIME [epoch: 9.04 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09936791737598166		[learning rate: 0.0011275]
	Learning Rate: 0.00112754
	LOSS [training: 0.09936791737598166 | validation: 0.097818981689233]
	TIME [epoch: 9.05 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09296592606307938		[learning rate: 0.0011241]
	Learning Rate: 0.00112409
	LOSS [training: 0.09296592606307938 | validation: 0.09579030052492221]
	TIME [epoch: 9.06 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08830058882378286		[learning rate: 0.0011206]
	Learning Rate: 0.00112064
	LOSS [training: 0.08830058882378286 | validation: 0.11199027756160301]
	TIME [epoch: 9.05 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10302356138291349		[learning rate: 0.0011172]
	Learning Rate: 0.00111721
	LOSS [training: 0.10302356138291349 | validation: 0.032887593641159105]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1214.pth
	Model improved!!!
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10392402423043931		[learning rate: 0.0011138]
	Learning Rate: 0.00111378
	LOSS [training: 0.10392402423043931 | validation: 0.07596043421053328]
	TIME [epoch: 9.06 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08576300359669393		[learning rate: 0.0011104]
	Learning Rate: 0.00111037
	LOSS [training: 0.08576300359669393 | validation: 0.05937903682716911]
	TIME [epoch: 9.06 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11299774774603626		[learning rate: 0.001107]
	Learning Rate: 0.00110696
	LOSS [training: 0.11299774774603626 | validation: 0.029370038680884947]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1217.pth
	Model improved!!!
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707228914267648		[learning rate: 0.0011036]
	Learning Rate: 0.00110357
	LOSS [training: 0.08707228914267648 | validation: 0.10274107934859666]
	TIME [epoch: 9.06 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12185405285344442		[learning rate: 0.0011002]
	Learning Rate: 0.00110019
	LOSS [training: 0.12185405285344442 | validation: 0.13772760513545995]
	TIME [epoch: 9.05 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13811215403426413		[learning rate: 0.0010968]
	Learning Rate: 0.00109681
	LOSS [training: 0.13811215403426413 | validation: 0.11801979381243306]
	TIME [epoch: 9.09 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13865892078473596		[learning rate: 0.0010935]
	Learning Rate: 0.00109345
	LOSS [training: 0.13865892078473596 | validation: 0.12083789373331713]
	TIME [epoch: 9.06 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11514570281270613		[learning rate: 0.0010901]
	Learning Rate: 0.0010901
	LOSS [training: 0.11514570281270613 | validation: 0.09358686282652896]
	TIME [epoch: 9.06 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10766467158166107		[learning rate: 0.0010868]
	Learning Rate: 0.00108676
	LOSS [training: 0.10766467158166107 | validation: 0.13388288638480617]
	TIME [epoch: 9.06 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09454811497382755		[learning rate: 0.0010834]
	Learning Rate: 0.00108343
	LOSS [training: 0.09454811497382755 | validation: 0.08348762357509228]
	TIME [epoch: 9.08 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006164077626456		[learning rate: 0.0010801]
	Learning Rate: 0.00108011
	LOSS [training: 0.10006164077626456 | validation: 0.1941778549098774]
	TIME [epoch: 9.06 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1072168202170836		[learning rate: 0.0010768]
	Learning Rate: 0.0010768
	LOSS [training: 0.1072168202170836 | validation: 0.0470656548418781]
	TIME [epoch: 9.06 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07798763290861044		[learning rate: 0.0010735]
	Learning Rate: 0.00107349
	LOSS [training: 0.07798763290861044 | validation: 0.23495988067826085]
	TIME [epoch: 9.06 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10056407434383526		[learning rate: 0.0010702]
	Learning Rate: 0.0010702
	LOSS [training: 0.10056407434383526 | validation: 0.05805627588334121]
	TIME [epoch: 9.08 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08835740587682397		[learning rate: 0.0010669]
	Learning Rate: 0.00106692
	LOSS [training: 0.08835740587682397 | validation: 0.04255307134369994]
	TIME [epoch: 9.07 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07922158201610721		[learning rate: 0.0010637]
	Learning Rate: 0.00106365
	LOSS [training: 0.07922158201610721 | validation: 0.06185103837813412]
	TIME [epoch: 9.07 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09064360131433269		[learning rate: 0.0010604]
	Learning Rate: 0.00106039
	LOSS [training: 0.09064360131433269 | validation: 0.032866623146545475]
	TIME [epoch: 9.07 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10361416113859427		[learning rate: 0.0010571]
	Learning Rate: 0.00105714
	LOSS [training: 0.10361416113859427 | validation: 0.16108782502614416]
	TIME [epoch: 9.08 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14341770531318876		[learning rate: 0.0010539]
	Learning Rate: 0.0010539
	LOSS [training: 0.14341770531318876 | validation: 0.16699906112994706]
	TIME [epoch: 9.07 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13841640217376835		[learning rate: 0.0010507]
	Learning Rate: 0.00105067
	LOSS [training: 0.13841640217376835 | validation: 0.12583855834164692]
	TIME [epoch: 9.07 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12886864657354558		[learning rate: 0.0010475]
	Learning Rate: 0.00104745
	LOSS [training: 0.12886864657354558 | validation: 0.10771306341650422]
	TIME [epoch: 9.07 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08608195801234896		[learning rate: 0.0010442]
	Learning Rate: 0.00104424
	LOSS [training: 0.08608195801234896 | validation: 0.03992020026962023]
	TIME [epoch: 9.07 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08265774273614604		[learning rate: 0.001041]
	Learning Rate: 0.00104104
	LOSS [training: 0.08265774273614604 | validation: 0.04474908255351756]
	TIME [epoch: 9.07 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07318011516900894		[learning rate: 0.0010378]
	Learning Rate: 0.00103785
	LOSS [training: 0.07318011516900894 | validation: 0.07782945254697063]
	TIME [epoch: 9.06 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11658714123773647		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.11658714123773647 | validation: 0.06926656660231215]
	TIME [epoch: 9.05 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674428279306533		[learning rate: 0.0010315]
	Learning Rate: 0.00103149
	LOSS [training: 0.05674428279306533 | validation: 0.04371286888740787]
	TIME [epoch: 9.06 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10727774624475454		[learning rate: 0.0010283]
	Learning Rate: 0.00102833
	LOSS [training: 0.10727774624475454 | validation: 0.1397088825352048]
	TIME [epoch: 9.08 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11196788394792415		[learning rate: 0.0010252]
	Learning Rate: 0.00102518
	LOSS [training: 0.11196788394792415 | validation: 0.06751492631288637]
	TIME [epoch: 9.06 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328470573897909		[learning rate: 0.001022]
	Learning Rate: 0.00102204
	LOSS [training: 0.08328470573897909 | validation: 0.07917430252864296]
	TIME [epoch: 9.05 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08293725503852645		[learning rate: 0.0010189]
	Learning Rate: 0.0010189
	LOSS [training: 0.08293725503852645 | validation: 0.06861634712472962]
	TIME [epoch: 9.05 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11489080384062952		[learning rate: 0.0010158]
	Learning Rate: 0.00101578
	LOSS [training: 0.11489080384062952 | validation: 0.0410713907328094]
	TIME [epoch: 9.08 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1218026221983172		[learning rate: 0.0010127]
	Learning Rate: 0.00101267
	LOSS [training: 0.1218026221983172 | validation: 0.20154545916654754]
	TIME [epoch: 9.06 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09348096460223652		[learning rate: 0.0010096]
	Learning Rate: 0.00100956
	LOSS [training: 0.09348096460223652 | validation: 0.05252151381779123]
	TIME [epoch: 9.06 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06940032546904873		[learning rate: 0.0010065]
	Learning Rate: 0.00100647
	LOSS [training: 0.06940032546904873 | validation: 0.052548566927312856]
	TIME [epoch: 9.06 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07191827462859089		[learning rate: 0.0010034]
	Learning Rate: 0.00100338
	LOSS [training: 0.07191827462859089 | validation: 0.10879765731849231]
	TIME [epoch: 9.08 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13242160233959716		[learning rate: 0.0010003]
	Learning Rate: 0.00100031
	LOSS [training: 0.13242160233959716 | validation: 0.11296056791934017]
	TIME [epoch: 9.06 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325129401888245		[learning rate: 0.00099724]
	Learning Rate: 0.000997241
	LOSS [training: 0.1325129401888245 | validation: 0.14039166797573938]
	TIME [epoch: 9.04 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11742962798994219		[learning rate: 0.00099418]
	Learning Rate: 0.000994184
	LOSS [training: 0.11742962798994219 | validation: 0.04549450401953903]
	TIME [epoch: 9.04 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07491568168544646		[learning rate: 0.00099114]
	Learning Rate: 0.000991136
	LOSS [training: 0.07491568168544646 | validation: 0.0584793837950667]
	TIME [epoch: 9.07 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185003833537927		[learning rate: 0.0009881]
	Learning Rate: 0.000988098
	LOSS [training: 0.10185003833537927 | validation: 0.12081441986297327]
	TIME [epoch: 9.05 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780302009827135		[learning rate: 0.00098507]
	Learning Rate: 0.000985069
	LOSS [training: 0.0780302009827135 | validation: 0.0750165534408752]
	TIME [epoch: 9.05 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08984963499293297		[learning rate: 0.00098205]
	Learning Rate: 0.00098205
	LOSS [training: 0.08984963499293297 | validation: 0.07545873156096422]
	TIME [epoch: 9.05 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09585922433142582		[learning rate: 0.00097904]
	Learning Rate: 0.000979039
	LOSS [training: 0.09585922433142582 | validation: 0.14358796825945375]
	TIME [epoch: 9.06 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126732193045005		[learning rate: 0.00097604]
	Learning Rate: 0.000976038
	LOSS [training: 0.126732193045005 | validation: 0.1023024806957438]
	TIME [epoch: 9.06 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10121236589091384		[learning rate: 0.00097305]
	Learning Rate: 0.000973046
	LOSS [training: 0.10121236589091384 | validation: 0.05897268800719873]
	TIME [epoch: 9.05 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10571439335563346		[learning rate: 0.00097006]
	Learning Rate: 0.000970063
	LOSS [training: 0.10571439335563346 | validation: 0.05193254642576706]
	TIME [epoch: 9.11 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1287988667388557		[learning rate: 0.00096709]
	Learning Rate: 0.000967089
	LOSS [training: 0.1287988667388557 | validation: 0.06279309064934693]
	TIME [epoch: 9.04 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08997645716294962		[learning rate: 0.00096412]
	Learning Rate: 0.000964125
	LOSS [training: 0.08997645716294962 | validation: 0.09819373687708664]
	TIME [epoch: 9.07 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0869682091879447		[learning rate: 0.00096117]
	Learning Rate: 0.00096117
	LOSS [training: 0.0869682091879447 | validation: 0.026073318539020653]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1263.pth
	Model improved!!!
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07858732852654018		[learning rate: 0.00095822]
	Learning Rate: 0.000958223
	LOSS [training: 0.07858732852654018 | validation: 0.04740442022751747]
	TIME [epoch: 9.05 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11200751558232344		[learning rate: 0.00095529]
	Learning Rate: 0.000955286
	LOSS [training: 0.11200751558232344 | validation: 0.04889777792908565]
	TIME [epoch: 9.05 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06376506618213547		[learning rate: 0.00095236]
	Learning Rate: 0.000952357
	LOSS [training: 0.06376506618213547 | validation: 0.037171319006155244]
	TIME [epoch: 9.07 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07862132179677704		[learning rate: 0.00094944]
	Learning Rate: 0.000949438
	LOSS [training: 0.07862132179677704 | validation: 0.0850163097846439]
	TIME [epoch: 9.05 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07472079122237898		[learning rate: 0.00094653]
	Learning Rate: 0.000946528
	LOSS [training: 0.07472079122237898 | validation: 0.07676867365625534]
	TIME [epoch: 9.05 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651870728720367		[learning rate: 0.00094363]
	Learning Rate: 0.000943626
	LOSS [training: 0.06651870728720367 | validation: 0.03590452153088987]
	TIME [epoch: 9.05 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06619121864288977		[learning rate: 0.00094073]
	Learning Rate: 0.000940734
	LOSS [training: 0.06619121864288977 | validation: 0.09376452423909568]
	TIME [epoch: 9.07 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11919944054697049		[learning rate: 0.00093785]
	Learning Rate: 0.00093785
	LOSS [training: 0.11919944054697049 | validation: 0.10988772252823992]
	TIME [epoch: 9.06 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12515381242093687		[learning rate: 0.00093497]
	Learning Rate: 0.000934975
	LOSS [training: 0.12515381242093687 | validation: 0.11610007693158617]
	TIME [epoch: 9.04 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436808026801704		[learning rate: 0.00093211]
	Learning Rate: 0.000932109
	LOSS [training: 0.11436808026801704 | validation: 0.15518615746862519]
	TIME [epoch: 9.05 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12288207401945403		[learning rate: 0.00092925]
	Learning Rate: 0.000929252
	LOSS [training: 0.12288207401945403 | validation: 0.11816149046465932]
	TIME [epoch: 9.07 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09031296869134836		[learning rate: 0.0009264]
	Learning Rate: 0.000926403
	LOSS [training: 0.09031296869134836 | validation: 0.058857545345336854]
	TIME [epoch: 9.05 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07575872615573194		[learning rate: 0.00092356]
	Learning Rate: 0.000923563
	LOSS [training: 0.07575872615573194 | validation: 0.1939647961265324]
	TIME [epoch: 9.06 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13111009265187104		[learning rate: 0.00092073]
	Learning Rate: 0.000920732
	LOSS [training: 0.13111009265187104 | validation: 0.08799397880030929]
	TIME [epoch: 9.05 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08439598650138037		[learning rate: 0.00091791]
	Learning Rate: 0.00091791
	LOSS [training: 0.08439598650138037 | validation: 0.07152383585246015]
	TIME [epoch: 9.06 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06723712306135114		[learning rate: 0.0009151]
	Learning Rate: 0.000915096
	LOSS [training: 0.06723712306135114 | validation: 0.07004056074161921]
	TIME [epoch: 9.06 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07301422751382558		[learning rate: 0.00091229]
	Learning Rate: 0.000912291
	LOSS [training: 0.07301422751382558 | validation: 0.16824647312845187]
	TIME [epoch: 9.05 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08705890057454303		[learning rate: 0.00090949]
	Learning Rate: 0.000909494
	LOSS [training: 0.08705890057454303 | validation: 0.0667199526963299]
	TIME [epoch: 9.05 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15129062115393258		[learning rate: 0.00090671]
	Learning Rate: 0.000906706
	LOSS [training: 0.15129062115393258 | validation: 0.19847369868761028]
	TIME [epoch: 9.07 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09934649563350847		[learning rate: 0.00090393]
	Learning Rate: 0.000903927
	LOSS [training: 0.09934649563350847 | validation: 0.14439669731613008]
	TIME [epoch: 9.07 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09077067095815514		[learning rate: 0.00090116]
	Learning Rate: 0.000901156
	LOSS [training: 0.09077067095815514 | validation: 0.08109211025742394]
	TIME [epoch: 9.06 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006882684071498		[learning rate: 0.00089839]
	Learning Rate: 0.000898394
	LOSS [training: 0.10006882684071498 | validation: 0.12433731647155975]
	TIME [epoch: 9.06 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468068600080574		[learning rate: 0.00089564]
	Learning Rate: 0.00089564
	LOSS [training: 0.08468068600080574 | validation: 0.11016728441319093]
	TIME [epoch: 9.05 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08895428416645253		[learning rate: 0.00089289]
	Learning Rate: 0.000892894
	LOSS [training: 0.08895428416645253 | validation: 0.038017695856795354]
	TIME [epoch: 9.07 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06970832725587017		[learning rate: 0.00089016]
	Learning Rate: 0.000890157
	LOSS [training: 0.06970832725587017 | validation: 0.08959295993811828]
	TIME [epoch: 9.04 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08731815697096951		[learning rate: 0.00088743]
	Learning Rate: 0.000887428
	LOSS [training: 0.08731815697096951 | validation: 0.1033411151965242]
	TIME [epoch: 9.06 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08309859320758546		[learning rate: 0.00088471]
	Learning Rate: 0.000884708
	LOSS [training: 0.08309859320758546 | validation: 0.11539624289514912]
	TIME [epoch: 9.06 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10579015358722894		[learning rate: 0.000882]
	Learning Rate: 0.000881996
	LOSS [training: 0.10579015358722894 | validation: 0.06861180738347242]
	TIME [epoch: 9.07 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12302044020360689		[learning rate: 0.00087929]
	Learning Rate: 0.000879292
	LOSS [training: 0.12302044020360689 | validation: 0.043693178952300404]
	TIME [epoch: 9.05 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215651330823339		[learning rate: 0.0008766]
	Learning Rate: 0.000876597
	LOSS [training: 0.07215651330823339 | validation: 0.058484793254950304]
	TIME [epoch: 9.05 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08547856825018349		[learning rate: 0.00087391]
	Learning Rate: 0.00087391
	LOSS [training: 0.08547856825018349 | validation: 0.060935706803642374]
	TIME [epoch: 9.05 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08020942692578058		[learning rate: 0.00087123]
	Learning Rate: 0.000871231
	LOSS [training: 0.08020942692578058 | validation: 0.1200765822410734]
	TIME [epoch: 9.08 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.127246447729983		[learning rate: 0.00086856]
	Learning Rate: 0.00086856
	LOSS [training: 0.127246447729983 | validation: 0.0696527809406871]
	TIME [epoch: 9.06 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06853877360061156		[learning rate: 0.0008659]
	Learning Rate: 0.000865898
	LOSS [training: 0.06853877360061156 | validation: 0.05145686416641407]
	TIME [epoch: 9.05 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10132318505577646		[learning rate: 0.00086324]
	Learning Rate: 0.000863243
	LOSS [training: 0.10132318505577646 | validation: 0.14955706773803618]
	TIME [epoch: 9.05 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14830429097779046		[learning rate: 0.0008606]
	Learning Rate: 0.000860597
	LOSS [training: 0.14830429097779046 | validation: 0.0930087031099866]
	TIME [epoch: 9.07 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08149233893137556		[learning rate: 0.00085796]
	Learning Rate: 0.000857959
	LOSS [training: 0.08149233893137556 | validation: 0.16513819774507021]
	TIME [epoch: 9.05 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08381327491032083		[learning rate: 0.00085533]
	Learning Rate: 0.000855329
	LOSS [training: 0.08381327491032083 | validation: 0.15612579517458147]
	TIME [epoch: 9.05 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07366828335335401		[learning rate: 0.00085271]
	Learning Rate: 0.000852707
	LOSS [training: 0.07366828335335401 | validation: 0.06111950616243802]
	TIME [epoch: 9.05 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13999827253285504		[learning rate: 0.00085009]
	Learning Rate: 0.000850093
	LOSS [training: 0.13999827253285504 | validation: 0.15836547683654678]
	TIME [epoch: 9.06 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10564768170957058		[learning rate: 0.00084749]
	Learning Rate: 0.000847488
	LOSS [training: 0.10564768170957058 | validation: 0.06909434392990743]
	TIME [epoch: 9.06 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08943514321667995		[learning rate: 0.00084489]
	Learning Rate: 0.00084489
	LOSS [training: 0.08943514321667995 | validation: 0.05559164839011385]
	TIME [epoch: 9.05 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0688974637837874		[learning rate: 0.0008423]
	Learning Rate: 0.0008423
	LOSS [training: 0.0688974637837874 | validation: 0.07567183542974396]
	TIME [epoch: 9.06 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07484611654381979		[learning rate: 0.00083972]
	Learning Rate: 0.000839718
	LOSS [training: 0.07484611654381979 | validation: 0.12956312787120094]
	TIME [epoch: 9.06 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07998675537746201		[learning rate: 0.00083714]
	Learning Rate: 0.000837144
	LOSS [training: 0.07998675537746201 | validation: 0.06978527405363158]
	TIME [epoch: 9.07 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08403929393617496		[learning rate: 0.00083458]
	Learning Rate: 0.000834578
	LOSS [training: 0.08403929393617496 | validation: 0.05043289033364537]
	TIME [epoch: 9.05 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09620532352467873		[learning rate: 0.00083202]
	Learning Rate: 0.000832019
	LOSS [training: 0.09620532352467873 | validation: 0.11291390424545208]
	TIME [epoch: 9.05 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13027370224828153		[learning rate: 0.00082947]
	Learning Rate: 0.000829469
	LOSS [training: 0.13027370224828153 | validation: 0.07344459435960768]
	TIME [epoch: 9.05 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645391593446715		[learning rate: 0.00082693]
	Learning Rate: 0.000826926
	LOSS [training: 0.0645391593446715 | validation: 0.0325159120225992]
	TIME [epoch: 9.08 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793026683516477		[learning rate: 0.00082439]
	Learning Rate: 0.000824391
	LOSS [training: 0.0793026683516477 | validation: 0.09905827337315382]
	TIME [epoch: 9.05 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09818035486452702		[learning rate: 0.00082186]
	Learning Rate: 0.000821864
	LOSS [training: 0.09818035486452702 | validation: 0.048490298373931734]
	TIME [epoch: 9.04 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0789265244655982		[learning rate: 0.00081934]
	Learning Rate: 0.000819345
	LOSS [training: 0.0789265244655982 | validation: 0.06251509686912472]
	TIME [epoch: 9.05 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06552930802742354		[learning rate: 0.00081683]
	Learning Rate: 0.000816833
	LOSS [training: 0.06552930802742354 | validation: 0.09211081714565138]
	TIME [epoch: 9.08 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1386852282787724		[learning rate: 0.00081433]
	Learning Rate: 0.000814329
	LOSS [training: 0.1386852282787724 | validation: 0.052619053937359966]
	TIME [epoch: 9.05 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05933362084115549		[learning rate: 0.00081183]
	Learning Rate: 0.000811833
	LOSS [training: 0.05933362084115549 | validation: 0.07054301758123999]
	TIME [epoch: 9.05 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07255771548828446		[learning rate: 0.00080934]
	Learning Rate: 0.000809344
	LOSS [training: 0.07255771548828446 | validation: 0.04569421945731219]
	TIME [epoch: 9.06 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059119141057286696		[learning rate: 0.00080686]
	Learning Rate: 0.000806863
	LOSS [training: 0.059119141057286696 | validation: 0.04948953611175194]
	TIME [epoch: 9.07 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09390116170130236		[learning rate: 0.00080439]
	Learning Rate: 0.00080439
	LOSS [training: 0.09390116170130236 | validation: 0.039780710492186025]
	TIME [epoch: 9.05 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05280297885827225		[learning rate: 0.00080192]
	Learning Rate: 0.000801924
	LOSS [training: 0.05280297885827225 | validation: 0.057150127990085224]
	TIME [epoch: 9.05 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08136231499507017		[learning rate: 0.00079947]
	Learning Rate: 0.000799466
	LOSS [training: 0.08136231499507017 | validation: 0.09208922898239989]
	TIME [epoch: 9.05 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09370602152183716		[learning rate: 0.00079702]
	Learning Rate: 0.000797015
	LOSS [training: 0.09370602152183716 | validation: 0.10001357030347614]
	TIME [epoch: 9.07 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11056478002940832		[learning rate: 0.00079457]
	Learning Rate: 0.000794572
	LOSS [training: 0.11056478002940832 | validation: 0.04801075038761958]
	TIME [epoch: 9.06 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08065060305852136		[learning rate: 0.00079214]
	Learning Rate: 0.000792136
	LOSS [training: 0.08065060305852136 | validation: 0.13253447280247066]
	TIME [epoch: 9.05 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09824762189260106		[learning rate: 0.00078971]
	Learning Rate: 0.000789708
	LOSS [training: 0.09824762189260106 | validation: 0.033449507921855984]
	TIME [epoch: 9.05 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05807683695697402		[learning rate: 0.00078729]
	Learning Rate: 0.000787287
	LOSS [training: 0.05807683695697402 | validation: 0.06637868290528709]
	TIME [epoch: 9.06 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10486824595638049		[learning rate: 0.00078487]
	Learning Rate: 0.000784874
	LOSS [training: 0.10486824595638049 | validation: 0.09236862900048742]
	TIME [epoch: 9.07 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08743011006922281		[learning rate: 0.00078247]
	Learning Rate: 0.000782468
	LOSS [training: 0.08743011006922281 | validation: 0.32404476706406105]
	TIME [epoch: 9.05 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16474544974117328		[learning rate: 0.00078007]
	Learning Rate: 0.00078007
	LOSS [training: 0.16474544974117328 | validation: 0.11569341057282057]
	TIME [epoch: 9.06 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11299827315163116		[learning rate: 0.00077768]
	Learning Rate: 0.000777678
	LOSS [training: 0.11299827315163116 | validation: 0.05515050329555856]
	TIME [epoch: 9.05 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059448558105501294		[learning rate: 0.00077529]
	Learning Rate: 0.000775294
	LOSS [training: 0.059448558105501294 | validation: 0.07332956191595938]
	TIME [epoch: 9.06 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06135586848662873		[learning rate: 0.00077292]
	Learning Rate: 0.000772918
	LOSS [training: 0.06135586848662873 | validation: 0.04331878206933168]
	TIME [epoch: 9.05 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059864521576661875		[learning rate: 0.00077055]
	Learning Rate: 0.000770548
	LOSS [training: 0.059864521576661875 | validation: 0.17448460974490632]
	TIME [epoch: 9.06 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09396755258923		[learning rate: 0.00076819]
	Learning Rate: 0.000768187
	LOSS [training: 0.09396755258923 | validation: 0.04485976653092992]
	TIME [epoch: 9.05 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705673861303511		[learning rate: 0.00076583]
	Learning Rate: 0.000765832
	LOSS [training: 0.0705673861303511 | validation: 0.13589766356237146]
	TIME [epoch: 9.07 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05743406252573453		[learning rate: 0.00076348]
	Learning Rate: 0.000763484
	LOSS [training: 0.05743406252573453 | validation: 0.040655807218958465]
	TIME [epoch: 9.05 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06165740895089522		[learning rate: 0.00076114]
	Learning Rate: 0.000761144
	LOSS [training: 0.06165740895089522 | validation: 0.03478231364464663]
	TIME [epoch: 9.06 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500019649278613		[learning rate: 0.00075881]
	Learning Rate: 0.00075881
	LOSS [training: 0.06500019649278613 | validation: 0.0784641366282077]
	TIME [epoch: 9.05 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11239647237911418		[learning rate: 0.00075648]
	Learning Rate: 0.000756484
	LOSS [training: 0.11239647237911418 | validation: 0.06346819810005058]
	TIME [epoch: 9.07 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07654269888792545		[learning rate: 0.00075417]
	Learning Rate: 0.000754165
	LOSS [training: 0.07654269888792545 | validation: 0.06513237113791173]
	TIME [epoch: 9.06 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053980994378747184		[learning rate: 0.00075185]
	Learning Rate: 0.000751854
	LOSS [training: 0.053980994378747184 | validation: 0.045813299981180236]
	TIME [epoch: 9.06 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05079131404028201		[learning rate: 0.00074955]
	Learning Rate: 0.000749549
	LOSS [training: 0.05079131404028201 | validation: 0.04150152386268004]
	TIME [epoch: 9.05 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05496940350666253		[learning rate: 0.00074725]
	Learning Rate: 0.000747251
	LOSS [training: 0.05496940350666253 | validation: 0.05365903200822873]
	TIME [epoch: 9.07 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08735903958595087		[learning rate: 0.00074496]
	Learning Rate: 0.000744961
	LOSS [training: 0.08735903958595087 | validation: 0.10360765109388054]
	TIME [epoch: 9.06 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08697888557659965		[learning rate: 0.00074268]
	Learning Rate: 0.000742677
	LOSS [training: 0.08697888557659965 | validation: 0.15624912635684707]
	TIME [epoch: 9.05 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07460512885347757		[learning rate: 0.0007404]
	Learning Rate: 0.0007404
	LOSS [training: 0.07460512885347757 | validation: 0.04622988627904885]
	TIME [epoch: 9.06 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0482691256690994		[learning rate: 0.00073813]
	Learning Rate: 0.000738131
	LOSS [training: 0.0482691256690994 | validation: 0.040518297205155526]
	TIME [epoch: 9.07 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0453139243734793		[learning rate: 0.00073587]
	Learning Rate: 0.000735868
	LOSS [training: 0.0453139243734793 | validation: 0.055807975464172155]
	TIME [epoch: 9.07 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04272840689651503		[learning rate: 0.00073361]
	Learning Rate: 0.000733612
	LOSS [training: 0.04272840689651503 | validation: 0.04674109216704503]
	TIME [epoch: 9.05 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08028938023210751		[learning rate: 0.00073136]
	Learning Rate: 0.000731364
	LOSS [training: 0.08028938023210751 | validation: 0.08106551865343045]
	TIME [epoch: 9.05 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10159494060646779		[learning rate: 0.00072912]
	Learning Rate: 0.000729122
	LOSS [training: 0.10159494060646779 | validation: 0.09314841460731954]
	TIME [epoch: 9.07 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07948059268064843		[learning rate: 0.00072689]
	Learning Rate: 0.000726886
	LOSS [training: 0.07948059268064843 | validation: 0.0729713741934015]
	TIME [epoch: 9.07 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092392469075862		[learning rate: 0.00072466]
	Learning Rate: 0.000724658
	LOSS [training: 0.092392469075862 | validation: 0.07136591826687103]
	TIME [epoch: 9.05 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09516497639296792		[learning rate: 0.00072244]
	Learning Rate: 0.000722437
	LOSS [training: 0.09516497639296792 | validation: 0.06663917584960435]
	TIME [epoch: 9.05 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08711939611925093		[learning rate: 0.00072022]
	Learning Rate: 0.000720223
	LOSS [training: 0.08711939611925093 | validation: 0.04090126036653146]
	TIME [epoch: 9.05 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0712882296267279		[learning rate: 0.00071801]
	Learning Rate: 0.000718015
	LOSS [training: 0.0712882296267279 | validation: 0.07653743600882706]
	TIME [epoch: 9.07 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460902669118566		[learning rate: 0.00071581]
	Learning Rate: 0.000715814
	LOSS [training: 0.09460902669118566 | validation: 0.061970032271271965]
	TIME [epoch: 9.05 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06250516586010278		[learning rate: 0.00071362]
	Learning Rate: 0.000713619
	LOSS [training: 0.06250516586010278 | validation: 0.04240179388542029]
	TIME [epoch: 9.05 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0467732280659849		[learning rate: 0.00071143]
	Learning Rate: 0.000711432
	LOSS [training: 0.0467732280659849 | validation: 0.03548928109880425]
	TIME [epoch: 9.05 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06931538938002876		[learning rate: 0.00070925]
	Learning Rate: 0.000709251
	LOSS [training: 0.06931538938002876 | validation: 0.054580534378563444]
	TIME [epoch: 9.07 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06005554858234967		[learning rate: 0.00070708]
	Learning Rate: 0.000707077
	LOSS [training: 0.06005554858234967 | validation: 0.0431957154101214]
	TIME [epoch: 9.06 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04877671183438531		[learning rate: 0.00070491]
	Learning Rate: 0.00070491
	LOSS [training: 0.04877671183438531 | validation: 0.06326462011263995]
	TIME [epoch: 9.04 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173846748648174		[learning rate: 0.00070275]
	Learning Rate: 0.000702748
	LOSS [training: 0.06173846748648174 | validation: 0.05209154261168636]
	TIME [epoch: 9.04 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05712193149375876		[learning rate: 0.00070059]
	Learning Rate: 0.000700594
	LOSS [training: 0.05712193149375876 | validation: 0.06549224311429883]
	TIME [epoch: 9.07 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06241553356682063		[learning rate: 0.00069845]
	Learning Rate: 0.000698447
	LOSS [training: 0.06241553356682063 | validation: 0.05265863587082008]
	TIME [epoch: 9.05 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941595613666458		[learning rate: 0.00069631]
	Learning Rate: 0.000696306
	LOSS [training: 0.06941595613666458 | validation: 0.0371769547845077]
	TIME [epoch: 9.05 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06964979512262075		[learning rate: 0.00069417]
	Learning Rate: 0.000694171
	LOSS [training: 0.06964979512262075 | validation: 0.03136920735610566]
	TIME [epoch: 9.05 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059865475325490324		[learning rate: 0.00069204]
	Learning Rate: 0.000692043
	LOSS [training: 0.059865475325490324 | validation: 0.06112216904715244]
	TIME [epoch: 9.07 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05967401596190656		[learning rate: 0.00068992]
	Learning Rate: 0.000689922
	LOSS [training: 0.05967401596190656 | validation: 0.11831968506315205]
	TIME [epoch: 9.05 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08229720223695472		[learning rate: 0.00068781]
	Learning Rate: 0.000687807
	LOSS [training: 0.08229720223695472 | validation: 0.04566634868877023]
	TIME [epoch: 9.06 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05138358902490038		[learning rate: 0.0006857]
	Learning Rate: 0.000685699
	LOSS [training: 0.05138358902490038 | validation: 0.03604369633660842]
	TIME [epoch: 9.05 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052641341538962785		[learning rate: 0.0006836]
	Learning Rate: 0.000683597
	LOSS [training: 0.052641341538962785 | validation: 0.059358656633239394]
	TIME [epoch: 9.06 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05322557580279733		[learning rate: 0.0006815]
	Learning Rate: 0.000681501
	LOSS [training: 0.05322557580279733 | validation: 0.04607870384673941]
	TIME [epoch: 9.07 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04911303832548487		[learning rate: 0.00067941]
	Learning Rate: 0.000679412
	LOSS [training: 0.04911303832548487 | validation: 0.02672011215895632]
	TIME [epoch: 9.05 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060962117483108		[learning rate: 0.00067733]
	Learning Rate: 0.000677329
	LOSS [training: 0.060962117483108 | validation: 0.06068781411198877]
	TIME [epoch: 9.06 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05469312452722948		[learning rate: 0.00067525]
	Learning Rate: 0.000675253
	LOSS [training: 0.05469312452722948 | validation: 0.04460456275456259]
	TIME [epoch: 9.05 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05347383065409861		[learning rate: 0.00067318]
	Learning Rate: 0.000673183
	LOSS [training: 0.05347383065409861 | validation: 0.0725190777242716]
	TIME [epoch: 9.07 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07622309853297948		[learning rate: 0.00067112]
	Learning Rate: 0.00067112
	LOSS [training: 0.07622309853297948 | validation: 0.08739108386332858]
	TIME [epoch: 9.05 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058299811256316836		[learning rate: 0.00066906]
	Learning Rate: 0.000669062
	LOSS [training: 0.058299811256316836 | validation: 0.04668848276044833]
	TIME [epoch: 9.05 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04417784335419018		[learning rate: 0.00066701]
	Learning Rate: 0.000667011
	LOSS [training: 0.04417784335419018 | validation: 0.1266551345027114]
	TIME [epoch: 9.05 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05955301111660878		[learning rate: 0.00066497]
	Learning Rate: 0.000664967
	LOSS [training: 0.05955301111660878 | validation: 0.08901841201440397]
	TIME [epoch: 9.08 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09240008598075096		[learning rate: 0.00066293]
	Learning Rate: 0.000662929
	LOSS [training: 0.09240008598075096 | validation: 0.03656178345472147]
	TIME [epoch: 9.05 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04663909476526052		[learning rate: 0.0006609]
	Learning Rate: 0.000660896
	LOSS [training: 0.04663909476526052 | validation: 0.07537540245622672]
	TIME [epoch: 9.05 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524200494027509		[learning rate: 0.00065887]
	Learning Rate: 0.00065887
	LOSS [training: 0.06524200494027509 | validation: 0.06031061184015095]
	TIME [epoch: 9.06 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07026072254033101		[learning rate: 0.00065685]
	Learning Rate: 0.000656851
	LOSS [training: 0.07026072254033101 | validation: 0.0496666600262991]
	TIME [epoch: 9.07 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05288319801132314		[learning rate: 0.00065484]
	Learning Rate: 0.000654837
	LOSS [training: 0.05288319801132314 | validation: 0.05491463843197003]
	TIME [epoch: 9.06 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05307192106156402		[learning rate: 0.00065283]
	Learning Rate: 0.00065283
	LOSS [training: 0.05307192106156402 | validation: 0.05824210286653159]
	TIME [epoch: 9.05 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05631037222480525		[learning rate: 0.00065083]
	Learning Rate: 0.000650829
	LOSS [training: 0.05631037222480525 | validation: 0.04707801555204942]
	TIME [epoch: 9.05 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06959269316188578		[learning rate: 0.00064883]
	Learning Rate: 0.000648834
	LOSS [training: 0.06959269316188578 | validation: 0.046168158001942614]
	TIME [epoch: 9.07 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06236945575416951		[learning rate: 0.00064684]
	Learning Rate: 0.000646845
	LOSS [training: 0.06236945575416951 | validation: 0.05781600715015437]
	TIME [epoch: 9.05 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05512860239041251		[learning rate: 0.00064486]
	Learning Rate: 0.000644862
	LOSS [training: 0.05512860239041251 | validation: 0.05512194659331109]
	TIME [epoch: 9.05 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06752209996862299		[learning rate: 0.00064289]
	Learning Rate: 0.000642885
	LOSS [training: 0.06752209996862299 | validation: 0.04075010447846458]
	TIME [epoch: 9.05 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05940506604541237		[learning rate: 0.00064091]
	Learning Rate: 0.000640914
	LOSS [training: 0.05940506604541237 | validation: 0.0608729276698949]
	TIME [epoch: 9.08 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08950083341165646		[learning rate: 0.00063895]
	Learning Rate: 0.00063895
	LOSS [training: 0.08950083341165646 | validation: 0.05743166796912681]
	TIME [epoch: 9.07 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048450330408156085		[learning rate: 0.00063699]
	Learning Rate: 0.000636991
	LOSS [training: 0.048450330408156085 | validation: 0.021817534332164865]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1397.pth
	Model improved!!!
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050122349554149445		[learning rate: 0.00063504]
	Learning Rate: 0.000635038
	LOSS [training: 0.050122349554149445 | validation: 0.04680755365825209]
	TIME [epoch: 9.05 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05445024459809068		[learning rate: 0.00063309]
	Learning Rate: 0.000633092
	LOSS [training: 0.05445024459809068 | validation: 0.062078411354480355]
	TIME [epoch: 9.06 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07152792079310111		[learning rate: 0.00063115]
	Learning Rate: 0.000631151
	LOSS [training: 0.07152792079310111 | validation: 0.03465522047455388]
	TIME [epoch: 9.06 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770746139493787		[learning rate: 0.00062922]
	Learning Rate: 0.000629216
	LOSS [training: 0.07770746139493787 | validation: 0.1032847704341617]
	TIME [epoch: 9.05 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094228704857254		[learning rate: 0.00062729]
	Learning Rate: 0.000627287
	LOSS [training: 0.07094228704857254 | validation: 0.06750554443841097]
	TIME [epoch: 9.05 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07143368922408327		[learning rate: 0.00062536]
	Learning Rate: 0.000625365
	LOSS [training: 0.07143368922408327 | validation: 0.05816389184995352]
	TIME [epoch: 9.05 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0917067457540316		[learning rate: 0.00062345]
	Learning Rate: 0.000623448
	LOSS [training: 0.0917067457540316 | validation: 0.05828779800651533]
	TIME [epoch: 9.06 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05711814477767154		[learning rate: 0.00062154]
	Learning Rate: 0.000621537
	LOSS [training: 0.05711814477767154 | validation: 0.06017340240366563]
	TIME [epoch: 9.04 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04413336647539708		[learning rate: 0.00061963]
	Learning Rate: 0.000619631
	LOSS [training: 0.04413336647539708 | validation: 0.04197002639083365]
	TIME [epoch: 9.05 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654782494064927		[learning rate: 0.00061773]
	Learning Rate: 0.000617732
	LOSS [training: 0.0654782494064927 | validation: 0.09892484911545392]
	TIME [epoch: 9.04 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10083193465309899		[learning rate: 0.00061584]
	Learning Rate: 0.000615838
	LOSS [training: 0.10083193465309899 | validation: 0.1109594226856936]
	TIME [epoch: 9.06 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09706284227658799		[learning rate: 0.00061395]
	Learning Rate: 0.00061395
	LOSS [training: 0.09706284227658799 | validation: 0.04673638049237673]
	TIME [epoch: 9.05 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05492027866591072		[learning rate: 0.00061207]
	Learning Rate: 0.000612068
	LOSS [training: 0.05492027866591072 | validation: 0.05990887927951046]
	TIME [epoch: 9.04 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04732891952194101		[learning rate: 0.00061019]
	Learning Rate: 0.000610192
	LOSS [training: 0.04732891952194101 | validation: 0.09676482827455488]
	TIME [epoch: 9.04 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06764729366248134		[learning rate: 0.00060832]
	Learning Rate: 0.000608322
	LOSS [training: 0.06764729366248134 | validation: 0.05493642252050336]
	TIME [epoch: 9.06 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874272087008077		[learning rate: 0.00060646]
	Learning Rate: 0.000606457
	LOSS [training: 0.05874272087008077 | validation: 0.03914025129422191]
	TIME [epoch: 9.06 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04653757894462023		[learning rate: 0.0006046]
	Learning Rate: 0.000604598
	LOSS [training: 0.04653757894462023 | validation: 0.035090041942879555]
	TIME [epoch: 9.04 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07547816171603142		[learning rate: 0.00060274]
	Learning Rate: 0.000602745
	LOSS [training: 0.07547816171603142 | validation: 0.07293779850547713]
	TIME [epoch: 9.05 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08203218075833682		[learning rate: 0.0006009]
	Learning Rate: 0.000600897
	LOSS [training: 0.08203218075833682 | validation: 0.02733885326021716]
	TIME [epoch: 9.06 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04173311863391211		[learning rate: 0.00059905]
	Learning Rate: 0.000599055
	LOSS [training: 0.04173311863391211 | validation: 0.04099113309115855]
	TIME [epoch: 9.05 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05786667696359069		[learning rate: 0.00059722]
	Learning Rate: 0.000597219
	LOSS [training: 0.05786667696359069 | validation: 0.03406172221111789]
	TIME [epoch: 9.05 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689609577757499		[learning rate: 0.00059539]
	Learning Rate: 0.000595388
	LOSS [training: 0.0689609577757499 | validation: 0.06983079058387685]
	TIME [epoch: 9.05 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05864535655012709		[learning rate: 0.00059356]
	Learning Rate: 0.000593563
	LOSS [training: 0.05864535655012709 | validation: 0.0365556731682897]
	TIME [epoch: 9.06 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0469305665248403		[learning rate: 0.00059174]
	Learning Rate: 0.000591743
	LOSS [training: 0.0469305665248403 | validation: 0.06431706153266845]
	TIME [epoch: 9.07 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06243186250549593		[learning rate: 0.00058993]
	Learning Rate: 0.000589929
	LOSS [training: 0.06243186250549593 | validation: 0.11261678141253156]
	TIME [epoch: 9.05 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07847147659027735		[learning rate: 0.00058812]
	Learning Rate: 0.000588121
	LOSS [training: 0.07847147659027735 | validation: 0.03754279891363202]
	TIME [epoch: 9.05 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04238854355279657		[learning rate: 0.00058632]
	Learning Rate: 0.000586318
	LOSS [training: 0.04238854355279657 | validation: 0.020418794954853423]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1424.pth
	Model improved!!!
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0566407125955939		[learning rate: 0.00058452]
	Learning Rate: 0.000584521
	LOSS [training: 0.0566407125955939 | validation: 0.06639246191472886]
	TIME [epoch: 9.07 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04805434411006948		[learning rate: 0.00058273]
	Learning Rate: 0.000582729
	LOSS [training: 0.04805434411006948 | validation: 0.03595405315448294]
	TIME [epoch: 9.06 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04280343208165092		[learning rate: 0.00058094]
	Learning Rate: 0.000580943
	LOSS [training: 0.04280343208165092 | validation: 0.0667514817463318]
	TIME [epoch: 9.05 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05683641108301868		[learning rate: 0.00057916]
	Learning Rate: 0.000579162
	LOSS [training: 0.05683641108301868 | validation: 0.1118239222776537]
	TIME [epoch: 9.05 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060973968350994015		[learning rate: 0.00057739]
	Learning Rate: 0.000577386
	LOSS [training: 0.060973968350994015 | validation: 0.03835538346246814]
	TIME [epoch: 9.08 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04379708808758507		[learning rate: 0.00057562]
	Learning Rate: 0.000575616
	LOSS [training: 0.04379708808758507 | validation: 0.02443218592651948]
	TIME [epoch: 9.04 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04531773899177814		[learning rate: 0.00057385]
	Learning Rate: 0.000573852
	LOSS [training: 0.04531773899177814 | validation: 0.031004263221218777]
	TIME [epoch: 9.04 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07825961311193423		[learning rate: 0.00057209]
	Learning Rate: 0.000572093
	LOSS [training: 0.07825961311193423 | validation: 0.04865113213236126]
	TIME [epoch: 9.05 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04879132403817439		[learning rate: 0.00057034]
	Learning Rate: 0.000570339
	LOSS [training: 0.04879132403817439 | validation: 0.022491588195854718]
	TIME [epoch: 9.07 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0520534564230577		[learning rate: 0.00056859]
	Learning Rate: 0.000568591
	LOSS [training: 0.0520534564230577 | validation: 0.04002425365377391]
	TIME [epoch: 9.05 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042833318536276		[learning rate: 0.00056685]
	Learning Rate: 0.000566848
	LOSS [training: 0.042833318536276 | validation: 0.03621754481726312]
	TIME [epoch: 9.05 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039072604001861175		[learning rate: 0.00056511]
	Learning Rate: 0.00056511
	LOSS [training: 0.039072604001861175 | validation: 0.0265224019232827]
	TIME [epoch: 9.05 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03689612502501173		[learning rate: 0.00056338]
	Learning Rate: 0.000563378
	LOSS [training: 0.03689612502501173 | validation: 0.020258660051759116]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1437.pth
	Model improved!!!
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07068382094314793		[learning rate: 0.00056165]
	Learning Rate: 0.000561651
	LOSS [training: 0.07068382094314793 | validation: 0.029755595585437652]
	TIME [epoch: 9.05 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03270346081959655		[learning rate: 0.00055993]
	Learning Rate: 0.000559929
	LOSS [training: 0.03270346081959655 | validation: 0.030810419417352235]
	TIME [epoch: 9.05 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03688410749223281		[learning rate: 0.00055821]
	Learning Rate: 0.000558213
	LOSS [training: 0.03688410749223281 | validation: 0.05009613069218394]
	TIME [epoch: 9.05 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05448605898403049		[learning rate: 0.0005565]
	Learning Rate: 0.000556502
	LOSS [training: 0.05448605898403049 | validation: 0.043052746193370225]
	TIME [epoch: 9.07 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566911232349346		[learning rate: 0.0005548]
	Learning Rate: 0.000554796
	LOSS [training: 0.06566911232349346 | validation: 0.05991468167562228]
	TIME [epoch: 9.05 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07588726214270111		[learning rate: 0.0005531]
	Learning Rate: 0.000553095
	LOSS [training: 0.07588726214270111 | validation: 0.07116738179932133]
	TIME [epoch: 9.05 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05208227905713718		[learning rate: 0.0005514]
	Learning Rate: 0.0005514
	LOSS [training: 0.05208227905713718 | validation: 0.028965216252968093]
	TIME [epoch: 9.04 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044695187994917306		[learning rate: 0.00054971]
	Learning Rate: 0.000549709
	LOSS [training: 0.044695187994917306 | validation: 0.1280479812607802]
	TIME [epoch: 9.06 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06765474669325697		[learning rate: 0.00054802]
	Learning Rate: 0.000548024
	LOSS [training: 0.06765474669325697 | validation: 0.038234804693945204]
	TIME [epoch: 9.07 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04979190163833745		[learning rate: 0.00054634]
	Learning Rate: 0.000546345
	LOSS [training: 0.04979190163833745 | validation: 0.07136174826710659]
	TIME [epoch: 9.05 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784005640912144		[learning rate: 0.00054467]
	Learning Rate: 0.00054467
	LOSS [training: 0.06784005640912144 | validation: 0.05392627966085063]
	TIME [epoch: 9.05 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05258677497689016		[learning rate: 0.000543]
	Learning Rate: 0.000543
	LOSS [training: 0.05258677497689016 | validation: 0.029917814436044243]
	TIME [epoch: 9.04 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171616582537002		[learning rate: 0.00054134]
	Learning Rate: 0.000541336
	LOSS [training: 0.05171616582537002 | validation: 0.09857941387899959]
	TIME [epoch: 9.07 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062196852376828794		[learning rate: 0.00053968]
	Learning Rate: 0.000539676
	LOSS [training: 0.062196852376828794 | validation: 0.05840407062470292]
	TIME [epoch: 9.04 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039208430591592534		[learning rate: 0.00053802]
	Learning Rate: 0.000538022
	LOSS [training: 0.039208430591592534 | validation: 0.05449279915413966]
	TIME [epoch: 9.04 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060374730264065216		[learning rate: 0.00053637]
	Learning Rate: 0.000536373
	LOSS [training: 0.060374730264065216 | validation: 0.08983967137620684]
	TIME [epoch: 9.05 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05257069646605278		[learning rate: 0.00053473]
	Learning Rate: 0.000534728
	LOSS [training: 0.05257069646605278 | validation: 0.03182454439291897]
	TIME [epoch: 9.06 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06246678551765984		[learning rate: 0.00053309]
	Learning Rate: 0.000533089
	LOSS [training: 0.06246678551765984 | validation: 0.08162889654560943]
	TIME [epoch: 9.04 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07540787717848815		[learning rate: 0.00053146]
	Learning Rate: 0.000531455
	LOSS [training: 0.07540787717848815 | validation: 0.07764874475272328]
	TIME [epoch: 9.05 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07509079874126383		[learning rate: 0.00052983]
	Learning Rate: 0.000529826
	LOSS [training: 0.07509079874126383 | validation: 0.0797606352948621]
	TIME [epoch: 9.05 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0640441030524432		[learning rate: 0.0005282]
	Learning Rate: 0.000528202
	LOSS [training: 0.0640441030524432 | validation: 0.029996631210648203]
	TIME [epoch: 9.07 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061510712399135706		[learning rate: 0.00052658]
	Learning Rate: 0.000526583
	LOSS [training: 0.061510712399135706 | validation: 0.06841557258613414]
	TIME [epoch: 9.06 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056203990458382105		[learning rate: 0.00052497]
	Learning Rate: 0.000524969
	LOSS [training: 0.056203990458382105 | validation: 0.05327860300107855]
	TIME [epoch: 9.05 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11269228671478819		[learning rate: 0.00052336]
	Learning Rate: 0.000523359
	LOSS [training: 0.11269228671478819 | validation: 0.08829341432282714]
	TIME [epoch: 9.04 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0632408710009389		[learning rate: 0.00052176]
	Learning Rate: 0.000521755
	LOSS [training: 0.0632408710009389 | validation: 0.05183096998233183]
	TIME [epoch: 9.07 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08285619676436348		[learning rate: 0.00052016]
	Learning Rate: 0.000520156
	LOSS [training: 0.08285619676436348 | validation: 0.057761747710760813]
	TIME [epoch: 9.05 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06165971851557732		[learning rate: 0.00051856]
	Learning Rate: 0.000518561
	LOSS [training: 0.06165971851557732 | validation: 0.10012409250136503]
	TIME [epoch: 9.05 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762589279043284		[learning rate: 0.00051697]
	Learning Rate: 0.000516972
	LOSS [training: 0.0762589279043284 | validation: 0.06799561174229113]
	TIME [epoch: 9.05 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017026157133048		[learning rate: 0.00051539]
	Learning Rate: 0.000515387
	LOSS [training: 0.07017026157133048 | validation: 0.05793469234415208]
	TIME [epoch: 9.06 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07044975266651218		[learning rate: 0.00051381]
	Learning Rate: 0.000513807
	LOSS [training: 0.07044975266651218 | validation: 0.036410850227449984]
	TIME [epoch: 9.07 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06487355144749271		[learning rate: 0.00051223]
	Learning Rate: 0.000512232
	LOSS [training: 0.06487355144749271 | validation: 0.10165749563892992]
	TIME [epoch: 9.05 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09429854172904832		[learning rate: 0.00051066]
	Learning Rate: 0.000510662
	LOSS [training: 0.09429854172904832 | validation: 0.048882701223423836]
	TIME [epoch: 9.04 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0794468302273467		[learning rate: 0.0005091]
	Learning Rate: 0.000509096
	LOSS [training: 0.0794468302273467 | validation: 0.1598998081421385]
	TIME [epoch: 9.06 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08730197188101106		[learning rate: 0.00050754]
	Learning Rate: 0.000507536
	LOSS [training: 0.08730197188101106 | validation: 0.06231034431352993]
	TIME [epoch: 9.07 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051894128293996325		[learning rate: 0.00050598]
	Learning Rate: 0.00050598
	LOSS [training: 0.051894128293996325 | validation: 0.040096067226045994]
	TIME [epoch: 9.05 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06674696399648335		[learning rate: 0.00050443]
	Learning Rate: 0.000504429
	LOSS [training: 0.06674696399648335 | validation: 0.07849174852976984]
	TIME [epoch: 9.06 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089115919487553		[learning rate: 0.00050288]
	Learning Rate: 0.000502883
	LOSS [training: 0.07089115919487553 | validation: 0.03821026302858288]
	TIME [epoch: 9.05 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048032462570278524		[learning rate: 0.00050134]
	Learning Rate: 0.000501341
	LOSS [training: 0.048032462570278524 | validation: 0.047483017567252414]
	TIME [epoch: 9.07 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05373481514463261		[learning rate: 0.0004998]
	Learning Rate: 0.000499804
	LOSS [training: 0.05373481514463261 | validation: 0.050934134261713226]
	TIME [epoch: 9.04 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05066595743954572		[learning rate: 0.00049827]
	Learning Rate: 0.000498272
	LOSS [training: 0.05066595743954572 | validation: 0.06020931594037958]
	TIME [epoch: 9.05 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05307015749295776		[learning rate: 0.00049674]
	Learning Rate: 0.000496745
	LOSS [training: 0.05307015749295776 | validation: 0.05179651959008308]
	TIME [epoch: 9.05 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770179969050807		[learning rate: 0.00049522]
	Learning Rate: 0.000495222
	LOSS [training: 0.06770179969050807 | validation: 0.08670522501700784]
	TIME [epoch: 9.06 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06853628254509173		[learning rate: 0.0004937]
	Learning Rate: 0.000493704
	LOSS [training: 0.06853628254509173 | validation: 0.03689450295662738]
	TIME [epoch: 9.04 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0622034948561722		[learning rate: 0.00049219]
	Learning Rate: 0.000492191
	LOSS [training: 0.0622034948561722 | validation: 0.05184954944961623]
	TIME [epoch: 9.05 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09762867926044065		[learning rate: 0.00049068]
	Learning Rate: 0.000490682
	LOSS [training: 0.09762867926044065 | validation: 0.14919470380930744]
	TIME [epoch: 9.04 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05961507913097526		[learning rate: 0.00048918]
	Learning Rate: 0.000489178
	LOSS [training: 0.05961507913097526 | validation: 0.04824884927244556]
	TIME [epoch: 9.06 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049413989534768554		[learning rate: 0.00048768]
	Learning Rate: 0.000487678
	LOSS [training: 0.049413989534768554 | validation: 0.030669354130707562]
	TIME [epoch: 9.04 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04643180374810907		[learning rate: 0.00048618]
	Learning Rate: 0.000486183
	LOSS [training: 0.04643180374810907 | validation: 0.030337936748799994]
	TIME [epoch: 9.05 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04784297417011151		[learning rate: 0.00048469]
	Learning Rate: 0.000484693
	LOSS [training: 0.04784297417011151 | validation: 0.020731006171215524]
	TIME [epoch: 9.04 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05084659312441412		[learning rate: 0.00048321]
	Learning Rate: 0.000483207
	LOSS [training: 0.05084659312441412 | validation: 0.031093777028558915]
	TIME [epoch: 9.07 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051539397903020624		[learning rate: 0.00048173]
	Learning Rate: 0.000481726
	LOSS [training: 0.051539397903020624 | validation: 0.04415443077573106]
	TIME [epoch: 9.04 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054017966324927544		[learning rate: 0.00048025]
	Learning Rate: 0.000480249
	LOSS [training: 0.054017966324927544 | validation: 0.04175049357063169]
	TIME [epoch: 9.04 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05812926815498263		[learning rate: 0.00047878]
	Learning Rate: 0.000478777
	LOSS [training: 0.05812926815498263 | validation: 0.05261439870940751]
	TIME [epoch: 9.05 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03756925758038122		[learning rate: 0.00047731]
	Learning Rate: 0.000477309
	LOSS [training: 0.03756925758038122 | validation: 0.03331240245993952]
	TIME [epoch: 9.07 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03463270320058742		[learning rate: 0.00047585]
	Learning Rate: 0.000475846
	LOSS [training: 0.03463270320058742 | validation: 0.03903425959096245]
	TIME [epoch: 9.07 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05656910118546384		[learning rate: 0.00047439]
	Learning Rate: 0.000474388
	LOSS [training: 0.05656910118546384 | validation: 0.05457936162207175]
	TIME [epoch: 9.05 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06461784274070301		[learning rate: 0.00047293]
	Learning Rate: 0.000472933
	LOSS [training: 0.06461784274070301 | validation: 0.03418958358000933]
	TIME [epoch: 9.05 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07159993808584737		[learning rate: 0.00047148]
	Learning Rate: 0.000471484
	LOSS [training: 0.07159993808584737 | validation: 0.08611441851721535]
	TIME [epoch: 9.05 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359255819655069		[learning rate: 0.00047004]
	Learning Rate: 0.000470038
	LOSS [training: 0.05359255819655069 | validation: 0.05311943566373892]
	TIME [epoch: 9.06 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047206582987042105		[learning rate: 0.0004686]
	Learning Rate: 0.000468597
	LOSS [training: 0.047206582987042105 | validation: 0.042079634218443907]
	TIME [epoch: 9.04 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05285267717478028		[learning rate: 0.00046716]
	Learning Rate: 0.000467161
	LOSS [training: 0.05285267717478028 | validation: 0.02344049011874856]
	TIME [epoch: 9.04 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03913487748870666		[learning rate: 0.00046573]
	Learning Rate: 0.000465729
	LOSS [training: 0.03913487748870666 | validation: 0.030325148146286878]
	TIME [epoch: 9.05 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053761479835627346		[learning rate: 0.0004643]
	Learning Rate: 0.000464301
	LOSS [training: 0.053761479835627346 | validation: 0.06510014409783967]
	TIME [epoch: 9.08 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054835549994308716		[learning rate: 0.00046288]
	Learning Rate: 0.000462878
	LOSS [training: 0.054835549994308716 | validation: 0.050226559573180035]
	TIME [epoch: 9.05 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04324720965147193		[learning rate: 0.00046146]
	Learning Rate: 0.000461459
	LOSS [training: 0.04324720965147193 | validation: 0.022104507810572948]
	TIME [epoch: 9.05 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028196408473681416		[learning rate: 0.00046004]
	Learning Rate: 0.000460045
	LOSS [training: 0.028196408473681416 | validation: 0.029065274986809886]
	TIME [epoch: 9.05 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04666139893343528		[learning rate: 0.00045863]
	Learning Rate: 0.000458634
	LOSS [training: 0.04666139893343528 | validation: 0.07054570563719142]
	TIME [epoch: 9.08 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051094583861953605		[learning rate: 0.00045723]
	Learning Rate: 0.000457229
	LOSS [training: 0.051094583861953605 | validation: 0.0468397340035102]
	TIME [epoch: 9.06 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0448630576097262		[learning rate: 0.00045583]
	Learning Rate: 0.000455827
	LOSS [training: 0.0448630576097262 | validation: 0.06023285899964143]
	TIME [epoch: 9.05 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0367745067845369		[learning rate: 0.00045443]
	Learning Rate: 0.00045443
	LOSS [training: 0.0367745067845369 | validation: 0.023878454589789044]
	TIME [epoch: 9.05 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04161184304173988		[learning rate: 0.00045304]
	Learning Rate: 0.000453037
	LOSS [training: 0.04161184304173988 | validation: 0.07577931205936327]
	TIME [epoch: 9.07 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051565779602752645		[learning rate: 0.00045165]
	Learning Rate: 0.000451648
	LOSS [training: 0.051565779602752645 | validation: 0.04746676801721914]
	TIME [epoch: 9.05 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05638821416326987		[learning rate: 0.00045026]
	Learning Rate: 0.000450263
	LOSS [training: 0.05638821416326987 | validation: 0.04311227732143091]
	TIME [epoch: 9.05 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06424933708033959		[learning rate: 0.00044888]
	Learning Rate: 0.000448883
	LOSS [training: 0.06424933708033959 | validation: 0.0335329510838603]
	TIME [epoch: 9.07 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041121350105268496		[learning rate: 0.00044751]
	Learning Rate: 0.000447507
	LOSS [training: 0.041121350105268496 | validation: 0.03804210594147813]
	TIME [epoch: 9.08 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05623185374589248		[learning rate: 0.00044614]
	Learning Rate: 0.000446135
	LOSS [training: 0.05623185374589248 | validation: 0.058319241250668334]
	TIME [epoch: 9.08 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047375008179558184		[learning rate: 0.00044477]
	Learning Rate: 0.000444768
	LOSS [training: 0.047375008179558184 | validation: 0.03019050458229336]
	TIME [epoch: 9.06 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06037933558786144		[learning rate: 0.0004434]
	Learning Rate: 0.000443404
	LOSS [training: 0.06037933558786144 | validation: 0.03229420554391047]
	TIME [epoch: 9.05 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06578581401492187		[learning rate: 0.00044205]
	Learning Rate: 0.000442045
	LOSS [training: 0.06578581401492187 | validation: 0.03576010112544497]
	TIME [epoch: 9.09 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04107657593771027		[learning rate: 0.00044069]
	Learning Rate: 0.00044069
	LOSS [training: 0.04107657593771027 | validation: 0.04540268424989262]
	TIME [epoch: 9.1 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04435443423289835		[learning rate: 0.00043934]
	Learning Rate: 0.000439339
	LOSS [training: 0.04435443423289835 | validation: 0.029834644434609658]
	TIME [epoch: 9.07 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040954954798477064		[learning rate: 0.00043799]
	Learning Rate: 0.000437992
	LOSS [training: 0.040954954798477064 | validation: 0.04614444730074637]
	TIME [epoch: 9.06 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0465664428285431		[learning rate: 0.00043665]
	Learning Rate: 0.00043665
	LOSS [training: 0.0465664428285431 | validation: 0.027840663749515594]
	TIME [epoch: 9.06 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04136088381432211		[learning rate: 0.00043531]
	Learning Rate: 0.000435311
	LOSS [training: 0.04136088381432211 | validation: 0.04275193347550041]
	TIME [epoch: 9.07 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04975244382426128		[learning rate: 0.00043398]
	Learning Rate: 0.000433977
	LOSS [training: 0.04975244382426128 | validation: 0.045184786476906595]
	TIME [epoch: 9.05 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047000741452139574		[learning rate: 0.00043265]
	Learning Rate: 0.000432647
	LOSS [training: 0.047000741452139574 | validation: 0.034675199561310446]
	TIME [epoch: 9.05 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046508520259031225		[learning rate: 0.00043132]
	Learning Rate: 0.00043132
	LOSS [training: 0.046508520259031225 | validation: 0.03665443400153087]
	TIME [epoch: 9.05 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03862906227075961		[learning rate: 0.00043]
	Learning Rate: 0.000429998
	LOSS [training: 0.03862906227075961 | validation: 0.018101429561911797]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1525.pth
	Model improved!!!
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024082344824455433		[learning rate: 0.00042868]
	Learning Rate: 0.00042868
	LOSS [training: 0.024082344824455433 | validation: 0.037184715633926925]
	TIME [epoch: 9.05 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04565779378749281		[learning rate: 0.00042737]
	Learning Rate: 0.000427366
	LOSS [training: 0.04565779378749281 | validation: 0.042045195408739064]
	TIME [epoch: 9.05 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045200369732413245		[learning rate: 0.00042606]
	Learning Rate: 0.000426056
	LOSS [training: 0.045200369732413245 | validation: 0.05842298244430176]
	TIME [epoch: 9.05 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06457574324060443		[learning rate: 0.00042475]
	Learning Rate: 0.00042475
	LOSS [training: 0.06457574324060443 | validation: 0.0648149702046753]
	TIME [epoch: 9.07 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05338419968951227		[learning rate: 0.00042345]
	Learning Rate: 0.000423448
	LOSS [training: 0.05338419968951227 | validation: 0.03571036559708745]
	TIME [epoch: 9.05 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051877113277329454		[learning rate: 0.00042215]
	Learning Rate: 0.00042215
	LOSS [training: 0.051877113277329454 | validation: 0.03764706933924923]
	TIME [epoch: 9.05 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06382227081373841		[learning rate: 0.00042086]
	Learning Rate: 0.000420856
	LOSS [training: 0.06382227081373841 | validation: 0.06113641310131495]
	TIME [epoch: 9.05 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053148741750023855		[learning rate: 0.00041957]
	Learning Rate: 0.000419566
	LOSS [training: 0.053148741750023855 | validation: 0.037628827613590154]
	TIME [epoch: 9.06 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041774666322496934		[learning rate: 0.00041828]
	Learning Rate: 0.00041828
	LOSS [training: 0.041774666322496934 | validation: 0.05348480077020972]
	TIME [epoch: 9.07 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043598115398587746		[learning rate: 0.000417]
	Learning Rate: 0.000416997
	LOSS [training: 0.043598115398587746 | validation: 0.04865740953063563]
	TIME [epoch: 9.06 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03852189387261549		[learning rate: 0.00041572]
	Learning Rate: 0.000415719
	LOSS [training: 0.03852189387261549 | validation: 0.03543533826406287]
	TIME [epoch: 9.05 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05242350015205303		[learning rate: 0.00041444]
	Learning Rate: 0.000414445
	LOSS [training: 0.05242350015205303 | validation: 0.028296532007571658]
	TIME [epoch: 9.05 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036619239163405384		[learning rate: 0.00041317]
	Learning Rate: 0.000413174
	LOSS [training: 0.036619239163405384 | validation: 0.040185922324314324]
	TIME [epoch: 9.08 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036920088608710266		[learning rate: 0.00041191]
	Learning Rate: 0.000411908
	LOSS [training: 0.036920088608710266 | validation: 0.0607097036375675]
	TIME [epoch: 9.06 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07359498704425696		[learning rate: 0.00041065]
	Learning Rate: 0.000410645
	LOSS [training: 0.07359498704425696 | validation: 0.039912468025209584]
	TIME [epoch: 9.06 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04520210334240836		[learning rate: 0.00040939]
	Learning Rate: 0.000409386
	LOSS [training: 0.04520210334240836 | validation: 0.03239078656348083]
	TIME [epoch: 9.05 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05820882018353537		[learning rate: 0.00040813]
	Learning Rate: 0.000408131
	LOSS [training: 0.05820882018353537 | validation: 0.06598499054715423]
	TIME [epoch: 9.07 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05977073511470434		[learning rate: 0.00040688]
	Learning Rate: 0.00040688
	LOSS [training: 0.05977073511470434 | validation: 0.07217478002054377]
	TIME [epoch: 9.06 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06426251941606739		[learning rate: 0.00040563]
	Learning Rate: 0.000405633
	LOSS [training: 0.06426251941606739 | validation: 0.06433205452104943]
	TIME [epoch: 9.05 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08773044923214171		[learning rate: 0.00040439]
	Learning Rate: 0.00040439
	LOSS [training: 0.08773044923214171 | validation: 0.08144848196027174]
	TIME [epoch: 9.05 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06966566231421495		[learning rate: 0.00040315]
	Learning Rate: 0.00040315
	LOSS [training: 0.06966566231421495 | validation: 0.0366642300631638]
	TIME [epoch: 9.07 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05231371684906553		[learning rate: 0.00040191]
	Learning Rate: 0.000401914
	LOSS [training: 0.05231371684906553 | validation: 0.04445399259266426]
	TIME [epoch: 9.05 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04346580444592706		[learning rate: 0.00040068]
	Learning Rate: 0.000400682
	LOSS [training: 0.04346580444592706 | validation: 0.03043057585229219]
	TIME [epoch: 9.05 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044239579664836166		[learning rate: 0.00039945]
	Learning Rate: 0.000399454
	LOSS [training: 0.044239579664836166 | validation: 0.049136476110433175]
	TIME [epoch: 9.05 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04633519314222315		[learning rate: 0.00039823]
	Learning Rate: 0.000398229
	LOSS [training: 0.04633519314222315 | validation: 0.12575529683150127]
	TIME [epoch: 9.08 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889268831355717		[learning rate: 0.00039701]
	Learning Rate: 0.000397009
	LOSS [training: 0.06889268831355717 | validation: 0.05603975187304935]
	TIME [epoch: 9.06 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057172390419109057		[learning rate: 0.00039579]
	Learning Rate: 0.000395792
	LOSS [training: 0.057172390419109057 | validation: 0.03752729633906458]
	TIME [epoch: 9.05 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04448528623329236		[learning rate: 0.00039458]
	Learning Rate: 0.000394578
	LOSS [training: 0.04448528623329236 | validation: 0.035710017242703486]
	TIME [epoch: 9.05 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06190827245488899		[learning rate: 0.00039337]
	Learning Rate: 0.000393369
	LOSS [training: 0.06190827245488899 | validation: 0.05783516472172977]
	TIME [epoch: 9.07 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497178409511503		[learning rate: 0.00039216]
	Learning Rate: 0.000392163
	LOSS [training: 0.06497178409511503 | validation: 0.05044443427952934]
	TIME [epoch: 9.07 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05222796965185914		[learning rate: 0.00039096]
	Learning Rate: 0.000390961
	LOSS [training: 0.05222796965185914 | validation: 0.07101329783096122]
	TIME [epoch: 9.05 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057775572705933934		[learning rate: 0.00038976]
	Learning Rate: 0.000389762
	LOSS [training: 0.057775572705933934 | validation: 0.05574192531118176]
	TIME [epoch: 9.05 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04294477778445513		[learning rate: 0.00038857]
	Learning Rate: 0.000388568
	LOSS [training: 0.04294477778445513 | validation: 0.034967427410114604]
	TIME [epoch: 9.06 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05003630315366405		[learning rate: 0.00038738]
	Learning Rate: 0.000387377
	LOSS [training: 0.05003630315366405 | validation: 0.04343858157637271]
	TIME [epoch: 9.07 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04051985159581949		[learning rate: 0.00038619]
	Learning Rate: 0.000386189
	LOSS [training: 0.04051985159581949 | validation: 0.03859801510711215]
	TIME [epoch: 9.06 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038708904491704985		[learning rate: 0.00038501]
	Learning Rate: 0.000385005
	LOSS [training: 0.038708904491704985 | validation: 0.034780140659536364]
	TIME [epoch: 9.05 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04484946802983337		[learning rate: 0.00038382]
	Learning Rate: 0.000383825
	LOSS [training: 0.04484946802983337 | validation: 0.020456250737499244]
	TIME [epoch: 9.06 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041512365019812265		[learning rate: 0.00038265]
	Learning Rate: 0.000382649
	LOSS [training: 0.041512365019812265 | validation: 0.04796422571147639]
	TIME [epoch: 9.08 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05142963573987615		[learning rate: 0.00038148]
	Learning Rate: 0.000381476
	LOSS [training: 0.05142963573987615 | validation: 0.046217185504087405]
	TIME [epoch: 9.06 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05325237674580274		[learning rate: 0.00038031]
	Learning Rate: 0.000380306
	LOSS [training: 0.05325237674580274 | validation: 0.06161267693595634]
	TIME [epoch: 9.06 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07555282595360277		[learning rate: 0.00037914]
	Learning Rate: 0.00037914
	LOSS [training: 0.07555282595360277 | validation: 0.06808189914300498]
	TIME [epoch: 9.06 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07190525610637784		[learning rate: 0.00037798]
	Learning Rate: 0.000377978
	LOSS [training: 0.07190525610637784 | validation: 0.06149414072611954]
	TIME [epoch: 9.07 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04913963691209516		[learning rate: 0.00037682]
	Learning Rate: 0.000376819
	LOSS [training: 0.04913963691209516 | validation: 0.06177276643413673]
	TIME [epoch: 9.06 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07251290915642765		[learning rate: 0.00037566]
	Learning Rate: 0.000375664
	LOSS [training: 0.07251290915642765 | validation: 0.045026713408011114]
	TIME [epoch: 9.05 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043391777502106765		[learning rate: 0.00037451]
	Learning Rate: 0.000374513
	LOSS [training: 0.043391777502106765 | validation: 0.04918493075220689]
	TIME [epoch: 9.06 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052450499776900604		[learning rate: 0.00037336]
	Learning Rate: 0.000373365
	LOSS [training: 0.052450499776900604 | validation: 0.05014217833516843]
	TIME [epoch: 9.08 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05806764063170792		[learning rate: 0.00037222]
	Learning Rate: 0.00037222
	LOSS [training: 0.05806764063170792 | validation: 0.08303503349040434]
	TIME [epoch: 9.06 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050401501151508155		[learning rate: 0.00037108]
	Learning Rate: 0.000371079
	LOSS [training: 0.050401501151508155 | validation: 0.03181173540433291]
	TIME [epoch: 9.06 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03726604175720285		[learning rate: 0.00036994]
	Learning Rate: 0.000369942
	LOSS [training: 0.03726604175720285 | validation: 0.02636668186768531]
	TIME [epoch: 9.06 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057439977471461054		[learning rate: 0.00036881]
	Learning Rate: 0.000368808
	LOSS [training: 0.057439977471461054 | validation: 0.03297163043331516]
	TIME [epoch: 9.06 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04040003010072318		[learning rate: 0.00036768]
	Learning Rate: 0.000367677
	LOSS [training: 0.04040003010072318 | validation: 0.05189081115380781]
	TIME [epoch: 9.07 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04039490303092145		[learning rate: 0.00036655]
	Learning Rate: 0.00036655
	LOSS [training: 0.04039490303092145 | validation: 0.05279889900242625]
	TIME [epoch: 9.05 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04850113046761824		[learning rate: 0.00036543]
	Learning Rate: 0.000365426
	LOSS [training: 0.04850113046761824 | validation: 0.04004092144515221]
	TIME [epoch: 9.06 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04573770676057368		[learning rate: 0.00036431]
	Learning Rate: 0.000364306
	LOSS [training: 0.04573770676057368 | validation: 0.03976940665123824]
	TIME [epoch: 9.06 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06364529045739625		[learning rate: 0.00036319]
	Learning Rate: 0.00036319
	LOSS [training: 0.06364529045739625 | validation: 0.03831713390964598]
	TIME [epoch: 9.07 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04249296956109409		[learning rate: 0.00036208]
	Learning Rate: 0.000362076
	LOSS [training: 0.04249296956109409 | validation: 0.043654805415947434]
	TIME [epoch: 9.05 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03774299644006366		[learning rate: 0.00036097]
	Learning Rate: 0.000360966
	LOSS [training: 0.03774299644006366 | validation: 0.029421049991601306]
	TIME [epoch: 9.05 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03621389405056511		[learning rate: 0.00035986]
	Learning Rate: 0.00035986
	LOSS [training: 0.03621389405056511 | validation: 0.027469450826069608]
	TIME [epoch: 9.05 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04312260954195161		[learning rate: 0.00035876]
	Learning Rate: 0.000358757
	LOSS [training: 0.04312260954195161 | validation: 0.07167327177502728]
	TIME [epoch: 9.07 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03774563077509259		[learning rate: 0.00035766]
	Learning Rate: 0.000357657
	LOSS [training: 0.03774563077509259 | validation: 0.031796425372441754]
	TIME [epoch: 9.05 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029941944954363486		[learning rate: 0.00035656]
	Learning Rate: 0.000356561
	LOSS [training: 0.029941944954363486 | validation: 0.05112017819108398]
	TIME [epoch: 9.06 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03738985542820119		[learning rate: 0.00035547]
	Learning Rate: 0.000355468
	LOSS [training: 0.03738985542820119 | validation: 0.03322688271813251]
	TIME [epoch: 9.07 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05409401925334413		[learning rate: 0.00035438]
	Learning Rate: 0.000354378
	LOSS [training: 0.05409401925334413 | validation: 0.04535117088781711]
	TIME [epoch: 9.08 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05167765721006379		[learning rate: 0.00035329]
	Learning Rate: 0.000353292
	LOSS [training: 0.05167765721006379 | validation: 0.027962431475686944]
	TIME [epoch: 9.05 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06043908669576951		[learning rate: 0.00035221]
	Learning Rate: 0.000352209
	LOSS [training: 0.06043908669576951 | validation: 0.046985328265292725]
	TIME [epoch: 9.05 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04105471894314271		[learning rate: 0.00035113]
	Learning Rate: 0.000351129
	LOSS [training: 0.04105471894314271 | validation: 0.05223322878226296]
	TIME [epoch: 9.06 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07728429378263464		[learning rate: 0.00035005]
	Learning Rate: 0.000350053
	LOSS [training: 0.07728429378263464 | validation: 0.03318658129520873]
	TIME [epoch: 9.07 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041356436351212666		[learning rate: 0.00034898]
	Learning Rate: 0.000348979
	LOSS [training: 0.041356436351212666 | validation: 0.028929332734425387]
	TIME [epoch: 9.06 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03351822071531531		[learning rate: 0.00034791]
	Learning Rate: 0.00034791
	LOSS [training: 0.03351822071531531 | validation: 0.025175624120432644]
	TIME [epoch: 9.05 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02709001949174572		[learning rate: 0.00034684]
	Learning Rate: 0.000346843
	LOSS [training: 0.02709001949174572 | validation: 0.044005151780535434]
	TIME [epoch: 9.05 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664389581302591		[learning rate: 0.00034578]
	Learning Rate: 0.00034578
	LOSS [training: 0.05664389581302591 | validation: 0.07684787165022494]
	TIME [epoch: 9.08 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05956795345947154		[learning rate: 0.00034472]
	Learning Rate: 0.00034472
	LOSS [training: 0.05956795345947154 | validation: 0.025452364607056056]
	TIME [epoch: 9.06 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033930811862054676		[learning rate: 0.00034366]
	Learning Rate: 0.000343663
	LOSS [training: 0.033930811862054676 | validation: 0.03424144564611506]
	TIME [epoch: 9.06 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03710553608213083		[learning rate: 0.00034261]
	Learning Rate: 0.00034261
	LOSS [training: 0.03710553608213083 | validation: 0.04129274082551246]
	TIME [epoch: 9.06 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07455936847871039		[learning rate: 0.00034156]
	Learning Rate: 0.00034156
	LOSS [training: 0.07455936847871039 | validation: 0.0877887513628749]
	TIME [epoch: 9.07 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871089166440039		[learning rate: 0.00034051]
	Learning Rate: 0.000340513
	LOSS [training: 0.05871089166440039 | validation: 0.0888574163536848]
	TIME [epoch: 9.07 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04858680914358565		[learning rate: 0.00033947]
	Learning Rate: 0.000339469
	LOSS [training: 0.04858680914358565 | validation: 0.051880926513557815]
	TIME [epoch: 9.06 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229510418222337		[learning rate: 0.00033843]
	Learning Rate: 0.000338428
	LOSS [training: 0.06229510418222337 | validation: 0.07511852758272387]
	TIME [epoch: 9.06 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036554176186754446		[learning rate: 0.00033739]
	Learning Rate: 0.000337391
	LOSS [training: 0.036554176186754446 | validation: 0.029082634382407022]
	TIME [epoch: 9.07 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03450549991872599		[learning rate: 0.00033636]
	Learning Rate: 0.000336357
	LOSS [training: 0.03450549991872599 | validation: 0.04529444995035126]
	TIME [epoch: 9.07 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04154759958345644		[learning rate: 0.00033533]
	Learning Rate: 0.000335326
	LOSS [training: 0.04154759958345644 | validation: 0.04485218296657676]
	TIME [epoch: 9.07 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03569434345137393		[learning rate: 0.0003343]
	Learning Rate: 0.000334298
	LOSS [training: 0.03569434345137393 | validation: 0.04641924662485364]
	TIME [epoch: 9.06 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03252531807691321		[learning rate: 0.00033327]
	Learning Rate: 0.000333273
	LOSS [training: 0.03252531807691321 | validation: 0.040754277696871025]
	TIME [epoch: 9.06 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075565208739514		[learning rate: 0.00033225]
	Learning Rate: 0.000332251
	LOSS [training: 0.04075565208739514 | validation: 0.020579335359836366]
	TIME [epoch: 9.08 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03465479679616486		[learning rate: 0.00033123]
	Learning Rate: 0.000331233
	LOSS [training: 0.03465479679616486 | validation: 0.04120232723029617]
	TIME [epoch: 9.06 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03741120495363103		[learning rate: 0.00033022]
	Learning Rate: 0.000330217
	LOSS [training: 0.03741120495363103 | validation: 0.037652984273910804]
	TIME [epoch: 9.06 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04030008734585656		[learning rate: 0.00032921]
	Learning Rate: 0.000329205
	LOSS [training: 0.04030008734585656 | validation: 0.04288289410857847]
	TIME [epoch: 9.06 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048136961972084724		[learning rate: 0.0003282]
	Learning Rate: 0.000328196
	LOSS [training: 0.048136961972084724 | validation: 0.03952204793581307]
	TIME [epoch: 9.08 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051149807554125494		[learning rate: 0.00032719]
	Learning Rate: 0.00032719
	LOSS [training: 0.051149807554125494 | validation: 0.08335055216086687]
	TIME [epoch: 9.06 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042892685700578664		[learning rate: 0.00032619]
	Learning Rate: 0.000326187
	LOSS [training: 0.042892685700578664 | validation: 0.049346221566279956]
	TIME [epoch: 9.06 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06014659561600032		[learning rate: 0.00032519]
	Learning Rate: 0.000325187
	LOSS [training: 0.06014659561600032 | validation: 0.0567862490436517]
	TIME [epoch: 9.06 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05680823282669449		[learning rate: 0.00032419]
	Learning Rate: 0.00032419
	LOSS [training: 0.05680823282669449 | validation: 0.049938868833151275]
	TIME [epoch: 9.08 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05252598509812815		[learning rate: 0.0003232]
	Learning Rate: 0.000323196
	LOSS [training: 0.05252598509812815 | validation: 0.06275006051645837]
	TIME [epoch: 9.06 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0553163584540297		[learning rate: 0.00032221]
	Learning Rate: 0.000322206
	LOSS [training: 0.0553163584540297 | validation: 0.04682983503051638]
	TIME [epoch: 9.06 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05811267606247293		[learning rate: 0.00032122]
	Learning Rate: 0.000321218
	LOSS [training: 0.05811267606247293 | validation: 0.03895146045478552]
	TIME [epoch: 9.05 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03812129735686162		[learning rate: 0.00032023]
	Learning Rate: 0.000320233
	LOSS [training: 0.03812129735686162 | validation: 0.044298315543420036]
	TIME [epoch: 9.07 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04341201885429141		[learning rate: 0.00031925]
	Learning Rate: 0.000319252
	LOSS [training: 0.04341201885429141 | validation: 0.04099276715532618]
	TIME [epoch: 9.06 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045088266528220095		[learning rate: 0.00031827]
	Learning Rate: 0.000318273
	LOSS [training: 0.045088266528220095 | validation: 0.03305664782681486]
	TIME [epoch: 9.06 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04907601068539099		[learning rate: 0.0003173]
	Learning Rate: 0.000317297
	LOSS [training: 0.04907601068539099 | validation: 0.04958018492772883]
	TIME [epoch: 9.05 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04464815670320444		[learning rate: 0.00031632]
	Learning Rate: 0.000316325
	LOSS [training: 0.04464815670320444 | validation: 0.07029064419822995]
	TIME [epoch: 9.06 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045127548801164305		[learning rate: 0.00031536]
	Learning Rate: 0.000315355
	LOSS [training: 0.045127548801164305 | validation: 0.03100503024211183]
	TIME [epoch: 9.07 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045490397593020634		[learning rate: 0.00031439]
	Learning Rate: 0.000314389
	LOSS [training: 0.045490397593020634 | validation: 0.028905063825262655]
	TIME [epoch: 9.06 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051646089468626886		[learning rate: 0.00031342]
	Learning Rate: 0.000313425
	LOSS [training: 0.051646089468626886 | validation: 0.024458682030238158]
	TIME [epoch: 9.05 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0483485006459757		[learning rate: 0.00031246]
	Learning Rate: 0.000312464
	LOSS [training: 0.0483485006459757 | validation: 0.04523994085113586]
	TIME [epoch: 9.06 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05517614243520798		[learning rate: 0.00031151]
	Learning Rate: 0.000311506
	LOSS [training: 0.05517614243520798 | validation: 0.04246754109490826]
	TIME [epoch: 9.08 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053070360898418475		[learning rate: 0.00031055]
	Learning Rate: 0.000310551
	LOSS [training: 0.053070360898418475 | validation: 0.04079250282647058]
	TIME [epoch: 9.08 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05375685952830352		[learning rate: 0.0003096]
	Learning Rate: 0.000309599
	LOSS [training: 0.05375685952830352 | validation: 0.03570914246315862]
	TIME [epoch: 9.05 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044508062304033		[learning rate: 0.00030865]
	Learning Rate: 0.00030865
	LOSS [training: 0.044508062304033 | validation: 0.05510707875527503]
	TIME [epoch: 9.06 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041044562076994674		[learning rate: 0.0003077]
	Learning Rate: 0.000307704
	LOSS [training: 0.041044562076994674 | validation: 0.024133626242651546]
	TIME [epoch: 9.08 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673309426828393		[learning rate: 0.00030676]
	Learning Rate: 0.000306761
	LOSS [training: 0.04673309426828393 | validation: 0.024002801993908196]
	TIME [epoch: 9.06 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04750766594984057		[learning rate: 0.00030582]
	Learning Rate: 0.00030582
	LOSS [training: 0.04750766594984057 | validation: 0.05821760666184082]
	TIME [epoch: 9.06 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03977804940033993		[learning rate: 0.00030488]
	Learning Rate: 0.000304883
	LOSS [training: 0.03977804940033993 | validation: 0.053274924007145535]
	TIME [epoch: 9.06 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03707218379632223		[learning rate: 0.00030395]
	Learning Rate: 0.000303948
	LOSS [training: 0.03707218379632223 | validation: 0.026676391174195173]
	TIME [epoch: 9.08 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037989836528031146		[learning rate: 0.00030302]
	Learning Rate: 0.000303017
	LOSS [training: 0.037989836528031146 | validation: 0.04099809954817184]
	TIME [epoch: 9.07 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04564701152984884		[learning rate: 0.00030209]
	Learning Rate: 0.000302088
	LOSS [training: 0.04564701152984884 | validation: 0.03919499999014126]
	TIME [epoch: 9.06 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04429409297979515		[learning rate: 0.00030116]
	Learning Rate: 0.000301162
	LOSS [training: 0.04429409297979515 | validation: 0.04114979311601681]
	TIME [epoch: 9.06 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047671067115973596		[learning rate: 0.00030024]
	Learning Rate: 0.000300239
	LOSS [training: 0.047671067115973596 | validation: 0.03621796926318005]
	TIME [epoch: 9.08 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04879981182499844		[learning rate: 0.00029932]
	Learning Rate: 0.000299318
	LOSS [training: 0.04879981182499844 | validation: 0.03897928097598932]
	TIME [epoch: 9.07 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043885151630540783		[learning rate: 0.0002984]
	Learning Rate: 0.000298401
	LOSS [training: 0.043885151630540783 | validation: 0.07070446235940572]
	TIME [epoch: 9.06 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03697741977095217		[learning rate: 0.00029749]
	Learning Rate: 0.000297486
	LOSS [training: 0.03697741977095217 | validation: 0.019438652221559202]
	TIME [epoch: 9.06 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03549332218781538		[learning rate: 0.00029657]
	Learning Rate: 0.000296574
	LOSS [training: 0.03549332218781538 | validation: 0.042813057906719826]
	TIME [epoch: 9.06 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03943469750291372		[learning rate: 0.00029567]
	Learning Rate: 0.000295665
	LOSS [training: 0.03943469750291372 | validation: 0.04556366047956145]
	TIME [epoch: 9.07 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05069188072316757		[learning rate: 0.00029476]
	Learning Rate: 0.000294759
	LOSS [training: 0.05069188072316757 | validation: 0.036581235063359516]
	TIME [epoch: 9.05 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05582562733402883		[learning rate: 0.00029386]
	Learning Rate: 0.000293855
	LOSS [training: 0.05582562733402883 | validation: 0.052466258745410374]
	TIME [epoch: 9.05 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04285210507803998		[learning rate: 0.00029295]
	Learning Rate: 0.000292954
	LOSS [training: 0.04285210507803998 | validation: 0.036620455436372205]
	TIME [epoch: 9.06 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04529435967934457		[learning rate: 0.00029206]
	Learning Rate: 0.000292056
	LOSS [training: 0.04529435967934457 | validation: 0.04086601700905858]
	TIME [epoch: 9.07 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03675906012079666		[learning rate: 0.00029116]
	Learning Rate: 0.000291161
	LOSS [training: 0.03675906012079666 | validation: 0.04115738382083583]
	TIME [epoch: 9.05 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04337529927796131		[learning rate: 0.00029027]
	Learning Rate: 0.000290269
	LOSS [training: 0.04337529927796131 | validation: 0.03689467112313286]
	TIME [epoch: 9.06 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050143698761031766		[learning rate: 0.00028938]
	Learning Rate: 0.000289379
	LOSS [training: 0.050143698761031766 | validation: 0.03328443218149829]
	TIME [epoch: 9.06 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038424669675882234		[learning rate: 0.00028849]
	Learning Rate: 0.000288492
	LOSS [training: 0.038424669675882234 | validation: 0.04600924678509519]
	TIME [epoch: 9.08 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387300249961269		[learning rate: 0.00028761]
	Learning Rate: 0.000287607
	LOSS [training: 0.05387300249961269 | validation: 0.039232737730859904]
	TIME [epoch: 9.06 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03383519373269096		[learning rate: 0.00028673]
	Learning Rate: 0.000286726
	LOSS [training: 0.03383519373269096 | validation: 0.03623515783996047]
	TIME [epoch: 9.05 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033975154457357326		[learning rate: 0.00028585]
	Learning Rate: 0.000285847
	LOSS [training: 0.033975154457357326 | validation: 0.03861115621478034]
	TIME [epoch: 9.06 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03738909827928128		[learning rate: 0.00028497]
	Learning Rate: 0.000284971
	LOSS [training: 0.03738909827928128 | validation: 0.046713277190820086]
	TIME [epoch: 9.08 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045347298764905314		[learning rate: 0.0002841]
	Learning Rate: 0.000284097
	LOSS [training: 0.045347298764905314 | validation: 0.049237219937934895]
	TIME [epoch: 9.06 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046406476698807944		[learning rate: 0.00028323]
	Learning Rate: 0.000283226
	LOSS [training: 0.046406476698807944 | validation: 0.04131587582884515]
	TIME [epoch: 9.05 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04184348134990011		[learning rate: 0.00028236]
	Learning Rate: 0.000282358
	LOSS [training: 0.04184348134990011 | validation: 0.030006885217329703]
	TIME [epoch: 9.05 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0389423953729577		[learning rate: 0.00028149]
	Learning Rate: 0.000281492
	LOSS [training: 0.0389423953729577 | validation: 0.03375288782584261]
	TIME [epoch: 9.08 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04803022439101575		[learning rate: 0.00028063]
	Learning Rate: 0.000280629
	LOSS [training: 0.04803022439101575 | validation: 0.08235123549496272]
	TIME [epoch: 9.05 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07700283450878384		[learning rate: 0.00027977]
	Learning Rate: 0.000279769
	LOSS [training: 0.07700283450878384 | validation: 0.03731886301910567]
	TIME [epoch: 9.05 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029689593914652757		[learning rate: 0.00027891]
	Learning Rate: 0.000278912
	LOSS [training: 0.029689593914652757 | validation: 0.023129249767687265]
	TIME [epoch: 9.06 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029023669360470523		[learning rate: 0.00027806]
	Learning Rate: 0.000278057
	LOSS [training: 0.029023669360470523 | validation: 0.03852566664750875]
	TIME [epoch: 9.07 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026961362462323467		[learning rate: 0.0002772]
	Learning Rate: 0.000277204
	LOSS [training: 0.026961362462323467 | validation: 0.02880652311896103]
	TIME [epoch: 9.06 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04718089250322808		[learning rate: 0.00027635]
	Learning Rate: 0.000276355
	LOSS [training: 0.04718089250322808 | validation: 0.03710863202991336]
	TIME [epoch: 9.06 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04257592934775263		[learning rate: 0.00027551]
	Learning Rate: 0.000275507
	LOSS [training: 0.04257592934775263 | validation: 0.05993053444920529]
	TIME [epoch: 9.05 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06719952736481874		[learning rate: 0.00027466]
	Learning Rate: 0.000274663
	LOSS [training: 0.06719952736481874 | validation: 0.044145538374156426]
	TIME [epoch: 9.06 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04219517169909948		[learning rate: 0.00027382]
	Learning Rate: 0.000273821
	LOSS [training: 0.04219517169909948 | validation: 0.03563345749704157]
	TIME [epoch: 9.07 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0401019008809035		[learning rate: 0.00027298]
	Learning Rate: 0.000272982
	LOSS [training: 0.0401019008809035 | validation: 0.032018530959508795]
	TIME [epoch: 9.06 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03624530342364951		[learning rate: 0.00027214]
	Learning Rate: 0.000272145
	LOSS [training: 0.03624530342364951 | validation: 0.039123017244001704]
	TIME [epoch: 9.05 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038522946532851446		[learning rate: 0.00027131]
	Learning Rate: 0.000271311
	LOSS [training: 0.038522946532851446 | validation: 0.04918059916391508]
	TIME [epoch: 9.07 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05384790523025331		[learning rate: 0.00027048]
	Learning Rate: 0.000270479
	LOSS [training: 0.05384790523025331 | validation: 0.03219172296022711]
	TIME [epoch: 9.07 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029953955618791946		[learning rate: 0.00026965]
	Learning Rate: 0.00026965
	LOSS [training: 0.029953955618791946 | validation: 0.026856431496131053]
	TIME [epoch: 9.06 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03667355172627979		[learning rate: 0.00026882]
	Learning Rate: 0.000268823
	LOSS [training: 0.03667355172627979 | validation: 0.03462193077739925]
	TIME [epoch: 9.05 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03197005574696314		[learning rate: 0.000268]
	Learning Rate: 0.000267999
	LOSS [training: 0.03197005574696314 | validation: 0.024185226620984795]
	TIME [epoch: 9.06 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030798723007110694		[learning rate: 0.00026718]
	Learning Rate: 0.000267178
	LOSS [training: 0.030798723007110694 | validation: 0.02374033222366728]
	TIME [epoch: 9.08 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03295352377899681		[learning rate: 0.00026636]
	Learning Rate: 0.000266359
	LOSS [training: 0.03295352377899681 | validation: 0.03657841579837711]
	TIME [epoch: 9.06 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02281179081643986		[learning rate: 0.00026554]
	Learning Rate: 0.000265542
	LOSS [training: 0.02281179081643986 | validation: 0.032573440620954006]
	TIME [epoch: 9.06 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033311547302624214		[learning rate: 0.00026473]
	Learning Rate: 0.000264728
	LOSS [training: 0.033311547302624214 | validation: 0.03187087650796562]
	TIME [epoch: 9.05 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033689941393934		[learning rate: 0.00026392]
	Learning Rate: 0.000263917
	LOSS [training: 0.033689941393934 | validation: 0.033136653743231326]
	TIME [epoch: 9.08 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033662759588299715		[learning rate: 0.00026311]
	Learning Rate: 0.000263108
	LOSS [training: 0.033662759588299715 | validation: 0.022633304585744477]
	TIME [epoch: 9.06 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033798931371239564		[learning rate: 0.0002623]
	Learning Rate: 0.000262301
	LOSS [training: 0.033798931371239564 | validation: 0.03755924918485699]
	TIME [epoch: 9.06 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0400400360855205		[learning rate: 0.0002615]
	Learning Rate: 0.000261497
	LOSS [training: 0.0400400360855205 | validation: 0.03893506491822653]
	TIME [epoch: 9.06 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03785566901152075		[learning rate: 0.0002607]
	Learning Rate: 0.000260695
	LOSS [training: 0.03785566901152075 | validation: 0.05310180259771782]
	TIME [epoch: 9.08 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03364163862197801		[learning rate: 0.0002599]
	Learning Rate: 0.000259896
	LOSS [training: 0.03364163862197801 | validation: 0.03374635104217805]
	TIME [epoch: 9.06 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03358173593773041		[learning rate: 0.0002591]
	Learning Rate: 0.0002591
	LOSS [training: 0.03358173593773041 | validation: 0.030152856961361406]
	TIME [epoch: 9.06 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027470070501935596		[learning rate: 0.00025831]
	Learning Rate: 0.000258305
	LOSS [training: 0.027470070501935596 | validation: 0.020249299583161212]
	TIME [epoch: 9.06 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02645608086390755		[learning rate: 0.00025751]
	Learning Rate: 0.000257513
	LOSS [training: 0.02645608086390755 | validation: 0.05230270485926537]
	TIME [epoch: 9.08 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04971962469166366		[learning rate: 0.00025672]
	Learning Rate: 0.000256724
	LOSS [training: 0.04971962469166366 | validation: 0.01871368749817041]
	TIME [epoch: 9.07 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02611508120112227		[learning rate: 0.00025594]
	Learning Rate: 0.000255937
	LOSS [training: 0.02611508120112227 | validation: 0.04204470133410052]
	TIME [epoch: 9.06 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043907921616279384		[learning rate: 0.00025515]
	Learning Rate: 0.000255153
	LOSS [training: 0.043907921616279384 | validation: 0.05000817050079713]
	TIME [epoch: 9.06 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08192981565466137		[learning rate: 0.00025437]
	Learning Rate: 0.00025437
	LOSS [training: 0.08192981565466137 | validation: 0.0508156780903945]
	TIME [epoch: 9.07 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039557806626792515		[learning rate: 0.00025359]
	Learning Rate: 0.000253591
	LOSS [training: 0.039557806626792515 | validation: 0.0345384651777107]
	TIME [epoch: 9.08 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034909838887042396		[learning rate: 0.00025281]
	Learning Rate: 0.000252813
	LOSS [training: 0.034909838887042396 | validation: 0.03849850737654942]
	TIME [epoch: 9.06 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04591165277537459		[learning rate: 0.00025204]
	Learning Rate: 0.000252038
	LOSS [training: 0.04591165277537459 | validation: 0.042381136213546666]
	TIME [epoch: 9.06 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03287216343457314		[learning rate: 0.00025127]
	Learning Rate: 0.000251266
	LOSS [training: 0.03287216343457314 | validation: 0.024292079553805426]
	TIME [epoch: 9.06 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03614131879204484		[learning rate: 0.0002505]
	Learning Rate: 0.000250496
	LOSS [training: 0.03614131879204484 | validation: 0.034626141637445214]
	TIME [epoch: 9.09 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02586389228131152		[learning rate: 0.00024973]
	Learning Rate: 0.000249728
	LOSS [training: 0.02586389228131152 | validation: 0.009903380086233603]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1702.pth
	Model improved!!!
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030945293521947297		[learning rate: 0.00024896]
	Learning Rate: 0.000248962
	LOSS [training: 0.030945293521947297 | validation: 0.04060315550441025]
	TIME [epoch: 9.07 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03566493375675257		[learning rate: 0.0002482]
	Learning Rate: 0.000248199
	LOSS [training: 0.03566493375675257 | validation: 0.04560485505113539]
	TIME [epoch: 9.07 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03626327504872696		[learning rate: 0.00024744]
	Learning Rate: 0.000247438
	LOSS [training: 0.03626327504872696 | validation: 0.035880203878504595]
	TIME [epoch: 9.09 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026271071054807325		[learning rate: 0.00024668]
	Learning Rate: 0.00024668
	LOSS [training: 0.026271071054807325 | validation: 0.022126638646753037]
	TIME [epoch: 9.06 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02678035860247661		[learning rate: 0.00024592]
	Learning Rate: 0.000245923
	LOSS [training: 0.02678035860247661 | validation: 0.02525149782674236]
	TIME [epoch: 9.07 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027109746683402353		[learning rate: 0.00024517]
	Learning Rate: 0.00024517
	LOSS [training: 0.027109746683402353 | validation: 0.019151663779399572]
	TIME [epoch: 9.06 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02461855396199568		[learning rate: 0.00024442]
	Learning Rate: 0.000244418
	LOSS [training: 0.02461855396199568 | validation: 0.02118220920953521]
	TIME [epoch: 9.08 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031694340028341504		[learning rate: 0.00024367]
	Learning Rate: 0.000243669
	LOSS [training: 0.031694340028341504 | validation: 0.021956982978824233]
	TIME [epoch: 9.07 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03625782292975703		[learning rate: 0.00024292]
	Learning Rate: 0.000242922
	LOSS [training: 0.03625782292975703 | validation: 0.02784341318427917]
	TIME [epoch: 9.06 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027185556437506992		[learning rate: 0.00024218]
	Learning Rate: 0.000242177
	LOSS [training: 0.027185556437506992 | validation: 0.04284080810472376]
	TIME [epoch: 9.06 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332406300066878		[learning rate: 0.00024143]
	Learning Rate: 0.000241435
	LOSS [training: 0.06332406300066878 | validation: 0.04255711760615756]
	TIME [epoch: 9.08 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04015486013205104		[learning rate: 0.00024069]
	Learning Rate: 0.000240695
	LOSS [training: 0.04015486013205104 | validation: 0.02883778817054579]
	TIME [epoch: 9.06 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029186950610710007		[learning rate: 0.00023996]
	Learning Rate: 0.000239957
	LOSS [training: 0.029186950610710007 | validation: 0.021156219140041052]
	TIME [epoch: 9.05 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0204618183381301		[learning rate: 0.00023922]
	Learning Rate: 0.000239221
	LOSS [training: 0.0204618183381301 | validation: 0.0312839505419011]
	TIME [epoch: 9.05 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03321139508538384		[learning rate: 0.00023849]
	Learning Rate: 0.000238488
	LOSS [training: 0.03321139508538384 | validation: 0.02975392754278241]
	TIME [epoch: 9.08 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028294943011435574		[learning rate: 0.00023776]
	Learning Rate: 0.000237757
	LOSS [training: 0.028294943011435574 | validation: 0.019847327379014075]
	TIME [epoch: 9.06 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03422538696626232		[learning rate: 0.00023703]
	Learning Rate: 0.000237028
	LOSS [training: 0.03422538696626232 | validation: 0.018669235928168267]
	TIME [epoch: 9.06 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0334147852270921		[learning rate: 0.0002363]
	Learning Rate: 0.000236302
	LOSS [training: 0.0334147852270921 | validation: 0.03186549489238793]
	TIME [epoch: 9.05 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045271736422381956		[learning rate: 0.00023558]
	Learning Rate: 0.000235577
	LOSS [training: 0.045271736422381956 | validation: 0.04241877212707258]
	TIME [epoch: 9.07 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035968837552516564		[learning rate: 0.00023486]
	Learning Rate: 0.000234855
	LOSS [training: 0.035968837552516564 | validation: 0.023457608867124728]
	TIME [epoch: 9.07 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027121087233614078		[learning rate: 0.00023414]
	Learning Rate: 0.000234135
	LOSS [training: 0.027121087233614078 | validation: 0.04999302914933643]
	TIME [epoch: 9.05 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031212188571577433		[learning rate: 0.00023342]
	Learning Rate: 0.000233417
	LOSS [training: 0.031212188571577433 | validation: 0.031739382602528586]
	TIME [epoch: 9.06 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035017617286081125		[learning rate: 0.0002327]
	Learning Rate: 0.000232702
	LOSS [training: 0.035017617286081125 | validation: 0.04158517148689866]
	TIME [epoch: 9.06 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0353021995681871		[learning rate: 0.00023199]
	Learning Rate: 0.000231989
	LOSS [training: 0.0353021995681871 | validation: 0.016762110365569575]
	TIME [epoch: 9.08 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03516947471063689		[learning rate: 0.00023128]
	Learning Rate: 0.000231277
	LOSS [training: 0.03516947471063689 | validation: 0.036926809364002805]
	TIME [epoch: 9.06 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03027986382165987		[learning rate: 0.00023057]
	Learning Rate: 0.000230569
	LOSS [training: 0.03027986382165987 | validation: 0.03507453158550776]
	TIME [epoch: 9.05 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03303491337684088		[learning rate: 0.00022986]
	Learning Rate: 0.000229862
	LOSS [training: 0.03303491337684088 | validation: 0.03170523200596763]
	TIME [epoch: 9.05 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0315405390482465		[learning rate: 0.00022916]
	Learning Rate: 0.000229157
	LOSS [training: 0.0315405390482465 | validation: 0.027000907556178858]
	TIME [epoch: 9.08 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03267251245679034		[learning rate: 0.00022845]
	Learning Rate: 0.000228455
	LOSS [training: 0.03267251245679034 | validation: 0.03479218863258193]
	TIME [epoch: 9.05 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042450740588250935		[learning rate: 0.00022775]
	Learning Rate: 0.000227754
	LOSS [training: 0.042450740588250935 | validation: 0.03147999079576921]
	TIME [epoch: 9.06 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04876860630110043		[learning rate: 0.00022706]
	Learning Rate: 0.000227056
	LOSS [training: 0.04876860630110043 | validation: 0.0395255177847053]
	TIME [epoch: 9.06 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0525775266094312		[learning rate: 0.00022636]
	Learning Rate: 0.00022636
	LOSS [training: 0.0525775266094312 | validation: 0.042090242673946635]
	TIME [epoch: 9.07 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03947299760641385		[learning rate: 0.00022567]
	Learning Rate: 0.000225666
	LOSS [training: 0.03947299760641385 | validation: 0.027215857188597405]
	TIME [epoch: 9.05 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0361949894739486		[learning rate: 0.00022497]
	Learning Rate: 0.000224974
	LOSS [training: 0.0361949894739486 | validation: 0.016717718818501214]
	TIME [epoch: 9.05 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030432133562552217		[learning rate: 0.00022428]
	Learning Rate: 0.000224285
	LOSS [training: 0.030432133562552217 | validation: 0.019786155611168824]
	TIME [epoch: 9.05 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02862445573593561		[learning rate: 0.0002236]
	Learning Rate: 0.000223597
	LOSS [training: 0.02862445573593561 | validation: 0.02751266810447166]
	TIME [epoch: 9.07 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02818315385603562		[learning rate: 0.00022291]
	Learning Rate: 0.000222912
	LOSS [training: 0.02818315385603562 | validation: 0.030075181558812836]
	TIME [epoch: 9.06 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036133184217086764		[learning rate: 0.00022223]
	Learning Rate: 0.000222229
	LOSS [training: 0.036133184217086764 | validation: 0.04425523678454615]
	TIME [epoch: 9.05 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05778426653225819		[learning rate: 0.00022155]
	Learning Rate: 0.000221547
	LOSS [training: 0.05778426653225819 | validation: 0.07753839565371803]
	TIME [epoch: 9.05 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056289770541551265		[learning rate: 0.00022087]
	Learning Rate: 0.000220868
	LOSS [training: 0.056289770541551265 | validation: 0.04405977130193562]
	TIME [epoch: 9.06 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035656774795822896		[learning rate: 0.00022019]
	Learning Rate: 0.000220191
	LOSS [training: 0.035656774795822896 | validation: 0.038763457465861205]
	TIME [epoch: 9.06 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0361480413320857		[learning rate: 0.00021952]
	Learning Rate: 0.000219516
	LOSS [training: 0.0361480413320857 | validation: 0.03618690681292173]
	TIME [epoch: 9.05 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036421205200049545		[learning rate: 0.00021884]
	Learning Rate: 0.000218843
	LOSS [training: 0.036421205200049545 | validation: 0.046427023623179575]
	TIME [epoch: 9.06 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049592381627746596		[learning rate: 0.00021817]
	Learning Rate: 0.000218172
	LOSS [training: 0.049592381627746596 | validation: 0.057657399703300104]
	TIME [epoch: 9.06 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0529978747532993		[learning rate: 0.0002175]
	Learning Rate: 0.000217504
	LOSS [training: 0.0529978747532993 | validation: 0.027584090131248247]
	TIME [epoch: 9.07 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03637521267333903		[learning rate: 0.00021684]
	Learning Rate: 0.000216837
	LOSS [training: 0.03637521267333903 | validation: 0.034087681380857604]
	TIME [epoch: 9.05 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03653966161771192		[learning rate: 0.00021617]
	Learning Rate: 0.000216172
	LOSS [training: 0.03653966161771192 | validation: 0.05041047149610607]
	TIME [epoch: 9.05 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03337124698904902		[learning rate: 0.00021551]
	Learning Rate: 0.00021551
	LOSS [training: 0.03337124698904902 | validation: 0.03295758419129269]
	TIME [epoch: 9.05 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03603059561459514		[learning rate: 0.00021485]
	Learning Rate: 0.000214849
	LOSS [training: 0.03603059561459514 | validation: 0.03808403554572808]
	TIME [epoch: 9.08 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03763446678600764		[learning rate: 0.00021419]
	Learning Rate: 0.00021419
	LOSS [training: 0.03763446678600764 | validation: 0.03845839408098636]
	TIME [epoch: 9.05 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04395312061670014		[learning rate: 0.00021353]
	Learning Rate: 0.000213534
	LOSS [training: 0.04395312061670014 | validation: 0.03576756803828692]
	TIME [epoch: 9.05 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03910259622602799		[learning rate: 0.00021288]
	Learning Rate: 0.000212879
	LOSS [training: 0.03910259622602799 | validation: 0.027805199379109715]
	TIME [epoch: 9.05 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03339134129356765		[learning rate: 0.00021223]
	Learning Rate: 0.000212227
	LOSS [training: 0.03339134129356765 | validation: 0.02869415264255723]
	TIME [epoch: 9.08 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03776019566619198		[learning rate: 0.00021158]
	Learning Rate: 0.000211576
	LOSS [training: 0.03776019566619198 | validation: 0.024425885422758052]
	TIME [epoch: 9.05 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04256263188632045		[learning rate: 0.00021093]
	Learning Rate: 0.000210928
	LOSS [training: 0.04256263188632045 | validation: 0.049018612484101415]
	TIME [epoch: 9.05 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04245921756264136		[learning rate: 0.00021028]
	Learning Rate: 0.000210281
	LOSS [training: 0.04245921756264136 | validation: 0.04807083693019573]
	TIME [epoch: 9.05 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04353223020347812		[learning rate: 0.00020964]
	Learning Rate: 0.000209636
	LOSS [training: 0.04353223020347812 | validation: 0.0404591294087209]
	TIME [epoch: 9.08 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031177073762098034		[learning rate: 0.00020899]
	Learning Rate: 0.000208994
	LOSS [training: 0.031177073762098034 | validation: 0.038343696518384915]
	TIME [epoch: 9.06 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04239149643505724		[learning rate: 0.00020835]
	Learning Rate: 0.000208353
	LOSS [training: 0.04239149643505724 | validation: 0.0656128338795191]
	TIME [epoch: 9.05 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05647508220658287		[learning rate: 0.00020771]
	Learning Rate: 0.000207714
	LOSS [training: 0.05647508220658287 | validation: 0.04683442182709642]
	TIME [epoch: 9.05 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034586783513579064		[learning rate: 0.00020708]
	Learning Rate: 0.000207078
	LOSS [training: 0.034586783513579064 | validation: 0.04012647926319941]
	TIME [epoch: 9.08 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04169413703897896		[learning rate: 0.00020644]
	Learning Rate: 0.000206443
	LOSS [training: 0.04169413703897896 | validation: 0.042821434593599536]
	TIME [epoch: 9.06 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048337288033719145		[learning rate: 0.00020581]
	Learning Rate: 0.00020581
	LOSS [training: 0.048337288033719145 | validation: 0.04020047520042094]
	TIME [epoch: 9.05 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054847376463678044		[learning rate: 0.00020518]
	Learning Rate: 0.000205179
	LOSS [training: 0.054847376463678044 | validation: 0.03980146069070493]
	TIME [epoch: 9.05 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04491470344708789		[learning rate: 0.00020455]
	Learning Rate: 0.00020455
	LOSS [training: 0.04491470344708789 | validation: 0.038660967366404814]
	TIME [epoch: 9.06 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03816072818997942		[learning rate: 0.00020392]
	Learning Rate: 0.000203923
	LOSS [training: 0.03816072818997942 | validation: 0.0644734066170343]
	TIME [epoch: 9.07 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043350677818058625		[learning rate: 0.0002033]
	Learning Rate: 0.000203298
	LOSS [training: 0.043350677818058625 | validation: 0.04109808780103346]
	TIME [epoch: 9.06 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03358670068174673		[learning rate: 0.00020267]
	Learning Rate: 0.000202675
	LOSS [training: 0.03358670068174673 | validation: 0.02391363925150693]
	TIME [epoch: 9.06 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03195068235567976		[learning rate: 0.00020205]
	Learning Rate: 0.000202054
	LOSS [training: 0.03195068235567976 | validation: 0.03950234357508746]
	TIME [epoch: 9.06 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03460078356473921		[learning rate: 0.00020143]
	Learning Rate: 0.000201434
	LOSS [training: 0.03460078356473921 | validation: 0.027042885942036632]
	TIME [epoch: 9.06 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03793565340915771		[learning rate: 0.00020082]
	Learning Rate: 0.000200817
	LOSS [training: 0.03793565340915771 | validation: 0.035637747860707676]
	TIME [epoch: 9.06 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02598851311187026		[learning rate: 0.0002002]
	Learning Rate: 0.000200201
	LOSS [training: 0.02598851311187026 | validation: 0.0339486605320314]
	TIME [epoch: 9.05 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03258851527001175		[learning rate: 0.00019959]
	Learning Rate: 0.000199588
	LOSS [training: 0.03258851527001175 | validation: 0.041486225865227135]
	TIME [epoch: 9.06 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044377123589760946		[learning rate: 0.00019898]
	Learning Rate: 0.000198976
	LOSS [training: 0.044377123589760946 | validation: 0.03778726571993549]
	TIME [epoch: 9.08 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03567401484644508		[learning rate: 0.00019837]
	Learning Rate: 0.000198366
	LOSS [training: 0.03567401484644508 | validation: 0.04534804722873036]
	TIME [epoch: 9.05 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0439457047984467		[learning rate: 0.00019776]
	Learning Rate: 0.000197758
	LOSS [training: 0.0439457047984467 | validation: 0.021166246392651057]
	TIME [epoch: 9.06 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02418693245335168		[learning rate: 0.00019715]
	Learning Rate: 0.000197151
	LOSS [training: 0.02418693245335168 | validation: 0.028804476253287692]
	TIME [epoch: 9.05 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03166317428088468		[learning rate: 0.00019655]
	Learning Rate: 0.000196547
	LOSS [training: 0.03166317428088468 | validation: 0.026214843937299635]
	TIME [epoch: 9.08 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026724854808441743		[learning rate: 0.00019594]
	Learning Rate: 0.000195945
	LOSS [training: 0.026724854808441743 | validation: 0.022692429742901414]
	TIME [epoch: 9.06 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021092670326514705		[learning rate: 0.00019534]
	Learning Rate: 0.000195344
	LOSS [training: 0.021092670326514705 | validation: 0.029071951321271584]
	TIME [epoch: 9.06 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026578094217751445		[learning rate: 0.00019475]
	Learning Rate: 0.000194745
	LOSS [training: 0.026578094217751445 | validation: 0.023119924468898913]
	TIME [epoch: 9.06 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025684325071020746		[learning rate: 0.00019415]
	Learning Rate: 0.000194148
	LOSS [training: 0.025684325071020746 | validation: 0.03353367109834199]
	TIME [epoch: 9.07 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02807515177578026		[learning rate: 0.00019355]
	Learning Rate: 0.000193553
	LOSS [training: 0.02807515177578026 | validation: 0.02455832410658817]
	TIME [epoch: 9.05 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03235380713974352		[learning rate: 0.00019296]
	Learning Rate: 0.00019296
	LOSS [training: 0.03235380713974352 | validation: 0.03260708860118855]
	TIME [epoch: 9.05 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03442121208955248		[learning rate: 0.00019237]
	Learning Rate: 0.000192368
	LOSS [training: 0.03442121208955248 | validation: 0.03672733318835787]
	TIME [epoch: 9.05 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030428680946288627		[learning rate: 0.00019178]
	Learning Rate: 0.000191778
	LOSS [training: 0.030428680946288627 | validation: 0.02567666184399585]
	TIME [epoch: 9.07 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024499503886992593		[learning rate: 0.00019119]
	Learning Rate: 0.000191191
	LOSS [training: 0.024499503886992593 | validation: 0.03716391277249412]
	TIME [epoch: 9.06 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03492317488686146		[learning rate: 0.0001906]
	Learning Rate: 0.000190605
	LOSS [training: 0.03492317488686146 | validation: 0.03298305651280695]
	TIME [epoch: 9.05 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04659730145590144		[learning rate: 0.00019002]
	Learning Rate: 0.00019002
	LOSS [training: 0.04659730145590144 | validation: 0.051040426111149576]
	TIME [epoch: 9.05 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04286912330554367		[learning rate: 0.00018944]
	Learning Rate: 0.000189438
	LOSS [training: 0.04286912330554367 | validation: 0.023536825597971555]
	TIME [epoch: 9.07 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026474358141092853		[learning rate: 0.00018886]
	Learning Rate: 0.000188857
	LOSS [training: 0.026474358141092853 | validation: 0.03338314904430323]
	TIME [epoch: 9.07 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023256971111147516		[learning rate: 0.00018828]
	Learning Rate: 0.000188278
	LOSS [training: 0.023256971111147516 | validation: 0.03071972053172201]
	TIME [epoch: 9.05 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02949483135029758		[learning rate: 0.0001877]
	Learning Rate: 0.000187701
	LOSS [training: 0.02949483135029758 | validation: 0.0216625015010236]
	TIME [epoch: 9.05 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027281894932112076		[learning rate: 0.00018713]
	Learning Rate: 0.000187126
	LOSS [training: 0.027281894932112076 | validation: 0.020338997452221064]
	TIME [epoch: 9.06 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024491880002448164		[learning rate: 0.00018655]
	Learning Rate: 0.000186552
	LOSS [training: 0.024491880002448164 | validation: 0.03782314426711167]
	TIME [epoch: 9.08 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030756808904709543		[learning rate: 0.00018598]
	Learning Rate: 0.00018598
	LOSS [training: 0.030756808904709543 | validation: 0.019269132737965943]
	TIME [epoch: 9.06 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03581176853685945		[learning rate: 0.00018541]
	Learning Rate: 0.00018541
	LOSS [training: 0.03581176853685945 | validation: 0.03985623960657805]
	TIME [epoch: 9.05 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0423261342307817		[learning rate: 0.00018484]
	Learning Rate: 0.000184842
	LOSS [training: 0.0423261342307817 | validation: 0.017550540066463]
	TIME [epoch: 9.05 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02571303063469807		[learning rate: 0.00018428]
	Learning Rate: 0.000184275
	LOSS [training: 0.02571303063469807 | validation: 0.019509443780495704]
	TIME [epoch: 9.08 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034927263234908607		[learning rate: 0.00018371]
	Learning Rate: 0.00018371
	LOSS [training: 0.034927263234908607 | validation: 0.036627122654484735]
	TIME [epoch: 9.06 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030850687212743155		[learning rate: 0.00018315]
	Learning Rate: 0.000183147
	LOSS [training: 0.030850687212743155 | validation: 0.023997775332184945]
	TIME [epoch: 9.05 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022847024843580414		[learning rate: 0.00018259]
	Learning Rate: 0.000182586
	LOSS [training: 0.022847024843580414 | validation: 0.01639145002937887]
	TIME [epoch: 9.05 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030131415892919938		[learning rate: 0.00018203]
	Learning Rate: 0.000182026
	LOSS [training: 0.030131415892919938 | validation: 0.018198568435829864]
	TIME [epoch: 9.07 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027099905799037916		[learning rate: 0.00018147]
	Learning Rate: 0.000181468
	LOSS [training: 0.027099905799037916 | validation: 0.027648256820907387]
	TIME [epoch: 9.06 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03167487479056465		[learning rate: 0.00018091]
	Learning Rate: 0.000180912
	LOSS [training: 0.03167487479056465 | validation: 0.04111126644537595]
	TIME [epoch: 9.05 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029188382298971315		[learning rate: 0.00018036]
	Learning Rate: 0.000180357
	LOSS [training: 0.029188382298971315 | validation: 0.03374827095762979]
	TIME [epoch: 9.05 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028289127032035184		[learning rate: 0.0001798]
	Learning Rate: 0.000179804
	LOSS [training: 0.028289127032035184 | validation: 0.02639741297059304]
	TIME [epoch: 9.08 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03036603231324932		[learning rate: 0.00017925]
	Learning Rate: 0.000179253
	LOSS [training: 0.03036603231324932 | validation: 0.03628561206797759]
	TIME [epoch: 9.06 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03408446384806805		[learning rate: 0.0001787]
	Learning Rate: 0.000178704
	LOSS [training: 0.03408446384806805 | validation: 0.03805350090139892]
	TIME [epoch: 9.05 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04042202364497755		[learning rate: 0.00017816]
	Learning Rate: 0.000178156
	LOSS [training: 0.04042202364497755 | validation: 0.04614588516046066]
	TIME [epoch: 9.05 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03964198567817601		[learning rate: 0.00017761]
	Learning Rate: 0.00017761
	LOSS [training: 0.03964198567817601 | validation: 0.02638887309893329]
	TIME [epoch: 9.06 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03289203023885271		[learning rate: 0.00017707]
	Learning Rate: 0.000177065
	LOSS [training: 0.03289203023885271 | validation: 0.030771404492841395]
	TIME [epoch: 9.06 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028643245620140305		[learning rate: 0.00017652]
	Learning Rate: 0.000176522
	LOSS [training: 0.028643245620140305 | validation: 0.020639353104234856]
	TIME [epoch: 9.05 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027478703592978666		[learning rate: 0.00017598]
	Learning Rate: 0.000175981
	LOSS [training: 0.027478703592978666 | validation: 0.02236469617584883]
	TIME [epoch: 9.06 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026299320394550796		[learning rate: 0.00017544]
	Learning Rate: 0.000175442
	LOSS [training: 0.026299320394550796 | validation: 0.02104911470047288]
	TIME [epoch: 9.06 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023723354789477465		[learning rate: 0.0001749]
	Learning Rate: 0.000174904
	LOSS [training: 0.023723354789477465 | validation: 0.017552691978029156]
	TIME [epoch: 9.07 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032219574747853155		[learning rate: 0.00017437]
	Learning Rate: 0.000174368
	LOSS [training: 0.032219574747853155 | validation: 0.03432488536069271]
	TIME [epoch: 9.06 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030024516081714796		[learning rate: 0.00017383]
	Learning Rate: 0.000173833
	LOSS [training: 0.030024516081714796 | validation: 0.01992321610613225]
	TIME [epoch: 9.05 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022793086637600667		[learning rate: 0.0001733]
	Learning Rate: 0.000173301
	LOSS [training: 0.022793086637600667 | validation: 0.023095720396835075]
	TIME [epoch: 9.05 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027088055787578995		[learning rate: 0.00017277]
	Learning Rate: 0.000172769
	LOSS [training: 0.027088055787578995 | validation: 0.027394612455831184]
	TIME [epoch: 9.08 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027642587641385923		[learning rate: 0.00017224]
	Learning Rate: 0.00017224
	LOSS [training: 0.027642587641385923 | validation: 0.023292078371034648]
	TIME [epoch: 9.05 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026084477276851613		[learning rate: 0.00017171]
	Learning Rate: 0.000171712
	LOSS [training: 0.026084477276851613 | validation: 0.017709065083439862]
	TIME [epoch: 9.05 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03078401404538485		[learning rate: 0.00017119]
	Learning Rate: 0.000171185
	LOSS [training: 0.03078401404538485 | validation: 0.032045335426306575]
	TIME [epoch: 9.05 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029815657071974117		[learning rate: 0.00017066]
	Learning Rate: 0.000170661
	LOSS [training: 0.029815657071974117 | validation: 0.02434986041033315]
	TIME [epoch: 9.07 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024516630066155825		[learning rate: 0.00017014]
	Learning Rate: 0.000170137
	LOSS [training: 0.024516630066155825 | validation: 0.0276488990904813]
	TIME [epoch: 9.06 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02349394916478293		[learning rate: 0.00016962]
	Learning Rate: 0.000169616
	LOSS [training: 0.02349394916478293 | validation: 0.03151734849163004]
	TIME [epoch: 9.05 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028860584274365136		[learning rate: 0.0001691]
	Learning Rate: 0.000169096
	LOSS [training: 0.028860584274365136 | validation: 0.03619877368150781]
	TIME [epoch: 9.05 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045384030649954714		[learning rate: 0.00016858]
	Learning Rate: 0.000168578
	LOSS [training: 0.045384030649954714 | validation: 0.028248277477506356]
	TIME [epoch: 9.07 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028559702701855365		[learning rate: 0.00016806]
	Learning Rate: 0.000168061
	LOSS [training: 0.028559702701855365 | validation: 0.025544670748528037]
	TIME [epoch: 9.06 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02705127539631009		[learning rate: 0.00016755]
	Learning Rate: 0.000167546
	LOSS [training: 0.02705127539631009 | validation: 0.0235576293667983]
	TIME [epoch: 9.05 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03550556509673565		[learning rate: 0.00016703]
	Learning Rate: 0.000167032
	LOSS [training: 0.03550556509673565 | validation: 0.02483280218474236]
	TIME [epoch: 9.05 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04029250656168258		[learning rate: 0.00016652]
	Learning Rate: 0.00016652
	LOSS [training: 0.04029250656168258 | validation: 0.02430748638340193]
	TIME [epoch: 9.07 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03214621778490014		[learning rate: 0.00016601]
	Learning Rate: 0.00016601
	LOSS [training: 0.03214621778490014 | validation: 0.02666318520945179]
	TIME [epoch: 9.06 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0390190093008629		[learning rate: 0.0001655]
	Learning Rate: 0.000165501
	LOSS [training: 0.0390190093008629 | validation: 0.036025770913268376]
	TIME [epoch: 9.05 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030956255969632186		[learning rate: 0.00016499]
	Learning Rate: 0.000164993
	LOSS [training: 0.030956255969632186 | validation: 0.029351601790884797]
	TIME [epoch: 9.05 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03481322167632614		[learning rate: 0.00016449]
	Learning Rate: 0.000164488
	LOSS [training: 0.03481322167632614 | validation: 0.025145910092870694]
	TIME [epoch: 9.06 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025884922411667115		[learning rate: 0.00016398]
	Learning Rate: 0.000163983
	LOSS [training: 0.025884922411667115 | validation: 0.027093210093339145]
	TIME [epoch: 9.07 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035141640711741244		[learning rate: 0.00016348]
	Learning Rate: 0.000163481
	LOSS [training: 0.035141640711741244 | validation: 0.03800559941551869]
	TIME [epoch: 9.06 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03652437720957417		[learning rate: 0.00016298]
	Learning Rate: 0.00016298
	LOSS [training: 0.03652437720957417 | validation: 0.021240525355547202]
	TIME [epoch: 9.05 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02985202843549269		[learning rate: 0.00016248]
	Learning Rate: 0.00016248
	LOSS [training: 0.02985202843549269 | validation: 0.020293967992567757]
	TIME [epoch: 9.06 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030776014656621255		[learning rate: 0.00016198]
	Learning Rate: 0.000161982
	LOSS [training: 0.030776014656621255 | validation: 0.022822997329949128]
	TIME [epoch: 9.07 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023002524377239878		[learning rate: 0.00016149]
	Learning Rate: 0.000161485
	LOSS [training: 0.023002524377239878 | validation: 0.020008726691329748]
	TIME [epoch: 9.06 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030861761154641187		[learning rate: 0.00016099]
	Learning Rate: 0.00016099
	LOSS [training: 0.030861761154641187 | validation: 0.02066522828562157]
	TIME [epoch: 9.06 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029226735070232084		[learning rate: 0.0001605]
	Learning Rate: 0.000160497
	LOSS [training: 0.029226735070232084 | validation: 0.03492740913285077]
	TIME [epoch: 9.05 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039749165851320406		[learning rate: 0.00016]
	Learning Rate: 0.000160005
	LOSS [training: 0.039749165851320406 | validation: 0.02656997121884775]
	TIME [epoch: 9.08 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030090642996968196		[learning rate: 0.00015951]
	Learning Rate: 0.000159514
	LOSS [training: 0.030090642996968196 | validation: 0.0354910447721451]
	TIME [epoch: 9.05 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04077924535390354		[learning rate: 0.00015903]
	Learning Rate: 0.000159025
	LOSS [training: 0.04077924535390354 | validation: 0.040709178520057725]
	TIME [epoch: 9.06 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04017704238569214		[learning rate: 0.00015854]
	Learning Rate: 0.000158538
	LOSS [training: 0.04017704238569214 | validation: 0.031656055081651695]
	TIME [epoch: 9.05 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03503164811578588		[learning rate: 0.00015805]
	Learning Rate: 0.000158052
	LOSS [training: 0.03503164811578588 | validation: 0.036672214631572816]
	TIME [epoch: 9.08 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024571549637545077		[learning rate: 0.00015757]
	Learning Rate: 0.000157567
	LOSS [training: 0.024571549637545077 | validation: 0.027693429816376965]
	TIME [epoch: 9.05 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028112245614165948		[learning rate: 0.00015708]
	Learning Rate: 0.000157084
	LOSS [training: 0.028112245614165948 | validation: 0.021600418064867923]
	TIME [epoch: 9.06 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024488245778391784		[learning rate: 0.0001566]
	Learning Rate: 0.000156603
	LOSS [training: 0.024488245778391784 | validation: 0.017857817107105284]
	TIME [epoch: 9.06 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025715220886496953		[learning rate: 0.00015612]
	Learning Rate: 0.000156123
	LOSS [training: 0.025715220886496953 | validation: 0.02051132142390634]
	TIME [epoch: 9.08 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02639159597929013		[learning rate: 0.00015564]
	Learning Rate: 0.000155644
	LOSS [training: 0.02639159597929013 | validation: 0.014658525096231468]
	TIME [epoch: 9.06 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018463403620780156		[learning rate: 0.00015517]
	Learning Rate: 0.000155167
	LOSS [training: 0.018463403620780156 | validation: 0.02017515364321499]
	TIME [epoch: 9.05 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025765625446077196		[learning rate: 0.00015469]
	Learning Rate: 0.000154692
	LOSS [training: 0.025765625446077196 | validation: 0.03067144685387744]
	TIME [epoch: 9.05 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027486884743699886		[learning rate: 0.00015422]
	Learning Rate: 0.000154217
	LOSS [training: 0.027486884743699886 | validation: 0.02445452075639263]
	TIME [epoch: 9.08 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02922134989847904		[learning rate: 0.00015374]
	Learning Rate: 0.000153745
	LOSS [training: 0.02922134989847904 | validation: 0.03101499427721311]
	TIME [epoch: 9.06 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03365781520174008		[learning rate: 0.00015327]
	Learning Rate: 0.000153273
	LOSS [training: 0.03365781520174008 | validation: 0.036884508426926685]
	TIME [epoch: 9.06 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027879205264419338		[learning rate: 0.0001528]
	Learning Rate: 0.000152803
	LOSS [training: 0.027879205264419338 | validation: 0.018860607086745407]
	TIME [epoch: 9.06 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038690434607693155		[learning rate: 0.00015234]
	Learning Rate: 0.000152335
	LOSS [training: 0.038690434607693155 | validation: 0.03063816342120082]
	TIME [epoch: 9.07 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03592237680605262		[learning rate: 0.00015187]
	Learning Rate: 0.000151868
	LOSS [training: 0.03592237680605262 | validation: 0.042602773165055785]
	TIME [epoch: 9.07 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0345571666879108		[learning rate: 0.0001514]
	Learning Rate: 0.000151403
	LOSS [training: 0.0345571666879108 | validation: 0.026758595658380138]
	TIME [epoch: 9.05 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0258751423927771		[learning rate: 0.00015094]
	Learning Rate: 0.000150938
	LOSS [training: 0.0258751423927771 | validation: 0.021062789560779897]
	TIME [epoch: 9.06 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025344382022203		[learning rate: 0.00015048]
	Learning Rate: 0.000150476
	LOSS [training: 0.025344382022203 | validation: 0.0141178984481788]
	TIME [epoch: 9.08 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022343257261983822		[learning rate: 0.00015001]
	Learning Rate: 0.000150015
	LOSS [training: 0.022343257261983822 | validation: 0.016755098147792108]
	TIME [epoch: 9.07 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03029125335319776		[learning rate: 0.00014955]
	Learning Rate: 0.000149555
	LOSS [training: 0.03029125335319776 | validation: 0.027180643071192983]
	TIME [epoch: 9.06 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02215306098400337		[learning rate: 0.0001491]
	Learning Rate: 0.000149096
	LOSS [training: 0.02215306098400337 | validation: 0.023632466882538283]
	TIME [epoch: 9.05 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03584135099938352		[learning rate: 0.00014864]
	Learning Rate: 0.000148639
	LOSS [training: 0.03584135099938352 | validation: 0.03033666863142775]
	TIME [epoch: 9.05 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03795608002044605		[learning rate: 0.00014818]
	Learning Rate: 0.000148184
	LOSS [training: 0.03795608002044605 | validation: 0.035832131216676354]
	TIME [epoch: 9.08 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02880706629120556		[learning rate: 0.00014773]
	Learning Rate: 0.000147729
	LOSS [training: 0.02880706629120556 | validation: 0.01910905744104155]
	TIME [epoch: 9.05 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024021703185455722		[learning rate: 0.00014728]
	Learning Rate: 0.000147276
	LOSS [training: 0.024021703185455722 | validation: 0.027483997545893413]
	TIME [epoch: 9.06 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025805800490324306		[learning rate: 0.00014682]
	Learning Rate: 0.000146825
	LOSS [training: 0.025805800490324306 | validation: 0.020944966256239865]
	TIME [epoch: 9.05 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022610961786070746		[learning rate: 0.00014637]
	Learning Rate: 0.000146375
	LOSS [training: 0.022610961786070746 | validation: 0.013707379356307]
	TIME [epoch: 9.08 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026536876982227058		[learning rate: 0.00014593]
	Learning Rate: 0.000145926
	LOSS [training: 0.026536876982227058 | validation: 0.013449417425894521]
	TIME [epoch: 9.06 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02045745491962159		[learning rate: 0.00014548]
	Learning Rate: 0.000145479
	LOSS [training: 0.02045745491962159 | validation: 0.024321741128887672]
	TIME [epoch: 9.05 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02637375959564701		[learning rate: 0.00014503]
	Learning Rate: 0.000145033
	LOSS [training: 0.02637375959564701 | validation: 0.02066324690005307]
	TIME [epoch: 9.06 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022705791542869412		[learning rate: 0.00014459]
	Learning Rate: 0.000144588
	LOSS [training: 0.022705791542869412 | validation: 0.013395756499356778]
	TIME [epoch: 9.07 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021975639419378017		[learning rate: 0.00014415]
	Learning Rate: 0.000144145
	LOSS [training: 0.021975639419378017 | validation: 0.022968786277980043]
	TIME [epoch: 9.06 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021916178019870478		[learning rate: 0.0001437]
	Learning Rate: 0.000143703
	LOSS [training: 0.021916178019870478 | validation: 0.021714644755560994]
	TIME [epoch: 9.06 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030324059567416205		[learning rate: 0.00014326]
	Learning Rate: 0.000143263
	LOSS [training: 0.030324059567416205 | validation: 0.03211069056840033]
	TIME [epoch: 9.05 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03150024922454405		[learning rate: 0.00014282]
	Learning Rate: 0.000142824
	LOSS [training: 0.03150024922454405 | validation: 0.024236753426120985]
	TIME [epoch: 9.07 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023410370031348993		[learning rate: 0.00014239]
	Learning Rate: 0.000142386
	LOSS [training: 0.023410370031348993 | validation: 0.025629423416233373]
	TIME [epoch: 9.06 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02481444622659094		[learning rate: 0.00014195]
	Learning Rate: 0.000141949
	LOSS [training: 0.02481444622659094 | validation: 0.024926127217795357]
	TIME [epoch: 9.05 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024330708453258774		[learning rate: 0.00014151]
	Learning Rate: 0.000141514
	LOSS [training: 0.024330708453258774 | validation: 0.023875893594367596]
	TIME [epoch: 9.05 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02284575895831093		[learning rate: 0.00014108]
	Learning Rate: 0.00014108
	LOSS [training: 0.02284575895831093 | validation: 0.021943485352866582]
	TIME [epoch: 9.07 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025323420597132808		[learning rate: 0.00014065]
	Learning Rate: 0.000140648
	LOSS [training: 0.025323420597132808 | validation: 0.03316527985612268]
	TIME [epoch: 9.06 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03643340446371768		[learning rate: 0.00014022]
	Learning Rate: 0.000140217
	LOSS [training: 0.03643340446371768 | validation: 0.035779131258836444]
	TIME [epoch: 9.06 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0349094765355027		[learning rate: 0.00013979]
	Learning Rate: 0.000139787
	LOSS [training: 0.0349094765355027 | validation: 0.015380986549409968]
	TIME [epoch: 9.06 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024908565473383916		[learning rate: 0.00013936]
	Learning Rate: 0.000139358
	LOSS [training: 0.024908565473383916 | validation: 0.04147381707968395]
	TIME [epoch: 9.06 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0325560102019333		[learning rate: 0.00013893]
	Learning Rate: 0.000138931
	LOSS [training: 0.0325560102019333 | validation: 0.02979472659059148]
	TIME [epoch: 9.07 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019261973763014528		[learning rate: 0.00013851]
	Learning Rate: 0.000138505
	LOSS [training: 0.019261973763014528 | validation: 0.030366167384779527]
	TIME [epoch: 9.06 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01985657755777593		[learning rate: 0.00013808]
	Learning Rate: 0.000138081
	LOSS [training: 0.01985657755777593 | validation: 0.02973834807213556]
	TIME [epoch: 9.06 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02428511175838562		[learning rate: 0.00013766]
	Learning Rate: 0.000137658
	LOSS [training: 0.02428511175838562 | validation: 0.019623640291985867]
	TIME [epoch: 9.05 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0186188439185152		[learning rate: 0.00013724]
	Learning Rate: 0.000137236
	LOSS [training: 0.0186188439185152 | validation: 0.017170393718300134]
	TIME [epoch: 9.08 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023076382509874305		[learning rate: 0.00013681]
	Learning Rate: 0.000136815
	LOSS [training: 0.023076382509874305 | validation: 0.0189884794076601]
	TIME [epoch: 9.05 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02844076077215646		[learning rate: 0.0001364]
	Learning Rate: 0.000136395
	LOSS [training: 0.02844076077215646 | validation: 0.02272518514604574]
	TIME [epoch: 9.06 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027569115856061078		[learning rate: 0.00013598]
	Learning Rate: 0.000135977
	LOSS [training: 0.027569115856061078 | validation: 0.03582310647009755]
	TIME [epoch: 9.06 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028715465123910322		[learning rate: 0.00013556]
	Learning Rate: 0.000135561
	LOSS [training: 0.028715465123910322 | validation: 0.02760513673867096]
	TIME [epoch: 9.07 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024796489939709072		[learning rate: 0.00013515]
	Learning Rate: 0.000135145
	LOSS [training: 0.024796489939709072 | validation: 0.015488877015994551]
	TIME [epoch: 9.06 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02656624941436057		[learning rate: 0.00013473]
	Learning Rate: 0.000134731
	LOSS [training: 0.02656624941436057 | validation: 0.015506304294669981]
	TIME [epoch: 9.05 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01950693229734398		[learning rate: 0.00013432]
	Learning Rate: 0.000134318
	LOSS [training: 0.01950693229734398 | validation: 0.020962351024474156]
	TIME [epoch: 9.05 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020859660392655993		[learning rate: 0.00013391]
	Learning Rate: 0.000133906
	LOSS [training: 0.020859660392655993 | validation: 0.032726316488596065]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026205869824022822		[learning rate: 0.0001335]
	Learning Rate: 0.000133496
	LOSS [training: 0.026205869824022822 | validation: 0.02561538924572096]
	TIME [epoch: 9.06 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026496646918576484		[learning rate: 0.00013309]
	Learning Rate: 0.000133086
	LOSS [training: 0.026496646918576484 | validation: 0.032024616348803506]
	TIME [epoch: 9.05 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02802384214316795		[learning rate: 0.00013268]
	Learning Rate: 0.000132678
	LOSS [training: 0.02802384214316795 | validation: 0.017698082439980403]
	TIME [epoch: 9.05 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0211809525349174		[learning rate: 0.00013227]
	Learning Rate: 0.000132272
	LOSS [training: 0.0211809525349174 | validation: 0.008859538763770682]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240216_221934/states/model_tr_study3_1909.pth
	Model improved!!!
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028309610743670933		[learning rate: 0.00013187]
	Learning Rate: 0.000131866
	LOSS [training: 0.028309610743670933 | validation: 0.024844442183336504]
	TIME [epoch: 9.07 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024515284648592033		[learning rate: 0.00013146]
	Learning Rate: 0.000131462
	LOSS [training: 0.024515284648592033 | validation: 0.02664688088390542]
	TIME [epoch: 9.05 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024742351822819288		[learning rate: 0.00013106]
	Learning Rate: 0.000131059
	LOSS [training: 0.024742351822819288 | validation: 0.01788810463274326]
	TIME [epoch: 9.05 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02520834093114842		[learning rate: 0.00013066]
	Learning Rate: 0.000130657
	LOSS [training: 0.02520834093114842 | validation: 0.01805748496608591]
	TIME [epoch: 9.05 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030852096564828263		[learning rate: 0.00013026]
	Learning Rate: 0.000130257
	LOSS [training: 0.030852096564828263 | validation: 0.036547403789129886]
	TIME [epoch: 9.06 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033221081420412926		[learning rate: 0.00012986]
	Learning Rate: 0.000129857
	LOSS [training: 0.033221081420412926 | validation: 0.02581068676945838]
	TIME [epoch: 9.05 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03855223131861328		[learning rate: 0.00012946]
	Learning Rate: 0.000129459
	LOSS [training: 0.03855223131861328 | validation: 0.023685319731223564]
	TIME [epoch: 9.05 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024297673267656677		[learning rate: 0.00012906]
	Learning Rate: 0.000129062
	LOSS [training: 0.024297673267656677 | validation: 0.02178699025048715]
	TIME [epoch: 9.05 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024419581902454496		[learning rate: 0.00012867]
	Learning Rate: 0.000128667
	LOSS [training: 0.024419581902454496 | validation: 0.02583027394837429]
	TIME [epoch: 9.06 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022568285868341094		[learning rate: 0.00012827]
	Learning Rate: 0.000128272
	LOSS [training: 0.022568285868341094 | validation: 0.030882091474439613]
	TIME [epoch: 9.05 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02373832033102143		[learning rate: 0.00012788]
	Learning Rate: 0.000127879
	LOSS [training: 0.02373832033102143 | validation: 0.025366638025618865]
	TIME [epoch: 9.05 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024597305155961844		[learning rate: 0.00012749]
	Learning Rate: 0.000127487
	LOSS [training: 0.024597305155961844 | validation: 0.01802969010841318]
	TIME [epoch: 9.05 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021201818474791433		[learning rate: 0.0001271]
	Learning Rate: 0.000127096
	LOSS [training: 0.021201818474791433 | validation: 0.023621411595590766]
	TIME [epoch: 9.07 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026451214713236672		[learning rate: 0.00012671]
	Learning Rate: 0.000126707
	LOSS [training: 0.026451214713236672 | validation: 0.02366510993031852]
	TIME [epoch: 9.05 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02315049544985233		[learning rate: 0.00012632]
	Learning Rate: 0.000126318
	LOSS [training: 0.02315049544985233 | validation: 0.03170311919312091]
	TIME [epoch: 9.04 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02715841232917405		[learning rate: 0.00012593]
	Learning Rate: 0.000125931
	LOSS [training: 0.02715841232917405 | validation: 0.028983389787291387]
	TIME [epoch: 9.05 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02618845081700011		[learning rate: 0.00012555]
	Learning Rate: 0.000125545
	LOSS [training: 0.02618845081700011 | validation: 0.009101991611023558]
	TIME [epoch: 9.07 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02454077268645629		[learning rate: 0.00012516]
	Learning Rate: 0.00012516
	LOSS [training: 0.02454077268645629 | validation: 0.03259806858165118]
	TIME [epoch: 9.05 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02365714408249226		[learning rate: 0.00012478]
	Learning Rate: 0.000124777
	LOSS [training: 0.02365714408249226 | validation: 0.03202298174968066]
	TIME [epoch: 9.06 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03213308409609701		[learning rate: 0.00012439]
	Learning Rate: 0.000124394
	LOSS [training: 0.03213308409609701 | validation: 0.027533913000137696]
	TIME [epoch: 9.04 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02182271058037898		[learning rate: 0.00012401]
	Learning Rate: 0.000124013
	LOSS [training: 0.02182271058037898 | validation: 0.028713323653880553]
	TIME [epoch: 9.06 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020474603318620947		[learning rate: 0.00012363]
	Learning Rate: 0.000123633
	LOSS [training: 0.020474603318620947 | validation: 0.022219792954844393]
	TIME [epoch: 9.05 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02190079224523039		[learning rate: 0.00012325]
	Learning Rate: 0.000123254
	LOSS [training: 0.02190079224523039 | validation: 0.03006788201564311]
	TIME [epoch: 9.05 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03160765437112852		[learning rate: 0.00012288]
	Learning Rate: 0.000122876
	LOSS [training: 0.03160765437112852 | validation: 0.016879952856677108]
	TIME [epoch: 9.05 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024430590034918175		[learning rate: 0.0001225]
	Learning Rate: 0.000122499
	LOSS [training: 0.024430590034918175 | validation: 0.016140784983753667]
	TIME [epoch: 9.06 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023827092273692983		[learning rate: 0.00012212]
	Learning Rate: 0.000122124
	LOSS [training: 0.023827092273692983 | validation: 0.02430926315425083]
	TIME [epoch: 9.06 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027871380954249642		[learning rate: 0.00012175]
	Learning Rate: 0.000121749
	LOSS [training: 0.027871380954249642 | validation: 0.02309158976183997]
	TIME [epoch: 9.05 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0238685813990867		[learning rate: 0.00012138]
	Learning Rate: 0.000121376
	LOSS [training: 0.0238685813990867 | validation: 0.028864080157100017]
	TIME [epoch: 9.05 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019902511439055318		[learning rate: 0.000121]
	Learning Rate: 0.000121004
	LOSS [training: 0.019902511439055318 | validation: 0.023376872118393087]
	TIME [epoch: 9.06 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023175165497579236		[learning rate: 0.00012063]
	Learning Rate: 0.000120633
	LOSS [training: 0.023175165497579236 | validation: 0.031656430691991304]
	TIME [epoch: 9.06 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0257062477545695		[learning rate: 0.00012026]
	Learning Rate: 0.000120263
	LOSS [training: 0.0257062477545695 | validation: 0.018822209936818393]
	TIME [epoch: 9.04 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016819252048671594		[learning rate: 0.00011989]
	Learning Rate: 0.000119895
	LOSS [training: 0.016819252048671594 | validation: 0.02571055643187336]
	TIME [epoch: 9.05 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026262552635326213		[learning rate: 0.00011953]
	Learning Rate: 0.000119527
	LOSS [training: 0.026262552635326213 | validation: 0.022796199256157966]
	TIME [epoch: 9.04 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02713990306359131		[learning rate: 0.00011916]
	Learning Rate: 0.000119161
	LOSS [training: 0.02713990306359131 | validation: 0.030347946403145993]
	TIME [epoch: 9.07 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028449020583388718		[learning rate: 0.0001188]
	Learning Rate: 0.000118795
	LOSS [training: 0.028449020583388718 | validation: 0.019330465702256664]
	TIME [epoch: 9.04 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024864814180635762		[learning rate: 0.00011843]
	Learning Rate: 0.000118431
	LOSS [training: 0.024864814180635762 | validation: 0.023489922669699754]
	TIME [epoch: 9.04 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019633972579785015		[learning rate: 0.00011807]
	Learning Rate: 0.000118068
	LOSS [training: 0.019633972579785015 | validation: 0.02023518840675735]
	TIME [epoch: 9.04 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02442384675243082		[learning rate: 0.00011771]
	Learning Rate: 0.000117706
	LOSS [training: 0.02442384675243082 | validation: 0.02499981765862326]
	TIME [epoch: 9.07 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022839361899038048		[learning rate: 0.00011735]
	Learning Rate: 0.000117346
	LOSS [training: 0.022839361899038048 | validation: 0.026834346941732003]
	TIME [epoch: 9.04 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022077073370460266		[learning rate: 0.00011699]
	Learning Rate: 0.000116986
	LOSS [training: 0.022077073370460266 | validation: 0.02165878485691848]
	TIME [epoch: 9.04 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01630567643444113		[learning rate: 0.00011663]
	Learning Rate: 0.000116627
	LOSS [training: 0.01630567643444113 | validation: 0.01824480435712448]
	TIME [epoch: 9.04 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0230867687607627		[learning rate: 0.00011627]
	Learning Rate: 0.00011627
	LOSS [training: 0.0230867687607627 | validation: 0.0313121800860198]
	TIME [epoch: 9.06 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033017420558805285		[learning rate: 0.00011591]
	Learning Rate: 0.000115913
	LOSS [training: 0.033017420558805285 | validation: 0.02091279524362561]
	TIME [epoch: 9.04 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020897939517809806		[learning rate: 0.00011556]
	Learning Rate: 0.000115558
	LOSS [training: 0.020897939517809806 | validation: 0.027135180482904225]
	TIME [epoch: 9.04 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02720423352336545		[learning rate: 0.0001152]
	Learning Rate: 0.000115204
	LOSS [training: 0.02720423352336545 | validation: 0.02196095550958207]
	TIME [epoch: 9.04 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028908146927420126		[learning rate: 0.00011485]
	Learning Rate: 0.000114851
	LOSS [training: 0.028908146927420126 | validation: 0.025995409432132154]
	TIME [epoch: 9.06 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0282626707489582		[learning rate: 0.0001145]
	Learning Rate: 0.000114499
	LOSS [training: 0.0282626707489582 | validation: 0.030604514962948318]
	TIME [epoch: 9.05 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02052931360847416		[learning rate: 0.00011415]
	Learning Rate: 0.000114148
	LOSS [training: 0.02052931360847416 | validation: 0.026805160358057488]
	TIME [epoch: 9.04 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031056589964130427		[learning rate: 0.0001138]
	Learning Rate: 0.000113798
	LOSS [training: 0.031056589964130427 | validation: 0.02466928458318622]
	TIME [epoch: 9.04 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021559957144778853		[learning rate: 0.00011345]
	Learning Rate: 0.000113449
	LOSS [training: 0.021559957144778853 | validation: 0.02309818855044774]
	TIME [epoch: 9.05 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03444219247211029		[learning rate: 0.0001131]
	Learning Rate: 0.000113101
	LOSS [training: 0.03444219247211029 | validation: 0.03987473950851697]
	TIME [epoch: 9.06 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030462234165086914		[learning rate: 0.00011275]
	Learning Rate: 0.000112754
	LOSS [training: 0.030462234165086914 | validation: 0.028566792937624083]
	TIME [epoch: 9.05 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027706121793220757		[learning rate: 0.00011241]
	Learning Rate: 0.000112409
	LOSS [training: 0.027706121793220757 | validation: 0.04006058671149504]
	TIME [epoch: 9.04 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031598017481362026		[learning rate: 0.00011206]
	Learning Rate: 0.000112064
	LOSS [training: 0.031598017481362026 | validation: 0.026018387260957607]
	TIME [epoch: 9.04 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021356006007051738		[learning rate: 0.00011172]
	Learning Rate: 0.000111721
	LOSS [training: 0.021356006007051738 | validation: 0.01607443073566593]
	TIME [epoch: 9.06 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028708127529378617		[learning rate: 0.00011138]
	Learning Rate: 0.000111378
	LOSS [training: 0.028708127529378617 | validation: 0.03940728240106559]
	TIME [epoch: 9.04 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033903473654072654		[learning rate: 0.00011104]
	Learning Rate: 0.000111037
	LOSS [training: 0.033903473654072654 | validation: 0.013542490660649581]
	TIME [epoch: 9.06 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022986998130797923		[learning rate: 0.0001107]
	Learning Rate: 0.000110696
	LOSS [training: 0.022986998130797923 | validation: 0.02812297963838626]
	TIME [epoch: 9.04 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030272701008347176		[learning rate: 0.00011036]
	Learning Rate: 0.000110357
	LOSS [training: 0.030272701008347176 | validation: 0.03421251028217633]
	TIME [epoch: 9.06 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031318285653642336		[learning rate: 0.00011002]
	Learning Rate: 0.000110019
	LOSS [training: 0.031318285653642336 | validation: 0.02766637598481419]
	TIME [epoch: 9.04 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027634375345163747		[learning rate: 0.00010968]
	Learning Rate: 0.000109681
	LOSS [training: 0.027634375345163747 | validation: 0.03465716627558233]
	TIME [epoch: 9.04 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029355640763152568		[learning rate: 0.00010935]
	Learning Rate: 0.000109345
	LOSS [training: 0.029355640763152568 | validation: 0.029103448656426868]
	TIME [epoch: 9.04 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02302961072167983		[learning rate: 0.00010901]
	Learning Rate: 0.00010901
	LOSS [training: 0.02302961072167983 | validation: 0.0216106565005462]
	TIME [epoch: 9.06 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029973177813336787		[learning rate: 0.00010868]
	Learning Rate: 0.000108676
	LOSS [training: 0.029973177813336787 | validation: 0.02427143999731536]
	TIME [epoch: 9.05 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02645175423217568		[learning rate: 0.00010834]
	Learning Rate: 0.000108343
	LOSS [training: 0.02645175423217568 | validation: 0.021083586276949826]
	TIME [epoch: 9.04 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025490907810666423		[learning rate: 0.00010801]
	Learning Rate: 0.000108011
	LOSS [training: 0.025490907810666423 | validation: 0.01991559342376804]
	TIME [epoch: 9.04 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029101233859015047		[learning rate: 0.00010768]
	Learning Rate: 0.00010768
	LOSS [training: 0.029101233859015047 | validation: 0.020865900907578838]
	TIME [epoch: 9.06 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028206442245533092		[learning rate: 0.00010735]
	Learning Rate: 0.000107349
	LOSS [training: 0.028206442245533092 | validation: 0.02155863205144311]
	TIME [epoch: 9.04 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03190581342964779		[learning rate: 0.00010702]
	Learning Rate: 0.00010702
	LOSS [training: 0.03190581342964779 | validation: 0.02822530725765028]
	TIME [epoch: 9.04 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02033744570992193		[learning rate: 0.00010669]
	Learning Rate: 0.000106692
	LOSS [training: 0.02033744570992193 | validation: 0.014916475669582457]
	TIME [epoch: 9.04 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026977877025511566		[learning rate: 0.00010637]
	Learning Rate: 0.000106365
	LOSS [training: 0.026977877025511566 | validation: 0.020357395581860144]
	TIME [epoch: 9.05 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024465886435219377		[learning rate: 0.00010604]
	Learning Rate: 0.000106039
	LOSS [training: 0.024465886435219377 | validation: 0.02960298298464751]
	TIME [epoch: 9.06 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022327241475800168		[learning rate: 0.00010571]
	Learning Rate: 0.000105714
	LOSS [training: 0.022327241475800168 | validation: 0.030233155719986256]
	TIME [epoch: 9.04 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023069758476104322		[learning rate: 0.00010539]
	Learning Rate: 0.00010539
	LOSS [training: 0.023069758476104322 | validation: 0.023505150224377682]
	TIME [epoch: 9.04 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024989990226616278		[learning rate: 0.00010507]
	Learning Rate: 0.000105067
	LOSS [training: 0.024989990226616278 | validation: 0.02130534130946258]
	TIME [epoch: 9.06 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02532435861746978		[learning rate: 0.00010474]
	Learning Rate: 0.000104745
	LOSS [training: 0.02532435861746978 | validation: 0.033703294433485256]
	TIME [epoch: 9.06 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028033641817930832		[learning rate: 0.00010442]
	Learning Rate: 0.000104424
	LOSS [training: 0.028033641817930832 | validation: 0.023387355127496377]
	TIME [epoch: 9.04 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023342558032286295		[learning rate: 0.0001041]
	Learning Rate: 0.000104104
	LOSS [training: 0.023342558032286295 | validation: 0.026553897444899586]
	TIME [epoch: 9.04 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025429533091414908		[learning rate: 0.00010378]
	Learning Rate: 0.000103785
	LOSS [training: 0.025429533091414908 | validation: 0.02357216991543387]
	TIME [epoch: 9.05 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02789262320293996		[learning rate: 0.00010347]
	Learning Rate: 0.000103467
	LOSS [training: 0.02789262320293996 | validation: 0.01663635831029458]
	TIME [epoch: 9.07 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02261463321186396		[learning rate: 0.00010315]
	Learning Rate: 0.000103149
	LOSS [training: 0.02261463321186396 | validation: 0.012050348740621832]
	TIME [epoch: 9.04 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02774962852449438		[learning rate: 0.00010283]
	Learning Rate: 0.000102833
	LOSS [training: 0.02774962852449438 | validation: 0.01876463378199611]
	TIME [epoch: 9.04 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02242524220439573		[learning rate: 0.00010252]
	Learning Rate: 0.000102518
	LOSS [training: 0.02242524220439573 | validation: 0.017239557184234155]
	TIME [epoch: 9.05 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027914284396084243		[learning rate: 0.0001022]
	Learning Rate: 0.000102204
	LOSS [training: 0.027914284396084243 | validation: 0.021854090952135655]
	TIME [epoch: 9.07 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02553380656060117		[learning rate: 0.00010189]
	Learning Rate: 0.00010189
	LOSS [training: 0.02553380656060117 | validation: 0.016184245568082508]
	TIME [epoch: 9.05 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027174165082126518		[learning rate: 0.00010158]
	Learning Rate: 0.000101578
	LOSS [training: 0.027174165082126518 | validation: 0.02856877064520081]
	TIME [epoch: 9.04 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03831418188879466		[learning rate: 0.00010127]
	Learning Rate: 0.000101267
	LOSS [training: 0.03831418188879466 | validation: 0.03622300844828642]
	TIME [epoch: 9.04 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038223734272952746		[learning rate: 0.00010096]
	Learning Rate: 0.000100956
	LOSS [training: 0.038223734272952746 | validation: 0.0247523455190318]
	TIME [epoch: 9.06 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03069147205561405		[learning rate: 0.00010065]
	Learning Rate: 0.000100647
	LOSS [training: 0.03069147205561405 | validation: 0.030875784385039677]
	TIME [epoch: 9.05 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023069555204418602		[learning rate: 0.00010034]
	Learning Rate: 0.000100338
	LOSS [training: 0.023069555204418602 | validation: 0.02322547614012206]
	TIME [epoch: 9.04 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026293757663669898		[learning rate: 0.00010003]
	Learning Rate: 0.000100031
	LOSS [training: 0.026293757663669898 | validation: 0.02007113954771582]
	TIME [epoch: 9.04 sec]
Finished training in 18248.894 seconds.
