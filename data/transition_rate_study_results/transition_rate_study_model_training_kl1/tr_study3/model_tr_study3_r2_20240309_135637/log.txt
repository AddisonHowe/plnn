Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r2', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 168980038

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.158246823190344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.158246823190344 | validation: 8.605583818242597]
	TIME [epoch: 101 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.472956839539961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.472956839539961 | validation: 8.136687813900688]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.623893936147028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.623893936147028 | validation: 7.8679338628422535]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.170732460849552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.170732460849552 | validation: 6.905043980200392]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8252096334779075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8252096334779075 | validation: 6.501388234652189]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.317647970315154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.317647970315154 | validation: 6.87378250718238]
	TIME [epoch: 11.5 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.322924922210486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.322924922210486 | validation: 6.26492732103413]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.013389236308029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.013389236308029 | validation: 5.906616168457532]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9989884002352065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9989884002352065 | validation: 5.756325185993701]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761690484185981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.761690484185981 | validation: 5.5748906786537695]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.725223671353142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.725223671353142 | validation: 5.661610755862104]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.653384978047472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.653384978047472 | validation: 5.465845689124246]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.69300424972878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.69300424972878 | validation: 5.443298428901407]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.551650116198634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551650116198634 | validation: 5.3591252024353]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718195504618034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.718195504618034 | validation: 5.644501523210233]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.472732744734631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.472732744734631 | validation: 5.4940830644511385]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.463173643421214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.463173643421214 | validation: 5.60185554609637]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.453260000252392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.453260000252392 | validation: 5.26623338741016]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4931280328225895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4931280328225895 | validation: 4.985263859898494]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.064563800482551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.064563800482551 | validation: 5.631017372504427]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.019193231874536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.019193231874536 | validation: 5.948540880866549]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.445361243762447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.445361243762447 | validation: 4.656917879890058]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.694304789584845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.694304789584845 | validation: 4.546003363986899]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.657283081997183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.657283081997183 | validation: 4.304002204813575]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.261936451317251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.261936451317251 | validation: 4.451612101251808]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9859620966107006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9859620966107006 | validation: 4.583952331878119]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.440136477222098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.440136477222098 | validation: 5.357469959053572]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.513470476454469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.513470476454469 | validation: 4.806906290738446]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.808584242872949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.808584242872949 | validation: 4.1310002811804765]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.594256532495159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.594256532495159 | validation: 4.390430104549751]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.731278986085485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.731278986085485 | validation: 4.215687476776684]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096490332700337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.096490332700337 | validation: 3.9680810817550958]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.045759870667669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.045759870667669 | validation: 8.091444034405392]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.213929372605188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.213929372605188 | validation: 6.030870516704231]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.076131173133026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.076131173133026 | validation: 4.395172240682727]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.378845268586266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.378845268586266 | validation: 5.935861794743407]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.75885643589743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.75885643589743 | validation: 7.523739795081195]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750551728104973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.750551728104973 | validation: 4.366631590295984]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.760389200777694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.760389200777694 | validation: 4.64801531281419]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.151774216469674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.151774216469674 | validation: 4.2872060754714]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.219001607689447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.219001607689447 | validation: 3.7926730885546887]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.842415211826884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.842415211826884 | validation: 4.004868955502316]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.154884624218523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.154884624218523 | validation: 3.808664358960267]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.847997349212106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.847997349212106 | validation: 3.381624935534663]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.594393185979214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.594393185979214 | validation: 3.198553532452034]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4864362578254875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4864362578254875 | validation: 4.048187298268426]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9493056901492913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9493056901492913 | validation: 3.7408434978641694]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6477254438137323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6477254438137323 | validation: 3.172732165943435]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3214007865974713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3214007865974713 | validation: 4.423399559317686]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132897853388903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.132897853388903 | validation: 3.1483471234240596]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4657672030616613		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.4657672030616613 | validation: 3.0491935609940173]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4263144187054886		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.4263144187054886 | validation: 3.33799675040627]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6351342104323705		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.6351342104323705 | validation: 3.527907836717541]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2953893466567328		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.2953893466567328 | validation: 3.7570300333268767]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.794625453347781		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.794625453347781 | validation: 2.929915871326636]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1591065791469357		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.1591065791469357 | validation: 2.7260701346721317]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1417114328483784		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.1417114328483784 | validation: 2.899634904304504]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0301223220178573		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.0301223220178573 | validation: 2.7711874354835393]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1214939818427654		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.1214939818427654 | validation: 2.7588144849686667]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617210604862006		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.617210604862006 | validation: 3.893644705195782]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8201113328162157		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.8201113328162157 | validation: 4.576381218276632]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5254885936267844		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.5254885936267844 | validation: 2.214301862302591]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6183845826744747		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.6183845826744747 | validation: 2.634466536161391]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4533739012797224		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.4533739012797224 | validation: 2.001896570231281]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6801263013225625		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.6801263013225625 | validation: 2.1739984913889328]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5137419893961144		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.5137419893961144 | validation: 1.9505021710751438]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169234490175813		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.169234490175813 | validation: 2.3425378182660377]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4476063529515364		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.4476063529515364 | validation: 2.1663581959072973]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.22753233851012		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.22753233851012 | validation: 1.8528618213199224]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1808991864061524		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.1808991864061524 | validation: 1.7899419677888608]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062972197479486		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.062972197479486 | validation: 1.5838354820377623]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.899464118921921		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.899464118921921 | validation: 3.387450742814755]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8455106824777836		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.8455106824777836 | validation: 2.1021336627810427]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0979898668438413		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.0979898668438413 | validation: 1.8864106004874706]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3562523680664196		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.3562523680664196 | validation: 1.6166290957484257]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8942888358373122		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.8942888358373122 | validation: 1.5913640701560763]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9311364617759532		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.9311364617759532 | validation: 1.3731028543873596]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2361566506286863		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.2361566506286863 | validation: 4.494056330000113]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.728808704164723		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.728808704164723 | validation: 1.6809861573221714]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6656560188161742		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.6656560188161742 | validation: 1.8170292795506344]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.787445635000175		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.787445635000175 | validation: 2.052174629100776]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9126474339335426		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9126474339335426 | validation: 1.6560188126621063]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0077125922610835		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.0077125922610835 | validation: 1.723286508423105]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6368712623467776		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.6368712623467776 | validation: 1.4817967531488632]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0070490586056846		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.0070490586056846 | validation: 1.9252871632178727]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.64356587015682		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.64356587015682 | validation: 1.2538496537861756]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.60324188940438		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.60324188940438 | validation: 1.6655640930012647]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.649347443039951		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.649347443039951 | validation: 1.3085542837985424]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5526913793619272		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.5526913793619272 | validation: 1.1612757459402168]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5214285658954338		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5214285658954338 | validation: 1.4782072244262014]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737090001682832		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.737090001682832 | validation: 1.1086795167436585]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.409476911919629		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.409476911919629 | validation: 1.5714700398379478]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5536449291115106		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.5536449291115106 | validation: 1.3513268411657102]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6982766343541915		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6982766343541915 | validation: 1.293986889078326]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0810851703558493		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.0810851703558493 | validation: 1.5053814867800304]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7981998332233418		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7981998332233418 | validation: 1.411596645867578]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482970980221452		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.482970980221452 | validation: 1.255408036219853]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6289574565429947		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.6289574565429947 | validation: 1.8435055885692664]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5873119677430874		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.5873119677430874 | validation: 1.096141795090203]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5038411607031708		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5038411607031708 | validation: 1.3544793849134835]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8688854925917302		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.8688854925917302 | validation: 1.6342839549942585]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7732156361512414		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.7732156361512414 | validation: 1.184718457967636]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5847018687132133		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.5847018687132133 | validation: 1.4109993160833278]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.634705970469966		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.634705970469966 | validation: 1.522287456994531]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5492432846030253		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.5492432846030253 | validation: 1.3058134302327806]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.380576416800675		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.380576416800675 | validation: 1.538907923495534]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4412598070191949		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.4412598070191949 | validation: 1.3446317410862318]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5711317455298834		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.5711317455298834 | validation: 1.5534861826134512]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4276170549020422		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.4276170549020422 | validation: 1.6372174318433554]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4678628413286847		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4678628413286847 | validation: 1.5186648763367094]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5657115387757108		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5657115387757108 | validation: 1.5389319065354534]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.63180404662776		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.63180404662776 | validation: 1.4271793591634887]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31144921163806		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.31144921163806 | validation: 3.088477583447142]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5391503021540145		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.5391503021540145 | validation: 2.4262800837267027]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0561550666437065		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.0561550666437065 | validation: 1.6855245914283439]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.53402202159418		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.53402202159418 | validation: 1.4837272768183187]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.563103980864822		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.563103980864822 | validation: 1.3575071056608794]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4265892848629815		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.4265892848629815 | validation: 1.4558497100027004]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5818802497137747		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.5818802497137747 | validation: 1.5118380284475168]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.53854849248675		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.53854849248675 | validation: 1.2782067672743649]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5499802569982095		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.5499802569982095 | validation: 1.4093580841990314]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3860313558041382		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.3860313558041382 | validation: 1.808870639290165]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5827865712372158		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.5827865712372158 | validation: 1.3102080680030073]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5182483906445303		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.5182483906445303 | validation: 1.2791206544876554]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5269167965538568		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5269167965538568 | validation: 1.4672596279361838]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4599513428969717		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.4599513428969717 | validation: 1.58983919411576]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4507856164713064		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.4507856164713064 | validation: 1.2111069438057305]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4051990654381201		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.4051990654381201 | validation: 1.2017735158125233]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5310893597308615		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.5310893597308615 | validation: 1.3721355760363485]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2475535715756196		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.2475535715756196 | validation: 0.9860828184856297]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391020288620728		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.1391020288620728 | validation: 1.0453176620205165]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1757157173399855		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.1757157173399855 | validation: 1.1685290251405618]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714469760226978		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1714469760226978 | validation: 0.9696147408002324]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0975889125012739		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.0975889125012739 | validation: 0.8540862620485342]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.011120062950455		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.011120062950455 | validation: 1.0285795500956627]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3035300009266917		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.3035300009266917 | validation: 1.631547064889581]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.490883193602825		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.490883193602825 | validation: 0.9979505231294746]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0939843781481962		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.0939843781481962 | validation: 1.0205357709487612]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9884004233953343		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9884004233953343 | validation: 1.7559218527127736]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4775623173706136		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4775623173706136 | validation: 1.0497676567739]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.101331747582885		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.101331747582885 | validation: 0.8877350409508676]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178791063213355		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.178791063213355 | validation: 0.7656503960514046]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587253959038012		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0587253959038012 | validation: 0.959103166999117]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217735096326372		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2217735096326372 | validation: 0.8566799225338287]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1209903140664208		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.1209903140664208 | validation: 0.7580435885729366]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635535949547808		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1635535949547808 | validation: 0.8990695790949167]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2396001957975848		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.2396001957975848 | validation: 0.8670032160676252]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0311048961529394		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0311048961529394 | validation: 1.116324376016512]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0479291509948216		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.0479291509948216 | validation: 1.2022272441923847]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528818284799801		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.0528818284799801 | validation: 0.733782816438582]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.955857533812055		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.955857533812055 | validation: 0.8302359675768018]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9936039948712794		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.9936039948712794 | validation: 0.5648117499292412]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872603183394398		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.872603183394398 | validation: 1.2035525385668908]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0121213466124526		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0121213466124526 | validation: 0.8379740550425109]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8588580661285629		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.8588580661285629 | validation: 1.1885946903724498]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495926535386771		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1495926535386771 | validation: 0.7909233344111243]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001873063777944		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.9001873063777944 | validation: 0.6919034358187143]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9416904528012442		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.9416904528012442 | validation: 1.0067342115839302]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345321459978734		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.345321459978734 | validation: 0.6931233976312146]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008876228970504		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.008876228970504 | validation: 0.6286889119392906]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9287316419806699		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.9287316419806699 | validation: 0.5982207303593607]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2352855108612109		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.2352855108612109 | validation: 0.945207425803604]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3221154505663328		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.3221154505663328 | validation: 1.0269194637042898]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2589843729116466		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.2589843729116466 | validation: 0.82007177930916]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7893575308518548		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.7893575308518548 | validation: 0.7902360501123817]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.270758251235474		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.270758251235474 | validation: 0.9715528055327302]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1445472755719834		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1445472755719834 | validation: 0.6410455149684222]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0657858837240497		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.0657858837240497 | validation: 0.9139579714772958]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8591330479176393		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8591330479176393 | validation: 1.2177357441269023]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0493570802815149		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.0493570802815149 | validation: 1.8694884818330246]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.281751368810491		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.281751368810491 | validation: 1.0123883618887088]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9581232724107458		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.9581232724107458 | validation: 1.294378473705981]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735507303591134		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0735507303591134 | validation: 0.9878266681695784]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8176153340846147		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.8176153340846147 | validation: 1.0248500374384828]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9636467262094519		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9636467262094519 | validation: 1.0173045956019053]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0376316074412708		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.0376316074412708 | validation: 0.6115736612709781]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9163096636285692		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.9163096636285692 | validation: 0.7704996438747955]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8230164676240387		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.8230164676240387 | validation: 0.9042301488865332]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0048197358153637		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.0048197358153637 | validation: 0.7579498224821165]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959751199935265		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7959751199935265 | validation: 0.581651552953408]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034069318671973		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9034069318671973 | validation: 1.5043439882584542]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2778097471728977		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.2778097471728977 | validation: 0.9692829681910007]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0720971390661065		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.0720971390661065 | validation: 0.8129108686159495]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9021946448374939		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9021946448374939 | validation: 0.6666739769703804]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0351538759662353		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0351538759662353 | validation: 1.4701080019746884]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1318855061188093		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.1318855061188093 | validation: 1.2680879482336334]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9465912284320183		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9465912284320183 | validation: 0.9301340912539479]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8700473070114941		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8700473070114941 | validation: 1.0889605994141136]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9127883725635074		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.9127883725635074 | validation: 1.6118530275500942]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3828394891218556		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3828394891218556 | validation: 1.0212644849306123]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8155508874058264		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8155508874058264 | validation: 1.5652700868557496]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0692363151039435		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0692363151039435 | validation: 0.9153572740367563]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098954124361275		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8098954124361275 | validation: 0.6865267462338435]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9560895171569608		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.9560895171569608 | validation: 0.944541595523174]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1832964447603609		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.1832964447603609 | validation: 1.0912498851546075]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593140058864068		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0593140058864068 | validation: 0.756269343925168]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9265904470678124		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9265904470678124 | validation: 0.6440934738198957]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000687110775211		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7000687110775211 | validation: 1.1774266627029473]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.197604915098926		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.197604915098926 | validation: 0.6388846822869835]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832630887006795		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.7832630887006795 | validation: 1.1775472399972284]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604758507688812		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0604758507688812 | validation: 0.8703902754854289]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9468426242979276		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.9468426242979276 | validation: 1.5332238290773452]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1715514882107336		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.1715514882107336 | validation: 0.9475717119960748]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488575579577817		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8488575579577817 | validation: 0.8489583999663826]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8901651002228463		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8901651002228463 | validation: 0.8781735072760151]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7866836981884736		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.7866836981884736 | validation: 1.027288222427709]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2760707727802663		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.2760707727802663 | validation: 1.2646279082477847]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346046588499617		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9346046588499617 | validation: 1.0763591390114287]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.101876884738928		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.101876884738928 | validation: 0.9435021816459016]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9321085381258147		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9321085381258147 | validation: 0.8541569886234823]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824659002675176		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7824659002675176 | validation: 0.5057514751274197]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7459786769104635		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7459786769104635 | validation: 0.7189017640334102]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.844350740637676		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.844350740637676 | validation: 0.9807758661161604]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8960296818615647		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8960296818615647 | validation: 0.7612227901222803]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7943535874769346		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.7943535874769346 | validation: 0.547860719313156]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271774652746521		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7271774652746521 | validation: 0.9441944615130484]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9027362445229986		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9027362445229986 | validation: 0.8924079548912974]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7408943617392016		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7408943617392016 | validation: 0.7047347781042789]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9489446138905506		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9489446138905506 | validation: 0.6927443981388204]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879139032365668		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8879139032365668 | validation: 0.48745670393139195]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158974044355019		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6158974044355019 | validation: 0.5892147253590099]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334398184881914		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7334398184881914 | validation: 0.7704416142116969]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908669488069155		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7908669488069155 | validation: 0.8225668245571285]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8124873525982736		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8124873525982736 | validation: 0.6209399748377809]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8884055272099087		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8884055272099087 | validation: 0.46059112415861314]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335396605516568		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7335396605516568 | validation: 0.5681611686936832]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100345239290225		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6100345239290225 | validation: 1.0765331194961065]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.781091846629075		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.781091846629075 | validation: 0.7751698539709752]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.987504404917698		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.987504404917698 | validation: 1.2985768598142307]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8952744870539743		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8952744870539743 | validation: 0.8168743121522075]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913143689603132		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.6913143689603132 | validation: 0.7119297900445273]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6340451417405946		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6340451417405946 | validation: 0.7188761096557752]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9147944361749731		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9147944361749731 | validation: 0.7083318347597267]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760579032780256		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.6760579032780256 | validation: 1.260993438977962]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8446211074001331		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8446211074001331 | validation: 0.9344186862364098]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334571536573		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7334571536573 | validation: 0.7863115194611909]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.778830903905346		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.778830903905346 | validation: 0.4181987161868634]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589473216889786		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7589473216889786 | validation: 0.6106012553102604]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7960674804445136		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.7960674804445136 | validation: 1.163940633158237]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90637943802657		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.90637943802657 | validation: 1.2502927011326828]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869858218275386		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.869858218275386 | validation: 0.5967043750497446]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351806738162404		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7351806738162404 | validation: 0.8094038778598228]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558910004656133		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7558910004656133 | validation: 0.6886045315842122]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125176426808701		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6125176426808701 | validation: 0.8114203848786231]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914443719086341		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6914443719086341 | validation: 0.7737859814597872]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451856138291718		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7451856138291718 | validation: 0.6476416987510991]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792501307942191		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6792501307942191 | validation: 0.5042829137248611]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962601695341317		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6962601695341317 | validation: 0.5841423844683441]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6452744242811426		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6452744242811426 | validation: 1.036641929628262]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7865457064164922		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7865457064164922 | validation: 0.68234906510815]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289297946919543		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6289297946919543 | validation: 0.7407731237229942]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382677596297139		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8382677596297139 | validation: 0.7912097411663589]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889582758448214		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5889582758448214 | validation: 0.5638976090406612]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444283783977999		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6444283783977999 | validation: 1.088996851083034]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9698457605813571		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9698457605813571 | validation: 0.5988136783098993]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418051120655109		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6418051120655109 | validation: 0.435888009797325]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958789804072895		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6958789804072895 | validation: 0.45084176308234003]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225149592291873		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7225149592291873 | validation: 0.6843033674700072]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201490133367306		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6201490133367306 | validation: 0.5956364065672898]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089209288655355		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6089209288655355 | validation: 0.743168447387524]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438270992203067		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6438270992203067 | validation: 0.7988502263398644]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8426773532843261		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.8426773532843261 | validation: 0.32808348401260995]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748375962782273		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5748375962782273 | validation: 0.8226743521718888]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533765490161108		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7533765490161108 | validation: 0.6052657695469479]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538678922375493		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.538678922375493 | validation: 0.8870598227129272]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147202045998774		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7147202045998774 | validation: 0.476822555757761]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6568278218479474		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6568278218479474 | validation: 0.8096226182487993]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7123691200922373		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7123691200922373 | validation: 0.6081386582338126]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48591466247639853		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.48591466247639853 | validation: 1.0370015190221158]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239616644844925		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6239616644844925 | validation: 0.8805645628578535]
	TIME [epoch: 11.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712573019657691		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7712573019657691 | validation: 0.5126002739271001]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6759407002690906		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.6759407002690906 | validation: 0.8319858802035577]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8636346445269443		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8636346445269443 | validation: 0.574737098400599]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032818944330529		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.6032818944330529 | validation: 0.38816542217591077]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45599403269310534		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.45599403269310534 | validation: 0.5236296020585963]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5628685816405399		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5628685816405399 | validation: 0.36121792184758716]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232132406433934		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5232132406433934 | validation: 0.38541954037515197]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5959808539549153		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5959808539549153 | validation: 0.5775152449584114]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866000267671327		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6866000267671327 | validation: 0.669670731039885]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5836781319328833		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5836781319328833 | validation: 0.5592026707660065]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859496047474607		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6859496047474607 | validation: 0.3001358902270643]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082847545725974		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.5082847545725974 | validation: 0.5702581783227493]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403525840634902		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5403525840634902 | validation: 0.35377787683543516]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.569949580572799		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.569949580572799 | validation: 0.5781934315083632]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015661011806445		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5015661011806445 | validation: 0.6164518429561292]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5659158347853215		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5659158347853215 | validation: 0.8322112580597468]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532887649185845		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.5532887649185845 | validation: 0.45977361526466737]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001136132069593		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6001136132069593 | validation: 0.6001597227533183]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451974420154637		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.451974420154637 | validation: 0.39490845001365293]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488981407958752		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5488981407958752 | validation: 0.6870098371429056]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5494558019360588		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5494558019360588 | validation: 0.3154794727513076]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4250073225507017		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.4250073225507017 | validation: 0.5675036718653145]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319233211577552		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5319233211577552 | validation: 0.4397543712234747]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740088268664332		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.4740088268664332 | validation: 0.4739230668723501]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205801262996916		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7205801262996916 | validation: 0.6263567473828624]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891167467310054		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6891167467310054 | validation: 0.4177558476839572]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523472275449213		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.4523472275449213 | validation: 0.5022838874089031]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530228013076403		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.530228013076403 | validation: 0.39841995032438304]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4988794153266845		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.4988794153266845 | validation: 0.40529927490806905]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44827102367403926		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.44827102367403926 | validation: 0.7860214616368366]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608278213921325		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.608278213921325 | validation: 0.3233090824352639]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727620311030015		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6727620311030015 | validation: 0.28118035124596935]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340301845228087		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5340301845228087 | validation: 0.31423443378246624]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832103165743702		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.4832103165743702 | validation: 0.4333449032407194]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7709161011686612		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7709161011686612 | validation: 0.5490083502766094]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271309567149838		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5271309567149838 | validation: 0.47386506958134483]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487409739401786		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.487409739401786 | validation: 0.3894125730672232]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484420216785635		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.5484420216785635 | validation: 0.42503045786042465]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325311199750199		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.4325311199750199 | validation: 0.5314291810143262]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101596258610303		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5101596258610303 | validation: 0.5893634404145077]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697127545400548		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5697127545400548 | validation: 0.37171581012580546]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324754331143249		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5324754331143249 | validation: 0.29595511619118015]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48169367124073886		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.48169367124073886 | validation: 0.3235345772963102]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5502024155599154		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5502024155599154 | validation: 0.3973471398211196]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594456328996478		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.4594456328996478 | validation: 0.4218088481472657]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4029007222916772		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.4029007222916772 | validation: 0.569484773274149]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605281974236058		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5605281974236058 | validation: 0.3626981747174465]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49499004050602835		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.49499004050602835 | validation: 0.36303698676703183]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8682202136429386		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.8682202136429386 | validation: 0.4643985784844199]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441117965014521		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.5441117965014521 | validation: 0.4461607709852746]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914225360598839		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3914225360598839 | validation: 0.5963008497167067]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111631898156405		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5111631898156405 | validation: 0.8325539098368503]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128930990144347		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6128930990144347 | validation: 0.32449219217451786]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5704088929664745		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5704088929664745 | validation: 0.3014666517072891]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155326668502849		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5155326668502849 | validation: 0.29514351259072874]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33969360874121934		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.33969360874121934 | validation: 0.4622700594006865]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188585145626919		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6188585145626919 | validation: 0.8464314045361699]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071712814533796		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.7071712814533796 | validation: 0.6467580314644029]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4898028293734125		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.4898028293734125 | validation: 0.3850501265304401]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739453177487409		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5739453177487409 | validation: 0.3364801313292978]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694601221164401		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3694601221164401 | validation: 0.37094779165889974]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133782713953959		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5133782713953959 | validation: 0.39224382250177053]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776171212125966		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5776171212125966 | validation: 0.631262235831487]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157477560235244		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5157477560235244 | validation: 0.4826750662896639]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241789036136982		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.4241789036136982 | validation: 0.6010327863445957]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500363029717972		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.4500363029717972 | validation: 0.5840476484010767]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5296480810157369		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.5296480810157369 | validation: 0.5511467640187374]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538752727933891		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.538752727933891 | validation: 0.39715380627697394]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49881636519326866		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.49881636519326866 | validation: 0.4635105828052118]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904161978236077		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.3904161978236077 | validation: 0.6132163974148711]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46415161473331146		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.46415161473331146 | validation: 0.3743996336897466]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40258366993873457		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.40258366993873457 | validation: 0.23863719489525348]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37425362655296956		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.37425362655296956 | validation: 0.2754465700197526]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720431407960033		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3720431407960033 | validation: 0.7439242313657886]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5375521891818448		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5375521891818448 | validation: 0.33166287482010876]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3905541844687541		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.3905541844687541 | validation: 0.37190981906900683]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47404052610968905		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.47404052610968905 | validation: 0.6239342079103639]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171593608020392		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.4171593608020392 | validation: 0.3332390994233744]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36600437963584764		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.36600437963584764 | validation: 0.2878972988748314]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37868720297637504		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.37868720297637504 | validation: 0.2864599515141179]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39843267551238065		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.39843267551238065 | validation: 0.26652562074525415]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34531314663952534		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.34531314663952534 | validation: 0.45226625585292274]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367953912426498		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.4367953912426498 | validation: 0.2596699970485883]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713132880197283		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.3713132880197283 | validation: 0.2926055203018474]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590455492014685		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.4590455492014685 | validation: 0.3539206748745056]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40592803121140647		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.40592803121140647 | validation: 0.31616375642519523]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873942934051482		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3873942934051482 | validation: 0.36656819202835406]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47981218577751533		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.47981218577751533 | validation: 0.4328240506651104]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42144784545819475		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.42144784545819475 | validation: 0.23116750205423614]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352074965547165		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.3352074965547165 | validation: 0.3340515965054313]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363078865767791		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.363078865767791 | validation: 0.4458243495288782]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561845173939244		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3561845173939244 | validation: 0.3134439474378552]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5041132179061927		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5041132179061927 | validation: 0.28200285183114815]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820995165471005		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3820995165471005 | validation: 0.5287577162926267]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522153760550406		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.522153760550406 | validation: 0.3104553545762302]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41222156342194455		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.41222156342194455 | validation: 0.3062161290159996]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41484742325670676		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.41484742325670676 | validation: 0.38037406483834346]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5038055948206829		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5038055948206829 | validation: 0.437730864973207]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.434565005658894		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.434565005658894 | validation: 0.45666137431436954]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731317123915592		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5731317123915592 | validation: 0.3805658166066989]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6362088642961877		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6362088642961877 | validation: 0.39816625865573185]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4076693374520509		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.4076693374520509 | validation: 0.4709835727450664]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45547476565529643		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.45547476565529643 | validation: 0.498108207858143]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43118737942259117		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.43118737942259117 | validation: 0.4926943382471777]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42747136274992226		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.42747136274992226 | validation: 0.29735998949949155]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44389603739217526		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.44389603739217526 | validation: 0.28051992129410314]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32524760880469894		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.32524760880469894 | validation: 0.33511549567145643]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785105044583102		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.5785105044583102 | validation: 0.4460057414161551]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908674917719299		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4908674917719299 | validation: 0.41807577912752175]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003665587641104		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5003665587641104 | validation: 0.2969147024962054]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996668455265695		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2996668455265695 | validation: 0.3352899349814774]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775773471088816		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.3775773471088816 | validation: 0.2944510081350893]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35869085981301785		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.35869085981301785 | validation: 0.17787602358324514]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27806355203005845		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.27806355203005845 | validation: 0.5315960088201226]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321746228838992		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5321746228838992 | validation: 0.35713647236536133]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397990340410131		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3397990340410131 | validation: 0.2032284719284576]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415707529142247		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.3415707529142247 | validation: 0.4155446639024055]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33459112898201		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.33459112898201 | validation: 0.25507417089165196]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228935009513116		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3228935009513116 | validation: 0.18487538832399664]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27441727101313607		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.27441727101313607 | validation: 0.5156563081542506]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39323784608026424		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.39323784608026424 | validation: 0.3213919095173644]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524379641884825		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2524379641884825 | validation: 0.24607413584735205]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369127913683923		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3369127913683923 | validation: 0.7361270726264345]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525899519414124		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6525899519414124 | validation: 0.3113435188559122]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32260271940647794		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.32260271940647794 | validation: 0.424665580144641]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530943988165859		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3530943988165859 | validation: 0.36386041948177755]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3262655420676949		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3262655420676949 | validation: 0.3191761018353222]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361858626612518		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.361858626612518 | validation: 0.729040750039986]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465266822842643		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.4465266822842643 | validation: 0.557478829648462]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37722643388901866		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.37722643388901866 | validation: 0.2508661207486537]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868068916079941		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3868068916079941 | validation: 0.6685860031274211]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44412485548608843		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.44412485548608843 | validation: 0.2498538163828156]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219661825917646		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.219661825917646 | validation: 0.35462411564271534]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030732551309463		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.3030732551309463 | validation: 0.29422047145722696]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079935204552219		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.4079935204552219 | validation: 0.25287226499068816]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4334306712690593		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4334306712690593 | validation: 0.3575856609692386]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809263614578226		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.4809263614578226 | validation: 0.5656788245730268]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4990466039517969		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.4990466039517969 | validation: 1.0435276472500294]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593613281556193		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5593613281556193 | validation: 0.2119106950350271]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3164254906928401		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3164254906928401 | validation: 0.24126297780896813]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2447929215132996		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2447929215132996 | validation: 0.19443137077214065]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302987481941384		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.302987481941384 | validation: 0.16910307749874878]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222627594725999		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.3222627594725999 | validation: 0.2541504724483692]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39497335806967926		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.39497335806967926 | validation: 0.3198910900702674]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045019376393622		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3045019376393622 | validation: 0.36832674506349855]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47264473001517593		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.47264473001517593 | validation: 0.3336579229676952]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37755446503055573		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.37755446503055573 | validation: 0.2371061647232257]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31858816800531986		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.31858816800531986 | validation: 0.6162981456437221]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40424163637888877		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.40424163637888877 | validation: 0.39424703495536106]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312401464508054		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3312401464508054 | validation: 0.5131083435612007]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124514983366522		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.4124514983366522 | validation: 0.2682906861468719]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870043312353737		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2870043312353737 | validation: 0.21296088003270217]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377568248069968		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3377568248069968 | validation: 0.27257588987301545]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1998261452728579		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.1998261452728579 | validation: 0.38443974047657764]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43439381013359424		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.43439381013359424 | validation: 0.39769705465315225]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878502375856692		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.2878502375856692 | validation: 0.5239067128143688]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36343593175425715		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.36343593175425715 | validation: 0.7558239239508732]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539927663557558		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.539927663557558 | validation: 0.3976002430289407]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.271841248732861		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.271841248732861 | validation: 0.2866942740276999]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3608110556611147		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3608110556611147 | validation: 0.17215110489170155]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254299431983716		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.254299431983716 | validation: 0.41582059400585036]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566541347328207		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3566541347328207 | validation: 0.31170482494575635]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458468502752247		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.2458468502752247 | validation: 0.19003588963146825]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22700678522285433		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.22700678522285433 | validation: 0.3080472553343374]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43508743244203607		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.43508743244203607 | validation: 0.6233896853510109]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44140443164161824		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.44140443164161824 | validation: 0.37401825463232613]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41849398086190454		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.41849398086190454 | validation: 0.40294468878672013]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29714483266402214		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.29714483266402214 | validation: 0.23954889213892036]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2480175765538826		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2480175765538826 | validation: 0.27587760775356723]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820642424054243		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2820642424054243 | validation: 0.20469983624157806]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3876963647759535		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3876963647759535 | validation: 0.35241224129678356]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464657649741853		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.3464657649741853 | validation: 0.3852080540841588]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36576703058536614		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.36576703058536614 | validation: 0.2942468652668343]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597015111405463		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2597015111405463 | validation: 0.3825094528889674]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36109170259948137		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.36109170259948137 | validation: 0.17434706172311693]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24804892270089743		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.24804892270089743 | validation: 0.40327955760305273]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255590193415929		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.3255590193415929 | validation: 0.35224900100095896]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397803774819712		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3397803774819712 | validation: 0.24800007856094872]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513403954637181		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2513403954637181 | validation: 0.43462618661152946]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3247135546192489		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3247135546192489 | validation: 0.3549720287799299]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337901230904139		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3337901230904139 | validation: 0.3159270801029126]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3127469299780077		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3127469299780077 | validation: 0.3848950434483607]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434219333881606		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3434219333881606 | validation: 0.26871325026032883]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396343546558384		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.3396343546558384 | validation: 0.23018761525453374]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49624078368135927		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.49624078368135927 | validation: 0.28611428708416436]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30883556503389364		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.30883556503389364 | validation: 0.193502408355229]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2406029847898318		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2406029847898318 | validation: 0.40003159705135233]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897364755789187		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2897364755789187 | validation: 0.19213219846604238]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010591440139314		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3010591440139314 | validation: 0.39861589370270606]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38096716572751077		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.38096716572751077 | validation: 0.21971020267302013]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30598836659766687		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.30598836659766687 | validation: 0.2842951219555575]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34452875358747115		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.34452875358747115 | validation: 0.3053504253911124]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3968151386212487		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3968151386212487 | validation: 0.2781667249207034]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4102219889775846		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.4102219889775846 | validation: 0.531522410375119]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944802832804405		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3944802832804405 | validation: 0.4629291136005129]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26800759733926793		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.26800759733926793 | validation: 0.21556189226207959]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22085986638734112		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22085986638734112 | validation: 0.250523403333513]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32397779774264557		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.32397779774264557 | validation: 0.10843723585264314]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28765699667872036		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.28765699667872036 | validation: 0.25449495042001896]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3367851534941389		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3367851534941389 | validation: 0.44947784994643697]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38562060873937865		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.38562060873937865 | validation: 0.2245141632473954]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24350801386260698		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.24350801386260698 | validation: 0.21294459543230623]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939908915908782		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2939908915908782 | validation: 0.2607297930444504]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834975822520243		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2834975822520243 | validation: 0.18213751781363816]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2554104935426029		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2554104935426029 | validation: 0.30070584469951145]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137081528311725		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.3137081528311725 | validation: 0.13850230136865901]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27515384607548765		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.27515384607548765 | validation: 0.19459881478793292]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301790400332082		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2301790400332082 | validation: 0.4410427170199686]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33241825782313517		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.33241825782313517 | validation: 0.41547394281185485]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112534017542629		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5112534017542629 | validation: 0.31883697916303894]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3270115314619596		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.3270115314619596 | validation: 0.3924854979865585]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816532497352694		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.3816532497352694 | validation: 0.30872173518375284]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858995322523388		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2858995322523388 | validation: 0.2439247608935084]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457495913480469		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2457495913480469 | validation: 0.2969507782430078]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31628843734380124		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.31628843734380124 | validation: 0.30750725088009695]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677532346941467		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.2677532346941467 | validation: 0.17121826045558433]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22023086468591518		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.22023086468591518 | validation: 0.217943127498826]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24351875855564703		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.24351875855564703 | validation: 0.21572318681447727]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32169409801447035		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.32169409801447035 | validation: 0.1596979571819677]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209991954551316		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2209991954551316 | validation: 0.44885190872595615]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747504000174096		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2747504000174096 | validation: 0.277663615001674]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23462194087808927		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.23462194087808927 | validation: 0.27944527772623323]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24844506155210344		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.24844506155210344 | validation: 0.2011663850771447]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27870177686253633		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.27870177686253633 | validation: 0.17117151470700223]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107973641250487		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2107973641250487 | validation: 0.16265745259303674]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23465650966792462		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.23465650966792462 | validation: 0.20854666450143172]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002210932932504		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2002210932932504 | validation: 0.1583841794834559]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863481769793065		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2863481769793065 | validation: 0.3433597056836558]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532188665088382		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.2532188665088382 | validation: 0.13873633991850418]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676704064001568		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.2676704064001568 | validation: 0.18386886286680187]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647560028110878		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2647560028110878 | validation: 0.23258761404714726]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556568110798067		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2556568110798067 | validation: 0.21074566301375]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31207767635799394		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.31207767635799394 | validation: 0.19388982581978717]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447549640279918		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.22447549640279918 | validation: 0.21052157135389887]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29620005164718266		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.29620005164718266 | validation: 0.25364401039414186]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010944727468841		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3010944727468841 | validation: 0.21689039490215478]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24005204236805294		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.24005204236805294 | validation: 0.3363314795999395]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36399575257212236		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.36399575257212236 | validation: 0.3190887714402653]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439861740429727		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3439861740429727 | validation: 0.2873582444003207]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304728510759604		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.304728510759604 | validation: 0.5347643800633837]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4313294305963053		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.4313294305963053 | validation: 0.2274092257328696]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22273823257526976		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.22273823257526976 | validation: 0.2173898083943523]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768592637221119		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.2768592637221119 | validation: 0.25002805125529765]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498850011612547		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.2498850011612547 | validation: 0.2362027680742856]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21572880194366756		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.21572880194366756 | validation: 0.21814980215282698]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089431351369857		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.2089431351369857 | validation: 0.21687750519353757]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28038738023055443		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.28038738023055443 | validation: 0.1410776900609482]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25879926345086557		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.25879926345086557 | validation: 0.1645295451629581]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23856103407941665		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.23856103407941665 | validation: 0.15112629982986253]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25513330552850344		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.25513330552850344 | validation: 0.3648508302230206]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33316399482690606		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.33316399482690606 | validation: 0.6302826557058507]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939510001540871		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2939510001540871 | validation: 0.1765611567371807]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23911908905299645		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.23911908905299645 | validation: 0.1617303475112395]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.222513667981536		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.222513667981536 | validation: 0.6464404629990004]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.405166605872052		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.405166605872052 | validation: 0.270088490500844]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23756577627499276		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.23756577627499276 | validation: 0.1721531171226669]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851796783280637		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.22851796783280637 | validation: 0.4784418318141641]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391632910661057		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3391632910661057 | validation: 0.26145964739400995]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23792102675186536		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.23792102675186536 | validation: 0.17815929328578783]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25985195311060955		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.25985195311060955 | validation: 0.22911741805679317]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118219895393838		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2118219895393838 | validation: 0.1855617145371508]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21946374474318475		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.21946374474318475 | validation: 0.23241829445027062]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30405730263151437		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.30405730263151437 | validation: 0.2651078927801377]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25940243714328165		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.25940243714328165 | validation: 0.19461475209536455]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23490184233768124		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.23490184233768124 | validation: 0.14560208199324198]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325865424661149		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2325865424661149 | validation: 0.1808656988565898]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2470904076449979		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2470904076449979 | validation: 0.24225765353541234]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737520173210696		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2737520173210696 | validation: 0.23517239094316503]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23862066235982993		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23862066235982993 | validation: 0.16392615698311333]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24495933568405337		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.24495933568405337 | validation: 0.21069117044671384]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18241261959293933		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.18241261959293933 | validation: 0.43676887765399924]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526379113268439		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.2526379113268439 | validation: 0.24318214734924581]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46230782792453		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.46230782792453 | validation: 0.4632362061519691]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29995597632539295		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.29995597632539295 | validation: 0.17384565716320183]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19478109746999261		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.19478109746999261 | validation: 0.20036275123067157]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318633618183508		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.318633618183508 | validation: 0.2960341858131811]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22403300638106313		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.22403300638106313 | validation: 0.149185955815686]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214199720822144		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.2214199720822144 | validation: 0.12337887804102636]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771386746455885		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.1771386746455885 | validation: 0.25309536809536304]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20074443876838555		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.20074443876838555 | validation: 0.2354170259496377]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20112305596369737		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.20112305596369737 | validation: 0.16783703083426424]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24572196887627978		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.24572196887627978 | validation: 0.20400289129252427]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19559733216967495		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.19559733216967495 | validation: 0.2599016312496973]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260887659559106		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.260887659559106 | validation: 0.2134378578882904]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2190380778638772		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2190380778638772 | validation: 0.38620417517869443]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27989171978225236		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.27989171978225236 | validation: 0.17585658171290763]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23099352809226215		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.23099352809226215 | validation: 0.43611201272036726]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332170424593102		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.332170424593102 | validation: 0.17916476369344472]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20047542776783203		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.20047542776783203 | validation: 0.2194856931615199]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21047209165085512		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.21047209165085512 | validation: 0.2190036109489132]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813531132092747		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2813531132092747 | validation: 0.3191264125067248]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708709676842047		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2708709676842047 | validation: 0.21360741952250528]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327633192202081		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.327633192202081 | validation: 0.40888428906669844]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29602721142871513		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.29602721142871513 | validation: 0.31150878537974097]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688540347184709		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.2688540347184709 | validation: 0.2042355463376617]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26568243171808004		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.26568243171808004 | validation: 0.14927510414433937]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758255154428831		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.2758255154428831 | validation: 0.13217796428947373]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602117434467126		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2602117434467126 | validation: 0.2125837514049548]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2253727090195836		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.2253727090195836 | validation: 0.34926823943403834]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790481618188094		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.2790481618188094 | validation: 0.28338555670570914]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543965437613125		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.2543965437613125 | validation: 0.17580612396217013]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26266411492946756		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.26266411492946756 | validation: 0.1921428192522425]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22093868942991407		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.22093868942991407 | validation: 0.22517930491077265]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23703651244050827		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.23703651244050827 | validation: 0.16687596408478392]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17491197162700944		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.17491197162700944 | validation: 0.201173513865429]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21163626880334024		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.21163626880334024 | validation: 0.17817866070588698]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15893762558583513		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.15893762558583513 | validation: 0.23213239492430596]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20640922594936623		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.20640922594936623 | validation: 0.24802893752123983]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21789775184997934		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.21789775184997934 | validation: 0.35570241073628495]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33005227523500164		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.33005227523500164 | validation: 0.20169465702908723]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901740771844106		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1901740771844106 | validation: 0.26145267210931983]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20028937112983014		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.20028937112983014 | validation: 0.43841767059398257]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32141949893110544		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.32141949893110544 | validation: 0.1884893173331384]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543764834060648		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2543764834060648 | validation: 0.10858771872422242]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792333457133885		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1792333457133885 | validation: 0.18786323765766877]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17693714192214915		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.17693714192214915 | validation: 0.15224932217061002]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617754098888404		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.2617754098888404 | validation: 0.22288019317281219]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24993265960228497		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.24993265960228497 | validation: 0.23755321600859838]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147819854000715		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3147819854000715 | validation: 0.46525135962678393]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044919714709212		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.4044919714709212 | validation: 0.3358753524429722]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21658739551561243		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.21658739551561243 | validation: 0.17477072628323917]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896952543780502		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.1896952543780502 | validation: 0.24665450409276848]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21189568825925156		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.21189568825925156 | validation: 0.20645909810810062]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21904372824313617		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.21904372824313617 | validation: 0.20662899407641283]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2027416304315303		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2027416304315303 | validation: 0.17458395988299813]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14502623718431334		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.14502623718431334 | validation: 0.10779481997114232]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18526578700414442		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.18526578700414442 | validation: 0.17168811261657005]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20681340801797016		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.20681340801797016 | validation: 0.14051792344597508]
	TIME [epoch: 11.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17637586103280845		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.17637586103280845 | validation: 0.2999733966751971]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536521313353779		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2536521313353779 | validation: 0.09991187852120055]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17603523033941673		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.17603523033941673 | validation: 0.17503970693461327]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23056602101554788		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.23056602101554788 | validation: 0.1359793871040424]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18855974226253858		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.18855974226253858 | validation: 0.16599155903992038]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17281643701789418		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.17281643701789418 | validation: 0.4594467431614443]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352392269385659		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.2352392269385659 | validation: 0.1585570798121925]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17710844723893343		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.17710844723893343 | validation: 0.2628759308885949]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21235613074728998		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.21235613074728998 | validation: 0.3602243025775421]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23824681924198074		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.23824681924198074 | validation: 0.15780486253343243]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255687966349033		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.2255687966349033 | validation: 0.14827867983433976]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20502665399703698		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.20502665399703698 | validation: 0.1935708606553833]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23129890041030868		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.23129890041030868 | validation: 0.30396651795080276]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907312360189455		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.2907312360189455 | validation: 0.1469821947372744]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3156231742420561		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3156231742420561 | validation: 0.1696213079806526]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16543390894197346		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.16543390894197346 | validation: 0.15927465313936492]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20759495015183707		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.20759495015183707 | validation: 0.31122761282989486]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24014500325262497		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.24014500325262497 | validation: 0.1868117157592431]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17071753570068343		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.17071753570068343 | validation: 0.15489326088489588]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22889835128083916		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.22889835128083916 | validation: 0.1374601261224965]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654702342974352		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1654702342974352 | validation: 0.1523129192176891]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18696804357390243		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.18696804357390243 | validation: 0.29764929142345875]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18522324309620955		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.18522324309620955 | validation: 0.09429126302802868]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12833312189911386		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.12833312189911386 | validation: 0.5638967368311554]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32016009161611175		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.32016009161611175 | validation: 0.20934009791886932]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028900263891511		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.2028900263891511 | validation: 0.18377513176472043]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128273605794433		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3128273605794433 | validation: 0.1678140130521592]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578523257179531		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.2578523257179531 | validation: 0.28040549988729035]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19429073939965488		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.19429073939965488 | validation: 0.22422951893816948]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19778994335789182		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.19778994335789182 | validation: 0.17277443890912125]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21201323560500995		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.21201323560500995 | validation: 0.16347016154315405]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16106059365949954		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.16106059365949954 | validation: 0.10749085208432443]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14660901664761863		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.14660901664761863 | validation: 0.2720877234771136]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2425704783235087		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2425704783235087 | validation: 0.1834040558910907]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21800631793290098		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.21800631793290098 | validation: 0.40872726079488725]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27200810102352646		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.27200810102352646 | validation: 0.1851946171104958]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18175526659094		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.18175526659094 | validation: 0.1342425843789317]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561486112624589		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.1561486112624589 | validation: 0.10404832390729876]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664237727816515		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.1664237727816515 | validation: 0.15257937794304932]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16309005961851514		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.16309005961851514 | validation: 0.10587320860905944]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585183084929866		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.1585183084929866 | validation: 0.14058126601169244]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845845388313882		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16845845388313882 | validation: 0.18436457560578695]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292788047690737		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2292788047690737 | validation: 0.2140742918500711]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21078241675011897		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.21078241675011897 | validation: 0.19447073025300937]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668699243113367		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.17668699243113367 | validation: 0.13491905144403987]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604118269414081		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.1604118269414081 | validation: 0.1564200589187957]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20229133621534642		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.20229133621534642 | validation: 0.17463397139237266]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23438300782980134		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.23438300782980134 | validation: 0.1922990947622955]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17905515479861908		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.17905515479861908 | validation: 0.13622841880910033]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18570024997026968		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.18570024997026968 | validation: 0.12404234620261546]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13614184546920433		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.13614184546920433 | validation: 0.1635811165549296]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15283524147182725		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15283524147182725 | validation: 0.11515259634884835]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20194843956656736		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.20194843956656736 | validation: 0.09532496136655377]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12199045892786572		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.12199045892786572 | validation: 0.14650592021447156]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1943504837584696		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1943504837584696 | validation: 0.1776778546949513]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16461313138760314		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.16461313138760314 | validation: 0.14300215865198826]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038367481594192		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.2038367481594192 | validation: 0.14812185663639077]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18954730457502927		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.18954730457502927 | validation: 0.14333393823521606]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025687811498345		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.2025687811498345 | validation: 0.10136112790753671]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16248986669488596		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.16248986669488596 | validation: 0.19962384478529488]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14460307559858948		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.14460307559858948 | validation: 0.10580611447162286]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16057857450300855		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.16057857450300855 | validation: 0.24601876513872573]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23349392406882524		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.23349392406882524 | validation: 0.1425410437294183]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636525754525208		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.16636525754525208 | validation: 0.21533155953150324]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670382310774663		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1670382310774663 | validation: 0.10381304236244702]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11313523344005358		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.11313523344005358 | validation: 0.1101381199074811]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12659671738274553		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12659671738274553 | validation: 0.1490194102683848]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16210483650141755		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.16210483650141755 | validation: 0.30904205588369593]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770271726674478		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.2770271726674478 | validation: 0.18156994552537523]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17984495701267333		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.17984495701267333 | validation: 0.180994706479542]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420205857509454		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.2420205857509454 | validation: 0.15120100556824523]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666378734527869		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1666378734527869 | validation: 0.12330169436010968]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19991452504639723		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.19991452504639723 | validation: 0.22533661659178122]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17223599049685626		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.17223599049685626 | validation: 0.22398355231747252]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25127623338221283		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.25127623338221283 | validation: 0.33195670690221285]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18675474531372863		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.18675474531372863 | validation: 0.17047957477371717]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16157657178633433		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.16157657178633433 | validation: 0.26640231365375305]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29725101823152544		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.29725101823152544 | validation: 0.09824906921089983]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17634920955122074		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.17634920955122074 | validation: 0.12756916052590106]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754706627339226		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.14754706627339226 | validation: 0.16400512022135721]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38617465717391875		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.38617465717391875 | validation: 0.20224910452670664]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1935865249376824		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1935865249376824 | validation: 0.1596977107707966]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12655917054954632		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.12655917054954632 | validation: 0.11826186838506422]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011274896870134		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.16011274896870134 | validation: 0.1964395585614505]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21715438031657208		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.21715438031657208 | validation: 0.1560621081477436]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158541828932649		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.158541828932649 | validation: 0.1199380812277822]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16455045970353938		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.16455045970353938 | validation: 0.20447243384806124]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19375884408087968		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.19375884408087968 | validation: 0.1446391232655322]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370638842297878		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.14370638842297878 | validation: 0.20647590265657031]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27397109129106995		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.27397109129106995 | validation: 0.1714005478983763]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14697356141719806		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.14697356141719806 | validation: 0.235621080778693]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17481596635254043		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.17481596635254043 | validation: 0.13861028307912185]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149625393632613		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.16149625393632613 | validation: 0.17805965403886287]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15051103022783915		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15051103022783915 | validation: 0.15518106348233324]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611527676085236		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1611527676085236 | validation: 0.13005883741010546]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303929230315103		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.1303929230315103 | validation: 0.13669853930896644]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15450687841685765		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15450687841685765 | validation: 0.10355433434069303]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208930486000283		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1208930486000283 | validation: 0.17282038418848097]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842513502437035		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.1842513502437035 | validation: 0.23629621331212255]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18364629654825668		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.18364629654825668 | validation: 0.15033051822695911]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19882218656549083		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.19882218656549083 | validation: 0.14367647531124816]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21366166209861562		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.21366166209861562 | validation: 0.17997403902528553]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15335628168300458		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.15335628168300458 | validation: 0.11213732095733997]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14240466946537328		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.14240466946537328 | validation: 0.13146949665998242]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14563939008186227		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.14563939008186227 | validation: 0.14220476314628908]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16256571740492623		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.16256571740492623 | validation: 0.11364609682828572]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182567524783335		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2182567524783335 | validation: 0.20879950521245466]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625102467075882		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.14625102467075882 | validation: 0.14704841365294916]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21205922936367466		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.21205922936367466 | validation: 0.20267296742031454]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16077182565931272		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.16077182565931272 | validation: 0.18117444920167158]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959616117101525		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.13959616117101525 | validation: 0.15917600445805324]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20349422160325226		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.20349422160325226 | validation: 0.23619004633153634]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17674738357804048		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.17674738357804048 | validation: 0.1336998387953989]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14329734294579483		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.14329734294579483 | validation: 0.16831544095969644]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456844718379672		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1456844718379672 | validation: 0.1436998917405114]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14220961529849502		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.14220961529849502 | validation: 0.20016047642079865]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16895540017012828		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.16895540017012828 | validation: 0.18790033504045425]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20948006510653333		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.20948006510653333 | validation: 0.13932972952083808]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555145738964599		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.1555145738964599 | validation: 0.12309279854205066]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14409805885073634		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.14409805885073634 | validation: 0.08238206162953887]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351518209285421		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1351518209285421 | validation: 0.17602406125845124]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17436623297687065		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.17436623297687065 | validation: 0.16201869972214764]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460467474356183		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1460467474356183 | validation: 0.10749696089903175]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718591950797182		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1718591950797182 | validation: 0.10317273980468628]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135450555984545		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.11135450555984545 | validation: 0.1488489327620357]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14874457732135146		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.14874457732135146 | validation: 0.194813464902839]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18167662374029295		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.18167662374029295 | validation: 0.17697648606308866]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679176338787784		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.15679176338787784 | validation: 0.17439922557964388]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15649097324976657		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.15649097324976657 | validation: 0.1286975415073966]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406792632099548		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.13406792632099548 | validation: 0.1760700572306208]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14406144330090517		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.14406144330090517 | validation: 0.10079896462527131]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14054691222388271		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.14054691222388271 | validation: 0.1808099171133121]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286542010433245		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1286542010433245 | validation: 0.15174343065963058]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13359303598501793		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.13359303598501793 | validation: 0.21766963353250282]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15664717571598757		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.15664717571598757 | validation: 0.11712053434956154]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20475098750979487		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.20475098750979487 | validation: 0.1327974177956616]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1847740484515002		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1847740484515002 | validation: 0.19132894204740253]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24228504609242313		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.24228504609242313 | validation: 0.17257215652439314]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14747318160293138		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.14747318160293138 | validation: 0.11745135877373533]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461920031148364		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1461920031148364 | validation: 0.10531954447838952]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15477843377312112		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.15477843377312112 | validation: 0.10327552966491417]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455460648519652		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1455460648519652 | validation: 0.12072899947350603]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13230454525556845		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.13230454525556845 | validation: 0.12877666260223292]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901589864434964		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.14901589864434964 | validation: 0.08944466240229673]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486590759063676		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1486590759063676 | validation: 0.11276522884261178]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222426792010836		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.17222426792010836 | validation: 0.14899291631240336]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605212426970652		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15605212426970652 | validation: 0.10118385709900801]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147224372625982		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.147224372625982 | validation: 0.2125243356935674]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198520048651918		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.198520048651918 | validation: 0.1066691336667807]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146568522023249		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.146568522023249 | validation: 0.10546916761655223]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12060261694852954		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.12060261694852954 | validation: 0.0894868435247273]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15010903611838441		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.15010903611838441 | validation: 0.13075470154327443]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112627535265403		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.13112627535265403 | validation: 0.11004353711353655]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18226658758123526		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.18226658758123526 | validation: 0.10053569000645178]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442964299546809		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1442964299546809 | validation: 0.11568693599636937]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365875394118977		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.1365875394118977 | validation: 0.08482636116561011]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593560345316465		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.12593560345316465 | validation: 0.11313885260500758]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444320173877559		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.12444320173877559 | validation: 0.15684738754471986]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13280623443877987		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.13280623443877987 | validation: 0.14391567600557814]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1545155315469414		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1545155315469414 | validation: 0.10909713378432948]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157011098627475		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.13157011098627475 | validation: 0.13536283403962873]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13439817897903167		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.13439817897903167 | validation: 0.1295696296844892]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16006344445530313		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.16006344445530313 | validation: 0.10023602682789125]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037366984597911		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.12037366984597911 | validation: 0.13677507776065906]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15114816180687562		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.15114816180687562 | validation: 0.2798121113685918]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20201412797317847		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.20201412797317847 | validation: 0.08107774971267681]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105544693057363		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.1105544693057363 | validation: 0.10640730096898901]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13774131543003093		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.13774131543003093 | validation: 0.1758327891198386]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134234958997512		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.13134234958997512 | validation: 0.10356073011398476]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11561848991392583		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.11561848991392583 | validation: 0.08306290070987886]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042666766756831		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.12042666766756831 | validation: 0.11833382790200066]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14497039006152523		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.14497039006152523 | validation: 0.10168744473512469]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11766103716272623		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.11766103716272623 | validation: 0.14433251793762866]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927582630846477		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.13927582630846477 | validation: 0.13439610631978893]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520273812992896		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1520273812992896 | validation: 0.14080111401853776]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402751536594597		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1402751536594597 | validation: 0.12997457813939514]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11532367296364615		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.11532367296364615 | validation: 0.12565974569914587]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12227991677492867		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.12227991677492867 | validation: 0.09199663867099929]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10005527578129242		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.10005527578129242 | validation: 0.12032189174963126]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12858609036744328		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.12858609036744328 | validation: 0.08587329505825424]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182432787209594		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.13182432787209594 | validation: 0.12065364436701606]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13920967977870582		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13920967977870582 | validation: 0.08086870869730675]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_780.pth
	Model improved!!!
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120089690035387		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.120089690035387 | validation: 0.09097924356979371]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186543063519746		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.14186543063519746 | validation: 0.09476824791572794]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13216152704511275		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.13216152704511275 | validation: 0.1196858068823488]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12751003718527043		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.12751003718527043 | validation: 0.14413157253218173]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129506349095936		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.129506349095936 | validation: 0.09855626670905103]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137625753635403		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.12137625753635403 | validation: 0.13878709058731292]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14742556720360425		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.14742556720360425 | validation: 0.09807092546274258]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15749517646395597		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.15749517646395597 | validation: 0.09671576175712439]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12187294826140715		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.12187294826140715 | validation: 0.13345185844742555]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15142335194394763		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.15142335194394763 | validation: 0.11558950300642011]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364105286521646		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1364105286521646 | validation: 0.09806655868853632]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13014111951413074		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.13014111951413074 | validation: 0.0910890985034599]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824523210583038		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.10824523210583038 | validation: 0.14954389646082078]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11794611074428182		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.11794611074428182 | validation: 0.10449732640389886]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15154965698313722		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15154965698313722 | validation: 0.12564776368181543]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267100566723516		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1267100566723516 | validation: 0.11561218435300426]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12865092031776296		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.12865092031776296 | validation: 0.1084965435017017]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12854405963255097		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.12854405963255097 | validation: 0.07347312992367065]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_798.pth
	Model improved!!!
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13331822718018718		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.13331822718018718 | validation: 0.0922234846234988]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12351328135658336		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.12351328135658336 | validation: 0.0696949589049621]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050203037054685		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.1050203037054685 | validation: 0.14478943290720364]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14697161544786935		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.14697161544786935 | validation: 0.14152816437438034]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141752509103104		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1141752509103104 | validation: 0.08556848125582174]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11146177148764809		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.11146177148764809 | validation: 0.11931239529007397]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11591833876121982		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.11591833876121982 | validation: 0.16589794235147426]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.118158290906202		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.118158290906202 | validation: 0.1298587587953332]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16753596772461135		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.16753596772461135 | validation: 0.18720818113420784]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595504602937687		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.14595504602937687 | validation: 0.11373602547194495]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12583751474858296		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.12583751474858296 | validation: 0.13965722830023006]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14644413215880647		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.14644413215880647 | validation: 0.1396301601188873]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079100626552845		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.13079100626552845 | validation: 0.10121977291967667]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497172731732024		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1497172731732024 | validation: 0.16166331619758545]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028833061179692		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.15028833061179692 | validation: 0.13553293929987897]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014432810440361		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.11014432810440361 | validation: 0.1418798841227554]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16653291772747225		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.16653291772747225 | validation: 0.13435671669105892]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12449995350183937		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12449995350183937 | validation: 0.10090071180184423]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13206300377508207		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.13206300377508207 | validation: 0.12576719723089708]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992829923178198		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12992829923178198 | validation: 0.1350901626871654]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12561934394240062		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.12561934394240062 | validation: 0.09927883547441779]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13964377642888856		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.13964377642888856 | validation: 0.09365704462199262]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11140863309842947		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.11140863309842947 | validation: 0.10153855540835466]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228483375882843		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.11228483375882843 | validation: 0.12643504622429844]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454081963485762		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.1454081963485762 | validation: 0.09028787528694927]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969527879188186		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.12969527879188186 | validation: 0.12248414796794897]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390334447130508		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1390334447130508 | validation: 0.10906607264765572]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120516206630178		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.120516206630178 | validation: 0.11233714035667053]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11512413742567743		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.11512413742567743 | validation: 0.1685613814060338]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11915557513983469		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.11915557513983469 | validation: 0.1243721901518183]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549961664510743		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.1549961664510743 | validation: 0.14320698505129886]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337591204403293		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.13337591204403293 | validation: 0.09280376470109117]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072838673438135		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.12072838673438135 | validation: 0.09432076216382526]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252585705308851		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.11252585705308851 | validation: 0.09209652089484262]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11297525573749705		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11297525573749705 | validation: 0.09309140822973162]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709577060895815		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.10709577060895815 | validation: 0.1344101758435509]
	TIME [epoch: 11.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102146456991423		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.10102146456991423 | validation: 0.1439876169144729]
	TIME [epoch: 11.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14465756451812584		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.14465756451812584 | validation: 0.10605812227127098]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893112326653202		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.11893112326653202 | validation: 0.07821787835660741]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11050380068224219		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.11050380068224219 | validation: 0.08814807280767599]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13237910973341777		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.13237910973341777 | validation: 0.1150418395430155]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11667819616426195		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.11667819616426195 | validation: 0.1446405584903519]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765087640423856		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.12765087640423856 | validation: 0.09961884571380435]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071109114146665		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.1071109114146665 | validation: 0.08612917782594602]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09322634462539076		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.09322634462539076 | validation: 0.09800885998008635]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281264518667438		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.1281264518667438 | validation: 0.11856968940989866]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775697621512655		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.12775697621512655 | validation: 0.13145363150924208]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15040804259465945		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.15040804259465945 | validation: 0.15473626069908417]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386332037620915		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.1386332037620915 | validation: 0.17433270150634347]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15722391324278653		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.15722391324278653 | validation: 0.11487072781331328]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310545977076158		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12310545977076158 | validation: 0.14752210936111756]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15008052356323856		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.15008052356323856 | validation: 0.10202379542313224]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13292149633742065		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13292149633742065 | validation: 0.10567293668192378]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060079473967975		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1060079473967975 | validation: 0.10516892754658119]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163575859360447		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.11163575859360447 | validation: 0.07353895360560983]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024727297220217		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.09024727297220217 | validation: 0.09931030169946778]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14600228894010958		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.14600228894010958 | validation: 0.10284015806617784]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14808562287922075		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.14808562287922075 | validation: 0.0979222383570032]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12127416994991254		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.12127416994991254 | validation: 0.09547062376664857]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300935117894547		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.10300935117894547 | validation: 0.08660863622301074]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11664807857193579		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.11664807857193579 | validation: 0.13647974554948483]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725106577229394		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.14725106577229394 | validation: 0.07467054440395576]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10615044685740016		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.10615044685740016 | validation: 0.1102081211843287]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15180219140930734		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.15180219140930734 | validation: 0.12593823429870854]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14551324551510644		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.14551324551510644 | validation: 0.10461400329256104]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13169024664031762		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.13169024664031762 | validation: 0.08850104265150859]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15166134136770024		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.15166134136770024 | validation: 0.13922258795889686]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600755081904926		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.1600755081904926 | validation: 0.13136374619700272]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13504361308652127		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.13504361308652127 | validation: 0.10419465490112538]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841985654003498		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.11841985654003498 | validation: 0.09102679089696061]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12825018229193275		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.12825018229193275 | validation: 0.11662661349322054]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855809991128168		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.10855809991128168 | validation: 0.10271884010200222]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13387639640237642		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.13387639640237642 | validation: 0.1387587299024246]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270994806293478		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.1270994806293478 | validation: 0.11036943471352269]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015841584371853		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.12015841584371853 | validation: 0.07140848557952306]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11614458937826264		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.11614458937826264 | validation: 0.11296820092252506]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083394274778548		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.11083394274778548 | validation: 0.07609672946208015]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709576448994925		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.11709576448994925 | validation: 0.11615951525102468]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426174771118212		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.12426174771118212 | validation: 0.11692065797574032]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10872241828663098		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.10872241828663098 | validation: 0.08709096971690648]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10524011952827446		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.10524011952827446 | validation: 0.08239783983832627]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0889272067394681		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.0889272067394681 | validation: 0.08509840680607746]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09603625853374655		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.09603625853374655 | validation: 0.07341451882394771]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366387039761544		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.11366387039761544 | validation: 0.10364002383391696]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10265458349097943		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.10265458349097943 | validation: 0.07909666087773473]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221330773807818		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.1221330773807818 | validation: 0.11851743883338335]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124481163572913		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.13124481163572913 | validation: 0.1116552291478899]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220294784489893		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.10220294784489893 | validation: 0.10135329935350751]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13818582032137836		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.13818582032137836 | validation: 0.10908417684002665]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11239358935967825		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.11239358935967825 | validation: 0.0778943125177747]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097166501278047		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.11097166501278047 | validation: 0.09651960426372189]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235299561395278		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.1235299561395278 | validation: 0.11668293792802947]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907716163676537		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.10907716163676537 | validation: 0.07817527222415038]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125306644731561		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.09125306644731561 | validation: 0.0863601061267192]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260085411349942		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.10260085411349942 | validation: 0.10046824159864638]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118710052410834		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1118710052410834 | validation: 0.08769818295953612]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466365122940711		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11466365122940711 | validation: 0.08042090900571561]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097459198417712		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.097459198417712 | validation: 0.07012811288356004]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633082725695644		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.10633082725695644 | validation: 0.0896262491312387]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14782148297137		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14782148297137 | validation: 0.14746892244982987]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11317844997462954		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.11317844997462954 | validation: 0.09116910817985406]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191318731217833		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.10191318731217833 | validation: 0.0930227394835282]
	TIME [epoch: 11.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068202221476145		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.11068202221476145 | validation: 0.06999371949969545]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920878896504095		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.10920878896504095 | validation: 0.13386581465895814]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13431161283007767		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.13431161283007767 | validation: 0.07433378412064556]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11565679807505469		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.11565679807505469 | validation: 0.09236906088697136]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214707565613275		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1214707565613275 | validation: 0.07844996485572776]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075268369470394		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10075268369470394 | validation: 0.09177081649544101]
	TIME [epoch: 11.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989729875631792		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0989729875631792 | validation: 0.0769350031215177]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209307076590302		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.1209307076590302 | validation: 0.18391404378802706]
	TIME [epoch: 11.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582916889971535		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.1582916889971535 | validation: 0.16910190458853477]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402794620145183		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.1402794620145183 | validation: 0.1879277967621393]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14860502576026335		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.14860502576026335 | validation: 0.14443621608907425]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15400237135921405		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.15400237135921405 | validation: 0.08378179898018717]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09331595897904517		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09331595897904517 | validation: 0.08521196963921882]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09592816197957746		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.09592816197957746 | validation: 0.07422753104761469]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217742085809733		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09217742085809733 | validation: 0.11314346940015249]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081028720289233		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.12081028720289233 | validation: 0.09538086581911018]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12003482600005493		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.12003482600005493 | validation: 0.09910360962358741]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11254334651353963		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.11254334651353963 | validation: 0.10434377954259713]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600108531201954		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.10600108531201954 | validation: 0.1429715122412736]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704702866476164		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.1704702866476164 | validation: 0.20315424886449035]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13861061186607673		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.13861061186607673 | validation: 0.1261795950666097]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026482470591714		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.14026482470591714 | validation: 0.09945152588430006]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716200339452919		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.11716200339452919 | validation: 0.06841293589583515]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08474867159155289		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.08474867159155289 | validation: 0.11492817665669272]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1149638913187088		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.1149638913187088 | validation: 0.11597024124436421]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13080690357186261		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.13080690357186261 | validation: 0.08198076539012598]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09831834646796414		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.09831834646796414 | validation: 0.13121546441680076]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475300365413956		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.12475300365413956 | validation: 0.12840532785119507]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11393948634887509		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.11393948634887509 | validation: 0.08598072046831547]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931117357600822		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0931117357600822 | validation: 0.08502077408223713]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515670990412492		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.12515670990412492 | validation: 0.09946357425109909]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124131049922658		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.13124131049922658 | validation: 0.08036014595270949]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09380777505024632		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.09380777505024632 | validation: 0.13474522956036528]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09877178942287937		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.09877178942287937 | validation: 0.07920389270326117]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739896051859094		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09739896051859094 | validation: 0.10487167554587118]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558390882569705		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.09558390882569705 | validation: 0.07495676669472529]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020118649308639		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.1020118649308639 | validation: 0.08706408622417136]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09378425463022551		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.09378425463022551 | validation: 0.09475791082675361]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656319655019248		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.09656319655019248 | validation: 0.10205425013608536]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076032908433111		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1076032908433111 | validation: 0.10405826274012527]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163086950123937		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.10163086950123937 | validation: 0.13230412028187194]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679581321861087		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.09679581321861087 | validation: 0.07506357493840793]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037995873601568		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08037995873601568 | validation: 0.06523856471372363]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10073264081733439		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.10073264081733439 | validation: 0.09621798132616378]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595174624079761		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.11595174624079761 | validation: 0.10489118946055946]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580192304933037		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.09580192304933037 | validation: 0.09001205222133318]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601106629976443		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.08601106629976443 | validation: 0.08164514113308385]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09987329423488345		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.09987329423488345 | validation: 0.08438968321977922]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12278511327660335		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12278511327660335 | validation: 0.09807847656841986]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165164740495123		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.11165164740495123 | validation: 0.12998170686655341]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10843461882246588		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.10843461882246588 | validation: 0.09015501730315086]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709864612033295		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.09709864612033295 | validation: 0.10666729483652714]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09834095086137982		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.09834095086137982 | validation: 0.10052973261411083]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08934284268296488		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08934284268296488 | validation: 0.07791946226502146]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671387787971466		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.08671387787971466 | validation: 0.0654423989094855]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839725428049757		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.0839725428049757 | validation: 0.06258024388426653]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09955792735356106		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.09955792735356106 | validation: 0.11485964353751005]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876131667948538		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08876131667948538 | validation: 0.0879655689739763]
	TIME [epoch: 11.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742721803294924		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09742721803294924 | validation: 0.08897357254383298]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674057428754692		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.08674057428754692 | validation: 0.09496463730168442]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970027350824242		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.10970027350824242 | validation: 0.10636787989734725]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173079955834326		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.10173079955834326 | validation: 0.10656384271754518]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11181262040324572		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.11181262040324572 | validation: 0.09975214260026291]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574536205879502		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.12574536205879502 | validation: 0.11163055470807105]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210565204175928		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.10210565204175928 | validation: 0.1185956798523727]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652440574085474		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.10652440574085474 | validation: 0.1046720154191667]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10765591888769904		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.10765591888769904 | validation: 0.0955534581482379]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11766587063145917		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.11766587063145917 | validation: 0.09037712866927035]
	TIME [epoch: 11.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218846210071105		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.09218846210071105 | validation: 0.09373527335758176]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118356803263546		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1118356803263546 | validation: 0.13764653028638338]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13025765070496076		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.13025765070496076 | validation: 0.12257254174917957]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141062467109426		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.12141062467109426 | validation: 0.10199748603175321]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288926992223855		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.11288926992223855 | validation: 0.09364960481379848]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09822038528945735		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09822038528945735 | validation: 0.11098315281036601]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984248732544106		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0984248732544106 | validation: 0.08599398408119126]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281179222172773		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.10281179222172773 | validation: 0.09944928060647598]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809577582415021		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.10809577582415021 | validation: 0.13575335625041884]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14333281153054467		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.14333281153054467 | validation: 0.16880359470159506]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346471811555905		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.1346471811555905 | validation: 0.08822694825521211]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09493393601277403		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.09493393601277403 | validation: 0.09717352287027929]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775171834476781		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.09775171834476781 | validation: 0.10172586685582338]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562103180384277		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10562103180384277 | validation: 0.12885782201787072]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577830262927242		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.12577830262927242 | validation: 0.09898687462499708]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804574051596593		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.09804574051596593 | validation: 0.08784926848551707]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507766287264804		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.08507766287264804 | validation: 0.08957102676931232]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10064614293528139		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.10064614293528139 | validation: 0.09469536923284828]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10313809644428888		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.10313809644428888 | validation: 0.10922372015928607]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09456092789759986		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.09456092789759986 | validation: 0.08543382769249401]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09815112637282877		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.09815112637282877 | validation: 0.1082762258016113]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065607153014778		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.1065607153014778 | validation: 0.07541761058426028]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09306629168606691		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.09306629168606691 | validation: 0.09050761182433875]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09153349536229483		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.09153349536229483 | validation: 0.08599641758786104]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050965018081962		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.09050965018081962 | validation: 0.07844982683505881]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650880466781224		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.08650880466781224 | validation: 0.07495039194725946]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816710559803325		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0816710559803325 | validation: 0.08323670350905657]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941388218282541		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.08941388218282541 | validation: 0.09145649695257785]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981070664145276		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.09981070664145276 | validation: 0.09290698251250333]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230747640947273		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.10230747640947273 | validation: 0.08032902659628484]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931655224607862		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.08931655224607862 | validation: 0.09396325671560744]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214495131302714		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.10214495131302714 | validation: 0.09106905458516013]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10189886873783414		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.10189886873783414 | validation: 0.07136056376749647]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386003938706552		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.09386003938706552 | validation: 0.10564062480395629]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117093821622898		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.10117093821622898 | validation: 0.1075999470544058]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743087506283907		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.09743087506283907 | validation: 0.0832439084064476]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09536530805440156		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.09536530805440156 | validation: 0.08340480798067246]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09167130191123182		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.09167130191123182 | validation: 0.06358174175625043]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08937883231209832		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.08937883231209832 | validation: 0.11984498212681599]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13156800524851006		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.13156800524851006 | validation: 0.13782228803500027]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203907185804675		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.13203907185804675 | validation: 0.1308777835036156]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11885399085537149		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.11885399085537149 | validation: 0.0819146058017937]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10732686291854193		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.10732686291854193 | validation: 0.12398065000313174]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179985390064464		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.13179985390064464 | validation: 0.10119448901126948]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497349138646147		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.11497349138646147 | validation: 0.12348679556098442]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16529882232958584		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.16529882232958584 | validation: 0.09365521390552121]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11506151026982042		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.11506151026982042 | validation: 0.12931501386885966]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11237902313923129		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.11237902313923129 | validation: 0.0662783764198144]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947034754354584		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.0947034754354584 | validation: 0.09749287727655474]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585816710755666		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.10585816710755666 | validation: 0.07986739647587321]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075342000507363		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.1075342000507363 | validation: 0.08402508440533173]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08897802482765271		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08897802482765271 | validation: 0.07169879718817035]
	TIME [epoch: 11.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08529550446465892		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.08529550446465892 | validation: 0.077385256149455]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499789204625937		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.09499789204625937 | validation: 0.1269382542169495]
	TIME [epoch: 11.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14511595935812913		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.14511595935812913 | validation: 0.1778648273692509]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898794025583338		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.12898794025583338 | validation: 0.09547093659876531]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883450965899273		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0883450965899273 | validation: 0.09943349434591006]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214289784614151		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.11214289784614151 | validation: 0.10030210877976237]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11494848372850662		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.11494848372850662 | validation: 0.09301598467522268]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291036490307803		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.13291036490307803 | validation: 0.07279834454846039]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07910996187276546		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07910996187276546 | validation: 0.07684446536714676]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245061683984728		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.08245061683984728 | validation: 0.09146887423961357]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952322878085574		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0952322878085574 | validation: 0.11085675527798895]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676510117439147		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.09676510117439147 | validation: 0.08891596957105873]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023434429795805		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.1023434429795805 | validation: 0.07236708563388242]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08469334169601153		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.08469334169601153 | validation: 0.09059181406460898]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09796782866593093		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.09796782866593093 | validation: 0.08437499000327627]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09385025993793851		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.09385025993793851 | validation: 0.07228319262612784]
	TIME [epoch: 11.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091086292518055		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09091086292518055 | validation: 0.08508204331159433]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990094218915058		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08990094218915058 | validation: 0.06368144500943759]
	TIME [epoch: 11.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09376645358725483		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.09376645358725483 | validation: 0.0959886412658198]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620691956949558		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.08620691956949558 | validation: 0.07541217690714064]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09233928928434487		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.09233928928434487 | validation: 0.10691131982668677]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535957783803666		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.11535957783803666 | validation: 0.10915956679819132]
	TIME [epoch: 11.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112056735792997		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.10112056735792997 | validation: 0.06868545568892506]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082517524678443		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.09082517524678443 | validation: 0.09098761203096213]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548637497541683		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08548637497541683 | validation: 0.09255585724835315]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608441424120988		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.08608441424120988 | validation: 0.06627372871338386]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997680756804014		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07997680756804014 | validation: 0.078014965754412]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08781792795483687		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.08781792795483687 | validation: 0.1395519030189749]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355969316658893		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.11355969316658893 | validation: 0.09472986555079269]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08907907211780938		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.08907907211780938 | validation: 0.10799695568703463]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09354202005731735		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.09354202005731735 | validation: 0.07028260175185458]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419886468052655		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.09419886468052655 | validation: 0.07043735900784129]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363398134921286		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.08363398134921286 | validation: 0.07855574739865821]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691814591653279		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.09691814591653279 | validation: 0.11285285384957172]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207141241883225		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.10207141241883225 | validation: 0.059904180583493866]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1055.pth
	Model improved!!!
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07804653397920606		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.07804653397920606 | validation: 0.08266074771836193]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09391351948694374		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.09391351948694374 | validation: 0.0995173076733282]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821371858492802		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.08821371858492802 | validation: 0.07249748136770172]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850744482711347		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0850744482711347 | validation: 0.08514728632750472]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09399351457661087		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.09399351457661087 | validation: 0.08586745772553851]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10029383984851128		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.10029383984851128 | validation: 0.08452315425890204]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09760162338450383		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.09760162338450383 | validation: 0.09584132913804368]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162468191820204		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.13162468191820204 | validation: 0.10315617243624098]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09822965019500651		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.09822965019500651 | validation: 0.07971810003635793]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09642888815556097		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.09642888815556097 | validation: 0.08196499632740491]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867556822370181		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.09867556822370181 | validation: 0.08353941888342364]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09560701430482907		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.09560701430482907 | validation: 0.09757274124955771]
	TIME [epoch: 11.4 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10358416522985826		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.10358416522985826 | validation: 0.10187886567255305]
	TIME [epoch: 11.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494670691876748		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.10494670691876748 | validation: 0.07944793289529566]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09578293736464914		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.09578293736464914 | validation: 0.06234273157348376]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854104808422915		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.08854104808422915 | validation: 0.06432930487540103]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011590702000931		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.08011590702000931 | validation: 0.06399439733360987]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07581788153778063		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07581788153778063 | validation: 0.05791735635862913]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078211157176214		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.078211157176214 | validation: 0.10018372533382865]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11638513347119109		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.11638513347119109 | validation: 0.12056065060076733]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539457265353738		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.10539457265353738 | validation: 0.08382688918059579]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546054729324767		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.09546054729324767 | validation: 0.08632053372773953]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09720486702517439		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.09720486702517439 | validation: 0.11605081513918267]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521093116843112		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.11521093116843112 | validation: 0.10139781894160958]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022933864153246		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.09022933864153246 | validation: 0.09963677625750773]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081892897474682		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.09081892897474682 | validation: 0.07609739551204892]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08927390740081859		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.08927390740081859 | validation: 0.08941285146073552]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09846930515834099		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.09846930515834099 | validation: 0.08209039258076498]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792920485194912		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.07792920485194912 | validation: 0.06627835769053916]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346024570999354		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08346024570999354 | validation: 0.08753884953617636]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09371842861637605		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.09371842861637605 | validation: 0.07663139305162539]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396527506621833		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.08396527506621833 | validation: 0.0792308638653069]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685472289131123		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08685472289131123 | validation: 0.06280050416728618]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879315105865741		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0879315105865741 | validation: 0.07362937208443665]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08184455240040518		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.08184455240040518 | validation: 0.05941887206718027]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826751317375672		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0826751317375672 | validation: 0.08120518322026148]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803772087428828		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.0803772087428828 | validation: 0.0708432415844199]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08215626448803014		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.08215626448803014 | validation: 0.07498230353466961]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07474162799033142		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07474162799033142 | validation: 0.07340034091389852]
	TIME [epoch: 11.4 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09052155840885936		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.09052155840885936 | validation: 0.06988718477291056]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09302876965186277		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.09302876965186277 | validation: 0.07232412705548211]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007761380297202		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.09007761380297202 | validation: 0.09787091374925436]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742419961946275		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.09742419961946275 | validation: 0.09733673033453322]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642199738760037		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.08642199738760037 | validation: 0.10583496376293428]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10939329458679328		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10939329458679328 | validation: 0.1124752552658392]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09731622219704403		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.09731622219704403 | validation: 0.09904806109544026]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058862571285171		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10058862571285171 | validation: 0.11519677358265519]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122890391159195		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.10122890391159195 | validation: 0.09698187804505849]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478923669755665		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09478923669755665 | validation: 0.10845782400674461]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09815658167946936		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09815658167946936 | validation: 0.08730605617231578]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204618298178666		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.09204618298178666 | validation: 0.09390628107021842]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361696963330286		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.09361696963330286 | validation: 0.09543979341146706]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108807490102355		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.10108807490102355 | validation: 0.0943332336588747]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271754692792541		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.09271754692792541 | validation: 0.09892492424941597]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10574110398613834		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.10574110398613834 | validation: 0.08460392812346765]
	TIME [epoch: 11.4 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08352519619050641		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.08352519619050641 | validation: 0.06829877796100794]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729873571907412		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08729873571907412 | validation: 0.09882633942409327]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08885345148942513		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08885345148942513 | validation: 0.07890525797078007]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08946938421410419		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.08946938421410419 | validation: 0.08717834118181085]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422797962070201		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08422797962070201 | validation: 0.06602758240987615]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08699345179536074		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.08699345179536074 | validation: 0.07446431212908752]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997416755702531		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.07997416755702531 | validation: 0.07222513069665146]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08179119936831407		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.08179119936831407 | validation: 0.07806969194967049]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08412355286323471		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.08412355286323471 | validation: 0.06696119606325487]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327383469384264		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.08327383469384264 | validation: 0.06940941533053559]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924443865954397		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.08924443865954397 | validation: 0.08274768843080661]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09408892281078472		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.09408892281078472 | validation: 0.06630369318500914]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762172925773991		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.07762172925773991 | validation: 0.08543799019467088]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09107775389698783		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.09107775389698783 | validation: 0.07914738910859843]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08545593049370061		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.08545593049370061 | validation: 0.07884742481063434]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502764083295868		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.07502764083295868 | validation: 0.06441858322973665]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509322061908134		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07509322061908134 | validation: 0.07740010923728535]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08183131228656856		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.08183131228656856 | validation: 0.06374799875263282]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830009265106128		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0830009265106128 | validation: 0.06358362937256012]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09472920803451991		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.09472920803451991 | validation: 0.06534559734743707]
	TIME [epoch: 11.4 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752171349289494		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.07752171349289494 | validation: 0.06838406413969021]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821815911817787		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.0821815911817787 | validation: 0.06932934846481821]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920993482705174		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.07920993482705174 | validation: 0.0792530338414512]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958616448332426		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07958616448332426 | validation: 0.08654739479662066]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141980325408682		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.08141980325408682 | validation: 0.09219400430450264]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08165161279829505		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.08165161279829505 | validation: 0.06607345537332797]
	TIME [epoch: 11.4 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391764524660625		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.08391764524660625 | validation: 0.06332097541262358]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09030255407568129		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.09030255407568129 | validation: 0.11071746352772455]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269436084285292		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.10269436084285292 | validation: 0.061332898697823504]
	TIME [epoch: 11.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08122854082746325		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.08122854082746325 | validation: 0.05698839299649959]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07152736811058204		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07152736811058204 | validation: 0.06908357830354761]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07583407522946642		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07583407522946642 | validation: 0.0733294150532258]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421949649919596		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.07421949649919596 | validation: 0.053639361766998093]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1143.pth
	Model improved!!!
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240773978797224		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.07240773978797224 | validation: 0.08995322947851715]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749498475943788		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.07749498475943788 | validation: 0.06846053437049616]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817214082012286		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0817214082012286 | validation: 0.06557506014240679]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863826951158419		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.07863826951158419 | validation: 0.07133028599440969]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08228208660833022		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.08228208660833022 | validation: 0.07109203261065224]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11046203751348684		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.11046203751348684 | validation: 0.07734278332187124]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10689929850727478		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.10689929850727478 | validation: 0.07667205119218208]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336283297266953		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10336283297266953 | validation: 0.10005050451297155]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09810481994004631		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09810481994004631 | validation: 0.06402071943587587]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390045878852737		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.08390045878852737 | validation: 0.07818533504289202]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657048438437241		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.09657048438437241 | validation: 0.08588513083021397]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08499347104356544		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.08499347104356544 | validation: 0.07958480845414295]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683013973844031		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.08683013973844031 | validation: 0.06829793048000748]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009152682286561		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.09009152682286561 | validation: 0.062090621372402066]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09324096483131775		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.09324096483131775 | validation: 0.10059744082948506]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628585392612263		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.09628585392612263 | validation: 0.05613880947355213]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08428114583603295		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.08428114583603295 | validation: 0.07625429002746667]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758922646566104		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.09758922646566104 | validation: 0.07076710513780644]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131373860466996		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.09131373860466996 | validation: 0.08043685887856321]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08996524275837647		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08996524275837647 | validation: 0.060966762415389265]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875130297794018		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.08875130297794018 | validation: 0.07959558440064282]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859183875994789		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0859183875994789 | validation: 0.05772836879455779]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209141300199545		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.08209141300199545 | validation: 0.06002270934806478]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784462801033557		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0784462801033557 | validation: 0.06739291777229538]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064609491758572		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.08064609491758572 | validation: 0.07087668127025049]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08007363034488105		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.08007363034488105 | validation: 0.08215575722036356]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685554064453715		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.08685554064453715 | validation: 0.08246303965349731]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08364347785533571		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.08364347785533571 | validation: 0.0705374974341077]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891104917305231		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.08891104917305231 | validation: 0.06266461799637993]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193115531760407		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.09193115531760407 | validation: 0.08219304620188286]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601020245753183		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.08601020245753183 | validation: 0.08811335846423331]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999397047567791		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.07999397047567791 | validation: 0.055354279331185946]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07816565867764323		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.07816565867764323 | validation: 0.07128256773353961]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775397205827989		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0775397205827989 | validation: 0.06632525278976]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703722060169053		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.07703722060169053 | validation: 0.056754740554663244]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629986528324988		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.07629986528324988 | validation: 0.07908003311698904]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08770529275638239		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.08770529275638239 | validation: 0.06702781070705313]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114583735530309		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.08114583735530309 | validation: 0.07341061959788274]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0842213428576461		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0842213428576461 | validation: 0.060836962358201394]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107484084630104		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.08107484084630104 | validation: 0.064062244012543]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08162132171722551		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.08162132171722551 | validation: 0.0704392064036857]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906283431945839		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0906283431945839 | validation: 0.09193043682578995]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359659309373476		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.09359659309373476 | validation: 0.08480299964077587]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374068625847976		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.08374068625847976 | validation: 0.06594072711485252]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08297416861855933		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.08297416861855933 | validation: 0.0845743382995708]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714371852053294		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.09714371852053294 | validation: 0.08867766012582715]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328297089498787		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09328297089498787 | validation: 0.08243256387537777]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972921537438252		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.07972921537438252 | validation: 0.06440223821037702]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0762110869287773		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.0762110869287773 | validation: 0.06183607634428499]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796852054954835		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.07796852054954835 | validation: 0.07302139301996588]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773563640938548		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.0773563640938548 | validation: 0.08011997954488834]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07567691850682254		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.07567691850682254 | validation: 0.05647815455036476]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670675271246369		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07670675271246369 | validation: 0.05578081590926308]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232690854341947		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.07232690854341947 | validation: 0.05280682085321729]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1197.pth
	Model improved!!!
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073439744329532		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.07073439744329532 | validation: 0.07382967383641938]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406004497359533		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08406004497359533 | validation: 0.09019294643576391]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09879904373703369		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.09879904373703369 | validation: 0.09065258277797898]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973125734470008		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.0973125734470008 | validation: 0.06761327907810306]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08906772769642107		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.08906772769642107 | validation: 0.07159897714454172]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094562050261923		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.09094562050261923 | validation: 0.08464121310710572]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164579936677319		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.08164579936677319 | validation: 0.07245950550805554]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08885876701050222		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.08885876701050222 | validation: 0.0879674439502849]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08712127945318701		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.08712127945318701 | validation: 0.06876482530666012]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589112476442455		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.08589112476442455 | validation: 0.07933284617456078]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08993080456350837		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.08993080456350837 | validation: 0.08237455339641155]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08180690033802716		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.08180690033802716 | validation: 0.06486857445221013]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930422211750014		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.07930422211750014 | validation: 0.061371696204663095]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923786768731808		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.07923786768731808 | validation: 0.049136916631503845]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1211.pth
	Model improved!!!
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07201237609640768		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07201237609640768 | validation: 0.058729624859689425]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821052204097676		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.06821052204097676 | validation: 0.07230860580462833]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10166025390980193		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.10166025390980193 | validation: 0.08319754820606962]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000991256081887		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.1000991256081887 | validation: 0.07415896370350654]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576477509423222		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.08576477509423222 | validation: 0.0823024433298286]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827611719105918		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.0827611719105918 | validation: 0.08032779581376794]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802182972745668		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.0802182972745668 | validation: 0.07379040776032204]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08397008723076056		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.08397008723076056 | validation: 0.08720329994187224]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08537533827130565		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.08537533827130565 | validation: 0.0763927277481438]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08332784931491535		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.08332784931491535 | validation: 0.06260858229849597]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126564739655518		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09126564739655518 | validation: 0.09076070093443725]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928054543563565		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.07928054543563565 | validation: 0.06494683959460469]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920754802411986		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.07920754802411986 | validation: 0.06026379404483803]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789706373579043		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.07789706373579043 | validation: 0.07032474997891677]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08165307543151622		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.08165307543151622 | validation: 0.061631227715366235]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08272792346483201		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.08272792346483201 | validation: 0.07752079071257]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462030474440557		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.09462030474440557 | validation: 0.08586307431978522]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821350549828279		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.08821350549828279 | validation: 0.06065969530596264]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07754898028066172		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.07754898028066172 | validation: 0.08058750277097364]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970303320540613		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.07970303320540613 | validation: 0.05860509489495433]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07175334698100586		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.07175334698100586 | validation: 0.06024310745447196]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225765758237747		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.07225765758237747 | validation: 0.07416709400761254]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07838940395278415		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.07838940395278415 | validation: 0.05950915126051366]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783269033659987		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.07783269033659987 | validation: 0.06825574304181213]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08524555445927083		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.08524555445927083 | validation: 0.060959159745077124]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08267818751239278		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.08267818751239278 | validation: 0.08868002412613345]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08554206757947334		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.08554206757947334 | validation: 0.06746594840218156]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07631403322264002		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.07631403322264002 | validation: 0.058162584632920976]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502046711635238		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.07502046711635238 | validation: 0.06231846043183209]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08502349216039731		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.08502349216039731 | validation: 0.060999162960443824]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922016069749338		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.07922016069749338 | validation: 0.08110821917734966]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030419098717186		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.08030419098717186 | validation: 0.05682337022335737]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07419527219372245		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.07419527219372245 | validation: 0.060694184436184816]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210181177749393		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.07210181177749393 | validation: 0.06255177449226675]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026633413164748		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.08026633413164748 | validation: 0.06401220318736776]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674758937904242		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.08674758937904242 | validation: 0.06398537405266065]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578343667772612		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.07578343667772612 | validation: 0.04997608466151221]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07216422873261728		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.07216422873261728 | validation: 0.06188338477303877]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566722517857212		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.07566722517857212 | validation: 0.058160878746579964]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186598091404915		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.07186598091404915 | validation: 0.06377916430335548]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07461390604274364		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.07461390604274364 | validation: 0.0587035732200032]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650880737999279		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.07650880737999279 | validation: 0.06067356574729458]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772790017114885		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0772790017114885 | validation: 0.0566422042792615]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105736967626074		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.07105736967626074 | validation: 0.05952513856676058]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07180258682565212		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.07180258682565212 | validation: 0.06410657070238866]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07282612317380563		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.07282612317380563 | validation: 0.0625858933903827]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232913916661597		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.08232913916661597 | validation: 0.07230061663166377]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909896781827648		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.0909896781827648 | validation: 0.06477301164176727]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022729305083436		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.08022729305083436 | validation: 0.061773136184065436]
	TIME [epoch: 11.4 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06930942711626556		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.06930942711626556 | validation: 0.06716469497682606]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985576067941332		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.07985576067941332 | validation: 0.05536674586679039]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787701844796829		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0787701844796829 | validation: 0.06464569598890671]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609588938297113		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.07609588938297113 | validation: 0.06208540176359446]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07736896130503258		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.07736896130503258 | validation: 0.05201203289560189]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08077195255010565		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.08077195255010565 | validation: 0.060859822548873344]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08117847166401387		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.08117847166401387 | validation: 0.05521378762528075]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703651466193234		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.07703651466193234 | validation: 0.06374226805595443]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08688268119786208		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.08688268119786208 | validation: 0.0555527239925201]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871227401204488		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.07871227401204488 | validation: 0.06452382582974553]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792930330308204		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.07792930330308204 | validation: 0.06252685285812003]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07511244003822608		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.07511244003822608 | validation: 0.0563921810129705]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484469495921032		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.08484469495921032 | validation: 0.056966160124501196]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07932547321801488		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.07932547321801488 | validation: 0.050828301554674445]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07289934605620327		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.07289934605620327 | validation: 0.049049930721436825]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1275.pth
	Model improved!!!
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427157557487718		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.07427157557487718 | validation: 0.05623915505793685]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493868315674812		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.07493868315674812 | validation: 0.05971973068838047]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07057841146551071		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.07057841146551071 | validation: 0.06636646937110387]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07234137393886318		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.07234137393886318 | validation: 0.08594175898043446]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08859202091472917		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.08859202091472917 | validation: 0.06541078197578502]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909662712695575		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.06909662712695575 | validation: 0.06834476674894598]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07281550354216366		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.07281550354216366 | validation: 0.05885710517730013]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06967059531654349		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06967059531654349 | validation: 0.07169141446958037]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750561212898187		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.07750561212898187 | validation: 0.06788088273621658]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478535282649278		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.07478535282649278 | validation: 0.057010626240771876]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07464677202510443		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.07464677202510443 | validation: 0.06885579643505782]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891785473980589		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.07891785473980589 | validation: 0.08159477530519704]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823773426027196		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.07823773426027196 | validation: 0.06386846670460551]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763898508930257		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.0763898508930257 | validation: 0.0551675885076089]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239105602764138		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.07239105602764138 | validation: 0.058000462355135396]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246968551194344		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.07246968551194344 | validation: 0.07457840017597304]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627267483410307		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.08627267483410307 | validation: 0.060889771738085914]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467162388737393		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.07467162388737393 | validation: 0.05058854888559355]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866441920616422		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.07866441920616422 | validation: 0.05939565402644453]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08995337682310128		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.08995337682310128 | validation: 0.11138922380210478]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11617533902547736		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.11617533902547736 | validation: 0.07887718349316307]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10672718830844424		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.10672718830844424 | validation: 0.058866700196731216]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09332782228696973		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.09332782228696973 | validation: 0.06079934588987957]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511940758927214		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.08511940758927214 | validation: 0.06809874474855544]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219477791743482		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.10219477791743482 | validation: 0.09812628076679943]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10703112886224683		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.10703112886224683 | validation: 0.05719561761312975]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08343434080821589		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.08343434080821589 | validation: 0.05631509568333085]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601024685895513		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.08601024685895513 | validation: 0.06598268257766579]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08638409400929768		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.08638409400929768 | validation: 0.07526968125918526]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915052808852202		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.09915052808852202 | validation: 0.061803329020143905]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08525054412137033		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.08525054412137033 | validation: 0.06564779972783298]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820183622056422		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0820183622056422 | validation: 0.06529199230279648]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521533164478841		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.07521533164478841 | validation: 0.059380264964151865]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746749793875334		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.0746749793875334 | validation: 0.04889968972401525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1309.pth
	Model improved!!!
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324017470605698		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.07324017470605698 | validation: 0.05714207630667893]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176592264856504		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.07176592264856504 | validation: 0.07367555545384587]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07514310106503183		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.07514310106503183 | validation: 0.06068519000923658]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427846535410554		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.07427846535410554 | validation: 0.06776633917877757]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320064830372555		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.07320064830372555 | validation: 0.048683065660797116]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1314.pth
	Model improved!!!
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07513189730741227		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.07513189730741227 | validation: 0.07214166351368496]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08109641203925945		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.08109641203925945 | validation: 0.06476357406750853]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08094266707282316		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.08094266707282316 | validation: 0.07554272920079343]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142243009584228		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.08142243009584228 | validation: 0.05557654469100309]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07861240925187236		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.07861240925187236 | validation: 0.06420449322237039]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07267701211249272		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.07267701211249272 | validation: 0.06568503464676569]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08025224973594922		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.08025224973594922 | validation: 0.05723728587602924]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08353661968026584		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.08353661968026584 | validation: 0.07262303803584959]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607130865333861		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07607130865333861 | validation: 0.06847706117538956]
	TIME [epoch: 11.4 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877819266457307		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.07877819266457307 | validation: 0.062421981029782046]
	TIME [epoch: 11.4 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068749193816762		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.07068749193816762 | validation: 0.05474862178621228]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07601112294683354		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.07601112294683354 | validation: 0.057979072525465226]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164196457541722		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.07164196457541722 | validation: 0.06018255568687952]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751691249631395		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0751691249631395 | validation: 0.06470150982993095]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863645979238862		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.07863645979238862 | validation: 0.058336988232836264]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788104768740024		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.07788104768740024 | validation: 0.05997592362932205]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500190644950036		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.07500190644950036 | validation: 0.05805136917108561]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871565768617741		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.07871565768617741 | validation: 0.0649791262779657]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345147890446311		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.08345147890446311 | validation: 0.05846696842197391]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088760890490111		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.088760890490111 | validation: 0.06214032136754157]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09346623767738402		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.09346623767738402 | validation: 0.07848569522856565]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046934997740626		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.09046934997740626 | validation: 0.06061483292861436]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07777585890049821		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.07777585890049821 | validation: 0.051403111038168546]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07386283362577518		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.07386283362577518 | validation: 0.04890095176468762]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07793570518873784		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.07793570518873784 | validation: 0.050081305566085796]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07434562962725115		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.07434562962725115 | validation: 0.05483648596092612]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331058285004839		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.08331058285004839 | validation: 0.05449544931379355]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809643650478626		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.07809643650478626 | validation: 0.06298425614768295]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07696255001902803		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.07696255001902803 | validation: 0.08103936600424212]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08797315403088654		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.08797315403088654 | validation: 0.051734314430430715]
	TIME [epoch: 11.4 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752807018894561		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.07752807018894561 | validation: 0.05481056944376407]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07469688461872984		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.07469688461872984 | validation: 0.05945842763479758]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07228306976938698		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.07228306976938698 | validation: 0.0630915784431151]
	TIME [epoch: 11.4 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07785289184736953		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.07785289184736953 | validation: 0.0833943859766416]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07623497021021423		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.07623497021021423 | validation: 0.07310133416941957]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07559633152265693		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.07559633152265693 | validation: 0.07336735937928107]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563649634135587		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.07563649634135587 | validation: 0.06512451655941036]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378978304010275		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.07378978304010275 | validation: 0.07017144793206756]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691956885831369		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.07691956885831369 | validation: 0.05444911333629196]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081569705940477		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.07081569705940477 | validation: 0.06436612625231468]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07506666070882254		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.07506666070882254 | validation: 0.07511854223343951]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07454201358618012		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.07454201358618012 | validation: 0.05595617110511106]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723499054997014		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.0723499054997014 | validation: 0.05558517714410692]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912953502596544		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.06912953502596544 | validation: 0.06756606121374249]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763194205287545		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.0763194205287545 | validation: 0.0739253570128051]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580316981996203		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.07580316981996203 | validation: 0.05630539897246306]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07620108388055474		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.07620108388055474 | validation: 0.07008092260131914]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103065479464368		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.07103065479464368 | validation: 0.07121249244028674]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864444180688113		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.0864444180688113 | validation: 0.08820429824625592]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07608816997872969		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.07608816997872969 | validation: 0.07776141218658339]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225593793589065		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.07225593793589065 | validation: 0.06692637896092507]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07243855133934048		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.07243855133934048 | validation: 0.06363332750688987]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196512223463452		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08196512223463452 | validation: 0.07641463568600852]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08275497178504247		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.08275497178504247 | validation: 0.08092349444456737]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07325152697415613		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.07325152697415613 | validation: 0.07978137547643858]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07135600553122703		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.07135600553122703 | validation: 0.06342495478178492]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07216208444017468		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.07216208444017468 | validation: 0.05872967706382279]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06826335209605966		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.06826335209605966 | validation: 0.05694761233347375]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07395636588392024		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.07395636588392024 | validation: 0.08166815085233868]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07885771265092924		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.07885771265092924 | validation: 0.058852906230048435]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240355774929583		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.07240355774929583 | validation: 0.0621257456128157]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796834216015632		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06796834216015632 | validation: 0.05852103150544237]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075947572140555		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.07075947572140555 | validation: 0.05684009969903536]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06957767868259962		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06957767868259962 | validation: 0.05800778340329325]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06942468623014172		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.06942468623014172 | validation: 0.06390210554067981]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013827327910781		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.07013827327910781 | validation: 0.06794527696574737]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604781770433931		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.07604781770433931 | validation: 0.06875127164647973]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07249610906041723		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.07249610906041723 | validation: 0.07074718527835235]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445191839180926		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.07445191839180926 | validation: 0.07221489550811948]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.079108052341622		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.079108052341622 | validation: 0.059626991351876865]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731557868770007		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.0731557868770007 | validation: 0.05808140700738699]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751017389054655		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0751017389054655 | validation: 0.06113257108051085]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07255606307939327		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.07255606307939327 | validation: 0.058980982015548376]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07113597346407947		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.07113597346407947 | validation: 0.056011661937872756]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06886319087595315		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.06886319087595315 | validation: 0.06552276737212753]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07171264882832408		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.07171264882832408 | validation: 0.053415958664961335]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07318141646056697		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.07318141646056697 | validation: 0.05722909113665098]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752504587897469		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.07752504587897469 | validation: 0.05698179195989433]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07050209235862709		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.07050209235862709 | validation: 0.06277727577740452]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06830615150778611		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06830615150778611 | validation: 0.05742202863382191]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695584579375367		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.0695584579375367 | validation: 0.06536851634927376]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07061592708974494		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.07061592708974494 | validation: 0.06738730040419241]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961899711528687		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.06961899711528687 | validation: 0.06665692540451006]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06455198783394714		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06455198783394714 | validation: 0.0702312693368547]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822754625451746		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.06822754625451746 | validation: 0.06282644750852569]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869611787520422		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06869611787520422 | validation: 0.058220098948785326]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06950060676288941		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06950060676288941 | validation: 0.07142279361841278]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07309400621501938		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.07309400621501938 | validation: 0.075890803973149]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07496307740309596		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.07496307740309596 | validation: 0.06398421550040534]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717721863053218		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0717721863053218 | validation: 0.06468407508191151]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07241080380261268		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.07241080380261268 | validation: 0.05822377943710385]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07296926479965855		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.07296926479965855 | validation: 0.05149274995539802]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06718736172486257		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.06718736172486257 | validation: 0.06376699949980834]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181171259220669		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.07181171259220669 | validation: 0.05993455155927488]
	TIME [epoch: 11.4 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07212121581545573		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.07212121581545573 | validation: 0.05860852151841066]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07133471667236425		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.07133471667236425 | validation: 0.06439280995441549]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460662341428581		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.07460662341428581 | validation: 0.058143139195019414]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270914317233755		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.07270914317233755 | validation: 0.07046946725962058]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964463721960125		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.06964463721960125 | validation: 0.056110861716195296]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688864041443732		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.06688864041443732 | validation: 0.060903761764849414]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675819463010657		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.06675819463010657 | validation: 0.06273304995950602]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06881207963623992		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.06881207963623992 | validation: 0.07105625615427358]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07575476481022139		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.07575476481022139 | validation: 0.07355497596299772]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08136541083004642		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.08136541083004642 | validation: 0.06384703898450483]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07396865360225702		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.07396865360225702 | validation: 0.06354600302223443]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058640351914369		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.07058640351914369 | validation: 0.050626458520549686]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076295354497758		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.07076295354497758 | validation: 0.05436840595443929]
	TIME [epoch: 11.4 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925183551370778		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06925183551370778 | validation: 0.0661074033317731]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07019020442667448		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.07019020442667448 | validation: 0.06667525502533284]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765249026626876		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0765249026626876 | validation: 0.06579290795430177]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683169330074746		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0683169330074746 | validation: 0.062096185532224527]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912597441749765		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06912597441749765 | validation: 0.06288765691146528]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06770545099854924		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.06770545099854924 | validation: 0.05608694780913072]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889372002656352		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.06889372002656352 | validation: 0.05897545337155087]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727713619698787		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06727713619698787 | validation: 0.0545785459837397]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695434114883226		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.0695434114883226 | validation: 0.05861157527348731]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819861048097972		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06819861048097972 | validation: 0.05982935762702779]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142922949194691		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.07142922949194691 | validation: 0.05888449975573569]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711117710059189		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06711117710059189 | validation: 0.05353030905675911]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091028098831914		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.07091028098831914 | validation: 0.06836601340873177]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161785846922739		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.07161785846922739 | validation: 0.06061335078843191]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731896446335589		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0731896446335589 | validation: 0.06354947100079832]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159318776247839		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.07159318776247839 | validation: 0.06586481471960264]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07584977217924105		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.07584977217924105 | validation: 0.06464974572476857]
	TIME [epoch: 11.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467015448056288		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.07467015448056288 | validation: 0.06996100094576449]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351289835815947		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.07351289835815947 | validation: 0.05938926389802297]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023718136817401		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.07023718136817401 | validation: 0.05411279641950735]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755532409662768		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.0755532409662768 | validation: 0.055131029204858704]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324449632807498		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.07324449632807498 | validation: 0.06985940652639613]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439013721251697		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.07439013721251697 | validation: 0.05062082391957334]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07383273114501875		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.07383273114501875 | validation: 0.06069994164062524]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07362661670924824		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.07362661670924824 | validation: 0.06781743105313669]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07342675056502691		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.07342675056502691 | validation: 0.0591960601494737]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757534555603098		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.0757534555603098 | validation: 0.060261888352202496]
	TIME [epoch: 11.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750182740828493		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.07750182740828493 | validation: 0.05609579578849243]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441160524655921		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.07441160524655921 | validation: 0.06039754958203349]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724557576216732		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.0724557576216732 | validation: 0.05992970201483676]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042647374552218		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.07042647374552218 | validation: 0.05991968683029276]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063500607191724		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.07063500607191724 | validation: 0.053899758755111014]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07056368175641307		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.07056368175641307 | validation: 0.06502367679274335]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641846753779095		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.07641846753779095 | validation: 0.06315570980286399]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07365330509815397		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.07365330509815397 | validation: 0.055758476194680356]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07146492823072992		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.07146492823072992 | validation: 0.06685750070703919]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07370832513579256		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.07370832513579256 | validation: 0.07057488687545332]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277897418654045		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.07277897418654045 | validation: 0.06919465000069124]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711820664353795		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.07711820664353795 | validation: 0.06058702326254217]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890444791793149		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.06890444791793149 | validation: 0.06323316147505717]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07415376490138778		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.07415376490138778 | validation: 0.0679290846392592]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818341729021897		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.07818341729021897 | validation: 0.06110205209265366]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662546316091556		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.07662546316091556 | validation: 0.07954241189471796]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08173975309590405		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.08173975309590405 | validation: 0.07455737298901607]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823878449696302		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.07823878449696302 | validation: 0.06808591581465474]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07536680272334387		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.07536680272334387 | validation: 0.06709824533418633]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07446847911032567		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.07446847911032567 | validation: 0.0685697630229115]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870794584630056		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.07870794584630056 | validation: 0.07190699226996126]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374926641056649		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.08374926641056649 | validation: 0.07115308583299416]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537051602496879		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.07537051602496879 | validation: 0.06871851348726514]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07207359206976391		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.07207359206976391 | validation: 0.0508938691132904]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06933602280506564		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.06933602280506564 | validation: 0.06183503255071118]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602710280747456		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.07602710280747456 | validation: 0.06948924065092532]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297112263057065		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.07297112263057065 | validation: 0.058533580895107996]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298505294827587		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.07298505294827587 | validation: 0.06981744121243443]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080567763481343		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.080567763481343 | validation: 0.08040875110700375]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07808402696617917		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.07808402696617917 | validation: 0.06686545741641518]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07634351037335338		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.07634351037335338 | validation: 0.0688392426745292]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762535103004972		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.07762535103004972 | validation: 0.06666966239261608]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029066955604982		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.07029066955604982 | validation: 0.06041256024980683]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122770518808443		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.07122770518808443 | validation: 0.06659908109396805]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07483134537451419		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.07483134537451419 | validation: 0.06052384279053553]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06974419426917748		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.06974419426917748 | validation: 0.059960230350697856]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06834118642711566		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.06834118642711566 | validation: 0.0594466804020904]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07601652534681293		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.07601652534681293 | validation: 0.059006745628101084]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07766881947072006		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.07766881947072006 | validation: 0.0687060445050943]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0748638405614157		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.0748638405614157 | validation: 0.06636029007658455]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441133388919673		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.07441133388919673 | validation: 0.05584867174683396]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06981839888498821		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.06981839888498821 | validation: 0.05462349353575136]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07041392024148545		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.07041392024148545 | validation: 0.05446297400634515]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07043318783054063		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.07043318783054063 | validation: 0.05721779468241334]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094362708143402		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.07094362708143402 | validation: 0.06363036501123558]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07458032762665565		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.07458032762665565 | validation: 0.05554054219175946]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06931308139919751		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.06931308139919751 | validation: 0.05664281965904701]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163382738764418		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.07163382738764418 | validation: 0.05908662538716006]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304291711920831		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.07304291711920831 | validation: 0.06507740406938524]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761484695996101		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.07761484695996101 | validation: 0.0709775882022334]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07299941969291579		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.07299941969291579 | validation: 0.05196974748635643]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695337410176968		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0695337410176968 | validation: 0.06849888625043125]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07524527354735391		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.07524527354735391 | validation: 0.08954124178400083]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076246579275086		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.08076246579275086 | validation: 0.055499724485618226]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132725675277649		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.07132725675277649 | validation: 0.05286898525575339]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0694918202213464		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.0694918202213464 | validation: 0.05887809287148752]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999377629332906		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.06999377629332906 | validation: 0.06606898302192162]
	TIME [epoch: 11.4 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07213307660412452		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.07213307660412452 | validation: 0.06780749876417481]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07465582832211559		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.07465582832211559 | validation: 0.05904610854863949]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727844659982029		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.0727844659982029 | validation: 0.04877820323503217]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07188067415579073		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.07188067415579073 | validation: 0.04793947660100055]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1509.pth
	Model improved!!!
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460472655715157		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.07460472655715157 | validation: 0.05193258483626922]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237504434517364		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.07237504434517364 | validation: 0.05665291173563032]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07236982311903557		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.07236982311903557 | validation: 0.0711833898700868]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099801914687845		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.07099801914687845 | validation: 0.06413410814982712]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07875099681239668		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.07875099681239668 | validation: 0.05719236098833358]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06764459349135021		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.06764459349135021 | validation: 0.05526976011811171]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855281715194263		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.06855281715194263 | validation: 0.05721723969813725]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812085011242808		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.06812085011242808 | validation: 0.06186585586785187]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661120584068826		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0661120584068826 | validation: 0.06034321125199877]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666463993760666		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.06666463993760666 | validation: 0.05808125389350063]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06835687198399416		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.06835687198399416 | validation: 0.05312989678442469]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06981034840943767		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.06981034840943767 | validation: 0.0626973596251556]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978734505083847		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.06978734505083847 | validation: 0.06378403402743042]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099455521259784		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.07099455521259784 | validation: 0.05713495830031541]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518548141826586		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.06518548141826586 | validation: 0.0641080780905406]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06827934978054301		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.06827934978054301 | validation: 0.061884423949863425]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06953730121875179		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.06953730121875179 | validation: 0.05330708048405171]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797999067595008		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06797999067595008 | validation: 0.060766979657460654]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703810956743829		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0703810956743829 | validation: 0.07258579081090658]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07257694675272626		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.07257694675272626 | validation: 0.060199104977690786]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351106322320854		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.07351106322320854 | validation: 0.07515675044278335]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06957827926545504		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.06957827926545504 | validation: 0.07185391801783678]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555568758020233		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.07555568758020233 | validation: 0.06488391499893639]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07214762497542637		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.07214762497542637 | validation: 0.06955496666747306]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210888332493168		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.07210888332493168 | validation: 0.07124363862408109]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075722640831117		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.07075722640831117 | validation: 0.061687395657450496]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06940572997249345		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.06940572997249345 | validation: 0.05938974878328986]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07116273072847527		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.07116273072847527 | validation: 0.060758787531742]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0732770978234026		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.0732770978234026 | validation: 0.05813775243881597]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686367751577928		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.0686367751577928 | validation: 0.06679041430927475]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07061674671472731		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.07061674671472731 | validation: 0.06244162702506619]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06960086201335453		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.06960086201335453 | validation: 0.055861770010306434]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312301574010477		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.07312301574010477 | validation: 0.05859440121971398]
	TIME [epoch: 11.4 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07066683002087068		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.07066683002087068 | validation: 0.05750612951339004]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077330402722688		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.07077330402722688 | validation: 0.05705445110734342]
	TIME [epoch: 11.4 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06998613522690808		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.06998613522690808 | validation: 0.06452481852422441]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742972292220804		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.0742972292220804 | validation: 0.07141566494979978]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983901048656366		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.06983901048656366 | validation: 0.06200365199320577]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418345960808251		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.07418345960808251 | validation: 0.06094833200308072]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07640230454149353		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.07640230454149353 | validation: 0.07085630717233542]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06811281755749708		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.06811281755749708 | validation: 0.06629096907967712]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07157921953682829		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.07157921953682829 | validation: 0.06649447789457998]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06916306966958538		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.06916306966958538 | validation: 0.0678360667471227]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714207762692707		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.0714207762692707 | validation: 0.0701551358815037]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07386584388047773		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.07386584388047773 | validation: 0.053517545517409636]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819233378133377		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.06819233378133377 | validation: 0.06214289152418765]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07090251282153372		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.07090251282153372 | validation: 0.05353211677067323]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06924600743634358		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06924600743634358 | validation: 0.06333865931670259]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071792238963936		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.07071792238963936 | validation: 0.05642918665716734]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659774529000294		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0659774529000294 | validation: 0.06193221139136525]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926583217761034		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.06926583217761034 | validation: 0.06491130613159492]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602608786979078		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.06602608786979078 | validation: 0.0692610837173828]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0690075016729188		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.0690075016729188 | validation: 0.051141020582101106]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239956831236685		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.07239956831236685 | validation: 0.04923769119457522]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686696417958362		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.0686696417958362 | validation: 0.05914858978777717]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911463371611715		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.06911463371611715 | validation: 0.06477349663170949]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023703604187771		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.07023703604187771 | validation: 0.05466704046030437]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094868836576589		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.07094868836576589 | validation: 0.06863200560407848]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740565087831353		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0740565087831353 | validation: 0.05746338463749849]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06835606756061553		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.06835606756061553 | validation: 0.05674840411432958]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644279454009655		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.06644279454009655 | validation: 0.050183405494913985]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458301598884368		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.06458301598884368 | validation: 0.06605587368547047]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690127038628114		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.06690127038628114 | validation: 0.06060106733439059]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07090536846660081		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.07090536846660081 | validation: 0.067115946905189]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455931719214165		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.07455931719214165 | validation: 0.0667339349864873]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477831107070482		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.07477831107070482 | validation: 0.07035424833738457]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271301011672693		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.07271301011672693 | validation: 0.06893002588203985]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07018391623649736		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.07018391623649736 | validation: 0.06644234340082272]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07107408799971601		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.07107408799971601 | validation: 0.06259016555792796]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377351570352767		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.06377351570352767 | validation: 0.056512292043971554]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161009848513986		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.07161009848513986 | validation: 0.05488999237935398]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968561969882472		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.06968561969882472 | validation: 0.05344418810633954]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07155031520549746		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.07155031520549746 | validation: 0.059475810566035306]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979541360399662		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.06979541360399662 | validation: 0.061302287146267335]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766734920922299		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06766734920922299 | validation: 0.05117004391605158]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06565082695556075		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.06565082695556075 | validation: 0.06405972665162236]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615852379928461		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.06615852379928461 | validation: 0.058180852324179896]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717942085508612		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.06717942085508612 | validation: 0.05306156522380185]
	TIME [epoch: 11.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482375591451273		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.06482375591451273 | validation: 0.05114098094126989]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0718446273216131		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.0718446273216131 | validation: 0.05579894622543558]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06456750097756378		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.06456750097756378 | validation: 0.05383841976339492]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07049979565631527		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.07049979565631527 | validation: 0.05575181212893103]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672355230620817		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.0672355230620817 | validation: 0.04529665455886141]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1592.pth
	Model improved!!!
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06618450374086449		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.06618450374086449 | validation: 0.05236923235904131]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842327117521864		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.06842327117521864 | validation: 0.06456729231556892]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556431674184021		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.06556431674184021 | validation: 0.06272047292948599]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421114383442765		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.06421114383442765 | validation: 0.05991370663103803]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529120462200946		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.06529120462200946 | validation: 0.05922604334414383]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07079948338530347		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.07079948338530347 | validation: 0.06363543315693242]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657768520930676		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.0657768520930676 | validation: 0.058024597485862986]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566783155416239		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.06566783155416239 | validation: 0.05655198697198279]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06948269692905068		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.06948269692905068 | validation: 0.05614966380581844]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740401008305719		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06740401008305719 | validation: 0.0764451020192095]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265692991154335		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.07265692991154335 | validation: 0.06418075961821253]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252732259622675		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.07252732259622675 | validation: 0.06534328292292146]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07097771049911532		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.07097771049911532 | validation: 0.06713292219871746]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07109429773920853		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.07109429773920853 | validation: 0.06075273963525244]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000075938101108		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.07000075938101108 | validation: 0.062496961084532]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892888871494675		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.06892888871494675 | validation: 0.07149812047495005]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06618154951506203		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.06618154951506203 | validation: 0.05993570913974535]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807624000165868		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.06807624000165868 | validation: 0.058776999724293844]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664684299410533		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0664684299410533 | validation: 0.06048522126821336]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717621945740515		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.06717621945740515 | validation: 0.06151321174138967]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07442966222576552		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.07442966222576552 | validation: 0.07277748059457002]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973884035712589		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.07973884035712589 | validation: 0.0724683063133532]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07205236960582946		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.07205236960582946 | validation: 0.06272099315943332]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742488260076127		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0742488260076127 | validation: 0.061572619882093456]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07138709841411975		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.07138709841411975 | validation: 0.06859811834732737]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746380530515822		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.06746380530515822 | validation: 0.058266171514066836]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226808620444877		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.07226808620444877 | validation: 0.06382400451622296]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06970710232791645		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.06970710232791645 | validation: 0.06458779099801476]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744945555144073		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.06744945555144073 | validation: 0.06232543026783106]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06471538390145108		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.06471538390145108 | validation: 0.06345875879458758]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851024697839316		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.06851024697839316 | validation: 0.05723416184221655]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702667932149564		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.06702667932149564 | validation: 0.07047560584007395]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126101803224996		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.07126101803224996 | validation: 0.05832844661672145]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644342480752369		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.06644342480752369 | validation: 0.05167537881461213]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590607446702729		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.06590607446702729 | validation: 0.0633768533167283]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977930018122178		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.06977930018122178 | validation: 0.059751671190541054]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06878259267393001		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.06878259267393001 | validation: 0.055499609184389675]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06638397516342043		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.06638397516342043 | validation: 0.056879817157773814]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06183733706749597		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.06183733706749597 | validation: 0.059830991597951064]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06827997786869036		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.06827997786869036 | validation: 0.059007803123228404]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851335282744721		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.06851335282744721 | validation: 0.05981731782243998]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06973935104319895		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.06973935104319895 | validation: 0.061630080450411615]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411343636747477		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.06411343636747477 | validation: 0.05473170166456209]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06707011572167967		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.06707011572167967 | validation: 0.049790437131900095]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854994630691733		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.06854994630691733 | validation: 0.050978148834489576]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06794649391879437		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.06794649391879437 | validation: 0.05095828450090407]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07060440475100088		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.07060440475100088 | validation: 0.05428357264635399]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865860649403009		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.06865860649403009 | validation: 0.06775123457069882]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644740466489796		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.06644740466489796 | validation: 0.06050671609830193]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666597251042175		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0666597251042175 | validation: 0.063054482027862]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530550871549465		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.06530550871549465 | validation: 0.0582316056619719]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06655695627108704		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.06655695627108704 | validation: 0.0561109431838714]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703762309715747		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.06703762309715747 | validation: 0.05645962953573219]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529455819325955		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.06529455819325955 | validation: 0.06141648211242779]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06599252322088334		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.06599252322088334 | validation: 0.06536243582050698]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613651214654591		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.06613651214654591 | validation: 0.06884469061996566]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0668471753599576		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0668471753599576 | validation: 0.057444557421574095]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894029418712797		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.06894029418712797 | validation: 0.06438060485786921]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633220113686142		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.06633220113686142 | validation: 0.05241474737652599]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203828776586645		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.06203828776586645 | validation: 0.05896935643925239]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0688533270641099		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0688533270641099 | validation: 0.05943296093069225]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896080984235106		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.06896080984235106 | validation: 0.06426342939533256]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812670815414085		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.06812670815414085 | validation: 0.057870608454334345]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844957628860215		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.06844957628860215 | validation: 0.06228214131735341]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067064097628091		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.07067064097628091 | validation: 0.06528723577064359]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06680091725712019		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.06680091725712019 | validation: 0.05838553786449979]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609636143912384		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.06609636143912384 | validation: 0.04949078625458679]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06928567802818328		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.06928567802818328 | validation: 0.056347221992096054]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07146511433889802		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.07146511433889802 | validation: 0.05746936885588501]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977943834137439		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.06977943834137439 | validation: 0.05863882055599187]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07113339080661285		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.07113339080661285 | validation: 0.06453629260712804]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232917766773324		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07232917766773324 | validation: 0.05730840242931616]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816701631840939		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.06816701631840939 | validation: 0.052097482863645864]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642900584676406		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.0642900584676406 | validation: 0.05502311354887098]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589034703141873		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.06589034703141873 | validation: 0.050781158694961144]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06833161740545038		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.06833161740545038 | validation: 0.06158083386183478]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669145367637838		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.06669145367637838 | validation: 0.0605356528194139]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06823569723739903		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.06823569723739903 | validation: 0.047410202075286706]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787857351967572		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.06787857351967572 | validation: 0.05713141642200568]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629016446650778		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.06629016446650778 | validation: 0.0567810512125301]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06921466227440672		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.06921466227440672 | validation: 0.054482908522556085]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999645311535344		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.06999645311535344 | validation: 0.05694049097979842]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06733576046632835		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.06733576046632835 | validation: 0.0533369469173436]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701510820213633		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.06701510820213633 | validation: 0.053553210178730735]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07052825123625		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.07052825123625 | validation: 0.051526060468831014]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070181527132412		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.070181527132412 | validation: 0.0492449294392285]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714914866073445		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0714914866073445 | validation: 0.05350951890503306]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07190236366484336		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.07190236366484336 | validation: 0.04819161845162299]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896204048468724		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.06896204048468724 | validation: 0.05343510324770742]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651909667027693		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.0651909667027693 | validation: 0.049900744178390716]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936744656482019		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.06936744656482019 | validation: 0.060246933603228706]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862591958625264		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.06862591958625264 | validation: 0.06204009268632242]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272766129113369		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.07272766129113369 | validation: 0.06310503117918727]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206911516899006		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.07206911516899006 | validation: 0.05675680254062245]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608147985889759		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.06608147985889759 | validation: 0.05788420381446926]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07151242984776428		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.07151242984776428 | validation: 0.04898228318850153]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530599336362532		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.06530599336362532 | validation: 0.05275099978874325]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581528364097637		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.06581528364097637 | validation: 0.053693046425672845]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650980679403341		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.06650980679403341 | validation: 0.047290596366221155]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859964241221607		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.06859964241221607 | validation: 0.05870400512663631]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917739998828018		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.06917739998828018 | validation: 0.05541234928079417]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824680210125508		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.06824680210125508 | validation: 0.056651245958965576]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06452142864932346		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.06452142864932346 | validation: 0.05856531772945294]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161407006573892		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.07161407006573892 | validation: 0.05951865207736701]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06718027388183499		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.06718027388183499 | validation: 0.06014013699836399]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06904492286194949		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.06904492286194949 | validation: 0.051155589836182784]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06504400485161632		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.06504400485161632 | validation: 0.05737782498483842]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646717367891664		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.0646717367891664 | validation: 0.05538706673295962]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512104879948055		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.06512104879948055 | validation: 0.05822892146587281]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06384556343452046		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.06384556343452046 | validation: 0.054498931866673324]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647714648076833		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.0647714648076833 | validation: 0.058550642765641536]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388671744234191		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.06388671744234191 | validation: 0.06078035973020189]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774284641516282		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.06774284641516282 | validation: 0.048709806440359646]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612280566048714		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.06612280566048714 | validation: 0.05070099501716111]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06923987481547661		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.06923987481547661 | validation: 0.05579268304465059]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628963268526598		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.06628963268526598 | validation: 0.06061403814782576]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493004964851931		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.06493004964851931 | validation: 0.05719894850854011]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894628241894143		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.06894628241894143 | validation: 0.05692491270449966]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06825961203305587		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.06825961203305587 | validation: 0.05725418814075416]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06989013418376673		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.06989013418376673 | validation: 0.06272321846799271]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726695843553858		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.06726695843553858 | validation: 0.05804209915496109]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06795873555680937		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.06795873555680937 | validation: 0.055487367541924314]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590237927773508		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.06590237927773508 | validation: 0.05487918924423706]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458690761492221		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.06458690761492221 | validation: 0.058047307795272104]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749791506153163		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.06749791506153163 | validation: 0.05729678851773194]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602215818843139		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.06602215818843139 | validation: 0.05346323585462283]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06882426097736802		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.06882426097736802 | validation: 0.05061581087382492]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667057393778288		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.06667057393778288 | validation: 0.0603122143935984]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541291673570498		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.06541291673570498 | validation: 0.0599540251657688]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918123890273155		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.06918123890273155 | validation: 0.058449554122403685]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06507164867926198		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.06507164867926198 | validation: 0.05195019008377433]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06626418960035185		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.06626418960035185 | validation: 0.0513978060179559]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462368979389663		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.06462368979389663 | validation: 0.06086271108509073]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0652226584851959		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.0652226584851959 | validation: 0.05087006231217213]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06429254587422312		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.06429254587422312 | validation: 0.05572866460909572]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328661139756567		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.06328661139756567 | validation: 0.057056152229614576]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761770200886118		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.06761770200886118 | validation: 0.05773351386819673]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06751522669756098		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.06751522669756098 | validation: 0.05601102405789741]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703455967208224		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.06703455967208224 | validation: 0.046446465997776964]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06698947890633378		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.06698947890633378 | validation: 0.05649029235617609]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575252671890092		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.06575252671890092 | validation: 0.05876240675861127]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575802263759767		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.06575802263759767 | validation: 0.05754187680970414]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409759034724984		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.06409759034724984 | validation: 0.0549068499669111]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027302264983021		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.07027302264983021 | validation: 0.059118048152906964]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785729752268184		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.06785729752268184 | validation: 0.053782231296160714]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959844759698074		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.06959844759698074 | validation: 0.05532018282700864]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06906978225342486		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.06906978225342486 | validation: 0.06313771821116175]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702281485012762		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.06702281485012762 | validation: 0.05936507042534751]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968851324211983		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.06968851324211983 | validation: 0.06787803066793302]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746456425192027		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.06746456425192027 | validation: 0.0647168677673743]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641409873065435		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.06641409873065435 | validation: 0.06000049982882637]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06657789694617666		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.06657789694617666 | validation: 0.05813901879848143]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07109235272272617		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.07109235272272617 | validation: 0.0612652841984673]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613125130108867		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.06613125130108867 | validation: 0.06096759660551907]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0677643656125263		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0677643656125263 | validation: 0.07146230127618548]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686126802611797		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.06686126802611797 | validation: 0.06417415151998072]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575384842343239		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.06575384842343239 | validation: 0.06176902366032993]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029548218637362		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.07029548218637362 | validation: 0.056761010765156064]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676865753042276		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.06676865753042276 | validation: 0.05811066984627649]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544948080877028		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.06544948080877028 | validation: 0.05576312080756087]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609420408909536		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.06609420408909536 | validation: 0.05355544384271386]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586828545743417		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.06586828545743417 | validation: 0.04806050532800404]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656271358323367		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.0656271358323367 | validation: 0.05103376514199721]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787687563521819		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.06787687563521819 | validation: 0.05151128052752701]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642349915547294		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.0642349915547294 | validation: 0.05473410931483368]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06490741182240782		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.06490741182240782 | validation: 0.05816738368889318]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06329498472412877		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.06329498472412877 | validation: 0.05945292494569781]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259662270949497		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.06259662270949497 | validation: 0.060370155403467525]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513445735965541		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.06513445735965541 | validation: 0.05634128353976021]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06931963392703133		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.06931963392703133 | validation: 0.0543716535169201]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431402019699774		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.06431402019699774 | validation: 0.05131255423315602]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06773687097075892		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.06773687097075892 | validation: 0.04795685724400795]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529058889948433		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.06529058889948433 | validation: 0.06049758316302092]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06867162749973678		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.06867162749973678 | validation: 0.04877566472823641]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108838729214886		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.07108838729214886 | validation: 0.05630261517625251]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06762864630943707		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.06762864630943707 | validation: 0.056297724915167005]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06928862902001796		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.06928862902001796 | validation: 0.056662947244916044]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670369500870709		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.0670369500870709 | validation: 0.055570735945772186]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482722278633188		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.06482722278633188 | validation: 0.059059399134775196]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845477495254029		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.06845477495254029 | validation: 0.05833565621406372]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463375053839497		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.06463375053839497 | validation: 0.048814697014194997]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06782688592944343		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.06782688592944343 | validation: 0.05545730815651018]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766621232203904		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.06766621232203904 | validation: 0.04889062373544819]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335595069419238		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.06335595069419238 | validation: 0.06505511279948344]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06663966118126222		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.06663966118126222 | validation: 0.052254825457713955]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407971741338012		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.06407971741338012 | validation: 0.044336625086895766]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1778.pth
	Model improved!!!
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06473116471100812		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.06473116471100812 | validation: 0.04861684419749373]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514929797451274		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.06514929797451274 | validation: 0.05130662418559748]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675030325668263		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0675030325668263 | validation: 0.054927253360309174]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06369504251052903		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.06369504251052903 | validation: 0.05598996123832453]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646516283125445		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.06646516283125445 | validation: 0.0550023786461504]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06515061442511517		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.06515061442511517 | validation: 0.051953795771887246]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546816861331745		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.06546816861331745 | validation: 0.05661662184141519]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06674205061888121		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.06674205061888121 | validation: 0.050500739792413665]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651526633228797		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.0651526633228797 | validation: 0.050767949719948476]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06391775349820247		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.06391775349820247 | validation: 0.05262469085971276]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06418338742815212		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.06418338742815212 | validation: 0.052707024977799985]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06601306059429239		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.06601306059429239 | validation: 0.054919374092581616]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662365493974198		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0662365493974198 | validation: 0.04837309064975793]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656698344904555		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.0656698344904555 | validation: 0.05686130424767658]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600827590029303		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.06600827590029303 | validation: 0.051003812377199975]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644124349118362		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.06644124349118362 | validation: 0.05602167575504334]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06723652838574114		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.06723652838574114 | validation: 0.055526585489497425]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06795438741101614		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.06795438741101614 | validation: 0.05678551851161811]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688431582120657		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.06688431582120657 | validation: 0.057489074320637816]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943017504163149		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.06943017504163149 | validation: 0.04900687277321584]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655567885946472		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.0655567885946472 | validation: 0.054540276666449186]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06680850782762945		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.06680850782762945 | validation: 0.04900319200918469]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655257724677658		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0655257724677658 | validation: 0.04598846698498481]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06567413590272643		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.06567413590272643 | validation: 0.06058899945013828]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07026927355927327		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.07026927355927327 | validation: 0.05108268026568348]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389518657750325		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.06389518657750325 | validation: 0.058136903665653515]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325655356434307		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.06325655356434307 | validation: 0.056854805034662545]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06670525613834916		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.06670525613834916 | validation: 0.05182325774984349]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440555394088142		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.06440555394088142 | validation: 0.05683010892576038]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666475236401944		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.0666475236401944 | validation: 0.053244223230314594]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707191632212271		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0707191632212271 | validation: 0.056259057959753424]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842012948924758		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.06842012948924758 | validation: 0.05759546819649633]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575523135269232		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.06575523135269232 | validation: 0.05524872831105518]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716748368076803		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.06716748368076803 | validation: 0.05521653832951238]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865435960676289		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.06865435960676289 | validation: 0.05588127991782965]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637201184795694		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.06637201184795694 | validation: 0.058221557148012054]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304525184279944		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.06304525184279944 | validation: 0.059243693828103926]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448087333129088		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.06448087333129088 | validation: 0.06596926195293304]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07020583042565454		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.07020583042565454 | validation: 0.06307614977090624]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675555901028061		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.0675555901028061 | validation: 0.05756931671242141]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489771098677104		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.06489771098677104 | validation: 0.056361403955052056]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06815772804884536		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.06815772804884536 | validation: 0.058766811938619073]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06617809659483317		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.06617809659483317 | validation: 0.06325682615674123]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678234481417707		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.06678234481417707 | validation: 0.06134503047302335]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766559137032808		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.06766559137032808 | validation: 0.05098874457217513]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915880445224237		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.06915880445224237 | validation: 0.054239986255711456]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800579157735018		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.06800579157735018 | validation: 0.06318594469234673]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323257566530952		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.06323257566530952 | validation: 0.052696471590155454]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403406544276866		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.06403406544276866 | validation: 0.04902809410683911]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803502820835955		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.06803502820835955 | validation: 0.057441933901303345]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694039031819067		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.06694039031819067 | validation: 0.054277787655504874]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644720580459033		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0644720580459033 | validation: 0.052380538527473]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749002151213372		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.06749002151213372 | validation: 0.06198682111917258]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641009289417249		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.06641009289417249 | validation: 0.06199944915354474]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887724144906439		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.06887724144906439 | validation: 0.05005632603964541]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790634126605385		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.06790634126605385 | validation: 0.06090061270611195]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666896302039348		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.06666896302039348 | validation: 0.05499390449954857]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0668148747632938		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.0668148747632938 | validation: 0.05985400019570553]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872935758570566		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.06872935758570566 | validation: 0.05670384658326098]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909457219020596		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.06909457219020596 | validation: 0.053003684623595844]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597474951973142		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.06597474951973142 | validation: 0.06543754823888934]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606330301994412		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.06606330301994412 | validation: 0.05512490360395846]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06814072477338423		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.06814072477338423 | validation: 0.06094587602362975]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06712340538783178		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.06712340538783178 | validation: 0.06323025988082746]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06696728462314043		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.06696728462314043 | validation: 0.051073045861139976]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499274033182788		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.06499274033182788 | validation: 0.05773448947599102]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454010311003378		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.06454010311003378 | validation: 0.056409684982785244]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597894974906897		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.06597894974906897 | validation: 0.058476838342916254]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589288934727726		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.06589288934727726 | validation: 0.060501606603383114]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06326564234750535		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.06326564234750535 | validation: 0.05057671136417215]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714876090218866		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.06714876090218866 | validation: 0.05413906741062514]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842215362741202		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.06842215362741202 | validation: 0.056863073947421676]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266664963364901		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.06266664963364901 | validation: 0.05140797694678073]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06651028451264586		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.06651028451264586 | validation: 0.0433680147869103]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240309_135637/states/model_tr_study3_1852.pth
	Model improved!!!
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715414762309924		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.06715414762309924 | validation: 0.05549986403620389]
	TIME [epoch: 11.4 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06661101742832602		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.06661101742832602 | validation: 0.05614363009029216]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06598985262280038		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.06598985262280038 | validation: 0.05875186038947627]
	TIME [epoch: 11.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07078583477054559		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.07078583477054559 | validation: 0.05784961910100769]
	TIME [epoch: 11.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725226581174422		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.06725226581174422 | validation: 0.055599621121549224]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458183561567882		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.06458183561567882 | validation: 0.05794887178333246]
	TIME [epoch: 11.4 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502995002777684		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.06502995002777684 | validation: 0.056756144325379516]
	TIME [epoch: 11.4 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06523100550158059		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.06523100550158059 | validation: 0.050349077202263975]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655230037266688		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.0655230037266688 | validation: 0.05706567442478916]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06417419558119425		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.06417419558119425 | validation: 0.061088652063064526]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582917790135998		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.06582917790135998 | validation: 0.05266812593582527]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335775864031516		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.06335775864031516 | validation: 0.050691077586459826]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591663367159378		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.06591663367159378 | validation: 0.05639502620685926]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07044660926339578		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.07044660926339578 | validation: 0.058893206061161774]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932660993002888		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.06932660993002888 | validation: 0.05289664384560339]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641438974897111		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.06641438974897111 | validation: 0.05578383397356083]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06284912619950507		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.06284912619950507 | validation: 0.04521329189379076]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061975397972243176		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.061975397972243176 | validation: 0.05885049811726109]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706156507222703		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.06706156507222703 | validation: 0.05403841631317663]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640055889985487		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.06640055889985487 | validation: 0.05204922017008582]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715037519418969		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.06715037519418969 | validation: 0.05347785685132633]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667166668456928		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.0667166668456928 | validation: 0.057656992906637276]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06334731303924455		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.06334731303924455 | validation: 0.05512276265477923]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06710643869258906		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.06710643869258906 | validation: 0.05536347246322027]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262148225122689		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.06262148225122689 | validation: 0.05788745866242188]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501648207098265		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.06501648207098265 | validation: 0.048604673582691604]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06455458270353133		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.06455458270353133 | validation: 0.04880760653436138]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659596934165052		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.0659596934165052 | validation: 0.05522188871111466]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528773487025079		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.06528773487025079 | validation: 0.0494238043189795]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065444820620445		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.065444820620445 | validation: 0.053612201568851575]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061005112575224785		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.061005112575224785 | validation: 0.05809810925126234]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607141436376489		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.06607141436376489 | validation: 0.049567825214620935]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06653308233148959		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.06653308233148959 | validation: 0.05466653154867089]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634616281257677		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.0634616281257677 | validation: 0.050165525435408184]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06801929919888201		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.06801929919888201 | validation: 0.05377229042125117]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06465880437354743		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.06465880437354743 | validation: 0.053489617205008]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666408710496101		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.06666408710496101 | validation: 0.0471584532592383]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06789961145091128		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.06789961145091128 | validation: 0.05219405184343092]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
