Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3664623947

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.107827872879026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.107827872879026 | validation: 11.336695160277412]
	TIME [epoch: 48.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.379300456043392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.379300456043392 | validation: 9.247378515287727]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.261820879303226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.261820879303226 | validation: 9.875235306665834]
	TIME [epoch: 9.15 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.931581797242327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.931581797242327 | validation: 8.297837357520336]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.076319124205245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.076319124205245 | validation: 7.427166402521226]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.546283507394314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.546283507394314 | validation: 7.286208197972313]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.210743186142454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.210743186142454 | validation: 6.900156496046728]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.804481202255827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.804481202255827 | validation: 6.372417214604088]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.460981192484754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.460981192484754 | validation: 6.501421983112236]
	TIME [epoch: 9.17 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.254238106971307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.254238106971307 | validation: 6.034931933126666]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.986973315032219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.986973315032219 | validation: 5.953535363082768]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.818898903555962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.818898903555962 | validation: 5.935204759460529]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.853078128492249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.853078128492249 | validation: 5.801627956979367]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.887117695057114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.887117695057114 | validation: 5.615730870438892]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.98406464200262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.98406464200262 | validation: 5.747131848629422]
	TIME [epoch: 9.16 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.757288700710975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.757288700710975 | validation: 5.974887666880733]
	TIME [epoch: 9.17 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.0717441948672635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0717441948672635 | validation: 5.585002920076632]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.654332442710137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654332442710137 | validation: 5.426654023372949]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.175816958626534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.175816958626534 | validation: 8.044484941585363]
	TIME [epoch: 9.18 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.550915104058255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.550915104058255 | validation: 5.686636068205338]
	TIME [epoch: 9.17 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.378981560159767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.378981560159767 | validation: 5.210001288272739]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.365979469871732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.365979469871732 | validation: 5.030971066995402]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.121994373075178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.121994373075178 | validation: 5.2122252360871695]
	TIME [epoch: 9.19 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.072888685728985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.072888685728985 | validation: 4.919731155160353]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.893321222342432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.893321222342432 | validation: 4.685970703878194]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.710307763927245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.710307763927245 | validation: 4.822373270475573]
	TIME [epoch: 9.18 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.69887912887571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.69887912887571 | validation: 4.279844648316427]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.474626870718817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.474626870718817 | validation: 4.16056694027224]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2036588826038415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2036588826038415 | validation: 3.9899450878484846]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.188142762923583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.188142762923583 | validation: 4.026211808897717]
	TIME [epoch: 9.17 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.031085557644355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.031085557644355 | validation: 3.4950223539751857]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5254531490000085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5254531490000085 | validation: 3.41116639783399]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0537956500367733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0537956500367733 | validation: 2.7644560605026]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.906802982185293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.906802982185293 | validation: 2.844804828469209]
	TIME [epoch: 9.17 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8119728908769437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8119728908769437 | validation: 2.1739179052816318]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.461561313967933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.461561313967933 | validation: 2.125932919301505]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3803428781210867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3803428781210867 | validation: 2.3552845970250944]
	TIME [epoch: 9.19 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4564038015055725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4564038015055725 | validation: 2.1521664420038595]
	TIME [epoch: 9.16 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.336283739416295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.336283739416295 | validation: 2.1097301309563434]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1733986382266233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1733986382266233 | validation: 1.8355764821606342]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9646864112144722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9646864112144722 | validation: 2.3271446056082263]
	TIME [epoch: 9.19 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.056219843253491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.056219843253491 | validation: 1.8413442336399601]
	TIME [epoch: 9.19 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7235204814952236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7235204814952236 | validation: 1.5906661207034447]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3049261994396275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3049261994396275 | validation: 3.599531519491733]
	TIME [epoch: 9.18 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1175314424090965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1175314424090965 | validation: 1.7826504612415355]
	TIME [epoch: 9.2 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.73557557330819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.73557557330819 | validation: 1.3481491039008033]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0423192833771764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0423192833771764 | validation: 2.479802968179605]
	TIME [epoch: 9.19 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.269684924071264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.269684924071264 | validation: 2.0267348493728132]
	TIME [epoch: 9.19 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2197527644192507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2197527644192507 | validation: 2.982816430581608]
	TIME [epoch: 9.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3299065950861926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3299065950861926 | validation: 2.5573848282615295]
	TIME [epoch: 9.22 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.303049892752844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.303049892752844 | validation: 2.1267332124709233]
	TIME [epoch: 9.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1578979331272343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1578979331272343 | validation: 1.539985763709863]
	TIME [epoch: 9.18 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7156188562408108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7156188562408108 | validation: 1.342323637188326]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.759907180510916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.759907180510916 | validation: 1.7919301347446184]
	TIME [epoch: 9.18 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9603772223865445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9603772223865445 | validation: 3.554355187462731]
	TIME [epoch: 9.21 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0969705256493776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0969705256493776 | validation: 1.4503383674650134]
	TIME [epoch: 9.19 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.787569383634991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.787569383634991 | validation: 1.2927453967313078]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7681401589930494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7681401589930494 | validation: 1.3042626959930075]
	TIME [epoch: 9.19 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6350823857346228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6350823857346228 | validation: 2.021066578943472]
	TIME [epoch: 9.19 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6562570418448377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6562570418448377 | validation: 1.63292727430809]
	TIME [epoch: 9.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7452776506072811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7452776506072811 | validation: 1.4591876870215486]
	TIME [epoch: 9.16 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.648829402309044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.648829402309044 | validation: 1.1240482266556344]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7270720192382192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7270720192382192 | validation: 1.669559567614951]
	TIME [epoch: 9.16 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.12431963878106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.12431963878106 | validation: 1.9557819678781048]
	TIME [epoch: 9.17 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0256141711907345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0256141711907345 | validation: 1.890016189634898]
	TIME [epoch: 9.17 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2147752354370693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2147752354370693 | validation: 1.9860970830209732]
	TIME [epoch: 9.15 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9005588941809364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9005588941809364 | validation: 2.0222580456082384]
	TIME [epoch: 9.17 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9315760563917084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9315760563917084 | validation: 1.2938512237655395]
	TIME [epoch: 9.16 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.728681166080402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.728681166080402 | validation: 1.3796018808101302]
	TIME [epoch: 9.17 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4436656017844383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4436656017844383 | validation: 2.1163480042130987]
	TIME [epoch: 9.16 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4163458792869241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4163458792869241 | validation: 1.0576847703216463]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.050454854556693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.050454854556693 | validation: 1.3416857093725918]
	TIME [epoch: 9.16 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4037139872975815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4037139872975815 | validation: 1.2708389464720702]
	TIME [epoch: 9.19 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3810771895297629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3810771895297629 | validation: 1.0601190481024552]
	TIME [epoch: 9.18 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0289340805325744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0289340805325744 | validation: 1.104001439996639]
	TIME [epoch: 9.18 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3989221919538373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3989221919538373 | validation: 1.6239444696374679]
	TIME [epoch: 9.18 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6186047666735903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6186047666735903 | validation: 1.1373347612855866]
	TIME [epoch: 9.17 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6054945756775663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6054945756775663 | validation: 1.3967769258031282]
	TIME [epoch: 9.18 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7751707164743138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7751707164743138 | validation: 2.191812841429904]
	TIME [epoch: 9.15 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9984797947754847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9984797947754847 | validation: 1.8711470868417317]
	TIME [epoch: 9.15 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8867750011483455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8867750011483455 | validation: 2.026424025328294]
	TIME [epoch: 9.16 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7408237591184839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7408237591184839 | validation: 1.7308107083720055]
	TIME [epoch: 9.17 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.115488388870467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.115488388870467 | validation: 1.3768794282284185]
	TIME [epoch: 9.17 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5608173406483232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5608173406483232 | validation: 2.0156761917747175]
	TIME [epoch: 9.16 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0383915588968433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0383915588968433 | validation: 2.276178294777289]
	TIME [epoch: 9.18 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7868942564812862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7868942564812862 | validation: 1.4108094712662613]
	TIME [epoch: 9.17 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5205647811440355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5205647811440355 | validation: 1.6427251883771503]
	TIME [epoch: 9.18 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9722042207401205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9722042207401205 | validation: 5.915445482509107]
	TIME [epoch: 9.17 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.834939337507368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834939337507368 | validation: 5.9419934529953355]
	TIME [epoch: 9.17 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.781897685873824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.781897685873824 | validation: 5.854651324849005]
	TIME [epoch: 9.18 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.001492565937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.001492565937 | validation: 5.7616032334658005]
	TIME [epoch: 9.17 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.730935524790832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.730935524790832 | validation: 5.852460643547631]
	TIME [epoch: 9.18 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.727284320135099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.727284320135099 | validation: 5.645085860948839]
	TIME [epoch: 9.17 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.056801427969951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.056801427969951 | validation: 5.921834313431512]
	TIME [epoch: 9.17 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.772935235535222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.772935235535222 | validation: 5.654967601752871]
	TIME [epoch: 9.16 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.842563792443474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.842563792443474 | validation: 5.655935921913193]
	TIME [epoch: 9.18 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.739599700767382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.739599700767382 | validation: 5.661632923015935]
	TIME [epoch: 9.17 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6531334394502455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6531334394502455 | validation: 5.832070786058255]
	TIME [epoch: 9.16 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.8406169897142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8406169897142 | validation: 4.302463111523314]
	TIME [epoch: 9.18 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6135687007946964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6135687007946964 | validation: 1.4475714695464712]
	TIME [epoch: 9.17 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5863509435281578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5863509435281578 | validation: 1.5194354240570438]
	TIME [epoch: 9.18 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6945058490399265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6945058490399265 | validation: 2.405710257294041]
	TIME [epoch: 9.17 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7631211714170327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7631211714170327 | validation: 1.8232095167050684]
	TIME [epoch: 9.18 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8812007046883916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8812007046883916 | validation: 1.555531538628951]
	TIME [epoch: 9.18 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9107742125740674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9107742125740674 | validation: 1.1501512882411205]
	TIME [epoch: 9.19 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2701043296872563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2701043296872563 | validation: 1.5743812663142913]
	TIME [epoch: 9.18 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4742764164999067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4742764164999067 | validation: 1.0435185599161831]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2993537174948018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2993537174948018 | validation: 0.9662421711470786]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6580198047735177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6580198047735177 | validation: 1.3969818052758842]
	TIME [epoch: 9.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.629671911367605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.629671911367605 | validation: 1.118517646437356]
	TIME [epoch: 9.19 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2822447070910488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2822447070910488 | validation: 2.1240414331533017]
	TIME [epoch: 9.19 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3693439331254762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3693439331254762 | validation: 1.092557368834258]
	TIME [epoch: 9.18 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6339937051397002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6339937051397002 | validation: 1.7957081055126702]
	TIME [epoch: 9.19 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.386905753133976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.386905753133976 | validation: 2.1940420209302296]
	TIME [epoch: 9.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.076022523128622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.076022523128622 | validation: 2.6371639350476626]
	TIME [epoch: 9.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6848295763619592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6848295763619592 | validation: 1.2434087012348443]
	TIME [epoch: 9.19 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5725489966230781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5725489966230781 | validation: 2.199924834814916]
	TIME [epoch: 9.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.076342249327707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.076342249327707 | validation: 1.7395073778143069]
	TIME [epoch: 9.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4262162193549819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4262162193549819 | validation: 1.151533109056059]
	TIME [epoch: 9.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.674674166741697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.674674166741697 | validation: 1.416771904491072]
	TIME [epoch: 9.19 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.153725311061587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.153725311061587 | validation: 0.9315906749860026]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9021935798166587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9021935798166587 | validation: 1.0107611648273476]
	TIME [epoch: 9.17 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.142729463953473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.142729463953473 | validation: 0.8313349258399283]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1873042589709084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1873042589709084 | validation: 1.21110989243441]
	TIME [epoch: 9.18 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2587458591278213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2587458591278213 | validation: 0.8040940593634658]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0376732975864902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0376732975864902 | validation: 0.6991787623258677]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0137172474379028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0137172474379028 | validation: 2.2056702144877858]
	TIME [epoch: 9.19 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8040852566332415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8040852566332415 | validation: 5.725584878045961]
	TIME [epoch: 9.19 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.761024913356732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.761024913356732 | validation: 5.564084965359962]
	TIME [epoch: 9.19 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.744989945158801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.744989945158801 | validation: 5.774090095586219]
	TIME [epoch: 9.17 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.74731793003527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.74731793003527 | validation: 5.5158060344935205]
	TIME [epoch: 9.17 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.9947559446550605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9947559446550605 | validation: 5.859139025794411]
	TIME [epoch: 9.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.7537540676331655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7537540676331655 | validation: 6.282334118303021]
	TIME [epoch: 9.18 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.813235980100698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.813235980100698 | validation: 5.687432011452575]
	TIME [epoch: 9.17 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.734529631798222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.734529631798222 | validation: 5.831771360613688]
	TIME [epoch: 9.17 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.479918621622739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.479918621622739 | validation: 1.1425804146427678]
	TIME [epoch: 9.18 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5008519276775583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5008519276775583 | validation: 1.3084722561170192]
	TIME [epoch: 9.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6052422570742917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6052422570742917 | validation: 1.3617349642007759]
	TIME [epoch: 9.19 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5499978587923902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5499978587923902 | validation: 0.974473210374401]
	TIME [epoch: 9.18 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4201393218043419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4201393218043419 | validation: 1.6424687875215853]
	TIME [epoch: 9.17 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1798705043571633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1798705043571633 | validation: 0.8707694959206853]
	TIME [epoch: 9.19 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4121404839869496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4121404839869496 | validation: 1.0937431291914597]
	TIME [epoch: 9.17 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.502512971326289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.502512971326289 | validation: 0.878129125986069]
	TIME [epoch: 9.18 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0614132459458816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0614132459458816 | validation: 1.1031979906931273]
	TIME [epoch: 9.17 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.078247959880495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.078247959880495 | validation: 0.706002440608029]
	TIME [epoch: 9.19 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2298270720492428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2298270720492428 | validation: 0.656274800969786]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2039619572769145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2039619572769145 | validation: 1.1707916288262719]
	TIME [epoch: 9.18 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.598043674530912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.598043674530912 | validation: 2.414081750401544]
	TIME [epoch: 9.18 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9364569708767445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9364569708767445 | validation: 0.6311148475076239]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.131810094128304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.131810094128304 | validation: 1.421115396099297]
	TIME [epoch: 9.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.214233743649867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.214233743649867 | validation: 1.5646780602062489]
	TIME [epoch: 9.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8412369746371504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8412369746371504 | validation: 0.9322782267053484]
	TIME [epoch: 9.19 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3461361223053812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3461361223053812 | validation: 1.1008735357374795]
	TIME [epoch: 9.19 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3834384839645704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3834384839645704 | validation: 1.353981026965914]
	TIME [epoch: 9.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2018102448857437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2018102448857437 | validation: 1.1444824708624441]
	TIME [epoch: 9.22 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.125698849068193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.125698849068193 | validation: 1.4446387813590411]
	TIME [epoch: 9.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7761659622991133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7761659622991133 | validation: 1.0303071662059684]
	TIME [epoch: 9.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.331589929616827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.331589929616827 | validation: 1.1242302545632523]
	TIME [epoch: 9.21 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2504897594903865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2504897594903865 | validation: 0.8921879119542535]
	TIME [epoch: 9.21 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.090118294547186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.090118294547186 | validation: 4.732915207281948]
	TIME [epoch: 9.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6176382909278781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6176382909278781 | validation: 0.9433488952425317]
	TIME [epoch: 9.19 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.339578766968551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.339578766968551 | validation: 2.046928478829328]
	TIME [epoch: 9.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0459880398952874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0459880398952874 | validation: 4.282167513178111]
	TIME [epoch: 9.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.221716189245309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.221716189245309 | validation: 1.6903908524239353]
	TIME [epoch: 9.22 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8641587901166239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8641587901166239 | validation: 1.9081817037047055]
	TIME [epoch: 9.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.565018643213573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.565018643213573 | validation: 2.057102421302005]
	TIME [epoch: 9.21 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2875020206936514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2875020206936514 | validation: 1.7386945481949092]
	TIME [epoch: 9.19 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3091921337193857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3091921337193857 | validation: 2.259049007491531]
	TIME [epoch: 9.21 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7865717453131509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7865717453131509 | validation: 1.7525401888796137]
	TIME [epoch: 9.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2379459790093301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2379459790093301 | validation: 1.0597133406001624]
	TIME [epoch: 9.19 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5003494930830437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5003494930830437 | validation: 2.07796332027236]
	TIME [epoch: 9.19 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2560713005662545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2560713005662545 | validation: 0.6786822167637967]
	TIME [epoch: 9.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.003193098205443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.003193098205443 | validation: 0.9612480016878107]
	TIME [epoch: 9.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0247632543446303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0247632543446303 | validation: 1.1841207916044614]
	TIME [epoch: 9.19 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.253865277015216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.253865277015216 | validation: 2.1126273579373653]
	TIME [epoch: 9.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1058150748588984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1058150748588984 | validation: 0.8551895333344737]
	TIME [epoch: 9.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9146650685013851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9146650685013851 | validation: 0.601775849983962]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9530799663982282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9530799663982282 | validation: 0.8009863223784748]
	TIME [epoch: 9.23 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9664333670201583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9664333670201583 | validation: 4.4707150277652365]
	TIME [epoch: 9.21 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.012678273319101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.012678273319101 | validation: 1.574807030162546]
	TIME [epoch: 9.22 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.675848253511901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.675848253511901 | validation: 1.5318432900813836]
	TIME [epoch: 9.22 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6612142714974685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6612142714974685 | validation: 1.4284192754073075]
	TIME [epoch: 9.24 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3032588370088645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3032588370088645 | validation: 0.9340254646625643]
	TIME [epoch: 9.22 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.181345533004642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.181345533004642 | validation: 1.1734493766445335]
	TIME [epoch: 9.21 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1317571544084992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1317571544084992 | validation: 0.9782463931087592]
	TIME [epoch: 9.21 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9474817703020209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9474817703020209 | validation: 0.665081312034911]
	TIME [epoch: 9.21 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.929416958276699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.929416958276699 | validation: 0.9893905175990101]
	TIME [epoch: 9.22 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.992883550264267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.992883550264267 | validation: 0.7436092005074455]
	TIME [epoch: 9.21 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2386884401596803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2386884401596803 | validation: 1.2368035191192548]
	TIME [epoch: 9.21 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2238715583255315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2238715583255315 | validation: 0.7572373578040752]
	TIME [epoch: 9.21 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4238304924534402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4238304924534402 | validation: 0.8281039333649025]
	TIME [epoch: 9.24 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5436309520437743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5436309520437743 | validation: 0.8066517230808334]
	TIME [epoch: 9.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0256751521292196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0256751521292196 | validation: 1.754103754101092]
	TIME [epoch: 9.21 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3108496824999292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3108496824999292 | validation: 1.1604464713762503]
	TIME [epoch: 9.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9078057252301015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9078057252301015 | validation: 1.4341594172631056]
	TIME [epoch: 9.22 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4167417993717675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4167417993717675 | validation: 0.7831111893298613]
	TIME [epoch: 9.22 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8856151768077962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8856151768077962 | validation: 1.9518113404592803]
	TIME [epoch: 9.21 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.284809531962958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.284809531962958 | validation: 1.8346656951725873]
	TIME [epoch: 9.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2893123929343535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2893123929343535 | validation: 1.0134631442218782]
	TIME [epoch: 9.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5362532600010153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5362532600010153 | validation: 1.6884955683833107]
	TIME [epoch: 9.22 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0909890017549566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0909890017549566 | validation: 1.1785477673288267]
	TIME [epoch: 9.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1431578583176814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1431578583176814 | validation: 1.4484995604349558]
	TIME [epoch: 9.21 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6075798867569522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6075798867569522 | validation: 1.83597892260621]
	TIME [epoch: 9.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.638786283461469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.638786283461469 | validation: 0.9462781737762556]
	TIME [epoch: 9.22 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8703269215689199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8703269215689199 | validation: 0.5949458635702171]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3777449979890772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3777449979890772 | validation: 0.8841287856514181]
	TIME [epoch: 9.19 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0698002639570667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0698002639570667 | validation: 0.7849634529211732]
	TIME [epoch: 9.23 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8418555712548498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8418555712548498 | validation: 0.9123313413992198]
	TIME [epoch: 9.22 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1037350668626393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1037350668626393 | validation: 1.4096433296179125]
	TIME [epoch: 9.24 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9980103255767856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9980103255767856 | validation: 0.840091218078319]
	TIME [epoch: 9.22 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8869000083397165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8869000083397165 | validation: 1.1532946530831405]
	TIME [epoch: 9.21 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.983068134006527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.983068134006527 | validation: 0.6913411959294682]
	TIME [epoch: 9.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1291629177170976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1291629177170976 | validation: 0.9464171593005031]
	TIME [epoch: 9.21 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8385163458938582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8385163458938582 | validation: 0.9487843154499258]
	TIME [epoch: 9.22 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0054523226504775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0054523226504775 | validation: 0.633582268648919]
	TIME [epoch: 9.22 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9360297722309193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9360297722309193 | validation: 0.971952919363432]
	TIME [epoch: 9.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8431022868567382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8431022868567382 | validation: 0.7065611525474522]
	TIME [epoch: 9.18 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8004630778212908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8004630778212908 | validation: 0.7145855116756643]
	TIME [epoch: 9.23 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8007447440878306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8007447440878306 | validation: 0.9036979559484764]
	TIME [epoch: 9.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0127652535447838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0127652535447838 | validation: 0.8818611655344866]
	TIME [epoch: 9.21 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7923075493244817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7923075493244817 | validation: 0.7906162177393669]
	TIME [epoch: 9.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7986130131713487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7986130131713487 | validation: 0.6342024459160349]
	TIME [epoch: 9.19 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7742310279394258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7742310279394258 | validation: 0.5397181414425778]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6895784523106454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6895784523106454 | validation: 2.2677366329749384]
	TIME [epoch: 9.18 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1186606526313772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1186606526313772 | validation: 1.394739193027996]
	TIME [epoch: 9.18 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6074192196376664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6074192196376664 | validation: 0.746706577165708]
	TIME [epoch: 9.18 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7331776976354651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7331776976354651 | validation: 0.5799360481630648]
	TIME [epoch: 9.21 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1097734740993765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1097734740993765 | validation: 0.5598601388770684]
	TIME [epoch: 9.21 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8959731316511057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8959731316511057 | validation: 1.1196663500644939]
	TIME [epoch: 9.21 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.074549506704509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.074549506704509 | validation: 1.1328109328524483]
	TIME [epoch: 9.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7801747988480755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7801747988480755 | validation: 0.5752177682428843]
	TIME [epoch: 9.21 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7159071953665979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7159071953665979 | validation: 1.0873396794524095]
	TIME [epoch: 9.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7464030580753617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7464030580753617 | validation: 0.5239794909020216]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8989228066542727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8989228066542727 | validation: 0.7396920586456268]
	TIME [epoch: 9.22 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8232046215660901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8232046215660901 | validation: 0.9387146906700066]
	TIME [epoch: 9.23 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8977303562112633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8977303562112633 | validation: 0.7482205030219905]
	TIME [epoch: 9.24 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1789225078220273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1789225078220273 | validation: 1.0421606380000052]
	TIME [epoch: 9.23 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9853753439995199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9853753439995199 | validation: 0.5334641194454872]
	TIME [epoch: 9.21 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3178490037850188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3178490037850188 | validation: 0.9366125437906568]
	TIME [epoch: 9.24 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2428840171863635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2428840171863635 | validation: 0.796170316967448]
	TIME [epoch: 9.22 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0040140761815146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0040140761815146 | validation: 1.1255601833969564]
	TIME [epoch: 9.25 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9764176287845793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9764176287845793 | validation: 0.6964117241028962]
	TIME [epoch: 9.23 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9664093097611988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9664093097611988 | validation: 0.8329960529854201]
	TIME [epoch: 9.22 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0058853712382028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0058853712382028 | validation: 0.6301209416267524]
	TIME [epoch: 9.23 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9254999368818384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9254999368818384 | validation: 0.5686464760914016]
	TIME [epoch: 9.24 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.787947383421775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.787947383421775 | validation: 1.4008835048385369]
	TIME [epoch: 9.23 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0870805176188532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0870805176188532 | validation: 0.5717465310914767]
	TIME [epoch: 9.23 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8024158919962163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8024158919962163 | validation: 0.5980967320772618]
	TIME [epoch: 9.23 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0056619013260684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0056619013260684 | validation: 0.6956795330272577]
	TIME [epoch: 9.24 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6920759444207489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6920759444207489 | validation: 0.4904040553026074]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8733835771748547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8733835771748547 | validation: 1.1614759388122597]
	TIME [epoch: 9.22 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9830246258121218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9830246258121218 | validation: 0.4456311466546915]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6772271336410178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6772271336410178 | validation: 0.7041970944162312]
	TIME [epoch: 9.21 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.825209464026415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.825209464026415 | validation: 0.8038803659482989]
	TIME [epoch: 9.25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8083986654739125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8083986654739125 | validation: 0.6840568491987202]
	TIME [epoch: 9.21 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0591184267658829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0591184267658829 | validation: 1.1677203446783309]
	TIME [epoch: 9.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0076121535465077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0076121535465077 | validation: 0.4237321206093941]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8286802956714056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8286802956714056 | validation: 0.900407327402195]
	TIME [epoch: 9.23 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7805069789960959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7805069789960959 | validation: 0.4200822973456107]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9117373428641468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9117373428641468 | validation: 1.2186192413495385]
	TIME [epoch: 9.22 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1569115900027234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1569115900027234 | validation: 0.6603615476365792]
	TIME [epoch: 9.22 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3038524819798067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3038524819798067 | validation: 0.8440666947773852]
	TIME [epoch: 9.21 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7958865359649531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7958865359649531 | validation: 0.729405838474402]
	TIME [epoch: 9.21 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7976477389577323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7976477389577323 | validation: 1.2251964616037911]
	TIME [epoch: 9.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7939719145116765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7939719145116765 | validation: 0.45907175847275494]
	TIME [epoch: 9.21 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7641341829391597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7641341829391597 | validation: 0.5721033428914128]
	TIME [epoch: 9.22 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8003071849611768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8003071849611768 | validation: 0.6924834050145117]
	TIME [epoch: 9.21 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6528167111833474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6528167111833474 | validation: 0.6532370758224819]
	TIME [epoch: 9.23 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7343972723331084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7343972723331084 | validation: 0.7145546753240084]
	TIME [epoch: 9.22 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7015844480302184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7015844480302184 | validation: 0.39784557511241525]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7994874758695031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7994874758695031 | validation: 0.8611559033675381]
	TIME [epoch: 9.19 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.819156482212264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.819156482212264 | validation: 0.5345630824391001]
	TIME [epoch: 9.17 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8107766240539588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8107766240539588 | validation: 0.688008021322276]
	TIME [epoch: 9.06 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447145042780994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7447145042780994 | validation: 0.7666258564360164]
	TIME [epoch: 9.14 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7463554045034921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7463554045034921 | validation: 0.9201360700266079]
	TIME [epoch: 9.14 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.933852528711739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.933852528711739 | validation: 2.3216371227498183]
	TIME [epoch: 9.17 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2064664847217543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2064664847217543 | validation: 0.8745029977127365]
	TIME [epoch: 9.19 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6981268926943182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6981268926943182 | validation: 1.920528875807856]
	TIME [epoch: 9.11 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8959126805021368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8959126805021368 | validation: 0.7575129185223715]
	TIME [epoch: 9.17 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0025852027141746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0025852027141746 | validation: 1.0068770691999878]
	TIME [epoch: 9.19 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6548789409973856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6548789409973856 | validation: 0.7804380718472639]
	TIME [epoch: 9.21 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7256281085208551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7256281085208551 | validation: 0.7052413764478385]
	TIME [epoch: 9.19 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1648254526203068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1648254526203068 | validation: 0.7902019637903303]
	TIME [epoch: 9.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8725134827780183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8725134827780183 | validation: 0.4821706004197651]
	TIME [epoch: 9.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.68830433027692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.68830433027692 | validation: 0.5954226062304115]
	TIME [epoch: 9.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0322218072601363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0322218072601363 | validation: 0.5319959262538021]
	TIME [epoch: 9.22 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7959940775366674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7959940775366674 | validation: 0.4457011644255243]
	TIME [epoch: 9.19 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7674030369110155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7674030369110155 | validation: 0.5784387644485851]
	TIME [epoch: 9.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.635151135009345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.635151135009345 | validation: 0.9085818772907113]
	TIME [epoch: 9.19 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6511015523511496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6511015523511496 | validation: 0.6335670249308363]
	TIME [epoch: 9.22 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0624789584099605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0624789584099605 | validation: 0.6529316836989764]
	TIME [epoch: 9.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6147642876378708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6147642876378708 | validation: 0.373801502181626]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6790552840683587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6790552840683587 | validation: 0.5047300950190877]
	TIME [epoch: 9.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7711075381202193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7711075381202193 | validation: 0.3942272427040815]
	TIME [epoch: 9.19 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7898390941743151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7898390941743151 | validation: 0.6066779811933878]
	TIME [epoch: 9.21 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7074911742246227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7074911742246227 | validation: 0.5179313737094721]
	TIME [epoch: 9.21 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5835243766201722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5835243766201722 | validation: 0.4784163231117854]
	TIME [epoch: 9.21 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.693471947909583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.693471947909583 | validation: 0.5562294292472924]
	TIME [epoch: 9.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8093977221706611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8093977221706611 | validation: 0.645391385715619]
	TIME [epoch: 9.22 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6520171301353255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6520171301353255 | validation: 0.4861210231363019]
	TIME [epoch: 9.19 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7480411379369729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7480411379369729 | validation: 0.526339070610343]
	TIME [epoch: 9.21 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7243035229959124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7243035229959124 | validation: 0.443177311605514]
	TIME [epoch: 9.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7782160140592039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7782160140592039 | validation: 1.0977502377012516]
	TIME [epoch: 9.19 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9684121180874936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9684121180874936 | validation: 0.7999653586864948]
	TIME [epoch: 9.22 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7846082257107756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7846082257107756 | validation: 0.8419448948603757]
	TIME [epoch: 9.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8731801299421026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8731801299421026 | validation: 0.892986113791362]
	TIME [epoch: 9.21 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7025515295829826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7025515295829826 | validation: 0.4807337373168542]
	TIME [epoch: 9.19 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6569027503875347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6569027503875347 | validation: 0.5190905783640478]
	TIME [epoch: 9.21 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5204087918071892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5204087918071892 | validation: 0.8426420553614412]
	TIME [epoch: 9.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7488602446115159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7488602446115159 | validation: 0.9358663259614661]
	TIME [epoch: 9.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7499704116209068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7499704116209068 | validation: 0.38358150080511677]
	TIME [epoch: 9.19 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7230896686353206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7230896686353206 | validation: 0.7715691547320056]
	TIME [epoch: 9.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8412290594941801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8412290594941801 | validation: 0.6841046180461563]
	TIME [epoch: 9.22 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7656974976848624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7656974976848624 | validation: 0.9463509803039101]
	TIME [epoch: 9.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8016754270158118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8016754270158118 | validation: 0.6469374681486375]
	TIME [epoch: 9.21 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9400509909746191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9400509909746191 | validation: 0.5583019473116322]
	TIME [epoch: 9.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8354705035776651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8354705035776651 | validation: 0.6511487147366598]
	TIME [epoch: 9.21 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.717644342108133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.717644342108133 | validation: 0.5211997369047792]
	TIME [epoch: 9.22 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.713872937949842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.713872937949842 | validation: 0.806388557042712]
	TIME [epoch: 9.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.697329619103088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.697329619103088 | validation: 0.4388797293267277]
	TIME [epoch: 9.21 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7541689966473971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7541689966473971 | validation: 0.5312830441316073]
	TIME [epoch: 9.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8367077473539453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8367077473539453 | validation: 0.48944378730777816]
	TIME [epoch: 9.23 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6996820257822902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6996820257822902 | validation: 0.5898389071590511]
	TIME [epoch: 9.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5753665449532532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5753665449532532 | validation: 0.5682094143941814]
	TIME [epoch: 9.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7856336430381171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7856336430381171 | validation: 1.1835188058060349]
	TIME [epoch: 9.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.858156122451485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.858156122451485 | validation: 0.5308121075647013]
	TIME [epoch: 9.21 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6483965309799323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6483965309799323 | validation: 0.5446755700985415]
	TIME [epoch: 9.22 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.775560242063026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.775560242063026 | validation: 0.5006532296688643]
	TIME [epoch: 9.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6643947943705684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6643947943705684 | validation: 0.8095323951508817]
	TIME [epoch: 9.22 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.732430277139739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.732430277139739 | validation: 0.9487666113850478]
	TIME [epoch: 9.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8949606808839053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8949606808839053 | validation: 0.7239009468463746]
	TIME [epoch: 9.22 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5966147783084994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5966147783084994 | validation: 0.5220363602055003]
	TIME [epoch: 9.21 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8015694823172714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8015694823172714 | validation: 2.5550479012234404]
	TIME [epoch: 9.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1665723742965133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1665723742965133 | validation: 0.8618809204217169]
	TIME [epoch: 9.21 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9845282176140568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9845282176140568 | validation: 0.7856978556193032]
	TIME [epoch: 9.21 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7353635166711789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7353635166711789 | validation: 0.5299969651635792]
	TIME [epoch: 9.22 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7722254544881914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7722254544881914 | validation: 0.6384615000101059]
	TIME [epoch: 9.18 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6705047790731851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6705047790731851 | validation: 0.9139008045793503]
	TIME [epoch: 9.18 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7163476087426912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7163476087426912 | validation: 0.41840142746358794]
	TIME [epoch: 9.17 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7455380628795203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7455380628795203 | validation: 0.48999773102142075]
	TIME [epoch: 9.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6591151172021522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6591151172021522 | validation: 0.6675391752286064]
	TIME [epoch: 9.19 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7297891954055726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7297891954055726 | validation: 0.4115221522432937]
	TIME [epoch: 9.19 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6925363204201644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6925363204201644 | validation: 0.4200717157488881]
	TIME [epoch: 9.21 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6623618425978928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6623618425978928 | validation: 1.1397800543220602]
	TIME [epoch: 9.21 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7353574362275167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7353574362275167 | validation: 0.579112485789314]
	TIME [epoch: 9.21 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8494728911921614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8494728911921614 | validation: 1.1027346097228259]
	TIME [epoch: 9.21 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0455718214718366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0455718214718366 | validation: 0.7323767739614503]
	TIME [epoch: 9.18 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8356582416860603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8356582416860603 | validation: 0.7612566419086092]
	TIME [epoch: 9.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8784894922481218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8784894922481218 | validation: 1.0335105937178801]
	TIME [epoch: 9.21 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8154653167779955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8154653167779955 | validation: 0.5936571962368087]
	TIME [epoch: 9.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7272355780439966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7272355780439966 | validation: 0.9060426267723012]
	TIME [epoch: 9.21 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8046183204729396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8046183204729396 | validation: 0.5256191201161348]
	TIME [epoch: 9.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7239461073517356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7239461073517356 | validation: 0.3852277204297203]
	TIME [epoch: 9.22 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5879830465705699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5879830465705699 | validation: 0.6887885739385571]
	TIME [epoch: 9.21 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8480165696600199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8480165696600199 | validation: 0.6379692028890123]
	TIME [epoch: 9.19 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7429764733070825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7429764733070825 | validation: 0.5637129132142242]
	TIME [epoch: 9.21 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6407454616863804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6407454616863804 | validation: 0.6490329014997273]
	TIME [epoch: 9.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7022332002390762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7022332002390762 | validation: 0.517944649526957]
	TIME [epoch: 9.23 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7395815155712373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7395815155712373 | validation: 4.929407619812617]
	TIME [epoch: 9.21 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3191153931161304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3191153931161304 | validation: 0.6210319789990613]
	TIME [epoch: 9.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7230814611190013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7230814611190013 | validation: 0.6836588941675941]
	TIME [epoch: 9.21 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8203206556033168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8203206556033168 | validation: 0.5212736320462386]
	TIME [epoch: 9.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8210944162899061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8210944162899061 | validation: 2.4566528609330405]
	TIME [epoch: 9.22 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.091530810425756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.091530810425756 | validation: 0.662106508773435]
	TIME [epoch: 9.19 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7923327635481197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7923327635481197 | validation: 0.8450616615659795]
	TIME [epoch: 9.19 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7493275152885268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7493275152885268 | validation: 0.44628713269039666]
	TIME [epoch: 9.21 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7392967817132844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7392967817132844 | validation: 1.2514883819258467]
	TIME [epoch: 9.21 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8221750652748673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8221750652748673 | validation: 0.3695371945553558]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5740463451616736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5740463451616736 | validation: 0.4887259998305181]
	TIME [epoch: 9.18 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7244438856597543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7244438856597543 | validation: 1.08570350776142]
	TIME [epoch: 9.19 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8433639195111983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8433639195111983 | validation: 2.401520959426198]
	TIME [epoch: 9.21 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9034666402020246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9034666402020246 | validation: 0.6498005188089999]
	TIME [epoch: 9.22 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7890395475137711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7890395475137711 | validation: 0.6951204992865503]
	TIME [epoch: 9.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.645760059776345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.645760059776345 | validation: 0.8459259106504915]
	TIME [epoch: 9.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7701356686325564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7701356686325564 | validation: 0.982065714932308]
	TIME [epoch: 9.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6869964790431402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6869964790431402 | validation: 0.46619407866243123]
	TIME [epoch: 9.23 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6549611191765334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6549611191765334 | validation: 0.42825312334870047]
	TIME [epoch: 9.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48720044713287985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48720044713287985 | validation: 0.9898601104132767]
	TIME [epoch: 9.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8829540946895555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8829540946895555 | validation: 0.8755181015614941]
	TIME [epoch: 9.22 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7823306010262584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7823306010262584 | validation: 0.7685795409635391]
	TIME [epoch: 9.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9925005329841599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9925005329841599 | validation: 1.3549230427147274]
	TIME [epoch: 9.22 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0234988462320695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0234988462320695 | validation: 0.512467685803747]
	TIME [epoch: 9.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2280600158801405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2280600158801405 | validation: 0.5465843558634351]
	TIME [epoch: 9.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6708813845941858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6708813845941858 | validation: 0.710288674297024]
	TIME [epoch: 9.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8983519188043363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8983519188043363 | validation: 1.1061127950862142]
	TIME [epoch: 9.22 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7216943886042919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7216943886042919 | validation: 0.9111605603812211]
	TIME [epoch: 9.21 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8791584024140697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8791584024140697 | validation: 0.6678785162589742]
	TIME [epoch: 9.21 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6297960775348886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6297960775348886 | validation: 0.4377535091590914]
	TIME [epoch: 9.19 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7365419190482306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7365419190482306 | validation: 0.6016208092433117]
	TIME [epoch: 9.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6383231401387695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6383231401387695 | validation: 0.9119212656753044]
	TIME [epoch: 9.24 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8310758050144772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8310758050144772 | validation: 1.4481992193023618]
	TIME [epoch: 9.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.827628841266472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.827628841266472 | validation: 1.1296027947405174]
	TIME [epoch: 9.21 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8573784262373746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8573784262373746 | validation: 0.7454487455041274]
	TIME [epoch: 9.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8393890406737944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8393890406737944 | validation: 0.714599097352226]
	TIME [epoch: 9.22 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5969913451028759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5969913451028759 | validation: 0.946521892971511]
	TIME [epoch: 9.21 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6691135940921698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6691135940921698 | validation: 1.691044437835349]
	TIME [epoch: 9.21 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8310915603318817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8310915603318817 | validation: 0.4435142585842836]
	TIME [epoch: 9.22 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9302033183883655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9302033183883655 | validation: 0.6320907398806053]
	TIME [epoch: 9.22 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8547996050568463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8547996050568463 | validation: 1.2118569428436339]
	TIME [epoch: 9.24 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8871821810225082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8871821810225082 | validation: 0.6986694287521675]
	TIME [epoch: 9.21 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7770717131647309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7770717131647309 | validation: 0.6120442427632418]
	TIME [epoch: 9.22 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0195630930979884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0195630930979884 | validation: 1.1070525557230424]
	TIME [epoch: 9.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.739550822418783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.739550822418783 | validation: 0.9542220954751184]
	TIME [epoch: 9.22 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.098738047309241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.098738047309241 | validation: 0.4693865232545905]
	TIME [epoch: 9.23 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6932490714812461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6932490714812461 | validation: 0.5538473348777517]
	TIME [epoch: 9.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6224348336001693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6224348336001693 | validation: 0.46350676064263907]
	TIME [epoch: 9.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6737165527494104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6737165527494104 | validation: 0.8574127253815109]
	TIME [epoch: 9.19 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8134386470891298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8134386470891298 | validation: 1.5765761149838529]
	TIME [epoch: 9.24 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9037738803839069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9037738803839069 | validation: 1.6112219311648275]
	TIME [epoch: 9.21 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1250107479576827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1250107479576827 | validation: 0.46020352544055126]
	TIME [epoch: 9.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.543927875618019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.543927875618019 | validation: 0.6408022237445155]
	TIME [epoch: 9.21 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6266503632791174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6266503632791174 | validation: 0.30280328066183615]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6338348486780948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6338348486780948 | validation: 0.5988232943727245]
	TIME [epoch: 9.22 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8684455379200793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8684455379200793 | validation: 0.9881638442811664]
	TIME [epoch: 9.21 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5712828471967832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5712828471967832 | validation: 0.7453441226477749]
	TIME [epoch: 9.21 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0061427713530169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0061427713530169 | validation: 1.9488600835681225]
	TIME [epoch: 9.22 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9272916125200013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9272916125200013 | validation: 0.9838601044750767]
	TIME [epoch: 9.23 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7879858829886299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7879858829886299 | validation: 0.5762292451063112]
	TIME [epoch: 9.22 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5932350959450853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5932350959450853 | validation: 1.101833839900595]
	TIME [epoch: 9.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.671774825630907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.671774825630907 | validation: 0.7807869776724483]
	TIME [epoch: 9.22 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9105824003528253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9105824003528253 | validation: 0.6191663693655212]
	TIME [epoch: 9.23 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6930044148141872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6930044148141872 | validation: 0.5923631091834922]
	TIME [epoch: 9.22 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7149698952072608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7149698952072608 | validation: 0.8030743995815497]
	TIME [epoch: 9.21 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.717239542081802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.717239542081802 | validation: 0.4806094022772735]
	TIME [epoch: 9.22 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7441109241797335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7441109241797335 | validation: 0.7002554811816023]
	TIME [epoch: 9.22 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6611058845943336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6611058845943336 | validation: 1.0182750348947125]
	TIME [epoch: 9.23 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.699247443309042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.699247443309042 | validation: 0.7135045526735849]
	TIME [epoch: 9.22 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.751132202394308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.751132202394308 | validation: 1.0176978440098297]
	TIME [epoch: 9.21 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7322475661227001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7322475661227001 | validation: 0.567501943902451]
	TIME [epoch: 9.21 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.965642143465369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.965642143465369 | validation: 0.702018566926961]
	TIME [epoch: 9.22 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7268028967829616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7268028967829616 | validation: 0.8736506271640607]
	TIME [epoch: 9.22 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6327372914521308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6327372914521308 | validation: 0.27927254729789586]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5104716801794896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5104716801794896 | validation: 0.8261429205524158]
	TIME [epoch: 9.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7157839625729592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7157839625729592 | validation: 0.341017888413301]
	TIME [epoch: 9.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6915487367491501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6915487367491501 | validation: 0.44629533247605824]
	TIME [epoch: 9.21 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7041998204577762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7041998204577762 | validation: 1.4393471705700718]
	TIME [epoch: 9.22 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7486884638380563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7486884638380563 | validation: 1.437154424848035]
	TIME [epoch: 9.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7081096037863771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7081096037863771 | validation: 0.4527317189389801]
	TIME [epoch: 9.22 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5143910105348262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5143910105348262 | validation: 0.4725490140188007]
	TIME [epoch: 9.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8336590310884043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8336590310884043 | validation: 1.579771911980755]
	TIME [epoch: 9.21 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0607853884026117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0607853884026117 | validation: 0.8100171776715575]
	TIME [epoch: 9.21 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6875564675528746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6875564675528746 | validation: 0.8561139928754826]
	TIME [epoch: 9.22 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8391905046119247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8391905046119247 | validation: 0.6438016446118889]
	TIME [epoch: 9.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5100033213569731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5100033213569731 | validation: 1.271600690173269]
	TIME [epoch: 9.21 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6750041709815454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6750041709815454 | validation: 1.156459105422437]
	TIME [epoch: 9.22 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.78364564078013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.78364564078013 | validation: 0.3931041972985716]
	TIME [epoch: 9.19 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6180175352651023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6180175352651023 | validation: 0.29423268688418264]
	TIME [epoch: 9.19 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6137465946845907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6137465946845907 | validation: 0.46381618498703947]
	TIME [epoch: 9.22 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7339251382898241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7339251382898241 | validation: 0.3652825465296049]
	TIME [epoch: 9.21 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47162484581449043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47162484581449043 | validation: 0.5034604989806255]
	TIME [epoch: 9.21 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275040084158282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5275040084158282 | validation: 0.4779575384549057]
	TIME [epoch: 9.19 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5457674594614059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5457674594614059 | validation: 0.21753175591872276]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6448235268536165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6448235268536165 | validation: 0.5780438022544798]
	TIME [epoch: 9.23 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5131010191416875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5131010191416875 | validation: 0.6472896553850895]
	TIME [epoch: 9.22 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7218302885394983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7218302885394983 | validation: 0.5789153599228034]
	TIME [epoch: 9.21 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6089152547493212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6089152547493212 | validation: 0.39801475702181943]
	TIME [epoch: 9.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6706255552948146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6706255552948146 | validation: 0.523469638200872]
	TIME [epoch: 9.21 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6026304578317221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6026304578317221 | validation: 0.550308063682228]
	TIME [epoch: 9.22 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5657851648842174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5657851648842174 | validation: 0.37433001084046097]
	TIME [epoch: 9.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6967475065246846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6967475065246846 | validation: 0.41378923032906556]
	TIME [epoch: 9.17 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6062548223437398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6062548223437398 | validation: 0.397856775128594]
	TIME [epoch: 9.17 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5817140170017387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5817140170017387 | validation: 0.5999904831438164]
	TIME [epoch: 9.21 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.621955389011223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.621955389011223 | validation: 0.5382786390393579]
	TIME [epoch: 9.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5997498064316289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5997498064316289 | validation: 0.36562486248185044]
	TIME [epoch: 9.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5598503463693761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5598503463693761 | validation: 0.40925046998609715]
	TIME [epoch: 9.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6284262873811978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6284262873811978 | validation: 0.6134345759241828]
	TIME [epoch: 9.22 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49920628440720005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49920628440720005 | validation: 0.3203891344060778]
	TIME [epoch: 9.21 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6086282067905864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6086282067905864 | validation: 0.5946659026528359]
	TIME [epoch: 9.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9971220768538501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9971220768538501 | validation: 0.9565316849807981]
	TIME [epoch: 9.21 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6626371428659269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6626371428659269 | validation: 1.718475778226574]
	TIME [epoch: 9.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9072151408393431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9072151408393431 | validation: 0.7407690549772739]
	TIME [epoch: 9.23 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5842859267638273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5842859267638273 | validation: 0.6549734561924543]
	TIME [epoch: 9.21 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5540763966085661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5540763966085661 | validation: 0.5889867473175898]
	TIME [epoch: 9.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6427535072194007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6427535072194007 | validation: 0.9441927224160588]
	TIME [epoch: 9.21 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7249952292099158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7249952292099158 | validation: 0.6396719067783203]
	TIME [epoch: 9.21 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47635653512470577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47635653512470577 | validation: 0.5289151414074185]
	TIME [epoch: 9.22 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5946393127155953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5946393127155953 | validation: 0.4701023265244174]
	TIME [epoch: 9.22 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5890970637140971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5890970637140971 | validation: 0.5896872319695267]
	TIME [epoch: 9.21 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6110643144285153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6110643144285153 | validation: 0.5841364182208733]
	TIME [epoch: 9.22 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5760448326103546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5760448326103546 | validation: 0.372037233166494]
	TIME [epoch: 9.22 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5616164268323408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5616164268323408 | validation: 0.9365578820373692]
	TIME [epoch: 9.21 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6733028313890497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6733028313890497 | validation: 0.5560380314355079]
	TIME [epoch: 9.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7632368611990511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7632368611990511 | validation: 0.8327721714930614]
	TIME [epoch: 9.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7134486897755281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7134486897755281 | validation: 0.4351959162662402]
	TIME [epoch: 9.21 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.628060251397448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.628060251397448 | validation: 1.1327337018112853]
	TIME [epoch: 9.24 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6327812616477689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6327812616477689 | validation: 0.4482476543363424]
	TIME [epoch: 9.21 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5353573108751198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5353573108751198 | validation: 0.5000329853042689]
	TIME [epoch: 9.19 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6932374711945238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6932374711945238 | validation: 0.9296629509383524]
	TIME [epoch: 9.22 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6383123577314704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6383123577314704 | validation: 0.7230765704217428]
	TIME [epoch: 9.23 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6142289277904914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6142289277904914 | validation: 0.46178607100068636]
	TIME [epoch: 9.22 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5046086724783356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5046086724783356 | validation: 0.36094959215366124]
	TIME [epoch: 9.21 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.491736146612881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.491736146612881 | validation: 0.4175552645081776]
	TIME [epoch: 9.22 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49448841521500875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49448841521500875 | validation: 0.6652107883848599]
	TIME [epoch: 9.21 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6988019176443725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6988019176443725 | validation: 0.7763172198086536]
	TIME [epoch: 9.24 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7372474547351245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7372474547351245 | validation: 0.7705222788414445]
	TIME [epoch: 9.22 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6385946372889807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6385946372889807 | validation: 0.4471147300253635]
	TIME [epoch: 9.23 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5226093441544986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5226093441544986 | validation: 0.4372092883904678]
	TIME [epoch: 9.22 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116976892868602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6116976892868602 | validation: 0.3912933137172187]
	TIME [epoch: 9.25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5469854550539371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5469854550539371 | validation: 0.5059532426001443]
	TIME [epoch: 9.22 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5723402156086365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5723402156086365 | validation: 0.3323563326735436]
	TIME [epoch: 9.22 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5011183525596518		[learning rate: 0.0099724]
	Learning Rate: 0.00997241
	LOSS [training: 0.5011183525596518 | validation: 0.4802007856440277]
	TIME [epoch: 9.21 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5865727062220157		[learning rate: 0.0099418]
	Learning Rate: 0.00994184
	LOSS [training: 0.5865727062220157 | validation: 0.329069712247989]
	TIME [epoch: 9.21 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9298518569627257		[learning rate: 0.0099114]
	Learning Rate: 0.00991136
	LOSS [training: 0.9298518569627257 | validation: 0.6588567727506421]
	TIME [epoch: 9.24 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8575986450735831		[learning rate: 0.009881]
	Learning Rate: 0.00988098
	LOSS [training: 0.8575986450735831 | validation: 0.6114610866726871]
	TIME [epoch: 9.22 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.563079436947164		[learning rate: 0.0098507]
	Learning Rate: 0.00985069
	LOSS [training: 0.563079436947164 | validation: 0.7328306631192485]
	TIME [epoch: 9.21 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6754204564021361		[learning rate: 0.0098205]
	Learning Rate: 0.00982049
	LOSS [training: 0.6754204564021361 | validation: 1.3732406141312568]
	TIME [epoch: 9.23 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7267676803997605		[learning rate: 0.0097904]
	Learning Rate: 0.00979039
	LOSS [training: 0.7267676803997605 | validation: 0.6414236527331845]
	TIME [epoch: 9.24 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6830666579694126		[learning rate: 0.0097604]
	Learning Rate: 0.00976038
	LOSS [training: 0.6830666579694126 | validation: 0.45991039917017795]
	TIME [epoch: 9.23 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6469753375194973		[learning rate: 0.0097305]
	Learning Rate: 0.00973046
	LOSS [training: 0.6469753375194973 | validation: 0.4813370138383323]
	TIME [epoch: 9.22 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7670502301856807		[learning rate: 0.0097006]
	Learning Rate: 0.00970063
	LOSS [training: 0.7670502301856807 | validation: 2.073116620389869]
	TIME [epoch: 9.22 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9091593236132514		[learning rate: 0.0096709]
	Learning Rate: 0.00967089
	LOSS [training: 0.9091593236132514 | validation: 0.8592639852988188]
	TIME [epoch: 9.22 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6877472675573559		[learning rate: 0.0096412]
	Learning Rate: 0.00964125
	LOSS [training: 0.6877472675573559 | validation: 0.5334451386716046]
	TIME [epoch: 9.25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494439352949702		[learning rate: 0.0096117]
	Learning Rate: 0.0096117
	LOSS [training: 0.6494439352949702 | validation: 0.4409646717616517]
	TIME [epoch: 9.22 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4516752316520048		[learning rate: 0.0095822]
	Learning Rate: 0.00958223
	LOSS [training: 0.4516752316520048 | validation: 0.3368043459279859]
	TIME [epoch: 9.22 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.645483163169095		[learning rate: 0.0095529]
	Learning Rate: 0.00955286
	LOSS [training: 0.645483163169095 | validation: 0.354661449143037]
	TIME [epoch: 9.21 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47195687137509773		[learning rate: 0.0095236]
	Learning Rate: 0.00952357
	LOSS [training: 0.47195687137509773 | validation: 0.4452523992952291]
	TIME [epoch: 9.24 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7167036531124928		[learning rate: 0.0094944]
	Learning Rate: 0.00949438
	LOSS [training: 0.7167036531124928 | validation: 0.40299655620818586]
	TIME [epoch: 9.23 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5141274384625028		[learning rate: 0.0094653]
	Learning Rate: 0.00946528
	LOSS [training: 0.5141274384625028 | validation: 0.5946221110522835]
	TIME [epoch: 9.22 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5151944505307954		[learning rate: 0.0094363]
	Learning Rate: 0.00943626
	LOSS [training: 0.5151944505307954 | validation: 0.5223583713712868]
	TIME [epoch: 9.21 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5265142139970066		[learning rate: 0.0094073]
	Learning Rate: 0.00940734
	LOSS [training: 0.5265142139970066 | validation: 0.47621458421231017]
	TIME [epoch: 9.22 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5384410057577373		[learning rate: 0.0093785]
	Learning Rate: 0.0093785
	LOSS [training: 0.5384410057577373 | validation: 0.5064006866873713]
	TIME [epoch: 9.24 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6787053612434238		[learning rate: 0.0093497]
	Learning Rate: 0.00934975
	LOSS [training: 0.6787053612434238 | validation: 0.4125186023480524]
	TIME [epoch: 9.21 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.604488754948832		[learning rate: 0.0093211]
	Learning Rate: 0.00932109
	LOSS [training: 0.604488754948832 | validation: 0.5512560140673746]
	TIME [epoch: 9.21 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5002240503687102		[learning rate: 0.0092925]
	Learning Rate: 0.00929252
	LOSS [training: 0.5002240503687102 | validation: 0.6492583817608029]
	TIME [epoch: 9.22 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5549564118569171		[learning rate: 0.009264]
	Learning Rate: 0.00926403
	LOSS [training: 0.5549564118569171 | validation: 0.5955220983510039]
	TIME [epoch: 9.22 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8806397725722442		[learning rate: 0.0092356]
	Learning Rate: 0.00923563
	LOSS [training: 0.8806397725722442 | validation: 0.6745810454942323]
	TIME [epoch: 9.24 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6333558839603484		[learning rate: 0.0092073]
	Learning Rate: 0.00920732
	LOSS [training: 0.6333558839603484 | validation: 0.37730871062817606]
	TIME [epoch: 9.22 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5163630713614017		[learning rate: 0.0091791]
	Learning Rate: 0.0091791
	LOSS [training: 0.5163630713614017 | validation: 0.6489639671807531]
	TIME [epoch: 9.22 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7399146380746661		[learning rate: 0.009151]
	Learning Rate: 0.00915096
	LOSS [training: 0.7399146380746661 | validation: 0.47784398928544325]
	TIME [epoch: 9.22 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8233918885705908		[learning rate: 0.0091229]
	Learning Rate: 0.00912291
	LOSS [training: 0.8233918885705908 | validation: 0.3587163575230191]
	TIME [epoch: 9.24 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5664827293801502		[learning rate: 0.0090949]
	Learning Rate: 0.00909494
	LOSS [training: 0.5664827293801502 | validation: 0.5508273960046619]
	TIME [epoch: 9.22 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6599190630202173		[learning rate: 0.0090671]
	Learning Rate: 0.00906706
	LOSS [training: 0.6599190630202173 | validation: 0.4167615896728404]
	TIME [epoch: 9.22 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5380587230806586		[learning rate: 0.0090393]
	Learning Rate: 0.00903927
	LOSS [training: 0.5380587230806586 | validation: 0.5935071515675383]
	TIME [epoch: 9.22 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.720491095686058		[learning rate: 0.0090116]
	Learning Rate: 0.00901156
	LOSS [training: 0.720491095686058 | validation: 0.8712099054477314]
	TIME [epoch: 9.24 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6334812340124498		[learning rate: 0.0089839]
	Learning Rate: 0.00898394
	LOSS [training: 0.6334812340124498 | validation: 0.678474024044071]
	TIME [epoch: 9.22 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6408257913721681		[learning rate: 0.0089564]
	Learning Rate: 0.0089564
	LOSS [training: 0.6408257913721681 | validation: 0.5192435504778801]
	TIME [epoch: 9.21 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5353107691981069		[learning rate: 0.0089289]
	Learning Rate: 0.00892894
	LOSS [training: 0.5353107691981069 | validation: 0.5979622194333891]
	TIME [epoch: 9.21 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5967348768994869		[learning rate: 0.0089016]
	Learning Rate: 0.00890157
	LOSS [training: 0.5967348768994869 | validation: 0.31404263864426074]
	TIME [epoch: 9.21 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5628750567990524		[learning rate: 0.0088743]
	Learning Rate: 0.00887428
	LOSS [training: 0.5628750567990524 | validation: 0.762691469202132]
	TIME [epoch: 9.24 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5916488197480333		[learning rate: 0.0088471]
	Learning Rate: 0.00884708
	LOSS [training: 0.5916488197480333 | validation: 0.49702648764822843]
	TIME [epoch: 9.22 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4768819949917562		[learning rate: 0.00882]
	Learning Rate: 0.00881996
	LOSS [training: 0.4768819949917562 | validation: 0.6555274730945087]
	TIME [epoch: 9.22 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6758151627478183		[learning rate: 0.0087929]
	Learning Rate: 0.00879292
	LOSS [training: 0.6758151627478183 | validation: 0.5072801160055559]
	TIME [epoch: 9.21 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6331968660909407		[learning rate: 0.008766]
	Learning Rate: 0.00876597
	LOSS [training: 0.6331968660909407 | validation: 1.1639677772400259]
	TIME [epoch: 9.22 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.707868854842959		[learning rate: 0.0087391]
	Learning Rate: 0.0087391
	LOSS [training: 0.707868854842959 | validation: 0.7265848370485045]
	TIME [epoch: 9.23 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5252351641774633		[learning rate: 0.0087123]
	Learning Rate: 0.00871231
	LOSS [training: 0.5252351641774633 | validation: 0.3513649686241222]
	TIME [epoch: 9.21 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7047282465655271		[learning rate: 0.0086856]
	Learning Rate: 0.0086856
	LOSS [training: 0.7047282465655271 | validation: 0.4227738864925916]
	TIME [epoch: 9.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5668450178858999		[learning rate: 0.008659]
	Learning Rate: 0.00865898
	LOSS [training: 0.5668450178858999 | validation: 0.4356824348530467]
	TIME [epoch: 9.21 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5905893182493444		[learning rate: 0.0086324]
	Learning Rate: 0.00863244
	LOSS [training: 0.5905893182493444 | validation: 0.842723123565143]
	TIME [epoch: 9.23 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5144881104532233		[learning rate: 0.008606]
	Learning Rate: 0.00860597
	LOSS [training: 0.5144881104532233 | validation: 0.33759618069428377]
	TIME [epoch: 9.21 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4638480870454468		[learning rate: 0.0085796]
	Learning Rate: 0.00857959
	LOSS [training: 0.4638480870454468 | validation: 0.6107453353882294]
	TIME [epoch: 9.21 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5911405141678496		[learning rate: 0.0085533]
	Learning Rate: 0.00855329
	LOSS [training: 0.5911405141678496 | validation: 0.39188241569748855]
	TIME [epoch: 9.21 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8401932446635552		[learning rate: 0.0085271]
	Learning Rate: 0.00852707
	LOSS [training: 0.8401932446635552 | validation: 0.6490376686624401]
	TIME [epoch: 9.23 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5377666014608986		[learning rate: 0.0085009]
	Learning Rate: 0.00850093
	LOSS [training: 0.5377666014608986 | validation: 0.7173289923526268]
	TIME [epoch: 9.22 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8070492850450005		[learning rate: 0.0084749]
	Learning Rate: 0.00847488
	LOSS [training: 0.8070492850450005 | validation: 0.3622920067929737]
	TIME [epoch: 9.22 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5007069841837382		[learning rate: 0.0084489]
	Learning Rate: 0.0084489
	LOSS [training: 0.5007069841837382 | validation: 0.3842915312431141]
	TIME [epoch: 9.22 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.597575940121918		[learning rate: 0.008423]
	Learning Rate: 0.008423
	LOSS [training: 0.597575940121918 | validation: 0.3000650905398828]
	TIME [epoch: 9.22 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554079764182756		[learning rate: 0.0083972]
	Learning Rate: 0.00839718
	LOSS [training: 0.5554079764182756 | validation: 0.48464730085049645]
	TIME [epoch: 9.23 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6319769168321979		[learning rate: 0.0083714]
	Learning Rate: 0.00837144
	LOSS [training: 0.6319769168321979 | validation: 0.25008534079763617]
	TIME [epoch: 9.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47022397569432944		[learning rate: 0.0083458]
	Learning Rate: 0.00834577
	LOSS [training: 0.47022397569432944 | validation: 0.5570342642774282]
	TIME [epoch: 9.21 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5753852500533266		[learning rate: 0.0083202]
	Learning Rate: 0.00832019
	LOSS [training: 0.5753852500533266 | validation: 0.3887996265523891]
	TIME [epoch: 9.21 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4712995716320954		[learning rate: 0.0082947]
	Learning Rate: 0.00829469
	LOSS [training: 0.4712995716320954 | validation: 0.3569265878275657]
	TIME [epoch: 9.21 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6963385906438042		[learning rate: 0.0082693]
	Learning Rate: 0.00826926
	LOSS [training: 0.6963385906438042 | validation: 0.7194926179803789]
	TIME [epoch: 9.21 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6105281804332098		[learning rate: 0.0082439]
	Learning Rate: 0.00824391
	LOSS [training: 0.6105281804332098 | validation: 0.34578879133180124]
	TIME [epoch: 9.18 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5298219372506863		[learning rate: 0.0082186]
	Learning Rate: 0.00821864
	LOSS [training: 0.5298219372506863 | validation: 0.3480249974718349]
	TIME [epoch: 9.19 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40829318959047634		[learning rate: 0.0081934]
	Learning Rate: 0.00819345
	LOSS [training: 0.40829318959047634 | validation: 0.3122840760323461]
	TIME [epoch: 9.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5236615276167939		[learning rate: 0.0081683]
	Learning Rate: 0.00816833
	LOSS [training: 0.5236615276167939 | validation: 0.6256983924172217]
	TIME [epoch: 9.22 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.505731732084876		[learning rate: 0.0081433]
	Learning Rate: 0.00814329
	LOSS [training: 0.505731732084876 | validation: 0.3457320337252249]
	TIME [epoch: 9.21 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5037284813570422		[learning rate: 0.0081183]
	Learning Rate: 0.00811833
	LOSS [training: 0.5037284813570422 | validation: 0.4091323235065508]
	TIME [epoch: 9.21 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46847166732223544		[learning rate: 0.0080934]
	Learning Rate: 0.00809344
	LOSS [training: 0.46847166732223544 | validation: 0.6422406306351388]
	TIME [epoch: 9.22 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3874207352691944		[learning rate: 0.0080686]
	Learning Rate: 0.00806863
	LOSS [training: 0.3874207352691944 | validation: 0.5830163924369656]
	TIME [epoch: 9.23 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275540364645678		[learning rate: 0.0080439]
	Learning Rate: 0.0080439
	LOSS [training: 0.5275540364645678 | validation: 0.41118293005168627]
	TIME [epoch: 9.22 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43825183105873966		[learning rate: 0.0080192]
	Learning Rate: 0.00801924
	LOSS [training: 0.43825183105873966 | validation: 0.38667515824987553]
	TIME [epoch: 9.21 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3477093227627903		[learning rate: 0.0079947]
	Learning Rate: 0.00799466
	LOSS [training: 0.3477093227627903 | validation: 0.442176604932183]
	TIME [epoch: 9.21 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4280231122493129		[learning rate: 0.0079702]
	Learning Rate: 0.00797015
	LOSS [training: 0.4280231122493129 | validation: 0.2760350885492029]
	TIME [epoch: 9.21 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48761915274786505		[learning rate: 0.0079457]
	Learning Rate: 0.00794572
	LOSS [training: 0.48761915274786505 | validation: 0.512519241431493]
	TIME [epoch: 9.21 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250459040569532		[learning rate: 0.0079214]
	Learning Rate: 0.00792136
	LOSS [training: 0.3250459040569532 | validation: 0.28982712299632896]
	TIME [epoch: 9.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48994348900545387		[learning rate: 0.0078971]
	Learning Rate: 0.00789708
	LOSS [training: 0.48994348900545387 | validation: 0.45019788779563585]
	TIME [epoch: 9.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917515981513587		[learning rate: 0.0078729]
	Learning Rate: 0.00787287
	LOSS [training: 0.3917515981513587 | validation: 0.5116581386238761]
	TIME [epoch: 9.21 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5088859693259411		[learning rate: 0.0078487]
	Learning Rate: 0.00784874
	LOSS [training: 0.5088859693259411 | validation: 0.529647979680137]
	TIME [epoch: 9.21 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5430826371387925		[learning rate: 0.0078247]
	Learning Rate: 0.00782468
	LOSS [training: 0.5430826371387925 | validation: 0.5704922305425741]
	TIME [epoch: 9.21 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4293909318363549		[learning rate: 0.0078007]
	Learning Rate: 0.0078007
	LOSS [training: 0.4293909318363549 | validation: 0.34474487967957246]
	TIME [epoch: 9.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5832575914390685		[learning rate: 0.0077768]
	Learning Rate: 0.00777678
	LOSS [training: 0.5832575914390685 | validation: 0.54592595030169]
	TIME [epoch: 9.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5037540766009256		[learning rate: 0.0077529]
	Learning Rate: 0.00775294
	LOSS [training: 0.5037540766009256 | validation: 0.2990147280730695]
	TIME [epoch: 9.21 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5001381990071029		[learning rate: 0.0077292]
	Learning Rate: 0.00772918
	LOSS [training: 0.5001381990071029 | validation: 0.3198575955773483]
	TIME [epoch: 9.22 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.425713776818809		[learning rate: 0.0077055]
	Learning Rate: 0.00770548
	LOSS [training: 0.425713776818809 | validation: 0.5014840223038158]
	TIME [epoch: 9.21 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43418350936189876		[learning rate: 0.0076819]
	Learning Rate: 0.00768186
	LOSS [training: 0.43418350936189876 | validation: 0.5076323436703393]
	TIME [epoch: 9.21 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4054019605917448		[learning rate: 0.0076583]
	Learning Rate: 0.00765832
	LOSS [training: 0.4054019605917448 | validation: 0.25368931293839114]
	TIME [epoch: 9.21 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47070847077958594		[learning rate: 0.0076348]
	Learning Rate: 0.00763484
	LOSS [training: 0.47070847077958594 | validation: 0.3713211511490171]
	TIME [epoch: 9.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4145657705744129		[learning rate: 0.0076114]
	Learning Rate: 0.00761144
	LOSS [training: 0.4145657705744129 | validation: 0.31587635327878405]
	TIME [epoch: 9.23 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40743984047704285		[learning rate: 0.0075881]
	Learning Rate: 0.0075881
	LOSS [training: 0.40743984047704285 | validation: 0.7246932219062362]
	TIME [epoch: 9.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5632263418159962		[learning rate: 0.0075648]
	Learning Rate: 0.00756484
	LOSS [training: 0.5632263418159962 | validation: 0.3395246185729207]
	TIME [epoch: 9.21 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48529292350942443		[learning rate: 0.0075417]
	Learning Rate: 0.00754165
	LOSS [training: 0.48529292350942443 | validation: 0.4487791990708999]
	TIME [epoch: 9.19 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4864924093066702		[learning rate: 0.0075185]
	Learning Rate: 0.00751854
	LOSS [training: 0.4864924093066702 | validation: 0.6712183443394868]
	TIME [epoch: 9.23 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45667339410610824		[learning rate: 0.0074955]
	Learning Rate: 0.00749549
	LOSS [training: 0.45667339410610824 | validation: 0.3938277949961836]
	TIME [epoch: 9.21 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42615189329094044		[learning rate: 0.0074725]
	Learning Rate: 0.00747251
	LOSS [training: 0.42615189329094044 | validation: 0.6545020491050009]
	TIME [epoch: 9.21 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44086053072151177		[learning rate: 0.0074496]
	Learning Rate: 0.00744961
	LOSS [training: 0.44086053072151177 | validation: 0.6135872879522983]
	TIME [epoch: 9.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4662070891374766		[learning rate: 0.0074268]
	Learning Rate: 0.00742677
	LOSS [training: 0.4662070891374766 | validation: 0.30407057661918624]
	TIME [epoch: 9.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44946142619235363		[learning rate: 0.007404]
	Learning Rate: 0.007404
	LOSS [training: 0.44946142619235363 | validation: 0.462007802262168]
	TIME [epoch: 9.22 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4326701825045439		[learning rate: 0.0073813]
	Learning Rate: 0.00738131
	LOSS [training: 0.4326701825045439 | validation: 0.3202853406125239]
	TIME [epoch: 9.21 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45284241961614635		[learning rate: 0.0073587]
	Learning Rate: 0.00735868
	LOSS [training: 0.45284241961614635 | validation: 0.14693462352267245]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5096097942768074		[learning rate: 0.0073361]
	Learning Rate: 0.00733612
	LOSS [training: 0.5096097942768074 | validation: 0.5254985284368423]
	TIME [epoch: 9.17 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5522624023171312		[learning rate: 0.0073136]
	Learning Rate: 0.00731364
	LOSS [training: 0.5522624023171312 | validation: 0.4683714574723043]
	TIME [epoch: 9.21 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42765344428471563		[learning rate: 0.0072912]
	Learning Rate: 0.00729122
	LOSS [training: 0.42765344428471563 | validation: 0.5580470230083026]
	TIME [epoch: 9.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4570670989161078		[learning rate: 0.0072689]
	Learning Rate: 0.00726887
	LOSS [training: 0.4570670989161078 | validation: 0.2987286362634676]
	TIME [epoch: 9.19 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48699204169127414		[learning rate: 0.0072466]
	Learning Rate: 0.00724658
	LOSS [training: 0.48699204169127414 | validation: 0.21418884688489379]
	TIME [epoch: 9.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39327129837501607		[learning rate: 0.0072244]
	Learning Rate: 0.00722437
	LOSS [training: 0.39327129837501607 | validation: 0.5197320775817572]
	TIME [epoch: 9.19 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4560363954791378		[learning rate: 0.0072022]
	Learning Rate: 0.00720222
	LOSS [training: 0.4560363954791378 | validation: 0.39174801302894924]
	TIME [epoch: 9.22 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3981379646358074		[learning rate: 0.0071801]
	Learning Rate: 0.00718015
	LOSS [training: 0.3981379646358074 | validation: 0.29547167312291367]
	TIME [epoch: 9.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4200617307378126		[learning rate: 0.0071581]
	Learning Rate: 0.00715814
	LOSS [training: 0.4200617307378126 | validation: 0.3627769262125703]
	TIME [epoch: 9.21 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.477034715659181		[learning rate: 0.0071362]
	Learning Rate: 0.00713619
	LOSS [training: 0.477034715659181 | validation: 0.4545959632867733]
	TIME [epoch: 9.19 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38330832445266505		[learning rate: 0.0071143]
	Learning Rate: 0.00711432
	LOSS [training: 0.38330832445266505 | validation: 0.48657521830585915]
	TIME [epoch: 9.21 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4166374802577103		[learning rate: 0.0070925]
	Learning Rate: 0.00709251
	LOSS [training: 0.4166374802577103 | validation: 0.2932436529171605]
	TIME [epoch: 9.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131829739972123		[learning rate: 0.0070708]
	Learning Rate: 0.00707077
	LOSS [training: 0.4131829739972123 | validation: 0.22807703903293117]
	TIME [epoch: 9.21 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3370495974983696		[learning rate: 0.0070491]
	Learning Rate: 0.00704909
	LOSS [training: 0.3370495974983696 | validation: 0.367899909304545]
	TIME [epoch: 9.19 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41988563092321635		[learning rate: 0.0070275]
	Learning Rate: 0.00702749
	LOSS [training: 0.41988563092321635 | validation: 0.4123393275679374]
	TIME [epoch: 9.19 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36275277906067954		[learning rate: 0.0070059]
	Learning Rate: 0.00700594
	LOSS [training: 0.36275277906067954 | validation: 0.23892763150346866]
	TIME [epoch: 9.21 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35967407082902025		[learning rate: 0.0069845]
	Learning Rate: 0.00698447
	LOSS [training: 0.35967407082902025 | validation: 0.36066103953136586]
	TIME [epoch: 9.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3718340825271137		[learning rate: 0.0069631]
	Learning Rate: 0.00696306
	LOSS [training: 0.3718340825271137 | validation: 0.2837034100742698]
	TIME [epoch: 9.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.439327186512411		[learning rate: 0.0069417]
	Learning Rate: 0.00694171
	LOSS [training: 0.439327186512411 | validation: 0.44039848005554777]
	TIME [epoch: 9.21 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46309266780833125		[learning rate: 0.0069204]
	Learning Rate: 0.00692043
	LOSS [training: 0.46309266780833125 | validation: 0.29279290816140946]
	TIME [epoch: 9.22 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41709772465146006		[learning rate: 0.0068992]
	Learning Rate: 0.00689922
	LOSS [training: 0.41709772465146006 | validation: 0.21832405412809086]
	TIME [epoch: 9.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4309580366077637		[learning rate: 0.0068781]
	Learning Rate: 0.00687807
	LOSS [training: 0.4309580366077637 | validation: 0.3304399989509984]
	TIME [epoch: 9.21 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3727386288997153		[learning rate: 0.006857]
	Learning Rate: 0.00685699
	LOSS [training: 0.3727386288997153 | validation: 0.22874322328511915]
	TIME [epoch: 9.19 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37953837493322135		[learning rate: 0.006836]
	Learning Rate: 0.00683597
	LOSS [training: 0.37953837493322135 | validation: 0.3018852343877768]
	TIME [epoch: 9.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3148754337639349		[learning rate: 0.006815]
	Learning Rate: 0.00681501
	LOSS [training: 0.3148754337639349 | validation: 0.6478830933788354]
	TIME [epoch: 9.23 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49110269949838586		[learning rate: 0.0067941]
	Learning Rate: 0.00679412
	LOSS [training: 0.49110269949838586 | validation: 0.3078979558468524]
	TIME [epoch: 9.21 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36424198628288684		[learning rate: 0.0067733]
	Learning Rate: 0.00677329
	LOSS [training: 0.36424198628288684 | validation: 0.27418167596373566]
	TIME [epoch: 9.21 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36911023796292497		[learning rate: 0.0067525]
	Learning Rate: 0.00675253
	LOSS [training: 0.36911023796292497 | validation: 0.3513048161950779]
	TIME [epoch: 9.18 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4695842692528466		[learning rate: 0.0067318]
	Learning Rate: 0.00673183
	LOSS [training: 0.4695842692528466 | validation: 0.23577858168320515]
	TIME [epoch: 9.21 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4268967765892798		[learning rate: 0.0067112]
	Learning Rate: 0.0067112
	LOSS [training: 0.4268967765892798 | validation: 0.34709088307269387]
	TIME [epoch: 9.21 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4438452691459778		[learning rate: 0.0066906]
	Learning Rate: 0.00669062
	LOSS [training: 0.4438452691459778 | validation: 0.2373420239159643]
	TIME [epoch: 9.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3984923371698939		[learning rate: 0.0066701]
	Learning Rate: 0.00667012
	LOSS [training: 0.3984923371698939 | validation: 0.19309629538843073]
	TIME [epoch: 9.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44393649036699145		[learning rate: 0.0066497]
	Learning Rate: 0.00664967
	LOSS [training: 0.44393649036699145 | validation: 0.32417306497776055]
	TIME [epoch: 9.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36832419837108776		[learning rate: 0.0066293]
	Learning Rate: 0.00662928
	LOSS [training: 0.36832419837108776 | validation: 0.24703447878881712]
	TIME [epoch: 9.23 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981862674391843		[learning rate: 0.006609]
	Learning Rate: 0.00660896
	LOSS [training: 0.2981862674391843 | validation: 0.23675478935965716]
	TIME [epoch: 9.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37305575295757676		[learning rate: 0.0065887]
	Learning Rate: 0.0065887
	LOSS [training: 0.37305575295757676 | validation: 0.26101931383919186]
	TIME [epoch: 9.19 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36727593374126233		[learning rate: 0.0065685]
	Learning Rate: 0.00656851
	LOSS [training: 0.36727593374126233 | validation: 0.41256389206966704]
	TIME [epoch: 9.21 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35932250211371536		[learning rate: 0.0065484]
	Learning Rate: 0.00654837
	LOSS [training: 0.35932250211371536 | validation: 0.5155752650246782]
	TIME [epoch: 9.21 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41848409522384256		[learning rate: 0.0065283]
	Learning Rate: 0.0065283
	LOSS [training: 0.41848409522384256 | validation: 0.4331959627402614]
	TIME [epoch: 9.22 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47958093426681464		[learning rate: 0.0065083]
	Learning Rate: 0.00650829
	LOSS [training: 0.47958093426681464 | validation: 0.3535039632639102]
	TIME [epoch: 9.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44254722072443303		[learning rate: 0.0064883]
	Learning Rate: 0.00648834
	LOSS [training: 0.44254722072443303 | validation: 0.30479086133017264]
	TIME [epoch: 9.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4553458516408358		[learning rate: 0.0064684]
	Learning Rate: 0.00646845
	LOSS [training: 0.4553458516408358 | validation: 0.24058318020884012]
	TIME [epoch: 9.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35712897938820987		[learning rate: 0.0064486]
	Learning Rate: 0.00644862
	LOSS [training: 0.35712897938820987 | validation: 0.198354044230588]
	TIME [epoch: 9.22 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35749378273039994		[learning rate: 0.0064289]
	Learning Rate: 0.00642885
	LOSS [training: 0.35749378273039994 | validation: 0.29254539496346393]
	TIME [epoch: 9.18 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4025558735475716		[learning rate: 0.0064091]
	Learning Rate: 0.00640914
	LOSS [training: 0.4025558735475716 | validation: 0.261431005688911]
	TIME [epoch: 9.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34014547361079367		[learning rate: 0.0063895]
	Learning Rate: 0.0063895
	LOSS [training: 0.34014547361079367 | validation: 0.23250716985601574]
	TIME [epoch: 9.19 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4145759688146299		[learning rate: 0.0063699]
	Learning Rate: 0.00636991
	LOSS [training: 0.4145759688146299 | validation: 0.3677428326799882]
	TIME [epoch: 9.22 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37406405628740214		[learning rate: 0.0063504]
	Learning Rate: 0.00635038
	LOSS [training: 0.37406405628740214 | validation: 0.34730231145185253]
	TIME [epoch: 9.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41498057707006686		[learning rate: 0.0063309]
	Learning Rate: 0.00633092
	LOSS [training: 0.41498057707006686 | validation: 0.293147971035435]
	TIME [epoch: 9.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3836952959618616		[learning rate: 0.0063115]
	Learning Rate: 0.00631151
	LOSS [training: 0.3836952959618616 | validation: 0.3278980142010066]
	TIME [epoch: 9.19 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40496385386607486		[learning rate: 0.0062922]
	Learning Rate: 0.00629216
	LOSS [training: 0.40496385386607486 | validation: 0.23426537382935902]
	TIME [epoch: 9.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30130964374539965		[learning rate: 0.0062729]
	Learning Rate: 0.00627288
	LOSS [training: 0.30130964374539965 | validation: 0.4869584624422849]
	TIME [epoch: 9.22 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42156522982104827		[learning rate: 0.0062536]
	Learning Rate: 0.00625365
	LOSS [training: 0.42156522982104827 | validation: 0.3092417831278942]
	TIME [epoch: 9.19 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3837292900472775		[learning rate: 0.0062345]
	Learning Rate: 0.00623448
	LOSS [training: 0.3837292900472775 | validation: 0.2784250855527302]
	TIME [epoch: 9.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113609357257612		[learning rate: 0.0062154]
	Learning Rate: 0.00621536
	LOSS [training: 0.3113609357257612 | validation: 0.8089496145801072]
	TIME [epoch: 9.18 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898490841056249		[learning rate: 0.0061963]
	Learning Rate: 0.00619631
	LOSS [training: 0.3898490841056249 | validation: 0.2215965566503943]
	TIME [epoch: 9.21 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2673175057641347		[learning rate: 0.0061773]
	Learning Rate: 0.00617732
	LOSS [training: 0.2673175057641347 | validation: 0.22704481705383606]
	TIME [epoch: 9.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36720604324150424		[learning rate: 0.0061584]
	Learning Rate: 0.00615838
	LOSS [training: 0.36720604324150424 | validation: 0.33416475148232927]
	TIME [epoch: 9.18 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36198934736755145		[learning rate: 0.0061395]
	Learning Rate: 0.0061395
	LOSS [training: 0.36198934736755145 | validation: 0.2847242120033101]
	TIME [epoch: 9.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285333337203169		[learning rate: 0.0061207]
	Learning Rate: 0.00612068
	LOSS [training: 0.3285333337203169 | validation: 0.2964619997373289]
	TIME [epoch: 9.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.357057958567606		[learning rate: 0.0061019]
	Learning Rate: 0.00610192
	LOSS [training: 0.357057958567606 | validation: 0.3637065762392632]
	TIME [epoch: 9.23 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3948899314743392		[learning rate: 0.0060832]
	Learning Rate: 0.00608322
	LOSS [training: 0.3948899314743392 | validation: 0.24788146147921458]
	TIME [epoch: 9.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3909979761924691		[learning rate: 0.0060646]
	Learning Rate: 0.00606457
	LOSS [training: 0.3909979761924691 | validation: 0.22288143918567022]
	TIME [epoch: 9.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3985028586661517		[learning rate: 0.006046]
	Learning Rate: 0.00604598
	LOSS [training: 0.3985028586661517 | validation: 0.3980759799961454]
	TIME [epoch: 9.19 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37058605823058804		[learning rate: 0.0060274]
	Learning Rate: 0.00602745
	LOSS [training: 0.37058605823058804 | validation: 0.8919058003486562]
	TIME [epoch: 9.18 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4186473001414298		[learning rate: 0.006009]
	Learning Rate: 0.00600897
	LOSS [training: 0.4186473001414298 | validation: 0.3270741786874474]
	TIME [epoch: 9.21 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.373535775195276		[learning rate: 0.0059905]
	Learning Rate: 0.00599055
	LOSS [training: 0.373535775195276 | validation: 0.27347854458555393]
	TIME [epoch: 9.19 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3923881079254054		[learning rate: 0.0059722]
	Learning Rate: 0.00597219
	LOSS [training: 0.3923881079254054 | validation: 0.573685867060864]
	TIME [epoch: 9.21 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36195759713023884		[learning rate: 0.0059539]
	Learning Rate: 0.00595388
	LOSS [training: 0.36195759713023884 | validation: 0.6876567933876296]
	TIME [epoch: 9.19 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5165756811142608		[learning rate: 0.0059356]
	Learning Rate: 0.00593563
	LOSS [training: 0.5165756811142608 | validation: 0.6588351676924808]
	TIME [epoch: 9.22 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5080562107862773		[learning rate: 0.0059174]
	Learning Rate: 0.00591743
	LOSS [training: 0.5080562107862773 | validation: 0.24740274051140665]
	TIME [epoch: 9.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39957265559974275		[learning rate: 0.0058993]
	Learning Rate: 0.00589929
	LOSS [training: 0.39957265559974275 | validation: 0.7347147284916771]
	TIME [epoch: 9.19 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.639702843681143		[learning rate: 0.0058812]
	Learning Rate: 0.00588121
	LOSS [training: 0.639702843681143 | validation: 0.25040757621490145]
	TIME [epoch: 9.18 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3808954928312312		[learning rate: 0.0058632]
	Learning Rate: 0.00586318
	LOSS [training: 0.3808954928312312 | validation: 0.5716617583554273]
	TIME [epoch: 9.22 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.530434686932388		[learning rate: 0.0058452]
	Learning Rate: 0.00584521
	LOSS [training: 0.530434686932388 | validation: 0.2677149534278077]
	TIME [epoch: 9.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4610630332460229		[learning rate: 0.0058273]
	Learning Rate: 0.00582729
	LOSS [training: 0.4610630332460229 | validation: 0.41224869742845593]
	TIME [epoch: 9.19 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4132338179609888		[learning rate: 0.0058094]
	Learning Rate: 0.00580943
	LOSS [training: 0.4132338179609888 | validation: 0.700694797046806]
	TIME [epoch: 9.19 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39721820226218574		[learning rate: 0.0057916]
	Learning Rate: 0.00579162
	LOSS [training: 0.39721820226218574 | validation: 0.3792905247584285]
	TIME [epoch: 9.21 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3653197802550087		[learning rate: 0.0057739]
	Learning Rate: 0.00577387
	LOSS [training: 0.3653197802550087 | validation: 0.2830949883365102]
	TIME [epoch: 9.22 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560560412687618		[learning rate: 0.0057562]
	Learning Rate: 0.00575617
	LOSS [training: 0.2560560412687618 | validation: 0.239797713348601]
	TIME [epoch: 9.21 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34168112604727263		[learning rate: 0.0057385]
	Learning Rate: 0.00573852
	LOSS [training: 0.34168112604727263 | validation: 0.34244363814856604]
	TIME [epoch: 9.22 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34844535487000455		[learning rate: 0.0057209]
	Learning Rate: 0.00572093
	LOSS [training: 0.34844535487000455 | validation: 0.16952663476805374]
	TIME [epoch: 9.21 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32909948197084093		[learning rate: 0.0057034]
	Learning Rate: 0.00570339
	LOSS [training: 0.32909948197084093 | validation: 0.7699253090035111]
	TIME [epoch: 9.22 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5159592474215838		[learning rate: 0.0056859]
	Learning Rate: 0.00568591
	LOSS [training: 0.5159592474215838 | validation: 0.7404715584047372]
	TIME [epoch: 9.22 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4172767405445434		[learning rate: 0.0056685]
	Learning Rate: 0.00566848
	LOSS [training: 0.4172767405445434 | validation: 0.39286247635581817]
	TIME [epoch: 9.21 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.417562383830683		[learning rate: 0.0056511]
	Learning Rate: 0.0056511
	LOSS [training: 0.417562383830683 | validation: 0.2946135020554388]
	TIME [epoch: 9.21 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34431325231498777		[learning rate: 0.0056338]
	Learning Rate: 0.00563378
	LOSS [training: 0.34431325231498777 | validation: 0.48476335481312594]
	TIME [epoch: 9.22 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28088075841651267		[learning rate: 0.0056165]
	Learning Rate: 0.00561651
	LOSS [training: 0.28088075841651267 | validation: 0.4347913880973094]
	TIME [epoch: 9.23 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3332070629085796		[learning rate: 0.0055993]
	Learning Rate: 0.00559929
	LOSS [training: 0.3332070629085796 | validation: 0.450900659173053]
	TIME [epoch: 9.22 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34236194198783215		[learning rate: 0.0055821]
	Learning Rate: 0.00558213
	LOSS [training: 0.34236194198783215 | validation: 0.3416301517316369]
	TIME [epoch: 9.21 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3241289705167521		[learning rate: 0.005565]
	Learning Rate: 0.00556502
	LOSS [training: 0.3241289705167521 | validation: 0.4301042556832902]
	TIME [epoch: 9.21 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.297867695869412		[learning rate: 0.005548]
	Learning Rate: 0.00554796
	LOSS [training: 0.297867695869412 | validation: 0.26527494754126646]
	TIME [epoch: 9.22 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31099815078653215		[learning rate: 0.005531]
	Learning Rate: 0.00553095
	LOSS [training: 0.31099815078653215 | validation: 0.29486190641492854]
	TIME [epoch: 9.22 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39042754718661915		[learning rate: 0.005514]
	Learning Rate: 0.005514
	LOSS [training: 0.39042754718661915 | validation: 0.2890777514588847]
	TIME [epoch: 9.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3129311674628862		[learning rate: 0.0054971]
	Learning Rate: 0.0054971
	LOSS [training: 0.3129311674628862 | validation: 0.2521495409440049]
	TIME [epoch: 9.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3945604348759649		[learning rate: 0.0054802]
	Learning Rate: 0.00548025
	LOSS [training: 0.3945604348759649 | validation: 0.23554828454917243]
	TIME [epoch: 9.21 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4215895431687252		[learning rate: 0.0054634]
	Learning Rate: 0.00546345
	LOSS [training: 0.4215895431687252 | validation: 0.39943056382814823]
	TIME [epoch: 9.23 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3469519037048959		[learning rate: 0.0054467]
	Learning Rate: 0.0054467
	LOSS [training: 0.3469519037048959 | validation: 0.21233500437922564]
	TIME [epoch: 9.21 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40463757351975926		[learning rate: 0.00543]
	Learning Rate: 0.00543
	LOSS [training: 0.40463757351975926 | validation: 0.260601792200852]
	TIME [epoch: 9.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4020109270611239		[learning rate: 0.0054134]
	Learning Rate: 0.00541336
	LOSS [training: 0.4020109270611239 | validation: 0.36527670598276785]
	TIME [epoch: 9.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3745874778067415		[learning rate: 0.0053968]
	Learning Rate: 0.00539676
	LOSS [training: 0.3745874778067415 | validation: 0.2068792924063496]
	TIME [epoch: 9.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105095001689268		[learning rate: 0.0053802]
	Learning Rate: 0.00538022
	LOSS [training: 0.3105095001689268 | validation: 0.3981775438153634]
	TIME [epoch: 9.22 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594357131571586		[learning rate: 0.0053637]
	Learning Rate: 0.00536373
	LOSS [training: 0.3594357131571586 | validation: 0.5033977648291111]
	TIME [epoch: 9.19 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46228903134860316		[learning rate: 0.0053473]
	Learning Rate: 0.00534728
	LOSS [training: 0.46228903134860316 | validation: 0.25674790533796205]
	TIME [epoch: 9.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3291220762735599		[learning rate: 0.0053309]
	Learning Rate: 0.00533089
	LOSS [training: 0.3291220762735599 | validation: 0.24097560638274068]
	TIME [epoch: 9.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3153384492893981		[learning rate: 0.0053146]
	Learning Rate: 0.00531455
	LOSS [training: 0.3153384492893981 | validation: 0.19905359550018073]
	TIME [epoch: 9.22 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29622288358110055		[learning rate: 0.0052983]
	Learning Rate: 0.00529826
	LOSS [training: 0.29622288358110055 | validation: 0.3216998451602094]
	TIME [epoch: 9.21 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36440460084365256		[learning rate: 0.005282]
	Learning Rate: 0.00528202
	LOSS [training: 0.36440460084365256 | validation: 0.3185781800521896]
	TIME [epoch: 9.21 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35780062535098794		[learning rate: 0.0052658]
	Learning Rate: 0.00526583
	LOSS [training: 0.35780062535098794 | validation: 0.36354975889186825]
	TIME [epoch: 9.21 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3091920027517085		[learning rate: 0.0052497]
	Learning Rate: 0.00524969
	LOSS [training: 0.3091920027517085 | validation: 0.42290723727957535]
	TIME [epoch: 9.21 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2668711159946241		[learning rate: 0.0052336]
	Learning Rate: 0.00523359
	LOSS [training: 0.2668711159946241 | validation: 0.2695340680718578]
	TIME [epoch: 9.23 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30684419977223965		[learning rate: 0.0052176]
	Learning Rate: 0.00521755
	LOSS [training: 0.30684419977223965 | validation: 0.24995776019316202]
	TIME [epoch: 9.21 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29096591707477887		[learning rate: 0.0052016]
	Learning Rate: 0.00520156
	LOSS [training: 0.29096591707477887 | validation: 0.15795988380145798]
	TIME [epoch: 9.21 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3491970682514946		[learning rate: 0.0051856]
	Learning Rate: 0.00518561
	LOSS [training: 0.3491970682514946 | validation: 0.25625006498561326]
	TIME [epoch: 9.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28063234115936353		[learning rate: 0.0051697]
	Learning Rate: 0.00516972
	LOSS [training: 0.28063234115936353 | validation: 0.3331108950954696]
	TIME [epoch: 9.23 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32746804032965765		[learning rate: 0.0051539]
	Learning Rate: 0.00515387
	LOSS [training: 0.32746804032965765 | validation: 0.2669498347147272]
	TIME [epoch: 9.21 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3209949815827752		[learning rate: 0.0051381]
	Learning Rate: 0.00513807
	LOSS [training: 0.3209949815827752 | validation: 0.5452335126678305]
	TIME [epoch: 9.19 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.424303205688667		[learning rate: 0.0051223]
	Learning Rate: 0.00512232
	LOSS [training: 0.424303205688667 | validation: 0.28058476398304044]
	TIME [epoch: 9.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28667254322770597		[learning rate: 0.0051066]
	Learning Rate: 0.00510662
	LOSS [training: 0.28667254322770597 | validation: 0.26108468194344814]
	TIME [epoch: 9.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37450272070464563		[learning rate: 0.005091]
	Learning Rate: 0.00509096
	LOSS [training: 0.37450272070464563 | validation: 0.22193232747590041]
	TIME [epoch: 9.23 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3309576198315881		[learning rate: 0.0050754]
	Learning Rate: 0.00507536
	LOSS [training: 0.3309576198315881 | validation: 0.30559020962539807]
	TIME [epoch: 9.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47531804509852743		[learning rate: 0.0050598]
	Learning Rate: 0.0050598
	LOSS [training: 0.47531804509852743 | validation: 0.4586841883868216]
	TIME [epoch: 9.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40776000415852875		[learning rate: 0.0050443]
	Learning Rate: 0.00504429
	LOSS [training: 0.40776000415852875 | validation: 0.18953868088848402]
	TIME [epoch: 9.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524718227256755		[learning rate: 0.0050288]
	Learning Rate: 0.00502883
	LOSS [training: 0.3524718227256755 | validation: 0.30929301379356106]
	TIME [epoch: 9.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4149089215021117		[learning rate: 0.0050134]
	Learning Rate: 0.00501341
	LOSS [training: 0.4149089215021117 | validation: 0.25566061760923303]
	TIME [epoch: 9.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.317832808342537		[learning rate: 0.004998]
	Learning Rate: 0.00499804
	LOSS [training: 0.317832808342537 | validation: 0.2452126431840323]
	TIME [epoch: 9.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35390363812024883		[learning rate: 0.0049827]
	Learning Rate: 0.00498272
	LOSS [training: 0.35390363812024883 | validation: 0.23826720608496754]
	TIME [epoch: 9.19 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4560660952786635		[learning rate: 0.0049674]
	Learning Rate: 0.00496745
	LOSS [training: 0.4560660952786635 | validation: 0.5663453941952249]
	TIME [epoch: 9.18 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329516381021994		[learning rate: 0.0049522]
	Learning Rate: 0.00495222
	LOSS [training: 0.3329516381021994 | validation: 0.1955727109891635]
	TIME [epoch: 9.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3664772130983054		[learning rate: 0.004937]
	Learning Rate: 0.00493704
	LOSS [training: 0.3664772130983054 | validation: 0.24029804876892785]
	TIME [epoch: 9.18 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3363216698414764		[learning rate: 0.0049219]
	Learning Rate: 0.00492191
	LOSS [training: 0.3363216698414764 | validation: 0.5454201108612431]
	TIME [epoch: 9.18 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5178170361346334		[learning rate: 0.0049068]
	Learning Rate: 0.00490682
	LOSS [training: 0.5178170361346334 | validation: 0.5707160054135458]
	TIME [epoch: 9.18 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37820175161600667		[learning rate: 0.0048918]
	Learning Rate: 0.00489178
	LOSS [training: 0.37820175161600667 | validation: 0.28398047950328575]
	TIME [epoch: 9.19 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3089238149663146		[learning rate: 0.0048768]
	Learning Rate: 0.00487678
	LOSS [training: 0.3089238149663146 | validation: 0.425558802414305]
	TIME [epoch: 9.17 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3701694691356683		[learning rate: 0.0048618]
	Learning Rate: 0.00486183
	LOSS [training: 0.3701694691356683 | validation: 0.31554678536695235]
	TIME [epoch: 9.18 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3528644018346877		[learning rate: 0.0048469]
	Learning Rate: 0.00484693
	LOSS [training: 0.3528644018346877 | validation: 0.5004730100525223]
	TIME [epoch: 9.17 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2701404927054818		[learning rate: 0.0048321]
	Learning Rate: 0.00483207
	LOSS [training: 1.2701404927054818 | validation: 0.3479325439557146]
	TIME [epoch: 9.17 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36953034746985575		[learning rate: 0.0048173]
	Learning Rate: 0.00481726
	LOSS [training: 0.36953034746985575 | validation: 0.2676952175171696]
	TIME [epoch: 9.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27072764510774305		[learning rate: 0.0048025]
	Learning Rate: 0.00480249
	LOSS [training: 0.27072764510774305 | validation: 0.25122255401333277]
	TIME [epoch: 9.16 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3806673527532919		[learning rate: 0.0047878]
	Learning Rate: 0.00478777
	LOSS [training: 0.3806673527532919 | validation: 0.2801071540158175]
	TIME [epoch: 9.17 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361865532402199		[learning rate: 0.0047731]
	Learning Rate: 0.00477309
	LOSS [training: 0.361865532402199 | validation: 0.25421303583236327]
	TIME [epoch: 9.17 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34065771305745374		[learning rate: 0.0047585]
	Learning Rate: 0.00475846
	LOSS [training: 0.34065771305745374 | validation: 0.2522998032720566]
	TIME [epoch: 9.17 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3504002782822926		[learning rate: 0.0047439]
	Learning Rate: 0.00474388
	LOSS [training: 0.3504002782822926 | validation: 0.2837991358757245]
	TIME [epoch: 9.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3966562971708837		[learning rate: 0.0047293]
	Learning Rate: 0.00472933
	LOSS [training: 0.3966562971708837 | validation: 0.38221083293817826]
	TIME [epoch: 9.15 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38505853658544853		[learning rate: 0.0047148]
	Learning Rate: 0.00471484
	LOSS [training: 0.38505853658544853 | validation: 0.49116801414942535]
	TIME [epoch: 9.16 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4356346177825759		[learning rate: 0.0047004]
	Learning Rate: 0.00470038
	LOSS [training: 0.4356346177825759 | validation: 0.439347518775167]
	TIME [epoch: 9.16 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5234395047546111		[learning rate: 0.004686]
	Learning Rate: 0.00468598
	LOSS [training: 0.5234395047546111 | validation: 0.2996414158688663]
	TIME [epoch: 9.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3845021859801759		[learning rate: 0.0046716]
	Learning Rate: 0.00467161
	LOSS [training: 0.3845021859801759 | validation: 0.3102522793241801]
	TIME [epoch: 9.17 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4064758681876709		[learning rate: 0.0046573]
	Learning Rate: 0.00465729
	LOSS [training: 0.4064758681876709 | validation: 0.19931908898074582]
	TIME [epoch: 9.17 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3997488610323273		[learning rate: 0.004643]
	Learning Rate: 0.00464301
	LOSS [training: 0.3997488610323273 | validation: 0.24623790360094508]
	TIME [epoch: 9.19 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36033928808451854		[learning rate: 0.0046288]
	Learning Rate: 0.00462878
	LOSS [training: 0.36033928808451854 | validation: 0.23886208739802603]
	TIME [epoch: 9.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3511976060572789		[learning rate: 0.0046146]
	Learning Rate: 0.00461459
	LOSS [training: 0.3511976060572789 | validation: 0.23492516031014696]
	TIME [epoch: 9.19 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3994500354890743		[learning rate: 0.0046004]
	Learning Rate: 0.00460045
	LOSS [training: 0.3994500354890743 | validation: 0.4555665858684498]
	TIME [epoch: 9.18 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34496865369814217		[learning rate: 0.0045863]
	Learning Rate: 0.00458634
	LOSS [training: 0.34496865369814217 | validation: 0.26514656440743944]
	TIME [epoch: 9.18 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30549290443270516		[learning rate: 0.0045723]
	Learning Rate: 0.00457229
	LOSS [training: 0.30549290443270516 | validation: 0.3154263223574273]
	TIME [epoch: 9.19 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3256558035958216		[learning rate: 0.0045583]
	Learning Rate: 0.00455827
	LOSS [training: 0.3256558035958216 | validation: 0.3580013117549833]
	TIME [epoch: 9.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38492534384954996		[learning rate: 0.0045443]
	Learning Rate: 0.0045443
	LOSS [training: 0.38492534384954996 | validation: 0.5228534344047799]
	TIME [epoch: 9.16 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296124023797436		[learning rate: 0.0045304]
	Learning Rate: 0.00453037
	LOSS [training: 0.296124023797436 | validation: 0.18523789895944248]
	TIME [epoch: 9.18 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34173238689903807		[learning rate: 0.0045165]
	Learning Rate: 0.00451648
	LOSS [training: 0.34173238689903807 | validation: 0.42950037869362606]
	TIME [epoch: 9.17 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.391802210655265		[learning rate: 0.0045026]
	Learning Rate: 0.00450263
	LOSS [training: 0.391802210655265 | validation: 0.21160050338193165]
	TIME [epoch: 9.19 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3492770252422529		[learning rate: 0.0044888]
	Learning Rate: 0.00448883
	LOSS [training: 0.3492770252422529 | validation: 0.21693455466860173]
	TIME [epoch: 9.18 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3129950317159049		[learning rate: 0.0044751]
	Learning Rate: 0.00447507
	LOSS [training: 0.3129950317159049 | validation: 0.2822434129462077]
	TIME [epoch: 9.17 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2949752275855516		[learning rate: 0.0044614]
	Learning Rate: 0.00446135
	LOSS [training: 0.2949752275855516 | validation: 0.2967592156488583]
	TIME [epoch: 9.17 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285123900930403		[learning rate: 0.0044477]
	Learning Rate: 0.00444768
	LOSS [training: 0.3285123900930403 | validation: 0.594191663060665]
	TIME [epoch: 9.14 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35077598902201557		[learning rate: 0.004434]
	Learning Rate: 0.00443404
	LOSS [training: 0.35077598902201557 | validation: 0.40075865027860247]
	TIME [epoch: 9.21 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3392272675154346		[learning rate: 0.0044205]
	Learning Rate: 0.00442045
	LOSS [training: 0.3392272675154346 | validation: 0.23148486446928856]
	TIME [epoch: 9.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046470959784797		[learning rate: 0.0044069]
	Learning Rate: 0.0044069
	LOSS [training: 0.3046470959784797 | validation: 0.4322981044091606]
	TIME [epoch: 9.17 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29422993452547774		[learning rate: 0.0043934]
	Learning Rate: 0.00439339
	LOSS [training: 0.29422993452547774 | validation: 0.6211525086637283]
	TIME [epoch: 9.17 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3116321296962709		[learning rate: 0.0043799]
	Learning Rate: 0.00437992
	LOSS [training: 0.3116321296962709 | validation: 0.38354178641218506]
	TIME [epoch: 9.18 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3302062072597637		[learning rate: 0.0043665]
	Learning Rate: 0.0043665
	LOSS [training: 0.3302062072597637 | validation: 0.2664850013373623]
	TIME [epoch: 9.17 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30468525534762164		[learning rate: 0.0043531]
	Learning Rate: 0.00435311
	LOSS [training: 0.30468525534762164 | validation: 0.26486401469171417]
	TIME [epoch: 9.17 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.301591497746015		[learning rate: 0.0043398]
	Learning Rate: 0.00433977
	LOSS [training: 0.301591497746015 | validation: 0.2608893818571764]
	TIME [epoch: 9.16 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25282479443415695		[learning rate: 0.0043265]
	Learning Rate: 0.00432647
	LOSS [training: 0.25282479443415695 | validation: 0.3583692464179066]
	TIME [epoch: 9.18 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053253447321809		[learning rate: 0.0043132]
	Learning Rate: 0.0043132
	LOSS [training: 0.3053253447321809 | validation: 0.2933475205295454]
	TIME [epoch: 9.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011708468235567		[learning rate: 0.0043]
	Learning Rate: 0.00429998
	LOSS [training: 0.3011708468235567 | validation: 0.30407567061872304]
	TIME [epoch: 9.16 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29839877793316394		[learning rate: 0.0042868]
	Learning Rate: 0.0042868
	LOSS [training: 0.29839877793316394 | validation: 0.38708031804778353]
	TIME [epoch: 9.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29346529484755884		[learning rate: 0.0042737]
	Learning Rate: 0.00427366
	LOSS [training: 0.29346529484755884 | validation: 0.4145944558909188]
	TIME [epoch: 9.16 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30118875035115567		[learning rate: 0.0042606]
	Learning Rate: 0.00426056
	LOSS [training: 0.30118875035115567 | validation: 0.21720852126352255]
	TIME [epoch: 9.19 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917658567061954		[learning rate: 0.0042475]
	Learning Rate: 0.0042475
	LOSS [training: 0.3917658567061954 | validation: 0.12513002830534153]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30130624068353085		[learning rate: 0.0042345]
	Learning Rate: 0.00423448
	LOSS [training: 0.30130624068353085 | validation: 0.21766050490747454]
	TIME [epoch: 9.21 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4685789913706735		[learning rate: 0.0042215]
	Learning Rate: 0.0042215
	LOSS [training: 0.4685789913706735 | validation: 0.719925816026083]
	TIME [epoch: 9.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3870984050029255		[learning rate: 0.0042086]
	Learning Rate: 0.00420856
	LOSS [training: 0.3870984050029255 | validation: 0.2709712957725232]
	TIME [epoch: 9.21 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2963811601344655		[learning rate: 0.0041957]
	Learning Rate: 0.00419566
	LOSS [training: 0.2963811601344655 | validation: 0.24149175309478638]
	TIME [epoch: 9.23 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2703515326665761		[learning rate: 0.0041828]
	Learning Rate: 0.0041828
	LOSS [training: 0.2703515326665761 | validation: 0.2963332249101135]
	TIME [epoch: 9.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4916432578583563		[learning rate: 0.00417]
	Learning Rate: 0.00416997
	LOSS [training: 0.4916432578583563 | validation: 0.22422944249288335]
	TIME [epoch: 9.21 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3399352554388483		[learning rate: 0.0041572]
	Learning Rate: 0.00415719
	LOSS [training: 0.3399352554388483 | validation: 0.27166607153242667]
	TIME [epoch: 9.19 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2644770938049733		[learning rate: 0.0041444]
	Learning Rate: 0.00414445
	LOSS [training: 0.2644770938049733 | validation: 0.1826207810549659]
	TIME [epoch: 9.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3024082915826625		[learning rate: 0.0041317]
	Learning Rate: 0.00413174
	LOSS [training: 0.3024082915826625 | validation: 0.26384904069482606]
	TIME [epoch: 9.21 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2871346519209454		[learning rate: 0.0041191]
	Learning Rate: 0.00411908
	LOSS [training: 0.2871346519209454 | validation: 0.30225195511442615]
	TIME [epoch: 9.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3403226817996699		[learning rate: 0.0041065]
	Learning Rate: 0.00410645
	LOSS [training: 0.3403226817996699 | validation: 0.23133375459304867]
	TIME [epoch: 9.19 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34065664515433597		[learning rate: 0.0040939]
	Learning Rate: 0.00409386
	LOSS [training: 0.34065664515433597 | validation: 0.31570079440615206]
	TIME [epoch: 9.19 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3615892274953482		[learning rate: 0.0040813]
	Learning Rate: 0.00408131
	LOSS [training: 0.3615892274953482 | validation: 0.19426707222066053]
	TIME [epoch: 9.24 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24311866799425624		[learning rate: 0.0040688]
	Learning Rate: 0.0040688
	LOSS [training: 0.24311866799425624 | validation: 0.1310846926400586]
	TIME [epoch: 9.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622949273479579		[learning rate: 0.0040563]
	Learning Rate: 0.00405633
	LOSS [training: 0.2622949273479579 | validation: 0.22964319197765656]
	TIME [epoch: 9.22 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28422002487194914		[learning rate: 0.0040439]
	Learning Rate: 0.0040439
	LOSS [training: 0.28422002487194914 | validation: 0.21446776834379058]
	TIME [epoch: 9.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054866042917408		[learning rate: 0.0040315]
	Learning Rate: 0.0040315
	LOSS [training: 0.3054866042917408 | validation: 0.41139752152504677]
	TIME [epoch: 9.19 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3225897687966382		[learning rate: 0.0040191]
	Learning Rate: 0.00401914
	LOSS [training: 0.3225897687966382 | validation: 0.29184949429293816]
	TIME [epoch: 9.23 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27831406666356495		[learning rate: 0.0040068]
	Learning Rate: 0.00400682
	LOSS [training: 0.27831406666356495 | validation: 0.20076928877240127]
	TIME [epoch: 9.22 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.407042540624267		[learning rate: 0.0039945]
	Learning Rate: 0.00399454
	LOSS [training: 0.407042540624267 | validation: 0.2175046577313544]
	TIME [epoch: 9.21 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3503414941824816		[learning rate: 0.0039823]
	Learning Rate: 0.00398229
	LOSS [training: 0.3503414941824816 | validation: 0.2799154983406843]
	TIME [epoch: 9.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36454873097178864		[learning rate: 0.0039701]
	Learning Rate: 0.00397009
	LOSS [training: 0.36454873097178864 | validation: 0.2037555300605965]
	TIME [epoch: 9.23 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30687541758876513		[learning rate: 0.0039579]
	Learning Rate: 0.00395792
	LOSS [training: 0.30687541758876513 | validation: 0.18013330525122204]
	TIME [epoch: 9.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3536567401288084		[learning rate: 0.0039458]
	Learning Rate: 0.00394578
	LOSS [training: 0.3536567401288084 | validation: 0.5719399456762568]
	TIME [epoch: 9.19 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33152775645870347		[learning rate: 0.0039337]
	Learning Rate: 0.00393369
	LOSS [training: 0.33152775645870347 | validation: 0.2747283015818467]
	TIME [epoch: 9.21 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2962025514686216		[learning rate: 0.0039216]
	Learning Rate: 0.00392163
	LOSS [training: 0.2962025514686216 | validation: 0.44007775477452526]
	TIME [epoch: 9.19 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30156788470113255		[learning rate: 0.0039096]
	Learning Rate: 0.00390961
	LOSS [training: 0.30156788470113255 | validation: 0.539494852151192]
	TIME [epoch: 9.23 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3646951360119021		[learning rate: 0.0038976]
	Learning Rate: 0.00389762
	LOSS [training: 0.3646951360119021 | validation: 0.6436057415064356]
	TIME [epoch: 9.19 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3788851392049236		[learning rate: 0.0038857]
	Learning Rate: 0.00388568
	LOSS [training: 0.3788851392049236 | validation: 0.3369711500435889]
	TIME [epoch: 9.21 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37671639913834964		[learning rate: 0.0038738]
	Learning Rate: 0.00387377
	LOSS [training: 0.37671639913834964 | validation: 0.38792131913083605]
	TIME [epoch: 9.19 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38511731445632946		[learning rate: 0.0038619]
	Learning Rate: 0.00386189
	LOSS [training: 0.38511731445632946 | validation: 0.2741992980146919]
	TIME [epoch: 9.23 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3810730859128199		[learning rate: 0.0038501]
	Learning Rate: 0.00385005
	LOSS [training: 0.3810730859128199 | validation: 0.2256665753373104]
	TIME [epoch: 9.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47261579046197566		[learning rate: 0.0038383]
	Learning Rate: 0.00383825
	LOSS [training: 0.47261579046197566 | validation: 0.6977149422931329]
	TIME [epoch: 9.21 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4416845216161939		[learning rate: 0.0038265]
	Learning Rate: 0.00382648
	LOSS [training: 0.4416845216161939 | validation: 0.22922987863432362]
	TIME [epoch: 9.22 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31110269580014865		[learning rate: 0.0038148]
	Learning Rate: 0.00381476
	LOSS [training: 0.31110269580014865 | validation: 0.32919855919238783]
	TIME [epoch: 9.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43276965281821517		[learning rate: 0.0038031]
	Learning Rate: 0.00380306
	LOSS [training: 0.43276965281821517 | validation: 0.22369565995632698]
	TIME [epoch: 9.22 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3689443353843821		[learning rate: 0.0037914]
	Learning Rate: 0.0037914
	LOSS [training: 0.3689443353843821 | validation: 0.2462884768213524]
	TIME [epoch: 9.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3349279954984619		[learning rate: 0.0037798]
	Learning Rate: 0.00377978
	LOSS [training: 0.3349279954984619 | validation: 0.24199465358828948]
	TIME [epoch: 9.21 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32309467519897606		[learning rate: 0.0037682]
	Learning Rate: 0.00376819
	LOSS [training: 0.32309467519897606 | validation: 0.24116906782932807]
	TIME [epoch: 9.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37992999467680394		[learning rate: 0.0037566]
	Learning Rate: 0.00375664
	LOSS [training: 0.37992999467680394 | validation: 0.29739300392004625]
	TIME [epoch: 9.22 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3998138721018631		[learning rate: 0.0037451]
	Learning Rate: 0.00374513
	LOSS [training: 0.3998138721018631 | validation: 0.2629444721504732]
	TIME [epoch: 9.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2810946084276483		[learning rate: 0.0037336]
	Learning Rate: 0.00373365
	LOSS [training: 0.2810946084276483 | validation: 0.3243941239629335]
	TIME [epoch: 9.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970456590823011		[learning rate: 0.0037222]
	Learning Rate: 0.0037222
	LOSS [training: 0.2970456590823011 | validation: 0.2530130931067526]
	TIME [epoch: 9.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3254369881679209		[learning rate: 0.0037108]
	Learning Rate: 0.00371079
	LOSS [training: 0.3254369881679209 | validation: 0.22582135762415703]
	TIME [epoch: 9.19 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24861320975807014		[learning rate: 0.0036994]
	Learning Rate: 0.00369942
	LOSS [training: 0.24861320975807014 | validation: 0.2743075581315681]
	TIME [epoch: 9.22 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26698436828348937		[learning rate: 0.0036881]
	Learning Rate: 0.00368808
	LOSS [training: 0.26698436828348937 | validation: 0.24976401351982197]
	TIME [epoch: 9.21 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24706641732114676		[learning rate: 0.0036768]
	Learning Rate: 0.00367677
	LOSS [training: 0.24706641732114676 | validation: 0.2561138793772824]
	TIME [epoch: 9.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2781387074442906		[learning rate: 0.0036655]
	Learning Rate: 0.0036655
	LOSS [training: 0.2781387074442906 | validation: 0.31694484275375895]
	TIME [epoch: 9.21 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23168064860922702		[learning rate: 0.0036543]
	Learning Rate: 0.00365426
	LOSS [training: 0.23168064860922702 | validation: 0.262921657603538]
	TIME [epoch: 9.21 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2602249936588487		[learning rate: 0.0036431]
	Learning Rate: 0.00364306
	LOSS [training: 0.2602249936588487 | validation: 0.28537093239138045]
	TIME [epoch: 9.21 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29631575883805245		[learning rate: 0.0036319]
	Learning Rate: 0.0036319
	LOSS [training: 0.29631575883805245 | validation: 0.6319654917465396]
	TIME [epoch: 9.18 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3818408254024181		[learning rate: 0.0036208]
	Learning Rate: 0.00362076
	LOSS [training: 0.3818408254024181 | validation: 0.4641698305083966]
	TIME [epoch: 9.21 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23751386725194218		[learning rate: 0.0036097]
	Learning Rate: 0.00360966
	LOSS [training: 0.23751386725194218 | validation: 0.2661434234627087]
	TIME [epoch: 9.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750669297441929		[learning rate: 0.0035986]
	Learning Rate: 0.0035986
	LOSS [training: 0.2750669297441929 | validation: 0.18349037164349202]
	TIME [epoch: 9.22 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24615293750422879		[learning rate: 0.0035876]
	Learning Rate: 0.00358757
	LOSS [training: 0.24615293750422879 | validation: 0.19432197209521207]
	TIME [epoch: 9.21 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26366895371794763		[learning rate: 0.0035766]
	Learning Rate: 0.00357657
	LOSS [training: 0.26366895371794763 | validation: 0.20092016959115006]
	TIME [epoch: 9.19 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27362729317082624		[learning rate: 0.0035656]
	Learning Rate: 0.00356561
	LOSS [training: 0.27362729317082624 | validation: 0.1388484377731682]
	TIME [epoch: 9.21 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34249960085207815		[learning rate: 0.0035547]
	Learning Rate: 0.00355468
	LOSS [training: 0.34249960085207815 | validation: 0.32768262068192866]
	TIME [epoch: 9.22 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2906676525643069		[learning rate: 0.0035438]
	Learning Rate: 0.00354378
	LOSS [training: 0.2906676525643069 | validation: 0.16340684231426103]
	TIME [epoch: 9.22 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29612782111578567		[learning rate: 0.0035329]
	Learning Rate: 0.00353292
	LOSS [training: 0.29612782111578567 | validation: 0.22591087378392521]
	TIME [epoch: 9.21 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22626969631056645		[learning rate: 0.0035221]
	Learning Rate: 0.00352209
	LOSS [training: 0.22626969631056645 | validation: 0.22830210948950533]
	TIME [epoch: 9.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641832283428222		[learning rate: 0.0035113]
	Learning Rate: 0.00351129
	LOSS [training: 0.2641832283428222 | validation: 0.25273075243457527]
	TIME [epoch: 9.21 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2629792525276248		[learning rate: 0.0035005]
	Learning Rate: 0.00350053
	LOSS [training: 0.2629792525276248 | validation: 0.4598256296840224]
	TIME [epoch: 9.24 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560859073490066		[learning rate: 0.0034898]
	Learning Rate: 0.0034898
	LOSS [training: 0.2560859073490066 | validation: 0.37340208548075926]
	TIME [epoch: 9.19 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3133234923612884		[learning rate: 0.0034791]
	Learning Rate: 0.0034791
	LOSS [training: 0.3133234923612884 | validation: 0.2226554902273451]
	TIME [epoch: 9.21 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2749600185564977		[learning rate: 0.0034684]
	Learning Rate: 0.00346843
	LOSS [training: 0.2749600185564977 | validation: 0.18462008815669861]
	TIME [epoch: 9.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29080795318133235		[learning rate: 0.0034578]
	Learning Rate: 0.0034578
	LOSS [training: 0.29080795318133235 | validation: 0.25723461295154615]
	TIME [epoch: 9.22 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32644283916157285		[learning rate: 0.0034472]
	Learning Rate: 0.0034472
	LOSS [training: 0.32644283916157285 | validation: 0.17787723034393965]
	TIME [epoch: 9.21 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31960227740702785		[learning rate: 0.0034366]
	Learning Rate: 0.00343663
	LOSS [training: 0.31960227740702785 | validation: 0.35794457832263205]
	TIME [epoch: 9.21 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28312537449986097		[learning rate: 0.0034261]
	Learning Rate: 0.0034261
	LOSS [training: 0.28312537449986097 | validation: 0.17139759006586214]
	TIME [epoch: 9.21 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23088207562269997		[learning rate: 0.0034156]
	Learning Rate: 0.0034156
	LOSS [training: 0.23088207562269997 | validation: 0.155548149358744]
	TIME [epoch: 9.21 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26584977867654613		[learning rate: 0.0034051]
	Learning Rate: 0.00340513
	LOSS [training: 0.26584977867654613 | validation: 0.24340791646867285]
	TIME [epoch: 9.21 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27320404015777966		[learning rate: 0.0033947]
	Learning Rate: 0.00339469
	LOSS [training: 0.27320404015777966 | validation: 0.25380806034608966]
	TIME [epoch: 9.22 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2282826350916624		[learning rate: 0.0033843]
	Learning Rate: 0.00338428
	LOSS [training: 0.2282826350916624 | validation: 0.11967843042917208]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.406242170725349		[learning rate: 0.0033739]
	Learning Rate: 0.00337391
	LOSS [training: 0.406242170725349 | validation: 0.286064871739204]
	TIME [epoch: 9.22 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24392334598093143		[learning rate: 0.0033636]
	Learning Rate: 0.00336357
	LOSS [training: 0.24392334598093143 | validation: 0.18383293851885302]
	TIME [epoch: 9.22 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.318700752308487		[learning rate: 0.0033533]
	Learning Rate: 0.00335326
	LOSS [training: 0.318700752308487 | validation: 0.2134752505142501]
	TIME [epoch: 9.23 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2091712272900502		[learning rate: 0.003343]
	Learning Rate: 0.00334298
	LOSS [training: 0.2091712272900502 | validation: 0.1987670022415846]
	TIME [epoch: 9.23 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21781279162179196		[learning rate: 0.0033327]
	Learning Rate: 0.00333273
	LOSS [training: 0.21781279162179196 | validation: 0.22825836155697504]
	TIME [epoch: 9.22 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43237528111367995		[learning rate: 0.0033225]
	Learning Rate: 0.00332251
	LOSS [training: 0.43237528111367995 | validation: 0.3915142090229098]
	TIME [epoch: 9.22 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4423337002674126		[learning rate: 0.0033123]
	Learning Rate: 0.00331233
	LOSS [training: 0.4423337002674126 | validation: 0.3167182229818674]
	TIME [epoch: 9.25 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25463594342934226		[learning rate: 0.0033022]
	Learning Rate: 0.00330217
	LOSS [training: 0.25463594342934226 | validation: 0.26731558494349117]
	TIME [epoch: 9.21 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2377832341307426		[learning rate: 0.0032921]
	Learning Rate: 0.00329205
	LOSS [training: 0.2377832341307426 | validation: 0.18787560973971848]
	TIME [epoch: 9.22 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24390742476699687		[learning rate: 0.003282]
	Learning Rate: 0.00328196
	LOSS [training: 0.24390742476699687 | validation: 0.49378689610790805]
	TIME [epoch: 9.22 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727938284927695		[learning rate: 0.0032719]
	Learning Rate: 0.0032719
	LOSS [training: 0.2727938284927695 | validation: 0.22650984665098092]
	TIME [epoch: 9.22 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23280763893688167		[learning rate: 0.0032619]
	Learning Rate: 0.00326187
	LOSS [training: 0.23280763893688167 | validation: 0.22323263731928422]
	TIME [epoch: 9.23 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1944636455705644		[learning rate: 0.0032519]
	Learning Rate: 0.00325187
	LOSS [training: 0.1944636455705644 | validation: 0.14761282832453243]
	TIME [epoch: 9.24 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25755398054431855		[learning rate: 0.0032419]
	Learning Rate: 0.0032419
	LOSS [training: 0.25755398054431855 | validation: 0.14150966493750172]
	TIME [epoch: 9.24 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42455567151585905		[learning rate: 0.003232]
	Learning Rate: 0.00323197
	LOSS [training: 0.42455567151585905 | validation: 0.1847503582779095]
	TIME [epoch: 9.23 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21205324233608014		[learning rate: 0.0032221]
	Learning Rate: 0.00322206
	LOSS [training: 0.21205324233608014 | validation: 0.28090805340615244]
	TIME [epoch: 9.25 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2220779620709305		[learning rate: 0.0032122]
	Learning Rate: 0.00321218
	LOSS [training: 0.2220779620709305 | validation: 0.24763608000947868]
	TIME [epoch: 9.23 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1871272209334168		[learning rate: 0.0032023]
	Learning Rate: 0.00320233
	LOSS [training: 0.1871272209334168 | validation: 0.25565879112313994]
	TIME [epoch: 9.27 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3086912746872436		[learning rate: 0.0031925]
	Learning Rate: 0.00319252
	LOSS [training: 0.3086912746872436 | validation: 0.15625739964609142]
	TIME [epoch: 9.23 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1951272786872576		[learning rate: 0.0031827]
	Learning Rate: 0.00318273
	LOSS [training: 0.1951272786872576 | validation: 0.16269260343141306]
	TIME [epoch: 9.23 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3146017495835052		[learning rate: 0.003173]
	Learning Rate: 0.00317297
	LOSS [training: 0.3146017495835052 | validation: 0.2402452334875043]
	TIME [epoch: 9.24 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27394267759442226		[learning rate: 0.0031632]
	Learning Rate: 0.00316325
	LOSS [training: 0.27394267759442226 | validation: 0.19640512450548553]
	TIME [epoch: 9.22 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2951803506201334		[learning rate: 0.0031536]
	Learning Rate: 0.00315355
	LOSS [training: 0.2951803506201334 | validation: 0.30175589942883607]
	TIME [epoch: 9.22 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21104305948073163		[learning rate: 0.0031439]
	Learning Rate: 0.00314389
	LOSS [training: 0.21104305948073163 | validation: 0.1933341052675388]
	TIME [epoch: 9.22 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19016481577417282		[learning rate: 0.0031342]
	Learning Rate: 0.00313425
	LOSS [training: 0.19016481577417282 | validation: 0.1727225341707247]
	TIME [epoch: 9.25 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23367188733955452		[learning rate: 0.0031246]
	Learning Rate: 0.00312464
	LOSS [training: 0.23367188733955452 | validation: 0.22508028833517274]
	TIME [epoch: 9.23 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25322613944501576		[learning rate: 0.0031151]
	Learning Rate: 0.00311506
	LOSS [training: 0.25322613944501576 | validation: 0.14140597955479145]
	TIME [epoch: 9.22 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25558962655801487		[learning rate: 0.0031055]
	Learning Rate: 0.00310551
	LOSS [training: 0.25558962655801487 | validation: 0.19361141385510405]
	TIME [epoch: 9.23 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18784102338532788		[learning rate: 0.003096]
	Learning Rate: 0.00309599
	LOSS [training: 0.18784102338532788 | validation: 0.268510345809411]
	TIME [epoch: 9.22 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20612102187042822		[learning rate: 0.0030865]
	Learning Rate: 0.0030865
	LOSS [training: 0.20612102187042822 | validation: 0.21361428320263093]
	TIME [epoch: 9.23 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17139348338757163		[learning rate: 0.003077]
	Learning Rate: 0.00307704
	LOSS [training: 0.17139348338757163 | validation: 0.07975523540836896]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_884.pth
	Model improved!!!
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28927088066498063		[learning rate: 0.0030676]
	Learning Rate: 0.00306761
	LOSS [training: 0.28927088066498063 | validation: 0.32734777613369326]
	TIME [epoch: 9.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.327641700219533		[learning rate: 0.0030582]
	Learning Rate: 0.00305821
	LOSS [training: 0.327641700219533 | validation: 0.2780594266308758]
	TIME [epoch: 9.21 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28660239789316627		[learning rate: 0.0030488]
	Learning Rate: 0.00304883
	LOSS [training: 0.28660239789316627 | validation: 0.13847185817971497]
	TIME [epoch: 9.22 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20670112391206136		[learning rate: 0.0030395]
	Learning Rate: 0.00303948
	LOSS [training: 0.20670112391206136 | validation: 0.15799612202468322]
	TIME [epoch: 9.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24857777154249003		[learning rate: 0.0030302]
	Learning Rate: 0.00303017
	LOSS [training: 0.24857777154249003 | validation: 0.21281388533919854]
	TIME [epoch: 9.19 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2233657071361029		[learning rate: 0.0030209]
	Learning Rate: 0.00302088
	LOSS [training: 0.2233657071361029 | validation: 0.17360892971729708]
	TIME [epoch: 9.22 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1972305398620691		[learning rate: 0.0030116]
	Learning Rate: 0.00301162
	LOSS [training: 0.1972305398620691 | validation: 0.3681783154980507]
	TIME [epoch: 9.22 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21507303518645743		[learning rate: 0.0030024]
	Learning Rate: 0.00300239
	LOSS [training: 0.21507303518645743 | validation: 0.170056305921143]
	TIME [epoch: 9.22 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18866178266670122		[learning rate: 0.0029932]
	Learning Rate: 0.00299318
	LOSS [training: 0.18866178266670122 | validation: 0.19696422657396379]
	TIME [epoch: 9.22 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2768122947260057		[learning rate: 0.002984]
	Learning Rate: 0.00298401
	LOSS [training: 0.2768122947260057 | validation: 0.15945541826714144]
	TIME [epoch: 9.21 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389720317677079		[learning rate: 0.0029749]
	Learning Rate: 0.00297486
	LOSS [training: 0.2389720317677079 | validation: 0.19397477135319924]
	TIME [epoch: 9.22 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278050565731371		[learning rate: 0.0029657]
	Learning Rate: 0.00296574
	LOSS [training: 0.2278050565731371 | validation: 0.22197627418465182]
	TIME [epoch: 9.23 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21857457911118253		[learning rate: 0.0029567]
	Learning Rate: 0.00295665
	LOSS [training: 0.21857457911118253 | validation: 0.07912122203384145]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24184786502125655		[learning rate: 0.0029476]
	Learning Rate: 0.00294759
	LOSS [training: 0.24184786502125655 | validation: 0.17230170408277756]
	TIME [epoch: 9.29 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22098286825268784		[learning rate: 0.0029386]
	Learning Rate: 0.00293855
	LOSS [training: 0.22098286825268784 | validation: 0.38889435424263274]
	TIME [epoch: 9.22 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32077288444436813		[learning rate: 0.0029295]
	Learning Rate: 0.00292954
	LOSS [training: 0.32077288444436813 | validation: 0.6495276127937777]
	TIME [epoch: 9.21 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646564948350983		[learning rate: 0.0029206]
	Learning Rate: 0.00292056
	LOSS [training: 0.2646564948350983 | validation: 0.15681749767755732]
	TIME [epoch: 9.23 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17098374795226715		[learning rate: 0.0029116]
	Learning Rate: 0.00291161
	LOSS [training: 0.17098374795226715 | validation: 0.24170924661069476]
	TIME [epoch: 9.21 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1964039126250585		[learning rate: 0.0029027]
	Learning Rate: 0.00290269
	LOSS [training: 0.1964039126250585 | validation: 0.19902898765701604]
	TIME [epoch: 9.22 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19184014121449977		[learning rate: 0.0028938]
	Learning Rate: 0.00289379
	LOSS [training: 0.19184014121449977 | validation: 0.157710633402889]
	TIME [epoch: 9.21 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21109398393172532		[learning rate: 0.0028849]
	Learning Rate: 0.00288492
	LOSS [training: 0.21109398393172532 | validation: 0.14979170866948163]
	TIME [epoch: 9.23 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19910575881387627		[learning rate: 0.0028761]
	Learning Rate: 0.00287607
	LOSS [training: 0.19910575881387627 | validation: 0.10102748636085929]
	TIME [epoch: 9.22 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2222984327111249		[learning rate: 0.0028673]
	Learning Rate: 0.00286726
	LOSS [training: 0.2222984327111249 | validation: 0.16802390922889393]
	TIME [epoch: 9.22 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24889984171810933		[learning rate: 0.0028585]
	Learning Rate: 0.00285847
	LOSS [training: 0.24889984171810933 | validation: 0.1809892983462416]
	TIME [epoch: 9.21 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23259578693072683		[learning rate: 0.0028497]
	Learning Rate: 0.00284971
	LOSS [training: 0.23259578693072683 | validation: 0.15986162633091547]
	TIME [epoch: 9.22 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23359601551325468		[learning rate: 0.002841]
	Learning Rate: 0.00284097
	LOSS [training: 0.23359601551325468 | validation: 0.11597021119139236]
	TIME [epoch: 9.23 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20925052197247979		[learning rate: 0.0028323]
	Learning Rate: 0.00283226
	LOSS [training: 0.20925052197247979 | validation: 0.14627192591918148]
	TIME [epoch: 9.22 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17748593493087036		[learning rate: 0.0028236]
	Learning Rate: 0.00282358
	LOSS [training: 0.17748593493087036 | validation: 0.19562944291308243]
	TIME [epoch: 9.21 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23237177146244803		[learning rate: 0.0028149]
	Learning Rate: 0.00281492
	LOSS [training: 0.23237177146244803 | validation: 0.1755464644197053]
	TIME [epoch: 9.21 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21581715022022205		[learning rate: 0.0028063]
	Learning Rate: 0.0028063
	LOSS [training: 0.21581715022022205 | validation: 0.17345802898122464]
	TIME [epoch: 9.23 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18438290455905418		[learning rate: 0.0027977]
	Learning Rate: 0.00279769
	LOSS [training: 0.18438290455905418 | validation: 0.17305372589270884]
	TIME [epoch: 9.21 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215995875053303		[learning rate: 0.0027891]
	Learning Rate: 0.00278912
	LOSS [training: 0.215995875053303 | validation: 0.1826975217436787]
	TIME [epoch: 9.21 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20286925560369878		[learning rate: 0.0027806]
	Learning Rate: 0.00278057
	LOSS [training: 0.20286925560369878 | validation: 0.1558564715976153]
	TIME [epoch: 9.22 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20887103339749138		[learning rate: 0.002772]
	Learning Rate: 0.00277204
	LOSS [training: 0.20887103339749138 | validation: 0.1513201020138092]
	TIME [epoch: 9.21 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18898674548035574		[learning rate: 0.0027635]
	Learning Rate: 0.00276355
	LOSS [training: 0.18898674548035574 | validation: 0.15811885817053403]
	TIME [epoch: 9.23 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25864798848999054		[learning rate: 0.0027551]
	Learning Rate: 0.00275507
	LOSS [training: 0.25864798848999054 | validation: 0.15595931864476756]
	TIME [epoch: 9.22 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23707380643565537		[learning rate: 0.0027466]
	Learning Rate: 0.00274663
	LOSS [training: 0.23707380643565537 | validation: 0.20465879050651797]
	TIME [epoch: 9.22 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2395855144378572		[learning rate: 0.0027382]
	Learning Rate: 0.00273821
	LOSS [training: 0.2395855144378572 | validation: 0.13141746826502515]
	TIME [epoch: 9.21 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24119354944679056		[learning rate: 0.0027298]
	Learning Rate: 0.00272982
	LOSS [training: 0.24119354944679056 | validation: 0.34721452304287925]
	TIME [epoch: 9.24 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20373606965881788		[learning rate: 0.0027214]
	Learning Rate: 0.00272145
	LOSS [training: 0.20373606965881788 | validation: 0.12000309283315354]
	TIME [epoch: 9.23 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1683892340072074		[learning rate: 0.0027131]
	Learning Rate: 0.00271311
	LOSS [training: 0.1683892340072074 | validation: 0.19601119111457643]
	TIME [epoch: 9.21 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2292430358473562		[learning rate: 0.0027048]
	Learning Rate: 0.00270479
	LOSS [training: 0.2292430358473562 | validation: 0.13677769071242707]
	TIME [epoch: 9.22 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22108603729444315		[learning rate: 0.0026965]
	Learning Rate: 0.0026965
	LOSS [training: 0.22108603729444315 | validation: 0.29135670615234055]
	TIME [epoch: 9.23 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2198817861774338		[learning rate: 0.0026882]
	Learning Rate: 0.00268823
	LOSS [training: 0.2198817861774338 | validation: 0.24969007874219598]
	TIME [epoch: 9.23 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19809775833760163		[learning rate: 0.00268]
	Learning Rate: 0.00267999
	LOSS [training: 0.19809775833760163 | validation: 0.2571119073952164]
	TIME [epoch: 9.23 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18902009826959013		[learning rate: 0.0026718]
	Learning Rate: 0.00267178
	LOSS [training: 0.18902009826959013 | validation: 0.10740759057257221]
	TIME [epoch: 9.21 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519417863675042		[learning rate: 0.0026636]
	Learning Rate: 0.00266359
	LOSS [training: 0.1519417863675042 | validation: 0.09836862749570667]
	TIME [epoch: 9.23 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2316574458183759		[learning rate: 0.0026554]
	Learning Rate: 0.00265542
	LOSS [training: 0.2316574458183759 | validation: 0.14129072415661353]
	TIME [epoch: 9.24 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15995574737658114		[learning rate: 0.0026473]
	Learning Rate: 0.00264728
	LOSS [training: 0.15995574737658114 | validation: 0.2036351149208867]
	TIME [epoch: 9.22 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19945795092664345		[learning rate: 0.0026392]
	Learning Rate: 0.00263917
	LOSS [training: 0.19945795092664345 | validation: 0.24795803989635545]
	TIME [epoch: 9.22 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22047726764570896		[learning rate: 0.0026311]
	Learning Rate: 0.00263108
	LOSS [training: 0.22047726764570896 | validation: 0.2590228134236324]
	TIME [epoch: 9.22 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2309500246670909		[learning rate: 0.002623]
	Learning Rate: 0.00262301
	LOSS [training: 0.2309500246670909 | validation: 0.14046944459900895]
	TIME [epoch: 9.23 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20686425971453898		[learning rate: 0.002615]
	Learning Rate: 0.00261497
	LOSS [training: 0.20686425971453898 | validation: 0.5301933182074214]
	TIME [epoch: 9.24 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23529998796806967		[learning rate: 0.002607]
	Learning Rate: 0.00260695
	LOSS [training: 0.23529998796806967 | validation: 0.17388431174706506]
	TIME [epoch: 9.22 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18411552025521516		[learning rate: 0.002599]
	Learning Rate: 0.00259896
	LOSS [training: 0.18411552025521516 | validation: 0.3190914667127749]
	TIME [epoch: 9.21 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725418639047441		[learning rate: 0.002591]
	Learning Rate: 0.002591
	LOSS [training: 0.2725418639047441 | validation: 0.2871767174495067]
	TIME [epoch: 9.22 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18250799926367994		[learning rate: 0.0025831]
	Learning Rate: 0.00258305
	LOSS [training: 0.18250799926367994 | validation: 0.17686053393248655]
	TIME [epoch: 9.24 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18996003342748588		[learning rate: 0.0025751]
	Learning Rate: 0.00257513
	LOSS [training: 0.18996003342748588 | validation: 0.1475424877948916]
	TIME [epoch: 9.22 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1815736235160855		[learning rate: 0.0025672]
	Learning Rate: 0.00256724
	LOSS [training: 0.1815736235160855 | validation: 0.11877381536508691]
	TIME [epoch: 9.23 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15153361185189496		[learning rate: 0.0025594]
	Learning Rate: 0.00255937
	LOSS [training: 0.15153361185189496 | validation: 0.2603271127764768]
	TIME [epoch: 9.22 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18557091208413318		[learning rate: 0.0025515]
	Learning Rate: 0.00255153
	LOSS [training: 0.18557091208413318 | validation: 0.1396248511171837]
	TIME [epoch: 9.23 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1775881695117064		[learning rate: 0.0025437]
	Learning Rate: 0.0025437
	LOSS [training: 0.1775881695117064 | validation: 0.2550162593004543]
	TIME [epoch: 9.23 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513784467191891		[learning rate: 0.0025359]
	Learning Rate: 0.00253591
	LOSS [training: 0.1513784467191891 | validation: 0.215557626549184]
	TIME [epoch: 9.22 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649388962961176		[learning rate: 0.0025281]
	Learning Rate: 0.00252813
	LOSS [training: 0.2649388962961176 | validation: 0.19307551589917804]
	TIME [epoch: 9.22 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627241613004548		[learning rate: 0.0025204]
	Learning Rate: 0.00252038
	LOSS [training: 0.1627241613004548 | validation: 0.191408996463042]
	TIME [epoch: 9.21 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2192368777320713		[learning rate: 0.0025127]
	Learning Rate: 0.00251266
	LOSS [training: 0.2192368777320713 | validation: 0.19045306192628125]
	TIME [epoch: 9.24 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21792171422163928		[learning rate: 0.002505]
	Learning Rate: 0.00250496
	LOSS [training: 0.21792171422163928 | validation: 0.1831743252935806]
	TIME [epoch: 9.23 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17739397848180052		[learning rate: 0.0024973]
	Learning Rate: 0.00249728
	LOSS [training: 0.17739397848180052 | validation: 0.2652434386999079]
	TIME [epoch: 9.23 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16708115349094907		[learning rate: 0.0024896]
	Learning Rate: 0.00248962
	LOSS [training: 0.16708115349094907 | validation: 0.1298529011993491]
	TIME [epoch: 9.22 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19389514067392827		[learning rate: 0.002482]
	Learning Rate: 0.00248199
	LOSS [training: 0.19389514067392827 | validation: 0.13098463737452565]
	TIME [epoch: 9.23 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14773169035876377		[learning rate: 0.0024744]
	Learning Rate: 0.00247438
	LOSS [training: 0.14773169035876377 | validation: 0.13231953136123373]
	TIME [epoch: 9.23 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16782824491496579		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.16782824491496579 | validation: 0.16366017786571202]
	TIME [epoch: 9.23 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14774438443429877		[learning rate: 0.0024592]
	Learning Rate: 0.00245923
	LOSS [training: 0.14774438443429877 | validation: 0.17353406556579903]
	TIME [epoch: 9.21 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15619351590695535		[learning rate: 0.0024517]
	Learning Rate: 0.0024517
	LOSS [training: 0.15619351590695535 | validation: 0.3776762438456995]
	TIME [epoch: 9.22 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17965418764735544		[learning rate: 0.0024442]
	Learning Rate: 0.00244418
	LOSS [training: 0.17965418764735544 | validation: 0.2726691388665482]
	TIME [epoch: 9.24 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21300552861470176		[learning rate: 0.0024367]
	Learning Rate: 0.00243669
	LOSS [training: 0.21300552861470176 | validation: 0.1899407714353474]
	TIME [epoch: 9.23 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20302112389428073		[learning rate: 0.0024292]
	Learning Rate: 0.00242922
	LOSS [training: 0.20302112389428073 | validation: 0.12177601264059032]
	TIME [epoch: 9.22 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20590464941797654		[learning rate: 0.0024218]
	Learning Rate: 0.00242177
	LOSS [training: 0.20590464941797654 | validation: 0.12214535851385758]
	TIME [epoch: 9.22 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13870696771696905		[learning rate: 0.0024143]
	Learning Rate: 0.00241435
	LOSS [training: 0.13870696771696905 | validation: 0.09936022892293495]
	TIME [epoch: 9.22 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18919154851934103		[learning rate: 0.0024069]
	Learning Rate: 0.00240695
	LOSS [training: 0.18919154851934103 | validation: 0.1480706885629734]
	TIME [epoch: 9.22 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15850757390469206		[learning rate: 0.0023996]
	Learning Rate: 0.00239957
	LOSS [training: 0.15850757390469206 | validation: 0.13058303321018122]
	TIME [epoch: 9.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2147709306154156		[learning rate: 0.0023922]
	Learning Rate: 0.00239221
	LOSS [training: 0.2147709306154156 | validation: 0.16329184262921892]
	TIME [epoch: 9.23 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2458571165875238		[learning rate: 0.0023849]
	Learning Rate: 0.00238488
	LOSS [training: 0.2458571165875238 | validation: 0.18662819754126972]
	TIME [epoch: 9.22 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21930555884302644		[learning rate: 0.0023776]
	Learning Rate: 0.00237757
	LOSS [training: 0.21930555884302644 | validation: 0.13812334166942036]
	TIME [epoch: 9.24 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2255306327684489		[learning rate: 0.0023703]
	Learning Rate: 0.00237028
	LOSS [training: 0.2255306327684489 | validation: 0.16480051689498382]
	TIME [epoch: 9.21 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2158027188594692		[learning rate: 0.002363]
	Learning Rate: 0.00236302
	LOSS [training: 0.2158027188594692 | validation: 0.19449612340547823]
	TIME [epoch: 9.22 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21081805954183572		[learning rate: 0.0023558]
	Learning Rate: 0.00235577
	LOSS [training: 0.21081805954183572 | validation: 0.18126677839750688]
	TIME [epoch: 9.21 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16525653566520934		[learning rate: 0.0023486]
	Learning Rate: 0.00234855
	LOSS [training: 0.16525653566520934 | validation: 0.09535399219795385]
	TIME [epoch: 9.22 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17608067209372447		[learning rate: 0.0023414]
	Learning Rate: 0.00234135
	LOSS [training: 0.17608067209372447 | validation: 0.19444510672176007]
	TIME [epoch: 9.22 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16418451211078516		[learning rate: 0.0023342]
	Learning Rate: 0.00233417
	LOSS [training: 0.16418451211078516 | validation: 0.10416845144429554]
	TIME [epoch: 9.21 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15158212407935173		[learning rate: 0.002327]
	Learning Rate: 0.00232702
	LOSS [training: 0.15158212407935173 | validation: 0.09233598465117124]
	TIME [epoch: 9.22 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17682602702387054		[learning rate: 0.0023199]
	Learning Rate: 0.00231989
	LOSS [training: 0.17682602702387054 | validation: 0.12843191133783358]
	TIME [epoch: 9.22 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17745328601875796		[learning rate: 0.0023128]
	Learning Rate: 0.00231277
	LOSS [training: 0.17745328601875796 | validation: 0.10648964399174227]
	TIME [epoch: 9.23 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17317593155062555		[learning rate: 0.0023057]
	Learning Rate: 0.00230569
	LOSS [training: 0.17317593155062555 | validation: 0.12064073721020235]
	TIME [epoch: 9.22 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13884110736517635		[learning rate: 0.0022986]
	Learning Rate: 0.00229862
	LOSS [training: 0.13884110736517635 | validation: 0.14801015421622984]
	TIME [epoch: 9.21 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2148157907640928		[learning rate: 0.0022916]
	Learning Rate: 0.00229157
	LOSS [training: 0.2148157907640928 | validation: 0.17173810816284493]
	TIME [epoch: 9.22 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17595652781505203		[learning rate: 0.0022845]
	Learning Rate: 0.00228455
	LOSS [training: 0.17595652781505203 | validation: 0.20689604147735588]
	TIME [epoch: 9.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1644383902906898		[learning rate: 0.0022775]
	Learning Rate: 0.00227754
	LOSS [training: 0.1644383902906898 | validation: 0.2208159523843605]
	TIME [epoch: 9.24 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17057946070909474		[learning rate: 0.0022706]
	Learning Rate: 0.00227056
	LOSS [training: 0.17057946070909474 | validation: 0.33250124534483516]
	TIME [epoch: 9.21 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2419620440503089		[learning rate: 0.0022636]
	Learning Rate: 0.0022636
	LOSS [training: 0.2419620440503089 | validation: 0.14751261907736374]
	TIME [epoch: 9.21 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15045813261120605		[learning rate: 0.0022567]
	Learning Rate: 0.00225666
	LOSS [training: 0.15045813261120605 | validation: 0.1381695862800628]
	TIME [epoch: 9.21 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20268507244012782		[learning rate: 0.0022497]
	Learning Rate: 0.00224975
	LOSS [training: 0.20268507244012782 | validation: 0.16098506836485477]
	TIME [epoch: 9.24 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14606272657364372		[learning rate: 0.0022428]
	Learning Rate: 0.00224285
	LOSS [training: 0.14606272657364372 | validation: 0.136369551435857]
	TIME [epoch: 9.22 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452512608242329		[learning rate: 0.002236]
	Learning Rate: 0.00223597
	LOSS [training: 0.1452512608242329 | validation: 0.1469183295210904]
	TIME [epoch: 9.21 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21705486057136195		[learning rate: 0.0022291]
	Learning Rate: 0.00222912
	LOSS [training: 0.21705486057136195 | validation: 0.11865320221745171]
	TIME [epoch: 9.22 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21767908009440254		[learning rate: 0.0022223]
	Learning Rate: 0.00222229
	LOSS [training: 0.21767908009440254 | validation: 0.2299359949392623]
	TIME [epoch: 9.22 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2315418093953691		[learning rate: 0.0022155]
	Learning Rate: 0.00221547
	LOSS [training: 0.2315418093953691 | validation: 0.24414517517502926]
	TIME [epoch: 9.24 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18374808435613543		[learning rate: 0.0022087]
	Learning Rate: 0.00220868
	LOSS [training: 0.18374808435613543 | validation: 0.08213193823193614]
	TIME [epoch: 9.23 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15452462371517992		[learning rate: 0.0022019]
	Learning Rate: 0.00220191
	LOSS [training: 0.15452462371517992 | validation: 0.11696756706734182]
	TIME [epoch: 9.22 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627540127450387		[learning rate: 0.0021952]
	Learning Rate: 0.00219516
	LOSS [training: 0.1627540127450387 | validation: 0.17691677486332086]
	TIME [epoch: 9.22 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22404935622050393		[learning rate: 0.0021884]
	Learning Rate: 0.00218843
	LOSS [training: 0.22404935622050393 | validation: 0.1473326742777735]
	TIME [epoch: 9.24 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.167395905254003		[learning rate: 0.0021817]
	Learning Rate: 0.00218173
	LOSS [training: 0.167395905254003 | validation: 0.15501463120142342]
	TIME [epoch: 9.22 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18304411935724		[learning rate: 0.002175]
	Learning Rate: 0.00217504
	LOSS [training: 0.18304411935724 | validation: 0.1451378609524595]
	TIME [epoch: 9.22 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18721519480397178		[learning rate: 0.0021684]
	Learning Rate: 0.00216837
	LOSS [training: 0.18721519480397178 | validation: 0.1254226342376933]
	TIME [epoch: 9.22 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18122160736471143		[learning rate: 0.0021617]
	Learning Rate: 0.00216172
	LOSS [training: 0.18122160736471143 | validation: 0.10705535610507169]
	TIME [epoch: 9.22 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15944322314393472		[learning rate: 0.0021551]
	Learning Rate: 0.0021551
	LOSS [training: 0.15944322314393472 | validation: 0.18454037477969215]
	TIME [epoch: 9.25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22098934346983928		[learning rate: 0.0021485]
	Learning Rate: 0.00214849
	LOSS [training: 0.22098934346983928 | validation: 0.16033802567682642]
	TIME [epoch: 9.23 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17481550173332314		[learning rate: 0.0021419]
	Learning Rate: 0.0021419
	LOSS [training: 0.17481550173332314 | validation: 0.15498574817304442]
	TIME [epoch: 9.22 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18243331714561264		[learning rate: 0.0021353]
	Learning Rate: 0.00213534
	LOSS [training: 0.18243331714561264 | validation: 0.1664893603830032]
	TIME [epoch: 9.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13925996701259652		[learning rate: 0.0021288]
	Learning Rate: 0.00212879
	LOSS [training: 0.13925996701259652 | validation: 0.14991140340327128]
	TIME [epoch: 9.24 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16560630435626125		[learning rate: 0.0021223]
	Learning Rate: 0.00212227
	LOSS [training: 0.16560630435626125 | validation: 0.13137349402974202]
	TIME [epoch: 9.23 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1552437311322694		[learning rate: 0.0021158]
	Learning Rate: 0.00211576
	LOSS [training: 0.1552437311322694 | validation: 0.08852733417252603]
	TIME [epoch: 9.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15222751443899823		[learning rate: 0.0021093]
	Learning Rate: 0.00210928
	LOSS [training: 0.15222751443899823 | validation: 0.21953790019640174]
	TIME [epoch: 9.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19346144362074832		[learning rate: 0.0021028]
	Learning Rate: 0.00210281
	LOSS [training: 0.19346144362074832 | validation: 0.11646586776623508]
	TIME [epoch: 9.21 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13560912682640838		[learning rate: 0.0020964]
	Learning Rate: 0.00209636
	LOSS [training: 0.13560912682640838 | validation: 0.12035681149805472]
	TIME [epoch: 9.23 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1464915562804827		[learning rate: 0.0020899]
	Learning Rate: 0.00208994
	LOSS [training: 0.1464915562804827 | validation: 0.15307814839224199]
	TIME [epoch: 9.21 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1738146526082854		[learning rate: 0.0020835]
	Learning Rate: 0.00208353
	LOSS [training: 0.1738146526082854 | validation: 0.1441773404768052]
	TIME [epoch: 9.21 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18670522780547208		[learning rate: 0.0020771]
	Learning Rate: 0.00207714
	LOSS [training: 0.18670522780547208 | validation: 0.0922606804949424]
	TIME [epoch: 9.18 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19287237643028912		[learning rate: 0.0020708]
	Learning Rate: 0.00207078
	LOSS [training: 0.19287237643028912 | validation: 0.10478764287591917]
	TIME [epoch: 9.22 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18666711639575131		[learning rate: 0.0020644]
	Learning Rate: 0.00206443
	LOSS [training: 0.18666711639575131 | validation: 0.20541972225694555]
	TIME [epoch: 9.2 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18560206975717744		[learning rate: 0.0020581]
	Learning Rate: 0.0020581
	LOSS [training: 0.18560206975717744 | validation: 0.12604855735124204]
	TIME [epoch: 9.2 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17943517363001646		[learning rate: 0.0020518]
	Learning Rate: 0.00205179
	LOSS [training: 0.17943517363001646 | validation: 0.17550597387752637]
	TIME [epoch: 9.2 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15394727398462027		[learning rate: 0.0020455]
	Learning Rate: 0.0020455
	LOSS [training: 0.15394727398462027 | validation: 0.13378177571293562]
	TIME [epoch: 9.21 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621676339723936		[learning rate: 0.0020392]
	Learning Rate: 0.00203923
	LOSS [training: 0.1621676339723936 | validation: 0.15647692902992427]
	TIME [epoch: 9.23 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15627207171699245		[learning rate: 0.002033]
	Learning Rate: 0.00203298
	LOSS [training: 0.15627207171699245 | validation: 0.1424630558955164]
	TIME [epoch: 9.21 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20268727342270654		[learning rate: 0.0020267]
	Learning Rate: 0.00202675
	LOSS [training: 0.20268727342270654 | validation: 0.16314935849310014]
	TIME [epoch: 9.22 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15785901704791055		[learning rate: 0.0020205]
	Learning Rate: 0.00202054
	LOSS [training: 0.15785901704791055 | validation: 0.10546670354650681]
	TIME [epoch: 9.18 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14923767285563921		[learning rate: 0.0020143]
	Learning Rate: 0.00201434
	LOSS [training: 0.14923767285563921 | validation: 0.14728278187912675]
	TIME [epoch: 9.23 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15555086179820515		[learning rate: 0.0020082]
	Learning Rate: 0.00200817
	LOSS [training: 0.15555086179820515 | validation: 0.1138653999187697]
	TIME [epoch: 9.21 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16230535724219114		[learning rate: 0.002002]
	Learning Rate: 0.00200201
	LOSS [training: 0.16230535724219114 | validation: 0.10795692878031322]
	TIME [epoch: 9.21 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16044255207829558		[learning rate: 0.0019959]
	Learning Rate: 0.00199587
	LOSS [training: 0.16044255207829558 | validation: 0.12870290736149534]
	TIME [epoch: 9.22 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618886599938309		[learning rate: 0.0019898]
	Learning Rate: 0.00198976
	LOSS [training: 0.1618886599938309 | validation: 0.09984214547472195]
	TIME [epoch: 9.21 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1417594006382254		[learning rate: 0.0019837]
	Learning Rate: 0.00198366
	LOSS [training: 0.1417594006382254 | validation: 0.13744878762770957]
	TIME [epoch: 9.23 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14959114650930294		[learning rate: 0.0019776]
	Learning Rate: 0.00197758
	LOSS [training: 0.14959114650930294 | validation: 0.16116196700837632]
	TIME [epoch: 9.21 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14750895848306603		[learning rate: 0.0019715]
	Learning Rate: 0.00197151
	LOSS [training: 0.14750895848306603 | validation: 0.10468161063758954]
	TIME [epoch: 9.22 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14320142465400393		[learning rate: 0.0019655]
	Learning Rate: 0.00196547
	LOSS [training: 0.14320142465400393 | validation: 0.14820371814608713]
	TIME [epoch: 9.21 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12903197925993135		[learning rate: 0.0019594]
	Learning Rate: 0.00195945
	LOSS [training: 0.12903197925993135 | validation: 0.09388273014782841]
	TIME [epoch: 9.23 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14531142348967976		[learning rate: 0.0019534]
	Learning Rate: 0.00195344
	LOSS [training: 0.14531142348967976 | validation: 0.10843510614942223]
	TIME [epoch: 9.22 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13391953041793825		[learning rate: 0.0019475]
	Learning Rate: 0.00194745
	LOSS [training: 0.13391953041793825 | validation: 0.09899040207175507]
	TIME [epoch: 9.21 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670371453963698		[learning rate: 0.0019415]
	Learning Rate: 0.00194148
	LOSS [training: 0.1670371453963698 | validation: 0.15277118057939942]
	TIME [epoch: 9.22 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15468695922155024		[learning rate: 0.0019355]
	Learning Rate: 0.00193553
	LOSS [training: 0.15468695922155024 | validation: 0.09666880945027634]
	TIME [epoch: 9.21 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15957765096261037		[learning rate: 0.0019296]
	Learning Rate: 0.0019296
	LOSS [training: 0.15957765096261037 | validation: 0.08290004670931524]
	TIME [epoch: 9.24 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326614255386125		[learning rate: 0.0019237]
	Learning Rate: 0.00192368
	LOSS [training: 0.1326614255386125 | validation: 0.09753538793869139]
	TIME [epoch: 9.23 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11300728364961451		[learning rate: 0.0019178]
	Learning Rate: 0.00191779
	LOSS [training: 0.11300728364961451 | validation: 0.054134238690695224]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1038.pth
	Model improved!!!
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19552077852183086		[learning rate: 0.0019119]
	Learning Rate: 0.00191191
	LOSS [training: 0.19552077852183086 | validation: 0.11748789167328026]
	TIME [epoch: 9.23 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292154308731421		[learning rate: 0.001906]
	Learning Rate: 0.00190605
	LOSS [training: 0.1292154308731421 | validation: 0.12478251835726233]
	TIME [epoch: 9.25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12577271977898935		[learning rate: 0.0019002]
	Learning Rate: 0.0019002
	LOSS [training: 0.12577271977898935 | validation: 0.15441598975231544]
	TIME [epoch: 9.23 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14306378371120423		[learning rate: 0.0018944]
	Learning Rate: 0.00189438
	LOSS [training: 0.14306378371120423 | validation: 0.13561415385111247]
	TIME [epoch: 9.22 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11845489796073028		[learning rate: 0.0018886]
	Learning Rate: 0.00188857
	LOSS [training: 0.11845489796073028 | validation: 0.13599871334307495]
	TIME [epoch: 9.23 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1460513365261383		[learning rate: 0.0018828]
	Learning Rate: 0.00188278
	LOSS [training: 0.1460513365261383 | validation: 0.1448289892124132]
	TIME [epoch: 9.23 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16637371788936586		[learning rate: 0.001877]
	Learning Rate: 0.00187701
	LOSS [training: 0.16637371788936586 | validation: 0.1009199928516352]
	TIME [epoch: 9.25 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15815131037182306		[learning rate: 0.0018713]
	Learning Rate: 0.00187126
	LOSS [training: 0.15815131037182306 | validation: 0.29541045817447137]
	TIME [epoch: 9.23 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1563153847216638		[learning rate: 0.0018655]
	Learning Rate: 0.00186552
	LOSS [training: 0.1563153847216638 | validation: 0.1369235646323101]
	TIME [epoch: 9.24 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14801210719024044		[learning rate: 0.0018598]
	Learning Rate: 0.0018598
	LOSS [training: 0.14801210719024044 | validation: 0.1236532255857948]
	TIME [epoch: 9.23 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1421952718308574		[learning rate: 0.0018541]
	Learning Rate: 0.0018541
	LOSS [training: 0.1421952718308574 | validation: 0.13138461572299168]
	TIME [epoch: 9.26 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14905494998444804		[learning rate: 0.0018484]
	Learning Rate: 0.00184842
	LOSS [training: 0.14905494998444804 | validation: 0.10438723541061856]
	TIME [epoch: 9.24 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1320891139672504		[learning rate: 0.0018428]
	Learning Rate: 0.00184275
	LOSS [training: 0.1320891139672504 | validation: 0.08760714710331541]
	TIME [epoch: 9.23 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17765458920823143		[learning rate: 0.0018371]
	Learning Rate: 0.0018371
	LOSS [training: 0.17765458920823143 | validation: 0.11191336928528436]
	TIME [epoch: 9.22 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13137625342782336		[learning rate: 0.0018315]
	Learning Rate: 0.00183147
	LOSS [training: 0.13137625342782336 | validation: 0.15905063732557068]
	TIME [epoch: 9.23 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16137416459273426		[learning rate: 0.0018259]
	Learning Rate: 0.00182586
	LOSS [training: 0.16137416459273426 | validation: 0.1103325650215041]
	TIME [epoch: 9.26 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17547808474721915		[learning rate: 0.0018203]
	Learning Rate: 0.00182026
	LOSS [training: 0.17547808474721915 | validation: 0.23152818513934645]
	TIME [epoch: 9.22 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.153126220046569		[learning rate: 0.0018147]
	Learning Rate: 0.00181468
	LOSS [training: 0.153126220046569 | validation: 0.09677947442966511]
	TIME [epoch: 9.23 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14159093913760784		[learning rate: 0.0018091]
	Learning Rate: 0.00180912
	LOSS [training: 0.14159093913760784 | validation: 0.13452149967726335]
	TIME [epoch: 9.23 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.129112333975053		[learning rate: 0.0018036]
	Learning Rate: 0.00180357
	LOSS [training: 0.129112333975053 | validation: 0.16007284076713346]
	TIME [epoch: 9.25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14742689273691		[learning rate: 0.001798]
	Learning Rate: 0.00179804
	LOSS [training: 0.14742689273691 | validation: 0.1728561613374995]
	TIME [epoch: 9.22 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1460386992852166		[learning rate: 0.0017925]
	Learning Rate: 0.00179253
	LOSS [training: 0.1460386992852166 | validation: 0.14919382872623166]
	TIME [epoch: 9.23 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1450986786480788		[learning rate: 0.001787]
	Learning Rate: 0.00178704
	LOSS [training: 0.1450986786480788 | validation: 0.10151859440150945]
	TIME [epoch: 9.22 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1528986901940699		[learning rate: 0.0017816]
	Learning Rate: 0.00178156
	LOSS [training: 0.1528986901940699 | validation: 0.13696112966732243]
	TIME [epoch: 9.23 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1384550204232839		[learning rate: 0.0017761]
	Learning Rate: 0.0017761
	LOSS [training: 0.1384550204232839 | validation: 0.08659290008173152]
	TIME [epoch: 9.25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12795328267915643		[learning rate: 0.0017707]
	Learning Rate: 0.00177065
	LOSS [training: 0.12795328267915643 | validation: 0.12535422111452252]
	TIME [epoch: 9.24 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1638497005455065		[learning rate: 0.0017652]
	Learning Rate: 0.00176522
	LOSS [training: 0.1638497005455065 | validation: 0.146814061260095]
	TIME [epoch: 9.23 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17098610565877378		[learning rate: 0.0017598]
	Learning Rate: 0.00175981
	LOSS [training: 0.17098610565877378 | validation: 0.13815008565415043]
	TIME [epoch: 9.23 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14611104434211314		[learning rate: 0.0017544]
	Learning Rate: 0.00175442
	LOSS [training: 0.14611104434211314 | validation: 0.12083283760110371]
	TIME [epoch: 9.25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13729487392355993		[learning rate: 0.001749]
	Learning Rate: 0.00174904
	LOSS [training: 0.13729487392355993 | validation: 0.08132189568040275]
	TIME [epoch: 9.24 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14388482488754292		[learning rate: 0.0017437]
	Learning Rate: 0.00174368
	LOSS [training: 0.14388482488754292 | validation: 0.09327369538480468]
	TIME [epoch: 9.22 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17757765904740608		[learning rate: 0.0017383]
	Learning Rate: 0.00173833
	LOSS [training: 0.17757765904740608 | validation: 0.12470765727764055]
	TIME [epoch: 9.23 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1285986278455239		[learning rate: 0.001733]
	Learning Rate: 0.00173301
	LOSS [training: 0.1285986278455239 | validation: 0.08974888571895356]
	TIME [epoch: 9.22 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1599573822467713		[learning rate: 0.0017277]
	Learning Rate: 0.00172769
	LOSS [training: 0.1599573822467713 | validation: 0.07615311547193737]
	TIME [epoch: 9.26 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11979672738766538		[learning rate: 0.0017224]
	Learning Rate: 0.0017224
	LOSS [training: 0.11979672738766538 | validation: 0.09020597331264343]
	TIME [epoch: 9.22 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12127487664856285		[learning rate: 0.0017171]
	Learning Rate: 0.00171712
	LOSS [training: 0.12127487664856285 | validation: 0.08493522545145074]
	TIME [epoch: 9.23 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14934018145771696		[learning rate: 0.0017119]
	Learning Rate: 0.00171185
	LOSS [training: 0.14934018145771696 | validation: 0.1706249232063932]
	TIME [epoch: 9.22 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13902688274196545		[learning rate: 0.0017066]
	Learning Rate: 0.00170661
	LOSS [training: 0.13902688274196545 | validation: 0.09077372020420847]
	TIME [epoch: 9.24 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12524376560941344		[learning rate: 0.0017014]
	Learning Rate: 0.00170137
	LOSS [training: 0.12524376560941344 | validation: 0.10845549223091433]
	TIME [epoch: 9.23 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12074239988143805		[learning rate: 0.0016962]
	Learning Rate: 0.00169616
	LOSS [training: 0.12074239988143805 | validation: 0.10673140290038771]
	TIME [epoch: 9.23 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12670819275497708		[learning rate: 0.001691]
	Learning Rate: 0.00169096
	LOSS [training: 0.12670819275497708 | validation: 0.1073374865607855]
	TIME [epoch: 9.23 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20518883056201337		[learning rate: 0.0016858]
	Learning Rate: 0.00168578
	LOSS [training: 0.20518883056201337 | validation: 0.10365396111640282]
	TIME [epoch: 9.22 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13063818444125283		[learning rate: 0.0016806]
	Learning Rate: 0.00168061
	LOSS [training: 0.13063818444125283 | validation: 0.1754850768108811]
	TIME [epoch: 9.25 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15104869374499533		[learning rate: 0.0016755]
	Learning Rate: 0.00167546
	LOSS [training: 0.15104869374499533 | validation: 0.11270441627771488]
	TIME [epoch: 9.23 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390765085833844		[learning rate: 0.0016703]
	Learning Rate: 0.00167032
	LOSS [training: 0.1390765085833844 | validation: 0.15034991234949754]
	TIME [epoch: 9.22 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12091904311589832		[learning rate: 0.0016652]
	Learning Rate: 0.0016652
	LOSS [training: 0.12091904311589832 | validation: 0.1126334014073867]
	TIME [epoch: 9.24 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11407856432210883		[learning rate: 0.0016601]
	Learning Rate: 0.0016601
	LOSS [training: 0.11407856432210883 | validation: 0.11392083692687986]
	TIME [epoch: 9.25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14282801067520765		[learning rate: 0.001655]
	Learning Rate: 0.00165501
	LOSS [training: 0.14282801067520765 | validation: 0.10065687892769297]
	TIME [epoch: 9.23 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12888354730096233		[learning rate: 0.0016499]
	Learning Rate: 0.00164993
	LOSS [training: 0.12888354730096233 | validation: 0.11885381148174315]
	TIME [epoch: 9.24 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1680698251677854		[learning rate: 0.0016449]
	Learning Rate: 0.00164488
	LOSS [training: 0.1680698251677854 | validation: 0.15636911989613855]
	TIME [epoch: 9.24 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.214798210011328		[learning rate: 0.0016398]
	Learning Rate: 0.00163983
	LOSS [training: 0.214798210011328 | validation: 0.11688225443157493]
	TIME [epoch: 9.23 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15498571851202175		[learning rate: 0.0016348]
	Learning Rate: 0.00163481
	LOSS [training: 0.15498571851202175 | validation: 0.10108698331684379]
	TIME [epoch: 9.26 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1114160798462986		[learning rate: 0.0016298]
	Learning Rate: 0.0016298
	LOSS [training: 0.1114160798462986 | validation: 0.09082723006906965]
	TIME [epoch: 9.23 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1205262977314242		[learning rate: 0.0016248]
	Learning Rate: 0.0016248
	LOSS [training: 0.1205262977314242 | validation: 0.13608159459005145]
	TIME [epoch: 9.23 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10875425960138799		[learning rate: 0.0016198]
	Learning Rate: 0.00161982
	LOSS [training: 0.10875425960138799 | validation: 0.1546321827771855]
	TIME [epoch: 9.23 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15370081686469111		[learning rate: 0.0016149]
	Learning Rate: 0.00161485
	LOSS [training: 0.15370081686469111 | validation: 0.132050876258704]
	TIME [epoch: 9.25 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14238969645319483		[learning rate: 0.0016099]
	Learning Rate: 0.0016099
	LOSS [training: 0.14238969645319483 | validation: 0.07299080564161131]
	TIME [epoch: 9.23 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1275622474548672		[learning rate: 0.001605]
	Learning Rate: 0.00160497
	LOSS [training: 0.1275622474548672 | validation: 0.12454943097797488]
	TIME [epoch: 9.23 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15717866754475043		[learning rate: 0.0016]
	Learning Rate: 0.00160005
	LOSS [training: 0.15717866754475043 | validation: 0.13913557076424465]
	TIME [epoch: 9.23 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13872104252829803		[learning rate: 0.0015951]
	Learning Rate: 0.00159514
	LOSS [training: 0.13872104252829803 | validation: 0.10006629851993987]
	TIME [epoch: 9.23 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15682419767846162		[learning rate: 0.0015903]
	Learning Rate: 0.00159025
	LOSS [training: 0.15682419767846162 | validation: 0.11454267508806087]
	TIME [epoch: 9.25 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1330464048349379		[learning rate: 0.0015854]
	Learning Rate: 0.00158538
	LOSS [training: 0.1330464048349379 | validation: 0.07705174353401457]
	TIME [epoch: 9.23 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1268588655259002		[learning rate: 0.0015805]
	Learning Rate: 0.00158052
	LOSS [training: 0.1268588655259002 | validation: 0.08720348390123465]
	TIME [epoch: 9.22 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16347015224673805		[learning rate: 0.0015757]
	Learning Rate: 0.00157568
	LOSS [training: 0.16347015224673805 | validation: 0.26687182177983837]
	TIME [epoch: 9.23 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18840239986382465		[learning rate: 0.0015708]
	Learning Rate: 0.00157084
	LOSS [training: 0.18840239986382465 | validation: 0.13090843057959614]
	TIME [epoch: 9.24 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14779293497043558		[learning rate: 0.001566]
	Learning Rate: 0.00156603
	LOSS [training: 0.14779293497043558 | validation: 0.1271673360040466]
	TIME [epoch: 9.24 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267775721989252		[learning rate: 0.0015612]
	Learning Rate: 0.00156123
	LOSS [training: 0.1267775721989252 | validation: 0.17661934311215385]
	TIME [epoch: 9.23 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1589298847508036		[learning rate: 0.0015564]
	Learning Rate: 0.00155644
	LOSS [training: 0.1589298847508036 | validation: 0.17157833493272565]
	TIME [epoch: 9.23 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14798426980618404		[learning rate: 0.0015517]
	Learning Rate: 0.00155167
	LOSS [training: 0.14798426980618404 | validation: 0.1203491856670573]
	TIME [epoch: 9.23 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12002104324774106		[learning rate: 0.0015469]
	Learning Rate: 0.00154692
	LOSS [training: 0.12002104324774106 | validation: 0.09281997126533281]
	TIME [epoch: 9.25 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09846099669648427		[learning rate: 0.0015422]
	Learning Rate: 0.00154217
	LOSS [training: 0.09846099669648427 | validation: 0.13283434901174396]
	TIME [epoch: 9.23 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13545111074351504		[learning rate: 0.0015374]
	Learning Rate: 0.00153745
	LOSS [training: 0.13545111074351504 | validation: 0.09002885414276232]
	TIME [epoch: 9.23 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14181797828345552		[learning rate: 0.0015327]
	Learning Rate: 0.00153273
	LOSS [training: 0.14181797828345552 | validation: 0.0909123411529604]
	TIME [epoch: 9.23 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18005320629993754		[learning rate: 0.001528]
	Learning Rate: 0.00152804
	LOSS [training: 0.18005320629993754 | validation: 0.11329244855397011]
	TIME [epoch: 9.24 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1777403322078969		[learning rate: 0.0015234]
	Learning Rate: 0.00152335
	LOSS [training: 0.1777403322078969 | validation: 0.3155588286829378]
	TIME [epoch: 9.24 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1810679607752742		[learning rate: 0.0015187]
	Learning Rate: 0.00151868
	LOSS [training: 0.1810679607752742 | validation: 0.2526613776263853]
	TIME [epoch: 9.23 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27209922344023507		[learning rate: 0.001514]
	Learning Rate: 0.00151403
	LOSS [training: 0.27209922344023507 | validation: 0.14214764877311142]
	TIME [epoch: 9.22 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15031327402911754		[learning rate: 0.0015094]
	Learning Rate: 0.00150938
	LOSS [training: 0.15031327402911754 | validation: 0.11239889476158457]
	TIME [epoch: 9.23 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12410484203140745		[learning rate: 0.0015048]
	Learning Rate: 0.00150476
	LOSS [training: 0.12410484203140745 | validation: 0.15925499917317737]
	TIME [epoch: 9.26 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11747422887611167		[learning rate: 0.0015001]
	Learning Rate: 0.00150015
	LOSS [training: 0.11747422887611167 | validation: 0.11873725075232279]
	TIME [epoch: 9.23 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1569794616663382		[learning rate: 0.0014955]
	Learning Rate: 0.00149555
	LOSS [training: 0.1569794616663382 | validation: 0.0953385627269883]
	TIME [epoch: 9.24 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1405627194738698		[learning rate: 0.001491]
	Learning Rate: 0.00149096
	LOSS [training: 0.1405627194738698 | validation: 0.11085240217871653]
	TIME [epoch: 9.23 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254514750655273		[learning rate: 0.0014864]
	Learning Rate: 0.00148639
	LOSS [training: 0.1254514750655273 | validation: 0.12098157174176555]
	TIME [epoch: 9.24 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2620371093132518		[learning rate: 0.0014818]
	Learning Rate: 0.00148184
	LOSS [training: 0.2620371093132518 | validation: 0.18695058695289907]
	TIME [epoch: 9.25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396741833161554		[learning rate: 0.0014773]
	Learning Rate: 0.00147729
	LOSS [training: 0.1396741833161554 | validation: 0.1121902271975188]
	TIME [epoch: 9.24 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14778181319222866		[learning rate: 0.0014728]
	Learning Rate: 0.00147276
	LOSS [training: 0.14778181319222866 | validation: 0.25343240722268817]
	TIME [epoch: 9.23 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14784016009881093		[learning rate: 0.0014682]
	Learning Rate: 0.00146825
	LOSS [training: 0.14784016009881093 | validation: 0.09681080046363333]
	TIME [epoch: 9.23 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1388924483762241		[learning rate: 0.0014637]
	Learning Rate: 0.00146375
	LOSS [training: 0.1388924483762241 | validation: 0.11874090447441116]
	TIME [epoch: 9.26 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1517739322679626		[learning rate: 0.0014593]
	Learning Rate: 0.00145926
	LOSS [training: 0.1517739322679626 | validation: 0.11577588210156872]
	TIME [epoch: 9.23 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14101877243842462		[learning rate: 0.0014548]
	Learning Rate: 0.00145479
	LOSS [training: 0.14101877243842462 | validation: 0.17921526204818156]
	TIME [epoch: 9.23 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13164907678890117		[learning rate: 0.0014503]
	Learning Rate: 0.00145033
	LOSS [training: 0.13164907678890117 | validation: 0.21818853697447227]
	TIME [epoch: 9.22 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15668638689051503		[learning rate: 0.0014459]
	Learning Rate: 0.00144588
	LOSS [training: 0.15668638689051503 | validation: 0.10568648999423844]
	TIME [epoch: 9.24 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13743702753277692		[learning rate: 0.0014415]
	Learning Rate: 0.00144145
	LOSS [training: 0.13743702753277692 | validation: 0.13869127738093234]
	TIME [epoch: 9.24 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.124281425206311		[learning rate: 0.001437]
	Learning Rate: 0.00143703
	LOSS [training: 0.124281425206311 | validation: 0.11165496983646864]
	TIME [epoch: 9.23 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14813033851100055		[learning rate: 0.0014326]
	Learning Rate: 0.00143263
	LOSS [training: 0.14813033851100055 | validation: 0.17011371554370192]
	TIME [epoch: 9.24 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342752892077978		[learning rate: 0.0014282]
	Learning Rate: 0.00142824
	LOSS [training: 0.1342752892077978 | validation: 0.08717105459920396]
	TIME [epoch: 9.24 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1182067714188922		[learning rate: 0.0014239]
	Learning Rate: 0.00142386
	LOSS [training: 0.1182067714188922 | validation: 0.1900126063847995]
	TIME [epoch: 9.25 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13687672947791746		[learning rate: 0.0014195]
	Learning Rate: 0.00141949
	LOSS [training: 0.13687672947791746 | validation: 0.10707135771550949]
	TIME [epoch: 9.23 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12641336885330695		[learning rate: 0.0014151]
	Learning Rate: 0.00141514
	LOSS [training: 0.12641336885330695 | validation: 0.09929585841602398]
	TIME [epoch: 9.22 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13478499048556367		[learning rate: 0.0014108]
	Learning Rate: 0.0014108
	LOSS [training: 0.13478499048556367 | validation: 0.13597825983793377]
	TIME [epoch: 9.23 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12116524869629834		[learning rate: 0.0014065]
	Learning Rate: 0.00140648
	LOSS [training: 0.12116524869629834 | validation: 0.11010577755237184]
	TIME [epoch: 9.24 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13277292051751233		[learning rate: 0.0014022]
	Learning Rate: 0.00140217
	LOSS [training: 0.13277292051751233 | validation: 0.12568703893346647]
	TIME [epoch: 9.24 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267479484077717		[learning rate: 0.0013979]
	Learning Rate: 0.00139787
	LOSS [training: 0.1267479484077717 | validation: 0.13457421341318276]
	TIME [epoch: 9.23 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1288485662258082		[learning rate: 0.0013936]
	Learning Rate: 0.00139358
	LOSS [training: 0.1288485662258082 | validation: 0.1042407078176951]
	TIME [epoch: 9.23 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11233042757497405		[learning rate: 0.0013893]
	Learning Rate: 0.00138931
	LOSS [training: 0.11233042757497405 | validation: 0.10457792442381024]
	TIME [epoch: 9.23 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1001030482594023		[learning rate: 0.0013851]
	Learning Rate: 0.00138505
	LOSS [training: 0.1001030482594023 | validation: 0.13725193458187795]
	TIME [epoch: 9.25 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11838971212070296		[learning rate: 0.0013808]
	Learning Rate: 0.00138081
	LOSS [training: 0.11838971212070296 | validation: 0.1086877127831438]
	TIME [epoch: 9.22 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13455155303001268		[learning rate: 0.0013766]
	Learning Rate: 0.00137658
	LOSS [training: 0.13455155303001268 | validation: 0.11368464859774895]
	TIME [epoch: 9.23 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1203748022923099		[learning rate: 0.0013724]
	Learning Rate: 0.00137236
	LOSS [training: 0.1203748022923099 | validation: 0.11534381059802527]
	TIME [epoch: 9.22 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377799829604685		[learning rate: 0.0013681]
	Learning Rate: 0.00136815
	LOSS [training: 0.1377799829604685 | validation: 0.15297690058545227]
	TIME [epoch: 9.24 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14355952545063708		[learning rate: 0.001364]
	Learning Rate: 0.00136395
	LOSS [training: 0.14355952545063708 | validation: 0.15103197707937663]
	TIME [epoch: 9.23 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13897646679054854		[learning rate: 0.0013598]
	Learning Rate: 0.00135977
	LOSS [training: 0.13897646679054854 | validation: 0.07849127061821395]
	TIME [epoch: 9.23 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11125149994254269		[learning rate: 0.0013556]
	Learning Rate: 0.00135561
	LOSS [training: 0.11125149994254269 | validation: 0.16441051280378757]
	TIME [epoch: 9.23 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15554493505517117		[learning rate: 0.0013515]
	Learning Rate: 0.00135145
	LOSS [training: 0.15554493505517117 | validation: 0.13544851835467708]
	TIME [epoch: 9.22 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12316439180110506		[learning rate: 0.0013473]
	Learning Rate: 0.00134731
	LOSS [training: 0.12316439180110506 | validation: 0.07856705280797922]
	TIME [epoch: 9.26 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1111505715475466		[learning rate: 0.0013432]
	Learning Rate: 0.00134318
	LOSS [training: 0.1111505715475466 | validation: 0.10029895286553661]
	TIME [epoch: 9.24 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13427119976027144		[learning rate: 0.0013391]
	Learning Rate: 0.00133906
	LOSS [training: 0.13427119976027144 | validation: 0.08286251861745376]
	TIME [epoch: 9.23 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1371906784324954		[learning rate: 0.001335]
	Learning Rate: 0.00133496
	LOSS [training: 0.1371906784324954 | validation: 0.08350092628855404]
	TIME [epoch: 9.23 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11471013996056537		[learning rate: 0.0013309]
	Learning Rate: 0.00133086
	LOSS [training: 0.11471013996056537 | validation: 0.11067431530039545]
	TIME [epoch: 9.23 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12876912303762908		[learning rate: 0.0013268]
	Learning Rate: 0.00132678
	LOSS [training: 0.12876912303762908 | validation: 0.20610460748554116]
	TIME [epoch: 9.24 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1369374785639471		[learning rate: 0.0013227]
	Learning Rate: 0.00132272
	LOSS [training: 0.1369374785639471 | validation: 0.1419101057084726]
	TIME [epoch: 9.21 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12899749497657204		[learning rate: 0.0013187]
	Learning Rate: 0.00131866
	LOSS [training: 0.12899749497657204 | validation: 0.09554194259071325]
	TIME [epoch: 9.23 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13338733753951956		[learning rate: 0.0013146]
	Learning Rate: 0.00131462
	LOSS [training: 0.13338733753951956 | validation: 0.08750015715759715]
	TIME [epoch: 9.23 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14490092817227807		[learning rate: 0.0013106]
	Learning Rate: 0.00131059
	LOSS [training: 0.14490092817227807 | validation: 0.0854751106983195]
	TIME [epoch: 9.24 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1331602385167273		[learning rate: 0.0013066]
	Learning Rate: 0.00130657
	LOSS [training: 0.1331602385167273 | validation: 0.1305836141078939]
	TIME [epoch: 9.23 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10929812574954241		[learning rate: 0.0013026]
	Learning Rate: 0.00130257
	LOSS [training: 0.10929812574954241 | validation: 0.09311696194752436]
	TIME [epoch: 9.23 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12665308153682628		[learning rate: 0.0012986]
	Learning Rate: 0.00129857
	LOSS [training: 0.12665308153682628 | validation: 0.07879169571190034]
	TIME [epoch: 9.24 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11080339746050531		[learning rate: 0.0012946]
	Learning Rate: 0.00129459
	LOSS [training: 0.11080339746050531 | validation: 0.07266903906116431]
	TIME [epoch: 9.24 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12152259737504463		[learning rate: 0.0012906]
	Learning Rate: 0.00129062
	LOSS [training: 0.12152259737504463 | validation: 0.08032296058520023]
	TIME [epoch: 9.25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12921233992742315		[learning rate: 0.0012867]
	Learning Rate: 0.00128667
	LOSS [training: 0.12921233992742315 | validation: 0.13400411412380783]
	TIME [epoch: 9.21 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11869481749648145		[learning rate: 0.0012827]
	Learning Rate: 0.00128272
	LOSS [training: 0.11869481749648145 | validation: 0.2008737912796984]
	TIME [epoch: 9.24 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13323763749045892		[learning rate: 0.0012788]
	Learning Rate: 0.00127879
	LOSS [training: 0.13323763749045892 | validation: 0.160703634159313]
	TIME [epoch: 9.23 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11045738356324464		[learning rate: 0.0012749]
	Learning Rate: 0.00127487
	LOSS [training: 0.11045738356324464 | validation: 0.09370691612040564]
	TIME [epoch: 9.26 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292767582280408		[learning rate: 0.001271]
	Learning Rate: 0.00127096
	LOSS [training: 0.1292767582280408 | validation: 0.08874984348943948]
	TIME [epoch: 9.23 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15188090315085706		[learning rate: 0.0012671]
	Learning Rate: 0.00126707
	LOSS [training: 0.15188090315085706 | validation: 0.0690992467441655]
	TIME [epoch: 9.23 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09843332471235357		[learning rate: 0.0012632]
	Learning Rate: 0.00126318
	LOSS [training: 0.09843332471235357 | validation: 0.07044458098703486]
	TIME [epoch: 9.23 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11066654390830526		[learning rate: 0.0012593]
	Learning Rate: 0.00125931
	LOSS [training: 0.11066654390830526 | validation: 0.06389263298164377]
	TIME [epoch: 9.24 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09071357660824286		[learning rate: 0.0012555]
	Learning Rate: 0.00125545
	LOSS [training: 0.09071357660824286 | validation: 0.07468339548990253]
	TIME [epoch: 9.24 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10691560774610656		[learning rate: 0.0012516]
	Learning Rate: 0.0012516
	LOSS [training: 0.10691560774610656 | validation: 0.11102893825695584]
	TIME [epoch: 9.24 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739442537255774		[learning rate: 0.0012478]
	Learning Rate: 0.00124777
	LOSS [training: 0.09739442537255774 | validation: 0.07008204872946133]
	TIME [epoch: 9.24 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09563090303155793		[learning rate: 0.0012439]
	Learning Rate: 0.00124394
	LOSS [training: 0.09563090303155793 | validation: 0.07668920576670532]
	TIME [epoch: 9.23 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10822179238906511		[learning rate: 0.0012401]
	Learning Rate: 0.00124013
	LOSS [training: 0.10822179238906511 | validation: 0.09165333629966171]
	TIME [epoch: 9.26 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627080428469232		[learning rate: 0.0012363]
	Learning Rate: 0.00123633
	LOSS [training: 0.11627080428469232 | validation: 0.05927110566414483]
	TIME [epoch: 9.21 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12088743521765857		[learning rate: 0.0012325]
	Learning Rate: 0.00123254
	LOSS [training: 0.12088743521765857 | validation: 0.15363286426052675]
	TIME [epoch: 9.23 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1351246606099201		[learning rate: 0.0012288]
	Learning Rate: 0.00122876
	LOSS [training: 0.1351246606099201 | validation: 0.07997521911944325]
	TIME [epoch: 9.23 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1148742879920593		[learning rate: 0.001225]
	Learning Rate: 0.00122499
	LOSS [training: 0.1148742879920593 | validation: 0.08880619493299677]
	TIME [epoch: 9.23 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778405772839924		[learning rate: 0.0012212]
	Learning Rate: 0.00122124
	LOSS [training: 0.11778405772839924 | validation: 0.08827989814469744]
	TIME [epoch: 9.24 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13419917244390667		[learning rate: 0.0012175]
	Learning Rate: 0.00121749
	LOSS [training: 0.13419917244390667 | validation: 0.16355973417574754]
	TIME [epoch: 9.24 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11618173710142862		[learning rate: 0.0012138]
	Learning Rate: 0.00121376
	LOSS [training: 0.11618173710142862 | validation: 0.158680267388991]
	TIME [epoch: 9.24 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1086415499243917		[learning rate: 0.00121]
	Learning Rate: 0.00121004
	LOSS [training: 0.1086415499243917 | validation: 0.0959570839989152]
	TIME [epoch: 9.23 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11862538046058084		[learning rate: 0.0012063]
	Learning Rate: 0.00120633
	LOSS [training: 0.11862538046058084 | validation: 0.11025991494096228]
	TIME [epoch: 9.25 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10393396309493794		[learning rate: 0.0012026]
	Learning Rate: 0.00120263
	LOSS [training: 0.10393396309493794 | validation: 0.0935465011458505]
	TIME [epoch: 9.23 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08856150518520753		[learning rate: 0.0011989]
	Learning Rate: 0.00119895
	LOSS [training: 0.08856150518520753 | validation: 0.1457369641174539]
	TIME [epoch: 9.24 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11307952438810975		[learning rate: 0.0011953]
	Learning Rate: 0.00119527
	LOSS [training: 0.11307952438810975 | validation: 0.06453668483311156]
	TIME [epoch: 9.24 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09548720549946861		[learning rate: 0.0011916]
	Learning Rate: 0.00119161
	LOSS [training: 0.09548720549946861 | validation: 0.06837978616748334]
	TIME [epoch: 9.24 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09596542563830177		[learning rate: 0.001188]
	Learning Rate: 0.00118795
	LOSS [training: 0.09596542563830177 | validation: 0.07348230219371037]
	TIME [epoch: 9.24 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09652663956382124		[learning rate: 0.0011843]
	Learning Rate: 0.00118431
	LOSS [training: 0.09652663956382124 | validation: 0.06914608149808235]
	TIME [epoch: 9.24 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12995547108080413		[learning rate: 0.0011807]
	Learning Rate: 0.00118068
	LOSS [training: 0.12995547108080413 | validation: 0.11763100375685022]
	TIME [epoch: 9.22 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13231661967532243		[learning rate: 0.0011771]
	Learning Rate: 0.00117706
	LOSS [training: 0.13231661967532243 | validation: 0.06127027427046647]
	TIME [epoch: 9.23 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09757326538908016		[learning rate: 0.0011735]
	Learning Rate: 0.00117346
	LOSS [training: 0.09757326538908016 | validation: 0.0782949172613032]
	TIME [epoch: 9.25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277310754333782		[learning rate: 0.0011699]
	Learning Rate: 0.00116986
	LOSS [training: 0.1277310754333782 | validation: 0.06736449101967978]
	TIME [epoch: 9.23 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11841528219722504		[learning rate: 0.0011663]
	Learning Rate: 0.00116627
	LOSS [training: 0.11841528219722504 | validation: 0.11244535226315136]
	TIME [epoch: 9.23 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09985414532381476		[learning rate: 0.0011627]
	Learning Rate: 0.0011627
	LOSS [training: 0.09985414532381476 | validation: 0.09237818580164664]
	TIME [epoch: 9.26 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11697694054856507		[learning rate: 0.0011591]
	Learning Rate: 0.00115913
	LOSS [training: 0.11697694054856507 | validation: 0.17273786033303626]
	TIME [epoch: 9.23 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13384843434263094		[learning rate: 0.0011556]
	Learning Rate: 0.00115558
	LOSS [training: 0.13384843434263094 | validation: 0.1233736866918711]
	TIME [epoch: 9.24 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1105921525028788		[learning rate: 0.001152]
	Learning Rate: 0.00115204
	LOSS [training: 0.1105921525028788 | validation: 0.07748601244543618]
	TIME [epoch: 9.23 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11482228699733384		[learning rate: 0.0011485]
	Learning Rate: 0.00114851
	LOSS [training: 0.11482228699733384 | validation: 0.1960890232413089]
	TIME [epoch: 9.23 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13163697533391677		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.13163697533391677 | validation: 0.05823361598428106]
	TIME [epoch: 9.23 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10124728461466677		[learning rate: 0.0011415]
	Learning Rate: 0.00114148
	LOSS [training: 0.10124728461466677 | validation: 0.08695653318600924]
	TIME [epoch: 9.25 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1071147491597522		[learning rate: 0.001138]
	Learning Rate: 0.00113798
	LOSS [training: 0.1071147491597522 | validation: 0.1297510010683991]
	TIME [epoch: 9.23 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1266721718481615		[learning rate: 0.0011345]
	Learning Rate: 0.00113449
	LOSS [training: 0.1266721718481615 | validation: 0.06744050880558734]
	TIME [epoch: 9.23 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10342359176250526		[learning rate: 0.001131]
	Learning Rate: 0.00113101
	LOSS [training: 0.10342359176250526 | validation: 0.09978677265628408]
	TIME [epoch: 9.23 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09270784024464981		[learning rate: 0.0011275]
	Learning Rate: 0.00112754
	LOSS [training: 0.09270784024464981 | validation: 0.08400072594672975]
	TIME [epoch: 9.23 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12262221641684315		[learning rate: 0.0011241]
	Learning Rate: 0.00112409
	LOSS [training: 0.12262221641684315 | validation: 0.11794151516060561]
	TIME [epoch: 9.23 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12230624000503214		[learning rate: 0.0011206]
	Learning Rate: 0.00112064
	LOSS [training: 0.12230624000503214 | validation: 0.14165586628089272]
	TIME [epoch: 9.22 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11191838600902822		[learning rate: 0.0011172]
	Learning Rate: 0.00111721
	LOSS [training: 0.11191838600902822 | validation: 0.08888743391440948]
	TIME [epoch: 9.23 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216515637555839		[learning rate: 0.0011138]
	Learning Rate: 0.00111378
	LOSS [training: 0.1216515637555839 | validation: 0.08198456590386027]
	TIME [epoch: 9.21 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11934865118066411		[learning rate: 0.0011104]
	Learning Rate: 0.00111037
	LOSS [training: 0.11934865118066411 | validation: 0.0697717578908488]
	TIME [epoch: 9.26 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07754485925172615		[learning rate: 0.001107]
	Learning Rate: 0.00110696
	LOSS [training: 0.07754485925172615 | validation: 0.07469563837334642]
	TIME [epoch: 9.22 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09044304331942038		[learning rate: 0.0011036]
	Learning Rate: 0.00110357
	LOSS [training: 0.09044304331942038 | validation: 0.09357294680131156]
	TIME [epoch: 9.22 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468098985802254		[learning rate: 0.0011002]
	Learning Rate: 0.00110019
	LOSS [training: 0.08468098985802254 | validation: 0.09123566586702707]
	TIME [epoch: 9.23 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08201496772107544		[learning rate: 0.0010968]
	Learning Rate: 0.00109681
	LOSS [training: 0.08201496772107544 | validation: 0.06805537666378014]
	TIME [epoch: 9.23 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900408648404017		[learning rate: 0.0010935]
	Learning Rate: 0.00109345
	LOSS [training: 0.0900408648404017 | validation: 0.15230806942921815]
	TIME [epoch: 9.24 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12416922064950875		[learning rate: 0.0010901]
	Learning Rate: 0.0010901
	LOSS [training: 0.12416922064950875 | validation: 0.21786260947383562]
	TIME [epoch: 9.23 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14198178913442155		[learning rate: 0.0010868]
	Learning Rate: 0.00108676
	LOSS [training: 0.14198178913442155 | validation: 0.11752273337898256]
	TIME [epoch: 9.23 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10599980616223419		[learning rate: 0.0010834]
	Learning Rate: 0.00108343
	LOSS [training: 0.10599980616223419 | validation: 0.19975703215827395]
	TIME [epoch: 9.22 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11435058513453641		[learning rate: 0.0010801]
	Learning Rate: 0.00108011
	LOSS [training: 0.11435058513453641 | validation: 0.07185369206247388]
	TIME [epoch: 9.24 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273293116203313		[learning rate: 0.0010768]
	Learning Rate: 0.0010768
	LOSS [training: 0.09273293116203313 | validation: 0.10276012216272792]
	TIME [epoch: 9.23 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11123736320378892		[learning rate: 0.0010735]
	Learning Rate: 0.00107349
	LOSS [training: 0.11123736320378892 | validation: 0.08684908006056917]
	TIME [epoch: 9.21 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11530998249645064		[learning rate: 0.0010702]
	Learning Rate: 0.0010702
	LOSS [training: 0.11530998249645064 | validation: 0.06409670323031405]
	TIME [epoch: 9.23 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09940519199062406		[learning rate: 0.0010669]
	Learning Rate: 0.00106692
	LOSS [training: 0.09940519199062406 | validation: 0.08231709478425317]
	TIME [epoch: 9.23 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07787401918768949		[learning rate: 0.0010637]
	Learning Rate: 0.00106365
	LOSS [training: 0.07787401918768949 | validation: 0.0753124220311664]
	TIME [epoch: 9.24 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10892067097109895		[learning rate: 0.0010604]
	Learning Rate: 0.00106039
	LOSS [training: 0.10892067097109895 | validation: 0.07258924846567728]
	TIME [epoch: 9.23 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921501491453723		[learning rate: 0.0010571]
	Learning Rate: 0.00105714
	LOSS [training: 0.0921501491453723 | validation: 0.1080606048807019]
	TIME [epoch: 9.23 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10311312987388203		[learning rate: 0.0010539]
	Learning Rate: 0.0010539
	LOSS [training: 0.10311312987388203 | validation: 0.13418694573392206]
	TIME [epoch: 9.22 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1539326302985554		[learning rate: 0.0010507]
	Learning Rate: 0.00105067
	LOSS [training: 0.1539326302985554 | validation: 0.21302693509581505]
	TIME [epoch: 9.25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1659560076230549		[learning rate: 0.0010475]
	Learning Rate: 0.00104745
	LOSS [training: 0.1659560076230549 | validation: 0.1267418450190731]
	TIME [epoch: 9.22 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11033336623919472		[learning rate: 0.0010442]
	Learning Rate: 0.00104424
	LOSS [training: 0.11033336623919472 | validation: 0.10737912558463647]
	TIME [epoch: 9.23 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09672748070816173		[learning rate: 0.001041]
	Learning Rate: 0.00104104
	LOSS [training: 0.09672748070816173 | validation: 0.09087192347237312]
	TIME [epoch: 9.23 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09002188741410488		[learning rate: 0.0010378]
	Learning Rate: 0.00103785
	LOSS [training: 0.09002188741410488 | validation: 0.07493463296065317]
	TIME [epoch: 9.24 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720539756128284		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.08720539756128284 | validation: 0.0804603214845539]
	TIME [epoch: 9.24 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910547055204553		[learning rate: 0.0010315]
	Learning Rate: 0.00103149
	LOSS [training: 0.0910547055204553 | validation: 0.07531237839676619]
	TIME [epoch: 9.23 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960895578843425		[learning rate: 0.0010283]
	Learning Rate: 0.00102833
	LOSS [training: 0.0960895578843425 | validation: 0.07047076425183507]
	TIME [epoch: 9.24 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09488880215927381		[learning rate: 0.0010252]
	Learning Rate: 0.00102518
	LOSS [training: 0.09488880215927381 | validation: 0.07594049691457816]
	TIME [epoch: 9.23 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12268682663392028		[learning rate: 0.001022]
	Learning Rate: 0.00102204
	LOSS [training: 0.12268682663392028 | validation: 0.127976334126224]
	TIME [epoch: 9.25 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12236967228935472		[learning rate: 0.0010189]
	Learning Rate: 0.0010189
	LOSS [training: 0.12236967228935472 | validation: 0.16301723838732907]
	TIME [epoch: 9.23 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11440963103233967		[learning rate: 0.0010158]
	Learning Rate: 0.00101578
	LOSS [training: 0.11440963103233967 | validation: 0.06166181062057742]
	TIME [epoch: 9.23 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08975252610961694		[learning rate: 0.0010127]
	Learning Rate: 0.00101267
	LOSS [training: 0.08975252610961694 | validation: 0.06960741097424256]
	TIME [epoch: 9.23 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11817283133157877		[learning rate: 0.0010096]
	Learning Rate: 0.00100956
	LOSS [training: 0.11817283133157877 | validation: 0.06579209173632139]
	TIME [epoch: 9.24 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09270476140270631		[learning rate: 0.0010065]
	Learning Rate: 0.00100647
	LOSS [training: 0.09270476140270631 | validation: 0.14501392227472276]
	TIME [epoch: 9.23 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12075629740204637		[learning rate: 0.0010034]
	Learning Rate: 0.00100338
	LOSS [training: 0.12075629740204637 | validation: 0.15034496722195623]
	TIME [epoch: 9.22 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11681267285278052		[learning rate: 0.0010003]
	Learning Rate: 0.00100031
	LOSS [training: 0.11681267285278052 | validation: 0.07872019119473114]
	TIME [epoch: 9.22 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08995731321554261		[learning rate: 0.00099724]
	Learning Rate: 0.000997241
	LOSS [training: 0.08995731321554261 | validation: 0.046435171946766676]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1251.pth
	Model improved!!!
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10594667097731916		[learning rate: 0.00099418]
	Learning Rate: 0.000994184
	LOSS [training: 0.10594667097731916 | validation: 0.11243354692611418]
	TIME [epoch: 9.24 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09508374916569426		[learning rate: 0.00099114]
	Learning Rate: 0.000991136
	LOSS [training: 0.09508374916569426 | validation: 0.057192294496133014]
	TIME [epoch: 9.23 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09134917798800216		[learning rate: 0.0009881]
	Learning Rate: 0.000988098
	LOSS [training: 0.09134917798800216 | validation: 0.09822507525097937]
	TIME [epoch: 9.22 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08757242467339192		[learning rate: 0.00098507]
	Learning Rate: 0.000985069
	LOSS [training: 0.08757242467339192 | validation: 0.05999017456247176]
	TIME [epoch: 9.22 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08083973808122007		[learning rate: 0.00098205]
	Learning Rate: 0.00098205
	LOSS [training: 0.08083973808122007 | validation: 0.06264169853639391]
	TIME [epoch: 9.22 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08329441009317182		[learning rate: 0.00097904]
	Learning Rate: 0.000979039
	LOSS [training: 0.08329441009317182 | validation: 0.07197233587724942]
	TIME [epoch: 9.24 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08413508953438512		[learning rate: 0.00097604]
	Learning Rate: 0.000976038
	LOSS [training: 0.08413508953438512 | validation: 0.11676189685253807]
	TIME [epoch: 9.22 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1144049718060153		[learning rate: 0.00097305]
	Learning Rate: 0.000973046
	LOSS [training: 0.1144049718060153 | validation: 0.11017998916138552]
	TIME [epoch: 9.23 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09865581149807487		[learning rate: 0.00097006]
	Learning Rate: 0.000970063
	LOSS [training: 0.09865581149807487 | validation: 0.11092736111404608]
	TIME [epoch: 9.22 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10023437098764965		[learning rate: 0.00096709]
	Learning Rate: 0.000967089
	LOSS [training: 0.10023437098764965 | validation: 0.07220421329337634]
	TIME [epoch: 9.25 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0884313823275887		[learning rate: 0.00096412]
	Learning Rate: 0.000964125
	LOSS [training: 0.0884313823275887 | validation: 0.055905155655300534]
	TIME [epoch: 9.23 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09395790341247547		[learning rate: 0.00096117]
	Learning Rate: 0.00096117
	LOSS [training: 0.09395790341247547 | validation: 0.08289787092076767]
	TIME [epoch: 9.22 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09690834183052165		[learning rate: 0.00095822]
	Learning Rate: 0.000958223
	LOSS [training: 0.09690834183052165 | validation: 0.09134066600320156]
	TIME [epoch: 9.23 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08330006902835445		[learning rate: 0.00095529]
	Learning Rate: 0.000955286
	LOSS [training: 0.08330006902835445 | validation: 0.11597248949627542]
	TIME [epoch: 9.23 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11418159795828035		[learning rate: 0.00095236]
	Learning Rate: 0.000952357
	LOSS [training: 0.11418159795828035 | validation: 0.12064860625514931]
	TIME [epoch: 9.24 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10346951345648654		[learning rate: 0.00094944]
	Learning Rate: 0.000949438
	LOSS [training: 0.10346951345648654 | validation: 0.12467509956180867]
	TIME [epoch: 9.22 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08538559483502067		[learning rate: 0.00094653]
	Learning Rate: 0.000946528
	LOSS [training: 0.08538559483502067 | validation: 0.06592022236117932]
	TIME [epoch: 9.23 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07566715184576386		[learning rate: 0.00094363]
	Learning Rate: 0.000943626
	LOSS [training: 0.07566715184576386 | validation: 0.0636404597356653]
	TIME [epoch: 9.23 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09320413546001247		[learning rate: 0.00094073]
	Learning Rate: 0.000940734
	LOSS [training: 0.09320413546001247 | validation: 0.07806062603459087]
	TIME [epoch: 9.24 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09165840879365207		[learning rate: 0.00093785]
	Learning Rate: 0.00093785
	LOSS [training: 0.09165840879365207 | validation: 0.10197129244707273]
	TIME [epoch: 9.22 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10706141391113455		[learning rate: 0.00093497]
	Learning Rate: 0.000934975
	LOSS [training: 0.10706141391113455 | validation: 0.10082721280641502]
	TIME [epoch: 9.22 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1021192753158143		[learning rate: 0.00093211]
	Learning Rate: 0.000932109
	LOSS [training: 0.1021192753158143 | validation: 0.10765084814240827]
	TIME [epoch: 9.22 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11235679887888365		[learning rate: 0.00092925]
	Learning Rate: 0.000929252
	LOSS [training: 0.11235679887888365 | validation: 0.08113238917999246]
	TIME [epoch: 9.22 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09216178303981606		[learning rate: 0.0009264]
	Learning Rate: 0.000926403
	LOSS [training: 0.09216178303981606 | validation: 0.06880319004138702]
	TIME [epoch: 9.23 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07801085816685169		[learning rate: 0.00092356]
	Learning Rate: 0.000923563
	LOSS [training: 0.07801085816685169 | validation: 0.07433342438032872]
	TIME [epoch: 9.22 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10536826825948235		[learning rate: 0.00092073]
	Learning Rate: 0.000920732
	LOSS [training: 0.10536826825948235 | validation: 0.10264199456836137]
	TIME [epoch: 9.21 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0969827796782333		[learning rate: 0.00091791]
	Learning Rate: 0.00091791
	LOSS [training: 0.0969827796782333 | validation: 0.06613756340579031]
	TIME [epoch: 9.22 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094595500183129		[learning rate: 0.0009151]
	Learning Rate: 0.000915096
	LOSS [training: 0.07094595500183129 | validation: 0.0741877501037623]
	TIME [epoch: 9.23 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08481556803021084		[learning rate: 0.00091229]
	Learning Rate: 0.000912291
	LOSS [training: 0.08481556803021084 | validation: 0.11309648541186153]
	TIME [epoch: 9.22 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09759010906897617		[learning rate: 0.00090949]
	Learning Rate: 0.000909494
	LOSS [training: 0.09759010906897617 | validation: 0.0602669285916006]
	TIME [epoch: 9.21 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08754696947571748		[learning rate: 0.00090671]
	Learning Rate: 0.000906706
	LOSS [training: 0.08754696947571748 | validation: 0.09665418804186496]
	TIME [epoch: 9.23 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09203254506184542		[learning rate: 0.00090393]
	Learning Rate: 0.000903927
	LOSS [training: 0.09203254506184542 | validation: 0.09267501836341913]
	TIME [epoch: 9.22 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11158462002752367		[learning rate: 0.00090116]
	Learning Rate: 0.000901156
	LOSS [training: 0.11158462002752367 | validation: 0.09532869941420949]
	TIME [epoch: 9.23 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09555678306748387		[learning rate: 0.00089839]
	Learning Rate: 0.000898394
	LOSS [training: 0.09555678306748387 | validation: 0.08637702598270658]
	TIME [epoch: 9.22 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08843275707057204		[learning rate: 0.00089564]
	Learning Rate: 0.00089564
	LOSS [training: 0.08843275707057204 | validation: 0.0866815846226429]
	TIME [epoch: 9.23 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11326946505439954		[learning rate: 0.00089289]
	Learning Rate: 0.000892894
	LOSS [training: 0.11326946505439954 | validation: 0.17540286616132172]
	TIME [epoch: 9.22 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14426934524707252		[learning rate: 0.00089016]
	Learning Rate: 0.000890157
	LOSS [training: 0.14426934524707252 | validation: 0.1227767758386921]
	TIME [epoch: 9.24 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10871641955773441		[learning rate: 0.00088743]
	Learning Rate: 0.000887428
	LOSS [training: 0.10871641955773441 | validation: 0.09745339370657266]
	TIME [epoch: 9.22 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09629738941124859		[learning rate: 0.00088471]
	Learning Rate: 0.000884708
	LOSS [training: 0.09629738941124859 | validation: 0.07522073844626283]
	TIME [epoch: 9.21 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09072988166829785		[learning rate: 0.000882]
	Learning Rate: 0.000881996
	LOSS [training: 0.09072988166829785 | validation: 0.12734240048388132]
	TIME [epoch: 9.21 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10866568610761093		[learning rate: 0.00087929]
	Learning Rate: 0.000879292
	LOSS [training: 0.10866568610761093 | validation: 0.08892286937011248]
	TIME [epoch: 9.23 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07669647718829041		[learning rate: 0.0008766]
	Learning Rate: 0.000876597
	LOSS [training: 0.07669647718829041 | validation: 0.07374108923188569]
	TIME [epoch: 9.23 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10289343606085295		[learning rate: 0.00087391]
	Learning Rate: 0.00087391
	LOSS [training: 0.10289343606085295 | validation: 0.08303324272655718]
	TIME [epoch: 9.22 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10112501810056067		[learning rate: 0.00087123]
	Learning Rate: 0.000871231
	LOSS [training: 0.10112501810056067 | validation: 0.08456166240439351]
	TIME [epoch: 9.22 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10028459036341524		[learning rate: 0.00086856]
	Learning Rate: 0.00086856
	LOSS [training: 0.10028459036341524 | validation: 0.06532110139545352]
	TIME [epoch: 9.22 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07651365166099341		[learning rate: 0.0008659]
	Learning Rate: 0.000865898
	LOSS [training: 0.07651365166099341 | validation: 0.07098936838783125]
	TIME [epoch: 9.23 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08356699336264231		[learning rate: 0.00086324]
	Learning Rate: 0.000863243
	LOSS [training: 0.08356699336264231 | validation: 0.10775965376864743]
	TIME [epoch: 9.23 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10173376507835127		[learning rate: 0.0008606]
	Learning Rate: 0.000860597
	LOSS [training: 0.10173376507835127 | validation: 0.061216772535418316]
	TIME [epoch: 9.22 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08677656890585804		[learning rate: 0.00085796]
	Learning Rate: 0.000857959
	LOSS [training: 0.08677656890585804 | validation: 0.10195319230558882]
	TIME [epoch: 9.21 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302225343142496		[learning rate: 0.00085533]
	Learning Rate: 0.000855329
	LOSS [training: 0.07302225343142496 | validation: 0.07840247022417277]
	TIME [epoch: 9.22 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09217006961978284		[learning rate: 0.00085271]
	Learning Rate: 0.000852707
	LOSS [training: 0.09217006961978284 | validation: 0.05933951240922597]
	TIME [epoch: 9.23 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08755941879602938		[learning rate: 0.00085009]
	Learning Rate: 0.000850093
	LOSS [training: 0.08755941879602938 | validation: 0.1237364202051365]
	TIME [epoch: 9.22 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09296389706579924		[learning rate: 0.00084749]
	Learning Rate: 0.000847488
	LOSS [training: 0.09296389706579924 | validation: 0.055997156032614376]
	TIME [epoch: 9.21 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1076769520107971		[learning rate: 0.00084489]
	Learning Rate: 0.00084489
	LOSS [training: 0.1076769520107971 | validation: 0.1541472338491814]
	TIME [epoch: 9.22 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09572512541282208		[learning rate: 0.0008423]
	Learning Rate: 0.0008423
	LOSS [training: 0.09572512541282208 | validation: 0.055900206629108676]
	TIME [epoch: 9.25 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08399095699219275		[learning rate: 0.00083972]
	Learning Rate: 0.000839718
	LOSS [training: 0.08399095699219275 | validation: 0.0701982846083428]
	TIME [epoch: 9.22 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08086402487543039		[learning rate: 0.00083714]
	Learning Rate: 0.000837144
	LOSS [training: 0.08086402487543039 | validation: 0.08092542333652114]
	TIME [epoch: 9.22 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07975299528478		[learning rate: 0.00083458]
	Learning Rate: 0.000834578
	LOSS [training: 0.07975299528478 | validation: 0.07505849390637467]
	TIME [epoch: 9.23 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10401150427897503		[learning rate: 0.00083202]
	Learning Rate: 0.000832019
	LOSS [training: 0.10401150427897503 | validation: 0.05505664203851532]
	TIME [epoch: 9.22 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08816824642240097		[learning rate: 0.00082947]
	Learning Rate: 0.000829469
	LOSS [training: 0.08816824642240097 | validation: 0.06279364676371214]
	TIME [epoch: 9.24 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09495834517860113		[learning rate: 0.00082693]
	Learning Rate: 0.000826926
	LOSS [training: 0.09495834517860113 | validation: 0.07219622694571877]
	TIME [epoch: 9.22 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0903276144273646		[learning rate: 0.00082439]
	Learning Rate: 0.000824391
	LOSS [training: 0.0903276144273646 | validation: 0.0526121991874486]
	TIME [epoch: 9.21 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0754075382063305		[learning rate: 0.00082186]
	Learning Rate: 0.000821864
	LOSS [training: 0.0754075382063305 | validation: 0.05804846762913296]
	TIME [epoch: 9.21 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07412969433532723		[learning rate: 0.00081934]
	Learning Rate: 0.000819345
	LOSS [training: 0.07412969433532723 | validation: 0.07002951434768222]
	TIME [epoch: 9.24 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223207729559343		[learning rate: 0.00081683]
	Learning Rate: 0.000816833
	LOSS [training: 0.09223207729559343 | validation: 0.07932983561427326]
	TIME [epoch: 9.23 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11085837970217831		[learning rate: 0.00081433]
	Learning Rate: 0.000814329
	LOSS [training: 0.11085837970217831 | validation: 0.087261380119899]
	TIME [epoch: 9.21 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09272163493796715		[learning rate: 0.00081183]
	Learning Rate: 0.000811833
	LOSS [training: 0.09272163493796715 | validation: 0.08003022119023401]
	TIME [epoch: 9.23 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09774381673294588		[learning rate: 0.00080934]
	Learning Rate: 0.000809344
	LOSS [training: 0.09774381673294588 | validation: 0.09103626283112942]
	TIME [epoch: 9.22 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08571009164255486		[learning rate: 0.00080686]
	Learning Rate: 0.000806863
	LOSS [training: 0.08571009164255486 | validation: 0.09355899163746556]
	TIME [epoch: 9.23 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08211343952798453		[learning rate: 0.00080439]
	Learning Rate: 0.00080439
	LOSS [training: 0.08211343952798453 | validation: 0.1253466121666975]
	TIME [epoch: 9.22 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434513642490969		[learning rate: 0.00080192]
	Learning Rate: 0.000801924
	LOSS [training: 0.09434513642490969 | validation: 0.042127128637749686]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1322.pth
	Model improved!!!
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10506969158222701		[learning rate: 0.00079947]
	Learning Rate: 0.000799466
	LOSS [training: 0.10506969158222701 | validation: 0.0686241209580915]
	TIME [epoch: 9.22 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07874776787999298		[learning rate: 0.00079702]
	Learning Rate: 0.000797015
	LOSS [training: 0.07874776787999298 | validation: 0.05256789301311093]
	TIME [epoch: 9.24 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07777390525294893		[learning rate: 0.00079457]
	Learning Rate: 0.000794572
	LOSS [training: 0.07777390525294893 | validation: 0.05093991056088902]
	TIME [epoch: 9.22 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07225862582584136		[learning rate: 0.00079214]
	Learning Rate: 0.000792136
	LOSS [training: 0.07225862582584136 | validation: 0.06290531959926257]
	TIME [epoch: 9.23 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1062791463308301		[learning rate: 0.00078971]
	Learning Rate: 0.000789708
	LOSS [training: 0.1062791463308301 | validation: 0.09700648187649508]
	TIME [epoch: 9.21 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0954439919031264		[learning rate: 0.00078729]
	Learning Rate: 0.000787287
	LOSS [training: 0.0954439919031264 | validation: 0.07589557259693226]
	TIME [epoch: 9.23 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10374440962578031		[learning rate: 0.00078487]
	Learning Rate: 0.000784874
	LOSS [training: 0.10374440962578031 | validation: 0.06948853247769207]
	TIME [epoch: 9.23 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13193906706322178		[learning rate: 0.00078247]
	Learning Rate: 0.000782468
	LOSS [training: 0.13193906706322178 | validation: 0.06134159217640281]
	TIME [epoch: 9.21 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08933727976370173		[learning rate: 0.00078007]
	Learning Rate: 0.00078007
	LOSS [training: 0.08933727976370173 | validation: 0.07582072061197924]
	TIME [epoch: 9.21 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09730235954684929		[learning rate: 0.00077768]
	Learning Rate: 0.000777678
	LOSS [training: 0.09730235954684929 | validation: 0.07437577181573414]
	TIME [epoch: 9.22 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08596364273545733		[learning rate: 0.00077529]
	Learning Rate: 0.000775294
	LOSS [training: 0.08596364273545733 | validation: 0.08079676646732667]
	TIME [epoch: 9.24 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07905120817401702		[learning rate: 0.00077292]
	Learning Rate: 0.000772918
	LOSS [training: 0.07905120817401702 | validation: 0.0619950471164084]
	TIME [epoch: 9.22 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07662429964053982		[learning rate: 0.00077055]
	Learning Rate: 0.000770548
	LOSS [training: 0.07662429964053982 | validation: 0.06889545281499627]
	TIME [epoch: 9.22 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07165479262221894		[learning rate: 0.00076819]
	Learning Rate: 0.000768187
	LOSS [training: 0.07165479262221894 | validation: 0.09791140173838772]
	TIME [epoch: 9.22 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09127979591458064		[learning rate: 0.00076583]
	Learning Rate: 0.000765832
	LOSS [training: 0.09127979591458064 | validation: 0.07524741748884928]
	TIME [epoch: 9.22 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08489316676739926		[learning rate: 0.00076348]
	Learning Rate: 0.000763484
	LOSS [training: 0.08489316676739926 | validation: 0.06972780252129678]
	TIME [epoch: 9.22 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0840414201527768		[learning rate: 0.00076114]
	Learning Rate: 0.000761144
	LOSS [training: 0.0840414201527768 | validation: 0.11041657730233093]
	TIME [epoch: 9.21 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07100326155313531		[learning rate: 0.00075881]
	Learning Rate: 0.00075881
	LOSS [training: 0.07100326155313531 | validation: 0.06031117918520669]
	TIME [epoch: 9.21 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07370377681938516		[learning rate: 0.00075648]
	Learning Rate: 0.000756484
	LOSS [training: 0.07370377681938516 | validation: 0.06318627545426807]
	TIME [epoch: 9.22 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07682935191354903		[learning rate: 0.00075417]
	Learning Rate: 0.000754165
	LOSS [training: 0.07682935191354903 | validation: 0.06165213128583689]
	TIME [epoch: 9.25 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06742812890434594		[learning rate: 0.00075185]
	Learning Rate: 0.000751854
	LOSS [training: 0.06742812890434594 | validation: 0.06686673530312053]
	TIME [epoch: 9.23 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11560206984663499		[learning rate: 0.00074955]
	Learning Rate: 0.000749549
	LOSS [training: 0.11560206984663499 | validation: 0.07885844194902339]
	TIME [epoch: 9.21 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07357429435596		[learning rate: 0.00074725]
	Learning Rate: 0.000747251
	LOSS [training: 0.07357429435596 | validation: 0.07207932592990667]
	TIME [epoch: 9.22 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10593348369220316		[learning rate: 0.00074496]
	Learning Rate: 0.000744961
	LOSS [training: 0.10593348369220316 | validation: 0.17408653952002595]
	TIME [epoch: 9.23 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1199133933220496		[learning rate: 0.00074268]
	Learning Rate: 0.000742677
	LOSS [training: 0.1199133933220496 | validation: 0.07236511364968456]
	TIME [epoch: 9.22 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08393498718467862		[learning rate: 0.0007404]
	Learning Rate: 0.0007404
	LOSS [training: 0.08393498718467862 | validation: 0.08193986209739045]
	TIME [epoch: 9.22 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07802108050431311		[learning rate: 0.00073813]
	Learning Rate: 0.000738131
	LOSS [training: 0.07802108050431311 | validation: 0.05980750357003418]
	TIME [epoch: 9.22 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.088733508146535		[learning rate: 0.00073587]
	Learning Rate: 0.000735868
	LOSS [training: 0.088733508146535 | validation: 0.07111086967005398]
	TIME [epoch: 9.22 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07859225599117169		[learning rate: 0.00073361]
	Learning Rate: 0.000733612
	LOSS [training: 0.07859225599117169 | validation: 0.04517985208443748]
	TIME [epoch: 9.24 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783721671607676		[learning rate: 0.00073136]
	Learning Rate: 0.000731364
	LOSS [training: 0.06783721671607676 | validation: 0.06659032969261498]
	TIME [epoch: 9.22 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12552437494940183		[learning rate: 0.00072912]
	Learning Rate: 0.000729122
	LOSS [training: 0.12552437494940183 | validation: 0.09960187770975486]
	TIME [epoch: 9.22 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09353463050607382		[learning rate: 0.00072689]
	Learning Rate: 0.000726886
	LOSS [training: 0.09353463050607382 | validation: 0.09282493708777852]
	TIME [epoch: 9.23 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07972170010231974		[learning rate: 0.00072466]
	Learning Rate: 0.000724658
	LOSS [training: 0.07972170010231974 | validation: 0.05954822582757154]
	TIME [epoch: 9.23 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09250057715695222		[learning rate: 0.00072244]
	Learning Rate: 0.000722437
	LOSS [training: 0.09250057715695222 | validation: 0.08903895230611417]
	TIME [epoch: 9.24 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06971898666859498		[learning rate: 0.00072022]
	Learning Rate: 0.000720223
	LOSS [training: 0.06971898666859498 | validation: 0.06361796044995646]
	TIME [epoch: 9.22 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07600796361540964		[learning rate: 0.00071801]
	Learning Rate: 0.000718015
	LOSS [training: 0.07600796361540964 | validation: 0.06530556907093316]
	TIME [epoch: 9.22 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09136469178752543		[learning rate: 0.00071581]
	Learning Rate: 0.000715814
	LOSS [training: 0.09136469178752543 | validation: 0.09979678585714291]
	TIME [epoch: 9.22 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09528807360754862		[learning rate: 0.00071362]
	Learning Rate: 0.000713619
	LOSS [training: 0.09528807360754862 | validation: 0.06838155004550468]
	TIME [epoch: 9.24 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223343302514034		[learning rate: 0.00071143]
	Learning Rate: 0.000711432
	LOSS [training: 0.09223343302514034 | validation: 0.155825522601857]
	TIME [epoch: 9.22 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09408947339934848		[learning rate: 0.00070925]
	Learning Rate: 0.000709251
	LOSS [training: 0.09408947339934848 | validation: 0.052154683371263506]
	TIME [epoch: 9.22 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739067706574535		[learning rate: 0.00070708]
	Learning Rate: 0.000707077
	LOSS [training: 0.08739067706574535 | validation: 0.07887970472077704]
	TIME [epoch: 9.22 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07505635499000798		[learning rate: 0.00070491]
	Learning Rate: 0.00070491
	LOSS [training: 0.07505635499000798 | validation: 0.09121514210702127]
	TIME [epoch: 9.24 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09644932677961351		[learning rate: 0.00070275]
	Learning Rate: 0.000702748
	LOSS [training: 0.09644932677961351 | validation: 0.06099275585962716]
	TIME [epoch: 9.23 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0941800730615974		[learning rate: 0.00070059]
	Learning Rate: 0.000700594
	LOSS [training: 0.0941800730615974 | validation: 0.07047419241848189]
	TIME [epoch: 9.22 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08852795166398734		[learning rate: 0.00069845]
	Learning Rate: 0.000698447
	LOSS [training: 0.08852795166398734 | validation: 0.0657134631141606]
	TIME [epoch: 9.23 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08643291265055934		[learning rate: 0.00069631]
	Learning Rate: 0.000696306
	LOSS [training: 0.08643291265055934 | validation: 0.08867956047423506]
	TIME [epoch: 9.24 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08407052375131144		[learning rate: 0.00069417]
	Learning Rate: 0.000694171
	LOSS [training: 0.08407052375131144 | validation: 0.08637329448263283]
	TIME [epoch: 9.25 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08201336188999628		[learning rate: 0.00069204]
	Learning Rate: 0.000692043
	LOSS [training: 0.08201336188999628 | validation: 0.06703511194224684]
	TIME [epoch: 9.23 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07168212785029715		[learning rate: 0.00068992]
	Learning Rate: 0.000689922
	LOSS [training: 0.07168212785029715 | validation: 0.08437432080629476]
	TIME [epoch: 9.24 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013551339090483		[learning rate: 0.00068781]
	Learning Rate: 0.000687807
	LOSS [training: 0.1013551339090483 | validation: 0.07164230555262652]
	TIME [epoch: 9.23 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07788211329877535		[learning rate: 0.0006857]
	Learning Rate: 0.000685699
	LOSS [training: 0.07788211329877535 | validation: 0.10444964866889812]
	TIME [epoch: 9.25 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09854661995616688		[learning rate: 0.0006836]
	Learning Rate: 0.000683597
	LOSS [training: 0.09854661995616688 | validation: 0.09096908378582366]
	TIME [epoch: 9.24 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09516807017285027		[learning rate: 0.0006815]
	Learning Rate: 0.000681501
	LOSS [training: 0.09516807017285027 | validation: 0.07211815481040285]
	TIME [epoch: 9.23 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06123301103639235		[learning rate: 0.00067941]
	Learning Rate: 0.000679412
	LOSS [training: 0.06123301103639235 | validation: 0.057317763793907295]
	TIME [epoch: 9.23 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0836803667561435		[learning rate: 0.00067733]
	Learning Rate: 0.000677329
	LOSS [training: 0.0836803667561435 | validation: 0.07184222821653274]
	TIME [epoch: 9.24 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707497131478266		[learning rate: 0.00067525]
	Learning Rate: 0.000675253
	LOSS [training: 0.06707497131478266 | validation: 0.07103451734152334]
	TIME [epoch: 9.25 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08152800585348689		[learning rate: 0.00067318]
	Learning Rate: 0.000673183
	LOSS [training: 0.08152800585348689 | validation: 0.07214341625555157]
	TIME [epoch: 9.24 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07965013775665439		[learning rate: 0.00067112]
	Learning Rate: 0.00067112
	LOSS [training: 0.07965013775665439 | validation: 0.09706695021388659]
	TIME [epoch: 9.23 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10085555500681279		[learning rate: 0.00066906]
	Learning Rate: 0.000669062
	LOSS [training: 0.10085555500681279 | validation: 0.060185740665772244]
	TIME [epoch: 9.24 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0621625165498262		[learning rate: 0.00066701]
	Learning Rate: 0.000667011
	LOSS [training: 0.0621625165498262 | validation: 0.059293261236590844]
	TIME [epoch: 9.24 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08703488509396536		[learning rate: 0.00066497]
	Learning Rate: 0.000664967
	LOSS [training: 0.08703488509396536 | validation: 0.058632506340720314]
	TIME [epoch: 9.24 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06966484153785478		[learning rate: 0.00066293]
	Learning Rate: 0.000662929
	LOSS [training: 0.06966484153785478 | validation: 0.0596060171559335]
	TIME [epoch: 9.24 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07212599334443878		[learning rate: 0.0006609]
	Learning Rate: 0.000660896
	LOSS [training: 0.07212599334443878 | validation: 0.0671283037575352]
	TIME [epoch: 9.24 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06669522021614285		[learning rate: 0.00065887]
	Learning Rate: 0.00065887
	LOSS [training: 0.06669522021614285 | validation: 0.06425108650357855]
	TIME [epoch: 9.24 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07009403390670031		[learning rate: 0.00065685]
	Learning Rate: 0.000656851
	LOSS [training: 0.07009403390670031 | validation: 0.0831466474369161]
	TIME [epoch: 9.25 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10199016553400367		[learning rate: 0.00065484]
	Learning Rate: 0.000654837
	LOSS [training: 0.10199016553400367 | validation: 0.06358600266164245]
	TIME [epoch: 9.23 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10764279459079396		[learning rate: 0.00065283]
	Learning Rate: 0.00065283
	LOSS [training: 0.10764279459079396 | validation: 0.054191441618867006]
	TIME [epoch: 9.23 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07165426731155185		[learning rate: 0.00065083]
	Learning Rate: 0.000650829
	LOSS [training: 0.07165426731155185 | validation: 0.061187634565670695]
	TIME [epoch: 9.24 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06952053057674329		[learning rate: 0.00064883]
	Learning Rate: 0.000648834
	LOSS [training: 0.06952053057674329 | validation: 0.05805275404458036]
	TIME [epoch: 9.24 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06409724704987749		[learning rate: 0.00064684]
	Learning Rate: 0.000646845
	LOSS [training: 0.06409724704987749 | validation: 0.07145139502870838]
	TIME [epoch: 9.25 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06764521200273493		[learning rate: 0.00064486]
	Learning Rate: 0.000644862
	LOSS [training: 0.06764521200273493 | validation: 0.054605654072943245]
	TIME [epoch: 9.23 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372012505960475		[learning rate: 0.00064289]
	Learning Rate: 0.000642885
	LOSS [training: 0.07372012505960475 | validation: 0.09269686843424702]
	TIME [epoch: 9.23 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814928054492225		[learning rate: 0.00064091]
	Learning Rate: 0.000640914
	LOSS [training: 0.07814928054492225 | validation: 0.1023252209790772]
	TIME [epoch: 9.24 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07519093269117912		[learning rate: 0.00063895]
	Learning Rate: 0.00063895
	LOSS [training: 0.07519093269117912 | validation: 0.07388677720993755]
	TIME [epoch: 9.25 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1078753711316719		[learning rate: 0.00063699]
	Learning Rate: 0.000636991
	LOSS [training: 0.1078753711316719 | validation: 0.05537363092782873]
	TIME [epoch: 9.24 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10847415557604434		[learning rate: 0.00063504]
	Learning Rate: 0.000635038
	LOSS [training: 0.10847415557604434 | validation: 0.10178592390648714]
	TIME [epoch: 9.23 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10426510019018465		[learning rate: 0.00063309]
	Learning Rate: 0.000633092
	LOSS [training: 0.10426510019018465 | validation: 0.1105937026789496]
	TIME [epoch: 9.23 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09238373132421299		[learning rate: 0.00063115]
	Learning Rate: 0.000631151
	LOSS [training: 0.09238373132421299 | validation: 0.08720414133064898]
	TIME [epoch: 9.24 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07937385166521493		[learning rate: 0.00062922]
	Learning Rate: 0.000629216
	LOSS [training: 0.07937385166521493 | validation: 0.11797045044175804]
	TIME [epoch: 9.25 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09706028507954423		[learning rate: 0.00062729]
	Learning Rate: 0.000627287
	LOSS [training: 0.09706028507954423 | validation: 0.06515242976499905]
	TIME [epoch: 9.23 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650153863949882		[learning rate: 0.00062536]
	Learning Rate: 0.000625365
	LOSS [training: 0.07650153863949882 | validation: 0.06964859727603762]
	TIME [epoch: 9.23 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0787532538094614		[learning rate: 0.00062345]
	Learning Rate: 0.000623448
	LOSS [training: 0.0787532538094614 | validation: 0.07990353931959439]
	TIME [epoch: 9.23 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08666028802437457		[learning rate: 0.00062154]
	Learning Rate: 0.000621537
	LOSS [training: 0.08666028802437457 | validation: 0.08013325688244446]
	TIME [epoch: 9.25 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08450385368734215		[learning rate: 0.00061963]
	Learning Rate: 0.000619631
	LOSS [training: 0.08450385368734215 | validation: 0.060752084676535326]
	TIME [epoch: 9.24 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08699465153002799		[learning rate: 0.00061773]
	Learning Rate: 0.000617732
	LOSS [training: 0.08699465153002799 | validation: 0.14229969424600625]
	TIME [epoch: 9.23 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08763752901407207		[learning rate: 0.00061584]
	Learning Rate: 0.000615838
	LOSS [training: 0.08763752901407207 | validation: 0.06323721374106281]
	TIME [epoch: 9.24 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06549574364402935		[learning rate: 0.00061395]
	Learning Rate: 0.00061395
	LOSS [training: 0.06549574364402935 | validation: 0.07500894304335395]
	TIME [epoch: 9.25 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11069899629337147		[learning rate: 0.00061207]
	Learning Rate: 0.000612068
	LOSS [training: 0.11069899629337147 | validation: 0.10943506595913904]
	TIME [epoch: 9.26 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10631787428613855		[learning rate: 0.00061019]
	Learning Rate: 0.000610192
	LOSS [training: 0.10631787428613855 | validation: 0.07123173232731439]
	TIME [epoch: 9.24 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08207188658635604		[learning rate: 0.00060832]
	Learning Rate: 0.000608322
	LOSS [training: 0.08207188658635604 | validation: 0.0651436031068395]
	TIME [epoch: 9.24 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07065115161950035		[learning rate: 0.00060646]
	Learning Rate: 0.000606457
	LOSS [training: 0.07065115161950035 | validation: 0.08876858877545238]
	TIME [epoch: 9.23 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713289372474363		[learning rate: 0.0006046]
	Learning Rate: 0.000604598
	LOSS [training: 0.0713289372474363 | validation: 0.058212790931633895]
	TIME [epoch: 9.26 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177605386934634		[learning rate: 0.00060274]
	Learning Rate: 0.000602745
	LOSS [training: 0.07177605386934634 | validation: 0.06320508853118403]
	TIME [epoch: 9.23 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06295074474660797		[learning rate: 0.0006009]
	Learning Rate: 0.000600897
	LOSS [training: 0.06295074474660797 | validation: 0.06786373185045427]
	TIME [epoch: 9.23 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07279462348133564		[learning rate: 0.00059905]
	Learning Rate: 0.000599055
	LOSS [training: 0.07279462348133564 | validation: 0.060230987519751256]
	TIME [epoch: 9.24 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794762192830353		[learning rate: 0.00059722]
	Learning Rate: 0.000597219
	LOSS [training: 0.06794762192830353 | validation: 0.06778054868255165]
	TIME [epoch: 9.25 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997628235506723		[learning rate: 0.00059539]
	Learning Rate: 0.000595388
	LOSS [training: 0.0997628235506723 | validation: 0.15926913022195494]
	TIME [epoch: 9.25 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08492292143023326		[learning rate: 0.00059356]
	Learning Rate: 0.000593563
	LOSS [training: 0.08492292143023326 | validation: 0.07263567101760149]
	TIME [epoch: 9.24 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09544505074731413		[learning rate: 0.00059174]
	Learning Rate: 0.000591743
	LOSS [training: 0.09544505074731413 | validation: 0.09270123120588722]
	TIME [epoch: 9.24 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085613194155111		[learning rate: 0.00058993]
	Learning Rate: 0.000589929
	LOSS [training: 0.085613194155111 | validation: 0.13770099119165732]
	TIME [epoch: 9.24 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08264607586665512		[learning rate: 0.00058812]
	Learning Rate: 0.000588121
	LOSS [training: 0.08264607586665512 | validation: 0.08076928894471064]
	TIME [epoch: 9.27 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06537145565869573		[learning rate: 0.00058632]
	Learning Rate: 0.000586318
	LOSS [training: 0.06537145565869573 | validation: 0.08691542612552812]
	TIME [epoch: 9.25 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09633348769229282		[learning rate: 0.00058452]
	Learning Rate: 0.000584521
	LOSS [training: 0.09633348769229282 | validation: 0.07422991443971041]
	TIME [epoch: 9.24 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0578074432001537		[learning rate: 0.00058273]
	Learning Rate: 0.000582729
	LOSS [training: 0.0578074432001537 | validation: 0.06289321894887737]
	TIME [epoch: 9.24 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05881641622655513		[learning rate: 0.00058094]
	Learning Rate: 0.000580943
	LOSS [training: 0.05881641622655513 | validation: 0.06054190120869618]
	TIME [epoch: 9.24 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06825644398875207		[learning rate: 0.00057916]
	Learning Rate: 0.000579162
	LOSS [training: 0.06825644398875207 | validation: 0.06200131814434716]
	TIME [epoch: 9.25 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328184526805843		[learning rate: 0.00057739]
	Learning Rate: 0.000577386
	LOSS [training: 0.08328184526805843 | validation: 0.11153865320283449]
	TIME [epoch: 9.23 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06948449676548188		[learning rate: 0.00057562]
	Learning Rate: 0.000575616
	LOSS [training: 0.06948449676548188 | validation: 0.1070568587317802]
	TIME [epoch: 9.23 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07014153264769218		[learning rate: 0.00057385]
	Learning Rate: 0.000573852
	LOSS [training: 0.07014153264769218 | validation: 0.07005095006461652]
	TIME [epoch: 9.24 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06817318894979665		[learning rate: 0.00057209]
	Learning Rate: 0.000572093
	LOSS [training: 0.06817318894979665 | validation: 0.064268889245105]
	TIME [epoch: 9.26 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06214765613634181		[learning rate: 0.00057034]
	Learning Rate: 0.000570339
	LOSS [training: 0.06214765613634181 | validation: 0.07607923493937144]
	TIME [epoch: 9.24 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06701784338651079		[learning rate: 0.00056859]
	Learning Rate: 0.000568591
	LOSS [training: 0.06701784338651079 | validation: 0.06010912949948789]
	TIME [epoch: 9.23 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07045737518701484		[learning rate: 0.00056685]
	Learning Rate: 0.000566848
	LOSS [training: 0.07045737518701484 | validation: 0.07066240181653519]
	TIME [epoch: 9.23 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06771937910721491		[learning rate: 0.00056511]
	Learning Rate: 0.00056511
	LOSS [training: 0.06771937910721491 | validation: 0.083702961953707]
	TIME [epoch: 9.24 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493507709949711		[learning rate: 0.00056338]
	Learning Rate: 0.000563378
	LOSS [training: 0.06493507709949711 | validation: 0.0715233894251959]
	TIME [epoch: 9.25 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06503595313039894		[learning rate: 0.00056165]
	Learning Rate: 0.000561651
	LOSS [training: 0.06503595313039894 | validation: 0.0799527590932776]
	TIME [epoch: 9.24 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09310784922836332		[learning rate: 0.00055993]
	Learning Rate: 0.000559929
	LOSS [training: 0.09310784922836332 | validation: 0.0870868157730771]
	TIME [epoch: 9.24 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08862155740208598		[learning rate: 0.00055821]
	Learning Rate: 0.000558213
	LOSS [training: 0.08862155740208598 | validation: 0.20489271248520932]
	TIME [epoch: 9.22 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10321578786643562		[learning rate: 0.0005565]
	Learning Rate: 0.000556502
	LOSS [training: 0.10321578786643562 | validation: 0.0739288100678277]
	TIME [epoch: 9.26 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0697568980274369		[learning rate: 0.0005548]
	Learning Rate: 0.000554796
	LOSS [training: 0.0697568980274369 | validation: 0.09015775772611248]
	TIME [epoch: 9.24 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07638027591925904		[learning rate: 0.0005531]
	Learning Rate: 0.000553095
	LOSS [training: 0.07638027591925904 | validation: 0.07236558470004908]
	TIME [epoch: 9.23 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0693807383075957		[learning rate: 0.0005514]
	Learning Rate: 0.0005514
	LOSS [training: 0.0693807383075957 | validation: 0.05749825006160854]
	TIME [epoch: 9.24 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889035911491928		[learning rate: 0.00054971]
	Learning Rate: 0.000549709
	LOSS [training: 0.06889035911491928 | validation: 0.07830622067940755]
	TIME [epoch: 9.24 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405860426991222		[learning rate: 0.00054802]
	Learning Rate: 0.000548024
	LOSS [training: 0.07405860426991222 | validation: 0.07740425655400725]
	TIME [epoch: 9.25 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060052616742949635		[learning rate: 0.00054634]
	Learning Rate: 0.000546345
	LOSS [training: 0.060052616742949635 | validation: 0.04755526185512576]
	TIME [epoch: 9.24 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06908965690972613		[learning rate: 0.00054467]
	Learning Rate: 0.00054467
	LOSS [training: 0.06908965690972613 | validation: 0.06469887432051223]
	TIME [epoch: 9.23 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05944294076835569		[learning rate: 0.000543]
	Learning Rate: 0.000543
	LOSS [training: 0.05944294076835569 | validation: 0.060247228910412606]
	TIME [epoch: 9.25 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08374711881054102		[learning rate: 0.00054134]
	Learning Rate: 0.000541336
	LOSS [training: 0.08374711881054102 | validation: 0.07331158171867914]
	TIME [epoch: 9.25 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811427681851327		[learning rate: 0.00053968]
	Learning Rate: 0.000539676
	LOSS [training: 0.06811427681851327 | validation: 0.04779728911885528]
	TIME [epoch: 9.25 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08433351450170806		[learning rate: 0.00053802]
	Learning Rate: 0.000538022
	LOSS [training: 0.08433351450170806 | validation: 0.0488208106667964]
	TIME [epoch: 9.24 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06268947223748246		[learning rate: 0.00053637]
	Learning Rate: 0.000536373
	LOSS [training: 0.06268947223748246 | validation: 0.059590933920189965]
	TIME [epoch: 9.24 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721939169766525		[learning rate: 0.00053473]
	Learning Rate: 0.000534728
	LOSS [training: 0.0721939169766525 | validation: 0.0559808244534296]
	TIME [epoch: 9.25 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06704543403229359		[learning rate: 0.00053309]
	Learning Rate: 0.000533089
	LOSS [training: 0.06704543403229359 | validation: 0.05827453063216343]
	TIME [epoch: 9.25 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06338394847419392		[learning rate: 0.00053146]
	Learning Rate: 0.000531455
	LOSS [training: 0.06338394847419392 | validation: 0.046577051563999314]
	TIME [epoch: 9.23 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0667055104185289		[learning rate: 0.00052983]
	Learning Rate: 0.000529826
	LOSS [training: 0.0667055104185289 | validation: 0.06550345504399252]
	TIME [epoch: 9.24 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056937625273839984		[learning rate: 0.0005282]
	Learning Rate: 0.000528202
	LOSS [training: 0.056937625273839984 | validation: 0.0539182074131256]
	TIME [epoch: 9.24 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0668211917325185		[learning rate: 0.00052658]
	Learning Rate: 0.000526583
	LOSS [training: 0.0668211917325185 | validation: 0.11203318961804973]
	TIME [epoch: 9.26 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08244648144121629		[learning rate: 0.00052497]
	Learning Rate: 0.000524969
	LOSS [training: 0.08244648144121629 | validation: 0.05752090350855685]
	TIME [epoch: 9.24 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05934955588874062		[learning rate: 0.00052336]
	Learning Rate: 0.000523359
	LOSS [training: 0.05934955588874062 | validation: 0.053938760517451265]
	TIME [epoch: 9.23 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304659423742838		[learning rate: 0.00052176]
	Learning Rate: 0.000521755
	LOSS [training: 0.06304659423742838 | validation: 0.05475686656797675]
	TIME [epoch: 9.23 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059991886660602865		[learning rate: 0.00052016]
	Learning Rate: 0.000520156
	LOSS [training: 0.059991886660602865 | validation: 0.049305347011522706]
	TIME [epoch: 9.23 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06730635442476499		[learning rate: 0.00051856]
	Learning Rate: 0.000518561
	LOSS [training: 0.06730635442476499 | validation: 0.06550437526950882]
	TIME [epoch: 9.25 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08904966145430264		[learning rate: 0.00051697]
	Learning Rate: 0.000516972
	LOSS [training: 0.08904966145430264 | validation: 0.05939681785011034]
	TIME [epoch: 9.24 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07077936908886351		[learning rate: 0.00051539]
	Learning Rate: 0.000515387
	LOSS [training: 0.07077936908886351 | validation: 0.0543806398591912]
	TIME [epoch: 9.23 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06387688535615713		[learning rate: 0.00051381]
	Learning Rate: 0.000513807
	LOSS [training: 0.06387688535615713 | validation: 0.0660439749908483]
	TIME [epoch: 9.23 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440985044305747		[learning rate: 0.00051223]
	Learning Rate: 0.000512232
	LOSS [training: 0.07440985044305747 | validation: 0.07546551674417402]
	TIME [epoch: 9.25 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720050030263676		[learning rate: 0.00051066]
	Learning Rate: 0.000510662
	LOSS [training: 0.0720050030263676 | validation: 0.0751659294457879]
	TIME [epoch: 9.24 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06798352875145189		[learning rate: 0.0005091]
	Learning Rate: 0.000509096
	LOSS [training: 0.06798352875145189 | validation: 0.05658386193939746]
	TIME [epoch: 9.23 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06758014053185787		[learning rate: 0.00050754]
	Learning Rate: 0.000507536
	LOSS [training: 0.06758014053185787 | validation: 0.06335181371086324]
	TIME [epoch: 9.24 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07167118977586825		[learning rate: 0.00050598]
	Learning Rate: 0.00050598
	LOSS [training: 0.07167118977586825 | validation: 0.04983051863973262]
	TIME [epoch: 9.25 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08205974070724867		[learning rate: 0.00050443]
	Learning Rate: 0.000504429
	LOSS [training: 0.08205974070724867 | validation: 0.08266284300361933]
	TIME [epoch: 9.24 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07539860421710627		[learning rate: 0.00050288]
	Learning Rate: 0.000502883
	LOSS [training: 0.07539860421710627 | validation: 0.06164699686785086]
	TIME [epoch: 9.24 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07142184875538311		[learning rate: 0.00050134]
	Learning Rate: 0.000501341
	LOSS [training: 0.07142184875538311 | validation: 0.056396066873204774]
	TIME [epoch: 9.24 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05946039509618275		[learning rate: 0.0004998]
	Learning Rate: 0.000499804
	LOSS [training: 0.05946039509618275 | validation: 0.04607705836230194]
	TIME [epoch: 9.23 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06248178829570465		[learning rate: 0.00049827]
	Learning Rate: 0.000498272
	LOSS [training: 0.06248178829570465 | validation: 0.04933928841746318]
	TIME [epoch: 9.25 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06398931938198203		[learning rate: 0.00049674]
	Learning Rate: 0.000496745
	LOSS [training: 0.06398931938198203 | validation: 0.052040126093269364]
	TIME [epoch: 9.23 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06877320724964192		[learning rate: 0.00049522]
	Learning Rate: 0.000495222
	LOSS [training: 0.06877320724964192 | validation: 0.0590345073073358]
	TIME [epoch: 9.24 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05720823133381334		[learning rate: 0.0004937]
	Learning Rate: 0.000493704
	LOSS [training: 0.05720823133381334 | validation: 0.050872271601962546]
	TIME [epoch: 9.24 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650498511172105		[learning rate: 0.00049219]
	Learning Rate: 0.000492191
	LOSS [training: 0.07650498511172105 | validation: 0.057315912994942354]
	TIME [epoch: 9.25 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0582153689849745		[learning rate: 0.00049068]
	Learning Rate: 0.000490682
	LOSS [training: 0.0582153689849745 | validation: 0.05505392501251395]
	TIME [epoch: 9.25 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08063692114456601		[learning rate: 0.00048918]
	Learning Rate: 0.000489178
	LOSS [training: 0.08063692114456601 | validation: 0.09836565358853037]
	TIME [epoch: 9.23 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07397130787091047		[learning rate: 0.00048768]
	Learning Rate: 0.000487678
	LOSS [training: 0.07397130787091047 | validation: 0.05790391254435527]
	TIME [epoch: 9.24 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07256267387344759		[learning rate: 0.00048618]
	Learning Rate: 0.000486183
	LOSS [training: 0.07256267387344759 | validation: 0.051303832457250946]
	TIME [epoch: 9.24 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245178573016301		[learning rate: 0.00048469]
	Learning Rate: 0.000484693
	LOSS [training: 0.06245178573016301 | validation: 0.04392911699206291]
	TIME [epoch: 9.25 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678496964964136		[learning rate: 0.00048321]
	Learning Rate: 0.000483207
	LOSS [training: 0.07678496964964136 | validation: 0.08713876891807176]
	TIME [epoch: 9.24 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08090379262283856		[learning rate: 0.00048173]
	Learning Rate: 0.000481726
	LOSS [training: 0.08090379262283856 | validation: 0.07280774610857457]
	TIME [epoch: 9.24 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08084138974789218		[learning rate: 0.00048025]
	Learning Rate: 0.000480249
	LOSS [training: 0.08084138974789218 | validation: 0.059539915535324735]
	TIME [epoch: 9.24 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05741788559882466		[learning rate: 0.00047878]
	Learning Rate: 0.000478777
	LOSS [training: 0.05741788559882466 | validation: 0.062442708937213334]
	TIME [epoch: 9.24 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08700935701240092		[learning rate: 0.00047731]
	Learning Rate: 0.000477309
	LOSS [training: 0.08700935701240092 | validation: 0.05328064098877098]
	TIME [epoch: 9.25 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06812443004682342		[learning rate: 0.00047585]
	Learning Rate: 0.000475846
	LOSS [training: 0.06812443004682342 | validation: 0.04468477787531476]
	TIME [epoch: 9.24 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060334289596021676		[learning rate: 0.00047439]
	Learning Rate: 0.000474388
	LOSS [training: 0.060334289596021676 | validation: 0.05773793899010497]
	TIME [epoch: 9.22 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07216896256318178		[learning rate: 0.00047293]
	Learning Rate: 0.000472933
	LOSS [training: 0.07216896256318178 | validation: 0.05748928310748992]
	TIME [epoch: 9.24 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06296451034024236		[learning rate: 0.00047148]
	Learning Rate: 0.000471484
	LOSS [training: 0.06296451034024236 | validation: 0.042444039684326806]
	TIME [epoch: 9.25 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08621349233488373		[learning rate: 0.00047004]
	Learning Rate: 0.000470038
	LOSS [training: 0.08621349233488373 | validation: 0.09242948994704542]
	TIME [epoch: 9.24 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09207092504960408		[learning rate: 0.0004686]
	Learning Rate: 0.000468597
	LOSS [training: 0.09207092504960408 | validation: 0.0912670054021843]
	TIME [epoch: 9.23 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10377645270556872		[learning rate: 0.00046716]
	Learning Rate: 0.000467161
	LOSS [training: 0.10377645270556872 | validation: 0.11074421680814608]
	TIME [epoch: 9.24 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07068912161719337		[learning rate: 0.00046573]
	Learning Rate: 0.000465729
	LOSS [training: 0.07068912161719337 | validation: 0.04763631206679868]
	TIME [epoch: 9.25 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053116616722295826		[learning rate: 0.0004643]
	Learning Rate: 0.000464301
	LOSS [training: 0.053116616722295826 | validation: 0.05806889417463773]
	TIME [epoch: 9.25 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05474322362637709		[learning rate: 0.00046288]
	Learning Rate: 0.000462878
	LOSS [training: 0.05474322362637709 | validation: 0.10509955600723836]
	TIME [epoch: 9.24 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09062485449294085		[learning rate: 0.00046146]
	Learning Rate: 0.000461459
	LOSS [training: 0.09062485449294085 | validation: 0.0742705560994916]
	TIME [epoch: 9.24 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07106724601370021		[learning rate: 0.00046004]
	Learning Rate: 0.000460045
	LOSS [training: 0.07106724601370021 | validation: 0.058118175954019295]
	TIME [epoch: 9.24 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07222490244464955		[learning rate: 0.00045863]
	Learning Rate: 0.000458634
	LOSS [training: 0.07222490244464955 | validation: 0.06530165019801717]
	TIME [epoch: 9.25 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057217881896734234		[learning rate: 0.00045723]
	Learning Rate: 0.000457229
	LOSS [training: 0.057217881896734234 | validation: 0.05363780120569121]
	TIME [epoch: 9.24 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051741622712657864		[learning rate: 0.00045583]
	Learning Rate: 0.000455827
	LOSS [training: 0.051741622712657864 | validation: 0.07918262622622647]
	TIME [epoch: 9.23 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205270891136673		[learning rate: 0.00045443]
	Learning Rate: 0.00045443
	LOSS [training: 0.06205270891136673 | validation: 0.05545191358140909]
	TIME [epoch: 9.24 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05948248638498016		[learning rate: 0.00045304]
	Learning Rate: 0.000453037
	LOSS [training: 0.05948248638498016 | validation: 0.07570748366858523]
	TIME [epoch: 9.24 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06818206230484357		[learning rate: 0.00045165]
	Learning Rate: 0.000451648
	LOSS [training: 0.06818206230484357 | validation: 0.10061934845262042]
	TIME [epoch: 9.26 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08536140993833406		[learning rate: 0.00045026]
	Learning Rate: 0.000450263
	LOSS [training: 0.08536140993833406 | validation: 0.06627078745053272]
	TIME [epoch: 9.23 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06327548617690683		[learning rate: 0.00044888]
	Learning Rate: 0.000448883
	LOSS [training: 0.06327548617690683 | validation: 0.05715986883987394]
	TIME [epoch: 9.24 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358854428784853		[learning rate: 0.00044751]
	Learning Rate: 0.000447507
	LOSS [training: 0.06358854428784853 | validation: 0.041594420709591934]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1512.pth
	Model improved!!!
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056642409306582965		[learning rate: 0.00044614]
	Learning Rate: 0.000446135
	LOSS [training: 0.056642409306582965 | validation: 0.04434651539886388]
	TIME [epoch: 9.26 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06088488491456158		[learning rate: 0.00044477]
	Learning Rate: 0.000444768
	LOSS [training: 0.06088488491456158 | validation: 0.03942754818299703]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1514.pth
	Model improved!!!
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08080753644836754		[learning rate: 0.0004434]
	Learning Rate: 0.000443404
	LOSS [training: 0.08080753644836754 | validation: 0.06491291109330805]
	TIME [epoch: 9.24 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656212229545277		[learning rate: 0.00044205]
	Learning Rate: 0.000442045
	LOSS [training: 0.07656212229545277 | validation: 0.052859414611575936]
	TIME [epoch: 9.24 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06923557422496351		[learning rate: 0.00044069]
	Learning Rate: 0.00044069
	LOSS [training: 0.06923557422496351 | validation: 0.05461455751215658]
	TIME [epoch: 9.25 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05880327516379704		[learning rate: 0.00043934]
	Learning Rate: 0.000439339
	LOSS [training: 0.05880327516379704 | validation: 0.04499250736097206]
	TIME [epoch: 9.25 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05900066909941533		[learning rate: 0.00043799]
	Learning Rate: 0.000437992
	LOSS [training: 0.05900066909941533 | validation: 0.06723582201549846]
	TIME [epoch: 9.24 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061091000528760854		[learning rate: 0.00043665]
	Learning Rate: 0.00043665
	LOSS [training: 0.061091000528760854 | validation: 0.056997099204356624]
	TIME [epoch: 9.25 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0622460007025466		[learning rate: 0.00043531]
	Learning Rate: 0.000435311
	LOSS [training: 0.0622460007025466 | validation: 0.07287252275999578]
	TIME [epoch: 9.24 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05893084048426587		[learning rate: 0.00043398]
	Learning Rate: 0.000433977
	LOSS [training: 0.05893084048426587 | validation: 0.07345910069983375]
	TIME [epoch: 9.26 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06051113007983115		[learning rate: 0.00043265]
	Learning Rate: 0.000432647
	LOSS [training: 0.06051113007983115 | validation: 0.04707397249671394]
	TIME [epoch: 9.24 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06201023871003829		[learning rate: 0.00043132]
	Learning Rate: 0.00043132
	LOSS [training: 0.06201023871003829 | validation: 0.06159162663573165]
	TIME [epoch: 9.24 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05875337661525574		[learning rate: 0.00043]
	Learning Rate: 0.000429998
	LOSS [training: 0.05875337661525574 | validation: 0.053130297191002554]
	TIME [epoch: 9.24 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344011219875081		[learning rate: 0.00042868]
	Learning Rate: 0.00042868
	LOSS [training: 0.06344011219875081 | validation: 0.05651768240632764]
	TIME [epoch: 9.25 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430822965670778		[learning rate: 0.00042737]
	Learning Rate: 0.000427366
	LOSS [training: 0.06430822965670778 | validation: 0.06172554430396929]
	TIME [epoch: 9.24 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06416104302961471		[learning rate: 0.00042606]
	Learning Rate: 0.000426056
	LOSS [training: 0.06416104302961471 | validation: 0.0685229423475115]
	TIME [epoch: 9.25 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07867296100076103		[learning rate: 0.00042475]
	Learning Rate: 0.00042475
	LOSS [training: 0.07867296100076103 | validation: 0.04853096905929276]
	TIME [epoch: 9.24 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058547497249632506		[learning rate: 0.00042345]
	Learning Rate: 0.000423448
	LOSS [training: 0.058547497249632506 | validation: 0.05250326693187582]
	TIME [epoch: 9.24 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06244489444818513		[learning rate: 0.00042215]
	Learning Rate: 0.00042215
	LOSS [training: 0.06244489444818513 | validation: 0.06669000760715722]
	TIME [epoch: 9.26 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07724349801694254		[learning rate: 0.00042086]
	Learning Rate: 0.000420856
	LOSS [training: 0.07724349801694254 | validation: 0.0649324004698905]
	TIME [epoch: 9.24 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06490541348653794		[learning rate: 0.00041957]
	Learning Rate: 0.000419566
	LOSS [training: 0.06490541348653794 | validation: 0.07835525216185059]
	TIME [epoch: 9.23 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900379059243086		[learning rate: 0.00041828]
	Learning Rate: 0.00041828
	LOSS [training: 0.0900379059243086 | validation: 0.07199006345859958]
	TIME [epoch: 9.23 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666482225306407		[learning rate: 0.000417]
	Learning Rate: 0.000416997
	LOSS [training: 0.06666482225306407 | validation: 0.03961673836593288]
	TIME [epoch: 9.24 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05439808518156627		[learning rate: 0.00041572]
	Learning Rate: 0.000415719
	LOSS [training: 0.05439808518156627 | validation: 0.059054220062266946]
	TIME [epoch: 9.26 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05967216622079239		[learning rate: 0.00041444]
	Learning Rate: 0.000414445
	LOSS [training: 0.05967216622079239 | validation: 0.06104458777321588]
	TIME [epoch: 9.23 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057615621664724816		[learning rate: 0.00041317]
	Learning Rate: 0.000413174
	LOSS [training: 0.057615621664724816 | validation: 0.05315924520380626]
	TIME [epoch: 9.24 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05123605839443703		[learning rate: 0.00041191]
	Learning Rate: 0.000411908
	LOSS [training: 0.05123605839443703 | validation: 0.05302247162539245]
	TIME [epoch: 9.24 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07046890631185891		[learning rate: 0.00041065]
	Learning Rate: 0.000410645
	LOSS [training: 0.07046890631185891 | validation: 0.07472204739058262]
	TIME [epoch: 9.25 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07517473131794146		[learning rate: 0.00040939]
	Learning Rate: 0.000409386
	LOSS [training: 0.07517473131794146 | validation: 0.08220296401636773]
	TIME [epoch: 9.24 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07413630933180967		[learning rate: 0.00040813]
	Learning Rate: 0.000408131
	LOSS [training: 0.07413630933180967 | validation: 0.06285877343948311]
	TIME [epoch: 9.23 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05691571579983602		[learning rate: 0.00040688]
	Learning Rate: 0.00040688
	LOSS [training: 0.05691571579983602 | validation: 0.051599631580541594]
	TIME [epoch: 9.24 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05561380115888185		[learning rate: 0.00040563]
	Learning Rate: 0.000405633
	LOSS [training: 0.05561380115888185 | validation: 0.0516432383928475]
	TIME [epoch: 9.24 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057670426185935986		[learning rate: 0.00040439]
	Learning Rate: 0.00040439
	LOSS [training: 0.057670426185935986 | validation: 0.09765949722219802]
	TIME [epoch: 9.25 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06870530772292778		[learning rate: 0.00040315]
	Learning Rate: 0.00040315
	LOSS [training: 0.06870530772292778 | validation: 0.05720235004149582]
	TIME [epoch: 9.24 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06510263167677098		[learning rate: 0.00040191]
	Learning Rate: 0.000401914
	LOSS [training: 0.06510263167677098 | validation: 0.07687330798091797]
	TIME [epoch: 9.23 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058759048699040015		[learning rate: 0.00040068]
	Learning Rate: 0.000400682
	LOSS [training: 0.058759048699040015 | validation: 0.04724004272710749]
	TIME [epoch: 9.24 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806599587041008		[learning rate: 0.00039945]
	Learning Rate: 0.000399454
	LOSS [training: 0.06806599587041008 | validation: 0.0726357353311528]
	TIME [epoch: 9.26 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811747155707183		[learning rate: 0.00039823]
	Learning Rate: 0.000398229
	LOSS [training: 0.0811747155707183 | validation: 0.0976154733596208]
	TIME [epoch: 9.24 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814050472106479		[learning rate: 0.00039701]
	Learning Rate: 0.000397009
	LOSS [training: 0.07814050472106479 | validation: 0.07978599468203318]
	TIME [epoch: 9.24 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06210011418789914		[learning rate: 0.00039579]
	Learning Rate: 0.000395792
	LOSS [training: 0.06210011418789914 | validation: 0.055570712953751766]
	TIME [epoch: 9.24 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0573648000164528		[learning rate: 0.00039458]
	Learning Rate: 0.000394578
	LOSS [training: 0.0573648000164528 | validation: 0.053800589608603164]
	TIME [epoch: 9.24 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06723215114793292		[learning rate: 0.00039337]
	Learning Rate: 0.000393369
	LOSS [training: 0.06723215114793292 | validation: 0.05459560141791604]
	TIME [epoch: 9.25 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349075637171539		[learning rate: 0.00039216]
	Learning Rate: 0.000392163
	LOSS [training: 0.06349075637171539 | validation: 0.06514831841315033]
	TIME [epoch: 9.24 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08396631799895876		[learning rate: 0.00039096]
	Learning Rate: 0.000390961
	LOSS [training: 0.08396631799895876 | validation: 0.1360072725281112]
	TIME [epoch: 9.23 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06959723081353067		[learning rate: 0.00038976]
	Learning Rate: 0.000389762
	LOSS [training: 0.06959723081353067 | validation: 0.07879208863848791]
	TIME [epoch: 9.23 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08282367611383348		[learning rate: 0.00038857]
	Learning Rate: 0.000388568
	LOSS [training: 0.08282367611383348 | validation: 0.07753655636641933]
	TIME [epoch: 9.26 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450967629507983		[learning rate: 0.00038738]
	Learning Rate: 0.000387377
	LOSS [training: 0.07450967629507983 | validation: 0.06947881445778792]
	TIME [epoch: 9.24 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06171899406991601		[learning rate: 0.00038619]
	Learning Rate: 0.000386189
	LOSS [training: 0.06171899406991601 | validation: 0.046856256991559535]
	TIME [epoch: 9.24 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05835077860397321		[learning rate: 0.00038501]
	Learning Rate: 0.000385005
	LOSS [training: 0.05835077860397321 | validation: 0.04624626469024989]
	TIME [epoch: 9.24 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059303584485501326		[learning rate: 0.00038382]
	Learning Rate: 0.000383825
	LOSS [training: 0.059303584485501326 | validation: 0.06584810984431455]
	TIME [epoch: 9.24 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06753474540827611		[learning rate: 0.00038265]
	Learning Rate: 0.000382649
	LOSS [training: 0.06753474540827611 | validation: 0.07410402478868194]
	TIME [epoch: 9.25 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05946661261854839		[learning rate: 0.00038148]
	Learning Rate: 0.000381476
	LOSS [training: 0.05946661261854839 | validation: 0.04331477840862105]
	TIME [epoch: 9.24 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05106496574383672		[learning rate: 0.00038031]
	Learning Rate: 0.000380306
	LOSS [training: 0.05106496574383672 | validation: 0.042983738194518284]
	TIME [epoch: 9.22 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053639466388323453		[learning rate: 0.00037914]
	Learning Rate: 0.00037914
	LOSS [training: 0.053639466388323453 | validation: 0.04622360217196929]
	TIME [epoch: 9.23 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052816175093252246		[learning rate: 0.00037798]
	Learning Rate: 0.000377978
	LOSS [training: 0.052816175093252246 | validation: 0.059432267711373]
	TIME [epoch: 9.26 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05609087461228104		[learning rate: 0.00037682]
	Learning Rate: 0.000376819
	LOSS [training: 0.05609087461228104 | validation: 0.07893513029495738]
	TIME [epoch: 9.24 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05877417566079428		[learning rate: 0.00037566]
	Learning Rate: 0.000375664
	LOSS [training: 0.05877417566079428 | validation: 0.07228309990793877]
	TIME [epoch: 9.23 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05911181781177214		[learning rate: 0.00037451]
	Learning Rate: 0.000374513
	LOSS [training: 0.05911181781177214 | validation: 0.05340851872692409]
	TIME [epoch: 9.24 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06032084132009834		[learning rate: 0.00037336]
	Learning Rate: 0.000373365
	LOSS [training: 0.06032084132009834 | validation: 0.09152447256865127]
	TIME [epoch: 9.25 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914988114280059		[learning rate: 0.00037222]
	Learning Rate: 0.00037222
	LOSS [training: 0.08914988114280059 | validation: 0.06404982712460117]
	TIME [epoch: 9.25 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061019607197658775		[learning rate: 0.00037108]
	Learning Rate: 0.000371079
	LOSS [training: 0.061019607197658775 | validation: 0.0639330204754415]
	TIME [epoch: 9.23 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057947280341035835		[learning rate: 0.00036994]
	Learning Rate: 0.000369942
	LOSS [training: 0.057947280341035835 | validation: 0.07906609612661153]
	TIME [epoch: 9.23 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060183595282876534		[learning rate: 0.00036881]
	Learning Rate: 0.000368808
	LOSS [training: 0.060183595282876534 | validation: 0.04810311237397291]
	TIME [epoch: 9.24 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06044677989717133		[learning rate: 0.00036768]
	Learning Rate: 0.000367677
	LOSS [training: 0.06044677989717133 | validation: 0.0571569768104482]
	TIME [epoch: 9.26 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05578000666655455		[learning rate: 0.00036655]
	Learning Rate: 0.00036655
	LOSS [training: 0.05578000666655455 | validation: 0.02928811136703524]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1577.pth
	Model improved!!!
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05827571711239092		[learning rate: 0.00036543]
	Learning Rate: 0.000365426
	LOSS [training: 0.05827571711239092 | validation: 0.058522540635421325]
	TIME [epoch: 9.22 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06052133422338938		[learning rate: 0.00036431]
	Learning Rate: 0.000364306
	LOSS [training: 0.06052133422338938 | validation: 0.053125797865519284]
	TIME [epoch: 9.21 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04898413180685071		[learning rate: 0.00036319]
	Learning Rate: 0.00036319
	LOSS [training: 0.04898413180685071 | validation: 0.04943177318495798]
	TIME [epoch: 9.23 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0522515563124372		[learning rate: 0.00036208]
	Learning Rate: 0.000362076
	LOSS [training: 0.0522515563124372 | validation: 0.06993567440890762]
	TIME [epoch: 9.24 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060632878923403744		[learning rate: 0.00036097]
	Learning Rate: 0.000360966
	LOSS [training: 0.060632878923403744 | validation: 0.05139434488438438]
	TIME [epoch: 9.21 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05564422581053655		[learning rate: 0.00035986]
	Learning Rate: 0.00035986
	LOSS [training: 0.05564422581053655 | validation: 0.050858798935347824]
	TIME [epoch: 9.22 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05781420058600987		[learning rate: 0.00035876]
	Learning Rate: 0.000358757
	LOSS [training: 0.05781420058600987 | validation: 0.050958459563604744]
	TIME [epoch: 9.22 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06506282691391721		[learning rate: 0.00035766]
	Learning Rate: 0.000357657
	LOSS [training: 0.06506282691391721 | validation: 0.07724157230998865]
	TIME [epoch: 9.24 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07253836662260145		[learning rate: 0.00035656]
	Learning Rate: 0.000356561
	LOSS [training: 0.07253836662260145 | validation: 0.0668338776795828]
	TIME [epoch: 9.2 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06762661048799581		[learning rate: 0.00035547]
	Learning Rate: 0.000355468
	LOSS [training: 0.06762661048799581 | validation: 0.07797626683079253]
	TIME [epoch: 9.21 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06899117108621952		[learning rate: 0.00035438]
	Learning Rate: 0.000354378
	LOSS [training: 0.06899117108621952 | validation: 0.050604143168951926]
	TIME [epoch: 9.21 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05239433839198628		[learning rate: 0.00035329]
	Learning Rate: 0.000353292
	LOSS [training: 0.05239433839198628 | validation: 0.05393774123355646]
	TIME [epoch: 9.23 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05354841836674583		[learning rate: 0.00035221]
	Learning Rate: 0.000352209
	LOSS [training: 0.05354841836674583 | validation: 0.05414962407611691]
	TIME [epoch: 9.22 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05847054691626709		[learning rate: 0.00035113]
	Learning Rate: 0.000351129
	LOSS [training: 0.05847054691626709 | validation: 0.03566482793453711]
	TIME [epoch: 9.22 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053886860739619194		[learning rate: 0.00035005]
	Learning Rate: 0.000350053
	LOSS [training: 0.053886860739619194 | validation: 0.03922904259547781]
	TIME [epoch: 9.2 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048347008785581354		[learning rate: 0.00034898]
	Learning Rate: 0.000348979
	LOSS [training: 0.048347008785581354 | validation: 0.046723725436542705]
	TIME [epoch: 9.21 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050404351453476395		[learning rate: 0.00034791]
	Learning Rate: 0.00034791
	LOSS [training: 0.050404351453476395 | validation: 0.05976674133098006]
	TIME [epoch: 9.23 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060551277327997276		[learning rate: 0.00034684]
	Learning Rate: 0.000346843
	LOSS [training: 0.060551277327997276 | validation: 0.07184975371036445]
	TIME [epoch: 9.22 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06241406057220202		[learning rate: 0.00034578]
	Learning Rate: 0.00034578
	LOSS [training: 0.06241406057220202 | validation: 0.05314329535372544]
	TIME [epoch: 9.21 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0591358860732907		[learning rate: 0.00034472]
	Learning Rate: 0.00034472
	LOSS [training: 0.0591358860732907 | validation: 0.06069765093131597]
	TIME [epoch: 9.22 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04903300042552379		[learning rate: 0.00034366]
	Learning Rate: 0.000343663
	LOSS [training: 0.04903300042552379 | validation: 0.059800373422428346]
	TIME [epoch: 9.23 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06290886482928831		[learning rate: 0.00034261]
	Learning Rate: 0.00034261
	LOSS [training: 0.06290886482928831 | validation: 0.0632354138610467]
	TIME [epoch: 9.23 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05082349353831469		[learning rate: 0.00034156]
	Learning Rate: 0.00034156
	LOSS [training: 0.05082349353831469 | validation: 0.05933708361299796]
	TIME [epoch: 9.23 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047379509335138195		[learning rate: 0.00034051]
	Learning Rate: 0.000340513
	LOSS [training: 0.047379509335138195 | validation: 0.04915344533482854]
	TIME [epoch: 9.23 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05271610193881462		[learning rate: 0.00033947]
	Learning Rate: 0.000339469
	LOSS [training: 0.05271610193881462 | validation: 0.05417963268927617]
	TIME [epoch: 9.23 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04428518585020462		[learning rate: 0.00033843]
	Learning Rate: 0.000338428
	LOSS [training: 0.04428518585020462 | validation: 0.05853135301594006]
	TIME [epoch: 9.23 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0527446007237393		[learning rate: 0.00033739]
	Learning Rate: 0.000337391
	LOSS [training: 0.0527446007237393 | validation: 0.05844993857565241]
	TIME [epoch: 9.22 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04720336103135245		[learning rate: 0.00033636]
	Learning Rate: 0.000336357
	LOSS [training: 0.04720336103135245 | validation: 0.0353269421221995]
	TIME [epoch: 9.22 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549598801107777		[learning rate: 0.00033533]
	Learning Rate: 0.000335326
	LOSS [training: 0.0549598801107777 | validation: 0.05437600243226598]
	TIME [epoch: 9.22 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431575914505931		[learning rate: 0.0003343]
	Learning Rate: 0.000334298
	LOSS [training: 0.06431575914505931 | validation: 0.06166162618442757]
	TIME [epoch: 9.23 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047697380235567424		[learning rate: 0.00033327]
	Learning Rate: 0.000333273
	LOSS [training: 0.047697380235567424 | validation: 0.057803515942457154]
	TIME [epoch: 9.25 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811789305202215		[learning rate: 0.00033225]
	Learning Rate: 0.000332251
	LOSS [training: 0.06811789305202215 | validation: 0.06046827607747545]
	TIME [epoch: 9.23 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07894028843414669		[learning rate: 0.00033123]
	Learning Rate: 0.000331233
	LOSS [training: 0.07894028843414669 | validation: 0.0692974576458316]
	TIME [epoch: 9.23 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015510652406667		[learning rate: 0.00033022]
	Learning Rate: 0.000330217
	LOSS [training: 0.06015510652406667 | validation: 0.05653244422317628]
	TIME [epoch: 9.23 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052556024067940056		[learning rate: 0.00032921]
	Learning Rate: 0.000329205
	LOSS [training: 0.052556024067940056 | validation: 0.05339460973451576]
	TIME [epoch: 9.24 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05456999694341935		[learning rate: 0.0003282]
	Learning Rate: 0.000328196
	LOSS [training: 0.05456999694341935 | validation: 0.05428305494615261]
	TIME [epoch: 9.22 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055711755039734946		[learning rate: 0.00032719]
	Learning Rate: 0.00032719
	LOSS [training: 0.055711755039734946 | validation: 0.062208328574000354]
	TIME [epoch: 9.23 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06661751434092224		[learning rate: 0.00032619]
	Learning Rate: 0.000326187
	LOSS [training: 0.06661751434092224 | validation: 0.042868115443561894]
	TIME [epoch: 9.23 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04845521261175011		[learning rate: 0.00032519]
	Learning Rate: 0.000325187
	LOSS [training: 0.04845521261175011 | validation: 0.05321704052710074]
	TIME [epoch: 9.24 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059127436709631165		[learning rate: 0.00032419]
	Learning Rate: 0.00032419
	LOSS [training: 0.059127436709631165 | validation: 0.04734957438638496]
	TIME [epoch: 9.24 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050816264679854804		[learning rate: 0.0003232]
	Learning Rate: 0.000323196
	LOSS [training: 0.050816264679854804 | validation: 0.04736959830176531]
	TIME [epoch: 9.22 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07076564854032484		[learning rate: 0.00032221]
	Learning Rate: 0.000322206
	LOSS [training: 0.07076564854032484 | validation: 0.0604818275556117]
	TIME [epoch: 9.23 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053119524631917034		[learning rate: 0.00032122]
	Learning Rate: 0.000321218
	LOSS [training: 0.053119524631917034 | validation: 0.04692698833063496]
	TIME [epoch: 9.23 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049769792658658274		[learning rate: 0.00032023]
	Learning Rate: 0.000320233
	LOSS [training: 0.049769792658658274 | validation: 0.054393194623166996]
	TIME [epoch: 9.26 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052250444689583044		[learning rate: 0.00031925]
	Learning Rate: 0.000319252
	LOSS [training: 0.052250444689583044 | validation: 0.04387850321275051]
	TIME [epoch: 9.23 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050645950440933465		[learning rate: 0.00031827]
	Learning Rate: 0.000318273
	LOSS [training: 0.050645950440933465 | validation: 0.044147562364133974]
	TIME [epoch: 9.23 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05628683998262225		[learning rate: 0.0003173]
	Learning Rate: 0.000317297
	LOSS [training: 0.05628683998262225 | validation: 0.049685379339916874]
	TIME [epoch: 9.23 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06397873468091252		[learning rate: 0.00031632]
	Learning Rate: 0.000316325
	LOSS [training: 0.06397873468091252 | validation: 0.052569491015453565]
	TIME [epoch: 9.24 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05477805140685912		[learning rate: 0.00031536]
	Learning Rate: 0.000315355
	LOSS [training: 0.05477805140685912 | validation: 0.03953661500096321]
	TIME [epoch: 9.24 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051293900721477104		[learning rate: 0.00031439]
	Learning Rate: 0.000314389
	LOSS [training: 0.051293900721477104 | validation: 0.03921401779759508]
	TIME [epoch: 9.22 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052329408281805004		[learning rate: 0.00031342]
	Learning Rate: 0.000313425
	LOSS [training: 0.052329408281805004 | validation: 0.05695504495954841]
	TIME [epoch: 9.22 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06708984562627918		[learning rate: 0.00031246]
	Learning Rate: 0.000312464
	LOSS [training: 0.06708984562627918 | validation: 0.049648103883854225]
	TIME [epoch: 9.23 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06302122170893158		[learning rate: 0.00031151]
	Learning Rate: 0.000311506
	LOSS [training: 0.06302122170893158 | validation: 0.05159604592495124]
	TIME [epoch: 9.25 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05255027187437498		[learning rate: 0.00031055]
	Learning Rate: 0.000310551
	LOSS [training: 0.05255027187437498 | validation: 0.055311142154709725]
	TIME [epoch: 9.22 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629101550419496		[learning rate: 0.0003096]
	Learning Rate: 0.000309599
	LOSS [training: 0.06629101550419496 | validation: 0.05705589462423751]
	TIME [epoch: 9.23 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06786904434664627		[learning rate: 0.00030865]
	Learning Rate: 0.00030865
	LOSS [training: 0.06786904434664627 | validation: 0.04890692652238984]
	TIME [epoch: 9.22 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06017263174659473		[learning rate: 0.0003077]
	Learning Rate: 0.000307704
	LOSS [training: 0.06017263174659473 | validation: 0.06002648822769535]
	TIME [epoch: 9.24 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819946656311718		[learning rate: 0.00030676]
	Learning Rate: 0.000306761
	LOSS [training: 0.05819946656311718 | validation: 0.04580430050637723]
	TIME [epoch: 9.24 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045627938667709214		[learning rate: 0.00030582]
	Learning Rate: 0.00030582
	LOSS [training: 0.045627938667709214 | validation: 0.04477408736503473]
	TIME [epoch: 9.21 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968723553414699		[learning rate: 0.00030488]
	Learning Rate: 0.000304883
	LOSS [training: 0.05968723553414699 | validation: 0.0481801133915924]
	TIME [epoch: 9.23 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04961828322707791		[learning rate: 0.00030395]
	Learning Rate: 0.000303948
	LOSS [training: 0.04961828322707791 | validation: 0.05309111546498296]
	TIME [epoch: 9.22 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05576440277419638		[learning rate: 0.00030302]
	Learning Rate: 0.000303017
	LOSS [training: 0.05576440277419638 | validation: 0.053427582534081655]
	TIME [epoch: 9.24 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05574893091838118		[learning rate: 0.00030209]
	Learning Rate: 0.000302088
	LOSS [training: 0.05574893091838118 | validation: 0.04848317427431577]
	TIME [epoch: 9.23 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043008826172560195		[learning rate: 0.00030116]
	Learning Rate: 0.000301162
	LOSS [training: 0.043008826172560195 | validation: 0.05261640232185694]
	TIME [epoch: 9.22 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681643074869521		[learning rate: 0.00030024]
	Learning Rate: 0.000300239
	LOSS [training: 0.0681643074869521 | validation: 0.05581213229595658]
	TIME [epoch: 9.22 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04925761943538776		[learning rate: 0.00029932]
	Learning Rate: 0.000299318
	LOSS [training: 0.04925761943538776 | validation: 0.05219911063255405]
	TIME [epoch: 9.23 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05559257475734256		[learning rate: 0.0002984]
	Learning Rate: 0.000298401
	LOSS [training: 0.05559257475734256 | validation: 0.057671022765128976]
	TIME [epoch: 9.23 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05209916940015134		[learning rate: 0.00029749]
	Learning Rate: 0.000297486
	LOSS [training: 0.05209916940015134 | validation: 0.05681946711637545]
	TIME [epoch: 9.22 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06279337379226996		[learning rate: 0.00029657]
	Learning Rate: 0.000296574
	LOSS [training: 0.06279337379226996 | validation: 0.056010170796755965]
	TIME [epoch: 9.21 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04786043623895971		[learning rate: 0.00029567]
	Learning Rate: 0.000295665
	LOSS [training: 0.04786043623895971 | validation: 0.05940773705035525]
	TIME [epoch: 9.19 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06325937389682038		[learning rate: 0.00029476]
	Learning Rate: 0.000294759
	LOSS [training: 0.06325937389682038 | validation: 0.06693896328120363]
	TIME [epoch: 9.24 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056950500903204596		[learning rate: 0.00029386]
	Learning Rate: 0.000293855
	LOSS [training: 0.056950500903204596 | validation: 0.05011491968319807]
	TIME [epoch: 9.23 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05402156992460203		[learning rate: 0.00029295]
	Learning Rate: 0.000292954
	LOSS [training: 0.05402156992460203 | validation: 0.042924409824896224]
	TIME [epoch: 9.22 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534474135908874		[learning rate: 0.00029206]
	Learning Rate: 0.000292056
	LOSS [training: 0.06534474135908874 | validation: 0.09495765636718223]
	TIME [epoch: 9.23 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062102912217270455		[learning rate: 0.00029116]
	Learning Rate: 0.000291161
	LOSS [training: 0.062102912217270455 | validation: 0.05192104692309071]
	TIME [epoch: 9.22 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06288416655360071		[learning rate: 0.00029027]
	Learning Rate: 0.000290269
	LOSS [training: 0.06288416655360071 | validation: 0.06841651317112157]
	TIME [epoch: 9.24 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05927075787696427		[learning rate: 0.00028938]
	Learning Rate: 0.000289379
	LOSS [training: 0.05927075787696427 | validation: 0.06220421068630612]
	TIME [epoch: 9.23 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05770867264791875		[learning rate: 0.00028849]
	Learning Rate: 0.000288492
	LOSS [training: 0.05770867264791875 | validation: 0.047195710867242696]
	TIME [epoch: 9.22 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06352011684744399		[learning rate: 0.00028761]
	Learning Rate: 0.000287607
	LOSS [training: 0.06352011684744399 | validation: 0.06309273585714215]
	TIME [epoch: 9.23 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04883107706396591		[learning rate: 0.00028673]
	Learning Rate: 0.000286726
	LOSS [training: 0.04883107706396591 | validation: 0.04255128461020939]
	TIME [epoch: 9.23 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04724154687733946		[learning rate: 0.00028585]
	Learning Rate: 0.000285847
	LOSS [training: 0.04724154687733946 | validation: 0.050904302216957485]
	TIME [epoch: 9.23 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04949539720660879		[learning rate: 0.00028497]
	Learning Rate: 0.000284971
	LOSS [training: 0.04949539720660879 | validation: 0.05354619435632521]
	TIME [epoch: 9.21 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04141645093497988		[learning rate: 0.0002841]
	Learning Rate: 0.000284097
	LOSS [training: 0.04141645093497988 | validation: 0.050458211656897664]
	TIME [epoch: 9.23 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05165605426547317		[learning rate: 0.00028323]
	Learning Rate: 0.000283226
	LOSS [training: 0.05165605426547317 | validation: 0.05316418616540383]
	TIME [epoch: 9.23 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0514153834375933		[learning rate: 0.00028236]
	Learning Rate: 0.000282358
	LOSS [training: 0.0514153834375933 | validation: 0.04547252322337055]
	TIME [epoch: 9.24 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054162163018038244		[learning rate: 0.00028149]
	Learning Rate: 0.000281492
	LOSS [training: 0.054162163018038244 | validation: 0.044220387707601644]
	TIME [epoch: 9.23 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04875483855689652		[learning rate: 0.00028063]
	Learning Rate: 0.000280629
	LOSS [training: 0.04875483855689652 | validation: 0.05135217200149651]
	TIME [epoch: 9.22 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042354610062980046		[learning rate: 0.00027977]
	Learning Rate: 0.000279769
	LOSS [training: 0.042354610062980046 | validation: 0.04413931997905868]
	TIME [epoch: 9.22 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048522669320522294		[learning rate: 0.00027891]
	Learning Rate: 0.000278912
	LOSS [training: 0.048522669320522294 | validation: 0.052102353439817936]
	TIME [epoch: 9.25 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053640752841564644		[learning rate: 0.00027806]
	Learning Rate: 0.000278057
	LOSS [training: 0.053640752841564644 | validation: 0.05120420272426224]
	TIME [epoch: 9.22 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05030540191003071		[learning rate: 0.0002772]
	Learning Rate: 0.000277204
	LOSS [training: 0.05030540191003071 | validation: 0.047156481271667085]
	TIME [epoch: 9.22 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04350644994924556		[learning rate: 0.00027635]
	Learning Rate: 0.000276355
	LOSS [training: 0.04350644994924556 | validation: 0.050806895388327694]
	TIME [epoch: 9.21 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053661026450332626		[learning rate: 0.00027551]
	Learning Rate: 0.000275507
	LOSS [training: 0.053661026450332626 | validation: 0.051109827253381465]
	TIME [epoch: 9.23 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051199561239766045		[learning rate: 0.00027466]
	Learning Rate: 0.000274663
	LOSS [training: 0.051199561239766045 | validation: 0.060156931563470975]
	TIME [epoch: 9.23 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06670235208558797		[learning rate: 0.00027382]
	Learning Rate: 0.000273821
	LOSS [training: 0.06670235208558797 | validation: 0.07709279058873926]
	TIME [epoch: 9.2 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05030026198442629		[learning rate: 0.00027298]
	Learning Rate: 0.000272982
	LOSS [training: 0.05030026198442629 | validation: 0.04376905985531611]
	TIME [epoch: 9.23 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05159817025011506		[learning rate: 0.00027214]
	Learning Rate: 0.000272145
	LOSS [training: 0.05159817025011506 | validation: 0.0608670504774868]
	TIME [epoch: 9.24 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05238142107288013		[learning rate: 0.00027131]
	Learning Rate: 0.000271311
	LOSS [training: 0.05238142107288013 | validation: 0.04295450686631522]
	TIME [epoch: 9.24 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04876812093413702		[learning rate: 0.00027048]
	Learning Rate: 0.000270479
	LOSS [training: 0.04876812093413702 | validation: 0.05138567294022453]
	TIME [epoch: 9.22 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04767101121693414		[learning rate: 0.00026965]
	Learning Rate: 0.00026965
	LOSS [training: 0.04767101121693414 | validation: 0.055123268743354235]
	TIME [epoch: 9.21 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171502575245392		[learning rate: 0.00026882]
	Learning Rate: 0.000268823
	LOSS [training: 0.05171502575245392 | validation: 0.03849487714845175]
	TIME [epoch: 9.21 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04744491495548393		[learning rate: 0.000268]
	Learning Rate: 0.000267999
	LOSS [training: 0.04744491495548393 | validation: 0.04959633146484612]
	TIME [epoch: 9.23 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936342577504823		[learning rate: 0.00026718]
	Learning Rate: 0.000267178
	LOSS [training: 0.04936342577504823 | validation: 0.05252979392838386]
	TIME [epoch: 9.23 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05266131650357634		[learning rate: 0.00026636]
	Learning Rate: 0.000266359
	LOSS [training: 0.05266131650357634 | validation: 0.04638566571004666]
	TIME [epoch: 9.22 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041055617282830595		[learning rate: 0.00026554]
	Learning Rate: 0.000265542
	LOSS [training: 0.041055617282830595 | validation: 0.04674594741332655]
	TIME [epoch: 9.22 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05147962155058118		[learning rate: 0.00026473]
	Learning Rate: 0.000264728
	LOSS [training: 0.05147962155058118 | validation: 0.04837054668806425]
	TIME [epoch: 9.22 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043131405256163886		[learning rate: 0.00026392]
	Learning Rate: 0.000263917
	LOSS [training: 0.043131405256163886 | validation: 0.06106105127186111]
	TIME [epoch: 9.23 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055400484428637264		[learning rate: 0.00026311]
	Learning Rate: 0.000263108
	LOSS [training: 0.055400484428637264 | validation: 0.050062492463848814]
	TIME [epoch: 9.23 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04766958196212907		[learning rate: 0.0002623]
	Learning Rate: 0.000262301
	LOSS [training: 0.04766958196212907 | validation: 0.04356882261066693]
	TIME [epoch: 9.22 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047432704535215295		[learning rate: 0.0002615]
	Learning Rate: 0.000261497
	LOSS [training: 0.047432704535215295 | validation: 0.0466291675616478]
	TIME [epoch: 9.23 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05153846550948131		[learning rate: 0.0002607]
	Learning Rate: 0.000260695
	LOSS [training: 0.05153846550948131 | validation: 0.04117327836259477]
	TIME [epoch: 9.24 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05372133673349534		[learning rate: 0.0002599]
	Learning Rate: 0.000259896
	LOSS [training: 0.05372133673349534 | validation: 0.05710590839682901]
	TIME [epoch: 9.24 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062224477471281306		[learning rate: 0.0002591]
	Learning Rate: 0.0002591
	LOSS [training: 0.062224477471281306 | validation: 0.05125207266803182]
	TIME [epoch: 9.22 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04775760973584402		[learning rate: 0.00025831]
	Learning Rate: 0.000258305
	LOSS [training: 0.04775760973584402 | validation: 0.0542141346350995]
	TIME [epoch: 9.23 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0519478961431354		[learning rate: 0.00025751]
	Learning Rate: 0.000257513
	LOSS [training: 0.0519478961431354 | validation: 0.05259899403293474]
	TIME [epoch: 9.23 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870964065915026		[learning rate: 0.00025672]
	Learning Rate: 0.000256724
	LOSS [training: 0.05870964065915026 | validation: 0.05277323119022892]
	TIME [epoch: 9.25 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04520782023593691		[learning rate: 0.00025594]
	Learning Rate: 0.000255937
	LOSS [training: 0.04520782023593691 | validation: 0.04034875209484531]
	TIME [epoch: 9.23 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057943574197776834		[learning rate: 0.00025515]
	Learning Rate: 0.000255153
	LOSS [training: 0.057943574197776834 | validation: 0.06422471408586497]
	TIME [epoch: 9.24 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.074690329843256		[learning rate: 0.00025437]
	Learning Rate: 0.00025437
	LOSS [training: 0.074690329843256 | validation: 0.05027826537158092]
	TIME [epoch: 9.23 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05494075705936281		[learning rate: 0.00025359]
	Learning Rate: 0.000253591
	LOSS [training: 0.05494075705936281 | validation: 0.06423395362728027]
	TIME [epoch: 9.23 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06326335711168796		[learning rate: 0.00025281]
	Learning Rate: 0.000252813
	LOSS [training: 0.06326335711168796 | validation: 0.0614205003369684]
	TIME [epoch: 9.25 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05276829367067139		[learning rate: 0.00025204]
	Learning Rate: 0.000252038
	LOSS [training: 0.05276829367067139 | validation: 0.04006903901211895]
	TIME [epoch: 9.22 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048105764744371296		[learning rate: 0.00025127]
	Learning Rate: 0.000251266
	LOSS [training: 0.048105764744371296 | validation: 0.04278750537271826]
	TIME [epoch: 9.22 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051539533490801745		[learning rate: 0.0002505]
	Learning Rate: 0.000250496
	LOSS [training: 0.051539533490801745 | validation: 0.05470288994640498]
	TIME [epoch: 9.23 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05146286524763444		[learning rate: 0.00024973]
	Learning Rate: 0.000249728
	LOSS [training: 0.05146286524763444 | validation: 0.04247662520622233]
	TIME [epoch: 9.25 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05428393303442384		[learning rate: 0.00024896]
	Learning Rate: 0.000248962
	LOSS [training: 0.05428393303442384 | validation: 0.06475903997701851]
	TIME [epoch: 9.23 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056795500314786626		[learning rate: 0.0002482]
	Learning Rate: 0.000248199
	LOSS [training: 0.056795500314786626 | validation: 0.05195244147962193]
	TIME [epoch: 9.22 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0487103853886484		[learning rate: 0.00024744]
	Learning Rate: 0.000247438
	LOSS [training: 0.0487103853886484 | validation: 0.03872937142272291]
	TIME [epoch: 9.24 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04770056627523007		[learning rate: 0.00024668]
	Learning Rate: 0.00024668
	LOSS [training: 0.04770056627523007 | validation: 0.05068676532281511]
	TIME [epoch: 9.24 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04763441222268318		[learning rate: 0.00024592]
	Learning Rate: 0.000245923
	LOSS [training: 0.04763441222268318 | validation: 0.049842175187524915]
	TIME [epoch: 9.25 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0427364220920118		[learning rate: 0.00024517]
	Learning Rate: 0.00024517
	LOSS [training: 0.0427364220920118 | validation: 0.04164233405920978]
	TIME [epoch: 9.24 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043733903940849056		[learning rate: 0.00024442]
	Learning Rate: 0.000244418
	LOSS [training: 0.043733903940849056 | validation: 0.03797345673992146]
	TIME [epoch: 9.23 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05363368967246261		[learning rate: 0.00024367]
	Learning Rate: 0.000243669
	LOSS [training: 0.05363368967246261 | validation: 0.04530075825122411]
	TIME [epoch: 9.23 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04435177871059471		[learning rate: 0.00024292]
	Learning Rate: 0.000242922
	LOSS [training: 0.04435177871059471 | validation: 0.0501032673056036]
	TIME [epoch: 9.25 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05175453961012687		[learning rate: 0.00024218]
	Learning Rate: 0.000242177
	LOSS [training: 0.05175453961012687 | validation: 0.04621088828836284]
	TIME [epoch: 9.22 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316359628003532		[learning rate: 0.00024143]
	Learning Rate: 0.000241435
	LOSS [training: 0.05316359628003532 | validation: 0.05676292040262424]
	TIME [epoch: 9.23 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049145447417905275		[learning rate: 0.00024069]
	Learning Rate: 0.000240695
	LOSS [training: 0.049145447417905275 | validation: 0.04954784071440832]
	TIME [epoch: 9.23 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04595158189795953		[learning rate: 0.00023996]
	Learning Rate: 0.000239957
	LOSS [training: 0.04595158189795953 | validation: 0.04734039739175547]
	TIME [epoch: 9.23 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05356155649322804		[learning rate: 0.00023922]
	Learning Rate: 0.000239221
	LOSS [training: 0.05356155649322804 | validation: 0.04466172913664696]
	TIME [epoch: 9.25 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051524425381065206		[learning rate: 0.00023849]
	Learning Rate: 0.000238488
	LOSS [training: 0.051524425381065206 | validation: 0.04237920202053125]
	TIME [epoch: 9.23 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04686548305276042		[learning rate: 0.00023776]
	Learning Rate: 0.000237757
	LOSS [training: 0.04686548305276042 | validation: 0.039131840045661774]
	TIME [epoch: 9.24 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05140500409644949		[learning rate: 0.00023703]
	Learning Rate: 0.000237028
	LOSS [training: 0.05140500409644949 | validation: 0.04365308465754389]
	TIME [epoch: 9.23 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04826824765439946		[learning rate: 0.0002363]
	Learning Rate: 0.000236302
	LOSS [training: 0.04826824765439946 | validation: 0.05066503435938567]
	TIME [epoch: 9.25 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045399072907619145		[learning rate: 0.00023558]
	Learning Rate: 0.000235577
	LOSS [training: 0.045399072907619145 | validation: 0.033077514598549344]
	TIME [epoch: 9.23 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04870371652751722		[learning rate: 0.00023486]
	Learning Rate: 0.000234855
	LOSS [training: 0.04870371652751722 | validation: 0.040637709315352]
	TIME [epoch: 9.22 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06029332244010481		[learning rate: 0.00023414]
	Learning Rate: 0.000234135
	LOSS [training: 0.06029332244010481 | validation: 0.05909666369568381]
	TIME [epoch: 9.23 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056045882460556175		[learning rate: 0.00023342]
	Learning Rate: 0.000233417
	LOSS [training: 0.056045882460556175 | validation: 0.05596939207512333]
	TIME [epoch: 9.22 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051613020255932986		[learning rate: 0.0002327]
	Learning Rate: 0.000232702
	LOSS [training: 0.051613020255932986 | validation: 0.040845901627135014]
	TIME [epoch: 9.24 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050003624496159124		[learning rate: 0.00023199]
	Learning Rate: 0.000231989
	LOSS [training: 0.050003624496159124 | validation: 0.049056319810229704]
	TIME [epoch: 9.23 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05484799683320155		[learning rate: 0.00023128]
	Learning Rate: 0.000231277
	LOSS [training: 0.05484799683320155 | validation: 0.04538120395705086]
	TIME [epoch: 9.23 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04863037055646952		[learning rate: 0.00023057]
	Learning Rate: 0.000230569
	LOSS [training: 0.04863037055646952 | validation: 0.049325415947284915]
	TIME [epoch: 9.22 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04627216112696104		[learning rate: 0.00022986]
	Learning Rate: 0.000229862
	LOSS [training: 0.04627216112696104 | validation: 0.03620827251766396]
	TIME [epoch: 9.25 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04346880525197199		[learning rate: 0.00022916]
	Learning Rate: 0.000229157
	LOSS [training: 0.04346880525197199 | validation: 0.031149668424219044]
	TIME [epoch: 9.23 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0523348811595251		[learning rate: 0.00022845]
	Learning Rate: 0.000228455
	LOSS [training: 0.0523348811595251 | validation: 0.043672620912282134]
	TIME [epoch: 9.24 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178949919834045		[learning rate: 0.00022775]
	Learning Rate: 0.000227754
	LOSS [training: 0.05178949919834045 | validation: 0.061606399103307084]
	TIME [epoch: 9.23 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0473938720665842		[learning rate: 0.00022706]
	Learning Rate: 0.000227056
	LOSS [training: 0.0473938720665842 | validation: 0.055126598080236344]
	TIME [epoch: 9.24 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04676950522472757		[learning rate: 0.00022636]
	Learning Rate: 0.00022636
	LOSS [training: 0.04676950522472757 | validation: 0.03092243746210361]
	TIME [epoch: 9.25 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04877522450689789		[learning rate: 0.00022567]
	Learning Rate: 0.000225666
	LOSS [training: 0.04877522450689789 | validation: 0.03785068018607156]
	TIME [epoch: 9.23 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04889136321195289		[learning rate: 0.00022497]
	Learning Rate: 0.000224974
	LOSS [training: 0.04889136321195289 | validation: 0.03241028934022293]
	TIME [epoch: 9.23 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05460087912665683		[learning rate: 0.00022428]
	Learning Rate: 0.000224285
	LOSS [training: 0.05460087912665683 | validation: 0.05700088309939024]
	TIME [epoch: 9.23 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05172115060300801		[learning rate: 0.0002236]
	Learning Rate: 0.000223597
	LOSS [training: 0.05172115060300801 | validation: 0.05023078818236097]
	TIME [epoch: 9.25 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05883833477964952		[learning rate: 0.00022291]
	Learning Rate: 0.000222912
	LOSS [training: 0.05883833477964952 | validation: 0.05019313095511989]
	TIME [epoch: 9.23 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04893430968043781		[learning rate: 0.00022223]
	Learning Rate: 0.000222229
	LOSS [training: 0.04893430968043781 | validation: 0.0445854917910955]
	TIME [epoch: 9.23 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316147734670762		[learning rate: 0.00022155]
	Learning Rate: 0.000221547
	LOSS [training: 0.05316147734670762 | validation: 0.0436696959968398]
	TIME [epoch: 9.23 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048354800677269744		[learning rate: 0.00022087]
	Learning Rate: 0.000220868
	LOSS [training: 0.048354800677269744 | validation: 0.04866180859243086]
	TIME [epoch: 9.25 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047618774688327856		[learning rate: 0.00022019]
	Learning Rate: 0.000220191
	LOSS [training: 0.047618774688327856 | validation: 0.04519459227964989]
	TIME [epoch: 9.25 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04609974644054243		[learning rate: 0.00021952]
	Learning Rate: 0.000219516
	LOSS [training: 0.04609974644054243 | validation: 0.04181423675249996]
	TIME [epoch: 9.23 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04463884522227633		[learning rate: 0.00021884]
	Learning Rate: 0.000218843
	LOSS [training: 0.04463884522227633 | validation: 0.046490072864548475]
	TIME [epoch: 9.24 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04615461378500141		[learning rate: 0.00021817]
	Learning Rate: 0.000218172
	LOSS [training: 0.04615461378500141 | validation: 0.047852158950968796]
	TIME [epoch: 9.23 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04234460179802393		[learning rate: 0.0002175]
	Learning Rate: 0.000217504
	LOSS [training: 0.04234460179802393 | validation: 0.0420429229585406]
	TIME [epoch: 9.26 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05838432872525492		[learning rate: 0.00021684]
	Learning Rate: 0.000216837
	LOSS [training: 0.05838432872525492 | validation: 0.04506538192154463]
	TIME [epoch: 9.23 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05004264903646458		[learning rate: 0.00021617]
	Learning Rate: 0.000216172
	LOSS [training: 0.05004264903646458 | validation: 0.055540941922561676]
	TIME [epoch: 9.23 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05057387416159577		[learning rate: 0.00021551]
	Learning Rate: 0.00021551
	LOSS [training: 0.05057387416159577 | validation: 0.030518384444980708]
	TIME [epoch: 9.22 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039570968504368725		[learning rate: 0.00021485]
	Learning Rate: 0.000214849
	LOSS [training: 0.039570968504368725 | validation: 0.04879255293789162]
	TIME [epoch: 9.24 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052594169297371395		[learning rate: 0.00021419]
	Learning Rate: 0.00021419
	LOSS [training: 0.052594169297371395 | validation: 0.0511740132001725]
	TIME [epoch: 9.24 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04715654613341782		[learning rate: 0.00021353]
	Learning Rate: 0.000213534
	LOSS [training: 0.04715654613341782 | validation: 0.04637958427960463]
	TIME [epoch: 9.24 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045783218412336214		[learning rate: 0.00021288]
	Learning Rate: 0.000212879
	LOSS [training: 0.045783218412336214 | validation: 0.047523254871933394]
	TIME [epoch: 9.24 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936344469609142		[learning rate: 0.00021223]
	Learning Rate: 0.000212227
	LOSS [training: 0.04936344469609142 | validation: 0.03861962508243094]
	TIME [epoch: 9.23 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05289678441866398		[learning rate: 0.00021158]
	Learning Rate: 0.000211576
	LOSS [training: 0.05289678441866398 | validation: 0.05247702146502826]
	TIME [epoch: 9.24 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04702504408123655		[learning rate: 0.00021093]
	Learning Rate: 0.000210928
	LOSS [training: 0.04702504408123655 | validation: 0.0571538202691942]
	TIME [epoch: 9.23 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04332523191027739		[learning rate: 0.00021028]
	Learning Rate: 0.000210281
	LOSS [training: 0.04332523191027739 | validation: 0.04006298824279867]
	TIME [epoch: 9.22 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04872243037594692		[learning rate: 0.00020964]
	Learning Rate: 0.000209636
	LOSS [training: 0.04872243037594692 | validation: 0.0594618688175816]
	TIME [epoch: 9.23 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059901345512946645		[learning rate: 0.00020899]
	Learning Rate: 0.000208994
	LOSS [training: 0.059901345512946645 | validation: 0.05481302652200404]
	TIME [epoch: 9.23 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05260298691983935		[learning rate: 0.00020835]
	Learning Rate: 0.000208353
	LOSS [training: 0.05260298691983935 | validation: 0.046706930040781656]
	TIME [epoch: 9.24 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0457489931096498		[learning rate: 0.00020771]
	Learning Rate: 0.000207714
	LOSS [training: 0.0457489931096498 | validation: 0.054802858574899846]
	TIME [epoch: 9.23 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050065948859253605		[learning rate: 0.00020708]
	Learning Rate: 0.000207078
	LOSS [training: 0.050065948859253605 | validation: 0.05888062636348568]
	TIME [epoch: 9.24 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04812925695828851		[learning rate: 0.00020644]
	Learning Rate: 0.000206443
	LOSS [training: 0.04812925695828851 | validation: 0.054157718381868766]
	TIME [epoch: 9.22 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042047736800372285		[learning rate: 0.00020581]
	Learning Rate: 0.00020581
	LOSS [training: 0.042047736800372285 | validation: 0.052477346263634414]
	TIME [epoch: 9.26 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04432118918676735		[learning rate: 0.00020518]
	Learning Rate: 0.000205179
	LOSS [training: 0.04432118918676735 | validation: 0.04498180319237571]
	TIME [epoch: 9.24 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04954747666724969		[learning rate: 0.00020455]
	Learning Rate: 0.00020455
	LOSS [training: 0.04954747666724969 | validation: 0.059555103098141195]
	TIME [epoch: 9.22 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051173681775909995		[learning rate: 0.00020392]
	Learning Rate: 0.000203923
	LOSS [training: 0.051173681775909995 | validation: 0.043041643398412224]
	TIME [epoch: 9.23 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04836722189392406		[learning rate: 0.0002033]
	Learning Rate: 0.000203298
	LOSS [training: 0.04836722189392406 | validation: 0.04577951623581884]
	TIME [epoch: 9.23 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04946764778961701		[learning rate: 0.00020267]
	Learning Rate: 0.000202675
	LOSS [training: 0.04946764778961701 | validation: 0.054062170320428427]
	TIME [epoch: 9.25 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04577832716008464		[learning rate: 0.00020205]
	Learning Rate: 0.000202054
	LOSS [training: 0.04577832716008464 | validation: 0.037334317470278]
	TIME [epoch: 9.22 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960271413330625		[learning rate: 0.00020143]
	Learning Rate: 0.000201434
	LOSS [training: 0.03960271413330625 | validation: 0.044248631470467974]
	TIME [epoch: 9.24 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03939891662883863		[learning rate: 0.00020082]
	Learning Rate: 0.000200817
	LOSS [training: 0.03939891662883863 | validation: 0.04119064772039993]
	TIME [epoch: 9.23 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04869083528581335		[learning rate: 0.0002002]
	Learning Rate: 0.000200201
	LOSS [training: 0.04869083528581335 | validation: 0.05531564193665732]
	TIME [epoch: 9.25 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680133914336632		[learning rate: 0.00019959]
	Learning Rate: 0.000199588
	LOSS [training: 0.04680133914336632 | validation: 0.030179440188000645]
	TIME [epoch: 9.23 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04811616085521177		[learning rate: 0.00019898]
	Learning Rate: 0.000198976
	LOSS [training: 0.04811616085521177 | validation: 0.042055341140564376]
	TIME [epoch: 9.23 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044832563606869213		[learning rate: 0.00019837]
	Learning Rate: 0.000198366
	LOSS [training: 0.044832563606869213 | validation: 0.0478522786057934]
	TIME [epoch: 9.23 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0421195517426163		[learning rate: 0.00019776]
	Learning Rate: 0.000197758
	LOSS [training: 0.0421195517426163 | validation: 0.04638285662101237]
	TIME [epoch: 9.23 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04278543205446813		[learning rate: 0.00019715]
	Learning Rate: 0.000197151
	LOSS [training: 0.04278543205446813 | validation: 0.040107923108939236]
	TIME [epoch: 9.25 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03713855060376933		[learning rate: 0.00019655]
	Learning Rate: 0.000196547
	LOSS [training: 0.03713855060376933 | validation: 0.03690327432137372]
	TIME [epoch: 9.22 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03968688478585951		[learning rate: 0.00019594]
	Learning Rate: 0.000195945
	LOSS [training: 0.03968688478585951 | validation: 0.04157765083569362]
	TIME [epoch: 9.23 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04915990012861014		[learning rate: 0.00019534]
	Learning Rate: 0.000195344
	LOSS [training: 0.04915990012861014 | validation: 0.03811194015774309]
	TIME [epoch: 9.22 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038526685782894025		[learning rate: 0.00019475]
	Learning Rate: 0.000194745
	LOSS [training: 0.038526685782894025 | validation: 0.04734029916845753]
	TIME [epoch: 9.25 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047208263777175366		[learning rate: 0.00019415]
	Learning Rate: 0.000194148
	LOSS [training: 0.047208263777175366 | validation: 0.0456933523260638]
	TIME [epoch: 9.23 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04618288408752973		[learning rate: 0.00019355]
	Learning Rate: 0.000193553
	LOSS [training: 0.04618288408752973 | validation: 0.03912536613338969]
	TIME [epoch: 9.23 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04844526043864393		[learning rate: 0.00019296]
	Learning Rate: 0.00019296
	LOSS [training: 0.04844526043864393 | validation: 0.029718857927550385]
	TIME [epoch: 9.23 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0394563213515833		[learning rate: 0.00019237]
	Learning Rate: 0.000192368
	LOSS [training: 0.0394563213515833 | validation: 0.0519820413227019]
	TIME [epoch: 9.24 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052805371350920095		[learning rate: 0.00019178]
	Learning Rate: 0.000191778
	LOSS [training: 0.052805371350920095 | validation: 0.04088835161694363]
	TIME [epoch: 9.25 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04423752704030867		[learning rate: 0.00019119]
	Learning Rate: 0.000191191
	LOSS [training: 0.04423752704030867 | validation: 0.039263453667984546]
	TIME [epoch: 9.23 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03897988900265988		[learning rate: 0.0001906]
	Learning Rate: 0.000190605
	LOSS [training: 0.03897988900265988 | validation: 0.04056966218887531]
	TIME [epoch: 9.22 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04996184126946		[learning rate: 0.00019002]
	Learning Rate: 0.00019002
	LOSS [training: 0.04996184126946 | validation: 0.042845160782589625]
	TIME [epoch: 9.21 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04599596972004884		[learning rate: 0.00018944]
	Learning Rate: 0.000189438
	LOSS [training: 0.04599596972004884 | validation: 0.03807020001837954]
	TIME [epoch: 9.24 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0554974137270132		[learning rate: 0.00018886]
	Learning Rate: 0.000188857
	LOSS [training: 0.0554974137270132 | validation: 0.04997650022976842]
	TIME [epoch: 9.21 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04538929167429795		[learning rate: 0.00018828]
	Learning Rate: 0.000188278
	LOSS [training: 0.04538929167429795 | validation: 0.05098311628020406]
	TIME [epoch: 9.23 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046834280331147275		[learning rate: 0.0001877]
	Learning Rate: 0.000187701
	LOSS [training: 0.046834280331147275 | validation: 0.045341649152245894]
	TIME [epoch: 9.23 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04411296290589687		[learning rate: 0.00018713]
	Learning Rate: 0.000187126
	LOSS [training: 0.04411296290589687 | validation: 0.05576125498242408]
	TIME [epoch: 9.24 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04734985584821008		[learning rate: 0.00018655]
	Learning Rate: 0.000186552
	LOSS [training: 0.04734985584821008 | validation: 0.03286399125048039]
	TIME [epoch: 9.23 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039561636751897125		[learning rate: 0.00018598]
	Learning Rate: 0.00018598
	LOSS [training: 0.039561636751897125 | validation: 0.05416355757133636]
	TIME [epoch: 9.21 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04945954179604868		[learning rate: 0.00018541]
	Learning Rate: 0.00018541
	LOSS [training: 0.04945954179604868 | validation: 0.056929769653717904]
	TIME [epoch: 9.22 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05629129166827074		[learning rate: 0.00018484]
	Learning Rate: 0.000184842
	LOSS [training: 0.05629129166827074 | validation: 0.0491283672817815]
	TIME [epoch: 9.23 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054854364338173534		[learning rate: 0.00018428]
	Learning Rate: 0.000184275
	LOSS [training: 0.054854364338173534 | validation: 0.03649994951844569]
	TIME [epoch: 9.24 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039083362658587514		[learning rate: 0.00018371]
	Learning Rate: 0.00018371
	LOSS [training: 0.039083362658587514 | validation: 0.04132309939354192]
	TIME [epoch: 9.23 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053084933008757926		[learning rate: 0.00018315]
	Learning Rate: 0.000183147
	LOSS [training: 0.053084933008757926 | validation: 0.06040584480607798]
	TIME [epoch: 9.23 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0579125832696981		[learning rate: 0.00018259]
	Learning Rate: 0.000182586
	LOSS [training: 0.0579125832696981 | validation: 0.040939868892456474]
	TIME [epoch: 9.23 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049070963313301394		[learning rate: 0.00018203]
	Learning Rate: 0.000182026
	LOSS [training: 0.049070963313301394 | validation: 0.0563910350808158]
	TIME [epoch: 9.23 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04476364201840926		[learning rate: 0.00018147]
	Learning Rate: 0.000181468
	LOSS [training: 0.04476364201840926 | validation: 0.046629752891906295]
	TIME [epoch: 9.24 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049165169675477904		[learning rate: 0.00018091]
	Learning Rate: 0.000180912
	LOSS [training: 0.049165169675477904 | validation: 0.06173252794611788]
	TIME [epoch: 9.23 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04599201482497632		[learning rate: 0.00018036]
	Learning Rate: 0.000180357
	LOSS [training: 0.04599201482497632 | validation: 0.04929802896632017]
	TIME [epoch: 9.23 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046390026295217324		[learning rate: 0.0001798]
	Learning Rate: 0.000179804
	LOSS [training: 0.046390026295217324 | validation: 0.03666067222687905]
	TIME [epoch: 9.22 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046361639239362894		[learning rate: 0.00017925]
	Learning Rate: 0.000179253
	LOSS [training: 0.046361639239362894 | validation: 0.04406445023696941]
	TIME [epoch: 9.25 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047793886254230214		[learning rate: 0.0001787]
	Learning Rate: 0.000178704
	LOSS [training: 0.047793886254230214 | validation: 0.05706193185115834]
	TIME [epoch: 9.21 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047125107704216206		[learning rate: 0.00017816]
	Learning Rate: 0.000178156
	LOSS [training: 0.047125107704216206 | validation: 0.03692465997196645]
	TIME [epoch: 9.23 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047338300547368276		[learning rate: 0.00017761]
	Learning Rate: 0.00017761
	LOSS [training: 0.047338300547368276 | validation: 0.04187074980463215]
	TIME [epoch: 9.22 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043260193196489084		[learning rate: 0.00017707]
	Learning Rate: 0.000177065
	LOSS [training: 0.043260193196489084 | validation: 0.04497897629202723]
	TIME [epoch: 9.23 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04205818015745184		[learning rate: 0.00017652]
	Learning Rate: 0.000176522
	LOSS [training: 0.04205818015745184 | validation: 0.04047726917176328]
	TIME [epoch: 9.24 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04005540035466154		[learning rate: 0.00017598]
	Learning Rate: 0.000175981
	LOSS [training: 0.04005540035466154 | validation: 0.03973281213065551]
	TIME [epoch: 9.22 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044675750597095464		[learning rate: 0.00017544]
	Learning Rate: 0.000175442
	LOSS [training: 0.044675750597095464 | validation: 0.04372774889684294]
	TIME [epoch: 9.22 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03930276032463356		[learning rate: 0.0001749]
	Learning Rate: 0.000174904
	LOSS [training: 0.03930276032463356 | validation: 0.047942805526594134]
	TIME [epoch: 9.2 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046604395346228344		[learning rate: 0.00017437]
	Learning Rate: 0.000174368
	LOSS [training: 0.046604395346228344 | validation: 0.037850568173991676]
	TIME [epoch: 9.23 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04054554878325425		[learning rate: 0.00017383]
	Learning Rate: 0.000173833
	LOSS [training: 0.04054554878325425 | validation: 0.04463346287174587]
	TIME [epoch: 9.21 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04923615004941358		[learning rate: 0.0001733]
	Learning Rate: 0.000173301
	LOSS [training: 0.04923615004941358 | validation: 0.04366363919514761]
	TIME [epoch: 9.21 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04469565644052532		[learning rate: 0.00017277]
	Learning Rate: 0.000172769
	LOSS [training: 0.04469565644052532 | validation: 0.042311202472667384]
	TIME [epoch: 9.21 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047387411344290184		[learning rate: 0.00017224]
	Learning Rate: 0.00017224
	LOSS [training: 0.047387411344290184 | validation: 0.040965032898682814]
	TIME [epoch: 9.22 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04570468665868378		[learning rate: 0.00017171]
	Learning Rate: 0.000171712
	LOSS [training: 0.04570468665868378 | validation: 0.061370295251909096]
	TIME [epoch: 9.24 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04594227102953503		[learning rate: 0.00017119]
	Learning Rate: 0.000171185
	LOSS [training: 0.04594227102953503 | validation: 0.04434685120108285]
	TIME [epoch: 9.22 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04108943659395686		[learning rate: 0.00017066]
	Learning Rate: 0.000170661
	LOSS [training: 0.04108943659395686 | validation: 0.04324763593179181]
	TIME [epoch: 9.22 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04873629466748282		[learning rate: 0.00017014]
	Learning Rate: 0.000170137
	LOSS [training: 0.04873629466748282 | validation: 0.045971884840533606]
	TIME [epoch: 9.22 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04110977722666988		[learning rate: 0.00016962]
	Learning Rate: 0.000169616
	LOSS [training: 0.04110977722666988 | validation: 0.04185783682659107]
	TIME [epoch: 9.22 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04521565324755372		[learning rate: 0.0001691]
	Learning Rate: 0.000169096
	LOSS [training: 0.04521565324755372 | validation: 0.04810132910413713]
	TIME [epoch: 9.21 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05076851724191247		[learning rate: 0.00016858]
	Learning Rate: 0.000168578
	LOSS [training: 0.05076851724191247 | validation: 0.05057777749211007]
	TIME [epoch: 9.21 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044710573704515554		[learning rate: 0.00016806]
	Learning Rate: 0.000168061
	LOSS [training: 0.044710573704515554 | validation: 0.036744265088532714]
	TIME [epoch: 9.2 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04736448201939718		[learning rate: 0.00016755]
	Learning Rate: 0.000167546
	LOSS [training: 0.04736448201939718 | validation: 0.05794654881701578]
	TIME [epoch: 9.22 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050236649972454084		[learning rate: 0.00016703]
	Learning Rate: 0.000167032
	LOSS [training: 0.050236649972454084 | validation: 0.041854635214028046]
	TIME [epoch: 9.23 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0449145691529007		[learning rate: 0.00016652]
	Learning Rate: 0.00016652
	LOSS [training: 0.0449145691529007 | validation: 0.05949276463067262]
	TIME [epoch: 9.21 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05060367447087771		[learning rate: 0.00016601]
	Learning Rate: 0.00016601
	LOSS [training: 0.05060367447087771 | validation: 0.0437582899774179]
	TIME [epoch: 9.2 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045694318983606506		[learning rate: 0.0001655]
	Learning Rate: 0.000165501
	LOSS [training: 0.045694318983606506 | validation: 0.04706747653200477]
	TIME [epoch: 9.21 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05044146359455749		[learning rate: 0.00016499]
	Learning Rate: 0.000164993
	LOSS [training: 0.05044146359455749 | validation: 0.04737405801732961]
	TIME [epoch: 9.23 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05225118441971958		[learning rate: 0.00016449]
	Learning Rate: 0.000164488
	LOSS [training: 0.05225118441971958 | validation: 0.04030854783275156]
	TIME [epoch: 9.22 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04399146286048505		[learning rate: 0.00016398]
	Learning Rate: 0.000163983
	LOSS [training: 0.04399146286048505 | validation: 0.03850699999077633]
	TIME [epoch: 9.21 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04600362556498196		[learning rate: 0.00016348]
	Learning Rate: 0.000163481
	LOSS [training: 0.04600362556498196 | validation: 0.0549052468519855]
	TIME [epoch: 9.2 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04588026291081568		[learning rate: 0.00016298]
	Learning Rate: 0.00016298
	LOSS [training: 0.04588026291081568 | validation: 0.048644296520517466]
	TIME [epoch: 9.21 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04756577249555301		[learning rate: 0.00016248]
	Learning Rate: 0.00016248
	LOSS [training: 0.04756577249555301 | validation: 0.03575799179039277]
	TIME [epoch: 9.23 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041400084084299266		[learning rate: 0.00016198]
	Learning Rate: 0.000161982
	LOSS [training: 0.041400084084299266 | validation: 0.05021020919667519]
	TIME [epoch: 9.22 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04685507060345054		[learning rate: 0.00016149]
	Learning Rate: 0.000161485
	LOSS [training: 0.04685507060345054 | validation: 0.04076083411087274]
	TIME [epoch: 9.23 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050725636084439765		[learning rate: 0.00016099]
	Learning Rate: 0.00016099
	LOSS [training: 0.050725636084439765 | validation: 0.05304503346692517]
	TIME [epoch: 9.21 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04970281949694244		[learning rate: 0.0001605]
	Learning Rate: 0.000160497
	LOSS [training: 0.04970281949694244 | validation: 0.05009545397379407]
	TIME [epoch: 9.23 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04164129092691876		[learning rate: 0.00016]
	Learning Rate: 0.000160005
	LOSS [training: 0.04164129092691876 | validation: 0.0575545986197712]
	TIME [epoch: 9.22 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04269492769972062		[learning rate: 0.00015951]
	Learning Rate: 0.000159514
	LOSS [training: 0.04269492769972062 | validation: 0.04009289536969802]
	TIME [epoch: 9.21 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04614914095473577		[learning rate: 0.00015903]
	Learning Rate: 0.000159025
	LOSS [training: 0.04614914095473577 | validation: 0.042214638063768704]
	TIME [epoch: 9.21 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049199886729607664		[learning rate: 0.00015854]
	Learning Rate: 0.000158538
	LOSS [training: 0.049199886729607664 | validation: 0.03924386298290957]
	TIME [epoch: 9.22 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04786910674514312		[learning rate: 0.00015805]
	Learning Rate: 0.000158052
	LOSS [training: 0.04786910674514312 | validation: 0.048108809122538065]
	TIME [epoch: 9.23 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218974385313404		[learning rate: 0.00015757]
	Learning Rate: 0.000157567
	LOSS [training: 0.04218974385313404 | validation: 0.03835411637138178]
	TIME [epoch: 9.22 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04405240823245581		[learning rate: 0.00015708]
	Learning Rate: 0.000157084
	LOSS [training: 0.04405240823245581 | validation: 0.033860479567245874]
	TIME [epoch: 9.22 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04073828914145563		[learning rate: 0.0001566]
	Learning Rate: 0.000156603
	LOSS [training: 0.04073828914145563 | validation: 0.04562035705686195]
	TIME [epoch: 9.22 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04439476694244014		[learning rate: 0.00015612]
	Learning Rate: 0.000156123
	LOSS [training: 0.04439476694244014 | validation: 0.034072110398953415]
	TIME [epoch: 9.23 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04228937785144229		[learning rate: 0.00015564]
	Learning Rate: 0.000155644
	LOSS [training: 0.04228937785144229 | validation: 0.04831603480622983]
	TIME [epoch: 9.22 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0441211376978204		[learning rate: 0.00015517]
	Learning Rate: 0.000155167
	LOSS [training: 0.0441211376978204 | validation: 0.04334198074384394]
	TIME [epoch: 9.23 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04379695869501812		[learning rate: 0.00015469]
	Learning Rate: 0.000154692
	LOSS [training: 0.04379695869501812 | validation: 0.041086647618078606]
	TIME [epoch: 9.21 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05094775986312039		[learning rate: 0.00015422]
	Learning Rate: 0.000154217
	LOSS [training: 0.05094775986312039 | validation: 0.051472023687629306]
	TIME [epoch: 9.22 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04336276118864751		[learning rate: 0.00015374]
	Learning Rate: 0.000153745
	LOSS [training: 0.04336276118864751 | validation: 0.029385725915777428]
	TIME [epoch: 9.24 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045013206487980614		[learning rate: 0.00015327]
	Learning Rate: 0.000153273
	LOSS [training: 0.045013206487980614 | validation: 0.04482808209265373]
	TIME [epoch: 9.22 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04664786971994415		[learning rate: 0.0001528]
	Learning Rate: 0.000152803
	LOSS [training: 0.04664786971994415 | validation: 0.05097696633049767]
	TIME [epoch: 9.23 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047847727384406666		[learning rate: 0.00015234]
	Learning Rate: 0.000152335
	LOSS [training: 0.047847727384406666 | validation: 0.051481913764675855]
	TIME [epoch: 9.22 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04456736911893022		[learning rate: 0.00015187]
	Learning Rate: 0.000151868
	LOSS [training: 0.04456736911893022 | validation: 0.046306145386926706]
	TIME [epoch: 9.25 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045402546035866596		[learning rate: 0.0001514]
	Learning Rate: 0.000151403
	LOSS [training: 0.045402546035866596 | validation: 0.049026270917204205]
	TIME [epoch: 9.21 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04544935328048025		[learning rate: 0.00015094]
	Learning Rate: 0.000150938
	LOSS [training: 0.04544935328048025 | validation: 0.04996820519093489]
	TIME [epoch: 9.22 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044457713606254085		[learning rate: 0.00015048]
	Learning Rate: 0.000150476
	LOSS [training: 0.044457713606254085 | validation: 0.040141659297967036]
	TIME [epoch: 9.23 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03959264257965748		[learning rate: 0.00015001]
	Learning Rate: 0.000150015
	LOSS [training: 0.03959264257965748 | validation: 0.038925759972934675]
	TIME [epoch: 9.24 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04113177680497226		[learning rate: 0.00014955]
	Learning Rate: 0.000149555
	LOSS [training: 0.04113177680497226 | validation: 0.05149412446353037]
	TIME [epoch: 9.24 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020551135853948		[learning rate: 0.0001491]
	Learning Rate: 0.000149096
	LOSS [training: 0.05020551135853948 | validation: 0.04586116944776662]
	TIME [epoch: 9.22 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046054263289817696		[learning rate: 0.00014864]
	Learning Rate: 0.000148639
	LOSS [training: 0.046054263289817696 | validation: 0.04144059183282506]
	TIME [epoch: 9.22 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04534658106707692		[learning rate: 0.00014818]
	Learning Rate: 0.000148184
	LOSS [training: 0.04534658106707692 | validation: 0.03621659487900157]
	TIME [epoch: 9.22 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339660186875479		[learning rate: 0.00014773]
	Learning Rate: 0.000147729
	LOSS [training: 0.04339660186875479 | validation: 0.050240250147151666]
	TIME [epoch: 9.23 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0452153862020407		[learning rate: 0.00014728]
	Learning Rate: 0.000147276
	LOSS [training: 0.0452153862020407 | validation: 0.034963429770347755]
	TIME [epoch: 9.23 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043164945446032		[learning rate: 0.00014682]
	Learning Rate: 0.000146825
	LOSS [training: 0.043164945446032 | validation: 0.042398858837635146]
	TIME [epoch: 9.23 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04353762019109961		[learning rate: 0.00014637]
	Learning Rate: 0.000146375
	LOSS [training: 0.04353762019109961 | validation: 0.05172547832016404]
	TIME [epoch: 9.2 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04310110467527388		[learning rate: 0.00014593]
	Learning Rate: 0.000145926
	LOSS [training: 0.04310110467527388 | validation: 0.04035273521834503]
	TIME [epoch: 9.24 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043398060392836633		[learning rate: 0.00014548]
	Learning Rate: 0.000145479
	LOSS [training: 0.043398060392836633 | validation: 0.03922155818880462]
	TIME [epoch: 9.23 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039615079766370784		[learning rate: 0.00014503]
	Learning Rate: 0.000145033
	LOSS [training: 0.039615079766370784 | validation: 0.044409496518193876]
	TIME [epoch: 9.22 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03989774866614644		[learning rate: 0.00014459]
	Learning Rate: 0.000144588
	LOSS [training: 0.03989774866614644 | validation: 0.05479447294755056]
	TIME [epoch: 9.24 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04514185157746618		[learning rate: 0.00014415]
	Learning Rate: 0.000144145
	LOSS [training: 0.04514185157746618 | validation: 0.05304928846647011]
	TIME [epoch: 9.23 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04641756418124901		[learning rate: 0.0001437]
	Learning Rate: 0.000143703
	LOSS [training: 0.04641756418124901 | validation: 0.03296813450019008]
	TIME [epoch: 9.24 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04242475351818549		[learning rate: 0.00014326]
	Learning Rate: 0.000143263
	LOSS [training: 0.04242475351818549 | validation: 0.04457581826923571]
	TIME [epoch: 9.22 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0467161589710472		[learning rate: 0.00014282]
	Learning Rate: 0.000142824
	LOSS [training: 0.0467161589710472 | validation: 0.05049585747049802]
	TIME [epoch: 9.22 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0470616288051803		[learning rate: 0.00014239]
	Learning Rate: 0.000142386
	LOSS [training: 0.0470616288051803 | validation: 0.03990050301798595]
	TIME [epoch: 9.22 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04752373855900261		[learning rate: 0.00014195]
	Learning Rate: 0.000141949
	LOSS [training: 0.04752373855900261 | validation: 0.04260335588594061]
	TIME [epoch: 9.22 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04480110912447784		[learning rate: 0.00014151]
	Learning Rate: 0.000141514
	LOSS [training: 0.04480110912447784 | validation: 0.037793800088058986]
	TIME [epoch: 9.23 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05076531033742408		[learning rate: 0.00014108]
	Learning Rate: 0.00014108
	LOSS [training: 0.05076531033742408 | validation: 0.03815785218694738]
	TIME [epoch: 9.21 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047685439326851695		[learning rate: 0.00014065]
	Learning Rate: 0.000140648
	LOSS [training: 0.047685439326851695 | validation: 0.041645210665836624]
	TIME [epoch: 9.23 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04563638078866057		[learning rate: 0.00014022]
	Learning Rate: 0.000140217
	LOSS [training: 0.04563638078866057 | validation: 0.04021258914000224]
	TIME [epoch: 9.23 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04815173247830771		[learning rate: 0.00013979]
	Learning Rate: 0.000139787
	LOSS [training: 0.04815173247830771 | validation: 0.045608801200550664]
	TIME [epoch: 9.22 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05193313088782788		[learning rate: 0.00013936]
	Learning Rate: 0.000139358
	LOSS [training: 0.05193313088782788 | validation: 0.03748098957165544]
	TIME [epoch: 9.21 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04658373209721719		[learning rate: 0.00013893]
	Learning Rate: 0.000138931
	LOSS [training: 0.04658373209721719 | validation: 0.033940129999359234]
	TIME [epoch: 9.2 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04023323201470774		[learning rate: 0.00013851]
	Learning Rate: 0.000138505
	LOSS [training: 0.04023323201470774 | validation: 0.046277186790118705]
	TIME [epoch: 9.22 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042185303239104036		[learning rate: 0.00013808]
	Learning Rate: 0.000138081
	LOSS [training: 0.042185303239104036 | validation: 0.0384565603659479]
	TIME [epoch: 9.22 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218032974833908		[learning rate: 0.00013766]
	Learning Rate: 0.000137658
	LOSS [training: 0.04218032974833908 | validation: 0.046414742150181224]
	TIME [epoch: 9.23 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044224331803754666		[learning rate: 0.00013724]
	Learning Rate: 0.000137236
	LOSS [training: 0.044224331803754666 | validation: 0.04317475142259635]
	TIME [epoch: 9.23 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043460692387693914		[learning rate: 0.00013681]
	Learning Rate: 0.000136815
	LOSS [training: 0.043460692387693914 | validation: 0.036182325267695874]
	TIME [epoch: 9.22 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048505763873848244		[learning rate: 0.0001364]
	Learning Rate: 0.000136395
	LOSS [training: 0.048505763873848244 | validation: 0.034790177231909185]
	TIME [epoch: 9.22 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04239917962149644		[learning rate: 0.00013598]
	Learning Rate: 0.000135977
	LOSS [training: 0.04239917962149644 | validation: 0.03499522633085124]
	TIME [epoch: 9.22 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042706038243971164		[learning rate: 0.00013556]
	Learning Rate: 0.000135561
	LOSS [training: 0.042706038243971164 | validation: 0.03459334460928701]
	TIME [epoch: 9.22 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044886894484098334		[learning rate: 0.00013515]
	Learning Rate: 0.000135145
	LOSS [training: 0.044886894484098334 | validation: 0.04570169582505792]
	TIME [epoch: 9.2 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282480283646441		[learning rate: 0.00013473]
	Learning Rate: 0.000134731
	LOSS [training: 0.04282480283646441 | validation: 0.04358114447184668]
	TIME [epoch: 9.21 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04413320859633747		[learning rate: 0.00013432]
	Learning Rate: 0.000134318
	LOSS [training: 0.04413320859633747 | validation: 0.04260978895946077]
	TIME [epoch: 9.19 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05208479896457173		[learning rate: 0.00013391]
	Learning Rate: 0.000133906
	LOSS [training: 0.05208479896457173 | validation: 0.03558802498696067]
	TIME [epoch: 9.22 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044064246193944695		[learning rate: 0.0001335]
	Learning Rate: 0.000133496
	LOSS [training: 0.044064246193944695 | validation: 0.03761611687470762]
	TIME [epoch: 9.18 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043141591603911775		[learning rate: 0.00013309]
	Learning Rate: 0.000133086
	LOSS [training: 0.043141591603911775 | validation: 0.04961572538518812]
	TIME [epoch: 9.2 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04811262577140265		[learning rate: 0.00013268]
	Learning Rate: 0.000132678
	LOSS [training: 0.04811262577140265 | validation: 0.055061782541454565]
	TIME [epoch: 9.19 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05216407169216517		[learning rate: 0.00013227]
	Learning Rate: 0.000132272
	LOSS [training: 0.05216407169216517 | validation: 0.04136679747323553]
	TIME [epoch: 9.21 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047413654737556155		[learning rate: 0.00013187]
	Learning Rate: 0.000131866
	LOSS [training: 0.047413654737556155 | validation: 0.037081783345634944]
	TIME [epoch: 9.19 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044456665519846075		[learning rate: 0.00013146]
	Learning Rate: 0.000131462
	LOSS [training: 0.044456665519846075 | validation: 0.043562547011637566]
	TIME [epoch: 9.18 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0411874129169567		[learning rate: 0.00013106]
	Learning Rate: 0.000131059
	LOSS [training: 0.0411874129169567 | validation: 0.04084085843833787]
	TIME [epoch: 9.19 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04398145794284645		[learning rate: 0.00013066]
	Learning Rate: 0.000130657
	LOSS [training: 0.04398145794284645 | validation: 0.03686617735341975]
	TIME [epoch: 9.21 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042838786730064464		[learning rate: 0.00013026]
	Learning Rate: 0.000130257
	LOSS [training: 0.042838786730064464 | validation: 0.026247247950707556]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1914.pth
	Model improved!!!
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041997395109480584		[learning rate: 0.00012986]
	Learning Rate: 0.000129857
	LOSS [training: 0.041997395109480584 | validation: 0.03087263490358417]
	TIME [epoch: 9.22 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04376599392895582		[learning rate: 0.00012946]
	Learning Rate: 0.000129459
	LOSS [training: 0.04376599392895582 | validation: 0.04106951612588494]
	TIME [epoch: 9.23 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04147770223915816		[learning rate: 0.00012906]
	Learning Rate: 0.000129062
	LOSS [training: 0.04147770223915816 | validation: 0.04666329740993772]
	TIME [epoch: 9.23 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03858573217317649		[learning rate: 0.00012867]
	Learning Rate: 0.000128667
	LOSS [training: 0.03858573217317649 | validation: 0.037420025990122834]
	TIME [epoch: 9.23 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045011019588759034		[learning rate: 0.00012827]
	Learning Rate: 0.000128272
	LOSS [training: 0.045011019588759034 | validation: 0.04414135063958576]
	TIME [epoch: 9.21 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04620042915969144		[learning rate: 0.00012788]
	Learning Rate: 0.000127879
	LOSS [training: 0.04620042915969144 | validation: 0.04094267928900874]
	TIME [epoch: 9.22 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04532051516703306		[learning rate: 0.00012749]
	Learning Rate: 0.000127487
	LOSS [training: 0.04532051516703306 | validation: 0.04085064317568898]
	TIME [epoch: 9.2 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04884536218540177		[learning rate: 0.0001271]
	Learning Rate: 0.000127096
	LOSS [training: 0.04884536218540177 | validation: 0.04929616253805573]
	TIME [epoch: 9.21 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04793264361579504		[learning rate: 0.00012671]
	Learning Rate: 0.000126707
	LOSS [training: 0.04793264361579504 | validation: 0.055985877337941886]
	TIME [epoch: 9.21 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057704066419986585		[learning rate: 0.00012632]
	Learning Rate: 0.000126318
	LOSS [training: 0.057704066419986585 | validation: 0.05330636120592763]
	TIME [epoch: 9.21 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05509986527141144		[learning rate: 0.00012593]
	Learning Rate: 0.000125931
	LOSS [training: 0.05509986527141144 | validation: 0.06803824521702978]
	TIME [epoch: 9.22 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04580626921007103		[learning rate: 0.00012555]
	Learning Rate: 0.000125545
	LOSS [training: 0.04580626921007103 | validation: 0.033836318963140655]
	TIME [epoch: 9.2 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04464191706626804		[learning rate: 0.00012516]
	Learning Rate: 0.00012516
	LOSS [training: 0.04464191706626804 | validation: 0.0468425933471225]
	TIME [epoch: 9.2 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049258190820788916		[learning rate: 0.00012478]
	Learning Rate: 0.000124777
	LOSS [training: 0.049258190820788916 | validation: 0.04257967900592078]
	TIME [epoch: 9.2 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05321307207189455		[learning rate: 0.00012439]
	Learning Rate: 0.000124394
	LOSS [training: 0.05321307207189455 | validation: 0.03324654743954719]
	TIME [epoch: 9.18 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043103186070810096		[learning rate: 0.00012401]
	Learning Rate: 0.000124013
	LOSS [training: 0.043103186070810096 | validation: 0.042434851341266996]
	TIME [epoch: 9.2 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041372080751259394		[learning rate: 0.00012363]
	Learning Rate: 0.000123633
	LOSS [training: 0.041372080751259394 | validation: 0.03135371754384866]
	TIME [epoch: 9.2 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04154880497750914		[learning rate: 0.00012325]
	Learning Rate: 0.000123254
	LOSS [training: 0.04154880497750914 | validation: 0.03373599485274545]
	TIME [epoch: 9.2 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0402141438838744		[learning rate: 0.00012288]
	Learning Rate: 0.000122876
	LOSS [training: 0.0402141438838744 | validation: 0.040483697771323435]
	TIME [epoch: 9.2 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03681832641184687		[learning rate: 0.0001225]
	Learning Rate: 0.000122499
	LOSS [training: 0.03681832641184687 | validation: 0.03531457850192239]
	TIME [epoch: 9.19 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04255161801582799		[learning rate: 0.00012212]
	Learning Rate: 0.000122124
	LOSS [training: 0.04255161801582799 | validation: 0.04569531147326812]
	TIME [epoch: 9.21 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04296217381823335		[learning rate: 0.00012175]
	Learning Rate: 0.000121749
	LOSS [training: 0.04296217381823335 | validation: 0.03993612859233737]
	TIME [epoch: 9.21 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04526617826607379		[learning rate: 0.00012138]
	Learning Rate: 0.000121376
	LOSS [training: 0.04526617826607379 | validation: 0.043385367012769]
	TIME [epoch: 9.22 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04287761186705211		[learning rate: 0.000121]
	Learning Rate: 0.000121004
	LOSS [training: 0.04287761186705211 | validation: 0.03812704456582132]
	TIME [epoch: 9.21 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03828679560716354		[learning rate: 0.00012063]
	Learning Rate: 0.000120633
	LOSS [training: 0.03828679560716354 | validation: 0.03048811644233874]
	TIME [epoch: 9.22 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0437495046851232		[learning rate: 0.00012026]
	Learning Rate: 0.000120263
	LOSS [training: 0.0437495046851232 | validation: 0.03934665127947491]
	TIME [epoch: 9.22 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04702879675848683		[learning rate: 0.00011989]
	Learning Rate: 0.000119895
	LOSS [training: 0.04702879675848683 | validation: 0.039138714827803414]
	TIME [epoch: 9.22 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04003590451238723		[learning rate: 0.00011953]
	Learning Rate: 0.000119527
	LOSS [training: 0.04003590451238723 | validation: 0.03270123545464424]
	TIME [epoch: 9.21 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04730931109424661		[learning rate: 0.00011916]
	Learning Rate: 0.000119161
	LOSS [training: 0.04730931109424661 | validation: 0.04572851849807057]
	TIME [epoch: 9.21 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04957804504748418		[learning rate: 0.0001188]
	Learning Rate: 0.000118795
	LOSS [training: 0.04957804504748418 | validation: 0.06116667142213954]
	TIME [epoch: 9.21 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05327974462652878		[learning rate: 0.00011843]
	Learning Rate: 0.000118431
	LOSS [training: 0.05327974462652878 | validation: 0.04227044064629357]
	TIME [epoch: 9.24 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04497615625579692		[learning rate: 0.00011807]
	Learning Rate: 0.000118068
	LOSS [training: 0.04497615625579692 | validation: 0.031464269849054136]
	TIME [epoch: 9.2 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04869186523650656		[learning rate: 0.00011771]
	Learning Rate: 0.000117706
	LOSS [training: 0.04869186523650656 | validation: 0.03937172619462813]
	TIME [epoch: 9.21 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0456757050825602		[learning rate: 0.00011735]
	Learning Rate: 0.000117346
	LOSS [training: 0.0456757050825602 | validation: 0.027331109948945095]
	TIME [epoch: 9.22 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03818779671896494		[learning rate: 0.00011699]
	Learning Rate: 0.000116986
	LOSS [training: 0.03818779671896494 | validation: 0.04056740427219473]
	TIME [epoch: 9.21 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0441448589284473		[learning rate: 0.00011663]
	Learning Rate: 0.000116627
	LOSS [training: 0.0441448589284473 | validation: 0.039322100524915415]
	TIME [epoch: 9.23 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043402071823662805		[learning rate: 0.00011627]
	Learning Rate: 0.00011627
	LOSS [training: 0.043402071823662805 | validation: 0.034120055149403236]
	TIME [epoch: 9.2 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0409692090582768		[learning rate: 0.00011591]
	Learning Rate: 0.000115913
	LOSS [training: 0.0409692090582768 | validation: 0.03746634225830604]
	TIME [epoch: 9.21 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03973775522533901		[learning rate: 0.00011556]
	Learning Rate: 0.000115558
	LOSS [training: 0.03973775522533901 | validation: 0.0409702988181201]
	TIME [epoch: 9.2 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041768855560386633		[learning rate: 0.0001152]
	Learning Rate: 0.000115204
	LOSS [training: 0.041768855560386633 | validation: 0.04349130336336437]
	TIME [epoch: 9.22 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04038045393798943		[learning rate: 0.00011485]
	Learning Rate: 0.000114851
	LOSS [training: 0.04038045393798943 | validation: 0.0409469189252778]
	TIME [epoch: 9.23 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039232309243862826		[learning rate: 0.0001145]
	Learning Rate: 0.000114499
	LOSS [training: 0.039232309243862826 | validation: 0.04651108647339954]
	TIME [epoch: 9.2 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047695257302792476		[learning rate: 0.00011415]
	Learning Rate: 0.000114148
	LOSS [training: 0.047695257302792476 | validation: 0.03753954215398249]
	TIME [epoch: 9.21 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04618991895356793		[learning rate: 0.0001138]
	Learning Rate: 0.000113798
	LOSS [training: 0.04618991895356793 | validation: 0.03786634122020991]
	TIME [epoch: 9.2 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04596464268657262		[learning rate: 0.00011345]
	Learning Rate: 0.000113449
	LOSS [training: 0.04596464268657262 | validation: 0.04680746385037754]
	TIME [epoch: 9.22 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043315784496259044		[learning rate: 0.0001131]
	Learning Rate: 0.000113101
	LOSS [training: 0.043315784496259044 | validation: 0.047515676673546184]
	TIME [epoch: 9.19 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673827638791114		[learning rate: 0.00011275]
	Learning Rate: 0.000112754
	LOSS [training: 0.04673827638791114 | validation: 0.047524596113291004]
	TIME [epoch: 9.19 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04133810643909218		[learning rate: 0.00011241]
	Learning Rate: 0.000112409
	LOSS [training: 0.04133810643909218 | validation: 0.043538039582113594]
	TIME [epoch: 9.2 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04103762811466744		[learning rate: 0.00011206]
	Learning Rate: 0.000112064
	LOSS [training: 0.04103762811466744 | validation: 0.0397578999125007]
	TIME [epoch: 9.22 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040778089339384205		[learning rate: 0.00011172]
	Learning Rate: 0.000111721
	LOSS [training: 0.040778089339384205 | validation: 0.0380676443938571]
	TIME [epoch: 9.22 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04244820614268217		[learning rate: 0.00011138]
	Learning Rate: 0.000111378
	LOSS [training: 0.04244820614268217 | validation: 0.04502931811380946]
	TIME [epoch: 9.2 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0406220642839419		[learning rate: 0.00011104]
	Learning Rate: 0.000111037
	LOSS [training: 0.0406220642839419 | validation: 0.0313310328168807]
	TIME [epoch: 9.21 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04117094533365141		[learning rate: 0.0001107]
	Learning Rate: 0.000110696
	LOSS [training: 0.04117094533365141 | validation: 0.046318944364802196]
	TIME [epoch: 9.21 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04697724973347757		[learning rate: 0.00011036]
	Learning Rate: 0.000110357
	LOSS [training: 0.04697724973347757 | validation: 0.03911206241642654]
	TIME [epoch: 9.22 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03967169189262508		[learning rate: 0.00011002]
	Learning Rate: 0.000110019
	LOSS [training: 0.03967169189262508 | validation: 0.03476916845440444]
	TIME [epoch: 9.2 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04048561007677445		[learning rate: 0.00010968]
	Learning Rate: 0.000109681
	LOSS [training: 0.04048561007677445 | validation: 0.02541667551535776]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1970.pth
	Model improved!!!
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03902498505174442		[learning rate: 0.00010935]
	Learning Rate: 0.000109345
	LOSS [training: 0.03902498505174442 | validation: 0.03772833383513177]
	TIME [epoch: 9.19 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03552754514187571		[learning rate: 0.00010901]
	Learning Rate: 0.00010901
	LOSS [training: 0.03552754514187571 | validation: 0.0349182005350306]
	TIME [epoch: 9.22 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04049385087081825		[learning rate: 0.00010868]
	Learning Rate: 0.000108676
	LOSS [training: 0.04049385087081825 | validation: 0.032151643460488946]
	TIME [epoch: 9.2 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040117000708219296		[learning rate: 0.00010834]
	Learning Rate: 0.000108343
	LOSS [training: 0.040117000708219296 | validation: 0.030265604612807806]
	TIME [epoch: 9.2 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04228235264825606		[learning rate: 0.00010801]
	Learning Rate: 0.000108011
	LOSS [training: 0.04228235264825606 | validation: 0.03746217358393281]
	TIME [epoch: 9.2 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0477245858136186		[learning rate: 0.00010768]
	Learning Rate: 0.00010768
	LOSS [training: 0.0477245858136186 | validation: 0.03719212539222889]
	TIME [epoch: 9.2 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03849967011835409		[learning rate: 0.00010735]
	Learning Rate: 0.000107349
	LOSS [training: 0.03849967011835409 | validation: 0.04062176617346182]
	TIME [epoch: 9.22 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03382095797538802		[learning rate: 0.00010702]
	Learning Rate: 0.00010702
	LOSS [training: 0.03382095797538802 | validation: 0.0399812830194806]
	TIME [epoch: 9.21 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05141231506380056		[learning rate: 0.00010669]
	Learning Rate: 0.000106692
	LOSS [training: 0.05141231506380056 | validation: 0.05168715085637103]
	TIME [epoch: 9.19 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047084471309021006		[learning rate: 0.00010637]
	Learning Rate: 0.000106365
	LOSS [training: 0.047084471309021006 | validation: 0.03109912430365086]
	TIME [epoch: 9.2 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037826276674281546		[learning rate: 0.00010604]
	Learning Rate: 0.000106039
	LOSS [training: 0.037826276674281546 | validation: 0.040356370441666414]
	TIME [epoch: 9.21 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03993749016699675		[learning rate: 0.00010571]
	Learning Rate: 0.000105714
	LOSS [training: 0.03993749016699675 | validation: 0.0366490202042761]
	TIME [epoch: 9.2 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035212611904799164		[learning rate: 0.00010539]
	Learning Rate: 0.00010539
	LOSS [training: 0.035212611904799164 | validation: 0.02669316669140249]
	TIME [epoch: 9.2 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04078823473170148		[learning rate: 0.00010507]
	Learning Rate: 0.000105067
	LOSS [training: 0.04078823473170148 | validation: 0.042089532467294834]
	TIME [epoch: 9.2 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03825444816223878		[learning rate: 0.00010474]
	Learning Rate: 0.000104745
	LOSS [training: 0.03825444816223878 | validation: 0.03249331574409027]
	TIME [epoch: 9.2 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03988899770875698		[learning rate: 0.00010442]
	Learning Rate: 0.000104424
	LOSS [training: 0.03988899770875698 | validation: 0.051526878012353186]
	TIME [epoch: 9.22 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04116145827320685		[learning rate: 0.0001041]
	Learning Rate: 0.000104104
	LOSS [training: 0.04116145827320685 | validation: 0.037396444543676036]
	TIME [epoch: 9.19 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039057315887163		[learning rate: 0.00010378]
	Learning Rate: 0.000103785
	LOSS [training: 0.039057315887163 | validation: 0.025280679186079173]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240217_012649/states/model_tr_study3_1988.pth
	Model improved!!!
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03939810992112292		[learning rate: 0.00010347]
	Learning Rate: 0.000103467
	LOSS [training: 0.03939810992112292 | validation: 0.03769804845558283]
	TIME [epoch: 9.2 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03755873465442672		[learning rate: 0.00010315]
	Learning Rate: 0.000103149
	LOSS [training: 0.03755873465442672 | validation: 0.048108624513677985]
	TIME [epoch: 9.23 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040526112819512614		[learning rate: 0.00010283]
	Learning Rate: 0.000102833
	LOSS [training: 0.040526112819512614 | validation: 0.0431483064921107]
	TIME [epoch: 9.2 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03914344573603901		[learning rate: 0.00010252]
	Learning Rate: 0.000102518
	LOSS [training: 0.03914344573603901 | validation: 0.048770185691145544]
	TIME [epoch: 9.21 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0422183982428206		[learning rate: 0.0001022]
	Learning Rate: 0.000102204
	LOSS [training: 0.0422183982428206 | validation: 0.04768852358164915]
	TIME [epoch: 9.2 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04381624141278723		[learning rate: 0.00010189]
	Learning Rate: 0.00010189
	LOSS [training: 0.04381624141278723 | validation: 0.03923858689283291]
	TIME [epoch: 9.21 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044252362265324		[learning rate: 0.00010158]
	Learning Rate: 0.000101578
	LOSS [training: 0.044252362265324 | validation: 0.04168490598453614]
	TIME [epoch: 9.22 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04206631097448357		[learning rate: 0.00010127]
	Learning Rate: 0.000101267
	LOSS [training: 0.04206631097448357 | validation: 0.05329963171130418]
	TIME [epoch: 9.21 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04134841799252876		[learning rate: 0.00010096]
	Learning Rate: 0.000100956
	LOSS [training: 0.04134841799252876 | validation: 0.03841739656592016]
	TIME [epoch: 9.2 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03712278041330064		[learning rate: 0.00010065]
	Learning Rate: 0.000100647
	LOSS [training: 0.03712278041330064 | validation: 0.044686633358054895]
	TIME [epoch: 9.2 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038413570853321914		[learning rate: 0.00010034]
	Learning Rate: 0.000100338
	LOSS [training: 0.038413570853321914 | validation: 0.0376228061340362]
	TIME [epoch: 9.22 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041681806350055466		[learning rate: 0.00010003]
	Learning Rate: 0.000100031
	LOSS [training: 0.041681806350055466 | validation: 0.049005829058454686]
	TIME [epoch: 9.2 sec]
Finished training in 18566.073 seconds.
