Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2143365582

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.37823343553713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.37823343553713 | validation: 11.496511325460315]
	TIME [epoch: 98.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.51117060905911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.51117060905911 | validation: 10.215263387939451]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.18378952174855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.18378952174855 | validation: 12.954778386465973]
	TIME [epoch: 11.6 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.652989133219481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.652989133219481 | validation: 9.002024740054171]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.503933714246038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.503933714246038 | validation: 7.901125195615126]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.045913171055222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.045913171055222 | validation: 7.839360242842907]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.754399710971978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.754399710971978 | validation: 8.31718527842487]
	TIME [epoch: 11.5 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.100837434080939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.100837434080939 | validation: 7.74571253116129]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.858087840503626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.858087840503626 | validation: 8.218980029278637]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.946047675370313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.946047675370313 | validation: 7.581989840665552]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.778315772889116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.778315772889116 | validation: 8.646704766163795]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.962968455920477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.962968455920477 | validation: 7.646478957135941]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.414040252116292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.414040252116292 | validation: 7.637326706504423]
	TIME [epoch: 11.6 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.419549624412008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.419549624412008 | validation: 7.123548734025556]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.221910085789535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.221910085789535 | validation: 9.076052839677143]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.55269216223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.55269216223 | validation: 9.794995829369222]
	TIME [epoch: 11.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.478453986772505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.478453986772505 | validation: 6.744083589727262]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.262764814578187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.262764814578187 | validation: 6.128537568403233]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.716799364852566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.716799364852566 | validation: 9.652273915704408]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.441014991266304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.441014991266304 | validation: 8.766498298403933]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.049988859509078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.049988859509078 | validation: 9.639798777404026]
	TIME [epoch: 11.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.890119186008999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.890119186008999 | validation: 6.096277178828063]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96348729332675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96348729332675 | validation: 6.028975162227844]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.858010230136937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.858010230136937 | validation: 5.622995520456915]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744836181617428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.744836181617428 | validation: 5.567489881094766]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.693780423701264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.693780423701264 | validation: 5.91722863376619]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.779297588835125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.779297588835125 | validation: 6.6184386015999825]
	TIME [epoch: 11.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.623639152275548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.623639152275548 | validation: 5.670060071967007]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736305277893013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.736305277893013 | validation: 5.990372399917017]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.788243687982797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.788243687982797 | validation: 5.4882166583009]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.634409168822429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.634409168822429 | validation: 5.55824476502071]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.620308606431831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.620308606431831 | validation: 5.678625956972913]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.562136343340441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.562136343340441 | validation: 5.746564951473119]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.939905531980005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.939905531980005 | validation: 5.7326595015131865]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711038248168737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.711038248168737 | validation: 5.746745251281989]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.802041083539201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.802041083539201 | validation: 5.340940072968704]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.545556775532791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.545556775532791 | validation: 6.185392885900789]
	TIME [epoch: 11.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.231636656842368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.231636656842368 | validation: 6.863580194014174]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89968102364496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.89968102364496 | validation: 5.585721912747724]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.556201377860285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.556201377860285 | validation: 5.163074223326241]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.385615779856613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.385615779856613 | validation: 5.271983171776431]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3483819710086244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3483819710086244 | validation: 6.247245527621289]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.138834092606645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.138834092606645 | validation: 5.633647155199814]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.287188677747322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.287188677747322 | validation: 5.299515991691349]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.686700007872591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.686700007872591 | validation: 6.834451368706092]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.196908385138887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.196908385138887 | validation: 5.439920154974514]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.395787138398326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.395787138398326 | validation: 5.250915592236707]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.153149467084488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.153149467084488 | validation: 4.864757962018512]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.036159623714164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.036159623714164 | validation: 4.975351896702493]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.968940286172932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.968940286172932 | validation: 4.835683553242382]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.743123164020568		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.743123164020568 | validation: 4.63228471410859]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.997873169875131		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.997873169875131 | validation: 4.597899233734032]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572674576615		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.572674576615 | validation: 6.193782675689952]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3032345794711135		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.3032345794711135 | validation: 4.4469593180266065]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479474119445135		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.479474119445135 | validation: 4.360150086645604]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496511767321827		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.496511767321827 | validation: 3.805983319837446]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.116147870647059		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.116147870647059 | validation: 3.6563476762074085]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9365753441571503		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.9365753441571503 | validation: 3.690681385205015]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7492653040269452		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.7492653040269452 | validation: 4.046128369386301]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5467637053077863		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.5467637053077863 | validation: 4.536328366382316]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.774116439296834		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.774116439296834 | validation: 3.526871481230108]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7005108437448886		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.7005108437448886 | validation: 3.07970342193113]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.099995973621458		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.099995973621458 | validation: 4.198851629528613]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5175051131674944		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.5175051131674944 | validation: 2.9727000180283447]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8930787146195573		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.8930787146195573 | validation: 3.186864401003268]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9403169575293675		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.9403169575293675 | validation: 2.5124983420393012]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.646912520632937		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.646912520632937 | validation: 2.5125643444645114]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.486109098187697		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.486109098187697 | validation: 6.133475747852756]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.071007308699767		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 7.071007308699767 | validation: 6.96471277362919]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.86072824494674		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.86072824494674 | validation: 3.709515930918991]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.056343739662426		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.056343739662426 | validation: 3.96673172035987]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0925723442364115		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.0925723442364115 | validation: 2.3604517783084185]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.659461453833207		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.659461453833207 | validation: 3.1616687121758265]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8499940210447905		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.8499940210447905 | validation: 2.578404793068325]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420614412161185		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.420614412161185 | validation: 3.044581448234485]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3856639641112976		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.3856639641112976 | validation: 2.7399916888520988]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6749034255407547		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.6749034255407547 | validation: 2.3640089498004424]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395805517362886		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.395805517362886 | validation: 2.682693756067777]
	TIME [epoch: 11.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6960836198197535		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.6960836198197535 | validation: 2.7552245948994982]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32796067815379		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.32796067815379 | validation: 2.0526743461620818]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1638586034705223		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.1638586034705223 | validation: 1.647596692370404]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3855755469374307		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.3855755469374307 | validation: 2.853213535669254]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7907419019646804		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.7907419019646804 | validation: 2.1859265109492556]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452136964223064		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.452136964223064 | validation: 2.3772672315608183]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251367029791087		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.251367029791087 | validation: 2.226539680609728]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094357237725918		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.094357237725918 | validation: 1.7770471733678894]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0169417550624025		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.0169417550624025 | validation: 4.794619004133438]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4395141640566322		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.4395141640566322 | validation: 1.9740675171050037]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0331443669707565		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.0331443669707565 | validation: 1.975672210143024]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4608087098637093		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.4608087098637093 | validation: 1.7750462846021777]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.516610415879568		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.516610415879568 | validation: 1.9618156201931292]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.035084534202887		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.035084534202887 | validation: 5.161894247902599]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.100925808285596		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.100925808285596 | validation: 1.8629235686658525]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9921333300037176		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.9921333300037176 | validation: 1.7250481201907695]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12618903948491		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.12618903948491 | validation: 1.9480301331329293]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1765625780897477		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.1765625780897477 | validation: 1.8923691535609948]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9264414392329796		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.9264414392329796 | validation: 2.1751955743338045]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9242801120233406		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9242801120233406 | validation: 4.671663632950687]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2052447583331		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.2052447583331 | validation: 2.259711132245941]
	TIME [epoch: 11.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6102184719299686		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.6102184719299686 | validation: 2.158719693318775]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.038406738632155		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.038406738632155 | validation: 1.8821602963359028]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2560020076883935		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.2560020076883935 | validation: 1.7683846243671806]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5065024527731072		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.5065024527731072 | validation: 2.9325910665175865]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396446758857319		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.396446758857319 | validation: 1.6645687400367803]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8726316137467904		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.8726316137467904 | validation: 2.575082862345606]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318073510703551		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.318073510703551 | validation: 1.8626798696605713]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347285325315922		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.347285325315922 | validation: 2.0557549013464134]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4153403340244877		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.4153403340244877 | validation: 1.9820648589912995]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2301128489634867		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.2301128489634867 | validation: 3.119653199924449]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.502160970775482		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.502160970775482 | validation: 2.25254287663355]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2224516131260206		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.2224516131260206 | validation: 2.573126882808795]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3404222648409743		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.3404222648409743 | validation: 2.352435282403774]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.192568326766413		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.192568326766413 | validation: 1.8624361861966576]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.168659391173052		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.168659391173052 | validation: 1.757305888489758]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.007600632285879		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.007600632285879 | validation: 3.010261739030771]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1744408064910266		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.1744408064910266 | validation: 3.577530522018419]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5711119376901777		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.5711119376901777 | validation: 2.6480898716383012]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0889467034913065		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.0889467034913065 | validation: 1.7030496506469626]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118280462125458		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.118280462125458 | validation: 2.0971876635917868]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.429815934098565		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.429815934098565 | validation: 1.9585226963487576]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9973672315038877		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.9973672315038877 | validation: 1.6232683141189137]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9020535825162155		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.9020535825162155 | validation: 1.556331723788509]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.820328148107302		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.820328148107302 | validation: 1.594390158250398]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1313784040844217		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.1313784040844217 | validation: 1.9300540983964516]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8266569946780309		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.8266569946780309 | validation: 2.6295697382019423]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.186464065425428		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.186464065425428 | validation: 1.4752683039484242]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6072229626126164		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.6072229626126164 | validation: 1.5828351861013346]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.98880226477314		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.98880226477314 | validation: 1.6631777913392933]
	TIME [epoch: 11.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556933719539447		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.0556933719539447 | validation: 1.6200316369117667]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0569357517454407		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.0569357517454407 | validation: 1.7407979258984028]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346710839602554		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.346710839602554 | validation: 1.8533882098050891]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9602652182502056		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.9602652182502056 | validation: 1.7917077539147048]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8092139959491398		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.8092139959491398 | validation: 1.464129841640081]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1939716693542053		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.1939716693542053 | validation: 2.21676164609165]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071114050494965		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.071114050494965 | validation: 1.6514214450360771]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6282851113229235		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.6282851113229235 | validation: 1.5843872686041514]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3524772212761706		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.3524772212761706 | validation: 2.3979725638526155]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.023864173741237		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.023864173741237 | validation: 2.191825605270627]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1632467011947982		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.1632467011947982 | validation: 1.369395728826722]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0503173132034656		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.0503173132034656 | validation: 1.48342707936279]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8626610914372623		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.8626610914372623 | validation: 1.9589078725537872]
	TIME [epoch: 11.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070412054068263		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.070412054068263 | validation: 1.7555307449892177]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1907324444404557		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.1907324444404557 | validation: 2.1001295679570045]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.203173736454092		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.203173736454092 | validation: 2.0849026405649216]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5707949031761395		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.5707949031761395 | validation: 1.860777029450424]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4202479657252867		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.4202479657252867 | validation: 1.603576363999313]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7638153048890075		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.7638153048890075 | validation: 1.9176649384644417]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.817276430942161		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.817276430942161 | validation: 1.4806181226490145]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6835392841754544		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6835392841754544 | validation: 4.710515497755046]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3273799932891		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.3273799932891 | validation: 1.7079175894387129]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243482469755633		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.243482469755633 | validation: 2.1865620866947912]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0537702310191897		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.0537702310191897 | validation: 1.618031777191042]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300250299745135		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.7300250299745135 | validation: 1.6351258994683588]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7066102650861243		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.7066102650861243 | validation: 1.6581320496464604]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.799044906117789		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.799044906117789 | validation: 1.794803128295747]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8779073517090183		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.8779073517090183 | validation: 1.8792292609150558]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9246993190414399		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.9246993190414399 | validation: 1.3118068339133446]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8208861946537875		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.8208861946537875 | validation: 1.684867525478589]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.646602868511978		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.646602868511978 | validation: 1.771726476649257]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8965529667977001		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.8965529667977001 | validation: 1.2773484648897888]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5271888149739774		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.5271888149739774 | validation: 2.0773625784917904]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9912141758845938		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.9912141758845938 | validation: 1.5527301932675224]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8580408600543676		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.8580408600543676 | validation: 1.2817521884320857]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7578572408777746		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.7578572408777746 | validation: 1.743155597277395]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9479274863411744		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.9479274863411744 | validation: 1.5796046332032483]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.816540145591088		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.816540145591088 | validation: 1.4301256040852517]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.586849718315473		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.586849718315473 | validation: 1.856730099542379]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7518393932605523		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.7518393932605523 | validation: 1.2682050940008227]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.706117339347009		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.706117339347009 | validation: 1.2814812282792698]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7850008579261316		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.7850008579261316 | validation: 1.638388439260354]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7422299877343805		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.7422299877343805 | validation: 1.8801150352968368]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6930591119881253		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.6930591119881253 | validation: 1.386060101507553]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4234581121286116		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.4234581121286116 | validation: 1.4151987522556664]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4392460450760538		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.4392460450760538 | validation: 1.391605350731871]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3761435085209344		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.3761435085209344 | validation: 1.6461155405180814]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5159418583135982		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.5159418583135982 | validation: 1.3491817351019901]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6274178320611004		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.6274178320611004 | validation: 1.2923085888771866]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5891436460581116		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.5891436460581116 | validation: 1.496609882359757]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5041867543039065		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.5041867543039065 | validation: 1.56832107370992]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4188601809385992		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.4188601809385992 | validation: 1.6836649796559437]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5882168810314836		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.5882168810314836 | validation: 1.1959070362633797]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562023293425934		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.562023293425934 | validation: 1.478273881504826]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6081318492333825		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.6081318492333825 | validation: 2.613840603612557]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.642713013090658		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.642713013090658 | validation: 2.50347921233445]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3630249702627637		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.3630249702627637 | validation: 2.1356323559225916]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9609621365994931		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.9609621365994931 | validation: 1.5429084222957903]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5383987152254843		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.5383987152254843 | validation: 1.38808062558098]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.637097960899358		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.637097960899358 | validation: 1.4844104809521923]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5573257778612044		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.5573257778612044 | validation: 1.5033094891340142]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4284785004471285		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.4284785004471285 | validation: 1.569314883291156]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5842453947838606		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.5842453947838606 | validation: 1.2636823458162554]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6270202627938049		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.6270202627938049 | validation: 1.380288313158836]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4224015793580245		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.4224015793580245 | validation: 2.367451144362759]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5938938466400752		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.5938938466400752 | validation: 1.3479489994429281]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4033719337189672		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.4033719337189672 | validation: 1.1143956733313047]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.401581073276227		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.401581073276227 | validation: 1.203805468085085]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335526937591759		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.2335526937591759 | validation: 1.0701738885529732]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8295056331829365		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.8295056331829365 | validation: 1.1797326410686393]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.692661304543639		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.692661304543639 | validation: 1.2637476732733073]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2976932000885857		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.2976932000885857 | validation: 1.5894694691944824]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.503583114291934		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.503583114291934 | validation: 1.2398929156345995]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692447518153453		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.4692447518153453 | validation: 1.532836881685711]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.840592544660261		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.840592544660261 | validation: 1.3269316886128342]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.606444378160237		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.606444378160237 | validation: 1.1691631432752834]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4866169872044335		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.4866169872044335 | validation: 1.5819845992127648]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4461879112706144		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.4461879112706144 | validation: 1.9054838382788866]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4106528795080866		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.4106528795080866 | validation: 1.292312008081243]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.550474371153043		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.550474371153043 | validation: 1.307654882946207]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5549219420659228		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.5549219420659228 | validation: 1.774261719832515]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5279584492891876		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.5279584492891876 | validation: 1.590186769928929]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6264801729564176		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6264801729564176 | validation: 1.280489529708421]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.312655245837713		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.312655245837713 | validation: 1.2117418095474595]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.508483945694577		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.508483945694577 | validation: 1.1549506342842648]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.422097247862506		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.422097247862506 | validation: 1.9935685399746916]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6979224508436739		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.6979224508436739 | validation: 1.7378552260237015]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7250015621845878		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.7250015621845878 | validation: 1.4785059859520424]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0338675951641125		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.0338675951641125 | validation: 1.950564634296704]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8768631104226916		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.8768631104226916 | validation: 1.5245336366810012]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.756287940429018		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.756287940429018 | validation: 1.6540196455298333]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9917025502456494		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.9917025502456494 | validation: 1.335265018777535]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5328632354635325		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.5328632354635325 | validation: 1.2720329277606937]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1101387622243792		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.1101387622243792 | validation: 2.8696642487399777]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6552605329732057		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.6552605329732057 | validation: 2.3981060418914315]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4479238055129136		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.4479238055129136 | validation: 2.174547507058428]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30786394884447		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.30786394884447 | validation: 1.413728704648214]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4075868330598094		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.4075868330598094 | validation: 1.3681399605282514]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0730503358929555		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.0730503358929555 | validation: 2.7429660946905297]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6169200037730223		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.6169200037730223 | validation: 2.1962052214775527]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9764396962302444		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.9764396962302444 | validation: 1.3550609012630912]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.555021799879865		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.555021799879865 | validation: 1.270054197009269]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.408961479512969		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.408961479512969 | validation: 1.4084283995350806]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265871736204759		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.7265871736204759 | validation: 1.6366365310732403]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8117241443072376		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.8117241443072376 | validation: 1.4444412572523875]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8053739601864995		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.8053739601864995 | validation: 1.4202507037899603]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4779833406589589		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.4779833406589589 | validation: 1.4223783601084248]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396146116619648		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.396146116619648 | validation: 1.7356621458140706]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7918086519881777		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.7918086519881777 | validation: 1.3324888338126832]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4601628920292333		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.4601628920292333 | validation: 2.132127966352472]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.762319879706067		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.762319879706067 | validation: 1.4691160827485954]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3908447346559116		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.3908447346559116 | validation: 1.966400495411561]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.192872889197566		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.192872889197566 | validation: 2.2323812115364223]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442561936252474		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.2442561936252474 | validation: 2.059188202206627]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9330238700298157		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.9330238700298157 | validation: 2.3210876160641765]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8409174752716053		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.8409174752716053 | validation: 1.5068272811930428]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.506265016829742		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.506265016829742 | validation: 1.1791579444177112]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728785816464214		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.728785816464214 | validation: 1.4102331201277272]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4963463996648685		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.4963463996648685 | validation: 1.4203713580359496]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3595039947573264		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.3595039947573264 | validation: 1.2334876760062463]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276309329324067		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.276309329324067 | validation: 1.4243542484404537]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5857980904695346		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.5857980904695346 | validation: 1.6253897802303134]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4416441554522714		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.4416441554522714 | validation: 1.338934884349922]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4946894761796816		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.4946894761796816 | validation: 1.6548449092941007]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4519714909115577		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.4519714909115577 | validation: 1.395789228592014]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3141893042703032		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.3141893042703032 | validation: 2.5143760234534778]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.806042216744863		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.806042216744863 | validation: 1.4231932952413766]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.379571416363226		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.379571416363226 | validation: 1.164004518277482]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6073745082883109		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.6073745082883109 | validation: 1.2544318195120783]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356151741617232		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.356151741617232 | validation: 1.215446348066234]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4062995278066883		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.4062995278066883 | validation: 1.3370605956982489]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5067737183660272		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.5067737183660272 | validation: 3.019348587716296]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467186726071255		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.467186726071255 | validation: 1.7386893691182377]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3078634984049766		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.3078634984049766 | validation: 1.162663297553239]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.31774191804678		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.31774191804678 | validation: 1.3918588993907555]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5024102941208533		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.5024102941208533 | validation: 1.361644921567264]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.163752552748168		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.163752552748168 | validation: 1.4204910705086276]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3927083887794522		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.3927083887794522 | validation: 1.5363018199615603]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5106899301236005		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.5106899301236005 | validation: 1.8730226462588178]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6637119532124005		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.6637119532124005 | validation: 3.6051754516537877]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3582909782716723		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.3582909782716723 | validation: 1.2334146240253885]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2778350599326453		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.2778350599326453 | validation: 1.4468668212281381]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3340860476929013		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.3340860476929013 | validation: 1.1829083796284352]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6709613575914743		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.6709613575914743 | validation: 1.143600180907323]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4068051271984914		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.4068051271984914 | validation: 1.0867471148260877]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6099651414914216		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.6099651414914216 | validation: 1.5584072178642856]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5501212920721508		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.5501212920721508 | validation: 1.9198185820239428]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8506938325401647		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.8506938325401647 | validation: 1.1517277037512461]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3427808211234824		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.3427808211234824 | validation: 1.3306038355970151]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7705607843058597		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.7705607843058597 | validation: 2.2055150170676714]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6509551131833087		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.6509551131833087 | validation: 1.8210666458079043]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5638848738379363		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.5638848738379363 | validation: 1.2308241778248643]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2393433686831918		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.2393433686831918 | validation: 1.893446015371981]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7444251503319375		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.7444251503319375 | validation: 2.347491264322022]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4577942320607487		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.4577942320607487 | validation: 2.3657106820353118]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123811119355433		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.123811119355433 | validation: 2.43940546595508]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0127865715742046		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.0127865715742046 | validation: 1.708109677033619]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4451028830034698		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.4451028830034698 | validation: 1.6228637222593916]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3666835198888978		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.3666835198888978 | validation: 1.4004500691100574]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2916610481175872		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.2916610481175872 | validation: 1.6279753697191268]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5140836855949718		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.5140836855949718 | validation: 1.1567039422909695]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2607877864435435		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.2607877864435435 | validation: 1.1440449985633756]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2825765369302282		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.2825765369302282 | validation: 1.2732392359452518]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.332460167138633		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.332460167138633 | validation: 1.3302304358603607]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.444946253125749		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.444946253125749 | validation: 1.3411599279601871]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5534043471189865		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.5534043471189865 | validation: 1.5893296869933244]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.404350495137876		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.404350495137876 | validation: 1.300594243425232]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.358692673611529		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.358692673611529 | validation: 1.5559542404750824]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8423002238760653		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.8423002238760653 | validation: 3.6787153476547867]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4487300273037738		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.4487300273037738 | validation: 1.233558775583151]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284841129967277		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.2284841129967277 | validation: 1.1878513454389767]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4622220605333531		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.4622220605333531 | validation: 1.36294526919795]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2700156740521316		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.2700156740521316 | validation: 1.7779519856053105]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.515384289218627		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.515384289218627 | validation: 1.316613019564082]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080443510649737		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.2080443510649737 | validation: 1.4374132373353106]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4952034206449472		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.4952034206449472 | validation: 1.0507284721532901]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2185075276182906		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.2185075276182906 | validation: 1.389072320481502]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2941744322081021		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.2941744322081021 | validation: 1.1906653364955095]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.476010123660683		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.476010123660683 | validation: 1.8430282351648657]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8257884360152234		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.8257884360152234 | validation: 2.860837054370618]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8499562921864876		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.8499562921864876 | validation: 2.2957840913608907]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2085546626469266		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.2085546626469266 | validation: 1.4948947247644382]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4001720216072826		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.4001720216072826 | validation: 1.084991602314873]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3439078074325992		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.3439078074325992 | validation: 1.173208459290907]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3660775526438462		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.3660775526438462 | validation: 1.0300750839116044]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1806157177724805		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.1806157177724805 | validation: 1.4856365138194507]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4614668906227286		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.4614668906227286 | validation: 1.6055738892458926]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.336532518921604		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.336532518921604 | validation: 1.1284024966348551]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2999800099276826		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.2999800099276826 | validation: 1.5377347785637108]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339176617717531		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.339176617717531 | validation: 1.1572697753089132]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2572041099799802		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.2572041099799802 | validation: 1.251470214822286]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339264431253382		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.339264431253382 | validation: 1.1662667675158287]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4007750816346565		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.4007750816346565 | validation: 1.3534994519848096]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2120750113354717		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.2120750113354717 | validation: 1.1884835640342417]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5148920702323805		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.5148920702323805 | validation: 1.325559871808519]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5538252933330279		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.5538252933330279 | validation: 1.1027559962255145]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.189432205300681		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.189432205300681 | validation: 1.0312235532055558]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2010398414990548		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.2010398414990548 | validation: 2.32080703407616]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.676782769604704		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.676782769604704 | validation: 1.032706995584038]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3357182321845742		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.3357182321845742 | validation: 1.0935202021941248]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8298646523226174		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.8298646523226174 | validation: 1.1671882707035643]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1504522609265893		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.1504522609265893 | validation: 1.462991572845497]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7260504513204906		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.7260504513204906 | validation: 3.4367160090486557]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.758142431051217		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.758142431051217 | validation: 2.186917831604556]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1813178337115042		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.1813178337115042 | validation: 2.708990939255798]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2577318386301704		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.2577318386301704 | validation: 1.94687377104989]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2700711323047638		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.2700711323047638 | validation: 2.151528811633451]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6705018208475801		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.6705018208475801 | validation: 1.3171225373074855]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3976402065952125		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.3976402065952125 | validation: 1.3063626183098813]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714353375095161		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.1714353375095161 | validation: 2.102570506487755]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8897455351570005		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.8897455351570005 | validation: 1.4240560342184603]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4525306265510376		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.4525306265510376 | validation: 1.138976318403126]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2581758340053655		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.2581758340053655 | validation: 1.1902142495512167]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3154486745498162		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.3154486745498162 | validation: 1.4022944003909903]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1911559815016046		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.1911559815016046 | validation: 2.6990733245420473]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.742098508675501		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.742098508675501 | validation: 2.5103986469753927]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1526792454706754		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.1526792454706754 | validation: 2.3627476409077515]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9918006582918588		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.9918006582918588 | validation: 1.2324858778964378]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3772685885649003		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.3772685885649003 | validation: 1.2436816578844012]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3573101389181284		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.3573101389181284 | validation: 1.85807565709634]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7358787634033261		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.7358787634033261 | validation: 1.4247151569060617]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3446156947525147		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.3446156947525147 | validation: 1.3365438734883532]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3594909896626792		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.3594909896626792 | validation: 1.6470378424563727]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9172624483652156		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.9172624483652156 | validation: 1.3741197396886364]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2172902593325576		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.2172902593325576 | validation: 1.1108821312321056]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.424077525404957		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.424077525404957 | validation: 1.0636346436044273]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2517102386483177		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.2517102386483177 | validation: 1.4802299523042928]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2236346212186042		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.2236346212186042 | validation: 1.3435727205148675]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240089914517671		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.240089914517671 | validation: 1.1395220224776228]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688618947979284		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.2688618947979284 | validation: 1.9109699385940155]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4931033471365507		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.4931033471365507 | validation: 1.2087420364272388]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3654773061300651		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.3654773061300651 | validation: 1.6065347904953102]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5454584378123308		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.5454584378123308 | validation: 1.5058699004385825]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2917184460151625		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.2917184460151625 | validation: 1.1173482521928448]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3315768930107368		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.3315768930107368 | validation: 1.2059305280029657]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2210916471623618		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.2210916471623618 | validation: 1.3883443274072644]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3447044004601525		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.3447044004601525 | validation: 1.1133867977505487]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.508305824244499		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.508305824244499 | validation: 2.5215270193871415]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887787776862119		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.887787776862119 | validation: 2.760391270059606]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6537493640182195		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.6537493640182195 | validation: 2.157350661371372]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1331195228797575		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.1331195228797575 | validation: 1.950977736273371]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4822096222548877		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.4822096222548877 | validation: 1.358272556916565]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2820875325055843		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.2820875325055843 | validation: 1.287726171837645]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2503804501457363		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.2503804501457363 | validation: 1.2179060953822898]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2341515478409917		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.2341515478409917 | validation: 1.3085057289950317]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3794084135354419		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.3794084135354419 | validation: 1.2831764018641036]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2633908679748709		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.2633908679748709 | validation: 1.4129365769081301]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2932325380324143		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.2932325380324143 | validation: 1.2892503177032058]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3619009390047814		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.3619009390047814 | validation: 1.1306139298146207]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.205704764205195		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.205704764205195 | validation: 1.6733559593282976]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4225981160113017		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.4225981160113017 | validation: 1.0514256464903216]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888628626604808		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.2888628626604808 | validation: 1.0768736959591343]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22530988561901		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.22530988561901 | validation: 1.2050824851579922]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2700355128859797		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.2700355128859797 | validation: 1.1627525888193815]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484797887112528		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.1484797887112528 | validation: 1.2389722449256408]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2019046621010763		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.2019046621010763 | validation: 1.522865994865707]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5280400333156483		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.5280400333156483 | validation: 1.4695414330512753]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3338430080202561		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.3338430080202561 | validation: 1.0440691334417085]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3837230307539403		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.3837230307539403 | validation: 1.3454001603058774]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4546080096321674		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.4546080096321674 | validation: 1.1216965425559702]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2893948639128057		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.2893948639128057 | validation: 0.9405539409982211]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035388609974467		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.035388609974467 | validation: 1.4310322560899011]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2958277160439966		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.2958277160439966 | validation: 1.0052959260966892]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164850672449818		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.164850672449818 | validation: 0.9886962587044529]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2186921639291346		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.2186921639291346 | validation: 1.1493941651392425]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1682783576994125		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.1682783576994125 | validation: 1.0320053110575542]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0709887581941526		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.0709887581941526 | validation: 1.1415779040784133]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2606830509013356		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.2606830509013356 | validation: 1.6720560052667635]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5203886643487479		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.5203886643487479 | validation: 1.381432190761559]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4064042100474774		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.4064042100474774 | validation: 1.3046615830859707]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3098491831620407		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.3098491831620407 | validation: 1.1280661945436374]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2318692652603493		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.2318692652603493 | validation: 1.0364967898419304]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2397901422318545		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.2397901422318545 | validation: 1.2487011437638202]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1612922902617169		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.1612922902617169 | validation: 1.1598327578319094]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162961569863424		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.2162961569863424 | validation: 1.0557311567234373]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.201760874055726		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.201760874055726 | validation: 1.195914269511341]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4649934431538552		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.4649934431538552 | validation: 1.4835352241673454]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1244507492964912		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.1244507492964912 | validation: 1.7558077984699398]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.661021999244913		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.661021999244913 | validation: 1.5924946176741615]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301886678011527		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.301886678011527 | validation: 1.1792851867625431]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1529435038020162		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.1529435038020162 | validation: 1.1350801690842665]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1434812673635932		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.1434812673635932 | validation: 1.2302711334435386]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568558545621408		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.1568558545621408 | validation: 1.1960484901489863]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3500498133470962		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3500498133470962 | validation: 1.4990068765162117]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2974636568120619		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.2974636568120619 | validation: 1.085488550663065]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0461503849174396		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.0461503849174396 | validation: 1.1450738402727072]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2021112507004605		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.2021112507004605 | validation: 1.3968969625200958]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397333451962206		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.1397333451962206 | validation: 1.1483638067331892]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1142379591181804		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.1142379591181804 | validation: 1.044289810028587]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2657822073698952		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.2657822073698952 | validation: 1.0827823243662735]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1526768380297074		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.1526768380297074 | validation: 1.2713635530187823]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1488824831484583		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.1488824831484583 | validation: 0.9873808183387575]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1027498398025253		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.1027498398025253 | validation: 1.1571204025889175]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1180245437570395		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.1180245437570395 | validation: 1.0623434281428934]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3264741471359303		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.3264741471359303 | validation: 1.1254308714109351]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0700508097366752		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.0700508097366752 | validation: 1.0729889273529387]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2797729383139673		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.2797729383139673 | validation: 1.3918196634212963]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2962936426579876		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.2962936426579876 | validation: 1.7411567952197462]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3351739894297887		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.3351739894297887 | validation: 0.9545214603976087]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211088086031237		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.0211088086031237 | validation: 1.2072477183366843]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1959282482638856		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.1959282482638856 | validation: 1.1321569910614144]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071701252298866		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.071701252298866 | validation: 1.0614961065645192]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.197399823639385		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.197399823639385 | validation: 0.9142449166228531]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_431.pth
	Model improved!!!
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1009494251727339		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.1009494251727339 | validation: 1.2049185673678566]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0722673630560755		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.0722673630560755 | validation: 1.1586946701453262]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.263557947212479		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.263557947212479 | validation: 1.4294042173809787]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9080368603331157		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.9080368603331157 | validation: 1.3035551132913856]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2104260907715234		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.2104260907715234 | validation: 1.7074882366877093]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3327214434612142		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.3327214434612142 | validation: 1.0897965471121929]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1501578318345902		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.1501578318345902 | validation: 1.1137051894134382]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2670690642544635		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.2670690642544635 | validation: 1.189219629695034]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1538227541795134		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.1538227541795134 | validation: 1.529075339210919]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2596530274735547		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.2596530274735547 | validation: 0.9828311117761916]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.206301912863256		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.206301912863256 | validation: 1.2433972737596555]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3330860682771675		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.3330860682771675 | validation: 1.281983201034992]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1813343610390366		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.1813343610390366 | validation: 1.0443403958472308]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386041402185898		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.386041402185898 | validation: 1.6989786253877308]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2662497866002236		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.2662497866002236 | validation: 0.9697486382732105]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1152474455455086		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.1152474455455086 | validation: 1.0015685674851826]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380575883576237		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.0380575883576237 | validation: 1.061115670941365]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968232962869811		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.9968232962869811 | validation: 1.2714850068699717]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2539375730159836		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.2539375730159836 | validation: 1.0436374750497057]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4087912955086321		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.4087912955086321 | validation: 1.9568635218827706]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4616501844791658		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.4616501844791658 | validation: 0.9812554237110314]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0641559946917192		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.0641559946917192 | validation: 1.0679978536785095]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729066365939535		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.0729066365939535 | validation: 1.3493832063226132]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1297349116491506		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.1297349116491506 | validation: 1.0322355992823053]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798312115681314		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.9798312115681314 | validation: 0.9090454395529329]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515829333670097		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.0515829333670097 | validation: 1.3126850083898833]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326182094268487		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.2326182094268487 | validation: 0.9321083543079128]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254570147810118		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.0254570147810118 | validation: 0.9278108524421869]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1513026492367757		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.1513026492367757 | validation: 1.1344595314822166]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5371786466184887		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.5371786466184887 | validation: 1.4762816112249177]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3114574898910254		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.3114574898910254 | validation: 1.158720840899758]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217182879725644		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.0217182879725644 | validation: 1.087945767125995]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9705297291965018		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.9705297291965018 | validation: 1.5499592384405148]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.583015087212632		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.583015087212632 | validation: 1.2527320046973638]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0943423272404778		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.0943423272404778 | validation: 0.9712230607758696]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1262947464038686		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.1262947464038686 | validation: 1.1414813788570348]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3928972473838237		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.3928972473838237 | validation: 0.9985031774380542]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0357416378796407		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.0357416378796407 | validation: 0.973539145713703]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647458818293298		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.0647458818293298 | validation: 1.1727139891233034]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642700246992614		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.0642700246992614 | validation: 1.1693794089732865]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0171042204577492		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.0171042204577492 | validation: 0.9181245594947015]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082706461057262		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.082706461057262 | validation: 1.1171413905513103]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2283249519110884		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.2283249519110884 | validation: 1.2760122024300409]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3752896546266218		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.3752896546266218 | validation: 1.5261940812483445]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4402589695143726		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.4402589695143726 | validation: 1.0395263827204826]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235953235110141		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.235953235110141 | validation: 1.05098884438577]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009207331373453		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.009207331373453 | validation: 0.9789631028484118]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9766422890509197		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.9766422890509197 | validation: 1.0632510450329646]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3249853561870193		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3249853561870193 | validation: 1.176892670288733]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0781488531481234		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.0781488531481234 | validation: 0.9313327433982553]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256940705520299		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.0256940705520299 | validation: 0.9182570156241937]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00863202844407		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.00863202844407 | validation: 1.2738591458756727]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2394572854021926		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.2394572854021926 | validation: 1.185042210759997]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.087076661169554		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.087076661169554 | validation: 1.0542941919440147]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0324557011982394		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.0324557011982394 | validation: 0.966576276689103]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036114195768468		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.036114195768468 | validation: 1.0067365217371689]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0345900517017081		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.0345900517017081 | validation: 0.9798276314109693]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0314951035366866		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.0314951035366866 | validation: 1.075203032277163]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1019405503535857		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.1019405503535857 | validation: 1.0037304308616999]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075948234009462		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.075948234009462 | validation: 0.9385746826321348]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025751401514746		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.025751401514746 | validation: 1.597209981829472]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3915051815228259		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.3915051815228259 | validation: 1.159503264801104]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4184535384075345		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.4184535384075345 | validation: 1.5805912027803317]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5765791904281472		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.5765791904281472 | validation: 0.9512545960921058]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9493910606499777		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.9493910606499777 | validation: 1.000236821002005]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0975390344343565		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.0975390344343565 | validation: 1.8524299097991286]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5691133686259213		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.5691133686259213 | validation: 1.2063298169194303]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0757021010874357		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.0757021010874357 | validation: 0.9285648075019012]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1097636551515586		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.1097636551515586 | validation: 1.1810448533383235]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1034656489303838		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.1034656489303838 | validation: 1.076735285548623]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1048195134315726		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.1048195134315726 | validation: 1.1404473408337055]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0758289373851189		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.0758289373851189 | validation: 0.9266340414532406]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021115653062497		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.021115653062497 | validation: 1.2608764292851593]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1959372038554823		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.1959372038554823 | validation: 0.9236683905462804]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0499234373301738		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.0499234373301738 | validation: 1.1952462319928063]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157769351727573		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.157769351727573 | validation: 1.7949940222527772]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3144050226258743		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.3144050226258743 | validation: 1.0039495322631513]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0421402174159806		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.0421402174159806 | validation: 1.2061081500815936]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1053911360461643		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.1053911360461643 | validation: 1.0267784087172962]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387004588241574		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1387004588241574 | validation: 1.157227260201668]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1539206478609692		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.1539206478609692 | validation: 1.3449437115756053]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1630516329587115		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.1630516329587115 | validation: 0.9423120919991612]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1551300576245476		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.1551300576245476 | validation: 1.0416537887911246]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730151787113853		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.2730151787113853 | validation: 0.9341464658125227]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9603075608475895		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.9603075608475895 | validation: 0.9188574586636016]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9317610139192407		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.9317610139192407 | validation: 1.1386201952865873]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2603119448157918		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.2603119448157918 | validation: 0.9964079217658506]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1003856202211286		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.1003856202211286 | validation: 1.2362908609693002]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0680860912628787		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.0680860912628787 | validation: 1.3000002731299365]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181311998633711		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.181311998633711 | validation: 0.9621018867847838]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0413209246284327		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.0413209246284327 | validation: 1.0283901391308263]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0487620282148868		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.0487620282148868 | validation: 1.239191066893036]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2098980038118996		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.2098980038118996 | validation: 0.8576484996722868]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9688761976041879		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.9688761976041879 | validation: 0.8937156121886766]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1824050633847278		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.1824050633847278 | validation: 0.8848596265986179]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9730691414757344		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.9730691414757344 | validation: 1.167736596092086]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659353125788171		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.0659353125788171 | validation: 0.9267406948499931]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3306593709505021		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.3306593709505021 | validation: 1.3307739302866737]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1841233103454576		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.1841233103454576 | validation: 1.0519181193444864]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256805352560312		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.0256805352560312 | validation: 1.7732776039765212]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4080652300562244		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.4080652300562244 | validation: 0.9748803627807249]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0023836369528079		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.0023836369528079 | validation: 0.9102337872096196]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2106316663749852		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.2106316663749852 | validation: 1.0596207432543718]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208131855328433		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.0208131855328433 | validation: 1.0186129123707077]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1280046744133527		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.1280046744133527 | validation: 1.7727618738027549]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384719305277835		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.384719305277835 | validation: 0.9303991189551225]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954404063370992		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.954404063370992 | validation: 1.0592386887253098]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903310661930923		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.0903310661930923 | validation: 1.0733505142412751]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759512120206026		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.9759512120206026 | validation: 1.0322569622601]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1492372492593956		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.1492372492593956 | validation: 0.9170776937007183]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9863194409922167		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.9863194409922167 | validation: 0.8551190536575121]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9224583354377838		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.9224583354377838 | validation: 1.0644902895315915]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0840325834234186		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.0840325834234186 | validation: 0.9593688348846806]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0658164801858567		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.0658164801858567 | validation: 1.879535734764773]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4189515650339328		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.4189515650339328 | validation: 1.136427319347298]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0690627715613237		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.0690627715613237 | validation: 1.2090771439806745]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0308853327828493		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.0308853327828493 | validation: 0.9377141967882926]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9576682181145355		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.9576682181145355 | validation: 0.8980383881942825]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301430372069758		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.1301430372069758 | validation: 1.029954849263147]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0055846103330437		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.0055846103330437 | validation: 0.8959126167400655]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9830756993623528		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.9830756993623528 | validation: 0.951253229583989]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592200294058651		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.0592200294058651 | validation: 1.0438113793498935]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9925404219357081		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.9925404219357081 | validation: 1.0667118564345237]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0572507560987103		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.0572507560987103 | validation: 1.0868809460281286]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1012467102609103		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.1012467102609103 | validation: 0.9436563218375875]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9903742031082936		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9903742031082936 | validation: 0.9880152541770038]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9366468471560059		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.9366468471560059 | validation: 1.0919875968760204]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9963833732433611		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.9963833732433611 | validation: 1.1945627912908645]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041206347685551		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.041206347685551 | validation: 0.9079810959027884]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9149771896506951		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.9149771896506951 | validation: 0.8804394707273062]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0506327396495796		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.0506327396495796 | validation: 1.023055811866761]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0475879545157913		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.0475879545157913 | validation: 0.8852948397489138]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9423241310665722		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.9423241310665722 | validation: 1.0642403430453675]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9872363299987283		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.9872363299987283 | validation: 0.9379482160316631]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8988578667424477		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.8988578667424477 | validation: 1.1284493599590593]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0884056486294496		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.0884056486294496 | validation: 0.9375549179680591]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9962454916915318		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.9962454916915318 | validation: 0.9868669437800597]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064955600700271		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.064955600700271 | validation: 0.9362196428393421]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4305792438024048		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.4305792438024048 | validation: 2.213111293603767]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8539336149158403		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.8539336149158403 | validation: 1.201978784937362]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274291469790158		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.274291469790158 | validation: 1.0228428816579977]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9915687308172512		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.9915687308172512 | validation: 0.9328330343177794]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9988084199044438		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.9988084199044438 | validation: 0.8924959584172092]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677496981716753		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.9677496981716753 | validation: 0.9199165812243536]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9523100020680524		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.9523100020680524 | validation: 0.9932657133409791]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2026465939069841		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.2026465939069841 | validation: 1.7819986200478457]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5185265181005856		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.5185265181005856 | validation: 0.9458443728882705]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0983777960892624		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.0983777960892624 | validation: 0.8802185760584422]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9537492860712125		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.9537492860712125 | validation: 0.9774693194335657]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0541157688736988		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.0541157688736988 | validation: 1.236259365953432]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5270292470528872		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.5270292470528872 | validation: 1.2841150229934182]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0817197472999447		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.0817197472999447 | validation: 0.9533086632425488]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9492066861252704		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.9492066861252704 | validation: 0.9054165850972252]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289951151225074		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.0289951151225074 | validation: 0.923476526226623]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9134946826757201		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.9134946826757201 | validation: 0.8796846416760906]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.976546596027652		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.976546596027652 | validation: 1.2905842788743447]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0920209441515518		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.0920209441515518 | validation: 1.0731356400329086]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0342374922435742		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.0342374922435742 | validation: 1.0939328614322674]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0326733836717732		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.0326733836717732 | validation: 0.8913669200027002]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9808287227452492		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.9808287227452492 | validation: 0.880437600179009]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9351631128255435		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.9351631128255435 | validation: 1.0338803410057371]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576516061062537		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.0576516061062537 | validation: 1.1054293928857408]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245795331375827		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.0245795331375827 | validation: 0.9600310998548944]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179668761197477		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.9179668761197477 | validation: 1.0089888169012082]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9719598706399373		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.9719598706399373 | validation: 0.9474140928307149]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0111604150787263		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.0111604150787263 | validation: 0.9120088679535837]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272174455330907		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.0272174455330907 | validation: 0.9846601830426006]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9127360321959636		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.9127360321959636 | validation: 1.013159737872052]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1165118470065938		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.1165118470065938 | validation: 1.0493552628136034]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0635189688106192		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.0635189688106192 | validation: 1.0306361623189357]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9898669125592292		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.9898669125592292 | validation: 1.0394831438702286]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9344075080256711		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.9344075080256711 | validation: 0.8347524984026827]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9131703593930536		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.9131703593930536 | validation: 1.0170667450250508]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1093894511823055		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.1093894511823055 | validation: 1.1292684422236432]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0074362219997879		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.0074362219997879 | validation: 1.1304916624500316]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0257932594868793		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.0257932594868793 | validation: 0.9386581295167435]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9461835734380606		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.9461835734380606 | validation: 0.9218800776005445]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9826041207451578		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.9826041207451578 | validation: 1.1782563445331509]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9619214192932173		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.9619214192932173 | validation: 0.9036444800115884]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0445668783425828		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.0445668783425828 | validation: 1.231789891873342]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193152015806021		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.193152015806021 | validation: 1.1241871542202704]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9788925156672279		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.9788925156672279 | validation: 1.087643511131408]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009096602793163		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.009096602793163 | validation: 0.9261760332411404]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9204549053393893		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.9204549053393893 | validation: 0.9045516047751471]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732486344094037		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.0732486344094037 | validation: 0.9559820278499307]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006303905656886		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.006303905656886 | validation: 0.8456065854667612]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.879244192768518		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.879244192768518 | validation: 1.1313606102915232]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0157383625840848		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.0157383625840848 | validation: 1.0914680716909222]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0140932704732117		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.0140932704732117 | validation: 1.1098238575047472]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024471803826963		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.024471803826963 | validation: 1.1655205614109903]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0356216415321464		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.0356216415321464 | validation: 0.8366489935963689]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8801954360963845		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.8801954360963845 | validation: 0.9242084524856047]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9218642425233599		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.9218642425233599 | validation: 1.0079581705998608]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9422781099657344		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.9422781099657344 | validation: 0.918267903561235]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8640446336571427		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.8640446336571427 | validation: 0.9017172201760556]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0356689389897134		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.0356689389897134 | validation: 0.835273093923843]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0440610475923637		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.0440610475923637 | validation: 0.875161980379718]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9217737963023491		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.9217737963023491 | validation: 0.9663890299112499]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9979457686316587		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.9979457686316587 | validation: 1.0155269483106677]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9076435554201735		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.9076435554201735 | validation: 1.1186558781022167]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068510967491038		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.068510967491038 | validation: 1.3585513351369651]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196686606859887		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.196686606859887 | validation: 0.9011570716875147]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8957894548153172		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.8957894548153172 | validation: 0.9494638994069492]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8901874080804812		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.8901874080804812 | validation: 0.8773906529284372]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8940776918102991		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.8940776918102991 | validation: 1.061576189428928]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.972174033828411		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.972174033828411 | validation: 0.8331033406302263]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9369646297295429		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.9369646297295429 | validation: 1.125352710866388]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02604631123775		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.02604631123775 | validation: 0.8521998857297957]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0805617922406145		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.0805617922406145 | validation: 1.3580667962098185]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482483355501989		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.482483355501989 | validation: 1.1039242255709514]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0558585541302703		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.0558585541302703 | validation: 0.911794289231769]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9775687719226367		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.9775687719226367 | validation: 1.0624938461403668]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0997164945099387		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.0997164945099387 | validation: 0.9183651135939326]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0335236183248804		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.0335236183248804 | validation: 0.9932676222328343]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9628591308670909		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.9628591308670909 | validation: 0.8749753282119417]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8802046894622233		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.8802046894622233 | validation: 1.1290768362744812]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101575062186814		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.0101575062186814 | validation: 0.9037574331575425]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9370846851374857		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.9370846851374857 | validation: 1.0264723260350153]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0336898851894687		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.0336898851894687 | validation: 1.0419904270673528]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053530508315535		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.053530508315535 | validation: 1.197409715185045]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144341040342114		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.144341040342114 | validation: 1.0030715150456615]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9774134623884332		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.9774134623884332 | validation: 1.1714888769447342]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636770481119175		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.0636770481119175 | validation: 0.9302831301759301]
	TIME [epoch: 11.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903730081745925		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.903730081745925 | validation: 0.9974701798746307]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179971589091664		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.9179971589091664 | validation: 0.8555928301396339]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1518616707892493		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.1518616707892493 | validation: 1.135253276419373]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968899067403516		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.9968899067403516 | validation: 0.9950223039870273]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0180631105479019		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.0180631105479019 | validation: 1.1777229878447084]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320106914482083		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.0320106914482083 | validation: 0.8768516238033311]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9219921051493609		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.9219921051493609 | validation: 1.388113430752957]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1240641539877938		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.1240641539877938 | validation: 1.786391014859877]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.328966366094312		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.328966366094312 | validation: 1.3143185693261132]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1315816116758384		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.1315816116758384 | validation: 0.9908245188590652]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8819916674736454		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.8819916674736454 | validation: 0.9807933939083234]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100717990321339		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.9100717990321339 | validation: 1.099493718573594]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.913633406925295		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.913633406925295 | validation: 0.8816708666400885]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889556625821731		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.8889556625821731 | validation: 1.2058134533868543]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0739792150003307		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.0739792150003307 | validation: 0.9940195785984756]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0108097865213068		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.0108097865213068 | validation: 0.9632555395997184]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9950254060058991		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.9950254060058991 | validation: 2.131113934648922]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6948861094972563		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.6948861094972563 | validation: 0.9412180586429186]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936474968320714		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.936474968320714 | validation: 0.9792257903924642]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9099434881514565		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.9099434881514565 | validation: 0.8696006260279282]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9261461855958579		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.9261461855958579 | validation: 0.8881871543731803]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042723080376411		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.9042723080376411 | validation: 0.9124566720989863]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8985844822709483		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.8985844822709483 | validation: 0.9964263827219386]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9301550453599773		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.9301550453599773 | validation: 0.9712836569821087]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881960972099658		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.8881960972099658 | validation: 0.8761884290853638]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816203406340507		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.8816203406340507 | validation: 0.9738427816377728]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9670287579069602		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.9670287579069602 | validation: 0.9773385485727792]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9637092134838444		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.9637092134838444 | validation: 0.9355886049281067]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9971303402222811		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.9971303402222811 | validation: 0.9274726653896496]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9201254567261525		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.9201254567261525 | validation: 0.8734213579338956]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9433751749031338		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.9433751749031338 | validation: 0.9434673419160597]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008796321696413		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.9008796321696413 | validation: 0.9993466915750253]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9220763043076013		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.9220763043076013 | validation: 0.980366995549399]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9547944166661628		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.9547944166661628 | validation: 1.2496083527523285]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403037940133122		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.0403037940133122 | validation: 0.927217883313769]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042390815887669		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.9042390815887669 | validation: 1.0625643288496736]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9232877106879323		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.9232877106879323 | validation: 0.8933167960403098]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8519054795064249		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.8519054795064249 | validation: 0.9272086528039972]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9192138236634712		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.9192138236634712 | validation: 0.8683013766844502]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8871081312141738		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.8871081312141738 | validation: 0.8261899819989098]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9245354834531053		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.9245354834531053 | validation: 0.9119040644326848]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045031877566885		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.045031877566885 | validation: 0.8142837611033944]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9015980329295595		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.9015980329295595 | validation: 0.8159337787293853]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9566813090741371		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.9566813090741371 | validation: 1.1125693730433814]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033002428180715		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.033002428180715 | validation: 0.8866424196109364]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9454192961988531		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.9454192961988531 | validation: 0.8117534105058011]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8688665214337731		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.8688665214337731 | validation: 0.8396029159347078]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404683975155552		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.1404683975155552 | validation: 1.3502590565884156]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1757964414524515		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.1757964414524515 | validation: 0.9132319312139354]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1235518816495105		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.1235518816495105 | validation: 1.0843403553467261]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003675844547392		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.003675844547392 | validation: 0.8810623995905287]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319669689994611		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.8319669689994611 | validation: 0.8802778555054224]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8786934421736636		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.8786934421736636 | validation: 0.8883195345121775]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.830508006064374		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.830508006064374 | validation: 0.8355142675488242]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.885849845083305		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.885849845083305 | validation: 0.952621478628744]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866280707117213		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.866280707117213 | validation: 0.886304041282908]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337084910373079		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.9337084910373079 | validation: 1.0654774379640768]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519332037102237		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.9519332037102237 | validation: 1.040055454637703]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03576499134878		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.03576499134878 | validation: 1.0965681446468971]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647816413596083		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.0647816413596083 | validation: 1.0771024852111581]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9490916661549847		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.9490916661549847 | validation: 0.9479502525542205]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9194481657102238		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.9194481657102238 | validation: 0.9046354787026585]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9180768749115911		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.9180768749115911 | validation: 0.988724643181854]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893071067806639		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.893071067806639 | validation: 0.8147757794035647]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563802942915938		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.8563802942915938 | validation: 0.8263942004282419]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8932531538618897		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.8932531538618897 | validation: 0.9075110491915953]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8973291553445315		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.8973291553445315 | validation: 0.8131002952021962]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8372790236393781		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.8372790236393781 | validation: 0.8739508483996167]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8502986026853584		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.8502986026853584 | validation: 0.9051947342650155]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9465607122228574		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.9465607122228574 | validation: 1.0899675408674048]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836232042223446		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.9836232042223446 | validation: 0.9582047060940692]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9326243138420891		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.9326243138420891 | validation: 0.9609562871995201]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9484060195887696		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.9484060195887696 | validation: 0.8885682151753533]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8540143717237598		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.8540143717237598 | validation: 0.806739738267729]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652207001668313		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.8652207001668313 | validation: 0.8822813462140076]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8325229576488048		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.8325229576488048 | validation: 0.8401988973677733]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.886458425363145		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.886458425363145 | validation: 0.8653868011908656]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8540798727283667		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.8540798727283667 | validation: 0.9450541895166233]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8802931401700322		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.8802931401700322 | validation: 0.8061886759793617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400845104912089		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.8400845104912089 | validation: 0.8034679620558948]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1298661875524485		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.1298661875524485 | validation: 0.9415181928347292]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231076559052714		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.0231076559052714 | validation: 0.8358298837529544]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9325196719180017		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.9325196719180017 | validation: 0.9442822405071801]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9021733252522492		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.9021733252522492 | validation: 0.9920933929652922]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9097719888714664		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.9097719888714664 | validation: 0.9074868995400343]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8525091645843959		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.8525091645843959 | validation: 0.8282635114514557]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382764638444626		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.8382764638444626 | validation: 0.8043966944721572]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8238896013015153		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.8238896013015153 | validation: 0.844390120347323]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9037947959995134		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.9037947959995134 | validation: 0.97188821770365]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8996009339211002		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.8996009339211002 | validation: 0.8236542001749326]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8483027446140581		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.8483027446140581 | validation: 0.8969622757913603]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8513647404782237		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.8513647404782237 | validation: 0.9179532316907028]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494376095913308		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.1494376095913308 | validation: 0.7947574041097138]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8293376585324659		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.8293376585324659 | validation: 0.8012050855155181]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673225050051101		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.8673225050051101 | validation: 0.8622183074694431]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9583624465490823		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.9583624465490823 | validation: 0.9497429860423385]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046487408793839		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.9046487408793839 | validation: 0.942611700657366]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8397551582991333		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.8397551582991333 | validation: 0.8457451274892699]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8299826175013587		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.8299826175013587 | validation: 0.8791034591876414]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8734978603389502		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.8734978603389502 | validation: 0.9566563141164907]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270522978268845		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.9270522978268845 | validation: 0.8867380869333235]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8492603600114258		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.8492603600114258 | validation: 0.8831760905694729]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.958807635229797		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.958807635229797 | validation: 1.0516224718356235]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9106901382436969		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.9106901382436969 | validation: 0.9042571930536829]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.847615020745879		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.847615020745879 | validation: 0.844745356074268]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9348715770876649		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.9348715770876649 | validation: 0.832388776988344]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233002645708066		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.8233002645708066 | validation: 0.8371812475719171]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8020439016604042		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.8020439016604042 | validation: 0.8368521686289608]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936318877368784		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.936318877368784 | validation: 1.1419139688469808]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9772541322469375		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.9772541322469375 | validation: 0.8972622930342121]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9276615117371609		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.9276615117371609 | validation: 0.9200125859385156]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9039945353470714		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.9039945353470714 | validation: 0.7612495786880838]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412011641390371		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.8412011641390371 | validation: 0.8207528761619454]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8204836394469254		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.8204836394469254 | validation: 0.7788984250344908]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160639983029475		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.8160639983029475 | validation: 0.8229514069935061]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8521895736454802		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.8521895736454802 | validation: 0.8424705379261448]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385977380253978		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.8385977380253978 | validation: 0.8523154509205986]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8383440120838141		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.8383440120838141 | validation: 1.0982250532590994]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519701104770596		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.9519701104770596 | validation: 0.8532751245817461]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8950809533598367		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.8950809533598367 | validation: 0.8043537242577657]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8610037988631644		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.8610037988631644 | validation: 0.882542509791019]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034886833339054		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.0034886833339054 | validation: 0.9014235769848267]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9746959960602952		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.9746959960602952 | validation: 0.8115085190366168]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8087751803194201		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.8087751803194201 | validation: 0.8323909263451094]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266886650950018		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.0266886650950018 | validation: 0.820403324355658]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9663217985382542		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.9663217985382542 | validation: 1.0733335895699374]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9470591225454448		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.9470591225454448 | validation: 0.8994361714829741]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.905857919405518		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.905857919405518 | validation: 0.8208097776126926]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8322585901003137		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.8322585901003137 | validation: 0.9498337955433541]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026380752159488		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.026380752159488 | validation: 0.8144095427888495]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8202549372016713		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.8202549372016713 | validation: 0.8693122465496632]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8632268610491413		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.8632268610491413 | validation: 0.8793793160769301]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547152418693991		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.8547152418693991 | validation: 0.8871663492536044]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934183654860106		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.8934183654860106 | validation: 0.9178025552925451]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984652231002663		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.8984652231002663 | validation: 0.8278692132709199]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619888035753088		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.8619888035753088 | validation: 0.9045640298781641]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9486304756660434		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.9486304756660434 | validation: 0.8616180048191894]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8798276724741874		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.8798276724741874 | validation: 0.8087690121749179]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821006671714057		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.821006671714057 | validation: 0.8095872787757833]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8227977179052729		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.8227977179052729 | validation: 0.7846889436932994]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077428579937684		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.8077428579937684 | validation: 0.8607881855158449]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371636835223317		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.8371636835223317 | validation: 0.9088601963979542]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8707587785914639		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.8707587785914639 | validation: 0.8324421456990879]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174375617330693		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.8174375617330693 | validation: 0.7879689843841974]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8499577398578748		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.8499577398578748 | validation: 0.8198339628608087]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8840416356413181		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.8840416356413181 | validation: 0.8948003071218765]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8550405560780923		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.8550405560780923 | validation: 0.8466347984400292]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9716598575352372		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.9716598575352372 | validation: 0.7547966279166687]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8959464865678212		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.8959464865678212 | validation: 0.7691268800294555]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8220174606228751		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.8220174606228751 | validation: 0.8033102934574501]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270614716397073		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.8270614716397073 | validation: 0.9028154713050148]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840861004115928		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.840861004115928 | validation: 0.8223274719424785]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8339700503600123		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.8339700503600123 | validation: 0.8352959164948867]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9405647745580252		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.9405647745580252 | validation: 0.9058172227069295]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8479113092456988		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.8479113092456988 | validation: 0.8670291886447663]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8689095700297695		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.8689095700297695 | validation: 1.3103619001713338]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1187730727522636		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.1187730727522636 | validation: 0.7732492002715742]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8284227805569883		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.8284227805569883 | validation: 0.8785156281099188]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8615832063657949		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.8615832063657949 | validation: 0.8491263417138449]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120431963579134		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.8120431963579134 | validation: 0.8855563098657337]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9764487377338141		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.9764487377338141 | validation: 0.8887361793649639]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008798084174423		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.9008798084174423 | validation: 0.9937862695297658]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1120393405998952		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.1120393405998952 | validation: 1.2269152843750188]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276388363608981		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.0276388363608981 | validation: 0.8813547875509498]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8144680137016657		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.8144680137016657 | validation: 0.7885642176296181]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8225391514695272		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.8225391514695272 | validation: 0.8262906481576952]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419388933640177		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.8419388933640177 | validation: 1.0247707843161855]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8956514855306124		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.8956514855306124 | validation: 0.8000830699884776]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8072251567099866		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.8072251567099866 | validation: 0.7607919127174619]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899124187757487		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.899124187757487 | validation: 0.8227036014447222]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002578610752699		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.8002578610752699 | validation: 0.8689571050919586]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81640618078794		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.81640618078794 | validation: 0.8714189621417973]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9201490045327098		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.9201490045327098 | validation: 0.7773875568236531]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8455314936349254		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.8455314936349254 | validation: 0.8261778947818371]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167339202837612		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.9167339202837612 | validation: 1.0799306202551884]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0267995822077316		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.0267995822077316 | validation: 1.060837231073692]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9468904643429774		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.9468904643429774 | validation: 0.9592331859643892]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8369574867607722		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.8369574867607722 | validation: 0.7851290139267618]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7675849758349687		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.7675849758349687 | validation: 0.7966541946067591]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7810679193428604		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.7810679193428604 | validation: 0.7954347673754292]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8166730288037285		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.8166730288037285 | validation: 0.7818959812594994]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8133172515981919		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.8133172515981919 | validation: 0.7713786669097445]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802411384936089		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.802411384936089 | validation: 0.8457180454602713]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9058222973310605		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.9058222973310605 | validation: 0.9050493188579682]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9473268455167896		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.9473268455167896 | validation: 1.1476146304247496]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2276790542054385		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.2276790542054385 | validation: 1.2452344270551365]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0972825714450496		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.0972825714450496 | validation: 0.9304470762095278]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9522016478944058		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.9522016478944058 | validation: 1.253501384460888]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840393811659528		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.9840393811659528 | validation: 0.864453237782829]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9092094231273695		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.9092094231273695 | validation: 0.8704945393902592]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8010740177363466		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.8010740177363466 | validation: 0.8449854920749903]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8087455440302127		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.8087455440302127 | validation: 0.787089325420817]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8297881979111164		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.8297881979111164 | validation: 0.8146966708045986]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8581652791802986		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.8581652791802986 | validation: 0.7931756843936849]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8560124657204358		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.8560124657204358 | validation: 0.7837762370071704]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090950012303548		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.8090950012303548 | validation: 0.7553604572971964]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409491367800501		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.8409491367800501 | validation: 0.7607374464828577]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7760291816453736		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.7760291816453736 | validation: 0.8203901029781652]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8298394184627835		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.8298394184627835 | validation: 0.822623077390839]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170653758188078		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.8170653758188078 | validation: 0.8118672691865296]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8758172085332321		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.8758172085332321 | validation: 0.768856301454645]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412506639114365		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.8412506639114365 | validation: 0.813922069953591]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8746973718612179		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.8746973718612179 | validation: 0.7870211669064529]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.898235768129003		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.898235768129003 | validation: 0.9213106668608757]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8862064671564818		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.8862064671564818 | validation: 0.9133779320629861]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84622604796413		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.84622604796413 | validation: 0.9009572737051093]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080980203501506		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.2080980203501506 | validation: 0.9457172830534987]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886936683772602		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.8886936683772602 | validation: 0.8284284950918179]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611571385508794		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.8611571385508794 | validation: 0.7778796335649506]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8298888179375585		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.8298888179375585 | validation: 0.7927294936082487]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9972757383653759		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.9972757383653759 | validation: 0.9039897711877534]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148625874826287		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.0148625874826287 | validation: 0.9240588842662348]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0626545811968189		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.0626545811968189 | validation: 0.8053432302942575]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8989110140242431		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.8989110140242431 | validation: 0.8142864374214637]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9434500888848166		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.9434500888848166 | validation: 1.0017256339775336]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.863256443940742		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.863256443940742 | validation: 0.8695292705678931]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108574873889478		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.8108574873889478 | validation: 0.9113902149764813]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8121058047938996		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.8121058047938996 | validation: 0.7709394537566397]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104348341662188		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.8104348341662188 | validation: 0.797409678787256]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858688111476345		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.7858688111476345 | validation: 0.8969333595412518]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8692509993371513		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.8692509993371513 | validation: 0.7863058359587406]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.79560858490899		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.79560858490899 | validation: 0.845839469417202]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8306942538487145		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.8306942538487145 | validation: 0.8219449910422502]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425036804896271		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.8425036804896271 | validation: 0.808052100215192]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.878554325884125		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.878554325884125 | validation: 0.8646235977297182]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371816402464263		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.8371816402464263 | validation: 0.7668981736510686]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.933866494919904		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.933866494919904 | validation: 0.8636371711336667]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8603823928003324		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.8603823928003324 | validation: 0.8453327480649029]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.957073643703883		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.957073643703883 | validation: 0.8001377250865914]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8492811801432577		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.8492811801432577 | validation: 0.8634127141722475]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8480924451814663		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.8480924451814663 | validation: 0.9954250493294948]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514970686589439		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.1514970686589439 | validation: 0.8232416918743733]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8394530860488582		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.8394530860488582 | validation: 0.8021918578905232]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8581770714611899		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.8581770714611899 | validation: 0.7675520793022507]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.960078984790345		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.960078984790345 | validation: 0.8612464876424811]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8332406832584046		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.8332406832584046 | validation: 0.7989896809890324]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213968091820005		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.8213968091820005 | validation: 0.8441981802707806]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8653739237317009		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.8653739237317009 | validation: 0.8452500483501257]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8366160013077681		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.8366160013077681 | validation: 0.8554474123462449]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098222578217962		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.8098222578217962 | validation: 0.826630764256886]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834599880890966		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.834599880890966 | validation: 0.7851202476499975]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.785894042579973		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.785894042579973 | validation: 0.7748503685249587]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.800735445422192		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.800735445422192 | validation: 0.8520979908510876]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8353220731403872		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.8353220731403872 | validation: 0.8368618017402413]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0486287507446517		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.0486287507446517 | validation: 1.0686355773826117]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0152411881824803		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.0152411881824803 | validation: 0.8039037729277756]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113836642956088		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.8113836642956088 | validation: 0.8126453195577217]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8365940697087926		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.8365940697087926 | validation: 0.9087897378791465]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889356082713267		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.8889356082713267 | validation: 0.7779098819996159]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8523570833254801		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.8523570833254801 | validation: 0.7662226242856889]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7964135117215664		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.7964135117215664 | validation: 0.8174359022204434]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075281499258251		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.8075281499258251 | validation: 0.809880720934729]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437078290163302		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.8437078290163302 | validation: 0.7564768979830829]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8096778673162195		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.8096778673162195 | validation: 0.7845552770307745]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8082724943509079		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.8082724943509079 | validation: 0.9323127892424617]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046739230291253		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.9046739230291253 | validation: 0.7769346510902966]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8086871735693699		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.8086871735693699 | validation: 0.7997835968141905]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8132624478987772		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.8132624478987772 | validation: 0.8751679934780975]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083064278466679		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.9083064278466679 | validation: 0.9104093846433312]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9405744682829429		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.9405744682829429 | validation: 0.8617975289262035]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128027535556706		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.8128027535556706 | validation: 0.7852233939700523]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098805583085638		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.8098805583085638 | validation: 0.8449638127156962]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8645516607325292		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.8645516607325292 | validation: 0.7812671775110235]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179812683172107		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.8179812683172107 | validation: 0.8097729816198111]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8636070375252685		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.8636070375252685 | validation: 0.8242957725711461]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7973563236036894		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.7973563236036894 | validation: 0.7881719346648295]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9380353631879882		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.9380353631879882 | validation: 0.8796876591452957]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201306148570786		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.8201306148570786 | validation: 0.7800489753639218]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037763838636163		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.8037763838636163 | validation: 0.7956819045171183]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7827976047607976		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.7827976047607976 | validation: 0.797833203921779]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152382477763582		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.8152382477763582 | validation: 0.9760729983956782]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9019246825464671		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.9019246825464671 | validation: 0.9158582106301321]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270831239347576		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.9270831239347576 | validation: 0.8092787991961754]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8189978653707629		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.8189978653707629 | validation: 0.8175792628087629]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120684540134827		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.8120684540134827 | validation: 0.852602343028826]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075207719069988		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.8075207719069988 | validation: 0.755015128047078]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7844571453181424		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.7844571453181424 | validation: 0.7573064459123103]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8194587986046467		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.8194587986046467 | validation: 0.7615566135704063]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789625785613643		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.789625785613643 | validation: 0.7787737168637694]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7971534183051852		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.7971534183051852 | validation: 0.8264660323106128]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9879280924017803		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.9879280924017803 | validation: 0.8147325651193399]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.824445655719415		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.824445655719415 | validation: 0.8465871362168704]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9362440169962671		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.9362440169962671 | validation: 0.8895728080170744]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8263780244611811		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.8263780244611811 | validation: 0.8126989575428274]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7992960318184694		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.7992960318184694 | validation: 0.8136754495960898]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775760162757062		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.775760162757062 | validation: 0.8645960851774254]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.849939987342172		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.849939987342172 | validation: 0.8062931976973843]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8095293764451789		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.8095293764451789 | validation: 0.8291695320528154]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8266450626166064		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.8266450626166064 | validation: 0.8278082675446006]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8366490954130037		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.8366490954130037 | validation: 0.7746686467969818]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.827238766307381		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.827238766307381 | validation: 0.8951590113853073]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8634996924106851		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.8634996924106851 | validation: 0.9051544242149322]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467426051014533		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.8467426051014533 | validation: 0.7741554330123028]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110183862604863		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.8110183862604863 | validation: 0.8545863725578886]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8268402288787596		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.8268402288787596 | validation: 0.7713832243081544]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8016901115768711		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.8016901115768711 | validation: 0.7840317951410183]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933054465757425		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.7933054465757425 | validation: 0.8007925421627178]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846509223045981		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.7846509223045981 | validation: 0.787240513305511]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8318944255217546		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.8318944255217546 | validation: 0.8126045248407622]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201021896720502		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.8201021896720502 | validation: 0.8047751311056439]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8025619606643476		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.8025619606643476 | validation: 0.7825584340654979]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160656160534185		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.8160656160534185 | validation: 0.8446252627194045]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.804243943722532		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.804243943722532 | validation: 0.7652728744389083]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734229710271147		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.7734229710271147 | validation: 0.7361756742526966]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_958.pth
	Model improved!!!
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7621792958506493		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.7621792958506493 | validation: 0.7857886571749854]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7769222414487081		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.7769222414487081 | validation: 0.8102237494303589]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8192051748295321		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.8192051748295321 | validation: 0.7682252328844521]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865271707209069		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.865271707209069 | validation: 0.82111151394896]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075192939082031		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.8075192939082031 | validation: 0.7781779232061097]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8205602368069885		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.8205602368069885 | validation: 0.8413046390813256]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926090163953143		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.7926090163953143 | validation: 0.8077683494700381]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7868844021838223		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.7868844021838223 | validation: 0.8065657205441187]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8189417666210337		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.8189417666210337 | validation: 0.7719726622795042]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648675445651799		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.7648675445651799 | validation: 0.8046636614684094]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966052457404008		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.7966052457404008 | validation: 0.7220536004419748]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_969.pth
	Model improved!!!
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7819428063535361		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.7819428063535361 | validation: 0.7397871167440875]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8131575228208991		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.8131575228208991 | validation: 0.7387409666444162]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047803597420691		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.8047803597420691 | validation: 0.8646743982081384]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8407506348433945		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.8407506348433945 | validation: 0.7532791047872388]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657853476089266		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.7657853476089266 | validation: 0.7793793355018547]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7778809318735155		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.7778809318735155 | validation: 0.7394807945470692]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700087740208892		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.7700087740208892 | validation: 0.8393404999903479]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7828119409351714		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.7828119409351714 | validation: 0.7960874786535094]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763759144373115		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.763759144373115 | validation: 0.7523627053005069]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7614225516032133		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.7614225516032133 | validation: 0.7926541254089676]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7736210588712527		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.7736210588712527 | validation: 0.838266819595634]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8693407207646927		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.8693407207646927 | validation: 0.8714487644215687]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990157470407773		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.7990157470407773 | validation: 0.7617054862627265]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7776283773974827		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.7776283773974827 | validation: 0.7497077128621595]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7720413573066434		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.7720413573066434 | validation: 0.7613100877549863]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7939109288736055		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.7939109288736055 | validation: 0.8503630908727462]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8223943465272581		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.8223943465272581 | validation: 0.8432657280612608]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689261954936943		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.7689261954936943 | validation: 0.7485417055262781]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8423361810080602		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.8423361810080602 | validation: 0.7732307647244949]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8020305705147495		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.8020305705147495 | validation: 0.8003234771571672]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863419425120408		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.7863419425120408 | validation: 0.8818936754550061]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8314802720406342		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.8314802720406342 | validation: 0.7743127770798701]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7810492730201319		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.7810492730201319 | validation: 0.7455956428817906]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665053355230562		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.7665053355230562 | validation: 0.740644432226288]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824191597720566		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.7824191597720566 | validation: 0.8622686290551645]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8226874542156131		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.8226874542156131 | validation: 0.7902092539856511]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002349789708734		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.8002349789708734 | validation: 0.826026706424771]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8006851194286754		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.8006851194286754 | validation: 0.8026860690933205]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641913262334475		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.7641913262334475 | validation: 0.7908209320381184]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759639454739405		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.759639454739405 | validation: 0.7939400425278622]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.776797139305448		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.776797139305448 | validation: 0.7987003401310426]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856100126747227		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.7856100126747227 | validation: 0.7848748732624098]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7636784210184429		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.7636784210184429 | validation: 0.7992795123891321]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012781361998429		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.8012781361998429 | validation: 0.8298617195063994]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8207174005265949		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.8207174005265949 | validation: 0.8018378429787218]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8168218157245248		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.8168218157245248 | validation: 0.8608173021890376]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8200871973837549		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.8200871973837549 | validation: 0.7826717529156599]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7656317125656893		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.7656317125656893 | validation: 0.7907288942246089]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056803217579807		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.8056803217579807 | validation: 0.8816626582820181]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7954605077729718		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.7954605077729718 | validation: 0.8201280991560365]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796637380411849		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.7796637380411849 | validation: 0.8361115352862163]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7761319773733926		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.7761319773733926 | validation: 0.7718443756682996]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7672232553066585		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.7672232553066585 | validation: 0.756752560625311]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755515663148836		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.7755515663148836 | validation: 0.796653483867463]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589583959041255		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.7589583959041255 | validation: 0.7758071077449004]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7938548540817143		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.7938548540817143 | validation: 0.8020108311338325]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625102812597924		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.7625102812597924 | validation: 0.7576126440876744]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8473007945314738		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.8473007945314738 | validation: 0.8396847139156105]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149484719645304		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.8149484719645304 | validation: 0.8082074387384327]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042968210365194		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.9042968210365194 | validation: 0.7419467710471662]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7817507453433868		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.7817507453433868 | validation: 0.806118978738245]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7719164827351574		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.7719164827351574 | validation: 0.749695579485168]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.768248108154333		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.768248108154333 | validation: 0.7982607166122465]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7754289531925083		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.7754289531925083 | validation: 0.7643811847204935]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615936503906375		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.7615936503906375 | validation: 0.7406634826874655]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.761855443031072		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.761855443031072 | validation: 0.7289957170702664]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624724704549046		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.7624724704549046 | validation: 0.7211021311562393]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7793219096547624		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.7793219096547624 | validation: 0.7295998368540856]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542564135580756		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.7542564135580756 | validation: 0.7638989247517322]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687425187736779		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.7687425187736779 | validation: 0.8128608795868516]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7961231948402157		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.7961231948402157 | validation: 0.7688466272637311]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559566401376647		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.7559566401376647 | validation: 0.7736388812843735]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605222676928327		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.7605222676928327 | validation: 0.7277687409494693]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8658253666091273		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.8658253666091273 | validation: 0.9163322600105116]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8535371320564322		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.8535371320564322 | validation: 0.7045031597981162]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7490235985085232		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.7490235985085232 | validation: 0.7881165777918075]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8041882681128465		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.8041882681128465 | validation: 0.7460333013709654]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799154304217123		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.799154304217123 | validation: 0.8425265831231888]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7905150114145897		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.7905150114145897 | validation: 0.7697057672800736]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7749512847808535		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.7749512847808535 | validation: 0.7821105680529681]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912284374998599		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.7912284374998599 | validation: 0.8539447922557983]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8239709910751384		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.8239709910751384 | validation: 0.8434059662446148]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8013778171702862		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.8013778171702862 | validation: 0.8501224405328566]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8464096912392807		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.8464096912392807 | validation: 0.7705055880990626]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7647435536580532		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.7647435536580532 | validation: 0.7767443711108265]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7539519191144132		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.7539519191144132 | validation: 0.7327259338188472]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661647801830773		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.7661647801830773 | validation: 0.7746376070602105]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525418837975607		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.7525418837975607 | validation: 0.7965067453135906]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7901260225057483		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.7901260225057483 | validation: 0.7494850692040734]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7535049129796134		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.7535049129796134 | validation: 0.74492554964295]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.772757497237653		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.772757497237653 | validation: 0.7528340948586617]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482619791533132		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.7482619791533132 | validation: 0.7669895738580295]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7633550082622683		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.7633550082622683 | validation: 0.7891397870680561]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625320307147646		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.7625320307147646 | validation: 0.7252441504432942]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7739008940078319		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.7739008940078319 | validation: 0.7375944045535898]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002717981719384		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.8002717981719384 | validation: 0.7194107965833442]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530512456788703		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.7530512456788703 | validation: 0.7443853223041427]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953202137821684		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.7953202137821684 | validation: 0.7083882272902495]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745800306806222		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.745800306806222 | validation: 0.7694037444374746]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651470606990064		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.7651470606990064 | validation: 0.7416145414212701]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8027611876055203		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.8027611876055203 | validation: 0.9230824875018013]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8866646907706495		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.8866646907706495 | validation: 0.9077567499811485]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8655495078157237		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.8655495078157237 | validation: 0.7717142838626672]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572159229384466		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.7572159229384466 | validation: 0.7352707722710343]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7419263667906981		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.7419263667906981 | validation: 0.7239553726777277]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7435271398778697		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.7435271398778697 | validation: 0.7862411492418206]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7560987198393088		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.7560987198393088 | validation: 0.7405156072100576]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7512537889770442		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.7512537889770442 | validation: 0.7385028862473201]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376367518292504		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.7376367518292504 | validation: 0.7602108823021447]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.754724135804636		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.754724135804636 | validation: 0.779190082846569]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7847800837688205		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.7847800837688205 | validation: 0.7411241702817956]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664309986836847		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.7664309986836847 | validation: 0.7191537588609859]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687614825406685		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.7687614825406685 | validation: 0.8793821617296701]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.88773208096804		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.88773208096804 | validation: 0.8136002257973667]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775425600913501		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.775425600913501 | validation: 0.752021733384174]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363867158059116		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.7363867158059116 | validation: 0.7670760469740185]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782005021611323		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.782005021611323 | validation: 0.7428514752269781]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635207863699831		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.7635207863699831 | validation: 0.7367640112969795]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437554336225464		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.7437554336225464 | validation: 0.7477384554529292]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7480242846802553		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.7480242846802553 | validation: 0.7262358603786387]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.753901272452974		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.753901272452974 | validation: 0.7155888693553112]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779885124740571		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.7779885124740571 | validation: 0.7631341835598343]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641080357747244		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.7641080357747244 | validation: 0.7257004831540553]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966470954469544		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.7966470954469544 | validation: 0.7182617365373952]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7434463780379694		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.7434463780379694 | validation: 0.7101347634903759]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7423280944603069		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.7423280944603069 | validation: 0.729199208475214]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463575359821846		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.7463575359821846 | validation: 0.7515482703342425]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744995012028221		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.744995012028221 | validation: 0.7310767213809797]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7541351473281931		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.7541351473281931 | validation: 0.7840408559975094]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7741863504751281		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.7741863504751281 | validation: 0.7249839304312107]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624330611521152		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.7624330611521152 | validation: 0.7292386000193619]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7609053759444466		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.7609053759444466 | validation: 0.7584407079401715]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7888269156683176		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.7888269156683176 | validation: 0.7054904462820014]
	TIME [epoch: 11.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7457528036652709		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.7457528036652709 | validation: 0.7191698119137638]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458213238309817		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.7458213238309817 | validation: 0.7306250611686795]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528332375908726		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.7528332375908726 | validation: 0.7247386582623677]
	TIME [epoch: 11.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496045667765634		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.7496045667765634 | validation: 0.7431348664962911]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7948884942504315		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.7948884942504315 | validation: 0.709966114708692]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661643144318385		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.7661643144318385 | validation: 0.7365663800833341]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634968377662413		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.7634968377662413 | validation: 0.7187569853473609]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565073516011536		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.7565073516011536 | validation: 0.7480489559048209]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726623722167371		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.7726623722167371 | validation: 0.8150208445512955]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545216445786256		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.8545216445786256 | validation: 0.835346501662232]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.801481756633077		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.801481756633077 | validation: 0.7170363981012207]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7502311820299956		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.7502311820299956 | validation: 0.7491638891343189]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.812194175573345		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.812194175573345 | validation: 0.8164340718291832]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7756121057681282		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.7756121057681282 | validation: 0.7359936219725277]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7512219807291818		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.7512219807291818 | validation: 0.7150617128814062]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601952092453407		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.7601952092453407 | validation: 0.7045285124692117]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7459308728202159		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.7459308728202159 | validation: 0.7066008909062248]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7441089684517548		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.7441089684517548 | validation: 0.7594748862631314]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7579631787450501		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.7579631787450501 | validation: 0.811934413870251]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104614739762848		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.8104614739762848 | validation: 0.7567514456900534]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607883599331178		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.7607883599331178 | validation: 0.76880347688591]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478972314657004		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.7478972314657004 | validation: 0.7353158327500193]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356745046149715		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.7356745046149715 | validation: 0.7075552527231882]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734725653558397		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.734725653558397 | validation: 0.7597634732762981]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406767713186935		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.7406767713186935 | validation: 0.7441862920766819]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7756304560456728		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.7756304560456728 | validation: 0.8449836649287531]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8286555385850365		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.8286555385850365 | validation: 0.7959764583782899]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826227685479727		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.7826227685479727 | validation: 0.8095966401492095]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678834244424542		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.7678834244424542 | validation: 0.7808410197766275]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7539950142675558		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.7539950142675558 | validation: 0.7558453796542404]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581471533415637		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.7581471533415637 | validation: 0.7620526812340817]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323819752792288		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.7323819752792288 | validation: 0.753945436898564]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533828638196846		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.7533828638196846 | validation: 0.7667469850751942]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425711396947416		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.7425711396947416 | validation: 0.7438210663778435]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301257225758966		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.7301257225758966 | validation: 0.7377812049150053]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341520568943422		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.7341520568943422 | validation: 0.745684872741926]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635186134765239		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.7635186134765239 | validation: 0.7697535081656559]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742420280527837		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.742420280527837 | validation: 0.7267722239067425]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402019037010324		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.7402019037010324 | validation: 0.7493939667686244]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369532432439805		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.7369532432439805 | validation: 0.7729774538123888]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7666454487081835		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.7666454487081835 | validation: 0.795706978976477]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692614469821906		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.7692614469821906 | validation: 0.7843371694736601]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7760941129523549		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.7760941129523549 | validation: 0.7331569768279556]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484047570181864		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.7484047570181864 | validation: 0.7347589384373399]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7711130505142344		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.7711130505142344 | validation: 0.7903237254450628]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090051429157255		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.8090051429157255 | validation: 0.7529006117977532]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418936644689142		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.7418936644689142 | validation: 0.769623517073133]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7781907699019939		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.7781907699019939 | validation: 0.7908625923621679]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466026075538376		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.7466026075538376 | validation: 0.7426363284091656]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476225078636043		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.7476225078636043 | validation: 0.7680207355805908]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509675239309487		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.7509675239309487 | validation: 0.7515874175300025]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577367913739067		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.7577367913739067 | validation: 0.7742904342113769]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492528444488847		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.7492528444488847 | validation: 0.7557439349070347]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7430976357092526		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.7430976357092526 | validation: 0.7378489989817988]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305263595302991		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.7305263595302991 | validation: 0.7356250962389936]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735361429447185		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.735361429447185 | validation: 0.7496472939158528]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321633663703483		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.7321633663703483 | validation: 0.7653236236933291]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7452659344295738		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.7452659344295738 | validation: 0.7560529074352446]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.753946076615664		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.753946076615664 | validation: 0.7294975880557513]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7430524257843895		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.7430524257843895 | validation: 0.7854771212042391]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458122436612109		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.7458122436612109 | validation: 0.7445728050600928]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568674101812748		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.7568674101812748 | validation: 0.758417439274467]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572143025780989		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.7572143025780989 | validation: 0.7536497927079572]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736760499720253		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.736760499720253 | validation: 0.7688881481125875]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74533618779003		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.74533618779003 | validation: 0.721055249154459]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7315225203046134		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.7315225203046134 | validation: 0.7481471007698565]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487956828364773		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.7487956828364773 | validation: 0.746690862058864]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347180547084797		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.7347180547084797 | validation: 0.7330707603096053]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447428476752473		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.7447428476752473 | validation: 0.811176673385408]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8797268464033499		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.8797268464033499 | validation: 0.8089960848297986]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688687396821539		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.7688687396821539 | validation: 0.7250031729971331]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745044876615619		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.745044876615619 | validation: 0.7603804386618894]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8021968131775691		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.8021968131775691 | validation: 0.7549419858649651]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687807796036109		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.7687807796036109 | validation: 0.7809168406585528]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912560109397041		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.7912560109397041 | validation: 0.7563969414751965]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744843881247037		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.744843881247037 | validation: 0.7364847552346846]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360054229925754		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.7360054229925754 | validation: 0.7106122524540063]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390922914557394		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.7390922914557394 | validation: 0.721906895765997]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370498808251743		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.7370498808251743 | validation: 0.720670093264724]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282711570909022		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.7282711570909022 | validation: 0.7087688211422147]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741060926948142		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.741060926948142 | validation: 0.7745592130154342]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779009411802116		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.7779009411802116 | validation: 0.7932463821368257]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8026570015676595		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.8026570015676595 | validation: 0.7163653653945385]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558358644310924		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.7558358644310924 | validation: 0.7626693776867546]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7442213520823209		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.7442213520823209 | validation: 0.7328960352528319]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7436088855618177		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.7436088855618177 | validation: 0.7807415616668593]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773036684429985		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.773036684429985 | validation: 0.7652131302355066]
	TIME [epoch: 11.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7695272551831474		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.7695272551831474 | validation: 0.8004007153806916]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911175683154891		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.7911175683154891 | validation: 0.810906890856131]
	TIME [epoch: 11.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661162031233906		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.7661162031233906 | validation: 0.7759108469006639]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525403447597965		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.7525403447597965 | validation: 0.8111431691596753]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918294470267523		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.7918294470267523 | validation: 0.7623676405716393]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351490564932618		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.7351490564932618 | validation: 0.7319497866057543]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324774410330335		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.7324774410330335 | validation: 0.7336295940309842]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243261503870014		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.7243261503870014 | validation: 0.7279608034641829]
	TIME [epoch: 11.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286095706906525		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.7286095706906525 | validation: 0.7463608275884994]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252564249595164		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.7252564249595164 | validation: 0.7441303200247873]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289514175757208		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.7289514175757208 | validation: 0.7162579954615285]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328791406362327		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.7328791406362327 | validation: 0.7244963907059335]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443845130678384		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.7443845130678384 | validation: 0.7087394579986181]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217255691834755		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.7217255691834755 | validation: 0.727346706386023]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335931925380439		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.7335931925380439 | validation: 0.7234332805274423]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260577622320461		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.7260577622320461 | validation: 0.7479050531937855]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364417244904489		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.7364417244904489 | validation: 0.7608283317462882]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7551396014613575		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.7551396014613575 | validation: 0.7512722962886208]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294673992977255		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.7294673992977255 | validation: 0.7453735568541167]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280549877406405		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.7280549877406405 | validation: 0.7462526315182751]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342655969631764		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.7342655969631764 | validation: 0.7783466605610787]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362465909143691		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.7362465909143691 | validation: 0.761025720369359]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615392250578576		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.7615392250578576 | validation: 0.8154555116630041]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7919161123211024		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.7919161123211024 | validation: 0.8037942419735009]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7719689746368358		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.7719689746368358 | validation: 0.7425257388743284]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339519538737763		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.7339519538737763 | validation: 0.7460061531918808]
	TIME [epoch: 11.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258461300709077		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.7258461300709077 | validation: 0.7553219402714004]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7521371361415922		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.7521371361415922 | validation: 0.7060830680533325]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7327350504973535		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.7327350504973535 | validation: 0.7169333014502359]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392746415112458		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.7392746415112458 | validation: 0.7045432390263265]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272702951612098		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.7272702951612098 | validation: 0.7297760268996685]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520751895817768		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.7520751895817768 | validation: 0.7040551261438109]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1211.pth
	Model improved!!!
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250405568173024		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.7250405568173024 | validation: 0.7380919114848065]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361288563775614		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.7361288563775614 | validation: 0.7611499493293699]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591941320724429		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.7591941320724429 | validation: 0.7578371884483514]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275613985352476		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.7275613985352476 | validation: 0.7323139034217416]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.729991278135372		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.729991278135372 | validation: 0.723588540125976]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236645198078313		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.7236645198078313 | validation: 0.7369536563786113]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272364852524996		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.7272364852524996 | validation: 0.7289176712989957]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247804470590514		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.7247804470590514 | validation: 0.7264562076902454]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358203905655902		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.7358203905655902 | validation: 0.7272389058688069]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427283919724111		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.7427283919724111 | validation: 0.7829855649607592]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7430764367812481		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.7430764367812481 | validation: 0.7631301636954974]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410310124460704		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.7410310124460704 | validation: 0.7723020497145123]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289546505977624		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.7289546505977624 | validation: 0.7720377113891137]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300935599644827		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.7300935599644827 | validation: 0.765297749383015]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733921566552946		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.733921566552946 | validation: 0.7419475266546519]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724375955240149		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.724375955240149 | validation: 0.7250106190400541]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276942644311832		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.7276942644311832 | validation: 0.7242636692948068]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275742536187689		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.7275742536187689 | validation: 0.7643878647720042]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653743590195418		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.7653743590195418 | validation: 0.7781320874647508]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744983837879491		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.744983837879491 | validation: 0.7470374752161799]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7344760515440109		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.7344760515440109 | validation: 0.7553627132589941]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319439458004853		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.7319439458004853 | validation: 0.763302697753158]
	TIME [epoch: 11.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575979348408973		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.7575979348408973 | validation: 0.7557479020093529]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482274921616727		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.7482274921616727 | validation: 0.7338845584568638]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265306217670564		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.7265306217670564 | validation: 0.7006102415975888]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1236.pth
	Model improved!!!
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403940780078353		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.7403940780078353 | validation: 0.7207643525454418]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724669714712165		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.724669714712165 | validation: 0.7349462688796525]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348073033686338		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.7348073033686338 | validation: 0.7392999502910058]
	TIME [epoch: 11.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7518077093986557		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.7518077093986557 | validation: 0.7650250538730896]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464672254690932		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.7464672254690932 | validation: 0.7482712245976656]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188412784703786		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.7188412784703786 | validation: 0.7516186638844076]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229117613870637		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.7229117613870637 | validation: 0.7358515146329151]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392732741521773		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.7392732741521773 | validation: 0.7488247474188302]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357306198722732		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.7357306198722732 | validation: 0.7482385308097897]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738843253375977		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.738843253375977 | validation: 0.7625008785027785]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339216365507096		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.7339216365507096 | validation: 0.7531694145484474]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287931937932781		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.7287931937932781 | validation: 0.7665704534550767]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412799324539433		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.7412799324539433 | validation: 0.7703771233752952]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476935796716092		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.7476935796716092 | validation: 0.7938208721908193]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809945982020752		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.7809945982020752 | validation: 0.7704093066316938]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427010118515265		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.7427010118515265 | validation: 0.7471457470247731]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401057823734671		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.7401057823734671 | validation: 0.757723101103494]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7284371679838554		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.7284371679838554 | validation: 0.7415948292389197]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357435151915098		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.7357435151915098 | validation: 0.7498836865419269]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72545930415172		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.72545930415172 | validation: 0.7321891396409689]
	TIME [epoch: 11.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292974399223018		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.7292974399223018 | validation: 0.7532706396374128]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332160099863783		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.7332160099863783 | validation: 0.7509233204194357]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428253344792768		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.7428253344792768 | validation: 0.7380086601572492]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.795099449593607		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.795099449593607 | validation: 0.8344478029902134]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475885211187965		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.8475885211187965 | validation: 0.7838632086225313]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764334582771519		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.7764334582771519 | validation: 0.721405538000905]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611108225497292		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.7611108225497292 | validation: 0.7521707594316972]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411378161361443		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.7411378161361443 | validation: 0.7069468518754729]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328963465228234		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.7328963465228234 | validation: 0.7348322877742249]
	TIME [epoch: 11.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243849281692074		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.7243849281692074 | validation: 0.7227116681685983]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293734095649628		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.7293734095649628 | validation: 0.7530725201263164]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542901641402002		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.7542901641402002 | validation: 0.7326129041945538]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745008055513108		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.745008055513108 | validation: 0.7327709551101883]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7298687805489481		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.7298687805489481 | validation: 0.7435986592194306]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7354345017374052		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.7354345017374052 | validation: 0.7736914204755118]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347329815304751		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.7347329815304751 | validation: 0.7477673573747055]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305955948621218		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.7305955948621218 | validation: 0.7312186482392695]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143666300054814		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.7143666300054814 | validation: 0.711031630886448]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265836356212191		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.7265836356212191 | validation: 0.7161298746516579]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238360583103141		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.7238360583103141 | validation: 0.7184191583837742]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721486892067307		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.721486892067307 | validation: 0.7256645986654122]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219047775733616		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.7219047775733616 | validation: 0.7198977830550451]
	TIME [epoch: 11.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287395402836014		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.7287395402836014 | validation: 0.724071988737352]
	TIME [epoch: 11.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279264556312832		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.7279264556312832 | validation: 0.7527936771864886]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263171703013189		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.7263171703013189 | validation: 0.7270070120987334]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182230490818479		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.7182230490818479 | validation: 0.7072510068638824]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248972383157524		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.7248972383157524 | validation: 0.7034753410487568]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246174187117007		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.7246174187117007 | validation: 0.7266917670229215]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205028447281181		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.7205028447281181 | validation: 0.7218446973120368]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370393477353151		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.7370393477353151 | validation: 0.7246299234436216]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264813443855278		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.7264813443855278 | validation: 0.7185725534870128]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508947246819453		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.7508947246819453 | validation: 0.7515738965823576]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360077722319466		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.7360077722319466 | validation: 0.7458767042678376]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270328792525137		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.7270328792525137 | validation: 0.7358726185151497]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187404211464945		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.7187404211464945 | validation: 0.7348333335897899]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719843710649839		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.719843710649839 | validation: 0.7389420865835575]
	TIME [epoch: 11.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346607870957309		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.7346607870957309 | validation: 0.7821755480101207]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808927535916911		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.7808927535916911 | validation: 0.8136939221232803]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926864161610785		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.7926864161610785 | validation: 0.8190514341822004]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826126796602714		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.7826126796602714 | validation: 0.7678791399500656]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7379924322023163		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.7379924322023163 | validation: 0.7619944342123127]
	TIME [epoch: 11.6 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7445687802435892		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.7445687802435892 | validation: 0.7689964898050174]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226575031807375		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.7226575031807375 | validation: 0.7575216434399031]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265071487009618		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.7265071487009618 | validation: 0.749863806642389]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7374651509687774		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.7374651509687774 | validation: 0.7621748019241972]
	TIME [epoch: 11.6 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458216685451755		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.7458216685451755 | validation: 0.7231814594701911]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263653908047134		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.7263653908047134 | validation: 0.7123550714081941]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246195197225251		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.7246195197225251 | validation: 0.7196806391556487]
	TIME [epoch: 11.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212902557588445		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.7212902557588445 | validation: 0.7125313737725457]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7155822179726942		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.7155822179726942 | validation: 0.7154230377051439]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195013900037374		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.7195013900037374 | validation: 0.7044773096636676]
	TIME [epoch: 11.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214146666239298		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.7214146666239298 | validation: 0.7035306044940473]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192850029718852		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.7192850029718852 | validation: 0.7069479986051885]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255882706552077		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.7255882706552077 | validation: 0.7130290165771132]
	TIME [epoch: 11.6 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707458939386504		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.707458939386504 | validation: 0.7425047605582791]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273074233433009		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.7273074233433009 | validation: 0.7182983231866491]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192779625325648		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.7192779625325648 | validation: 0.7430291631897449]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212292228543248		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.7212292228543248 | validation: 0.7206916834542741]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7152732876103354		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.7152732876103354 | validation: 0.7207368829887362]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7166011870846694		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.7166011870846694 | validation: 0.7244070892560879]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265527489744215		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.7265527489744215 | validation: 0.7477621473675737]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302885887037103		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.7302885887037103 | validation: 0.7199519451860061]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144972121796136		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.7144972121796136 | validation: 0.7381371098631629]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235077081173746		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.7235077081173746 | validation: 0.7368374063192582]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131322181917019		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.7131322181917019 | validation: 0.7257852886419969]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130131607802983		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.7130131607802983 | validation: 0.7100002339799008]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090609870338703		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.7090609870338703 | validation: 0.7075247387005511]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191850655448034		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.7191850655448034 | validation: 0.7054453116782335]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149157029177995		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.7149157029177995 | validation: 0.7160605900832618]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711427160503455		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.711427160503455 | validation: 0.7347980930841126]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349328546445432		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.7349328546445432 | validation: 0.7142223506754428]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718506895957676		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.718506895957676 | validation: 0.7022783954150661]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187522981488665		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.7187522981488665 | validation: 0.7034907705056256]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063288014072193		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.7063288014072193 | validation: 0.6999786827779301]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1330.pth
	Model improved!!!
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170602466788766		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.7170602466788766 | validation: 0.757147520939385]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509596092112095		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.7509596092112095 | validation: 0.8024249791078636]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8245290368331409		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.8245290368331409 | validation: 0.8611667913402365]
	TIME [epoch: 11.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8311760105303914		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.8311760105303914 | validation: 0.8077591743638454]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7857851677351609		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.7857851677351609 | validation: 0.7776026785245784]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7498603176935775		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.7498603176935775 | validation: 0.73267242127006]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281893069083268		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.7281893069083268 | validation: 0.713219923763329]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180168295609619		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.7180168295609619 | validation: 0.7337703721316305]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282026348401428		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.7282026348401428 | validation: 0.7210840538108464]
	TIME [epoch: 11.6 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162157518846128		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.7162157518846128 | validation: 0.718334233915127]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195579082045699		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.7195579082045699 | validation: 0.7012270325854669]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117591450861614		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.7117591450861614 | validation: 0.7080919861429874]
	TIME [epoch: 11.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135548528616098		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.7135548528616098 | validation: 0.7079977781195852]
	TIME [epoch: 11.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211042802627872		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.7211042802627872 | validation: 0.7171576420743548]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182302822032871		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.7182302822032871 | validation: 0.7040190662025338]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192208760274587		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.7192208760274587 | validation: 0.7004102786102439]
	TIME [epoch: 11.6 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099829589604		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.7099829589604 | validation: 0.6906225318686969]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1347.pth
	Model improved!!!
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204004193211394		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.7204004193211394 | validation: 0.6884758180864878]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7155215383933448		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.7155215383933448 | validation: 0.6791021239307736]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1349.pth
	Model improved!!!
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219579640049377		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.7219579640049377 | validation: 0.6857016583736117]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218269742146733		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.7218269742146733 | validation: 0.705953958296979]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716917050383342		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.716917050383342 | validation: 0.7034413916692372]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196350677331039		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.7196350677331039 | validation: 0.7075398341007245]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157521558039561		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.7157521558039561 | validation: 0.7064371904582876]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091196872244594		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.7091196872244594 | validation: 0.7072974954584692]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732860236723577		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.732860236723577 | validation: 0.7501289091647414]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324312418817044		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.7324312418817044 | validation: 0.7379690413837925]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162231862066395		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.7162231862066395 | validation: 0.7184482027273162]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084720697470177		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.7084720697470177 | validation: 0.7222783108767686]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135253077260008		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.7135253077260008 | validation: 0.7215133925795376]
	TIME [epoch: 11.6 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713447190609318		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.713447190609318 | validation: 0.7113087350637802]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107471639408829		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.7107471639408829 | validation: 0.7260221543402012]
	TIME [epoch: 11.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71682407309192		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.71682407309192 | validation: 0.7090477988649809]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7154099449892881		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.7154099449892881 | validation: 0.7264635743540823]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262796105957448		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.7262796105957448 | validation: 0.7210487322565411]
	TIME [epoch: 11.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220803698771574		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.7220803698771574 | validation: 0.7111411963314933]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7096052794637195		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.7096052794637195 | validation: 0.7293207631203182]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.715047781213761		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.715047781213761 | validation: 0.7112727880351579]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108822759232977		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.7108822759232977 | validation: 0.7261415167370392]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717138672489039		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.717138672489039 | validation: 0.7160197655150025]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709416774801874		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.709416774801874 | validation: 0.711602860472387]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217881498684675		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.7217881498684675 | validation: 0.7306483180294154]
	TIME [epoch: 11.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195840548341467		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.7195840548341467 | validation: 0.7111185490586587]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266381280903813		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.7266381280903813 | validation: 0.7059165986625209]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215000115058061		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.7215000115058061 | validation: 0.7121028437417039]
	TIME [epoch: 11.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709466970837763		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.709466970837763 | validation: 0.7108775172091708]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227418518136981		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.7227418518136981 | validation: 0.7293492701812471]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147354937265078		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.7147354937265078 | validation: 0.7200259937068796]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174042998769852		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.7174042998769852 | validation: 0.7151429669744426]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208372270053289		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.7208372270053289 | validation: 0.7216090873353472]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149980579559259		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.7149980579559259 | validation: 0.7239120578672208]
	TIME [epoch: 11.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212927770445889		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.7212927770445889 | validation: 0.7178264289618682]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120281456227875		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.7120281456227875 | validation: 0.6965680717772709]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157881332550083		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.7157881332550083 | validation: 0.7166390064815248]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188712517097989		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.7188712517097989 | validation: 0.7189759485402664]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207274994779428		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.7207274994779428 | validation: 0.7174770645269595]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716627487409852		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.716627487409852 | validation: 0.7124537957559232]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409535690479033		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.7409535690479033 | validation: 0.7754636985153681]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588319542996778		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.7588319542996778 | validation: 0.7319463501507368]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341875713378793		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.7341875713378793 | validation: 0.7550989487995482]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.747937384367296		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.747937384367296 | validation: 0.7800667634546022]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7455350344957075		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.7455350344957075 | validation: 0.7631311031078665]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289588773242165		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.7289588773242165 | validation: 0.7406997570397933]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237804977923905		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.7237804977923905 | validation: 0.7151293577911008]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716632817886593		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.716632817886593 | validation: 0.7495145237617166]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740105968414246		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.740105968414246 | validation: 0.7405466752472145]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325171104800464		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.7325171104800464 | validation: 0.7122132872569589]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222137875955799		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.7222137875955799 | validation: 0.7282585417849708]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332460767879101		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.7332460767879101 | validation: 0.6938826848686002]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159981297668961		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.7159981297668961 | validation: 0.697932958932933]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195225600600829		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.7195225600600829 | validation: 0.7163651553341183]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237279409656778		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.7237279409656778 | validation: 0.7134391175792354]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240657465259848		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.7240657465259848 | validation: 0.7048063823431687]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.715413658496721		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.715413658496721 | validation: 0.7054435594007785]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148250429158605		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.7148250429158605 | validation: 0.7317572117236083]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161496510919192		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.7161496510919192 | validation: 0.7330085002722714]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232395730579064		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.7232395730579064 | validation: 0.7224887195142913]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258894241537419		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.7258894241537419 | validation: 0.7596491718915467]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529699328381803		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.7529699328381803 | validation: 0.761253286309442]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7326208922034694		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.7326208922034694 | validation: 0.7286165619712952]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343189282479159		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.7343189282479159 | validation: 0.7386558369707372]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261928830954107		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.7261928830954107 | validation: 0.7377852567175455]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224654084940338		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.7224654084940338 | validation: 0.7452168030130379]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109463146996813		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.7109463146996813 | validation: 0.7274583263370203]
	TIME [epoch: 11.6 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135388798771894		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.7135388798771894 | validation: 0.7229818056005145]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173900488859873		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.7173900488859873 | validation: 0.7211235082799733]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169317252252929		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.7169317252252929 | validation: 0.697676793294926]
	TIME [epoch: 11.6 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074118256852664		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.7074118256852664 | validation: 0.7138576664285907]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141004120238619		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.7141004120238619 | validation: 0.705307018250597]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140852554204659		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.7140852554204659 | validation: 0.6939524024520229]
	TIME [epoch: 11.6 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704649592260667		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.704649592260667 | validation: 0.7158114226856815]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146837277025002		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.7146837277025002 | validation: 0.6934273216967943]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132515264850797		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.7132515264850797 | validation: 0.7310833896981678]
	TIME [epoch: 11.6 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476776533149663		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.7476776533149663 | validation: 0.7498594652573398]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322779983004012		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.7322779983004012 | validation: 0.7091464814011239]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130012268655332		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.7130012268655332 | validation: 0.7081428893234814]
	TIME [epoch: 11.6 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115015580025108		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.7115015580025108 | validation: 0.7109294636634891]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047516791526814		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.7047516791526814 | validation: 0.7036898763012703]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228037838665141		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.7228037838665141 | validation: 0.7100654210424956]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148871449279436		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.7148871449279436 | validation: 0.6981894465587847]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007585521512973		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.7007585521512973 | validation: 0.7211769090730508]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185090018309328		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.7185090018309328 | validation: 0.7180428082167524]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209466658822442		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.7209466658822442 | validation: 0.7000415773375867]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109499262612176		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.7109499262612176 | validation: 0.7255443520427772]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7151289024470794		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.7151289024470794 | validation: 0.7005021483839934]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146436263600386		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.7146436263600386 | validation: 0.7227588070349108]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159386135315285		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.7159386135315285 | validation: 0.7028264640599254]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207223775377398		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.7207223775377398 | validation: 0.7184069278493403]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217520296878113		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.7217520296878113 | validation: 0.6909826350955404]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157958347514815		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.7157958347514815 | validation: 0.6997825180919296]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131028394810173		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.7131028394810173 | validation: 0.7096010889954485]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191887947791824		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.7191887947791824 | validation: 0.686897913178627]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113076383393393		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.7113076383393393 | validation: 0.7089486180734562]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7155370463457952		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.7155370463457952 | validation: 0.7061416007348104]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173372266889368		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.7173372266889368 | validation: 0.716301808027428]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282201516265912		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.7282201516265912 | validation: 0.7137702334950137]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292174879459994		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.7292174879459994 | validation: 0.7188976494589429]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147177888562412		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.7147177888562412 | validation: 0.7115793894528628]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140016284779749		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.7140016284779749 | validation: 0.7139813169104469]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712772002186103		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.712772002186103 | validation: 0.7122236783572313]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260330666349462		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.7260330666349462 | validation: 0.6923299941429099]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201546460887069		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.7201546460887069 | validation: 0.6907498314666887]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255882684138539		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.7255882684138539 | validation: 0.6910047544218714]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192468702014503		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.7192468702014503 | validation: 0.6987537360740871]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161589719853609		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.7161589719853609 | validation: 0.6988604000768046]
	TIME [epoch: 11.6 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283183384501759		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.7283183384501759 | validation: 0.7213405370021596]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415619819724826		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.7415619819724826 | validation: 0.73451049605435]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411051632318446		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.7411051632318446 | validation: 0.7184442317781544]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141702246420549		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.7141702246420549 | validation: 0.7071994205413629]
	TIME [epoch: 11.6 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7114296954975953		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.7114296954975953 | validation: 0.7153785115916362]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991983242293827		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.6991983242293827 | validation: 0.7149234819155345]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235086726012645		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.7235086726012645 | validation: 0.7162981136182808]
	TIME [epoch: 11.6 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725870811097026		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.725870811097026 | validation: 0.7162995945047896]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410034525566053		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.7410034525566053 | validation: 0.7701328205301283]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7436826092691935		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.7436826092691935 | validation: 0.7458098129592347]
	TIME [epoch: 11.6 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353537478195505		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.7353537478195505 | validation: 0.7314350088927347]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293062882741739		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.7293062882741739 | validation: 0.7309148249926901]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721908499130058		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.721908499130058 | validation: 0.7245600166507385]
	TIME [epoch: 11.6 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231688968488192		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.7231688968488192 | validation: 0.7392075112974007]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302200472534135		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.7302200472534135 | validation: 0.7557517874048676]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290155483994851		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.7290155483994851 | validation: 0.7204189895006167]
	TIME [epoch: 11.6 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294292480659958		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.7294292480659958 | validation: 0.7227927382950132]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213895093342712		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.7213895093342712 | validation: 0.703948036823573]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140873096613667		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.7140873096613667 | validation: 0.709937839346163]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144487942471043		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.7144487942471043 | validation: 0.7155465694100486]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7150884125010863		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.7150884125010863 | validation: 0.7178063167985148]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266303098600257		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.7266303098600257 | validation: 0.7488900582538895]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7145160516603215		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.7145160516603215 | validation: 0.7571758978146119]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223160875319764		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.7223160875319764 | validation: 0.7300934432809263]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188276958402198		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.7188276958402198 | validation: 0.7324483291159498]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156016667837892		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.7156016667837892 | validation: 0.7216829684203694]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147139356311536		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.7147139356311536 | validation: 0.7282648102469693]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109084789120804		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.7109084789120804 | validation: 0.7162366868519123]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707077320584224		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.707077320584224 | validation: 0.7146673223691371]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70899171943457		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.70899171943457 | validation: 0.7020485537189869]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138148233688282		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.7138148233688282 | validation: 0.7206721014498502]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160563447181207		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.7160563447181207 | validation: 0.7083993515863272]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055031758374338		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.7055031758374338 | validation: 0.7119484621983759]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132373917717614		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.7132373917717614 | validation: 0.6993965559878853]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236660851967567		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.7236660851967567 | validation: 0.7146873307718928]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161492998016973		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.7161492998016973 | validation: 0.7060111222409244]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720555648420077		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.720555648420077 | validation: 0.7189899019016304]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192610892497335		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.7192610892497335 | validation: 0.7094131209117245]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721532551233705		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.721532551233705 | validation: 0.7012169764320482]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205461959946224		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.7205461959946224 | validation: 0.7229783910320058]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289279756380559		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.7289279756380559 | validation: 0.7124915594984345]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7128463039573878		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.7128463039573878 | validation: 0.7095220930299502]
	TIME [epoch: 11.6 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71406519720212		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.71406519720212 | validation: 0.7001394720901886]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094789562492898		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.7094789562492898 | validation: 0.7065576245250276]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156829891668868		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.7156829891668868 | validation: 0.6938116185723445]
	TIME [epoch: 11.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149181409338307		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.7149181409338307 | validation: 0.7181296035565754]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295033346865757		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.7295033346865757 | validation: 0.7037798503565642]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231470047634021		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.7231470047634021 | validation: 0.6975810455097136]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196592222819208		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.7196592222819208 | validation: 0.6856553793610752]
	TIME [epoch: 11.6 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176126561227875		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.7176126561227875 | validation: 0.6905996904319395]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711380021396846		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.711380021396846 | validation: 0.6917999663243748]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090537326070985		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.7090537326070985 | validation: 0.7080349984148978]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071576014092926		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.7071576014092926 | validation: 0.6901334726687891]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110332669287646		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.7110332669287646 | validation: 0.7053402814818901]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708934638086764		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.708934638086764 | validation: 0.7098384758484937]
	TIME [epoch: 11.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724322591621752		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.724322591621752 | validation: 0.7156817862405755]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200588258605308		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.7200588258605308 | validation: 0.7233769950485172]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220220803562032		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.7220220803562032 | validation: 0.7078414021304731]
	TIME [epoch: 11.6 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091215814018704		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.7091215814018704 | validation: 0.7069704525666332]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710533202172687		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.710533202172687 | validation: 0.7133212432053381]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063105223750616		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.7063105223750616 | validation: 0.7155928395497732]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095216079034035		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.7095216079034035 | validation: 0.7079091721992987]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191419495882692		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.7191419495882692 | validation: 0.6977438381400438]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062718304647506		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.7062718304647506 | validation: 0.7099042279404574]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032556180748223		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.7032556180748223 | validation: 0.7002352839666369]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082140989214609		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.7082140989214609 | validation: 0.6984225327610013]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050144709734953		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.7050144709734953 | validation: 0.7089118335919952]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052183213613898		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.7052183213613898 | validation: 0.7048139327795171]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112122101020608		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.7112122101020608 | validation: 0.7190033284665728]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148547604480655		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.7148547604480655 | validation: 0.7062250457832417]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066813425505376		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.7066813425505376 | validation: 0.7076677818744435]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706602625103393		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.706602625103393 | validation: 0.7121524822827577]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037242834684574		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.7037242834684574 | validation: 0.7020827375749841]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083746264747461		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.7083746264747461 | validation: 0.7041933108860178]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7096866047852872		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.7096866047852872 | validation: 0.6970919765193102]
	TIME [epoch: 11.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071856560181162		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.7071856560181162 | validation: 0.6994445728327852]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070752349525933		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.7070752349525933 | validation: 0.6989027026987964]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705002064072502		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.705002064072502 | validation: 0.7054098639635471]
	TIME [epoch: 11.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073811725451125		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.7073811725451125 | validation: 0.6925285272543726]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078953103136993		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.7078953103136993 | validation: 0.710557659733266]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034800004636823		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.7034800004636823 | validation: 0.7117313124971998]
	TIME [epoch: 11.6 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157993600877997		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.7157993600877997 | validation: 0.7141213394634974]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234880924215259		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.7234880924215259 | validation: 0.7138969248596644]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131281039087253		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.7131281039087253 | validation: 0.7076507161164379]
	TIME [epoch: 11.6 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105267842663849		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.7105267842663849 | validation: 0.713306998677763]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7025843833236929		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.7025843833236929 | validation: 0.708334868941931]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026990315874257		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.7026990315874257 | validation: 0.6915377528550299]
	TIME [epoch: 11.6 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062748745389		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.7062748745389 | validation: 0.7085192277603161]
	TIME [epoch: 11.6 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053339656000078		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.7053339656000078 | validation: 0.719177596257392]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130683429959372		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.7130683429959372 | validation: 0.7022026959776622]
	TIME [epoch: 11.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126271768761331		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.7126271768761331 | validation: 0.7098927294473677]
	TIME [epoch: 11.6 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090764269801363		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.7090764269801363 | validation: 0.7294449608301145]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044717431342782		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.7044717431342782 | validation: 0.6975568053051348]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700818310277535		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.700818310277535 | validation: 0.699615570784932]
	TIME [epoch: 11.6 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707000859601155		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.707000859601155 | validation: 0.7140854732841413]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116931582956185		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.7116931582956185 | validation: 0.7014591428682039]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206445324242645		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.7206445324242645 | validation: 0.6911368434087519]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713199775095981		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.713199775095981 | validation: 0.7029937911074046]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148492085713966		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.7148492085713966 | validation: 0.6927305328177628]
	TIME [epoch: 11.6 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094880474713434		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.7094880474713434 | validation: 0.6986368203916361]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131038567140685		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.7131038567140685 | validation: 0.6987005448232997]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061435378296804		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.7061435378296804 | validation: 0.6899676458898725]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102513354394557		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.7102513354394557 | validation: 0.6892697025523344]
	TIME [epoch: 11.6 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143593316902365		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.7143593316902365 | validation: 0.7030131138882416]
	TIME [epoch: 11.6 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061520776551661		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.7061520776551661 | validation: 0.6996404410961631]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713821312369593		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.713821312369593 | validation: 0.7057123403718899]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174336680270808		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.7174336680270808 | validation: 0.7134087680567786]
	TIME [epoch: 11.6 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176387391387338		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.7176387391387338 | validation: 0.6812653716352878]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070484794280019		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.7070484794280019 | validation: 0.6925805476443843]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018519121251968		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.7018519121251968 | validation: 0.6884746938398553]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7046396892847014		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.7046396892847014 | validation: 0.6848657574153154]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708115452423349		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.708115452423349 | validation: 0.6886779696816839]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063688422303489		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.7063688422303489 | validation: 0.6911290051898686]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217979760252515		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.7217979760252515 | validation: 0.7022416041463009]
	TIME [epoch: 11.6 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148423082556388		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.7148423082556388 | validation: 0.6994224952685323]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100780679971009		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.7100780679971009 | validation: 0.6978667018715181]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051172577473056		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.7051172577473056 | validation: 0.6851253013420859]
	TIME [epoch: 11.6 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066800955819137		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.7066800955819137 | validation: 0.6858634837498911]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021058213121458		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.7021058213121458 | validation: 0.7032230228860662]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023308058735545		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.7023308058735545 | validation: 0.7028360803327118]
	TIME [epoch: 11.6 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088224095174634		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.7088224095174634 | validation: 0.7060724322673632]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015239735792251		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.7015239735792251 | validation: 0.6863142960216283]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990331936743385		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.6990331936743385 | validation: 0.6850200650020212]
	TIME [epoch: 11.6 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024820384588302		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.7024820384588302 | validation: 0.6975412421013756]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084753042375034		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.7084753042375034 | validation: 0.6972111519614461]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7136754723407771		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.7136754723407771 | validation: 0.7020140906872212]
	TIME [epoch: 11.6 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089825780373122		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.7089825780373122 | validation: 0.705155819795885]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064508059061522		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.7064508059061522 | validation: 0.6975751136001279]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979639640704146		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.6979639640704146 | validation: 0.701649133099522]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034335244218424		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.7034335244218424 | validation: 0.705300257210161]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703319166045361		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.703319166045361 | validation: 0.70259350460994]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038497453602561		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.7038497453602561 | validation: 0.7026556976731638]
	TIME [epoch: 11.6 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085364498595901		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.7085364498595901 | validation: 0.6807134380789037]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041369349694955		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.7041369349694955 | validation: 0.7033273142312874]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067694964951747		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.7067694964951747 | validation: 0.6974256407132201]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711878192289788		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.711878192289788 | validation: 0.687538241251445]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051677950170042		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.7051677950170042 | validation: 0.694146344823283]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026897413859674		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.7026897413859674 | validation: 0.6939962170968417]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079433483618149		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.7079433483618149 | validation: 0.701807829646233]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036947001491246		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.7036947001491246 | validation: 0.705301001165819]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059214470208519		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.7059214470208519 | validation: 0.6989462595776476]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70701608800277		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.70701608800277 | validation: 0.6989554693236414]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7035927939158396		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.7035927939158396 | validation: 0.7018705273916939]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132278719997635		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.7132278719997635 | validation: 0.7090729658033361]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116420223444246		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.7116420223444246 | validation: 0.7003351775288479]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991262784067682		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.6991262784067682 | validation: 0.7051064522235313]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032705109237519		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.7032705109237519 | validation: 0.6929327837575368]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107877793387488		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.7107877793387488 | validation: 0.693308036006553]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058242224456804		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.7058242224456804 | validation: 0.6890880906031108]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052399189733267		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.7052399189733267 | validation: 0.7024964663394192]
	TIME [epoch: 11.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047835179391194		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.7047835179391194 | validation: 0.6909904154348578]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052935298280786		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.7052935298280786 | validation: 0.680852572792806]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111174279496827		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.7111174279496827 | validation: 0.6771153537829844]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1608.pth
	Model improved!!!
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049528286589881		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.7049528286589881 | validation: 0.6949995979516705]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064649622844295		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.7064649622844295 | validation: 0.6819627240534059]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7142211271862575		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.7142211271862575 | validation: 0.7022162701306576]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026921414831719		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.7026921414831719 | validation: 0.6832060185396607]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7025335773236571		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.7025335773236571 | validation: 0.6955314050599364]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033945266689178		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.7033945266689178 | validation: 0.6997298582186865]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006558713042794		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.7006558713042794 | validation: 0.6982009300104318]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962894942207857		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.6962894942207857 | validation: 0.7053519275550565]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058912881669235		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.7058912881669235 | validation: 0.6919279428834051]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019897023202268		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.7019897023202268 | validation: 0.7006995031850329]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985420645325805		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.6985420645325805 | validation: 0.6855374766021015]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6981633589893804		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.6981633589893804 | validation: 0.6964730839363824]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988054748831342		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.6988054748831342 | validation: 0.6865560249780146]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023394951017585		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.7023394951017585 | validation: 0.6924372490864434]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110367269379458		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.7110367269379458 | validation: 0.7114459488842277]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075746274933886		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.7075746274933886 | validation: 0.7077969201494108]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089089181863655		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.7089089181863655 | validation: 0.6862236607732172]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7056070320841401		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.7056070320841401 | validation: 0.6941994706306333]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704311662436637		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.704311662436637 | validation: 0.6968401375429784]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110024843727069		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.7110024843727069 | validation: 0.7032712350800656]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7153934385766476		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.7153934385766476 | validation: 0.7020642266384064]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159199155300938		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.7159199155300938 | validation: 0.720143112456491]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266905937350495		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.7266905937350495 | validation: 0.7192437444571464]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7145700337424834		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.7145700337424834 | validation: 0.7010738002618703]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041202755782937		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.7041202755782937 | validation: 0.7061075738231648]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048184346357431		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.7048184346357431 | validation: 0.7139922140538468]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061344028636771		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.7061344028636771 | validation: 0.7067476873369981]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044801928329063		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.7044801928329063 | validation: 0.6971453349527872]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065722883344868		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.7065722883344868 | validation: 0.7055469645552576]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084155282423743		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.7084155282423743 | validation: 0.6982887757011744]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074524151890276		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.7074524151890276 | validation: 0.689797373151879]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039469720292859		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.7039469720292859 | validation: 0.6933396385245295]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051545413987839		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.7051545413987839 | validation: 0.692067463765124]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033366603916466		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.7033366603916466 | validation: 0.6955570911426641]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7069278997197533		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.7069278997197533 | validation: 0.694880356074736]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044035253934654		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.7044035253934654 | validation: 0.6942400566605454]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034838030795738		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.7034838030795738 | validation: 0.7007650547713975]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045165567703191		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.7045165567703191 | validation: 0.7013642341986368]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026809496076698		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.7026809496076698 | validation: 0.6975762134767558]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706539900083677		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.706539900083677 | validation: 0.7036787547099869]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983274739837422		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.6983274739837422 | validation: 0.6993744958238037]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049597291052057		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.7049597291052057 | validation: 0.7128445018214646]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032027148293869		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.7032027148293869 | validation: 0.7003486636672779]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6987101869634074		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.6987101869634074 | validation: 0.6973925810081357]
	TIME [epoch: 11.6 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7001076191534428		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.7001076191534428 | validation: 0.7063950349062228]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005343389134944		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.7005343389134944 | validation: 0.7108300254094158]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048625339778393		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.7048625339778393 | validation: 0.6920943719266712]
	TIME [epoch: 11.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105800113565189		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.7105800113565189 | validation: 0.7015408495560338]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133334806318361		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.7133334806318361 | validation: 0.6978768202486512]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7166927698886884		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.7166927698886884 | validation: 0.7052744230539781]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175000273343516		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.7175000273343516 | validation: 0.7077076778505679]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103917517294793		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.7103917517294793 | validation: 0.6975393353371752]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237703104432343		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.7237703104432343 | validation: 0.7021678444751698]
	TIME [epoch: 11.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253128366735806		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.7253128366735806 | validation: 0.703970261582652]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085549269124393		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.7085549269124393 | validation: 0.6859322914822225]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103880752488679		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.7103880752488679 | validation: 0.6938453232073593]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070383625733289		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.7070383625733289 | validation: 0.700623816788903]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019474823132232		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.7019474823132232 | validation: 0.6850180270305711]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073648021635809		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.7073648021635809 | validation: 0.6952113347532867]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075278271979415		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.7075278271979415 | validation: 0.6839272499592473]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700753221732924		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.700753221732924 | validation: 0.6885603297806779]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009746298321339		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.7009746298321339 | validation: 0.6779842538088062]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027230531261137		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.7027230531261137 | validation: 0.6854925801413633]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707802705897454		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.707802705897454 | validation: 0.6824866502450473]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702149401708271		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.702149401708271 | validation: 0.6846530072564386]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6975956419960818		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.6975956419960818 | validation: 0.6912101246483533]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027480467048663		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.7027480467048663 | validation: 0.6940955819803574]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993733295775768		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.6993733295775768 | validation: 0.6921235258792894]
	TIME [epoch: 11.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008813151448116		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.7008813151448116 | validation: 0.6825743663520176]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971006523037404		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.6971006523037404 | validation: 0.6949504674505783]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701159867252738		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.701159867252738 | validation: 0.6874541592251285]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027464448839171		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.7027464448839171 | validation: 0.7019940017330291]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033802652443197		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.7033802652443197 | validation: 0.6887033345328087]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109814777659195		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.7109814777659195 | validation: 0.7034468508662302]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100376396256355		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.7100376396256355 | validation: 0.7035571582768152]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712220362096022		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.712220362096022 | validation: 0.6973966915507726]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116510992395515		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.7116510992395515 | validation: 0.6932840138034887]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060764952298029		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.7060764952298029 | validation: 0.7001361510437186]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088402448560296		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.7088402448560296 | validation: 0.7102458962216458]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176061237010186		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.7176061237010186 | validation: 0.7114808917196718]
	TIME [epoch: 11.6 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070708919745108		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.7070708919745108 | validation: 0.6987707609798625]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064165910136949		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.7064165910136949 | validation: 0.697603688588419]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082198135328195		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.7082198135328195 | validation: 0.6873279504127348]
	TIME [epoch: 11.6 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049598488810656		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.7049598488810656 | validation: 0.682700538147746]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007844923433115		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.7007844923433115 | validation: 0.6835122337368084]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968602865022686		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.6968602865022686 | validation: 0.681049925387338]
	TIME [epoch: 11.6 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040050223211998		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.7040050223211998 | validation: 0.6959658384472017]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016497822430579		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.7016497822430579 | validation: 0.6932093031892945]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972614133019276		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.6972614133019276 | validation: 0.6941865531806823]
	TIME [epoch: 11.6 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037564789739075		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.7037564789739075 | validation: 0.6931686478518863]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059445163159772		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.7059445163159772 | validation: 0.6836681242986353]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7166117635502127		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.7166117635502127 | validation: 0.6896664506536005]
	TIME [epoch: 11.6 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079960950933107		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.7079960950933107 | validation: 0.6961569241368051]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173423550103217		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.7173423550103217 | validation: 0.6839216949965942]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7081648409208177		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.7081648409208177 | validation: 0.6855756445328121]
	TIME [epoch: 11.6 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988992451796352		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.6988992451796352 | validation: 0.6858723640022691]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005680121439903		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.7005680121439903 | validation: 0.6879399077201401]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002693687338601		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.7002693687338601 | validation: 0.6897454972400885]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982919098942942		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.6982919098942942 | validation: 0.6870784980939701]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7046899887502033		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.7046899887502033 | validation: 0.6768428049995234]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1708.pth
	Model improved!!!
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044869542927347		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.7044869542927347 | validation: 0.6917905257583646]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699965828877883		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.699965828877883 | validation: 0.6785221370824981]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698327928953405		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.698327928953405 | validation: 0.6935023506575374]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028433270771005		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.7028433270771005 | validation: 0.6789528803400271]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032622276864882		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.7032622276864882 | validation: 0.6737700416562942]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1713.pth
	Model improved!!!
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021485400083816		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.7021485400083816 | validation: 0.6789976024635918]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042012571340763		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.7042012571340763 | validation: 0.6870921228813572]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709230327711321		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.709230327711321 | validation: 0.6781822711531496]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986031000660373		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.6986031000660373 | validation: 0.6717693491502204]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1717.pth
	Model improved!!!
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954720326525945		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.6954720326525945 | validation: 0.6936769593241067]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062808979064492		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.7062808979064492 | validation: 0.6868674556804607]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954223122957309		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.6954223122957309 | validation: 0.6903517242437033]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692953987325198		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.692953987325198 | validation: 0.6797514402920569]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037640832659356		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.7037640832659356 | validation: 0.6828526919320769]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015865954736472		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.7015865954736472 | validation: 0.6815396991765172]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063717235878169		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.7063717235878169 | validation: 0.6916381441265108]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013131387366875		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.7013131387366875 | validation: 0.6762366686095374]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053769898672095		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.7053769898672095 | validation: 0.6921223964682449]
	TIME [epoch: 11.6 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049407048308773		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.7049407048308773 | validation: 0.6977367753117345]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031922003773595		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.7031922003773595 | validation: 0.7042804356508978]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016069602292891		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.7016069602292891 | validation: 0.6985914551970471]
	TIME [epoch: 11.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018657958191817		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.7018657958191817 | validation: 0.6856082466106369]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991560710371579		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.6991560710371579 | validation: 0.6926544903260939]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952471238622481		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.6952471238622481 | validation: 0.6898730884243153]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007436475046469		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.7007436475046469 | validation: 0.6917866527567879]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902403992530849		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.6902403992530849 | validation: 0.6915010431758793]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977240471506115		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.6977240471506115 | validation: 0.6891320358317009]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027330977246192		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.7027330977246192 | validation: 0.6917731187246119]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990226618374906		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.6990226618374906 | validation: 0.6992704946807702]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955927603951437		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.6955927603951437 | validation: 0.6920391640819696]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979609862013518		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.6979609862013518 | validation: 0.6936856225956004]
	TIME [epoch: 11.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055484043096969		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.7055484043096969 | validation: 0.6863998605541238]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692426001287974		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.692426001287974 | validation: 0.703004599834548]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699780406505899		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.699780406505899 | validation: 0.6911131035605539]
	TIME [epoch: 11.6 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989834208413491		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.6989834208413491 | validation: 0.6927239292290834]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009054730261715		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.7009054730261715 | validation: 0.6988825890354415]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703553038389427		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.703553038389427 | validation: 0.7024026398435512]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7017804540952678		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.7017804540952678 | validation: 0.6888331133681135]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012802091552921		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.7012802091552921 | validation: 0.6961852891898344]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907239828310063		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.6907239828310063 | validation: 0.6793007803351889]
	TIME [epoch: 11.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042294773345189		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.7042294773345189 | validation: 0.7043740046576897]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694999709828638		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.694999709828638 | validation: 0.7054114490326893]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907776412893403		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.6907776412893403 | validation: 0.6968615000944814]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6933123670509895		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.6933123670509895 | validation: 0.682904261320321]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005464694936212		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.7005464694936212 | validation: 0.6913941086056044]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701848724776573		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.701848724776573 | validation: 0.6923384561024443]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043850995733133		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.7043850995733133 | validation: 0.6911274537441042]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064491763205649		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.7064491763205649 | validation: 0.6904840637830043]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6995614740278795		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.6995614740278795 | validation: 0.6975106192843833]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991301114076925		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.6991301114076925 | validation: 0.6997812110535508]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990355983787995		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.6990355983787995 | validation: 0.6841109080189404]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974665049558019		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.6974665049558019 | validation: 0.6879743006325038]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988652636387895		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.6988652636387895 | validation: 0.6829499241008842]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903393592537388		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.6903393592537388 | validation: 0.6868510819118978]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005749573510944		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.7005749573510944 | validation: 0.6770237628357734]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012250063261284		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.7012250063261284 | validation: 0.6829975137652644]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943323754728437		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.6943323754728437 | validation: 0.6828927922864219]
	TIME [epoch: 11.6 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040357241275667		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.7040357241275667 | validation: 0.703748558541566]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966753599781486		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.6966753599781486 | validation: 0.6991311110149157]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962213745978987		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.6962213745978987 | validation: 0.6974842156700376]
	TIME [epoch: 11.6 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6959175173955894		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.6959175173955894 | validation: 0.7005348316072998]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073455499853336		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.7073455499853336 | validation: 0.7070334468831969]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037260171483136		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.7037260171483136 | validation: 0.6833664931422629]
	TIME [epoch: 11.6 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047871907204348		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.7047871907204348 | validation: 0.7054888635939764]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989751155813733		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.6989751155813733 | validation: 0.6927973721929235]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032355379265178		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.7032355379265178 | validation: 0.7092408590059935]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086914676607939		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.7086914676607939 | validation: 0.7156809670184383]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057555383393845		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.7057555383393845 | validation: 0.6824888575629185]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028592789928958		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.7028592789928958 | validation: 0.6927750581328301]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094140056540426		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.7094140056540426 | validation: 0.712973230623557]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135737712472857		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.7135737712472857 | validation: 0.7137380522596048]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7101529200581962		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.7101529200581962 | validation: 0.700664838018901]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161176507631231		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.7161176507631231 | validation: 0.7168136757105618]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979707553283185		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.6979707553283185 | validation: 0.6948014265851474]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089675063888073		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.7089675063888073 | validation: 0.7044600633570707]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031811884738675		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.7031811884738675 | validation: 0.6891002121668579]
	TIME [epoch: 11.6 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7001297532007663		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.7001297532007663 | validation: 0.68268312812316]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970269023855922		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.6970269023855922 | validation: 0.7097648116034279]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993049880626029		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.6993049880626029 | validation: 0.6803215695076879]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924804960249598		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.6924804960249598 | validation: 0.7051943220000156]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021715912074357		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.7021715912074357 | validation: 0.6888045759222393]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047933920424156		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.7047933920424156 | validation: 0.6913481766091024]
	TIME [epoch: 11.6 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027229721183574		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.7027229721183574 | validation: 0.691967810182659]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028912400824028		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.7028912400824028 | validation: 0.6960229388202234]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976436200708748		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.6976436200708748 | validation: 0.6966925675413836]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6981445365245647		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.6981445365245647 | validation: 0.7033180593586573]
	TIME [epoch: 11.6 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973351605235862		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.6973351605235862 | validation: 0.6921968809060058]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968719537302523		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.6968719537302523 | validation: 0.7034370773357803]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698239570933458		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.698239570933458 | validation: 0.7000684795725816]
	TIME [epoch: 11.6 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049809853219687		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.7049809853219687 | validation: 0.7061540442232155]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6959725067742341		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.6959725067742341 | validation: 0.6906500754650545]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033925139134982		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.7033925139134982 | validation: 0.7028697818943269]
	TIME [epoch: 11.6 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071830631940406		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.7071830631940406 | validation: 0.6979193401386123]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954834178502425		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.6954834178502425 | validation: 0.6977961610794244]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984433242794439		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.6984433242794439 | validation: 0.6988277582225847]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965095212511552		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.6965095212511552 | validation: 0.6830126167675253]
	TIME [epoch: 11.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994648049377803		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.6994648049377803 | validation: 0.6928571577920468]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934964689151455		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.6934964689151455 | validation: 0.6854217632140975]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703015937530412		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.703015937530412 | validation: 0.679334543843104]
	TIME [epoch: 11.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962032838974493		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.6962032838974493 | validation: 0.6996766764810215]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698590627051012		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.698590627051012 | validation: 0.6942438566228907]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036825874879458		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.7036825874879458 | validation: 0.6871779787078137]
	TIME [epoch: 11.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014659211374358		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.7014659211374358 | validation: 0.6936625169290485]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698907288513599		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.698907288513599 | validation: 0.6860542599719566]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6969527172586982		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.6969527172586982 | validation: 0.6768584590091876]
	TIME [epoch: 11.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007028323871513		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.7007028323871513 | validation: 0.6955916050343651]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026712097248431		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.7026712097248431 | validation: 0.6848148399543791]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029572148419098		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.7029572148419098 | validation: 0.6944362304345895]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005246864224304		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.7005246864224304 | validation: 0.6942095125127363]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022322634699222		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.7022322634699222 | validation: 0.699177504744397]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102618076492394		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.7102618076492394 | validation: 0.6919259974224603]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079639967436521		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.7079639967436521 | validation: 0.7007014655618921]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060315801117121		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.7060315801117121 | validation: 0.6994026187407579]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058590617083285		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.7058590617083285 | validation: 0.6998506964866644]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709110312847866		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.709110312847866 | validation: 0.6906397564901561]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954151696255753		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.6954151696255753 | validation: 0.6999160038563857]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080081903947912		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.7080081903947912 | validation: 0.6881932474513335]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006764505039854		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.7006764505039854 | validation: 0.6926454197102447]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983164881120066		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.6983164881120066 | validation: 0.6932132588743078]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992097727763622		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.6992097727763622 | validation: 0.6881827172805238]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973990259674423		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.6973990259674423 | validation: 0.6907952139083813]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027191378729378		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.7027191378729378 | validation: 0.6830284692527425]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003161284168645		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.7003161284168645 | validation: 0.6950149873714924]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903719484321343		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.6903719484321343 | validation: 0.6856390329810439]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972719071472302		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.6972719071472302 | validation: 0.6813857801235045]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955935930987165		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.6955935930987165 | validation: 0.6740068793551544]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992744250357731		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.6992744250357731 | validation: 0.6895255603093762]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967033370636844		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.6967033370636844 | validation: 0.6795393102634991]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019030974586794		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.7019030974586794 | validation: 0.6892585062585209]
	TIME [epoch: 11.6 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018733683155167		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.7018733683155167 | validation: 0.6891913371055154]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041515406560839		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.7041515406560839 | validation: 0.6919075160540539]
	TIME [epoch: 11.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976505835411957		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.6976505835411957 | validation: 0.6919246950607021]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039162349555409		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.7039162349555409 | validation: 0.6877973079546738]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947228667505315		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.6947228667505315 | validation: 0.679188623032274]
	TIME [epoch: 11.6 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945317344366584		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.6945317344366584 | validation: 0.6918264105369244]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936521063740345		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.6936521063740345 | validation: 0.7027839421716294]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977008162251411		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.6977008162251411 | validation: 0.6909599683181368]
	TIME [epoch: 11.6 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963535791640778		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.6963535791640778 | validation: 0.699695693887583]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6975730603371542		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.6975730603371542 | validation: 0.6911094775529888]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972109386509078		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.6972109386509078 | validation: 0.6864908024319977]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042503005072016		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.7042503005072016 | validation: 0.6836485508886107]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962857753778053		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.6962857753778053 | validation: 0.6920383474057078]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695490633101626		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.695490633101626 | validation: 0.695083057512272]
	TIME [epoch: 11.6 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7035863487728324		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.7035863487728324 | validation: 0.6996469599441764]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700059732381733		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.700059732381733 | validation: 0.6882369806247728]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030594232153855		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.7030594232153855 | validation: 0.6872632653144194]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030875328738158		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.7030875328738158 | validation: 0.6947089428473419]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951101494853487		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.6951101494853487 | validation: 0.6839131325156464]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036646282384784		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.7036646282384784 | validation: 0.6934265422934444]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989117930931618		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.6989117930931618 | validation: 0.6933912897136513]
	TIME [epoch: 11.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004803965448503		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.7004803965448503 | validation: 0.6927573816568494]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69452742380794		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.69452742380794 | validation: 0.6711592006329872]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1860.pth
	Model improved!!!
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999942699424829		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.6999942699424829 | validation: 0.6920429989832135]
	TIME [epoch: 11.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016817408571878		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.7016817408571878 | validation: 0.6943446600541643]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010838770926245		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.7010838770926245 | validation: 0.7001199821237936]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039862341952416		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.7039862341952416 | validation: 0.695603050931451]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910229242726706		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.6910229242726706 | validation: 0.6894498677016277]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952565990874942		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.6952565990874942 | validation: 0.6922048839879493]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011624609581995		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.7011624609581995 | validation: 0.6888309029533273]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976495871004003		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.6976495871004003 | validation: 0.6903480454277476]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047103418139741		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.7047103418139741 | validation: 0.7018792815748972]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986288150237312		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.6986288150237312 | validation: 0.7012477937055392]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6995076399364961		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.6995076399364961 | validation: 0.6912327819692422]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707132704440466		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.707132704440466 | validation: 0.7099108176623193]
	TIME [epoch: 11.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007728894494495		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.7007728894494495 | validation: 0.712538761241174]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060161674353085		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.7060161674353085 | validation: 0.6885010121237528]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028787831047959		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.7028787831047959 | validation: 0.6808598564854139]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984965867484536		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.6984965867484536 | validation: 0.697886628743313]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961215211072851		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.6961215211072851 | validation: 0.680171448853543]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963869997080044		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.6963869997080044 | validation: 0.7164132013377719]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005677866149923		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.7005677866149923 | validation: 0.69796434190728]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965466591605692		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.6965466591605692 | validation: 0.6924434399995023]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7139152049768795		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.7139152049768795 | validation: 0.70827569248021]
	TIME [epoch: 11.6 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027590054341133		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.7027590054341133 | validation: 0.7015218400817225]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004806367310424		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.7004806367310424 | validation: 0.6914902029936021]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957504808832332		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.6957504808832332 | validation: 0.6938141690827874]
	TIME [epoch: 11.6 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994398780229794		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.6994398780229794 | validation: 0.6924460989560072]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927152324237842		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.6927152324237842 | validation: 0.6918241044722143]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997352430539218		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.6997352430539218 | validation: 0.6900969477963156]
	TIME [epoch: 11.6 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020472260803827		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.7020472260803827 | validation: 0.6962155042470636]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023540313905962		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.7023540313905962 | validation: 0.7056827882644118]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979409142579619		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.6979409142579619 | validation: 0.7006081469394831]
	TIME [epoch: 11.6 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694161002235715		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.694161002235715 | validation: 0.6933074375883876]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6940514149203503		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.6940514149203503 | validation: 0.6985600534129734]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007221456967224		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.7007221456967224 | validation: 0.6899468993100846]
	TIME [epoch: 11.6 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044307800681517		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.7044307800681517 | validation: 0.6844498193516263]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951120029085256		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.6951120029085256 | validation: 0.6884639078251212]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000219307246847		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.7000219307246847 | validation: 0.6969127476348405]
	TIME [epoch: 11.6 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977467279372503		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.6977467279372503 | validation: 0.6941542172092272]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949875932542157		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.6949875932542157 | validation: 0.6898576784218708]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985130615342983		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.6985130615342983 | validation: 0.6991594277053871]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923318190250674		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.6923318190250674 | validation: 0.7003979564997336]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013725098894692		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.7013725098894692 | validation: 0.6962512315495386]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979681001686957		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.6979681001686957 | validation: 0.6961351365988692]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992246527976839		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.6992246527976839 | validation: 0.6961474392605351]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009185027064821		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.7009185027064821 | validation: 0.6903811740773848]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69718136945804		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.69718136945804 | validation: 0.6913607565355468]
	TIME [epoch: 11.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985429596592867		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.6985429596592867 | validation: 0.6807004228774031]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957750096574948		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.6957750096574948 | validation: 0.6956662373447372]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018203581880978		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.7018203581880978 | validation: 0.6888411969408044]
	TIME [epoch: 11.6 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984205379953242		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.6984205379953242 | validation: 0.6897587693436492]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029200757090723		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.7029200757090723 | validation: 0.6873443210561699]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6959262021481994		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.6959262021481994 | validation: 0.7009102585548759]
	TIME [epoch: 11.6 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968431983323041		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.6968431983323041 | validation: 0.6984257101051299]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023261332429738		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.7023261332429738 | validation: 0.6876859955457755]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000197924871207		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.7000197924871207 | validation: 0.6806085924316747]
	TIME [epoch: 11.6 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961761703319783		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.6961761703319783 | validation: 0.6927072350157195]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970135602603353		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.6970135602603353 | validation: 0.6854249065562614]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047467386116786		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.7047467386116786 | validation: 0.6943517587040825]
	TIME [epoch: 11.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983169560944621		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.6983169560944621 | validation: 0.6890720757084793]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948594196443388		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.6948594196443388 | validation: 0.6905073606965628]
	TIME [epoch: 11.6 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6950543500469157		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.6950543500469157 | validation: 0.7059547892272342]
	TIME [epoch: 11.6 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982246876156797		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.6982246876156797 | validation: 0.6951707535854093]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999667019047582		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.6999667019047582 | validation: 0.6825523012276489]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003884093636716		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.7003884093636716 | validation: 0.6916809289659501]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989320720789585		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.6989320720789585 | validation: 0.6903417490978859]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962648533542973		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.6962648533542973 | validation: 0.6910988404134863]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944991974331617		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.6944991974331617 | validation: 0.680575078068295]
	TIME [epoch: 11.6 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954216620895417		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.6954216620895417 | validation: 0.6836135505736732]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693680766021226		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.693680766021226 | validation: 0.6780103472456971]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980599906091256		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.6980599906091256 | validation: 0.6846149591473278]
	TIME [epoch: 11.6 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008704800124571		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.7008704800124571 | validation: 0.6721535346715655]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6987985279681422		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.6987985279681422 | validation: 0.6860929451693351]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917156162275393		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.6917156162275393 | validation: 0.658599375501474]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240310_003030/states/model_tr_study3_1932.pth
	Model improved!!!
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013572980313849		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.7013572980313849 | validation: 0.6888695976868311]
	TIME [epoch: 11.6 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004424406234555		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.7004424406234555 | validation: 0.6989305204303105]
	TIME [epoch: 11.6 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970456787551071		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.6970456787551071 | validation: 0.6769488271124949]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962408548432879		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.6962408548432879 | validation: 0.6790784734808436]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955723340574804		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.6955723340574804 | validation: 0.6823961847046877]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000868613373137		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.7000868613373137 | validation: 0.6864373354588748]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993844430710274		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.6993844430710274 | validation: 0.6781915627699008]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007006274991975		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.7007006274991975 | validation: 0.6807864885262878]
	TIME [epoch: 11.6 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964366418542381		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.6964366418542381 | validation: 0.6779808658950605]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971410096817989		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.6971410096817989 | validation: 0.6816893949539541]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980718831727863		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.6980718831727863 | validation: 0.6919585985990361]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984981706303658		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.6984981706303658 | validation: 0.6721471235882522]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972217547365469		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.6972217547365469 | validation: 0.6939412549485903]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936377004436927		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.6936377004436927 | validation: 0.679385995568818]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050245184714024		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.7050245184714024 | validation: 0.6755804146664157]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034019255509001		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.7034019255509001 | validation: 0.6893248838357687]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034390466163342		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.7034390466163342 | validation: 0.6768508394267988]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993435355204687		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.6993435355204687 | validation: 0.6795505797716804]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949410924471341		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.6949410924471341 | validation: 0.6888008746851513]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913374453289718		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.6913374453289718 | validation: 0.6780529076597795]
	TIME [epoch: 11.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013816002988393		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.7013816002988393 | validation: 0.6872858683299069]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6995573702932691		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.6995573702932691 | validation: 0.6972296463594816]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951666814982195		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.6951666814982195 | validation: 0.6865067145728105]
	TIME [epoch: 11.6 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991765799678933		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.6991765799678933 | validation: 0.6714761970845035]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967238011102983		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.6967238011102983 | validation: 0.6857764508138436]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6950694509042719		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.6950694509042719 | validation: 0.6864954659342086]
	TIME [epoch: 11.6 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6946139290375826		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.6946139290375826 | validation: 0.6808933790329926]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012496450733504		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.7012496450733504 | validation: 0.6955139477848524]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705288757828915		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.705288757828915 | validation: 0.6806231579466517]
	TIME [epoch: 11.6 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974992279430327		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.6974992279430327 | validation: 0.6867568563440576]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963999528971176		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.6963999528971176 | validation: 0.6864749128434405]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937581014658736		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.6937581014658736 | validation: 0.6757898558126678]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956003972026934		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.6956003972026934 | validation: 0.67602049232278]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034277543301537		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.7034277543301537 | validation: 0.687142336660622]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693779721612408		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.693779721612408 | validation: 0.6765508840271481]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6932437861221323		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.6932437861221323 | validation: 0.681182101881761]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698482331027349		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.698482331027349 | validation: 0.6726085560978668]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872819103119839		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.6872819103119839 | validation: 0.6809155303154214]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7025003777573423		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.7025003777573423 | validation: 0.6840415267195747]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026864399315437		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.7026864399315437 | validation: 0.6712105133746425]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963518388936466		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.6963518388936466 | validation: 0.6799893510750079]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970961928306754		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.6970961928306754 | validation: 0.6919483835686413]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701192647765909		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.701192647765909 | validation: 0.6825360041700782]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033263200456863		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.7033263200456863 | validation: 0.6704109404955807]
	TIME [epoch: 11.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986046033057476		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.6986046033057476 | validation: 0.6761096176043]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000091934496265		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.7000091934496265 | validation: 0.6934415366101828]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023324206532696		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.7023324206532696 | validation: 0.6896681513420652]
	TIME [epoch: 11.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013094789746057		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.7013094789746057 | validation: 0.6906691751994556]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986742685685831		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.6986742685685831 | validation: 0.686443822690506]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966784855006704		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.6966784855006704 | validation: 0.6791168061489984]
	TIME [epoch: 11.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009870645003026		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.7009870645003026 | validation: 0.6964590514504108]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973394624811964		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.6973394624811964 | validation: 0.6907097117212706]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6959029883633648		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.6959029883633648 | validation: 0.6835865796658429]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036111972526482		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.7036111972526482 | validation: 0.6871794398326452]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698014630935905		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.698014630935905 | validation: 0.688965971822193]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954407750281296		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.6954407750281296 | validation: 0.6787640809803404]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696394747638786		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.696394747638786 | validation: 0.6937362111911449]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002045386844631		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.7002045386844631 | validation: 0.689977704759288]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990963049970602		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.6990963049970602 | validation: 0.6923650100047186]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988625979354767		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.6988625979354767 | validation: 0.6913503702238708]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953364989258404		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.6953364989258404 | validation: 0.685055925889973]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965426298247406		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.6965426298247406 | validation: 0.696551671633584]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014525312930202		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.7014525312930202 | validation: 0.6783394437610366]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015864290751405		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.7015864290751405 | validation: 0.6751157078618966]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915256546504686		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.6915256546504686 | validation: 0.6838741079976799]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953964639372696		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.6953964639372696 | validation: 0.6851476424273508]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978460784456038		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.6978460784456038 | validation: 0.6973755007641443]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010821647567979		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.7010821647567979 | validation: 0.686856972791594]
	TIME [epoch: 11.6 sec]
Finished training in 23318.924 seconds.
