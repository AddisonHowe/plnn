Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 923431963

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.254490462330242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.254490462330242 | validation: 11.766119920164074]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.990192203876614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.990192203876614 | validation: 9.728642142161997]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.625179040325465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.625179040325465 | validation: 9.267530212441674]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.200442524004007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.200442524004007 | validation: 6.904211401027791]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.6890638526407145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6890638526407145 | validation: 7.230127774327171]
	TIME [epoch: 9.06 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.207468757233177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.207468757233177 | validation: 6.327909705386764]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.822486714438545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.822486714438545 | validation: 5.6442226854283355]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.457834393736858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.457834393736858 | validation: 5.934425975359358]
	TIME [epoch: 9.04 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.423199872774728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.423199872774728 | validation: 6.395799800564227]
	TIME [epoch: 9.04 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.634299059936436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.634299059936436 | validation: 5.4694482723135796]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.288858261048536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.288858261048536 | validation: 5.868159195033327]
	TIME [epoch: 9.06 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.293245893590546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.293245893590546 | validation: 5.498535456754416]
	TIME [epoch: 9.04 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.327594258248263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.327594258248263 | validation: 6.623227389132979]
	TIME [epoch: 9.04 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.363814840332066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.363814840332066 | validation: 5.372467323175314]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.137105098426298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.137105098426298 | validation: 5.131604460816734]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.309628479986397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.309628479986397 | validation: 5.085145675647345]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.318379697881415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.318379697881415 | validation: 5.829932923176292]
	TIME [epoch: 9.03 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.212973916724229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.212973916724229 | validation: 5.064355570122425]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.948500860757636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.948500860757636 | validation: 5.242877747142819]
	TIME [epoch: 9.07 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.880167920532847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.880167920532847 | validation: 4.998202703778925]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.816603981470566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.816603981470566 | validation: 5.929990322629293]
	TIME [epoch: 9.04 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.88733289415341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.88733289415341 | validation: 4.7603604017009395]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.683710592846184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.683710592846184 | validation: 5.217720972263405]
	TIME [epoch: 9.07 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.670673875861668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.670673875861668 | validation: 4.875224401421162]
	TIME [epoch: 9.05 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.563880098466528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.563880098466528 | validation: 4.881148231816153]
	TIME [epoch: 9.04 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.492517008548867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.492517008548867 | validation: 4.876540386097696]
	TIME [epoch: 9.03 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.411483379911124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.411483379911124 | validation: 5.923691374600898]
	TIME [epoch: 9.02 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.4919442144422534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4919442144422534 | validation: 4.902477749846316]
	TIME [epoch: 9.05 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.383926516298265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.383926516298265 | validation: 4.725350363120695]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.330931125142058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.330931125142058 | validation: 5.346809269035449]
	TIME [epoch: 9.02 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.319424806907859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.319424806907859 | validation: 4.318069133437091]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.261166764068298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.261166764068298 | validation: 4.968669108766424]
	TIME [epoch: 9.06 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.4201274629431335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4201274629431335 | validation: 5.301072986443417]
	TIME [epoch: 9.03 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.169756678286698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.169756678286698 | validation: 4.3384060051036535]
	TIME [epoch: 9.03 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0733988129248235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0733988129248235 | validation: 4.093218973191341]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.05942722009543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.05942722009543 | validation: 4.179636907290721]
	TIME [epoch: 9.04 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.861487754638887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.861487754638887 | validation: 4.232712541917861]
	TIME [epoch: 9.07 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.017301762894265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.017301762894265 | validation: 4.0570252304368415]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.9479465874929005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9479465874929005 | validation: 4.001869667725899]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.074009487914535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.074009487914535 | validation: 5.259208970573892]
	TIME [epoch: 9.05 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.908481315710988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.908481315710988 | validation: 4.082271677777553]
	TIME [epoch: 9.05 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.802956936800742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.802956936800742 | validation: 3.861951930548644]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.92194296804227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.92194296804227 | validation: 4.873873183130556]
	TIME [epoch: 9.04 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.657245529443965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.657245529443965 | validation: 4.626137189188021]
	TIME [epoch: 9.04 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.857972616435837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.857972616435837 | validation: 3.685263696456448]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.9776845939433185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9776845939433185 | validation: 4.170091217902389]
	TIME [epoch: 9.06 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.727891945494409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.727891945494409 | validation: 4.66067099604009]
	TIME [epoch: 9.03 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.775068050088508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.775068050088508 | validation: 3.848949551028605]
	TIME [epoch: 9.03 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.571077635510895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.571077635510895 | validation: 4.421391011258988]
	TIME [epoch: 9.03 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.808961896244995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.808961896244995 | validation: 4.151275003142394]
	TIME [epoch: 9.05 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.756035382568349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.756035382568349 | validation: 4.052059642655915]
	TIME [epoch: 9.04 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.737609651714845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.737609651714845 | validation: 3.80562977227619]
	TIME [epoch: 9.03 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.468528820981435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.468528820981435 | validation: 4.470995837377138]
	TIME [epoch: 9.02 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.517687661839961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.517687661839961 | validation: 4.002915451529882]
	TIME [epoch: 9.02 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.520459054856937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.520459054856937 | validation: 3.218490913709788]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8156269859521785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8156269859521785 | validation: 2.15667492164523]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.532062398493655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.532062398493655 | validation: 2.2281436964912773]
	TIME [epoch: 9.03 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4482399490088396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4482399490088396 | validation: 2.3140378056938244]
	TIME [epoch: 9.02 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.32896725345423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.32896725345423 | validation: 1.8371412668810152]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.200037179079158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.200037179079158 | validation: 2.4004655923381857]
	TIME [epoch: 9.03 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.41297914232105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.41297914232105 | validation: 2.540400111032562]
	TIME [epoch: 9.02 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.344122736923135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344122736923135 | validation: 3.8751643246748646]
	TIME [epoch: 9.02 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5596093469150665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5596093469150665 | validation: 2.0335324552872898]
	TIME [epoch: 9.02 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.355703113809701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.355703113809701 | validation: 2.5689537095107333]
	TIME [epoch: 9.04 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9166496738918317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9166496738918317 | validation: 1.7869678048638613]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2041166386152504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2041166386152504 | validation: 2.446638650469945]
	TIME [epoch: 9.02 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0934900913866024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0934900913866024 | validation: 2.018620637302684]
	TIME [epoch: 9.02 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.483329148061982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.483329148061982 | validation: 2.0860196658058165]
	TIME [epoch: 9.02 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.454194253620687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.454194253620687 | validation: 2.202653728285889]
	TIME [epoch: 9.04 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0990761941721527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0990761941721527 | validation: 1.9282612291942773]
	TIME [epoch: 9.01 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.173392346790295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.173392346790295 | validation: 2.012608461423997]
	TIME [epoch: 9.02 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.298341119949238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.298341119949238 | validation: 2.17397818509482]
	TIME [epoch: 9.02 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.003857331405165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.003857331405165 | validation: 1.7760904803970736]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8983772818378526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8983772818378526 | validation: 3.135167266190302]
	TIME [epoch: 9.03 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0829740352817114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0829740352817114 | validation: 1.7065510658840344]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8229674452076197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8229674452076197 | validation: 1.548969458490515]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9021262124805525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9021262124805525 | validation: 1.4283521634284924]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6867818186226142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6867818186226142 | validation: 2.1950101571301754]
	TIME [epoch: 9.06 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.365123348621067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.365123348621067 | validation: 1.3884883585009127]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.204176079533735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.204176079533735 | validation: 1.8440328878727863]
	TIME [epoch: 9.03 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9398286302775058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9398286302775058 | validation: 1.787488235802055]
	TIME [epoch: 9.04 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8644216944670362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8644216944670362 | validation: 1.7700844478990256]
	TIME [epoch: 9.05 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1105735597762503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1105735597762503 | validation: 2.118758711188052]
	TIME [epoch: 9.04 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.203385903912094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.203385903912094 | validation: 1.892443023926763]
	TIME [epoch: 9.03 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7270822431820672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7270822431820672 | validation: 1.6292018739327458]
	TIME [epoch: 9.03 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8752026020287516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8752026020287516 | validation: 1.4762828203378935]
	TIME [epoch: 9.04 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7077584697217454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7077584697217454 | validation: 1.4010878399606748]
	TIME [epoch: 9.05 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7593125115032442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7593125115032442 | validation: 1.413910116978081]
	TIME [epoch: 9.04 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7642846285716114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7642846285716114 | validation: 1.5050227935832527]
	TIME [epoch: 9.03 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4011853676984956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4011853676984956 | validation: 1.2845953738165286]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7679124863527487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7679124863527487 | validation: 1.3428534944375723]
	TIME [epoch: 9.06 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6372812275378448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6372812275378448 | validation: 1.4529487594882617]
	TIME [epoch: 9.02 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.220547601233757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.220547601233757 | validation: 1.5779978166917965]
	TIME [epoch: 9.04 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6659837124636219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6659837124636219 | validation: 1.4872481758045595]
	TIME [epoch: 9.03 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4870167086839792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4870167086839792 | validation: 1.4879115109014427]
	TIME [epoch: 9.02 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6811788851414928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6811788851414928 | validation: 1.1224776951460493]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6964650219697717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6964650219697717 | validation: 1.5880282926258174]
	TIME [epoch: 9.04 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4733828500528834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4733828500528834 | validation: 1.2954306916527107]
	TIME [epoch: 9.03 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4591877632886106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4591877632886106 | validation: 1.5489612700160063]
	TIME [epoch: 9.03 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5903346716612505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5903346716612505 | validation: 1.466842839797866]
	TIME [epoch: 9.04 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9907912813529576		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 2.9907912813529576 | validation: 2.3171891937949667]
	TIME [epoch: 9.06 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8437375933769022		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.8437375933769022 | validation: 1.280250318692707]
	TIME [epoch: 9.05 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6980074218931953		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 1.6980074218931953 | validation: 1.166172219246545]
	TIME [epoch: 9.04 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5129804586576865		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.5129804586576865 | validation: 1.5619233347065542]
	TIME [epoch: 9.04 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.852851688382821		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 1.852851688382821 | validation: 1.9773933341086731]
	TIME [epoch: 9.06 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8882366312140633		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.8882366312140633 | validation: 1.6734256545932897]
	TIME [epoch: 9.05 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6336439810806052		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 1.6336439810806052 | validation: 3.374390140573509]
	TIME [epoch: 9.04 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0108099510859514		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 2.0108099510859514 | validation: 2.4238756405200177]
	TIME [epoch: 9.04 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7498810478602287		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 1.7498810478602287 | validation: 1.8065597942032698]
	TIME [epoch: 9.03 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3399720776361401		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.3399720776361401 | validation: 1.5650250595353565]
	TIME [epoch: 9.06 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8125377098446296		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 1.8125377098446296 | validation: 1.348140815545919]
	TIME [epoch: 9.05 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4399631767771748		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.4399631767771748 | validation: 1.588738317890408]
	TIME [epoch: 9.03 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5247840129662529		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 1.5247840129662529 | validation: 1.2780573778585054]
	TIME [epoch: 9.04 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6542947747991463		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.6542947747991463 | validation: 1.9129638201739985]
	TIME [epoch: 9.06 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5235832844328496		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 1.5235832844328496 | validation: 3.107529116233024]
	TIME [epoch: 9.04 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8972126208437092		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.8972126208437092 | validation: 1.6973091507099256]
	TIME [epoch: 9.05 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.543422812935749		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 1.543422812935749 | validation: 1.390921701208453]
	TIME [epoch: 9.04 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5510266012917089		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.5510266012917089 | validation: 1.3774955616663234]
	TIME [epoch: 9.04 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.865162961201813		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 1.865162961201813 | validation: 2.0966973055310634]
	TIME [epoch: 9.05 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8036279757695035		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.8036279757695035 | validation: 1.5387096623727032]
	TIME [epoch: 9.03 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6678555558742598		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 1.6678555558742598 | validation: 1.762077175498649]
	TIME [epoch: 9.05 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9109143105631639		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.9109143105631639 | validation: 2.1336677137929767]
	TIME [epoch: 9.04 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7795012561310024		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 1.7795012561310024 | validation: 1.4087793104525859]
	TIME [epoch: 9.04 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2147608836885224		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 2.2147608836885224 | validation: 1.456861388415648]
	TIME [epoch: 9.07 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9415168683702078		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 1.9415168683702078 | validation: 1.6032498141948999]
	TIME [epoch: 9.04 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6860201458563098		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.6860201458563098 | validation: 1.9210685795282594]
	TIME [epoch: 9.05 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.605179716025281		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 1.605179716025281 | validation: 1.8453767319239573]
	TIME [epoch: 9.04 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9897563710145314		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.9897563710145314 | validation: 1.3985200020624422]
	TIME [epoch: 9.06 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.009952412692004		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 2.009952412692004 | validation: 1.3650415649598049]
	TIME [epoch: 9.05 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5426374257890747		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.5426374257890747 | validation: 1.3363870008619503]
	TIME [epoch: 9.05 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8909835557109016		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 1.8909835557109016 | validation: 1.8524209926043715]
	TIME [epoch: 9.04 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.144662412475516		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 2.144662412475516 | validation: 2.138385262192953]
	TIME [epoch: 9.04 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.934478838391516		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 1.934478838391516 | validation: 1.911106864322202]
	TIME [epoch: 9.06 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1618492573975843		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 2.1618492573975843 | validation: 2.2919984768892174]
	TIME [epoch: 9.04 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.064908484893904		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 2.064908484893904 | validation: 1.693154017682562]
	TIME [epoch: 9.05 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8591324223494632		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 1.8591324223494632 | validation: 2.242893243510424]
	TIME [epoch: 9.04 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8528132593923323		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 1.8528132593923323 | validation: 2.1620820404356698]
	TIME [epoch: 9.05 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5316557906298416		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 1.5316557906298416 | validation: 1.631266787232999]
	TIME [epoch: 9.04 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3334320517170986		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 1.3334320517170986 | validation: 1.2527076613419066]
	TIME [epoch: 9.04 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0987481837070776		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 2.0987481837070776 | validation: 1.5773249519824524]
	TIME [epoch: 9.03 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3484368468882775		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 1.3484368468882775 | validation: 1.6177322875389604]
	TIME [epoch: 9.05 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3393170807794839		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 1.3393170807794839 | validation: 1.2925409233236618]
	TIME [epoch: 9.07 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3944892245590044		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 1.3944892245590044 | validation: 1.2054954298360028]
	TIME [epoch: 9.05 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2653379427795872		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.2653379427795872 | validation: 1.3895420267574177]
	TIME [epoch: 9.04 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4112351336380535		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 1.4112351336380535 | validation: 1.2517550524203565]
	TIME [epoch: 9.03 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4136393659263518		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 1.4136393659263518 | validation: 1.6402846584839452]
	TIME [epoch: 9.03 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.292304884638715		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 1.292304884638715 | validation: 1.6523133963263368]
	TIME [epoch: 9.05 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2856631453920202		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 1.2856631453920202 | validation: 1.6511024040988445]
	TIME [epoch: 9.03 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2478190294575797		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 1.2478190294575797 | validation: 1.0118969795831836]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.047864029344653		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 1.047864029344653 | validation: 0.775925694146503]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1370418634047001		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 1.1370418634047001 | validation: 0.9186708232381378]
	TIME [epoch: 9.07 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.054709378558399		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 1.054709378558399 | validation: 0.9230788218605407]
	TIME [epoch: 9.04 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1330746438216557		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 1.1330746438216557 | validation: 0.8795592270992498]
	TIME [epoch: 9.02 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2320078656808917		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 2.2320078656808917 | validation: 2.378967987834875]
	TIME [epoch: 9.02 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6492066039372257		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 1.6492066039372257 | validation: 1.4333446946112671]
	TIME [epoch: 9.02 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4889720585693225		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 1.4889720585693225 | validation: 1.2203252989002065]
	TIME [epoch: 9.03 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2403676039376434		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 1.2403676039376434 | validation: 0.8001228327567154]
	TIME [epoch: 9.02 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1999389336413337		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 1.1999389336413337 | validation: 1.0384026074557187]
	TIME [epoch: 9.02 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1479770336234243		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 1.1479770336234243 | validation: 0.8237931611635849]
	TIME [epoch: 9.02 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.231672464234322		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 1.231672464234322 | validation: 0.998551260229237]
	TIME [epoch: 9.04 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0835415504842811		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 1.0835415504842811 | validation: 0.7592088554492673]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0092689294610342		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 1.0092689294610342 | validation: 1.855600362441062]
	TIME [epoch: 9.02 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0701424038610008		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 1.0701424038610008 | validation: 1.2127971265711421]
	TIME [epoch: 9.01 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0580225139688477		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 1.0580225139688477 | validation: 0.5719037316464445]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7496622083400286		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.7496622083400286 | validation: 0.7074540979176503]
	TIME [epoch: 9.06 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0295985005675121		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.0295985005675121 | validation: 1.0293670887473074]
	TIME [epoch: 9.04 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0870342403562125		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 1.0870342403562125 | validation: 0.8519067750196531]
	TIME [epoch: 9.05 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9255668450980418		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.9255668450980418 | validation: 1.1551466453221049]
	TIME [epoch: 9.05 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9253407418091573		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.9253407418091573 | validation: 1.6207726253741694]
	TIME [epoch: 9.07 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1381491838386981		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 1.1381491838386981 | validation: 2.312172166913331]
	TIME [epoch: 9.07 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1658137546715603		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 1.1658137546715603 | validation: 0.9172966672485141]
	TIME [epoch: 9.04 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1371166691511334		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 1.1371166691511334 | validation: 0.9267395638323029]
	TIME [epoch: 9.05 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0291802335324678		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 1.0291802335324678 | validation: 1.0764007822692152]
	TIME [epoch: 9.04 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1694777903310933		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 1.1694777903310933 | validation: 1.2976424282217023]
	TIME [epoch: 9.07 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1326896101789348		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 1.1326896101789348 | validation: 0.8964684641930745]
	TIME [epoch: 9.05 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.03003726226884		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 1.03003726226884 | validation: 0.9124124013995161]
	TIME [epoch: 9.05 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9271653896522665		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.9271653896522665 | validation: 1.1232426295629487]
	TIME [epoch: 9.05 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9830115925899054		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.9830115925899054 | validation: 0.45477714654313817]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8909444553492621		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.8909444553492621 | validation: 0.5897726419741178]
	TIME [epoch: 9.07 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7123115512186102		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.7123115512186102 | validation: 1.1718883231656658]
	TIME [epoch: 9.05 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8782524754923529		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.8782524754923529 | validation: 0.8895334219132562]
	TIME [epoch: 9.04 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.785799823000084		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.785799823000084 | validation: 0.8917355679140735]
	TIME [epoch: 9.05 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8221029937589386		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.8221029937589386 | validation: 0.5950651829378439]
	TIME [epoch: 9.06 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6305234870156602		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.6305234870156602 | validation: 0.5189810440919183]
	TIME [epoch: 9.05 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9369612463525927		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.9369612463525927 | validation: 0.5909217824896779]
	TIME [epoch: 9.04 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.824774393124272		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.824774393124272 | validation: 1.2854127055836204]
	TIME [epoch: 9.04 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0521395730203564		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 1.0521395730203564 | validation: 0.7870134244483904]
	TIME [epoch: 9.05 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7299349970076738		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.7299349970076738 | validation: 0.7964158064583112]
	TIME [epoch: 9.07 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6873622788152385		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.6873622788152385 | validation: 0.8884674245680125]
	TIME [epoch: 9.06 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8538182281042292		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.8538182281042292 | validation: 0.9603437177784109]
	TIME [epoch: 9.05 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.738573725423001		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.738573725423001 | validation: 1.1091671708330364]
	TIME [epoch: 9.05 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0008603893298023		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 1.0008603893298023 | validation: 0.6262864042858411]
	TIME [epoch: 9.07 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.127872463136962		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 1.127872463136962 | validation: 0.6821729042300089]
	TIME [epoch: 9.06 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7010462795485133		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.7010462795485133 | validation: 0.7733417279119703]
	TIME [epoch: 9.05 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9126409965124594		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.9126409965124594 | validation: 0.5748361719349584]
	TIME [epoch: 9.05 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6961234787860405		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.6961234787860405 | validation: 0.9226732644355171]
	TIME [epoch: 9.06 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.695867316764908		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.695867316764908 | validation: 0.36059422639212424]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.668269175533809		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.668269175533809 | validation: 0.5858021706478062]
	TIME [epoch: 9.06 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7550184512711493		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.7550184512711493 | validation: 1.1511541518835582]
	TIME [epoch: 9.05 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6475812394481976		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.6475812394481976 | validation: 1.0206577743705227]
	TIME [epoch: 9.05 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7444050450484702		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.7444050450484702 | validation: 0.5715365820874808]
	TIME [epoch: 9.05 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6733597889000925		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.6733597889000925 | validation: 1.1692633130814283]
	TIME [epoch: 9.07 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7688884307828974		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.7688884307828974 | validation: 0.6854863366225151]
	TIME [epoch: 9.04 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7703598761033407		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.7703598761033407 | validation: 0.7950332555655149]
	TIME [epoch: 9.04 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8979278348348693		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.8979278348348693 | validation: 0.8550200393113824]
	TIME [epoch: 9.04 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6797561700480158		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.6797561700480158 | validation: 1.5187698740182725]
	TIME [epoch: 9.06 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7869877940352485		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.7869877940352485 | validation: 0.8062411999111643]
	TIME [epoch: 9.06 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7730395282677684		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.7730395282677684 | validation: 0.5287139240481176]
	TIME [epoch: 9.05 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6639765081716419		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.6639765081716419 | validation: 0.49335417113340563]
	TIME [epoch: 9.05 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6643929247231299		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.6643929247231299 | validation: 0.703741086858522]
	TIME [epoch: 9.05 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8106080442002481		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.8106080442002481 | validation: 0.45942741484820704]
	TIME [epoch: 9.06 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7817296991150205		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.7817296991150205 | validation: 0.7299371195868773]
	TIME [epoch: 9.04 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6462334259848006		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.6462334259848006 | validation: 0.40837608613199194]
	TIME [epoch: 9.04 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7366095567014416		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.7366095567014416 | validation: 0.6980527954594051]
	TIME [epoch: 9.04 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7365542100147346		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.7365542100147346 | validation: 0.6419118476297001]
	TIME [epoch: 9.06 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7109890690652879		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.7109890690652879 | validation: 0.3570200798156247]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6898222801505656		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.6898222801505656 | validation: 0.3502160420976136]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.840119365895208		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.840119365895208 | validation: 1.0942375080781253]
	TIME [epoch: 9.04 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447632168563729		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.7447632168563729 | validation: 0.5959264311149007]
	TIME [epoch: 9.02 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6445797637043895		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.6445797637043895 | validation: 0.6243155257971877]
	TIME [epoch: 9.06 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7412353221225177		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.7412353221225177 | validation: 0.8588315597569116]
	TIME [epoch: 9.05 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7709550000005909		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.7709550000005909 | validation: 0.7053426634689087]
	TIME [epoch: 9.04 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6782620433571832		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.6782620433571832 | validation: 0.47064236777571766]
	TIME [epoch: 9.03 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8242076813733746		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.8242076813733746 | validation: 0.5325947364861441]
	TIME [epoch: 9.04 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6595663718318818		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.6595663718318818 | validation: 0.5457914837801088]
	TIME [epoch: 9.04 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5281979446375216		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.5281979446375216 | validation: 0.5761055143789859]
	TIME [epoch: 9.03 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6157666126249761		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.6157666126249761 | validation: 0.5648264369186295]
	TIME [epoch: 9.03 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5899378200881371		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.5899378200881371 | validation: 0.9889236770821028]
	TIME [epoch: 9.04 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6020999361786116		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.6020999361786116 | validation: 0.7870639535893628]
	TIME [epoch: 9.05 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7127030620011972		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.7127030620011972 | validation: 0.8757220317328644]
	TIME [epoch: 9.04 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7283651912354241		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.7283651912354241 | validation: 0.33748914110457817]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6250961642811832		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.6250961642811832 | validation: 0.4034099851168438]
	TIME [epoch: 9.04 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6448185885741964		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.6448185885741964 | validation: 0.6071737931686236]
	TIME [epoch: 9.04 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7512180486083633		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.7512180486083633 | validation: 1.1594146759901802]
	TIME [epoch: 9.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6523727486494124		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.6523727486494124 | validation: 0.44576149861889935]
	TIME [epoch: 9.04 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6087630948084939		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.6087630948084939 | validation: 0.2921310881791205]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5971071627367013		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.5971071627367013 | validation: 0.5716938054578581]
	TIME [epoch: 9.04 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.605419804630096		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.605419804630096 | validation: 0.3679685531904374]
	TIME [epoch: 9.05 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5775242227622142		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.5775242227622142 | validation: 0.528844937494783]
	TIME [epoch: 9.04 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6224261163877428		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.6224261163877428 | validation: 0.5580878486498251]
	TIME [epoch: 9.03 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6388841340245452		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.6388841340245452 | validation: 0.3623152612024557]
	TIME [epoch: 9.02 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5903939235826338		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.5903939235826338 | validation: 0.4427653208854828]
	TIME [epoch: 9.02 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6013817050434973		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.6013817050434973 | validation: 0.7042090882996871]
	TIME [epoch: 9.05 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6328149228590348		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.6328149228590348 | validation: 0.8148571273562235]
	TIME [epoch: 9.02 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5691729250582649		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.5691729250582649 | validation: 0.7188684738546997]
	TIME [epoch: 9.03 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6927209251638877		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.6927209251638877 | validation: 0.6897452463216099]
	TIME [epoch: 9.03 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6187565443738177		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.6187565443738177 | validation: 0.8450148387156988]
	TIME [epoch: 9.04 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6765978220057884		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.6765978220057884 | validation: 0.5099303519647799]
	TIME [epoch: 9.04 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46309253367278247		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.46309253367278247 | validation: 0.5883754245108495]
	TIME [epoch: 9.03 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6155065446049699		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.6155065446049699 | validation: 0.403292536178272]
	TIME [epoch: 9.03 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5883108276266517		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.5883108276266517 | validation: 0.6784848278381002]
	TIME [epoch: 9.03 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225104502180654		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.6225104502180654 | validation: 0.4773579631163321]
	TIME [epoch: 9.05 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5137268821503878		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.5137268821503878 | validation: 0.6593770739669138]
	TIME [epoch: 9.03 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.549844359618086		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.549844359618086 | validation: 0.5845880542505639]
	TIME [epoch: 9.02 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554688114232152		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.5554688114232152 | validation: 1.7032935543381158]
	TIME [epoch: 9.03 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7960713934066778		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.7960713934066778 | validation: 0.8267613374786231]
	TIME [epoch: 9.03 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5900071616306076		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.5900071616306076 | validation: 0.6665485124741901]
	TIME [epoch: 9.05 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5541937041352286		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.5541937041352286 | validation: 0.5088711735203428]
	TIME [epoch: 9.02 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4836504099887279		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.4836504099887279 | validation: 0.8262974944093295]
	TIME [epoch: 9.03 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6141293326252367		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.6141293326252367 | validation: 0.35465562166746234]
	TIME [epoch: 9.03 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5093776821407656		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.5093776821407656 | validation: 0.5556641894062364]
	TIME [epoch: 9.05 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7212588156993452		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.7212588156993452 | validation: 0.3818793870745639]
	TIME [epoch: 9.03 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5576580537303676		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.5576580537303676 | validation: 0.5491378041313277]
	TIME [epoch: 9.03 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4892192357528047		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.4892192357528047 | validation: 0.3964437195571065]
	TIME [epoch: 9.03 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6020749310178573		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.6020749310178573 | validation: 0.40836981078313483]
	TIME [epoch: 9.03 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5123390804680122		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.5123390804680122 | validation: 0.6212457971109371]
	TIME [epoch: 9.04 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.761286282930169		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.761286282930169 | validation: 0.6622564253792176]
	TIME [epoch: 9.02 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5639188008909451		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.5639188008909451 | validation: 0.4345353223596747]
	TIME [epoch: 9.03 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4493657875236627		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.4493657875236627 | validation: 0.2565605177882557]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.311798561237013		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 1.311798561237013 | validation: 2.4681723308483647]
	TIME [epoch: 9.04 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8341149201880089		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.8341149201880089 | validation: 0.41976555398092463]
	TIME [epoch: 9.05 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6055973336350433		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.6055973336350433 | validation: 1.5661040175090082]
	TIME [epoch: 9.03 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7297978049838368		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.7297978049838368 | validation: 0.3937971073709414]
	TIME [epoch: 9.04 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296425127545359		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.5296425127545359 | validation: 0.3645743736110308]
	TIME [epoch: 9.04 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49215746475387956		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.49215746475387956 | validation: 0.30948736080013917]
	TIME [epoch: 9.06 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5017324851035674		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.5017324851035674 | validation: 0.8732739797657872]
	TIME [epoch: 9.04 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5632999020089577		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.5632999020089577 | validation: 0.35439609312446463]
	TIME [epoch: 9.03 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7355394468006576		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.7355394468006576 | validation: 0.7133013101155423]
	TIME [epoch: 9.03 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5661184571067837		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.5661184571067837 | validation: 0.44820629476559576]
	TIME [epoch: 9.03 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7763696771470683		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.7763696771470683 | validation: 1.107635459125892]
	TIME [epoch: 9.05 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6941811534789999		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.6941811534789999 | validation: 0.4642514926380839]
	TIME [epoch: 9.03 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6101216339807245		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.6101216339807245 | validation: 0.5073624138574193]
	TIME [epoch: 9.02 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5183507351531804		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.5183507351531804 | validation: 0.6126311318690573]
	TIME [epoch: 9.03 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49759292934456034		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.49759292934456034 | validation: 0.39193833556097124]
	TIME [epoch: 9.04 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7489439946079385		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.7489439946079385 | validation: 0.6524335654436382]
	TIME [epoch: 9.03 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49830976976948743		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.49830976976948743 | validation: 0.3301911752097304]
	TIME [epoch: 9.03 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5263555493436239		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.5263555493436239 | validation: 0.5543640804218584]
	TIME [epoch: 9.03 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6773611352106601		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.6773611352106601 | validation: 0.5842903949554314]
	TIME [epoch: 9.03 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5338983286211972		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.5338983286211972 | validation: 0.4633092996553558]
	TIME [epoch: 9.06 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4962126806455882		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.4962126806455882 | validation: 0.39766614769574005]
	TIME [epoch: 9.03 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023966913603742		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.5023966913603742 | validation: 0.6140634523420502]
	TIME [epoch: 9.03 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47878967326900695		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.47878967326900695 | validation: 0.33973738953037863]
	TIME [epoch: 9.03 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48143945087472567		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.48143945087472567 | validation: 0.4489847930413078]
	TIME [epoch: 9.04 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5886575748809688		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.5886575748809688 | validation: 0.3681421848958079]
	TIME [epoch: 9.05 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4824631311295498		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.4824631311295498 | validation: 0.39066714132889346]
	TIME [epoch: 9.02 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5695244364081862		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.5695244364081862 | validation: 0.37045980122763855]
	TIME [epoch: 9.02 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5030436665723002		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.5030436665723002 | validation: 0.4567752403591602]
	TIME [epoch: 9.02 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171318833075619		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.5171318833075619 | validation: 0.4502228953676365]
	TIME [epoch: 9.05 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5345662229003609		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.5345662229003609 | validation: 0.4494463264910008]
	TIME [epoch: 9.03 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5443293808472861		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.5443293808472861 | validation: 0.6303184420184769]
	TIME [epoch: 9.03 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5478788341405619		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.5478788341405619 | validation: 0.459717850035631]
	TIME [epoch: 9.04 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4206457205726094		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.4206457205726094 | validation: 0.4062170772684568]
	TIME [epoch: 9.03 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.472252217958934		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.472252217958934 | validation: 0.7474809528821708]
	TIME [epoch: 9.05 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5037681366216646		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.5037681366216646 | validation: 0.3559970222700536]
	TIME [epoch: 9.03 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.952892584091534		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.952892584091534 | validation: 0.6143506955618752]
	TIME [epoch: 9.02 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.476872397712806		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.476872397712806 | validation: 0.7115345481692237]
	TIME [epoch: 9.03 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600996685385444		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.5600996685385444 | validation: 0.4293864138502629]
	TIME [epoch: 9.04 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4487510390380369		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.4487510390380369 | validation: 0.33997827053922547]
	TIME [epoch: 9.04 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.514714005547675		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.514714005547675 | validation: 0.6829193470500352]
	TIME [epoch: 9.03 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3047886500587318		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 1.3047886500587318 | validation: 0.5645625536021617]
	TIME [epoch: 9.02 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6798928923324778		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.6798928923324778 | validation: 0.3170491939099026]
	TIME [epoch: 9.03 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40784884347371275		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.40784884347371275 | validation: 0.563731184825018]
	TIME [epoch: 9.05 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4717591082670138		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.4717591082670138 | validation: 0.3997492412319681]
	TIME [epoch: 9.04 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5440853854612568		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.5440853854612568 | validation: 0.4254042364147419]
	TIME [epoch: 9.04 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4699720042389163		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.4699720042389163 | validation: 0.42555923856734623]
	TIME [epoch: 9.03 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5545037895545974		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.5545037895545974 | validation: 0.42623244818905537]
	TIME [epoch: 9.03 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43154308563536914		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.43154308563536914 | validation: 0.52760805439304]
	TIME [epoch: 9.05 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4740242033504275		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.4740242033504275 | validation: 0.3100219592346649]
	TIME [epoch: 9.03 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5058544048747073		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.5058544048747073 | validation: 0.7218933898574111]
	TIME [epoch: 9.03 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5773787449911808		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.5773787449911808 | validation: 0.3339033083388794]
	TIME [epoch: 9.02 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38086811345024174		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.38086811345024174 | validation: 0.525381352692266]
	TIME [epoch: 9.05 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44871712300543354		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.44871712300543354 | validation: 0.3666920232959141]
	TIME [epoch: 9.03 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49152443761343745		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.49152443761343745 | validation: 0.4123123670781621]
	TIME [epoch: 9.03 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.516853612363637		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.516853612363637 | validation: 0.8709743809132511]
	TIME [epoch: 9.03 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4840230969290321		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.4840230969290321 | validation: 0.21121421328418016]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.413818877905933		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.413818877905933 | validation: 0.3707930435157324]
	TIME [epoch: 9.06 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4324601852739855		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.4324601852739855 | validation: 0.46588001503462084]
	TIME [epoch: 9.04 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4573938307629676		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.4573938307629676 | validation: 0.4619053442347436]
	TIME [epoch: 9.03 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.398572478754136		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.398572478754136 | validation: 0.2542519252305521]
	TIME [epoch: 9.03 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4859846571148929		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.4859846571148929 | validation: 0.2717519266388252]
	TIME [epoch: 9.04 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39154817689797794		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.39154817689797794 | validation: 0.2862760345357521]
	TIME [epoch: 9.03 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7686281756657244		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.7686281756657244 | validation: 0.4452944982800524]
	TIME [epoch: 9.02 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47616613265773405		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.47616613265773405 | validation: 0.3107700351886927]
	TIME [epoch: 9.02 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131568395949259		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.4131568395949259 | validation: 0.4959408486720556]
	TIME [epoch: 9.02 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5447710814764087		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.5447710814764087 | validation: 0.31539634793505295]
	TIME [epoch: 9.04 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5228784442070445		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.5228784442070445 | validation: 0.7155416952649787]
	TIME [epoch: 9.02 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44151710496603985		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.44151710496603985 | validation: 0.5498361698751113]
	TIME [epoch: 9.02 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36043172604061036		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.36043172604061036 | validation: 0.6751116972224218]
	TIME [epoch: 9.02 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5307822592037678		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.5307822592037678 | validation: 0.436143848637768]
	TIME [epoch: 9.03 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3972906121736037		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.3972906121736037 | validation: 0.26992671026799275]
	TIME [epoch: 9.05 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36833507240797986		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.36833507240797986 | validation: 0.339128785918203]
	TIME [epoch: 9.03 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5552706355870012		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.5552706355870012 | validation: 0.6332021825019055]
	TIME [epoch: 9.03 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4623896089474604		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.4623896089474604 | validation: 0.3222040438902769]
	TIME [epoch: 9.02 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3971616136821905		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.3971616136821905 | validation: 0.6127157499116211]
	TIME [epoch: 9.04 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5765430470974287		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.5765430470974287 | validation: 0.7796424345669903]
	TIME [epoch: 9.03 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4943082572585683		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.4943082572585683 | validation: 0.3026675202779373]
	TIME [epoch: 9.03 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5667768075089222		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.5667768075089222 | validation: 0.4636533378586583]
	TIME [epoch: 9.02 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4727548981145249		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.4727548981145249 | validation: 0.39602933351096425]
	TIME [epoch: 9.02 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34588558178607665		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.34588558178607665 | validation: 0.47185994978596724]
	TIME [epoch: 9.05 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34497685872038814		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.34497685872038814 | validation: 0.3417082959192954]
	TIME [epoch: 9.02 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36559873804467025		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.36559873804467025 | validation: 0.3451738984654853]
	TIME [epoch: 9.02 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3633465045637666		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.3633465045637666 | validation: 1.1326957916359728]
	TIME [epoch: 9.02 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5078354554957176		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.5078354554957176 | validation: 0.17131510856814358]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898733850283894		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.3898733850283894 | validation: 0.5622362096054542]
	TIME [epoch: 9.07 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5276057927094916		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.5276057927094916 | validation: 0.49899736843201503]
	TIME [epoch: 9.05 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45618085195515334		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.45618085195515334 | validation: 0.29627192457079]
	TIME [epoch: 9.05 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37305017643080274		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.37305017643080274 | validation: 0.4350102403001158]
	TIME [epoch: 9.05 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.482043658115456		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.482043658115456 | validation: 0.26954939313269244]
	TIME [epoch: 9.07 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38029584645336884		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.38029584645336884 | validation: 0.47351472199419564]
	TIME [epoch: 9.05 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4288140536007816		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.4288140536007816 | validation: 0.6404500949922785]
	TIME [epoch: 9.05 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5452609469213601		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.5452609469213601 | validation: 1.108480150263776]
	TIME [epoch: 9.05 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5578744586454782		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.5578744586454782 | validation: 0.4408103397910822]
	TIME [epoch: 9.05 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670190786818278		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.3670190786818278 | validation: 0.3417743031698529]
	TIME [epoch: 9.07 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.411227254303158		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.411227254303158 | validation: 0.4099914863223795]
	TIME [epoch: 9.06 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6174141658473814		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.6174141658473814 | validation: 0.5176645081571231]
	TIME [epoch: 9.05 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5331699230804879		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.5331699230804879 | validation: 0.5772608572722188]
	TIME [epoch: 9.05 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5199020931474283		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.5199020931474283 | validation: 0.45630455707332684]
	TIME [epoch: 9.07 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4592988260659232		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.4592988260659232 | validation: 0.3514629975688242]
	TIME [epoch: 9.05 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5576452625117676		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.5576452625117676 | validation: 0.4088996982520947]
	TIME [epoch: 9.05 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47156416440258225		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.47156416440258225 | validation: 0.4797560234727662]
	TIME [epoch: 9.05 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5371655308095089		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.5371655308095089 | validation: 0.25393014480981857]
	TIME [epoch: 9.05 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4729905185512552		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.4729905185512552 | validation: 0.3527823570296026]
	TIME [epoch: 9.07 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5194018476612543		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.5194018476612543 | validation: 0.45347860372286064]
	TIME [epoch: 9.05 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.441632909606479		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.441632909606479 | validation: 0.36587122949122786]
	TIME [epoch: 9.05 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37982019128495387		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.37982019128495387 | validation: 0.29269559967598013]
	TIME [epoch: 9.05 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30611149447937724		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.30611149447937724 | validation: 0.20016718955565377]
	TIME [epoch: 9.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43577531808702014		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.43577531808702014 | validation: 0.19197637301746218]
	TIME [epoch: 9.05 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4002950747987387		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.4002950747987387 | validation: 0.3174878162313468]
	TIME [epoch: 9.05 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33738013918337983		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.33738013918337983 | validation: 0.28583584478683954]
	TIME [epoch: 9.06 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4300233002147955		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.4300233002147955 | validation: 0.41482889987555943]
	TIME [epoch: 9.05 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34046839859366396		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.34046839859366396 | validation: 1.065523776084599]
	TIME [epoch: 9.08 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6529192888623188		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.6529192888623188 | validation: 0.4526145585413385]
	TIME [epoch: 9.05 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3737461840588254		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.3737461840588254 | validation: 0.5698349389576998]
	TIME [epoch: 9.04 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39629841313542824		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.39629841313542824 | validation: 0.46719422331100224]
	TIME [epoch: 9.05 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40480643313485026		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.40480643313485026 | validation: 0.4143677284486165]
	TIME [epoch: 9.05 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3961875148192048		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.3961875148192048 | validation: 0.316104247571257]
	TIME [epoch: 9.07 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34327488005552986		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.34327488005552986 | validation: 0.46633743374731434]
	TIME [epoch: 9.05 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42305407901209213		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.42305407901209213 | validation: 0.33693842215944075]
	TIME [epoch: 9.05 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4554163747048223		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.4554163747048223 | validation: 0.4102546912537405]
	TIME [epoch: 9.05 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3282323853816386		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.3282323853816386 | validation: 0.3096538085582663]
	TIME [epoch: 9.07 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38294273790853295		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.38294273790853295 | validation: 0.3812861866050996]
	TIME [epoch: 9.05 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32734402677821717		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.32734402677821717 | validation: 0.18362429552211296]
	TIME [epoch: 9.05 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.339207536705419		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.339207536705419 | validation: 0.24212681292399804]
	TIME [epoch: 9.04 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2574041633061509		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2574041633061509 | validation: 0.6905135667485625]
	TIME [epoch: 9.05 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38699438064807		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.38699438064807 | validation: 0.3267826730069681]
	TIME [epoch: 9.07 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3319235453016057		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.3319235453016057 | validation: 0.2926006522592757]
	TIME [epoch: 9.05 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37788338735500826		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.37788338735500826 | validation: 0.20550183708954517]
	TIME [epoch: 9.05 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32749421657764116		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.32749421657764116 | validation: 0.511198336550928]
	TIME [epoch: 9.04 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4368382219114116		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.4368382219114116 | validation: 0.3342470086333641]
	TIME [epoch: 9.07 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3696413167794045		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.3696413167794045 | validation: 0.4332577293299839]
	TIME [epoch: 9.06 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4832632228069837		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.4832632228069837 | validation: 0.62577752671852]
	TIME [epoch: 9.05 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757049144590609		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.3757049144590609 | validation: 0.4101017774040399]
	TIME [epoch: 9.04 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4388887760098269		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.4388887760098269 | validation: 1.3311368088588482]
	TIME [epoch: 9.04 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6558393491263812		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.6558393491263812 | validation: 0.9132433348546969]
	TIME [epoch: 9.06 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5956679367320693		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.5956679367320693 | validation: 0.5689675529896798]
	TIME [epoch: 9.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4889389860187482		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.4889389860187482 | validation: 0.34368603951831467]
	TIME [epoch: 9.05 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41003797791107754		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.41003797791107754 | validation: 0.2828042902175638]
	TIME [epoch: 9.05 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7240257049451649		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.7240257049451649 | validation: 0.6010597562331788]
	TIME [epoch: 9.05 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38505012465696836		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.38505012465696836 | validation: 0.25117566866287366]
	TIME [epoch: 9.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3409082716901012		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.3409082716901012 | validation: 0.39960263266276896]
	TIME [epoch: 9.04 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35395480278017083		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.35395480278017083 | validation: 0.3239129218871456]
	TIME [epoch: 9.04 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4322634132119106		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.4322634132119106 | validation: 0.3975474416390352]
	TIME [epoch: 9.05 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44121213923703817		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.44121213923703817 | validation: 0.18967659955867477]
	TIME [epoch: 9.06 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37005171007270155		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.37005171007270155 | validation: 0.3002355212301837]
	TIME [epoch: 9.05 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46323805050510797		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.46323805050510797 | validation: 0.31665943424377324]
	TIME [epoch: 9.05 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3548719236471545		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.3548719236471545 | validation: 0.27838445967019765]
	TIME [epoch: 9.04 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131522892663712		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.4131522892663712 | validation: 0.37518087648709036]
	TIME [epoch: 9.04 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36754769133491916		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.36754769133491916 | validation: 0.40244789266445524]
	TIME [epoch: 9.07 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36783725062107564		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.36783725062107564 | validation: 0.3469482769387354]
	TIME [epoch: 9.05 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31549276156179507		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.31549276156179507 | validation: 0.4034386267090114]
	TIME [epoch: 9.05 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4468190702758056		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.4468190702758056 | validation: 0.3721685661653939]
	TIME [epoch: 9.05 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5435815021844612		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.5435815021844612 | validation: 0.5612865509552004]
	TIME [epoch: 9.06 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4948658857553265		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.4948658857553265 | validation: 0.3518022880989934]
	TIME [epoch: 9.04 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38893396732203234		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.38893396732203234 | validation: 0.3680615231326611]
	TIME [epoch: 9.04 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45194680538127335		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.45194680538127335 | validation: 0.4419286936583158]
	TIME [epoch: 9.05 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3247949513548568		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.3247949513548568 | validation: 0.29255430132827437]
	TIME [epoch: 9.04 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984804847116599		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.2984804847116599 | validation: 0.38060124132610423]
	TIME [epoch: 9.07 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4126897205457212		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.4126897205457212 | validation: 0.2159400660627091]
	TIME [epoch: 9.04 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26829203962217096		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.26829203962217096 | validation: 0.33220710972635215]
	TIME [epoch: 9.04 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6906084205748023		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.6906084205748023 | validation: 0.48937232370717126]
	TIME [epoch: 9.04 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39815237441431595		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.39815237441431595 | validation: 0.299949172235844]
	TIME [epoch: 9.04 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3515282056455321		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.3515282056455321 | validation: 0.23722815558450483]
	TIME [epoch: 9.07 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3735422527607561		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.3735422527607561 | validation: 0.2688920966723907]
	TIME [epoch: 9.04 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37478500242206997		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.37478500242206997 | validation: 0.4810380334283244]
	TIME [epoch: 9.04 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3590671794158705		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.3590671794158705 | validation: 0.4425369740803206]
	TIME [epoch: 9.04 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3910701935430817		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.3910701935430817 | validation: 0.2896286129911547]
	TIME [epoch: 9.06 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.290064680012405		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.290064680012405 | validation: 0.3824213603742513]
	TIME [epoch: 9.04 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42413091331075836		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.42413091331075836 | validation: 0.3162187233742223]
	TIME [epoch: 9.04 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3916147153790782		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.3916147153790782 | validation: 0.3587700325021742]
	TIME [epoch: 9.04 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611341359110126		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.3611341359110126 | validation: 0.3973361337142547]
	TIME [epoch: 9.04 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.315357093326354		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.315357093326354 | validation: 0.31826163909918986]
	TIME [epoch: 9.06 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3075389501427755		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.3075389501427755 | validation: 0.3081090882756111]
	TIME [epoch: 9.04 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48142404206007494		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.48142404206007494 | validation: 0.3158469465805416]
	TIME [epoch: 9.04 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713880664070713		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.2713880664070713 | validation: 0.22872151307642966]
	TIME [epoch: 9.03 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35124168155123425		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.35124168155123425 | validation: 0.2128763791813157]
	TIME [epoch: 9.06 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3068443461023899		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.3068443461023899 | validation: 0.342795469684415]
	TIME [epoch: 9.06 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3532266196773585		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.3532266196773585 | validation: 0.2733921508607172]
	TIME [epoch: 9.04 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3198896410425177		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.3198896410425177 | validation: 0.36131434431469306]
	TIME [epoch: 9.04 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112917976243691		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.3112917976243691 | validation: 0.27784128307670275]
	TIME [epoch: 9.03 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32640362338200063		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.32640362338200063 | validation: 0.3052451229064155]
	TIME [epoch: 9.06 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042695649512467		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.3042695649512467 | validation: 0.20407162542816726]
	TIME [epoch: 9.04 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3100503354358794		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.3100503354358794 | validation: 0.30665764211368907]
	TIME [epoch: 9.04 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3623920589957082		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.3623920589957082 | validation: 0.28270399587236666]
	TIME [epoch: 9.04 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3722173842531852		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.3722173842531852 | validation: 0.24358684498306576]
	TIME [epoch: 9.04 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3207630648644786		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.3207630648644786 | validation: 0.2916126218375942]
	TIME [epoch: 9.07 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33262533070597156		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.33262533070597156 | validation: 0.36144262621924705]
	TIME [epoch: 9.04 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36789685095679475		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.36789685095679475 | validation: 0.29498729054805195]
	TIME [epoch: 9.04 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3023192470226589		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.3023192470226589 | validation: 0.2644372682279984]
	TIME [epoch: 9.04 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37681428009588086		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.37681428009588086 | validation: 0.330635084394009]
	TIME [epoch: 9.06 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4496409309685926		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.4496409309685926 | validation: 0.3427193638445454]
	TIME [epoch: 9.05 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2909072321516286		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.2909072321516286 | validation: 0.2488574912266605]
	TIME [epoch: 9.04 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32843279004185705		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.32843279004185705 | validation: 0.24026555620136703]
	TIME [epoch: 9.04 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31617538995132644		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.31617538995132644 | validation: 0.3136177021474922]
	TIME [epoch: 9.04 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41561663886930467		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.41561663886930467 | validation: 0.6246998616989738]
	TIME [epoch: 9.06 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964264840543452		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.2964264840543452 | validation: 0.21979459954293215]
	TIME [epoch: 9.05 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47188110627045265		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.47188110627045265 | validation: 0.3162674148201554]
	TIME [epoch: 9.04 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.275541318115494		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.275541318115494 | validation: 0.20620876770888025]
	TIME [epoch: 9.04 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24206016849804612		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.24206016849804612 | validation: 0.5131981164300851]
	TIME [epoch: 9.05 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.352249058077509		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.352249058077509 | validation: 0.16795456824839547]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042030606462871		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.5042030606462871 | validation: 0.711847095565222]
	TIME [epoch: 9.04 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41963225377607954		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.41963225377607954 | validation: 0.4491552710726129]
	TIME [epoch: 9.03 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27172907372834226		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.27172907372834226 | validation: 0.32457555467390264]
	TIME [epoch: 9.04 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27613619025491787		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.27613619025491787 | validation: 0.1992571119858022]
	TIME [epoch: 9.07 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36526123320210135		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.36526123320210135 | validation: 0.21216748146911768]
	TIME [epoch: 9.04 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32413932414994456		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.32413932414994456 | validation: 0.3043257006420357]
	TIME [epoch: 9.03 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2824087087601976		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.2824087087601976 | validation: 0.38620985830259463]
	TIME [epoch: 9.03 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25771846415486566		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.25771846415486566 | validation: 0.36884746722031003]
	TIME [epoch: 9.02 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30264855073569646		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.30264855073569646 | validation: 0.449393212724017]
	TIME [epoch: 9.06 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32179333726352943		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.32179333726352943 | validation: 0.2998408225787315]
	TIME [epoch: 9.03 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24677143741350127		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.24677143741350127 | validation: 0.39964066417634747]
	TIME [epoch: 9.03 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39546913699300185		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.39546913699300185 | validation: 0.3522956430084996]
	TIME [epoch: 9.03 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39812674098461853		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.39812674098461853 | validation: 0.17379653424751304]
	TIME [epoch: 9.04 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5659211700869544		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.5659211700869544 | validation: 0.8417024301524616]
	TIME [epoch: 9.04 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49071312789069355		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.49071312789069355 | validation: 0.18964397321861282]
	TIME [epoch: 9.02 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050414097496437		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.3050414097496437 | validation: 0.4284132403325446]
	TIME [epoch: 9.04 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30521289909814714		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.30521289909814714 | validation: 0.23894618730568745]
	TIME [epoch: 9.03 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34791205968559463		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.34791205968559463 | validation: 0.310293808016037]
	TIME [epoch: 9.06 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3229057317315455		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.3229057317315455 | validation: 0.3988992725311211]
	TIME [epoch: 9.04 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32329689088305186		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.32329689088305186 | validation: 0.19899736089009368]
	TIME [epoch: 9.03 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36409496900312593		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.36409496900312593 | validation: 0.26534772709016613]
	TIME [epoch: 9.02 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32103191525935404		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.32103191525935404 | validation: 0.2748223803557634]
	TIME [epoch: 9.05 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863179127479175		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.2863179127479175 | validation: 0.44207909901340003]
	TIME [epoch: 9.04 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30421954536813833		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.30421954536813833 | validation: 0.20281798002352225]
	TIME [epoch: 9.04 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2515009832814917		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.2515009832814917 | validation: 0.25012051132538804]
	TIME [epoch: 9.02 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31925916467793		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.31925916467793 | validation: 0.3172043565810401]
	TIME [epoch: 9.03 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24340838201511678		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.24340838201511678 | validation: 0.1306691746379769]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.247833881544648		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.247833881544648 | validation: 0.1810509816859308]
	TIME [epoch: 9.03 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24796621351800568		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.24796621351800568 | validation: 0.40562956110159465]
	TIME [epoch: 9.03 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28639820178068764		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.28639820178068764 | validation: 0.3235680152936906]
	TIME [epoch: 9.03 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27889895473884485		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.27889895473884485 | validation: 0.30118927329834483]
	TIME [epoch: 9.03 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19877695960046532		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.19877695960046532 | validation: 0.22233148961495708]
	TIME [epoch: 9.05 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26548272079029744		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.26548272079029744 | validation: 0.1656642037968446]
	TIME [epoch: 9.02 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26931122194122165		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.26931122194122165 | validation: 0.2039447487024557]
	TIME [epoch: 9.02 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2898327824307464		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.2898327824307464 | validation: 0.19466148714834758]
	TIME [epoch: 9.02 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25809485816892214		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.25809485816892214 | validation: 0.41485979444612064]
	TIME [epoch: 9.04 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37047938967059324		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.37047938967059324 | validation: 0.31033573907759665]
	TIME [epoch: 9.03 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250595402876535		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.3250595402876535 | validation: 0.49058150185407773]
	TIME [epoch: 9.02 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38646586497524854		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.38646586497524854 | validation: 0.3187313187845278]
	TIME [epoch: 9.03 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41230832904167		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.41230832904167 | validation: 0.20981173871444722]
	TIME [epoch: 9.03 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30047190693247955		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.30047190693247955 | validation: 0.3645818938106944]
	TIME [epoch: 9.05 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2609477398356296		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.2609477398356296 | validation: 0.448781567097011]
	TIME [epoch: 9.04 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30529725186052714		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.30529725186052714 | validation: 0.1943948793556679]
	TIME [epoch: 9.03 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2841721458301834		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.2841721458301834 | validation: 0.20471980229894604]
	TIME [epoch: 9.02 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19780162488960462		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.19780162488960462 | validation: 0.18780975536374728]
	TIME [epoch: 9.03 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25187538479030225		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.25187538479030225 | validation: 0.18468692857575286]
	TIME [epoch: 9.04 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29583008224620555		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.29583008224620555 | validation: 0.29404247980440645]
	TIME [epoch: 9.03 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859472928467883		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.2859472928467883 | validation: 0.17470847740252438]
	TIME [epoch: 9.02 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582151484983813		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.2582151484983813 | validation: 0.21082985697056056]
	TIME [epoch: 9.02 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2594991257406692		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.2594991257406692 | validation: 0.3173301528727885]
	TIME [epoch: 9.05 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147601280127584		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.3147601280127584 | validation: 0.20753734456895045]
	TIME [epoch: 9.03 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22634592317809216		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.22634592317809216 | validation: 0.3091924512143165]
	TIME [epoch: 9.02 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25571705268990325		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.25571705268990325 | validation: 0.41769085961808106]
	TIME [epoch: 9.02 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2877285970228476		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.2877285970228476 | validation: 0.1806230099047446]
	TIME [epoch: 9.03 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2756633715129277		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.2756633715129277 | validation: 0.22957703910105876]
	TIME [epoch: 9.04 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23466298454340664		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.23466298454340664 | validation: 0.2940054898508292]
	TIME [epoch: 9.03 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2789874266172128		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.2789874266172128 | validation: 0.4644885893181139]
	TIME [epoch: 9.03 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32542907373278485		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.32542907373278485 | validation: 0.3195332820149569]
	TIME [epoch: 9.03 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25979366485683625		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.25979366485683625 | validation: 0.12421824853512278]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24177055889587096		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.24177055889587096 | validation: 0.30698509609114055]
	TIME [epoch: 9.04 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.299691679066317		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.299691679066317 | validation: 0.10544905023094697]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.268257233492058		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.268257233492058 | validation: 0.33867088678850665]
	TIME [epoch: 9.03 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3410270696338105		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.3410270696338105 | validation: 0.14466034668495045]
	TIME [epoch: 9.02 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22995710579019998		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.22995710579019998 | validation: 0.3533538060796356]
	TIME [epoch: 9.04 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27220528492507395		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.27220528492507395 | validation: 0.2457628552373762]
	TIME [epoch: 9.02 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23132366381939412		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.23132366381939412 | validation: 0.3993626800903906]
	TIME [epoch: 9.02 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611335923834459		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.2611335923834459 | validation: 0.25852416779394455]
	TIME [epoch: 9.01 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24293569533141746		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.24293569533141746 | validation: 0.17171715325068299]
	TIME [epoch: 9.03 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22654774666523406		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.22654774666523406 | validation: 0.31849707810556005]
	TIME [epoch: 9.05 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936122111552486		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.2936122111552486 | validation: 0.13198479920989592]
	TIME [epoch: 9.03 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1811439919752464		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.1811439919752464 | validation: 0.1737097808371398]
	TIME [epoch: 9.03 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23870545853886357		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.23870545853886357 | validation: 0.3509260070678242]
	TIME [epoch: 9.02 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2500014849338211		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.2500014849338211 | validation: 0.22569327800017341]
	TIME [epoch: 9.04 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2305010822880825		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.2305010822880825 | validation: 0.1985067801715768]
	TIME [epoch: 9.02 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26665917552673585		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.26665917552673585 | validation: 0.22001442961768725]
	TIME [epoch: 9.03 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2937259740779754		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.2937259740779754 | validation: 0.14188769565560203]
	TIME [epoch: 9.02 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20168979170877982		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.20168979170877982 | validation: 0.24509242268887005]
	TIME [epoch: 9.02 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2743387249790038		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.2743387249790038 | validation: 0.29975523426927675]
	TIME [epoch: 9.04 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31778808793567803		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.31778808793567803 | validation: 0.3586521854199396]
	TIME [epoch: 9.02 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26929296124343205		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.26929296124343205 | validation: 0.2768820913925357]
	TIME [epoch: 9.01 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303320160266342		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.3303320160266342 | validation: 0.25732962761970873]
	TIME [epoch: 9.01 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28100998715265596		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.28100998715265596 | validation: 0.4469310574553458]
	TIME [epoch: 9.04 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3369677121664714		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.3369677121664714 | validation: 0.27479277878454667]
	TIME [epoch: 9.03 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598329818886928		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.2598329818886928 | validation: 0.3798620772504794]
	TIME [epoch: 9.03 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24289128725560735		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.24289128725560735 | validation: 0.19935391251929258]
	TIME [epoch: 9.02 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2519400872543607		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.2519400872543607 | validation: 0.30588818005203067]
	TIME [epoch: 9.02 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24128968657851013		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.24128968657851013 | validation: 0.28375428050331136]
	TIME [epoch: 9.03 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27965612023986597		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.27965612023986597 | validation: 0.3456685905490654]
	TIME [epoch: 9.01 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21074232343246768		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.21074232343246768 | validation: 0.19174297252179645]
	TIME [epoch: 9.02 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22231758349406405		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.22231758349406405 | validation: 0.2102471514197534]
	TIME [epoch: 9.05 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24547515084866395		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.24547515084866395 | validation: 0.12142543866354555]
	TIME [epoch: 9.02 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2520000893535336		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.2520000893535336 | validation: 0.27700924129361004]
	TIME [epoch: 9.03 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29110050789303626		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.29110050789303626 | validation: 0.27107303300241875]
	TIME [epoch: 9.01 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31917032631275244		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.31917032631275244 | validation: 0.1841878269715727]
	TIME [epoch: 9.01 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23434064296628762		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.23434064296628762 | validation: 0.29133001189877444]
	TIME [epoch: 9.03 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2944174774490954		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.2944174774490954 | validation: 0.28997205683759064]
	TIME [epoch: 9.05 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750729858056181		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.2750729858056181 | validation: 0.2567555807331142]
	TIME [epoch: 9.03 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27687376380995055		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.27687376380995055 | validation: 0.3579644036320453]
	TIME [epoch: 9.02 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3856003545878125		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.3856003545878125 | validation: 0.16984271958350564]
	TIME [epoch: 9.01 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22749110928084876		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.22749110928084876 | validation: 0.43147003836765085]
	TIME [epoch: 9.02 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.426813043991764		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.426813043991764 | validation: 0.2187911863538028]
	TIME [epoch: 9.04 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30742098981033317		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.30742098981033317 | validation: 0.34527044184641054]
	TIME [epoch: 9.01 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28821921643738574		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.28821921643738574 | validation: 0.38655066912389524]
	TIME [epoch: 9.02 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22758803407817857		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.22758803407817857 | validation: 0.12819241494946199]
	TIME [epoch: 9.02 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23950488046440857		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.23950488046440857 | validation: 0.33094704344640724]
	TIME [epoch: 9.03 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922488885337349		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.2922488885337349 | validation: 0.3228830830001739]
	TIME [epoch: 9.02 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29235656504875457		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.29235656504875457 | validation: 0.12953255682612289]
	TIME [epoch: 9.02 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25784259857429614		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.25784259857429614 | validation: 0.17949242851440497]
	TIME [epoch: 9.01 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20431109801269512		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.20431109801269512 | validation: 0.23582321810697168]
	TIME [epoch: 9.01 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2990975119982261		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.2990975119982261 | validation: 0.2954792045229605]
	TIME [epoch: 9.04 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3224673066712312		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.3224673066712312 | validation: 0.17422315004437428]
	TIME [epoch: 9.01 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2829430552516099		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.2829430552516099 | validation: 0.46029328171540684]
	TIME [epoch: 9.01 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27494757305049744		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.27494757305049744 | validation: 0.27702198278710477]
	TIME [epoch: 9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760630451017979		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.2760630451017979 | validation: 0.22678886891190841]
	TIME [epoch: 9.01 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18326114411607894		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.18326114411607894 | validation: 0.1599536166241628]
	TIME [epoch: 9.05 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23267574438669253		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.23267574438669253 | validation: 0.2025033173967664]
	TIME [epoch: 9.02 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19106314560089827		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.19106314560089827 | validation: 0.29180479889394895]
	TIME [epoch: 9.03 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21930001438899524		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.21930001438899524 | validation: 0.19890620969280504]
	TIME [epoch: 9.02 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2401424221385713		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.2401424221385713 | validation: 0.13376046873747502]
	TIME [epoch: 9.04 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950552107431541		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.1950552107431541 | validation: 0.19904897127510923]
	TIME [epoch: 9.03 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24669209821655375		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.24669209821655375 | validation: 0.14872207258834919]
	TIME [epoch: 9.02 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2166075073817481		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.2166075073817481 | validation: 0.2507508789336172]
	TIME [epoch: 9.02 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20947729747569643		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.20947729747569643 | validation: 0.17051985873964665]
	TIME [epoch: 9.03 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2377448738899716		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.2377448738899716 | validation: 0.3072757013670201]
	TIME [epoch: 9.04 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2543675013887516		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.2543675013887516 | validation: 0.1780034870843374]
	TIME [epoch: 9.02 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20937884406331558		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.20937884406331558 | validation: 0.19172192332834964]
	TIME [epoch: 9.01 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25013923161672247		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.25013923161672247 | validation: 0.1456921714399858]
	TIME [epoch: 9.02 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19670623883982508		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.19670623883982508 | validation: 0.23032985793905625]
	TIME [epoch: 9.03 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1987790051667379		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.1987790051667379 | validation: 0.17691744527177777]
	TIME [epoch: 9.04 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2217110942029925		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.2217110942029925 | validation: 0.1496305165723416]
	TIME [epoch: 9.02 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19905237372352405		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.19905237372352405 | validation: 0.1473700957444965]
	TIME [epoch: 9.02 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1903769005533173		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.1903769005533173 | validation: 0.1388755896172233]
	TIME [epoch: 9.02 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22628993678867007		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.22628993678867007 | validation: 0.1970682404390437]
	TIME [epoch: 9.05 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21295993806471086		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.21295993806471086 | validation: 0.280275842937097]
	TIME [epoch: 9.02 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21060968945246214		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.21060968945246214 | validation: 0.33045304183208596]
	TIME [epoch: 9.02 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1965770047015311		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.1965770047015311 | validation: 0.24381020828120187]
	TIME [epoch: 9.02 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22438984184457506		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.22438984184457506 | validation: 0.1339419395159891]
	TIME [epoch: 9.02 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2061368607490114		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.2061368607490114 | validation: 0.39083574814656225]
	TIME [epoch: 9.05 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516627350035943		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.2516627350035943 | validation: 0.25721282974061965]
	TIME [epoch: 9.02 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2828378213628157		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.2828378213628157 | validation: 0.20214630660059205]
	TIME [epoch: 9.02 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26067325368792416		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.26067325368792416 | validation: 0.21318403679057424]
	TIME [epoch: 9.02 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19891617327751546		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.19891617327751546 | validation: 0.24173542791851318]
	TIME [epoch: 9.04 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21214895472781606		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.21214895472781606 | validation: 0.17765666654540063]
	TIME [epoch: 9.04 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.268645688613767		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.268645688613767 | validation: 0.2757402738900662]
	TIME [epoch: 9.04 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978431949755328		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.2978431949755328 | validation: 0.16186509935270366]
	TIME [epoch: 9.01 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22889525372820868		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.22889525372820868 | validation: 0.21361856964111794]
	TIME [epoch: 9.02 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21861902168087885		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.21861902168087885 | validation: 0.2650739189285427]
	TIME [epoch: 9.03 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21550798788445125		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.21550798788445125 | validation: 0.1800978125910348]
	TIME [epoch: 9.03 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20004268977015158		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.20004268977015158 | validation: 0.1255735038213775]
	TIME [epoch: 9.02 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19129003143069695		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.19129003143069695 | validation: 0.14592741553538421]
	TIME [epoch: 9.02 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598831325382173		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.2598831325382173 | validation: 0.16121622754175835]
	TIME [epoch: 9.02 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20287105177436962		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.20287105177436962 | validation: 0.17564849000393368]
	TIME [epoch: 9.03 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21814056357266462		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.21814056357266462 | validation: 0.20020930266429082]
	TIME [epoch: 9.02 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16959231862685822		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.16959231862685822 | validation: 0.2067640948972636]
	TIME [epoch: 9.02 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24317895752492938		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.24317895752492938 | validation: 0.1435113929112649]
	TIME [epoch: 9.01 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1951459668042811		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.1951459668042811 | validation: 0.12578115646825758]
	TIME [epoch: 9.03 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20901315645206314		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.20901315645206314 | validation: 0.16725347796455042]
	TIME [epoch: 9.03 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20969648616508088		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.20969648616508088 | validation: 0.21548004782270472]
	TIME [epoch: 9.03 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21311507188714293		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.21311507188714293 | validation: 0.29448168860796]
	TIME [epoch: 9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2190732045495433		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.2190732045495433 | validation: 0.25913716699656597]
	TIME [epoch: 9.02 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26428951770631437		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.26428951770631437 | validation: 0.17701938799726175]
	TIME [epoch: 9.03 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18404934080638075		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.18404934080638075 | validation: 0.14785843271581015]
	TIME [epoch: 9.02 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2260274932391591		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.2260274932391591 | validation: 0.22686993885424128]
	TIME [epoch: 9.02 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23354536483648838		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.23354536483648838 | validation: 0.3169134799853703]
	TIME [epoch: 9.01 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21086970519487785		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.21086970519487785 | validation: 0.22857870139760955]
	TIME [epoch: 9.03 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26700360122987415		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.26700360122987415 | validation: 0.42614711198403676]
	TIME [epoch: 9.03 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859707418103109		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.2859707418103109 | validation: 0.18779066350973897]
	TIME [epoch: 9.01 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2640776995762494		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.2640776995762494 | validation: 0.3460408533940517]
	TIME [epoch: 9.02 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844228220198847		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.1844228220198847 | validation: 0.16058069430765443]
	TIME [epoch: 9.02 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16924772547202557		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.16924772547202557 | validation: 0.24020222461589236]
	TIME [epoch: 9.04 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22482148858990728		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.22482148858990728 | validation: 0.287875419398939]
	TIME [epoch: 9.03 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2401351368039395		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.2401351368039395 | validation: 0.2893983330765133]
	TIME [epoch: 9.02 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22962736726664912		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.22962736726664912 | validation: 0.23325553032386265]
	TIME [epoch: 9.01 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18673217435000408		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.18673217435000408 | validation: 0.14106261912949647]
	TIME [epoch: 9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19887228818903782		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.19887228818903782 | validation: 0.3105047329305015]
	TIME [epoch: 9.05 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21683649291611423		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.21683649291611423 | validation: 0.1256924704823465]
	TIME [epoch: 9.03 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973470819827541		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.1973470819827541 | validation: 0.16808776760836328]
	TIME [epoch: 9.02 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671706766855472		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.2671706766855472 | validation: 0.38212846083820096]
	TIME [epoch: 9.02 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24903759592711833		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.24903759592711833 | validation: 0.22381322497054637]
	TIME [epoch: 9.04 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.157166794578625		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.157166794578625 | validation: 0.14372335864617383]
	TIME [epoch: 9.02 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20648546728553238		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.20648546728553238 | validation: 0.15472702947263683]
	TIME [epoch: 9.01 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19447555443253067		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.19447555443253067 | validation: 0.17066797777134662]
	TIME [epoch: 9.01 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19867199952187148		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.19867199952187148 | validation: 0.22783430715305436]
	TIME [epoch: 9.01 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20567462505563677		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.20567462505563677 | validation: 0.2148827565652762]
	TIME [epoch: 9.03 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929237222032088		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.2929237222032088 | validation: 0.2556391968881031]
	TIME [epoch: 9.02 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19736805237293958		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.19736805237293958 | validation: 0.17029361674378243]
	TIME [epoch: 9.01 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20192495064622634		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.20192495064622634 | validation: 0.18032423880862475]
	TIME [epoch: 9.01 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21762785665521894		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.21762785665521894 | validation: 0.25211778425338655]
	TIME [epoch: 9.03 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2120214349106902		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.2120214349106902 | validation: 0.1568088145208275]
	TIME [epoch: 9.03 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.174976784422854		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.174976784422854 | validation: 0.21408300592774168]
	TIME [epoch: 9.03 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21758653737763428		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.21758653737763428 | validation: 0.22322585685114893]
	TIME [epoch: 9.02 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22943343091344853		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.22943343091344853 | validation: 0.17274304271998747]
	TIME [epoch: 9.01 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22547092965944776		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.22547092965944776 | validation: 0.22686056162413387]
	TIME [epoch: 9.04 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2083290264544305		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.2083290264544305 | validation: 0.22305689934807785]
	TIME [epoch: 9.02 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2082829110134808		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.2082829110134808 | validation: 0.28055630294203326]
	TIME [epoch: 9.01 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340329665434668		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.4340329665434668 | validation: 0.1471805443148602]
	TIME [epoch: 9.01 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19839738263790205		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.19839738263790205 | validation: 0.32251939652847117]
	TIME [epoch: 9.01 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2503005346933258		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.2503005346933258 | validation: 0.3206289500485421]
	TIME [epoch: 9.04 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2729460138376149		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.2729460138376149 | validation: 0.19586208014674733]
	TIME [epoch: 9.01 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18006231854194657		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.18006231854194657 | validation: 0.1291380798811431]
	TIME [epoch: 9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18859159231501438		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.18859159231501438 | validation: 0.1373741387530361]
	TIME [epoch: 9.01 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20303835842582957		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.20303835842582957 | validation: 0.39157459175801335]
	TIME [epoch: 9.03 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22801698697154835		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.22801698697154835 | validation: 0.19360159078185124]
	TIME [epoch: 9.03 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22557082483123292		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.22557082483123292 | validation: 0.2281529244393526]
	TIME [epoch: 9.01 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19381134641003314		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.19381134641003314 | validation: 0.15135402302034653]
	TIME [epoch: 9.02 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2438066417866999		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.2438066417866999 | validation: 0.24104593760311466]
	TIME [epoch: 9.01 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2187816932164995		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.2187816932164995 | validation: 0.25379497118177874]
	TIME [epoch: 9.04 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20144909643930448		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.20144909643930448 | validation: 0.11995707909803036]
	TIME [epoch: 9.03 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19476648814528513		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.19476648814528513 | validation: 0.17266258607958418]
	TIME [epoch: 9.01 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3177598996958535		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.3177598996958535 | validation: 0.17230834601306497]
	TIME [epoch: 9.02 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.217341604851079		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.217341604851079 | validation: 0.19285093259966402]
	TIME [epoch: 9.03 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19614039131309402		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.19614039131309402 | validation: 0.1811544096570611]
	TIME [epoch: 9.02 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19166764510171627		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.19166764510171627 | validation: 0.12341340395699621]
	TIME [epoch: 9.01 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2000805959345318		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.2000805959345318 | validation: 0.1522377647457094]
	TIME [epoch: 9.01 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18271799944739348		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.18271799944739348 | validation: 0.16627200932666464]
	TIME [epoch: 9.02 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21961446316644548		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.21961446316644548 | validation: 0.18863470841157215]
	TIME [epoch: 9.04 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24784260951217077		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.24784260951217077 | validation: 0.19015426725976506]
	TIME [epoch: 9.02 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15150042491964522		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.15150042491964522 | validation: 0.1748466355600567]
	TIME [epoch: 9.02 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17451839386197662		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.17451839386197662 | validation: 0.1460079869700523]
	TIME [epoch: 9.01 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1936886711756876		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.1936886711756876 | validation: 0.19646828190233573]
	TIME [epoch: 9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18950905535259213		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.18950905535259213 | validation: 0.31315926319977466]
	TIME [epoch: 9.04 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18742558064450165		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.18742558064450165 | validation: 0.19623480344228855]
	TIME [epoch: 9.02 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15027990555439177		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.15027990555439177 | validation: 0.15820020815272878]
	TIME [epoch: 9.02 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17876968850800082		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.17876968850800082 | validation: 0.2159532501245593]
	TIME [epoch: 9.01 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16575372699102586		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.16575372699102586 | validation: 0.10310015249082205]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646312145678899		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.1646312145678899 | validation: 0.08440511749270149]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16219738595302954		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.16219738595302954 | validation: 0.19538983417922529]
	TIME [epoch: 9.02 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17435080797185987		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.17435080797185987 | validation: 0.14136968055496485]
	TIME [epoch: 9.01 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1781424715176196		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.1781424715176196 | validation: 0.08935207753378435]
	TIME [epoch: 9.02 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700488411938565		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.1700488411938565 | validation: 0.22633859906959755]
	TIME [epoch: 9.03 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1796653165970769		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.1796653165970769 | validation: 0.15005530293113956]
	TIME [epoch: 9.02 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933786860468209		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.1933786860468209 | validation: 0.17607690024477177]
	TIME [epoch: 9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1789250337329971		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.1789250337329971 | validation: 0.07840639185161086]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16505020898284645		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.16505020898284645 | validation: 0.142847251620212]
	TIME [epoch: 9.02 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14779238509275458		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.14779238509275458 | validation: 0.13961016056993686]
	TIME [epoch: 9.02 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22202139244243096		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.22202139244243096 | validation: 0.08885931549088649]
	TIME [epoch: 9.02 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17454782185067058		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.17454782185067058 | validation: 0.28711407586634263]
	TIME [epoch: 9.01 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22767727382948025		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.22767727382948025 | validation: 0.28424395378540124]
	TIME [epoch: 9.02 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16526583171080778		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.16526583171080778 | validation: 0.15725849898272648]
	TIME [epoch: 9.03 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15635785790061574		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.15635785790061574 | validation: 0.13147449093201558]
	TIME [epoch: 9.01 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23165621089583915		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.23165621089583915 | validation: 0.18059821615693722]
	TIME [epoch: 9.02 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2043243304332968		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.2043243304332968 | validation: 0.34427349943538077]
	TIME [epoch: 9.01 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18204480978862603		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.18204480978862603 | validation: 0.17808285837656745]
	TIME [epoch: 9.01 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21754130556857043		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.21754130556857043 | validation: 0.2265178219930719]
	TIME [epoch: 9.04 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18589870745987164		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.18589870745987164 | validation: 0.08871869164994084]
	TIME [epoch: 9.01 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18504494426578516		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.18504494426578516 | validation: 0.14442187525383898]
	TIME [epoch: 9.02 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20910551523217813		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.20910551523217813 | validation: 0.3697295238912195]
	TIME [epoch: 9.02 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2548857611389073		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.2548857611389073 | validation: 0.2911442443516362]
	TIME [epoch: 9.03 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19192733193609218		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.19192733193609218 | validation: 0.24430512720892072]
	TIME [epoch: 9.02 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25450570280843865		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.25450570280843865 | validation: 0.2712584106365874]
	TIME [epoch: 9.01 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15947131741269088		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.15947131741269088 | validation: 0.10417346478183331]
	TIME [epoch: 9.01 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15134840852712442		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.15134840852712442 | validation: 0.10554127704455775]
	TIME [epoch: 9.02 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19772421849333405		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.19772421849333405 | validation: 0.13112081817606525]
	TIME [epoch: 9.03 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13600038632706496		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.13600038632706496 | validation: 0.17284985045706364]
	TIME [epoch: 9.02 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20689526908759187		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.20689526908759187 | validation: 0.24807611950031194]
	TIME [epoch: 9.02 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615985713046439		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.1615985713046439 | validation: 0.15427465301381305]
	TIME [epoch: 9.03 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18028855004746913		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.18028855004746913 | validation: 0.1312481385097985]
	TIME [epoch: 9.03 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19574589235181972		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.19574589235181972 | validation: 0.2526224976483994]
	TIME [epoch: 9.02 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662085472918587		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.1662085472918587 | validation: 0.13451862271787368]
	TIME [epoch: 9.02 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300871379985253		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.2300871379985253 | validation: 0.13544159530462935]
	TIME [epoch: 9.01 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18852381381283648		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.18852381381283648 | validation: 0.1304250686033282]
	TIME [epoch: 9.01 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19925414310327982		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.19925414310327982 | validation: 0.13094418708675304]
	TIME [epoch: 9.04 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15291911747310682		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.15291911747310682 | validation: 0.16714197229470604]
	TIME [epoch: 9.03 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19136162077348673		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.19136162077348673 | validation: 0.15717558867338666]
	TIME [epoch: 9.01 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1785035941550038		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.1785035941550038 | validation: 0.23389206431850496]
	TIME [epoch: 9.01 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18437152203093338		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.18437152203093338 | validation: 0.20003098112871123]
	TIME [epoch: 9.02 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19922846159782331		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.19922846159782331 | validation: 0.13353944000141307]
	TIME [epoch: 9.05 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1465569039949833		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.1465569039949833 | validation: 0.16798716957166815]
	TIME [epoch: 9.02 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278367818168007		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.2278367818168007 | validation: 0.1441580831952981]
	TIME [epoch: 9.03 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24980966470641675		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.24980966470641675 | validation: 0.45088321644355833]
	TIME [epoch: 9.02 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3308621807814393		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.3308621807814393 | validation: 0.19338262694363614]
	TIME [epoch: 9.04 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18347692195983223		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.18347692195983223 | validation: 0.2967039865566407]
	TIME [epoch: 9.03 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2160975754568045		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.2160975754568045 | validation: 0.2620117372599803]
	TIME [epoch: 9.02 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21412408094892244		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.21412408094892244 | validation: 0.2541209580641079]
	TIME [epoch: 9.03 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2655709254793587		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.2655709254793587 | validation: 0.24480549293798248]
	TIME [epoch: 9.02 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17803638877554384		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.17803638877554384 | validation: 0.209589547623548]
	TIME [epoch: 9.05 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14675890769588382		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.14675890769588382 | validation: 0.3293317779332753]
	TIME [epoch: 9.03 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20684984934129597		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.20684984934129597 | validation: 0.12131485731385312]
	TIME [epoch: 9.02 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20155228927461807		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.20155228927461807 | validation: 0.18903563750581326]
	TIME [epoch: 9.03 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15485664795328152		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.15485664795328152 | validation: 0.28434303186179966]
	TIME [epoch: 9.01 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19460423592375858		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.19460423592375858 | validation: 0.11791938932875545]
	TIME [epoch: 9.06 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13889856119305302		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.13889856119305302 | validation: 0.17834404145721575]
	TIME [epoch: 9.02 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18746111193942935		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.18746111193942935 | validation: 0.11386097476715726]
	TIME [epoch: 9.03 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19986524092591826		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.19986524092591826 | validation: 0.13205742260267855]
	TIME [epoch: 9.02 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1626206437595983		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.1626206437595983 | validation: 0.1917507194398369]
	TIME [epoch: 9.03 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23334473029753391		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.23334473029753391 | validation: 0.2526028664193676]
	TIME [epoch: 9.02 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29693282078870864		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.29693282078870864 | validation: 0.20803594274046228]
	TIME [epoch: 9.02 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17991858308176778		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.17991858308176778 | validation: 0.18562845470058392]
	TIME [epoch: 9.02 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15087500603717086		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.15087500603717086 | validation: 0.1691985045674908]
	TIME [epoch: 9.02 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1840620085223914		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.1840620085223914 | validation: 0.1479594545033584]
	TIME [epoch: 9.04 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20958036764196222		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.20958036764196222 | validation: 0.2367382738475805]
	TIME [epoch: 9.02 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1776326377976815		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.1776326377976815 | validation: 0.1375768543157386]
	TIME [epoch: 9.02 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1426039323548052		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.1426039323548052 | validation: 0.27146000240119617]
	TIME [epoch: 9.02 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1923321482579932		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.1923321482579932 | validation: 0.23784331375856477]
	TIME [epoch: 9.04 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19926285272342265		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.19926285272342265 | validation: 0.0768390091826555]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14546430639830635		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.14546430639830635 | validation: 0.07073843732451277]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_765.pth
	Model improved!!!
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14260640622717083		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.14260640622717083 | validation: 0.07022763170452756]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14565832492824357		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.14565832492824357 | validation: 0.11973170392394636]
	TIME [epoch: 9.02 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1735659606862984		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.1735659606862984 | validation: 0.07652397584523277]
	TIME [epoch: 9.04 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13359486208820556		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.13359486208820556 | validation: 0.12825836242450744]
	TIME [epoch: 9.02 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972797730132886		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.14972797730132886 | validation: 0.10917869715742984]
	TIME [epoch: 9.02 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14475258863203375		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.14475258863203375 | validation: 0.10022685714525778]
	TIME [epoch: 9.02 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13913348444738965		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.13913348444738965 | validation: 0.0877548105367868]
	TIME [epoch: 9.02 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17120483960487395		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.17120483960487395 | validation: 0.12993675946176944]
	TIME [epoch: 9.03 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16628573564047433		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.16628573564047433 | validation: 0.15819533926613416]
	TIME [epoch: 9.02 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458977320745525		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.1458977320745525 | validation: 0.12643510710889425]
	TIME [epoch: 9.01 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17482464553976476		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.17482464553976476 | validation: 0.09939219397829435]
	TIME [epoch: 9.03 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19323041937806784		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.19323041937806784 | validation: 0.11169215566582755]
	TIME [epoch: 9.05 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1716874328158151		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.1716874328158151 | validation: 0.27792002471671856]
	TIME [epoch: 9.03 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18642029295011026		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.18642029295011026 | validation: 0.10929406919018006]
	TIME [epoch: 9.03 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16577582496573542		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.16577582496573542 | validation: 0.28472661003647837]
	TIME [epoch: 9.02 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1870353928986776		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.1870353928986776 | validation: 0.08728306382102691]
	TIME [epoch: 9.03 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18827973471490417		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.18827973471490417 | validation: 0.18610214754006987]
	TIME [epoch: 9.05 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029748487731203		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.2029748487731203 | validation: 0.20973367818775623]
	TIME [epoch: 9.03 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1847810358578502		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.1847810358578502 | validation: 0.2546855927698735]
	TIME [epoch: 9.03 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2130133889779545		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.2130133889779545 | validation: 0.13282009219941007]
	TIME [epoch: 9.03 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16542976631710976		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.16542976631710976 | validation: 0.29137229782905416]
	TIME [epoch: 9.05 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16131486515847082		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.16131486515847082 | validation: 0.21493349165649672]
	TIME [epoch: 9.03 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2174974214019801		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.2174974214019801 | validation: 0.1077394023735004]
	TIME [epoch: 9.03 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16429900535573055		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.16429900535573055 | validation: 0.12332532912433997]
	TIME [epoch: 9.03 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16503690931530593		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.16503690931530593 | validation: 0.20809611003638018]
	TIME [epoch: 9.03 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2308403111159508		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.2308403111159508 | validation: 0.21255202820304825]
	TIME [epoch: 9.06 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20592273162554137		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.20592273162554137 | validation: 0.13929006869774502]
	TIME [epoch: 9.04 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.155541619099208		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.155541619099208 | validation: 0.16085162142196552]
	TIME [epoch: 9.04 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16742980193023033		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.16742980193023033 | validation: 0.13462955239797253]
	TIME [epoch: 9.03 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607276898822205		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.1607276898822205 | validation: 0.1142212355519214]
	TIME [epoch: 9.04 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10997883532384276		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.10997883532384276 | validation: 0.10780753659680373]
	TIME [epoch: 9.05 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15111375170951036		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.15111375170951036 | validation: 0.10125887439679204]
	TIME [epoch: 9.04 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15811301972093356		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.15811301972093356 | validation: 0.07506167817454401]
	TIME [epoch: 9.04 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18210544506259851		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.18210544506259851 | validation: 0.19398683790922025]
	TIME [epoch: 9.03 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882476342267662		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.1882476342267662 | validation: 0.1668605897924561]
	TIME [epoch: 9.05 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15557327646619556		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.15557327646619556 | validation: 0.1413609560738227]
	TIME [epoch: 9.04 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12350187778103294		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.12350187778103294 | validation: 0.10855968749748587]
	TIME [epoch: 9.03 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.175210556009483		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.175210556009483 | validation: 0.2970891544368281]
	TIME [epoch: 9.04 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17625817976837657		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.17625817976837657 | validation: 0.09110589216856455]
	TIME [epoch: 9.04 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670153030210118		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.1670153030210118 | validation: 0.15329851647744389]
	TIME [epoch: 9.06 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1736749349177718		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.1736749349177718 | validation: 0.12912455264082295]
	TIME [epoch: 9.04 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15826021043052207		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.15826021043052207 | validation: 0.10219445811300232]
	TIME [epoch: 9.03 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13953837116052167		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.13953837116052167 | validation: 0.1421703433582327]
	TIME [epoch: 9.03 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15228757173784752		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.15228757173784752 | validation: 0.13255206645121875]
	TIME [epoch: 9.04 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14703050391848133		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.14703050391848133 | validation: 0.08923988576028191]
	TIME [epoch: 9.03 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484599237747918		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.1484599237747918 | validation: 0.10666248795740246]
	TIME [epoch: 9.02 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13318004003337477		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.13318004003337477 | validation: 0.13276673967006525]
	TIME [epoch: 9.02 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15763371652423255		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.15763371652423255 | validation: 0.15716713520499692]
	TIME [epoch: 9.02 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15077959666996305		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.15077959666996305 | validation: 0.11432524544976937]
	TIME [epoch: 9.04 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508303012281647		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.1508303012281647 | validation: 0.14186434878396423]
	TIME [epoch: 9.01 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19624148040004777		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.19624148040004777 | validation: 0.07771604935593393]
	TIME [epoch: 9.03 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13484585898808968		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.13484585898808968 | validation: 0.097833259638715]
	TIME [epoch: 9.02 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1339094008403545		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.1339094008403545 | validation: 0.10021196827913303]
	TIME [epoch: 9.02 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16307413573558843		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.16307413573558843 | validation: 0.13813011988204554]
	TIME [epoch: 9.04 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18204120572864904		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.18204120572864904 | validation: 0.15659516445308574]
	TIME [epoch: 9.01 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17376575253542045		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.17376575253542045 | validation: 0.13242929897759784]
	TIME [epoch: 9.01 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1771554979233748		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.1771554979233748 | validation: 0.09419301555671036]
	TIME [epoch: 9.01 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18922257202224707		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.18922257202224707 | validation: 0.09820407556879951]
	TIME [epoch: 9.03 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1357396456759417		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.1357396456759417 | validation: 0.1009019857022297]
	TIME [epoch: 9.02 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15862801977982122		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.15862801977982122 | validation: 0.16897617937184856]
	TIME [epoch: 9.02 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229277385508254		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.14229277385508254 | validation: 0.09170629851977113]
	TIME [epoch: 9.02 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16828762761381957		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.16828762761381957 | validation: 0.09459857959324276]
	TIME [epoch: 9.01 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13368280939561386		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.13368280939561386 | validation: 0.10010572077857496]
	TIME [epoch: 9.03 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13536449221632327		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.13536449221632327 | validation: 0.11513211922853522]
	TIME [epoch: 9.03 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14263337616508628		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.14263337616508628 | validation: 0.13976645459521936]
	TIME [epoch: 9.02 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14458989651902535		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.14458989651902535 | validation: 0.06347065817750684]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12360408935549072		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.12360408935549072 | validation: 0.17732540528249036]
	TIME [epoch: 9.05 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16373931711714113		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.16373931711714113 | validation: 0.17961889478009563]
	TIME [epoch: 9.02 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15159661533242114		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.15159661533242114 | validation: 0.1294053423121348]
	TIME [epoch: 9.02 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17680107723433983		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.17680107723433983 | validation: 0.24995643203357817]
	TIME [epoch: 9.01 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2876787108820425		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.2876787108820425 | validation: 0.26013465008026454]
	TIME [epoch: 9.03 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25142070974731157		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.25142070974731157 | validation: 0.2565238130004829]
	TIME [epoch: 9.04 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18844651942982715		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.18844651942982715 | validation: 0.1455529393622338]
	TIME [epoch: 9.02 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14931638793101407		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.14931638793101407 | validation: 0.13510385631969196]
	TIME [epoch: 9.02 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15112486039577175		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.15112486039577175 | validation: 0.2865555476881121]
	TIME [epoch: 9.02 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16532590590801344		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.16532590590801344 | validation: 0.11169236434864034]
	TIME [epoch: 9.02 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12104824540708917		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.12104824540708917 | validation: 0.10194213747406435]
	TIME [epoch: 9.04 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13403718202148346		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.13403718202148346 | validation: 0.2817474121352447]
	TIME [epoch: 9.02 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16825247849342012		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.16825247849342012 | validation: 0.25407043745482283]
	TIME [epoch: 9.02 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17990008135164579		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.17990008135164579 | validation: 0.19548434801215486]
	TIME [epoch: 9.01 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367199107478589		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.1367199107478589 | validation: 0.09746521506573533]
	TIME [epoch: 9.03 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13599834855972562		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.13599834855972562 | validation: 0.07578836720026594]
	TIME [epoch: 9.03 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11632825725871834		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.11632825725871834 | validation: 0.21423585491859454]
	TIME [epoch: 9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332354606778169		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.1332354606778169 | validation: 0.17327560320311863]
	TIME [epoch: 9.02 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14621878638797356		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.14621878638797356 | validation: 0.15770898288435464]
	TIME [epoch: 9.04 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18881104350463765		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.18881104350463765 | validation: 0.1375928388279964]
	TIME [epoch: 9.03 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12156147310704812		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.12156147310704812 | validation: 0.06052500394898788]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10199416835675981		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.10199416835675981 | validation: 0.115464046294159]
	TIME [epoch: 9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14042090602309684		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.14042090602309684 | validation: 0.12814897121112306]
	TIME [epoch: 9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18724752697938185		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.18724752697938185 | validation: 0.3181193155814333]
	TIME [epoch: 9.02 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18771783717321971		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.18771783717321971 | validation: 0.10868751269147572]
	TIME [epoch: 9.02 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14166799121231327		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.14166799121231327 | validation: 0.07928248196129731]
	TIME [epoch: 9.02 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13985571051141016		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.13985571051141016 | validation: 0.08951181135791439]
	TIME [epoch: 9.02 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12820078930808637		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.12820078930808637 | validation: 0.1263581255348507]
	TIME [epoch: 9.01 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1560193438099872		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.1560193438099872 | validation: 0.07698640841739607]
	TIME [epoch: 9.03 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14873747991281352		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.14873747991281352 | validation: 0.1247797447061417]
	TIME [epoch: 9.01 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15159520180329614		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.15159520180329614 | validation: 0.0982832025872539]
	TIME [epoch: 9.01 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1552942437123323		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.1552942437123323 | validation: 0.10011539123861052]
	TIME [epoch: 9.01 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15429706298656487		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.15429706298656487 | validation: 0.22425771106410297]
	TIME [epoch: 9.01 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15407583584155862		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.15407583584155862 | validation: 0.17578768839460723]
	TIME [epoch: 9.03 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1380461304406475		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.1380461304406475 | validation: 0.1448924248649699]
	TIME [epoch: 9.01 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14411534930647718		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.14411534930647718 | validation: 0.17671457438801347]
	TIME [epoch: 9.02 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15784428121208824		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.15784428121208824 | validation: 0.1147977883842192]
	TIME [epoch: 9.01 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11444140792679539		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.11444140792679539 | validation: 0.10661898700005834]
	TIME [epoch: 9.04 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14216597840704018		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.14216597840704018 | validation: 0.12107649134261858]
	TIME [epoch: 9.03 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15496575359333473		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.15496575359333473 | validation: 0.09996891328356242]
	TIME [epoch: 9.02 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17274153394332745		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.17274153394332745 | validation: 0.13952672209433]
	TIME [epoch: 9.02 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14200698020363156		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.14200698020363156 | validation: 0.15212137112757118]
	TIME [epoch: 9.01 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.139818891075896		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.139818891075896 | validation: 0.10371994738935864]
	TIME [epoch: 9.03 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11873321679242133		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.11873321679242133 | validation: 0.0853371422468045]
	TIME [epoch: 9.02 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13128626316853598		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.13128626316853598 | validation: 0.0718114699197379]
	TIME [epoch: 9.01 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14904833361322162		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.14904833361322162 | validation: 0.1136061480162905]
	TIME [epoch: 9.02 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14737587342685368		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.14737587342685368 | validation: 0.10309032803133542]
	TIME [epoch: 9.03 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12200252432867564		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.12200252432867564 | validation: 0.11914531189439306]
	TIME [epoch: 9.02 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15183190624977821		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.15183190624977821 | validation: 0.1622286769381078]
	TIME [epoch: 9.01 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15769295937271383		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.15769295937271383 | validation: 0.07958527907825244]
	TIME [epoch: 9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1343341847309061		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.1343341847309061 | validation: 0.1089698407699036]
	TIME [epoch: 9.02 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17668850817940468		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.17668850817940468 | validation: 0.13045618156023403]
	TIME [epoch: 9.03 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10800923935339365		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.10800923935339365 | validation: 0.07437204160013802]
	TIME [epoch: 9.02 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13790920271621487		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.13790920271621487 | validation: 0.18625418320999204]
	TIME [epoch: 9.01 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16662075198374077		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.16662075198374077 | validation: 0.09812242467764079]
	TIME [epoch: 9.01 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12961666015026738		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.12961666015026738 | validation: 0.1055815244378778]
	TIME [epoch: 9.02 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12942685849118066		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.12942685849118066 | validation: 0.11955082577733886]
	TIME [epoch: 9.03 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11942098207454337		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.11942098207454337 | validation: 0.08226086942068575]
	TIME [epoch: 9.02 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1584864341079425		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.1584864341079425 | validation: 0.21118155483134501]
	TIME [epoch: 9.02 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20920780468712574		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.20920780468712574 | validation: 0.11758377978450038]
	TIME [epoch: 9.01 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16649706926470523		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.16649706926470523 | validation: 0.1494316372161335]
	TIME [epoch: 9.04 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618658142732619		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.1618658142732619 | validation: 0.096209583399477]
	TIME [epoch: 9.01 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15107010127279336		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.15107010127279336 | validation: 0.13200420544679387]
	TIME [epoch: 9.01 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17633209294182706		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.17633209294182706 | validation: 0.16328814515941964]
	TIME [epoch: 9.01 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20212402570185417		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.20212402570185417 | validation: 0.20133407509140713]
	TIME [epoch: 9.01 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19437389917763548		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.19437389917763548 | validation: 0.19922229723661541]
	TIME [epoch: 9.03 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1427753545963089		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.1427753545963089 | validation: 0.07726173548400397]
	TIME [epoch: 9.01 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11403057497871036		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.11403057497871036 | validation: 0.10099879689279918]
	TIME [epoch: 9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1341298092621075		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.1341298092621075 | validation: 0.10814793267380891]
	TIME [epoch: 9.01 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09895242128068057		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.09895242128068057 | validation: 0.18386356730963052]
	TIME [epoch: 9.01 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12110612776703678		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.12110612776703678 | validation: 0.13165774262987487]
	TIME [epoch: 9.03 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1314332255534328		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.1314332255534328 | validation: 0.09980275119289034]
	TIME [epoch: 9.01 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1191365076354531		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.1191365076354531 | validation: 0.09243927108977876]
	TIME [epoch: 9.01 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17308387499259897		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.17308387499259897 | validation: 0.08201518668009009]
	TIME [epoch: 9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14135397710164818		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.14135397710164818 | validation: 0.11249616011909372]
	TIME [epoch: 9.02 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11527125534701428		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.11527125534701428 | validation: 0.11160414644939534]
	TIME [epoch: 9.01 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12851339908634662		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.12851339908634662 | validation: 0.09279952652340165]
	TIME [epoch: 9.01 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16947601898705805		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.16947601898705805 | validation: 0.06705251941543262]
	TIME [epoch: 9.02 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11341011539065897		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.11341011539065897 | validation: 0.07644721686147307]
	TIME [epoch: 9.01 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003359127796036		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.12003359127796036 | validation: 0.10449384238599371]
	TIME [epoch: 9.03 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10678572787027493		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.10678572787027493 | validation: 0.11144651690120283]
	TIME [epoch: 9.01 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11900128211105605		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.11900128211105605 | validation: 0.1454040939550365]
	TIME [epoch: 9.01 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557011757686914		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.1557011757686914 | validation: 0.10897217198068002]
	TIME [epoch: 9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14454950659107876		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.14454950659107876 | validation: 0.06540914119760496]
	TIME [epoch: 9.03 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238618378068866		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.1238618378068866 | validation: 0.18452138626744896]
	TIME [epoch: 9.01 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277804003986503		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.1277804003986503 | validation: 0.10585140669909818]
	TIME [epoch: 9.01 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11476601088726249		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.11476601088726249 | validation: 0.09137954269632362]
	TIME [epoch: 9.01 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15233133172769722		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.15233133172769722 | validation: 0.1353274993539238]
	TIME [epoch: 9.01 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613699620514329		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.1613699620514329 | validation: 0.16382432745389008]
	TIME [epoch: 9.03 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399159665848187		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.1399159665848187 | validation: 0.1590518100027114]
	TIME [epoch: 9.01 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13476851313385435		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.13476851313385435 | validation: 0.07807172141448566]
	TIME [epoch: 9.01 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1198049421937272		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.1198049421937272 | validation: 0.06550183997897299]
	TIME [epoch: 9.01 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13092798135221434		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.13092798135221434 | validation: 0.14088112606638564]
	TIME [epoch: 9.01 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13922182117611298		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.13922182117611298 | validation: 0.14936016512810668]
	TIME [epoch: 9.04 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16387531670078043		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.16387531670078043 | validation: 0.1355137347156093]
	TIME [epoch: 9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126537981788491		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.126537981788491 | validation: 0.08916652244591072]
	TIME [epoch: 9.01 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1389243172463331		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.1389243172463331 | validation: 0.0813181523682535]
	TIME [epoch: 9.01 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11768978116018662		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.11768978116018662 | validation: 0.07249668231157722]
	TIME [epoch: 9.03 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11227917664099567		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.11227917664099567 | validation: 0.08152397931492683]
	TIME [epoch: 9.02 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11001474585661426		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.11001474585661426 | validation: 0.08007566698560184]
	TIME [epoch: 9.01 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11522730231171263		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.11522730231171263 | validation: 0.09829471527149766]
	TIME [epoch: 9.01 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12155072797046244		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.12155072797046244 | validation: 0.10384309711324619]
	TIME [epoch: 9.02 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12248431261463077		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.12248431261463077 | validation: 0.0741916821604495]
	TIME [epoch: 9.03 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11704154400222581		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.11704154400222581 | validation: 0.08106468210306314]
	TIME [epoch: 9.02 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13149038128907656		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.13149038128907656 | validation: 0.11194204910903624]
	TIME [epoch: 9.02 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1329994103627565		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.1329994103627565 | validation: 0.12250024093117211]
	TIME [epoch: 9.01 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1261585684773329		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.1261585684773329 | validation: 0.09674041849813406]
	TIME [epoch: 9.02 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11161435198216951		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.11161435198216951 | validation: 0.05549097288301839]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_939.pth
	Model improved!!!
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1384945154077369		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.1384945154077369 | validation: 0.10397060584918916]
	TIME [epoch: 9.02 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13200360590475482		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.13200360590475482 | validation: 0.2538373832996682]
	TIME [epoch: 9.01 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17636083079778705		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.17636083079778705 | validation: 0.13479816978180392]
	TIME [epoch: 9.01 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16516307055389962		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.16516307055389962 | validation: 0.25849758417173885]
	TIME [epoch: 9.04 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17384828748335257		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.17384828748335257 | validation: 0.08802059341097708]
	TIME [epoch: 9.03 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13541356373486857		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.13541356373486857 | validation: 0.17998746323325923]
	TIME [epoch: 9.01 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11941173570185945		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.11941173570185945 | validation: 0.15101886587680352]
	TIME [epoch: 9.01 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13187511937885069		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.13187511937885069 | validation: 0.08295156833055271]
	TIME [epoch: 9.02 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09618440333296233		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.09618440333296233 | validation: 0.10365240691322367]
	TIME [epoch: 9.05 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11264242504685495		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.11264242504685495 | validation: 0.08341982076457125]
	TIME [epoch: 9.01 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10517416482253358		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.10517416482253358 | validation: 0.15063868440144668]
	TIME [epoch: 9.03 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13831339563052444		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.13831339563052444 | validation: 0.11529751627245735]
	TIME [epoch: 9.03 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1464762388255817		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.1464762388255817 | validation: 0.08322374350731518]
	TIME [epoch: 9.04 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16874221170594705		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.16874221170594705 | validation: 0.10227702420561066]
	TIME [epoch: 9.03 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10474490124244476		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.10474490124244476 | validation: 0.08630640777915279]
	TIME [epoch: 9.02 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13243951405687476		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.13243951405687476 | validation: 0.12652187546392252]
	TIME [epoch: 9.02 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12954273784175568		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.12954273784175568 | validation: 0.10307873659069774]
	TIME [epoch: 9.02 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1120739579200658		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.1120739579200658 | validation: 0.09970659871124221]
	TIME [epoch: 9.04 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11739407171402957		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.11739407171402957 | validation: 0.08120524380182462]
	TIME [epoch: 9.02 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1259691092362386		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.1259691092362386 | validation: 0.13115488215991877]
	TIME [epoch: 9.02 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14179024199119397		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.14179024199119397 | validation: 0.14252631086746764]
	TIME [epoch: 9.03 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14989443943051953		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.14989443943051953 | validation: 0.15179781265754505]
	TIME [epoch: 9.02 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15815348541526142		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.15815348541526142 | validation: 0.1651521348817941]
	TIME [epoch: 9.03 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18539016690392623		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.18539016690392623 | validation: 0.14399182242398273]
	TIME [epoch: 9.03 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18451776865142594		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.18451776865142594 | validation: 0.2458485705181875]
	TIME [epoch: 9.02 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18605869981552478		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.18605869981552478 | validation: 0.16137793491334435]
	TIME [epoch: 9.01 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1737223415722628		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.1737223415722628 | validation: 0.20655647317824544]
	TIME [epoch: 9.03 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16897762225162408		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.16897762225162408 | validation: 0.2598657066756982]
	TIME [epoch: 9.02 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14859146973100618		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.14859146973100618 | validation: 0.13564704765172864]
	TIME [epoch: 9.02 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505079333552779		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.1505079333552779 | validation: 0.10418633881845235]
	TIME [epoch: 9.01 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1431096379671684		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.1431096379671684 | validation: 0.10088365492170634]
	TIME [epoch: 9.01 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765746383546018		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.1765746383546018 | validation: 0.1377423395322901]
	TIME [epoch: 9.04 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12024708974323128		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.12024708974323128 | validation: 0.13501126386905427]
	TIME [epoch: 9.02 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11135910675819938		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.11135910675819938 | validation: 0.10935012927259974]
	TIME [epoch: 9.01 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11745807959607509		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.11745807959607509 | validation: 0.13639511785073896]
	TIME [epoch: 9.02 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13470367637009442		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.13470367637009442 | validation: 0.1671390650518199]
	TIME [epoch: 9.05 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11917373851266624		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.11917373851266624 | validation: 0.14571838629073441]
	TIME [epoch: 9.03 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12678459634081513		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.12678459634081513 | validation: 0.1297295492004904]
	TIME [epoch: 9.02 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1409162610988323		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.1409162610988323 | validation: 0.13390953188147733]
	TIME [epoch: 9.02 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12340431495669142		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.12340431495669142 | validation: 0.09743820252577412]
	TIME [epoch: 9.02 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14529112814768003		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.14529112814768003 | validation: 0.10695751445202756]
	TIME [epoch: 9.04 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265433689856665		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.1265433689856665 | validation: 0.2075228654601973]
	TIME [epoch: 9.01 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14416757079673034		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.14416757079673034 | validation: 0.08818880079781641]
	TIME [epoch: 9.03 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1247361166451526		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.1247361166451526 | validation: 0.12090707713801735]
	TIME [epoch: 9.03 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14076226715001047		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.14076226715001047 | validation: 0.10887495518192364]
	TIME [epoch: 9.03 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1472243397214312		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.1472243397214312 | validation: 0.13926918136744626]
	TIME [epoch: 9.03 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13543817150362114		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.13543817150362114 | validation: 0.10573087866138318]
	TIME [epoch: 9.01 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14851847974516397		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.14851847974516397 | validation: 0.1472998759694447]
	TIME [epoch: 9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1304768468507999		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.1304768468507999 | validation: 0.08500828651509676]
	TIME [epoch: 9.02 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12484890516572252		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.12484890516572252 | validation: 0.08907100285673483]
	TIME [epoch: 9.04 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12556381522979038		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.12556381522979038 | validation: 0.11119969352437946]
	TIME [epoch: 9.03 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13505024397823387		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.13505024397823387 | validation: 0.11121735535871777]
	TIME [epoch: 9.02 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13398358602353194		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.13398358602353194 | validation: 0.14709212614352762]
	TIME [epoch: 9.02 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437716101988175		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.1437716101988175 | validation: 0.09977152767035952]
	TIME [epoch: 9.02 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1365525372646915		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.1365525372646915 | validation: 0.10740183450359472]
	TIME [epoch: 9.03 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15808275128939292		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.15808275128939292 | validation: 0.0885943853353992]
	TIME [epoch: 9.01 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10992076792002928		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.10992076792002928 | validation: 0.08803561882208615]
	TIME [epoch: 9.02 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1549549011600033		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.1549549011600033 | validation: 0.07756726571831192]
	TIME [epoch: 9.03 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13129915881415927		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.13129915881415927 | validation: 0.1319648043814296]
	TIME [epoch: 9.03 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13370858089906973		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.13370858089906973 | validation: 0.10290078055955953]
	TIME [epoch: 9.02 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342044459259586		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.1342044459259586 | validation: 0.1447358851810996]
	TIME [epoch: 9.03 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627027578100854		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.11627027578100854 | validation: 0.0664753972263315]
	TIME [epoch: 9.02 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13490976086676604		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.13490976086676604 | validation: 0.1300207806848675]
	TIME [epoch: 9.02 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10257868028227879		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.10257868028227879 | validation: 0.06927356060926626]
	TIME [epoch: 9.04 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1131225210790893		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.1131225210790893 | validation: 0.09692865795798689]
	TIME [epoch: 9.02 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11261577541970844		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.11261577541970844 | validation: 0.17662233394906118]
	TIME [epoch: 9.02 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292158742696356		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.1292158742696356 | validation: 0.0785826733406324]
	TIME [epoch: 9.02 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10463488420219105		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.10463488420219105 | validation: 0.16618153876616618]
	TIME [epoch: 9.01 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13364328682381837		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.13364328682381837 | validation: 0.07005674284094152]
	TIME [epoch: 9.05 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10411786894659418		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.10411786894659418 | validation: 0.11481822274494052]
	TIME [epoch: 9.02 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11970410667597586		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.11970410667597586 | validation: 0.09587362236345012]
	TIME [epoch: 9.02 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10047400556504767		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.10047400556504767 | validation: 0.09876712262306961]
	TIME [epoch: 9.02 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12744733905776812		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.12744733905776812 | validation: 0.0852926641376848]
	TIME [epoch: 9.03 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11093353176617611		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.11093353176617611 | validation: 0.073121922400481]
	TIME [epoch: 9.02 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09298994468763253		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.09298994468763253 | validation: 0.07905423984828075]
	TIME [epoch: 9.01 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09582490903128986		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.09582490903128986 | validation: 0.06604796899867812]
	TIME [epoch: 9.02 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12403771569560021		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.12403771569560021 | validation: 0.06028847974619354]
	TIME [epoch: 9.03 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.112464959537438		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.112464959537438 | validation: 0.08184417796270023]
	TIME [epoch: 9.05 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12852245304579088		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.12852245304579088 | validation: 0.1064925369957064]
	TIME [epoch: 9.02 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09511888812832976		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.09511888812832976 | validation: 0.09750157891312808]
	TIME [epoch: 9.01 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11380878212843577		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.11380878212843577 | validation: 0.1123873412356026]
	TIME [epoch: 9.01 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.135490950047877		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.135490950047877 | validation: 0.14957736723506065]
	TIME [epoch: 9.04 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11990307900743233		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.11990307900743233 | validation: 0.08930589503580204]
	TIME [epoch: 9.03 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10255322269681022		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.10255322269681022 | validation: 0.07031071451043241]
	TIME [epoch: 9.02 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10668779238357715		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.10668779238357715 | validation: 0.11583863760253602]
	TIME [epoch: 9.01 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13642612692517267		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.13642612692517267 | validation: 0.11228007761520493]
	TIME [epoch: 9.01 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1401415436182118		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.1401415436182118 | validation: 0.0773700672129935]
	TIME [epoch: 9.02 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12199255770492849		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.12199255770492849 | validation: 0.10586069834121209]
	TIME [epoch: 9.02 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09633887554417997		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.09633887554417997 | validation: 0.11700640022103992]
	TIME [epoch: 9.02 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12119446338385813		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.12119446338385813 | validation: 0.06530869709431429]
	TIME [epoch: 9.01 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910667732751548		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.0910667732751548 | validation: 0.07620763311181533]
	TIME [epoch: 9.02 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638322774844426		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.10638322774844426 | validation: 0.15122784924975408]
	TIME [epoch: 9.04 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12293861848876195		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.12293861848876195 | validation: 0.1321332242999823]
	TIME [epoch: 9.01 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14064684009592834		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.14064684009592834 | validation: 0.12158451784992512]
	TIME [epoch: 9.02 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15063189456391662		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.15063189456391662 | validation: 0.08347581320276984]
	TIME [epoch: 9.02 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10692228906382681		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.10692228906382681 | validation: 0.07762381878195149]
	TIME [epoch: 9.03 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14356284080680942		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.14356284080680942 | validation: 0.1458748251901651]
	TIME [epoch: 9.03 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11211309766743957		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.11211309766743957 | validation: 0.10135085273390285]
	TIME [epoch: 9.02 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11896947910390514		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.11896947910390514 | validation: 0.08972186338918144]
	TIME [epoch: 9.02 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13091905124431819		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.13091905124431819 | validation: 0.11256826534923237]
	TIME [epoch: 9.01 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14059773075676968		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.14059773075676968 | validation: 0.06553517771807688]
	TIME [epoch: 9.04 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11553476452168292		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.11553476452168292 | validation: 0.1116162953767057]
	TIME [epoch: 9.03 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08787219097734923		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.08787219097734923 | validation: 0.08044430445487674]
	TIME [epoch: 9.02 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10386703135015714		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.10386703135015714 | validation: 0.10993766529915869]
	TIME [epoch: 9.03 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09445182049137403		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.09445182049137403 | validation: 0.1333032752846849]
	TIME [epoch: 9.04 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10424184595828945		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.10424184595828945 | validation: 0.11162626570823958]
	TIME [epoch: 9.04 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13557152567109443		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.13557152567109443 | validation: 0.086194872287359]
	TIME [epoch: 9.02 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10994587679626347		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.10994587679626347 | validation: 0.09373951171291119]
	TIME [epoch: 9.01 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09820188501205494		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.09820188501205494 | validation: 0.08903281638531241]
	TIME [epoch: 9.02 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11752513331980922		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.11752513331980922 | validation: 0.07524720965400294]
	TIME [epoch: 9.04 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1031898248848957		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.1031898248848957 | validation: 0.10364953565804158]
	TIME [epoch: 9.02 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10591338826618699		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.10591338826618699 | validation: 0.12420683429016757]
	TIME [epoch: 9.02 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11356652590854202		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.11356652590854202 | validation: 0.12624376375465274]
	TIME [epoch: 9.02 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1233090767409329		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.1233090767409329 | validation: 0.160159317314575]
	TIME [epoch: 9.02 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12862422069884		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.12862422069884 | validation: 0.10837162325691344]
	TIME [epoch: 9.04 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12554439165866832		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.12554439165866832 | validation: 0.17446908957211832]
	TIME [epoch: 9.02 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09818117305609678		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.09818117305609678 | validation: 0.06887450399962128]
	TIME [epoch: 9.02 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10244997130995373		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.10244997130995373 | validation: 0.12258720111630157]
	TIME [epoch: 9.02 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1090020841889912		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.1090020841889912 | validation: 0.08985980204649491]
	TIME [epoch: 9.04 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10379456690365826		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.10379456690365826 | validation: 0.06040453537530323]
	TIME [epoch: 9.02 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09823172091547978		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.09823172091547978 | validation: 0.06457650572723264]
	TIME [epoch: 9.02 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09561722677062384		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.09561722677062384 | validation: 0.06963785349899665]
	TIME [epoch: 9.02 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10921860421229654		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.10921860421229654 | validation: 0.08633993385602654]
	TIME [epoch: 9.01 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11510623059652543		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.11510623059652543 | validation: 0.1104474452793513]
	TIME [epoch: 9.03 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11615978051970592		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.11615978051970592 | validation: 0.10829447644471549]
	TIME [epoch: 9.01 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914096570464905		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.08914096570464905 | validation: 0.07917215836550577]
	TIME [epoch: 9.01 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10579698182967467		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.10579698182967467 | validation: 0.09589108789265618]
	TIME [epoch: 9.04 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11820347274758336		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.11820347274758336 | validation: 0.13993766295400378]
	TIME [epoch: 9.03 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095784320736484		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.1095784320736484 | validation: 0.09754083212990805]
	TIME [epoch: 9.03 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.099633686685989		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.099633686685989 | validation: 0.11698743139458251]
	TIME [epoch: 9.02 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14951822122092925		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.14951822122092925 | validation: 0.13142033651560414]
	TIME [epoch: 9.02 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13474662604565202		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.13474662604565202 | validation: 0.08061686726454728]
	TIME [epoch: 9.02 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1387718517867193		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.1387718517867193 | validation: 0.10677058093627681]
	TIME [epoch: 9.02 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342773379336662		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.1342773379336662 | validation: 0.10508123666242444]
	TIME [epoch: 9.02 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11127113316028978		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.11127113316028978 | validation: 0.09659883989277551]
	TIME [epoch: 9.01 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10911730530046346		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.10911730530046346 | validation: 0.08974238267236714]
	TIME [epoch: 9.01 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10319208596835257		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.10319208596835257 | validation: 0.09782322628877996]
	TIME [epoch: 9.01 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10000654083395355		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.10000654083395355 | validation: 0.08837473403374099]
	TIME [epoch: 9.04 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0903120182190413		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.0903120182190413 | validation: 0.14261105509462]
	TIME [epoch: 9.03 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13443451019405542		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.13443451019405542 | validation: 0.06871193821033114]
	TIME [epoch: 9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09891563800369148		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.09891563800369148 | validation: 0.10062043796023735]
	TIME [epoch: 9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11318696223396914		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.11318696223396914 | validation: 0.08141462483900873]
	TIME [epoch: 9.03 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09041897906339166		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.09041897906339166 | validation: 0.13701047227870067]
	TIME [epoch: 9.01 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11899131758818979		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.11899131758818979 | validation: 0.08780490702827198]
	TIME [epoch: 9.02 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20309131634400726		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.20309131634400726 | validation: 0.12821572876228451]
	TIME [epoch: 9.02 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314416267746918		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.11314416267746918 | validation: 0.14588892766920553]
	TIME [epoch: 9.01 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1079409563556735		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.1079409563556735 | validation: 0.10955253478152005]
	TIME [epoch: 9.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10781666287871161		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.10781666287871161 | validation: 0.10518444859229495]
	TIME [epoch: 9.01 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12092417303422857		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.12092417303422857 | validation: 0.13043925926569103]
	TIME [epoch: 9.01 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13483303138440467		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.13483303138440467 | validation: 0.0875968019656979]
	TIME [epoch: 9.01 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10025925019573956		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.10025925019573956 | validation: 0.06643217088280144]
	TIME [epoch: 9.01 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08080938405565845		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.08080938405565845 | validation: 0.08012291102646857]
	TIME [epoch: 9.03 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997058459366089		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.0997058459366089 | validation: 0.08640520774630986]
	TIME [epoch: 9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09754487973783543		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.09754487973783543 | validation: 0.07507141475275309]
	TIME [epoch: 9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09850283230081962		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.09850283230081962 | validation: 0.08352223771248776]
	TIME [epoch: 9.01 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10231647661619199		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.10231647661619199 | validation: 0.08646846719241022]
	TIME [epoch: 9.02 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12465749753968894		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.12465749753968894 | validation: 0.10385136044702291]
	TIME [epoch: 9.01 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13186383193819412		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.13186383193819412 | validation: 0.07056912477723554]
	TIME [epoch: 9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09037495720153102		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.09037495720153102 | validation: 0.05632889685956373]
	TIME [epoch: 9.01 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08622067111238838		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.08622067111238838 | validation: 0.10611331777498748]
	TIME [epoch: 9.02 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1059303614496413		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.1059303614496413 | validation: 0.10491549978250914]
	TIME [epoch: 9.03 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09093326316513904		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.09093326316513904 | validation: 0.07953174284760856]
	TIME [epoch: 9.01 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11056800116593175		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.11056800116593175 | validation: 0.10516647120665203]
	TIME [epoch: 9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09862032580049285		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.09862032580049285 | validation: 0.11333010639608235]
	TIME [epoch: 9.01 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09793375995275132		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.09793375995275132 | validation: 0.08514918538897231]
	TIME [epoch: 9.02 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09836611040911084		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.09836611040911084 | validation: 0.06843832782019851]
	TIME [epoch: 9.03 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11738329800749059		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.11738329800749059 | validation: 0.06296408508822707]
	TIME [epoch: 9.01 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10641569068067307		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.10641569068067307 | validation: 0.12096325465131237]
	TIME [epoch: 9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11407994943819247		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.11407994943819247 | validation: 0.077637240299781]
	TIME [epoch: 9.01 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986576532903328		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.0986576532903328 | validation: 0.0755985821616047]
	TIME [epoch: 9.04 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08841338681289049		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.08841338681289049 | validation: 0.08421629598733713]
	TIME [epoch: 9.01 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.100858262444624		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.100858262444624 | validation: 0.0659000171256856]
	TIME [epoch: 9.01 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09182105614118473		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.09182105614118473 | validation: 0.08915133572625981]
	TIME [epoch: 9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0817576653432846		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.0817576653432846 | validation: 0.06844789130521654]
	TIME [epoch: 9.01 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0824141297741448		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.0824141297741448 | validation: 0.10373918919318462]
	TIME [epoch: 9.03 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09939239651468629		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.09939239651468629 | validation: 0.11267313679841637]
	TIME [epoch: 9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10257832419408341		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.10257832419408341 | validation: 0.0865659551103174]
	TIME [epoch: 9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08290825889169638		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.08290825889169638 | validation: 0.08812339970725616]
	TIME [epoch: 9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10053330622340653		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.10053330622340653 | validation: 0.09668402334105664]
	TIME [epoch: 9.03 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12582121203746185		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.12582121203746185 | validation: 0.06254850268019727]
	TIME [epoch: 9.02 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10864603771497486		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.10864603771497486 | validation: 0.09863845039256963]
	TIME [epoch: 9.01 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10210883591832882		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.10210883591832882 | validation: 0.08982276869191355]
	TIME [epoch: 9.01 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273633157307523		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.09273633157307523 | validation: 0.0691334636177103]
	TIME [epoch: 9.01 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07720597648209274		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.07720597648209274 | validation: 0.0767231346755889]
	TIME [epoch: 9.04 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07878812514673972		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.07878812514673972 | validation: 0.0986831381401282]
	TIME [epoch: 9.02 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09011290405659005		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.09011290405659005 | validation: 0.10286524116800774]
	TIME [epoch: 8.99 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0926516675944069		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.0926516675944069 | validation: 0.09153370306028782]
	TIME [epoch: 9.01 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09365457298694155		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.09365457298694155 | validation: 0.07712724061200443]
	TIME [epoch: 9.02 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08325744324689625		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.08325744324689625 | validation: 0.08823043822576404]
	TIME [epoch: 9.03 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382386850901952		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.1382386850901952 | validation: 0.10372043504808613]
	TIME [epoch: 9.02 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739797649028986		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.09739797649028986 | validation: 0.08039219943818984]
	TIME [epoch: 9.02 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11266404830534202		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.11266404830534202 | validation: 0.12132714481902424]
	TIME [epoch: 9.01 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14460916297635854		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.14460916297635854 | validation: 0.11598694594649264]
	TIME [epoch: 9.03 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11065146709623996		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.11065146709623996 | validation: 0.07855443397709796]
	TIME [epoch: 9.01 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10336522737536927		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.10336522737536927 | validation: 0.09844920877174207]
	TIME [epoch: 9.03 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10655801792187025		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.10655801792187025 | validation: 0.09929154509391822]
	TIME [epoch: 9.03 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10703545923785385		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.10703545923785385 | validation: 0.08065300071314745]
	TIME [epoch: 9.02 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11509205699370242		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.11509205699370242 | validation: 0.11274306120783699]
	TIME [epoch: 9.04 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0952347374724809		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.0952347374724809 | validation: 0.04775262621323564]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1138.pth
	Model improved!!!
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10009662022073318		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.10009662022073318 | validation: 0.06414191936328777]
	TIME [epoch: 9.01 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09669716184389372		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.09669716184389372 | validation: 0.10235738016053791]
	TIME [epoch: 9.02 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09792849017309208		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.09792849017309208 | validation: 0.06121586795428614]
	TIME [epoch: 9.04 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08194701359877012		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.08194701359877012 | validation: 0.057814975949588725]
	TIME [epoch: 9.02 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09107702002644766		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.09107702002644766 | validation: 0.09049505386463343]
	TIME [epoch: 9.01 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08065690867598509		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.08065690867598509 | validation: 0.09904585806669494]
	TIME [epoch: 9.01 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11684903347655015		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.11684903347655015 | validation: 0.07489619063529411]
	TIME [epoch: 9.01 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09254193548534612		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.09254193548534612 | validation: 0.05708716067698706]
	TIME [epoch: 9.03 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09399605522983186		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.09399605522983186 | validation: 0.05957637918051275]
	TIME [epoch: 9.01 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08334624000293661		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.08334624000293661 | validation: 0.0660244002813481]
	TIME [epoch: 9.02 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0989285056659715		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.0989285056659715 | validation: 0.09899527334093566]
	TIME [epoch: 9.03 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08668216613488663		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.08668216613488663 | validation: 0.06718812377136127]
	TIME [epoch: 9.03 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1109711578480997		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.1109711578480997 | validation: 0.15171071272796008]
	TIME [epoch: 9.03 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11076678877577475		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.11076678877577475 | validation: 0.06806509679340592]
	TIME [epoch: 9.01 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09822804109979837		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.09822804109979837 | validation: 0.1255416804726457]
	TIME [epoch: 9.01 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10246937918020167		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.10246937918020167 | validation: 0.0992831015709082]
	TIME [epoch: 9.02 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12898041450266615		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.12898041450266615 | validation: 0.06995505389922616]
	TIME [epoch: 9.02 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09465321680473328		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.09465321680473328 | validation: 0.08486797879353106]
	TIME [epoch: 9.02 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08658719575844893		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.08658719575844893 | validation: 0.07031281550880589]
	TIME [epoch: 9.02 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599352979035631		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.07599352979035631 | validation: 0.08631711059079314]
	TIME [epoch: 9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08550783419707539		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.08550783419707539 | validation: 0.0780757226871211]
	TIME [epoch: 9.02 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10516093856767379		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.10516093856767379 | validation: 0.07767204470971367]
	TIME [epoch: 9.02 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0949851478700901		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.0949851478700901 | validation: 0.07037888576134282]
	TIME [epoch: 9.03 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09185114767715565		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.09185114767715565 | validation: 0.10846945371559152]
	TIME [epoch: 9.02 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10320253884753446		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.10320253884753446 | validation: 0.10174274199448902]
	TIME [epoch: 9.01 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08043279870429779		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.08043279870429779 | validation: 0.07596146276066582]
	TIME [epoch: 9.03 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09059805455701106		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.09059805455701106 | validation: 0.07116400120430187]
	TIME [epoch: 9.02 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251248293527346		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.1251248293527346 | validation: 0.10428927798284549]
	TIME [epoch: 9.01 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10853861352808192		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.10853861352808192 | validation: 0.12269871728880889]
	TIME [epoch: 9.02 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09915820231610059		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.09915820231610059 | validation: 0.058953344409782026]
	TIME [epoch: 9.01 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10111852756314546		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.10111852756314546 | validation: 0.05428926884244989]
	TIME [epoch: 9.04 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08915674041033017		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.08915674041033017 | validation: 0.15807583849976353]
	TIME [epoch: 9.01 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10235125813292359		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.10235125813292359 | validation: 0.06717137529363361]
	TIME [epoch: 9.01 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10095358205556385		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.10095358205556385 | validation: 0.11135702297108913]
	TIME [epoch: 9.01 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11411037663593274		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.11411037663593274 | validation: 0.07924430420501319]
	TIME [epoch: 9.01 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08101017318680129		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.08101017318680129 | validation: 0.08342869526429231]
	TIME [epoch: 9.04 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08206904860182104		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.08206904860182104 | validation: 0.09054840528459866]
	TIME [epoch: 9.02 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0888300560191355		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.0888300560191355 | validation: 0.09240827307551605]
	TIME [epoch: 9.02 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09243619843479614		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.09243619843479614 | validation: 0.09622252206349922]
	TIME [epoch: 9.01 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09187008268401269		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.09187008268401269 | validation: 0.07865323611472988]
	TIME [epoch: 9.03 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09678113904829175		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.09678113904829175 | validation: 0.056492189726959206]
	TIME [epoch: 9.02 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295280292343402		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.08295280292343402 | validation: 0.06767013302311604]
	TIME [epoch: 9.01 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09289730280877322		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.09289730280877322 | validation: 0.05544306003696482]
	TIME [epoch: 9.02 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09862294546085505		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.09862294546085505 | validation: 0.06136041620498659]
	TIME [epoch: 9.02 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295038446327539		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.08295038446327539 | validation: 0.0640124346500255]
	TIME [epoch: 9.03 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08352874366816283		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.08352874366816283 | validation: 0.11034547079655882]
	TIME [epoch: 9.02 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09672558382246284		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.09672558382246284 | validation: 0.07484951729859889]
	TIME [epoch: 9.01 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0872275152225617		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.0872275152225617 | validation: 0.12777601231474484]
	TIME [epoch: 9.01 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13030070089103007		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.13030070089103007 | validation: 0.07331928748563014]
	TIME [epoch: 9.03 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07799835483724574		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.07799835483724574 | validation: 0.07433978880933048]
	TIME [epoch: 9.02 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09139039098864532		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.09139039098864532 | validation: 0.17779599292240167]
	TIME [epoch: 9.02 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10896308746051744		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.10896308746051744 | validation: 0.0824405623966444]
	TIME [epoch: 9.01 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09681801903967542		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.09681801903967542 | validation: 0.0652356951900889]
	TIME [epoch: 9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418928025936027		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.08418928025936027 | validation: 0.0849337677289518]
	TIME [epoch: 9.03 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08343478045579752		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.08343478045579752 | validation: 0.0810517326885972]
	TIME [epoch: 9.01 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0801860588439935		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.0801860588439935 | validation: 0.08379292929935661]
	TIME [epoch: 9.02 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09215491173983648		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.09215491173983648 | validation: 0.056255212621933046]
	TIME [epoch: 9.01 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0770373190303493		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.0770373190303493 | validation: 0.08269230901927473]
	TIME [epoch: 9.01 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09061131773308065		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.09061131773308065 | validation: 0.06708379866350112]
	TIME [epoch: 9.04 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07687378078966339		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.07687378078966339 | validation: 0.06492149490649501]
	TIME [epoch: 9.01 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07790853776949634		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.07790853776949634 | validation: 0.06249073789808629]
	TIME [epoch: 9.01 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10563928915586358		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.10563928915586358 | validation: 0.05289930512638938]
	TIME [epoch: 9.01 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10299738270089631		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.10299738270089631 | validation: 0.0720910991839811]
	TIME [epoch: 9.04 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09492067319383879		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.09492067319383879 | validation: 0.0783587725737198]
	TIME [epoch: 9.03 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10207654819709426		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.10207654819709426 | validation: 0.08170846694953948]
	TIME [epoch: 9.02 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08896531173989194		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.08896531173989194 | validation: 0.06649233980590728]
	TIME [epoch: 9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08711696931233275		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.08711696931233275 | validation: 0.07056149932335279]
	TIME [epoch: 9.01 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08287658010684676		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.08287658010684676 | validation: 0.06600520495497425]
	TIME [epoch: 9.03 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08357789316549169		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.08357789316549169 | validation: 0.10145370912757085]
	TIME [epoch: 9.01 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09319768168830991		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.09319768168830991 | validation: 0.046767819465453705]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1208.pth
	Model improved!!!
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09450220424903599		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.09450220424903599 | validation: 0.08392993781687158]
	TIME [epoch: 9.02 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08521461354554893		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.08521461354554893 | validation: 0.06308149849972883]
	TIME [epoch: 9.02 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1124140589396618		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.1124140589396618 | validation: 0.09330609837463988]
	TIME [epoch: 9.02 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0912952876293459		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.0912952876293459 | validation: 0.08643230884056002]
	TIME [epoch: 9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09573583626091968		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.09573583626091968 | validation: 0.06866846622794039]
	TIME [epoch: 9.01 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0938445568586201		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.0938445568586201 | validation: 0.08776834300455286]
	TIME [epoch: 9.01 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124376971446867		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.11124376971446867 | validation: 0.14547922798720697]
	TIME [epoch: 9.04 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09967978163264646		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.09967978163264646 | validation: 0.11542623528203161]
	TIME [epoch: 9.01 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10772375067451398		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.10772375067451398 | validation: 0.1438128179145335]
	TIME [epoch: 9.01 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1207386001052754		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.1207386001052754 | validation: 0.09870999559497237]
	TIME [epoch: 9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09085747780987284		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.09085747780987284 | validation: 0.07191821627282423]
	TIME [epoch: 9.01 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09443220668425009		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.09443220668425009 | validation: 0.07521271032843059]
	TIME [epoch: 9.03 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09693164834776272		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.09693164834776272 | validation: 0.13374427001056688]
	TIME [epoch: 9.01 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12561962524242418		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.12561962524242418 | validation: 0.08807363203603097]
	TIME [epoch: 9.02 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10365065240992737		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.10365065240992737 | validation: 0.07664329693496276]
	TIME [epoch: 9.01 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09775198650388331		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.09775198650388331 | validation: 0.06679508378526453]
	TIME [epoch: 9.02 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10040395292998402		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.10040395292998402 | validation: 0.06910234491177134]
	TIME [epoch: 9.02 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08785423697682838		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.08785423697682838 | validation: 0.09486152920307696]
	TIME [epoch: 9.01 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064115958537246		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.08064115958537246 | validation: 0.07100310441847107]
	TIME [epoch: 9.02 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09107630119615398		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.09107630119615398 | validation: 0.08574656181859233]
	TIME [epoch: 9.02 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12977197886793856		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.12977197886793856 | validation: 0.06586061905298393]
	TIME [epoch: 9.04 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528315073270181		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.10528315073270181 | validation: 0.07994638750818883]
	TIME [epoch: 9.02 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09280784253048618		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.09280784253048618 | validation: 0.082473164919946]
	TIME [epoch: 9.01 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09020927814293742		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.09020927814293742 | validation: 0.08645130415719583]
	TIME [epoch: 9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10033789344401618		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.10033789344401618 | validation: 0.09314900083137401]
	TIME [epoch: 9.02 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0916781935837365		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.0916781935837365 | validation: 0.06719271694973167]
	TIME [epoch: 9.02 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07533239393847721		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.07533239393847721 | validation: 0.08456785225227305]
	TIME [epoch: 9.01 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07970793118605747		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.07970793118605747 | validation: 0.06812669298210491]
	TIME [epoch: 9.02 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07243453045529484		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.07243453045529484 | validation: 0.07884597174033608]
	TIME [epoch: 9.02 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08070223162043302		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.08070223162043302 | validation: 0.07298000905718521]
	TIME [epoch: 9.03 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0908611758243005		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.0908611758243005 | validation: 0.06005367247394616]
	TIME [epoch: 9.03 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07590750878268282		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.07590750878268282 | validation: 0.08480814925015956]
	TIME [epoch: 9.02 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09782130907340388		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.09782130907340388 | validation: 0.05829265350820048]
	TIME [epoch: 9.01 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08738964522405351		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.08738964522405351 | validation: 0.06904610854132828]
	TIME [epoch: 9.02 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980814665414898		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.07980814665414898 | validation: 0.06962402421877538]
	TIME [epoch: 9.03 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07715607151621309		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.07715607151621309 | validation: 0.08217722047009189]
	TIME [epoch: 9.01 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07835060237150969		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.07835060237150969 | validation: 0.05512556376557494]
	TIME [epoch: 9.01 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0824825165528033		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.0824825165528033 | validation: 0.09458222364167582]
	TIME [epoch: 9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08079996768217983		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.08079996768217983 | validation: 0.08503076126151919]
	TIME [epoch: 9.03 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07427880903008875		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.07427880903008875 | validation: 0.07673150501211186]
	TIME [epoch: 9.02 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09092461112381456		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.09092461112381456 | validation: 0.12274605189122709]
	TIME [epoch: 9.01 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09645644101029786		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.09645644101029786 | validation: 0.13396323094720883]
	TIME [epoch: 9.01 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08589906601541104		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.08589906601541104 | validation: 0.0713038014845847]
	TIME [epoch: 9.01 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08041573157757359		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.08041573157757359 | validation: 0.06105346245433964]
	TIME [epoch: 9.03 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08989872058925587		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.08989872058925587 | validation: 0.10659520893958181]
	TIME [epoch: 9.02 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08719321699715127		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.08719321699715127 | validation: 0.06324516344449552]
	TIME [epoch: 9.02 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09657599987664398		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.09657599987664398 | validation: 0.06231970164666239]
	TIME [epoch: 9.02 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07468298539283794		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.07468298539283794 | validation: 0.058034182277093393]
	TIME [epoch: 9.02 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07194536960425829		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.07194536960425829 | validation: 0.07369489866292553]
	TIME [epoch: 9.04 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07941644859677521		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.07941644859677521 | validation: 0.06270224140403093]
	TIME [epoch: 9.01 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09149378131282264		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.09149378131282264 | validation: 0.0777813685965704]
	TIME [epoch: 9.01 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08851659276447559		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.08851659276447559 | validation: 0.0915731191927488]
	TIME [epoch: 9.02 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08818297337890714		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.08818297337890714 | validation: 0.08239396303903485]
	TIME [epoch: 9.03 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08972526773517095		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.08972526773517095 | validation: 0.08558103139042744]
	TIME [epoch: 9.02 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10244145048079083		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.10244145048079083 | validation: 0.11705321971638184]
	TIME [epoch: 9.01 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09127423734999704		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.09127423734999704 | validation: 0.0637618481909612]
	TIME [epoch: 9.02 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08378992001325024		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.08378992001325024 | validation: 0.07806675492553554]
	TIME [epoch: 9.01 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0965839018406924		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.0965839018406924 | validation: 0.07847689196445223]
	TIME [epoch: 9.03 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814978453789154		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.07814978453789154 | validation: 0.06612138977409479]
	TIME [epoch: 9.03 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08090964139514571		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.08090964139514571 | validation: 0.05069727693408982]
	TIME [epoch: 9.02 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07038724018660951		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.07038724018660951 | validation: 0.10420852582075796]
	TIME [epoch: 9.02 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08716570495644581		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.08716570495644581 | validation: 0.057737945517891576]
	TIME [epoch: 9.03 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06810659441615173		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.06810659441615173 | validation: 0.07458323998134303]
	TIME [epoch: 9.02 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08329194437531799		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.08329194437531799 | validation: 0.06013942957851029]
	TIME [epoch: 9.01 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09198739497080684		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.09198739497080684 | validation: 0.08417961482474673]
	TIME [epoch: 9.02 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09589701894255229		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.09589701894255229 | validation: 0.07954418495130304]
	TIME [epoch: 9.01 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08819057072032657		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.08819057072032657 | validation: 0.0994388964092715]
	TIME [epoch: 9.05 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13114415704079863		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.13114415704079863 | validation: 0.11564995865985764]
	TIME [epoch: 9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10095122013775293		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.10095122013775293 | validation: 0.10045629760304883]
	TIME [epoch: 9.01 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10179244263960605		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.10179244263960605 | validation: 0.1324220714537453]
	TIME [epoch: 9.02 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09672627252193586		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.09672627252193586 | validation: 0.06461867294811237]
	TIME [epoch: 9.01 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770775925964873		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.06770775925964873 | validation: 0.06390268907676044]
	TIME [epoch: 9.04 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08060090756705698		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.08060090756705698 | validation: 0.06140366411654451]
	TIME [epoch: 9.02 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796762764139547		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.0796762764139547 | validation: 0.06335730685140037]
	TIME [epoch: 9.02 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07595043565568234		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.07595043565568234 | validation: 0.10030009853144767]
	TIME [epoch: 9.02 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08743134505251562		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.08743134505251562 | validation: 0.0678321280461471]
	TIME [epoch: 9.03 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09028626826508648		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.09028626826508648 | validation: 0.11068996839897288]
	TIME [epoch: 9.01 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1184996246035344		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.1184996246035344 | validation: 0.05984230328941864]
	TIME [epoch: 9.02 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07313475009048839		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.07313475009048839 | validation: 0.059883395139467804]
	TIME [epoch: 9.01 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08233538430402251		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.08233538430402251 | validation: 0.04111620861042864]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1288.pth
	Model improved!!!
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392765251950381		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.07392765251950381 | validation: 0.07514162353741985]
	TIME [epoch: 9.03 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07665635339664253		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.07665635339664253 | validation: 0.06277595040411338]
	TIME [epoch: 9.02 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06705102177011864		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.06705102177011864 | validation: 0.06492649570926844]
	TIME [epoch: 9.01 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671300963800427		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.07671300963800427 | validation: 0.06693562004267427]
	TIME [epoch: 9.01 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07073062651604728		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.07073062651604728 | validation: 0.06276679208411154]
	TIME [epoch: 9.03 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08185191987643767		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.08185191987643767 | validation: 0.10637657411198582]
	TIME [epoch: 9.04 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08695311572157038		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.08695311572157038 | validation: 0.08675985438202609]
	TIME [epoch: 9.01 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0742955892185296		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.0742955892185296 | validation: 0.06479100513015612]
	TIME [epoch: 9.02 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780566844829099		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.0780566844829099 | validation: 0.0660498380463477]
	TIME [epoch: 9.01 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0760178374821501		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.0760178374821501 | validation: 0.06818789955344931]
	TIME [epoch: 9.04 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08555555534056436		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.08555555534056436 | validation: 0.08185914047026585]
	TIME [epoch: 9.02 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09279957367092109		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.09279957367092109 | validation: 0.0787398279460277]
	TIME [epoch: 9.01 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08514412577681167		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.08514412577681167 | validation: 0.05550894953704878]
	TIME [epoch: 9.01 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07485809447338751		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.07485809447338751 | validation: 0.0768493325855441]
	TIME [epoch: 9.01 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630105396022854		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.07630105396022854 | validation: 0.07440642195451982]
	TIME [epoch: 9.04 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09006217792791878		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.09006217792791878 | validation: 0.13492398944837491]
	TIME [epoch: 9.01 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0949202974853192		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.0949202974853192 | validation: 0.07082536498552798]
	TIME [epoch: 9.01 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08136378004217673		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.08136378004217673 | validation: 0.07321728308882808]
	TIME [epoch: 9.02 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08846718613103673		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.08846718613103673 | validation: 0.07219027304283758]
	TIME [epoch: 9.04 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08121843827644545		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.08121843827644545 | validation: 0.07562515202910985]
	TIME [epoch: 9.03 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08394016638029055		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.08394016638029055 | validation: 0.08997416036017201]
	TIME [epoch: 9.02 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0884878535835246		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.0884878535835246 | validation: 0.06258298770129918]
	TIME [epoch: 9.01 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0746448778259762		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.0746448778259762 | validation: 0.08665398456455632]
	TIME [epoch: 9.01 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878913488764689		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.0878913488764689 | validation: 0.10917252872115932]
	TIME [epoch: 9.02 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0774713357281386		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.0774713357281386 | validation: 0.07232448716912648]
	TIME [epoch: 9.02 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156837932657253		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.08156837932657253 | validation: 0.06551340636750526]
	TIME [epoch: 9 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08210682553556709		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.08210682553556709 | validation: 0.08841047814985623]
	TIME [epoch: 9.01 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08901043456999154		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.08901043456999154 | validation: 0.06635885804826844]
	TIME [epoch: 9.03 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07523407323965256		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.07523407323965256 | validation: 0.0629456160699412]
	TIME [epoch: 9.02 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09280198509978152		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.09280198509978152 | validation: 0.053538313040723984]
	TIME [epoch: 9.01 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09058233673218201		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.09058233673218201 | validation: 0.05636483131735054]
	TIME [epoch: 9.01 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09807512549460129		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.09807512549460129 | validation: 0.05545109658334873]
	TIME [epoch: 9.02 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08161246430526381		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.08161246430526381 | validation: 0.05797474188463303]
	TIME [epoch: 9.04 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07637697471719558		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.07637697471719558 | validation: 0.07242585370986804]
	TIME [epoch: 9.01 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09918077057716816		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.09918077057716816 | validation: 0.0585122340365828]
	TIME [epoch: 9 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08619612817968407		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.08619612817968407 | validation: 0.05548032458822548]
	TIME [epoch: 9.01 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07775848844100476		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.07775848844100476 | validation: 0.08622459785783573]
	TIME [epoch: 9.01 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09010332635132233		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.09010332635132233 | validation: 0.08416089229760848]
	TIME [epoch: 9.04 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07438361158445816		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.07438361158445816 | validation: 0.08435772166730865]
	TIME [epoch: 9.01 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0779940021212347		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.0779940021212347 | validation: 0.07140033058394127]
	TIME [epoch: 9.01 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07471166033745669		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.07471166033745669 | validation: 0.07547414505336547]
	TIME [epoch: 9.01 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07229522168700689		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.07229522168700689 | validation: 0.06539244910760043]
	TIME [epoch: 9.03 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06648422402822132		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.06648422402822132 | validation: 0.0877323215001945]
	TIME [epoch: 9.01 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10035575753564474		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.10035575753564474 | validation: 0.10736595782248141]
	TIME [epoch: 9.01 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08464754328373747		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.08464754328373747 | validation: 0.11441751763301942]
	TIME [epoch: 9.02 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0944595743044825		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.0944595743044825 | validation: 0.05535647076330243]
	TIME [epoch: 9.02 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08803503040111257		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.08803503040111257 | validation: 0.08177874422919643]
	TIME [epoch: 9.05 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08409952549763905		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.08409952549763905 | validation: 0.06948872918950433]
	TIME [epoch: 9.03 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07536611528241337		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.07536611528241337 | validation: 0.05629083499465791]
	TIME [epoch: 9.01 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07112985356473672		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.07112985356473672 | validation: 0.050434576915137586]
	TIME [epoch: 9 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08389204954108967		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.08389204954108967 | validation: 0.0577584530044182]
	TIME [epoch: 9.01 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07527215232938017		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.07527215232938017 | validation: 0.06368574174247546]
	TIME [epoch: 9.04 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121800901363633		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.07121800901363633 | validation: 0.07552385646518128]
	TIME [epoch: 9.01 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07969281666621095		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.07969281666621095 | validation: 0.05779120298771566]
	TIME [epoch: 9.01 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08400818530258725		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.08400818530258725 | validation: 0.04906424391741529]
	TIME [epoch: 9.01 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07036201490414976		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.07036201490414976 | validation: 0.056759962260098704]
	TIME [epoch: 9.03 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07439476406898074		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.07439476406898074 | validation: 0.08216169632053172]
	TIME [epoch: 9.02 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08475661481833796		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.08475661481833796 | validation: 0.05987963008222738]
	TIME [epoch: 9.01 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07049394578332713		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.07049394578332713 | validation: 0.054832931707682955]
	TIME [epoch: 9.01 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10367903891950365		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.10367903891950365 | validation: 0.08225681084105779]
	TIME [epoch: 9.02 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06627236096452357		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.06627236096452357 | validation: 0.058855391386933534]
	TIME [epoch: 9.02 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09120989002005374		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.09120989002005374 | validation: 0.049229720933804136]
	TIME [epoch: 9.01 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06810780342333039		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.06810780342333039 | validation: 0.054870578217767196]
	TIME [epoch: 9.01 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06998649987412364		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.06998649987412364 | validation: 0.07450890000941307]
	TIME [epoch: 9 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07403409093373844		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.07403409093373844 | validation: 0.08329421433674417]
	TIME [epoch: 9.03 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08884574140640991		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.08884574140640991 | validation: 0.10604211623155746]
	TIME [epoch: 9.02 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08412711235814245		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.08412711235814245 | validation: 0.07113906463541202]
	TIME [epoch: 9.01 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08518513380609548		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.08518513380609548 | validation: 0.07547740449829839]
	TIME [epoch: 9.01 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875913554262716		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.07875913554262716 | validation: 0.0742846572732367]
	TIME [epoch: 9 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07398144158136118		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.07398144158136118 | validation: 0.07559600107741699]
	TIME [epoch: 9.04 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07629274255554039		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.07629274255554039 | validation: 0.06600941437687881]
	TIME [epoch: 9.01 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08688289159023525		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.08688289159023525 | validation: 0.07454689166127183]
	TIME [epoch: 9.02 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08866082220611485		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.08866082220611485 | validation: 0.07151405487099614]
	TIME [epoch: 9.02 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07503192394566638		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.07503192394566638 | validation: 0.07010547369343041]
	TIME [epoch: 9.01 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07499146139145041		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.07499146139145041 | validation: 0.0827786599980212]
	TIME [epoch: 9.03 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07270313805973491		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.07270313805973491 | validation: 0.0805806487155641]
	TIME [epoch: 9.01 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08428445302696877		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.08428445302696877 | validation: 0.08338870489303421]
	TIME [epoch: 9.01 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09248247224764249		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.09248247224764249 | validation: 0.0897342840165137]
	TIME [epoch: 9.01 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07690215115289417		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.07690215115289417 | validation: 0.06341526461849883]
	TIME [epoch: 9.03 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07073051453923238		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.07073051453923238 | validation: 0.10051609684407048]
	TIME [epoch: 9.01 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08964025777781046		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.08964025777781046 | validation: 0.09174060259556657]
	TIME [epoch: 9.01 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10269254599590749		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.10269254599590749 | validation: 0.08972875429649613]
	TIME [epoch: 9 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09351239272482569		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.09351239272482569 | validation: 0.08059506821224444]
	TIME [epoch: 9.02 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07508002987756154		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.07508002987756154 | validation: 0.06095286815360625]
	TIME [epoch: 9.03 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06685197070488896		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.06685197070488896 | validation: 0.06299311595239004]
	TIME [epoch: 9.03 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07605903269116446		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.07605903269116446 | validation: 0.0652580724996138]
	TIME [epoch: 9.02 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06892300560322104		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.06892300560322104 | validation: 0.0374610502888634]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1375.pth
	Model improved!!!
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525743326520239		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.06525743326520239 | validation: 0.06829636602267407]
	TIME [epoch: 9.05 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720655234932376		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.08720655234932376 | validation: 0.06561517969170766]
	TIME [epoch: 9.02 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08125090588946778		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.08125090588946778 | validation: 0.07936906548659153]
	TIME [epoch: 9.02 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07173905216994163		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.07173905216994163 | validation: 0.058487137716628494]
	TIME [epoch: 9.03 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07950003763820501		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.07950003763820501 | validation: 0.04744884566311391]
	TIME [epoch: 9.03 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06731567120215179		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.06731567120215179 | validation: 0.0806169931534586]
	TIME [epoch: 9.05 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09174459807877725		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.09174459807877725 | validation: 0.08363086030362037]
	TIME [epoch: 9.03 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09405004114301914		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.09405004114301914 | validation: 0.07185810035337989]
	TIME [epoch: 9.02 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08162291337434915		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.08162291337434915 | validation: 0.07645625855432997]
	TIME [epoch: 9.02 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07842528744763029		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.07842528744763029 | validation: 0.06356631796656671]
	TIME [epoch: 9.02 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777542396997083		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.0777542396997083 | validation: 0.06981354678635529]
	TIME [epoch: 9.06 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06712826870065025		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.06712826870065025 | validation: 0.05928510454283885]
	TIME [epoch: 9.03 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08183148293504226		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.08183148293504226 | validation: 0.050442638002843584]
	TIME [epoch: 9.03 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07878578933532768		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.07878578933532768 | validation: 0.060250847853378094]
	TIME [epoch: 9.02 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08489016889857333		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.08489016889857333 | validation: 0.06660219213100993]
	TIME [epoch: 9.04 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07820870239174675		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.07820870239174675 | validation: 0.05745044711281179]
	TIME [epoch: 9.03 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06612667050951428		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.06612667050951428 | validation: 0.07258406028171235]
	TIME [epoch: 9.02 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08040294828002471		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.08040294828002471 | validation: 0.11065123559675363]
	TIME [epoch: 9.02 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08371357097047274		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.08371357097047274 | validation: 0.061362667121987576]
	TIME [epoch: 9.03 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07375986554042974		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.07375986554042974 | validation: 0.06035505199817723]
	TIME [epoch: 9.04 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0865239016198391		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.0865239016198391 | validation: 0.07288614416426868]
	TIME [epoch: 9.03 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08261001270843947		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.08261001270843947 | validation: 0.07039579632294626]
	TIME [epoch: 9.02 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08428464981792529		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.08428464981792529 | validation: 0.07057193406412822]
	TIME [epoch: 9.02 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08733225283512472		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.08733225283512472 | validation: 0.07862442516089006]
	TIME [epoch: 9.05 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09425872061555522		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.09425872061555522 | validation: 0.08512937306866109]
	TIME [epoch: 9.03 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07716200387187018		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.07716200387187018 | validation: 0.06255357605228737]
	TIME [epoch: 9.03 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064851080505607		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.08064851080505607 | validation: 0.06489930006460201]
	TIME [epoch: 9.03 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07480126607568997		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.07480126607568997 | validation: 0.0751897842447135]
	TIME [epoch: 9.02 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06556587201126024		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.06556587201126024 | validation: 0.05945661273832419]
	TIME [epoch: 9.04 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07080866588359155		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.07080866588359155 | validation: 0.0564146181112999]
	TIME [epoch: 9.02 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816209723315568		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.07816209723315568 | validation: 0.10171718845595934]
	TIME [epoch: 9.03 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095213173546068		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.1095213173546068 | validation: 0.06983181635379403]
	TIME [epoch: 9.02 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07495612103200394		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.07495612103200394 | validation: 0.06393449858633588]
	TIME [epoch: 9.02 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0758305809323585		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.0758305809323585 | validation: 0.06538523775916427]
	TIME [epoch: 9.04 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07172275997285643		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.07172275997285643 | validation: 0.07506668973512395]
	TIME [epoch: 9.02 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07634100124079848		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.07634100124079848 | validation: 0.051191237593031916]
	TIME [epoch: 9.03 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08829906576862837		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.08829906576862837 | validation: 0.06568339873255087]
	TIME [epoch: 9.02 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08363309923551719		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.08363309923551719 | validation: 0.09393287653654422]
	TIME [epoch: 9.05 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08304652721504895		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.08304652721504895 | validation: 0.06472019888063803]
	TIME [epoch: 9.04 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609837482191186		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.06609837482191186 | validation: 0.07231251335223216]
	TIME [epoch: 9.02 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707172073863456		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.06707172073863456 | validation: 0.07208314094154064]
	TIME [epoch: 9.02 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0783768277240705		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.0783768277240705 | validation: 0.07346456440351401]
	TIME [epoch: 9.02 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07538936380391752		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.07538936380391752 | validation: 0.05791436977002647]
	TIME [epoch: 9.04 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08060505884225924		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.08060505884225924 | validation: 0.06891062776309219]
	TIME [epoch: 9.03 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09882989673184565		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.09882989673184565 | validation: 0.0443324506966054]
	TIME [epoch: 9.02 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07861003819918165		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.07861003819918165 | validation: 0.04752742602100275]
	TIME [epoch: 9.03 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07001262431853786		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.07001262431853786 | validation: 0.05738674191639918]
	TIME [epoch: 9.03 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07470588948910609		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.07470588948910609 | validation: 0.05762634075409042]
	TIME [epoch: 9.03 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643383159981596		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.0643383159981596 | validation: 0.10121984671021694]
	TIME [epoch: 9.03 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08346784479704493		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.08346784479704493 | validation: 0.04757212533421321]
	TIME [epoch: 9.02 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06616714058990023		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.06616714058990023 | validation: 0.04801628165257485]
	TIME [epoch: 9.03 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07725870301308282		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.07725870301308282 | validation: 0.061031681528962684]
	TIME [epoch: 9.05 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07404041491692664		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.07404041491692664 | validation: 0.0782495950171567]
	TIME [epoch: 9.02 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09917337920182534		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.09917337920182534 | validation: 0.08524547111255054]
	TIME [epoch: 9.03 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07044895505508693		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.07044895505508693 | validation: 0.05577792852746545]
	TIME [epoch: 9.01 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270129919518896		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.06270129919518896 | validation: 0.05392726051632453]
	TIME [epoch: 9.02 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07549112861052606		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.07549112861052606 | validation: 0.07999389233749213]
	TIME [epoch: 9.05 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08116495214031397		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.08116495214031397 | validation: 0.05191630038390252]
	TIME [epoch: 9.01 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07185543369023598		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.07185543369023598 | validation: 0.06406365116064043]
	TIME [epoch: 9.02 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06617290226941668		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.06617290226941668 | validation: 0.041229966503270446]
	TIME [epoch: 9.02 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0697797486452057		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.0697797486452057 | validation: 0.061690476638574576]
	TIME [epoch: 9.04 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665519712957625		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.0665519712957625 | validation: 0.05797109048694904]
	TIME [epoch: 9.02 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07823665006104114		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.07823665006104114 | validation: 0.07834175866780183]
	TIME [epoch: 9.01 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630402834286362		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.07630402834286362 | validation: 0.0482704013951037]
	TIME [epoch: 9.02 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08455785466536717		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.08455785466536717 | validation: 0.08264624695376116]
	TIME [epoch: 9.02 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09117339446793445		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.09117339446793445 | validation: 0.06200298469320143]
	TIME [epoch: 9.04 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07041325276413159		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.07041325276413159 | validation: 0.0828909739268914]
	TIME [epoch: 9.02 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291412040893124		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.07291412040893124 | validation: 0.03437306798910878]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1443.pth
	Model improved!!!
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05792071870086437		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.05792071870086437 | validation: 0.05588051238214224]
	TIME [epoch: 9.02 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662024175173974		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.0662024175173974 | validation: 0.051031035226139526]
	TIME [epoch: 9.03 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07318315927411446		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.07318315927411446 | validation: 0.07542512399353232]
	TIME [epoch: 9.02 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08946588178593207		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.08946588178593207 | validation: 0.0757458438863558]
	TIME [epoch: 9.02 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08083820021473576		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.08083820021473576 | validation: 0.054084844676242166]
	TIME [epoch: 9.02 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083162240770741		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.083162240770741 | validation: 0.06045226244893288]
	TIME [epoch: 9.02 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727082041885683		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.07727082041885683 | validation: 0.06765742012258731]
	TIME [epoch: 9.04 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08640894974416181		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.08640894974416181 | validation: 0.050211132524105535]
	TIME [epoch: 9.02 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06933417515228231		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.06933417515228231 | validation: 0.05816181300620442]
	TIME [epoch: 9.02 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06116399955783995		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.06116399955783995 | validation: 0.05491660316912288]
	TIME [epoch: 9.03 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08025462672542091		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.08025462672542091 | validation: 0.06215298854669833]
	TIME [epoch: 9.03 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07292248424211026		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.07292248424211026 | validation: 0.06499763350741822]
	TIME [epoch: 9.05 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441130691779004		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.06441130691779004 | validation: 0.043856718423227255]
	TIME [epoch: 9.02 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07350816402874259		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.07350816402874259 | validation: 0.06433223067064205]
	TIME [epoch: 9.02 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06928153681795886		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.06928153681795886 | validation: 0.06158278798380032]
	TIME [epoch: 9.02 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07004291437664599		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.07004291437664599 | validation: 0.07791570203772312]
	TIME [epoch: 9.04 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0715408173046609		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.0715408173046609 | validation: 0.06247520173994374]
	TIME [epoch: 9.03 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07546861595321269		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.07546861595321269 | validation: 0.06770229094510037]
	TIME [epoch: 9.02 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07254556236928178		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.07254556236928178 | validation: 0.0622540414967538]
	TIME [epoch: 9.02 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684287044181671		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.0684287044181671 | validation: 0.06408919350969472]
	TIME [epoch: 9.02 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040275029340848		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.07040275029340848 | validation: 0.0659107716611669]
	TIME [epoch: 9.04 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06940552784553525		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.06940552784553525 | validation: 0.058012382273475036]
	TIME [epoch: 9.03 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07192888544012797		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.07192888544012797 | validation: 0.056407415280282]
	TIME [epoch: 9.03 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06977381986264138		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.06977381986264138 | validation: 0.07273349318469323]
	TIME [epoch: 9.03 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08281859912147946		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.08281859912147946 | validation: 0.06530370554975387]
	TIME [epoch: 9.03 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630286065712003		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.07630286065712003 | validation: 0.0537624166216065]
	TIME [epoch: 9.03 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06910808006371916		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.06910808006371916 | validation: 0.06576408478017581]
	TIME [epoch: 9.02 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284611472732563		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.07284611472732563 | validation: 0.06994051936862206]
	TIME [epoch: 9.02 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08035544942127067		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.08035544942127067 | validation: 0.05601483027675433]
	TIME [epoch: 9.02 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06942944952059418		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.06942944952059418 | validation: 0.05958054360691378]
	TIME [epoch: 9.04 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07677373987422276		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.07677373987422276 | validation: 0.056647503991794745]
	TIME [epoch: 9.02 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0641311244738679		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.0641311244738679 | validation: 0.050397157504652616]
	TIME [epoch: 9.02 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689901762882909		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.0689901762882909 | validation: 0.06373034918318898]
	TIME [epoch: 9.03 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07807727922254748		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.07807727922254748 | validation: 0.06339415003518302]
	TIME [epoch: 9.02 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06862507985578618		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.06862507985578618 | validation: 0.056649621190954194]
	TIME [epoch: 9.05 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07478157302351665		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.07478157302351665 | validation: 0.06564169489526142]
	TIME [epoch: 9.03 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525817862064807		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.07525817862064807 | validation: 0.07935463017108023]
	TIME [epoch: 9.03 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.072802111722482		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.072802111722482 | validation: 0.04328249908637796]
	TIME [epoch: 9.03 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0745257610049874		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.0745257610049874 | validation: 0.06472531778222293]
	TIME [epoch: 9.05 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07984224014132849		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.07984224014132849 | validation: 0.047689489297729204]
	TIME [epoch: 9.03 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07399444043156865		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.07399444043156865 | validation: 0.07780037819129443]
	TIME [epoch: 9.03 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854489565138029		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.06854489565138029 | validation: 0.053247758464524696]
	TIME [epoch: 9.03 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06904186109000422		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.06904186109000422 | validation: 0.044430393439568096]
	TIME [epoch: 9.02 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06290562266067376		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.06290562266067376 | validation: 0.0536061723206925]
	TIME [epoch: 9.04 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07280356561611208		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.07280356561611208 | validation: 0.0515788178579466]
	TIME [epoch: 9.03 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07448773484179734		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.07448773484179734 | validation: 0.07530610923903477]
	TIME [epoch: 9.03 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890317989111873		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.06890317989111873 | validation: 0.04189169058156241]
	TIME [epoch: 9.03 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07627615861889844		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.07627615861889844 | validation: 0.07702123565222785]
	TIME [epoch: 9.03 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07380154090166116		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.07380154090166116 | validation: 0.061757647829155375]
	TIME [epoch: 9.05 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951154190080555		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.06951154190080555 | validation: 0.054768553538698764]
	TIME [epoch: 9.04 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06164001726582356		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.06164001726582356 | validation: 0.05016186872562169]
	TIME [epoch: 9.03 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407309752845922		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.06407309752845922 | validation: 0.048144592224298614]
	TIME [epoch: 9.03 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06749356971113517		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.06749356971113517 | validation: 0.054268659659749634]
	TIME [epoch: 9.04 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06602810470143453		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.06602810470143453 | validation: 0.05506408327956895]
	TIME [epoch: 9.03 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770759268445539		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.06770759268445539 | validation: 0.057094652902709916]
	TIME [epoch: 9.03 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06424491250809763		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.06424491250809763 | validation: 0.042796847283046675]
	TIME [epoch: 9.02 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06487415172840702		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.06487415172840702 | validation: 0.05692169275150048]
	TIME [epoch: 9.03 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07199596651289726		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.07199596651289726 | validation: 0.06912564826801151]
	TIME [epoch: 9.04 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941311616265716		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.06941311616265716 | validation: 0.06438089342535544]
	TIME [epoch: 9.03 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07997542397596605		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.07997542397596605 | validation: 0.04525877013087276]
	TIME [epoch: 9.03 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07444919691435331		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.07444919691435331 | validation: 0.06408036849284877]
	TIME [epoch: 9.02 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0634656153403719		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.0634656153403719 | validation: 0.04573162072122841]
	TIME [epoch: 9.05 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648521097302038		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.0648521097302038 | validation: 0.05812052151398257]
	TIME [epoch: 9.03 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556598846825824		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.07556598846825824 | validation: 0.058729514221760516]
	TIME [epoch: 9.03 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0641959359114955		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0641959359114955 | validation: 0.056254708920087784]
	TIME [epoch: 9.03 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07257665721182607		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.07257665721182607 | validation: 0.05288372525103378]
	TIME [epoch: 9.02 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05643168846515391		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.05643168846515391 | validation: 0.06446290869405333]
	TIME [epoch: 9.05 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545645485827122		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.06545645485827122 | validation: 0.045394119843351816]
	TIME [epoch: 9.03 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060853852675033474		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.060853852675033474 | validation: 0.05242763504632714]
	TIME [epoch: 9.03 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06657361136550835		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.06657361136550835 | validation: 0.06324836373580375]
	TIME [epoch: 9.03 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493383379080445		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.06493383379080445 | validation: 0.041590430770589465]
	TIME [epoch: 9.03 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06504718102598744		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.06504718102598744 | validation: 0.05520335273677803]
	TIME [epoch: 9.04 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07027352651367019		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.07027352651367019 | validation: 0.05085759190345388]
	TIME [epoch: 9.02 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07958339133168264		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.07958339133168264 | validation: 0.0554669020093443]
	TIME [epoch: 9.02 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06387517667053218		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.06387517667053218 | validation: 0.05805994510020043]
	TIME [epoch: 9.02 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533394958998158		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.06533394958998158 | validation: 0.04661230756017572]
	TIME [epoch: 9.04 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06809773705858733		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.06809773705858733 | validation: 0.06510130747344724]
	TIME [epoch: 9.03 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06509988904782331		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.06509988904782331 | validation: 0.04713255772992679]
	TIME [epoch: 9.02 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09319375656692044		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.09319375656692044 | validation: 0.07483491993475412]
	TIME [epoch: 9.03 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06954407860379472		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.06954407860379472 | validation: 0.06250953190896646]
	TIME [epoch: 9.03 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229464022684848		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.06229464022684848 | validation: 0.06486924689461018]
	TIME [epoch: 9.04 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500743077132116		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.06500743077132116 | validation: 0.05937531422113798]
	TIME [epoch: 9.02 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06345022298081679		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.06345022298081679 | validation: 0.08587224593677725]
	TIME [epoch: 9.02 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07635004874378862		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.07635004874378862 | validation: 0.04691307827246146]
	TIME [epoch: 9.02 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06759176622808052		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.06759176622808052 | validation: 0.07053603291830815]
	TIME [epoch: 9.04 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566254201070845		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.06566254201070845 | validation: 0.0650721367858579]
	TIME [epoch: 9.03 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07210514042839579		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.07210514042839579 | validation: 0.05062437182907692]
	TIME [epoch: 9.02 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324202307063746		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.07324202307063746 | validation: 0.055733696636138634]
	TIME [epoch: 9.02 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07418106079085726		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.07418106079085726 | validation: 0.07946622095559323]
	TIME [epoch: 9.03 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07917890482696964		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.07917890482696964 | validation: 0.05495111907154192]
	TIME [epoch: 9.05 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07706452170368441		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.07706452170368441 | validation: 0.06770488696407784]
	TIME [epoch: 9.02 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06690102345463313		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.06690102345463313 | validation: 0.06183687112532635]
	TIME [epoch: 9.03 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07833146488043907		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.07833146488043907 | validation: 0.0704334975732111]
	TIME [epoch: 9.02 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07125392505861405		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.07125392505861405 | validation: 0.0615206826962025]
	TIME [epoch: 9.03 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07794112886261642		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.07794112886261642 | validation: 0.06477188823940637]
	TIME [epoch: 9.05 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06970272654755848		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.06970272654755848 | validation: 0.04967332349786565]
	TIME [epoch: 9.02 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06644730084067876		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.06644730084067876 | validation: 0.059864903599758344]
	TIME [epoch: 9.03 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06602787472962365		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.06602787472962365 | validation: 0.060163168585037216]
	TIME [epoch: 9.03 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06462334230519225		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.06462334230519225 | validation: 0.05035778719195601]
	TIME [epoch: 9.04 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060631978433106984		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.060631978433106984 | validation: 0.053729617677261615]
	TIME [epoch: 9.02 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06749929945580632		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.06749929945580632 | validation: 0.04702273934449862]
	TIME [epoch: 9.02 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07137379692932526		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.07137379692932526 | validation: 0.0912336160960737]
	TIME [epoch: 9.03 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08614895165449364		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.08614895165449364 | validation: 0.07255221900691682]
	TIME [epoch: 9.03 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270617867988801		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.08270617867988801 | validation: 0.08279195240925044]
	TIME [epoch: 9.05 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08297845905506479		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.08297845905506479 | validation: 0.06370598951860558]
	TIME [epoch: 9.03 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666254139594632		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.06666254139594632 | validation: 0.05777973364463637]
	TIME [epoch: 9.02 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06652795243852316		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.06652795243852316 | validation: 0.05544647122544356]
	TIME [epoch: 9.02 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06257175297114322		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.06257175297114322 | validation: 0.05174919461317786]
	TIME [epoch: 9.04 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040482748764343		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.07040482748764343 | validation: 0.04612954823378905]
	TIME [epoch: 9.03 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524738880691588		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.06524738880691588 | validation: 0.05006800636028971]
	TIME [epoch: 9.02 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06640864123821308		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.06640864123821308 | validation: 0.05155344970852174]
	TIME [epoch: 9.02 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0736678282673675		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.0736678282673675 | validation: 0.052614185606725275]
	TIME [epoch: 9.02 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0822992442482958		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.0822992442482958 | validation: 0.09685321050285459]
	TIME [epoch: 9.03 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0853567949595135		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.0853567949595135 | validation: 0.059511321109960574]
	TIME [epoch: 9.01 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07132673563737928		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.07132673563737928 | validation: 0.044888487636341484]
	TIME [epoch: 9.03 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631534547889109		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.0631534547889109 | validation: 0.05347620130511033]
	TIME [epoch: 9.02 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500837023138169		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.06500837023138169 | validation: 0.03951801412450091]
	TIME [epoch: 9.03 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06745680622486244		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.06745680622486244 | validation: 0.05790662385375951]
	TIME [epoch: 9.04 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06932147731591226		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.06932147731591226 | validation: 0.04951480044931696]
	TIME [epoch: 9.01 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811726744312878		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.06811726744312878 | validation: 0.059267064201144984]
	TIME [epoch: 9.02 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062444519340830416		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.062444519340830416 | validation: 0.05664224823076994]
	TIME [epoch: 9.01 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06437973588935345		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.06437973588935345 | validation: 0.0488159218275238]
	TIME [epoch: 9.03 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059105551550416434		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.059105551550416434 | validation: 0.04875346252601705]
	TIME [epoch: 9.03 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07940353322496504		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.07940353322496504 | validation: 0.06668073177028382]
	TIME [epoch: 9.02 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07576797890057178		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.07576797890057178 | validation: 0.06558643429276909]
	TIME [epoch: 9.01 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07332433233274138		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.07332433233274138 | validation: 0.06694113325548894]
	TIME [epoch: 9.01 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555557051768399		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.06555557051768399 | validation: 0.04724530328307988]
	TIME [epoch: 9.04 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681337297245167		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.0681337297245167 | validation: 0.051310840623022276]
	TIME [epoch: 9.03 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061786755346824006		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.061786755346824006 | validation: 0.05760254797129012]
	TIME [epoch: 9.03 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553789505777931		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.06553789505777931 | validation: 0.0577087274907323]
	TIME [epoch: 9.03 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06488065637004467		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.06488065637004467 | validation: 0.057475181650808047]
	TIME [epoch: 9.04 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07210425728226616		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.07210425728226616 | validation: 0.04142279502038422]
	TIME [epoch: 9.02 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811454003581109		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.06811454003581109 | validation: 0.05786908985166314]
	TIME [epoch: 9.02 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06846549349385164		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.06846549349385164 | validation: 0.05333422520817721]
	TIME [epoch: 9.01 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07641434593971257		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.07641434593971257 | validation: 0.052861151325081325]
	TIME [epoch: 9.02 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07195393348988091		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.07195393348988091 | validation: 0.08418113673206548]
	TIME [epoch: 9.05 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0906367236642597		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.0906367236642597 | validation: 0.08617239537685713]
	TIME [epoch: 9.02 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08232634153042824		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.08232634153042824 | validation: 0.05435708895795317]
	TIME [epoch: 9.02 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834622419527565		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.06834622419527565 | validation: 0.05996955109100888]
	TIME [epoch: 9.02 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0690599753644848		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.0690599753644848 | validation: 0.056563089241721105]
	TIME [epoch: 9.02 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07147392214639092		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.07147392214639092 | validation: 0.06360695961144953]
	TIME [epoch: 9.03 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793947884179597		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.0793947884179597 | validation: 0.04542544618382875]
	TIME [epoch: 9.02 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06891546368197435		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.06891546368197435 | validation: 0.06609191537586681]
	TIME [epoch: 9.03 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526392299104267		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.06526392299104267 | validation: 0.0520930471112593]
	TIME [epoch: 9.02 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299293820895653		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.07299293820895653 | validation: 0.0703588525212753]
	TIME [epoch: 9.03 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785043212982854		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.0785043212982854 | validation: 0.07629551757105205]
	TIME [epoch: 9.02 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08098281164298624		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.08098281164298624 | validation: 0.05668506729460172]
	TIME [epoch: 9.01 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629268391354964		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.0629268391354964 | validation: 0.04348951029419858]
	TIME [epoch: 9.02 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05490632115882811		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.05490632115882811 | validation: 0.04315346048210907]
	TIME [epoch: 9.01 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528093844269969		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.06528093844269969 | validation: 0.04645028257012143]
	TIME [epoch: 9.04 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628185199817916		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.0628185199817916 | validation: 0.04490433580809978]
	TIME [epoch: 9.01 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06625395501991997		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.06625395501991997 | validation: 0.04463488328197808]
	TIME [epoch: 9.01 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06405804718946156		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.06405804718946156 | validation: 0.05204336105662234]
	TIME [epoch: 9.02 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060646779066476156		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.060646779066476156 | validation: 0.04446499741187014]
	TIME [epoch: 9.03 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07282288771855491		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.07282288771855491 | validation: 0.054895801064031156]
	TIME [epoch: 9.03 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0664244521196837		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.0664244521196837 | validation: 0.07866217832088815]
	TIME [epoch: 9.03 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682436616177243		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.0682436616177243 | validation: 0.052139684591757635]
	TIME [epoch: 9.02 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06531246508742695		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.06531246508742695 | validation: 0.06596982866056363]
	TIME [epoch: 9.02 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06448944345946178		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.06448944345946178 | validation: 0.07005577748032277]
	TIME [epoch: 9.03 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06807606034679574		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.06807606034679574 | validation: 0.0572673609461815]
	TIME [epoch: 9.02 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062127706094940324		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.062127706094940324 | validation: 0.054329257774086794]
	TIME [epoch: 9.02 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411871298367225		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.06411871298367225 | validation: 0.04966364186002008]
	TIME [epoch: 9.01 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06654561284452364		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.06654561284452364 | validation: 0.048895552750209896]
	TIME [epoch: 9.01 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06035624782784266		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.06035624782784266 | validation: 0.06426823494948915]
	TIME [epoch: 9.04 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890751326295672		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.06890751326295672 | validation: 0.07033639640553983]
	TIME [epoch: 9.01 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06536906550185531		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.06536906550185531 | validation: 0.05862908797388567]
	TIME [epoch: 9.02 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06384575407581106		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.06384575407581106 | validation: 0.054921055851075914]
	TIME [epoch: 9.01 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06813525241751925		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.06813525241751925 | validation: 0.05461733661136575]
	TIME [epoch: 9.04 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06561924452772624		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.06561924452772624 | validation: 0.05653696253259022]
	TIME [epoch: 9.02 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06590550560218746		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.06590550560218746 | validation: 0.06267999128535148]
	TIME [epoch: 9.02 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06184125368021447		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.06184125368021447 | validation: 0.0689314935462558]
	TIME [epoch: 9.01 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06867765719748761		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.06867765719748761 | validation: 0.06652370621838982]
	TIME [epoch: 9.02 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06543521922402236		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.06543521922402236 | validation: 0.05624370152421999]
	TIME [epoch: 9.03 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06119693566463519		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.06119693566463519 | validation: 0.04563102838399597]
	TIME [epoch: 9.02 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493621587805712		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.06493621587805712 | validation: 0.06474543562775834]
	TIME [epoch: 9.01 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951605726708339		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.06951605726708339 | validation: 0.05985314631195582]
	TIME [epoch: 9.01 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06394179140898917		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.06394179140898917 | validation: 0.04527282043195456]
	TIME [epoch: 9.02 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05894655044232648		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.05894655044232648 | validation: 0.05459912612691313]
	TIME [epoch: 9.04 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06450916948022102		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.06450916948022102 | validation: 0.06700256084957482]
	TIME [epoch: 9.01 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053415110730817		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.07053415110730817 | validation: 0.04859516942761263]
	TIME [epoch: 9.01 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06285704924865874		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.06285704924865874 | validation: 0.04631391247142997]
	TIME [epoch: 9.02 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0658581538938612		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.0658581538938612 | validation: 0.06740448063118654]
	TIME [epoch: 9.03 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06717719544922214		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.06717719544922214 | validation: 0.05546821681717966]
	TIME [epoch: 9.02 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819300749583737		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.05819300749583737 | validation: 0.062447952784258014]
	TIME [epoch: 9.02 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0649165573778616		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.0649165573778616 | validation: 0.054337684744106614]
	TIME [epoch: 9.02 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061315182903006596		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.061315182903006596 | validation: 0.05920863793198802]
	TIME [epoch: 9.02 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06220936828917464		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.06220936828917464 | validation: 0.059056940724465254]
	TIME [epoch: 9.03 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057558462858487126		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.057558462858487126 | validation: 0.05370073876929719]
	TIME [epoch: 9.02 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0586586731309036		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.0586586731309036 | validation: 0.04928505268558497]
	TIME [epoch: 9.01 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06975187631882525		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.06975187631882525 | validation: 0.049927350362453694]
	TIME [epoch: 9.01 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060598724097596215		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.060598724097596215 | validation: 0.06925208427444143]
	TIME [epoch: 9.03 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860545813094066		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.06860545813094066 | validation: 0.061825458465905564]
	TIME [epoch: 9.02 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06367861743303319		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.06367861743303319 | validation: 0.04626807766018957]
	TIME [epoch: 9.02 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06455485535325564		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.06455485535325564 | validation: 0.06901462133875752]
	TIME [epoch: 9.01 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06372122433778893		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.06372122433778893 | validation: 0.061519071124691786]
	TIME [epoch: 9.02 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648219318317764		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.0648219318317764 | validation: 0.04279138884386463]
	TIME [epoch: 9.04 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06114243233747135		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.06114243233747135 | validation: 0.06137976601123134]
	TIME [epoch: 9.02 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06624438086597202		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.06624438086597202 | validation: 0.049888962835016246]
	TIME [epoch: 9.01 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666760756717453		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.06666760756717453 | validation: 0.06371075025350953]
	TIME [epoch: 9.01 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06492007807192056		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.06492007807192056 | validation: 0.06358387056222824]
	TIME [epoch: 9.02 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06073966377442889		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.06073966377442889 | validation: 0.045421010596413236]
	TIME [epoch: 9.02 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06550948523786752		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.06550948523786752 | validation: 0.05828675944724869]
	TIME [epoch: 9.01 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936082985775852		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.05936082985775852 | validation: 0.059334177458204226]
	TIME [epoch: 9.01 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06544867213399244		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.06544867213399244 | validation: 0.04938286219063438]
	TIME [epoch: 9.01 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06735904193108319		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.06735904193108319 | validation: 0.060250031347170774]
	TIME [epoch: 9.02 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05839081123391622		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.05839081123391622 | validation: 0.04530388775281556]
	TIME [epoch: 9.01 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059411840487659504		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.059411840487659504 | validation: 0.047789575400563306]
	TIME [epoch: 9.01 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05852745053359508		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.05852745053359508 | validation: 0.05490290338451632]
	TIME [epoch: 9.02 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05440001312621059		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.05440001312621059 | validation: 0.050444500171220666]
	TIME [epoch: 9.02 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06425298172521403		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.06425298172521403 | validation: 0.0607252167611895]
	TIME [epoch: 9.03 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05925295159631243		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.05925295159631243 | validation: 0.04784097196994665]
	TIME [epoch: 9.01 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061470920614416204		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.061470920614416204 | validation: 0.05224647783596027]
	TIME [epoch: 9.01 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060310153216480936		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.060310153216480936 | validation: 0.04103508765992424]
	TIME [epoch: 9.01 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058651582454380666		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.058651582454380666 | validation: 0.0658367264040645]
	TIME [epoch: 9.02 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834316114962515		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.06834316114962515 | validation: 0.04836323201076039]
	TIME [epoch: 9.02 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784092974215475		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.06784092974215475 | validation: 0.05157883441577364]
	TIME [epoch: 9.01 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059736555793030666		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.059736555793030666 | validation: 0.05899703505301811]
	TIME [epoch: 9 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05756619389057198		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.05756619389057198 | validation: 0.045264810878754634]
	TIME [epoch: 9.01 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215651301745427		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.07215651301745427 | validation: 0.04917604556777131]
	TIME [epoch: 9.03 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06247737495140454		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.06247737495140454 | validation: 0.05013214324251815]
	TIME [epoch: 9.01 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06177447934227692		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.06177447934227692 | validation: 0.06071023423743137]
	TIME [epoch: 9.02 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06322516430451289		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.06322516430451289 | validation: 0.059518989373738375]
	TIME [epoch: 9.02 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06484541968363326		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.06484541968363326 | validation: 0.05256282447329806]
	TIME [epoch: 9.03 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06235797942653813		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.06235797942653813 | validation: 0.06562730505753463]
	TIME [epoch: 9.03 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07085074024736893		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.07085074024736893 | validation: 0.05416358380856891]
	TIME [epoch: 9 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06538878415879433		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.06538878415879433 | validation: 0.052491029620493665]
	TIME [epoch: 9.01 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653651236405662		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.0653651236405662 | validation: 0.053823988995649025]
	TIME [epoch: 9.01 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06218346958526562		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.06218346958526562 | validation: 0.0565193449348364]
	TIME [epoch: 9.03 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494071241048405		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.06494071241048405 | validation: 0.0743071207435118]
	TIME [epoch: 9.01 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07116935281788454		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.07116935281788454 | validation: 0.05498284990698287]
	TIME [epoch: 9.01 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06396951578287925		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.06396951578287925 | validation: 0.055241949974001545]
	TIME [epoch: 9.01 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061509743876123714		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.061509743876123714 | validation: 0.04210412896698563]
	TIME [epoch: 9.01 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061576263268221444		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.061576263268221444 | validation: 0.05147309636893248]
	TIME [epoch: 9.03 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06602634144151806		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.06602634144151806 | validation: 0.05106209121545974]
	TIME [epoch: 9.02 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06491063431561336		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.06491063431561336 | validation: 0.05181724646176639]
	TIME [epoch: 9.01 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062422823382469225		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.062422823382469225 | validation: 0.060405561567457855]
	TIME [epoch: 9.02 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173946851284482		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.06173946851284482 | validation: 0.04931485285485307]
	TIME [epoch: 9.03 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058871149397706414		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.058871149397706414 | validation: 0.052356256151227576]
	TIME [epoch: 9.01 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06168400185781505		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.06168400185781505 | validation: 0.05773641733127057]
	TIME [epoch: 9.02 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659293460120594		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.0659293460120594 | validation: 0.06296496168958542]
	TIME [epoch: 9.01 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633545061971554		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.0633545061971554 | validation: 0.049427434089371766]
	TIME [epoch: 9.02 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05806821971264914		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.05806821971264914 | validation: 0.049909200506855635]
	TIME [epoch: 9.03 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05730787816713908		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.05730787816713908 | validation: 0.036605914595993765]
	TIME [epoch: 9.02 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783864840674458		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.06783864840674458 | validation: 0.04844881014103939]
	TIME [epoch: 9.02 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06234778712103343		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.06234778712103343 | validation: 0.05574607369192934]
	TIME [epoch: 9.01 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651414598679828		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.0651414598679828 | validation: 0.050845421491786766]
	TIME [epoch: 9.02 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06252013392604164		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.06252013392604164 | validation: 0.062328961702778754]
	TIME [epoch: 9.03 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604056927314065		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.07604056927314065 | validation: 0.06522646307242116]
	TIME [epoch: 9.02 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528725886439689		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.06528725886439689 | validation: 0.07591363683602168]
	TIME [epoch: 9.02 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583339501792088		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.07583339501792088 | validation: 0.06493974615005199]
	TIME [epoch: 9.01 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06656261705968465		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.06656261705968465 | validation: 0.07019543934359986]
	TIME [epoch: 9.03 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0699403910953625		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.0699403910953625 | validation: 0.05821269423214884]
	TIME [epoch: 9.01 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060617601922827155		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.060617601922827155 | validation: 0.05263430252951101]
	TIME [epoch: 9 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205455256939211		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.06205455256939211 | validation: 0.05037446712554426]
	TIME [epoch: 9.02 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061375712812560136		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.061375712812560136 | validation: 0.05038220916969091]
	TIME [epoch: 9 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05931312534918236		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.05931312534918236 | validation: 0.0611159712026617]
	TIME [epoch: 9.03 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06309616566437495		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.06309616566437495 | validation: 0.04301166636216883]
	TIME [epoch: 9.01 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411758540338071		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.06411758540338071 | validation: 0.061746200829496264]
	TIME [epoch: 9.01 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06204677704720479		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.06204677704720479 | validation: 0.06771041271561318]
	TIME [epoch: 9.01 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642623461571973		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.0642623461571973 | validation: 0.05449524757305273]
	TIME [epoch: 9.03 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05798226947501918		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.05798226947501918 | validation: 0.050455115285143556]
	TIME [epoch: 9.02 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05508744757383932		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.05508744757383932 | validation: 0.04935116385754112]
	TIME [epoch: 9.02 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441415539095866		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.06441415539095866 | validation: 0.05517824260803923]
	TIME [epoch: 9.02 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06055734142296591		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.06055734142296591 | validation: 0.05119972109771921]
	TIME [epoch: 9.01 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05654569638803645		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.05654569638803645 | validation: 0.050749939562761366]
	TIME [epoch: 9.03 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0650489202520896		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.0650489202520896 | validation: 0.05018989722229565]
	TIME [epoch: 9.02 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06802978599725054		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.06802978599725054 | validation: 0.04549015725770408]
	TIME [epoch: 9.01 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061027851142388234		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.061027851142388234 | validation: 0.045382987417771706]
	TIME [epoch: 9.01 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171278530623532		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.05171278530623532 | validation: 0.047590108538043796]
	TIME [epoch: 9.02 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060122354455869796		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.060122354455869796 | validation: 0.0505267091973315]
	TIME [epoch: 9.03 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05676121145082781		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.05676121145082781 | validation: 0.061084785468060676]
	TIME [epoch: 9.01 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06290981991651401		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.06290981991651401 | validation: 0.0619704661626142]
	TIME [epoch: 9.02 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07465832834981481		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.07465832834981481 | validation: 0.05353722391191168]
	TIME [epoch: 9.01 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06090716032567652		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.06090716032567652 | validation: 0.05686608060358904]
	TIME [epoch: 9.04 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06022729513574743		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.06022729513574743 | validation: 0.052416463922314374]
	TIME [epoch: 9.02 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06495595525804151		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.06495595525804151 | validation: 0.04779859045022347]
	TIME [epoch: 9.02 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060540264121915786		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.060540264121915786 | validation: 0.06015264934026007]
	TIME [epoch: 9.01 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060148045235386804		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.060148045235386804 | validation: 0.04705718377360962]
	TIME [epoch: 9.01 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05669741027798937		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.05669741027798937 | validation: 0.05215393196596959]
	TIME [epoch: 9.03 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06606123937240894		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.06606123937240894 | validation: 0.053729778886245125]
	TIME [epoch: 9.01 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05592673665106954		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.05592673665106954 | validation: 0.0504983859185354]
	TIME [epoch: 9.01 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05732225047370447		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.05732225047370447 | validation: 0.06004093589233235]
	TIME [epoch: 9.02 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057176658392084155		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.057176658392084155 | validation: 0.05087964713251929]
	TIME [epoch: 9.03 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06419476428370385		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.06419476428370385 | validation: 0.04972534706438107]
	TIME [epoch: 9.03 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0600126022566234		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.0600126022566234 | validation: 0.0606498899853658]
	TIME [epoch: 9.01 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477510558492545		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.06477510558492545 | validation: 0.037757416095975285]
	TIME [epoch: 9.01 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05677077659283317		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.05677077659283317 | validation: 0.05124395017005247]
	TIME [epoch: 9.02 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06262979562435536		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.06262979562435536 | validation: 0.054854937518668226]
	TIME [epoch: 9.05 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407385890101709		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.06407385890101709 | validation: 0.0465400849684037]
	TIME [epoch: 9.03 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06107805672853951		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.06107805672853951 | validation: 0.05517149883400352]
	TIME [epoch: 9.02 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062275537225397394		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.062275537225397394 | validation: 0.0563914415001794]
	TIME [epoch: 9.02 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06815836672246102		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.06815836672246102 | validation: 0.05786981528528089]
	TIME [epoch: 9.02 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06078411300596469		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.06078411300596469 | validation: 0.04661542737105402]
	TIME [epoch: 9.03 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057252110939480405		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.057252110939480405 | validation: 0.04325320499663229]
	TIME [epoch: 9.02 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06581271908444532		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.06581271908444532 | validation: 0.051963630526427405]
	TIME [epoch: 9.01 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06241516529054011		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.06241516529054011 | validation: 0.05257612137194406]
	TIME [epoch: 9.01 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062047069195581825		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.062047069195581825 | validation: 0.046731241742153234]
	TIME [epoch: 9.04 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05900086120950905		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.05900086120950905 | validation: 0.049998625798461586]
	TIME [epoch: 9.01 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993949537733878		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.05993949537733878 | validation: 0.06272398150727444]
	TIME [epoch: 9.02 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06222006591558173		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.06222006591558173 | validation: 0.053555958633774194]
	TIME [epoch: 9.01 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060636214269888966		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.060636214269888966 | validation: 0.049827307624238246]
	TIME [epoch: 9.01 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059056663856229964		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.059056663856229964 | validation: 0.042428235867295126]
	TIME [epoch: 9.05 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058810050371516945		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.058810050371516945 | validation: 0.0490152992181979]
	TIME [epoch: 9.03 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05824325313182606		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.05824325313182606 | validation: 0.04524452234238474]
	TIME [epoch: 9.02 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059692480546118844		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.059692480546118844 | validation: 0.04669319697924886]
	TIME [epoch: 9.02 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06644146418744905		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.06644146418744905 | validation: 0.058691183106128586]
	TIME [epoch: 9.02 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05855133660137085		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.05855133660137085 | validation: 0.041263881374444845]
	TIME [epoch: 9.03 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499780507671653		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.06499780507671653 | validation: 0.0506423835719052]
	TIME [epoch: 9.02 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06171896988500793		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.06171896988500793 | validation: 0.054097151990977164]
	TIME [epoch: 9.01 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061086747591172816		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.061086747591172816 | validation: 0.04231957397354212]
	TIME [epoch: 9.02 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0573341427988998		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.0573341427988998 | validation: 0.04602979912381115]
	TIME [epoch: 9.03 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643910501812601		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.0643910501812601 | validation: 0.05945751706795733]
	TIME [epoch: 9.01 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061395800112703736		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.061395800112703736 | validation: 0.04821221803975673]
	TIME [epoch: 9.01 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056728876050070876		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.056728876050070876 | validation: 0.04439201904806791]
	TIME [epoch: 9.02 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05980229075287271		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.05980229075287271 | validation: 0.054313719817556505]
	TIME [epoch: 9.02 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058431922169672766		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.058431922169672766 | validation: 0.05350453068175379]
	TIME [epoch: 9.03 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780249836065219		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.05780249836065219 | validation: 0.046861439796005176]
	TIME [epoch: 9.01 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06121703175363806		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.06121703175363806 | validation: 0.05128436087833456]
	TIME [epoch: 9.01 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662129443815734		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.0662129443815734 | validation: 0.061752325852797336]
	TIME [epoch: 9.01 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06476324803526685		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.06476324803526685 | validation: 0.057722468133107656]
	TIME [epoch: 9.03 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0664668067604404		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0664668067604404 | validation: 0.06161784066907397]
	TIME [epoch: 9.01 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06552092984824284		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.06552092984824284 | validation: 0.05113715770636782]
	TIME [epoch: 9.01 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130658516996688		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.06130658516996688 | validation: 0.05079790246960188]
	TIME [epoch: 9.01 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0621113498029159		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.0621113498029159 | validation: 0.05944613859193382]
	TIME [epoch: 9.01 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525295743065326		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.06525295743065326 | validation: 0.048380842654292266]
	TIME [epoch: 9.04 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06797194111085626		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.06797194111085626 | validation: 0.0685563468456809]
	TIME [epoch: 9.01 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07570134299912266		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.07570134299912266 | validation: 0.05317201432984528]
	TIME [epoch: 9.02 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298098996053179		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.07298098996053179 | validation: 0.06087472992491148]
	TIME [epoch: 9.02 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07777492326403349		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.07777492326403349 | validation: 0.06178291473919824]
	TIME [epoch: 9.03 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06814272270626252		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.06814272270626252 | validation: 0.05634488580486287]
	TIME [epoch: 9.03 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897298186114464		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.06897298186114464 | validation: 0.05450478546149719]
	TIME [epoch: 9.01 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677735248542457		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.0677735248542457 | validation: 0.04431040258061496]
	TIME [epoch: 9.01 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319812876447402		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.06319812876447402 | validation: 0.051225833948741514]
	TIME [epoch: 9.01 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06298765667465209		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.06298765667465209 | validation: 0.0471193362100064]
	TIME [epoch: 9.03 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06243153742672029		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.06243153742672029 | validation: 0.0552718575103284]
	TIME [epoch: 9.02 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831340157339008		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.06831340157339008 | validation: 0.04907369973105144]
	TIME [epoch: 9.01 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06881795636151153		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.06881795636151153 | validation: 0.06678707701006856]
	TIME [epoch: 9.02 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06751703846174013		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.06751703846174013 | validation: 0.07019202537511172]
	TIME [epoch: 9 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0624619705147985		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.0624619705147985 | validation: 0.05019349882183787]
	TIME [epoch: 9.04 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058890996270480535		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.058890996270480535 | validation: 0.05096101753566962]
	TIME [epoch: 9.02 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871920641305782		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.05871920641305782 | validation: 0.05031003925970626]
	TIME [epoch: 9.02 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06224401898691219		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.06224401898691219 | validation: 0.07073465161628613]
	TIME [epoch: 9.02 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07434835846588618		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.07434835846588618 | validation: 0.057680743847401156]
	TIME [epoch: 9.03 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0702318789963905		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.0702318789963905 | validation: 0.05912313730365157]
	TIME [epoch: 9.02 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06055934332462334		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.06055934332462334 | validation: 0.05338799097012831]
	TIME [epoch: 9.02 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440603959299914		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.07440603959299914 | validation: 0.05870725743495274]
	TIME [epoch: 9.01 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672968856951642		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.0672968856951642 | validation: 0.055071706995889584]
	TIME [epoch: 9.02 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062199083097285356		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.062199083097285356 | validation: 0.044440789563325284]
	TIME [epoch: 9.04 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05925207792254879		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.05925207792254879 | validation: 0.04894592509919597]
	TIME [epoch: 9.02 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463225759944757		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.06463225759944757 | validation: 0.05466559680802431]
	TIME [epoch: 9.02 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061044825912220636		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.061044825912220636 | validation: 0.0498174374868192]
	TIME [epoch: 9.01 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087075639666924		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.06087075639666924 | validation: 0.05418958125689417]
	TIME [epoch: 9.01 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062049985087924676		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.062049985087924676 | validation: 0.061677222229829486]
	TIME [epoch: 9.04 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06271926880681492		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.06271926880681492 | validation: 0.05208001143419885]
	TIME [epoch: 9.03 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06192821471157672		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.06192821471157672 | validation: 0.06081323766547539]
	TIME [epoch: 9.03 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062106097151319005		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.062106097151319005 | validation: 0.05166702956764849]
	TIME [epoch: 9.03 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629011339867888		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.06629011339867888 | validation: 0.050509772602015154]
	TIME [epoch: 9.04 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06256754131904022		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.06256754131904022 | validation: 0.04582517384139731]
	TIME [epoch: 9.03 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06498793880123185		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.06498793880123185 | validation: 0.0440051446450287]
	TIME [epoch: 9.01 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06045828541569982		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.06045828541569982 | validation: 0.05443468699293064]
	TIME [epoch: 9.02 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654493639906845		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.0654493639906845 | validation: 0.05545961182524749]
	TIME [epoch: 9.02 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564798228022235		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.06564798228022235 | validation: 0.06181393853726716]
	TIME [epoch: 9.03 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481654700552626		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.06481654700552626 | validation: 0.046608199656138494]
	TIME [epoch: 9.02 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06134907275774291		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.06134907275774291 | validation: 0.05197446930884761]
	TIME [epoch: 9.02 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058400608228651875		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.058400608228651875 | validation: 0.052569258692530124]
	TIME [epoch: 9.03 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665920547474429		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.0665920547474429 | validation: 0.05877593508933381]
	TIME [epoch: 9.03 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07226394375211145		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.07226394375211145 | validation: 0.07726960269940435]
	TIME [epoch: 9.04 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07197764505943131		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.07197764505943131 | validation: 0.057461350503076755]
	TIME [epoch: 9.04 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056427282892723585		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.056427282892723585 | validation: 0.05530665919030242]
	TIME [epoch: 9.02 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780425695971121		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.05780425695971121 | validation: 0.0393909098300534]
	TIME [epoch: 9.02 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05764285816130567		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.05764285816130567 | validation: 0.057854890200973806]
	TIME [epoch: 9.03 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629275974741084		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.0629275974741084 | validation: 0.04053611062877846]
	TIME [epoch: 9.01 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06094792073549473		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.06094792073549473 | validation: 0.05964903664808018]
	TIME [epoch: 9.01 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062218311563300724		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.062218311563300724 | validation: 0.05392225304264635]
	TIME [epoch: 9.01 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719868308737857		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.0719868308737857 | validation: 0.04477915506807585]
	TIME [epoch: 9.01 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057482351206924576		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.057482351206924576 | validation: 0.04359372669136435]
	TIME [epoch: 9.05 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05589618671338453		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.05589618671338453 | validation: 0.049350501567192485]
	TIME [epoch: 9.01 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06131692577848778		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.06131692577848778 | validation: 0.03481821521777778]
	TIME [epoch: 9.01 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062499980262690616		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.062499980262690616 | validation: 0.04473747748475686]
	TIME [epoch: 9.02 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059158804069518366		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.059158804069518366 | validation: 0.04899955943066947]
	TIME [epoch: 9.04 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058624325107786604		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.058624325107786604 | validation: 0.046476670119073735]
	TIME [epoch: 9.02 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800631803577831		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.05800631803577831 | validation: 0.05131257595310589]
	TIME [epoch: 9.03 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060491821128212275		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.060491821128212275 | validation: 0.04374481580155922]
	TIME [epoch: 9.03 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05753413218940047		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.05753413218940047 | validation: 0.05701795679518199]
	TIME [epoch: 9.03 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0615091629722049		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.0615091629722049 | validation: 0.05922051852352219]
	TIME [epoch: 9.04 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06607000003268307		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.06607000003268307 | validation: 0.05843162571590181]
	TIME [epoch: 9.01 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06194178500740237		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.06194178500740237 | validation: 0.052094602095609066]
	TIME [epoch: 9.03 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06167780046992276		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.06167780046992276 | validation: 0.05526147498729275]
	TIME [epoch: 9.02 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05275409547600416		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.05275409547600416 | validation: 0.055290249335547145]
	TIME [epoch: 9.03 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054308887824710314		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.054308887824710314 | validation: 0.060020857523082144]
	TIME [epoch: 9.03 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06322533772739246		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.06322533772739246 | validation: 0.05496089243892243]
	TIME [epoch: 9.02 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245370343486302		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.06245370343486302 | validation: 0.051682720285491965]
	TIME [epoch: 9.01 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770355155808122		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.06770355155808122 | validation: 0.061610260987654264]
	TIME [epoch: 9.02 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06715319434481518		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.06715319434481518 | validation: 0.051525778987716195]
	TIME [epoch: 9.03 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0568908682923747		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.0568908682923747 | validation: 0.05582293183189817]
	TIME [epoch: 9.03 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061137147663977785		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.061137147663977785 | validation: 0.030518158249419242]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240219_183145/states/model_tr_study3_1839.pth
	Model improved!!!
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0560974902248005		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.0560974902248005 | validation: 0.054540122472804375]
	TIME [epoch: 9 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055246293701212014		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.055246293701212014 | validation: 0.03737759499434628]
	TIME [epoch: 9.02 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055669318208672394		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.055669318208672394 | validation: 0.04995739113251635]
	TIME [epoch: 9.01 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05894250264918768		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.05894250264918768 | validation: 0.05613823560687156]
	TIME [epoch: 9.01 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059988289886019695		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.059988289886019695 | validation: 0.04068748746052979]
	TIME [epoch: 9.01 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05521210732670355		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.05521210732670355 | validation: 0.04620486863714542]
	TIME [epoch: 9.01 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06343737758831305		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.06343737758831305 | validation: 0.044383681735123005]
	TIME [epoch: 9.03 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05977030061187573		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.05977030061187573 | validation: 0.054176551966339095]
	TIME [epoch: 9.01 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057949577207961976		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.057949577207961976 | validation: 0.0528370176271134]
	TIME [epoch: 9.02 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059897615559430295		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.059897615559430295 | validation: 0.0507241209338809]
	TIME [epoch: 9.02 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993183845788237		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.05993183845788237 | validation: 0.040397342148676005]
	TIME [epoch: 9.02 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05186803663394789		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.05186803663394789 | validation: 0.054136350895823845]
	TIME [epoch: 9.03 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05357436393355823		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.05357436393355823 | validation: 0.06210945615556862]
	TIME [epoch: 9.02 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06171725930927456		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.06171725930927456 | validation: 0.060909512900899944]
	TIME [epoch: 9.01 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0605724406715759		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.0605724406715759 | validation: 0.04366900147378623]
	TIME [epoch: 9.01 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05212613232660388		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.05212613232660388 | validation: 0.049385473553576115]
	TIME [epoch: 9.03 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05486971275669561		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.05486971275669561 | validation: 0.041289900768628346]
	TIME [epoch: 9.02 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059587393304090276		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.059587393304090276 | validation: 0.057772145727613355]
	TIME [epoch: 9.01 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06154468540547518		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.06154468540547518 | validation: 0.052508263795736004]
	TIME [epoch: 9.02 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565035543685146		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.0565035543685146 | validation: 0.04427376932405619]
	TIME [epoch: 9.02 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057262345818064574		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.057262345818064574 | validation: 0.05247112290220599]
	TIME [epoch: 9.03 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05322482240357573		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.05322482240357573 | validation: 0.04677467971878141]
	TIME [epoch: 9.01 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05608641193726149		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.05608641193726149 | validation: 0.05198410819278356]
	TIME [epoch: 9.01 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06109956902756353		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.06109956902756353 | validation: 0.046417459543630926]
	TIME [epoch: 9.02 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05319944245712702		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.05319944245712702 | validation: 0.041796073070984575]
	TIME [epoch: 9.02 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056402517147329856		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.056402517147329856 | validation: 0.050087717625039316]
	TIME [epoch: 9.05 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06510053301284909		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.06510053301284909 | validation: 0.05656769471984041]
	TIME [epoch: 9.01 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06485479956063174		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.06485479956063174 | validation: 0.055593411560036304]
	TIME [epoch: 9.01 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06571440271397265		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.06571440271397265 | validation: 0.04785262352359575]
	TIME [epoch: 9.01 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646088795767289		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.0646088795767289 | validation: 0.04811113479624692]
	TIME [epoch: 9.03 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06454635891107663		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.06454635891107663 | validation: 0.04851916887092017]
	TIME [epoch: 9.02 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724798708084448		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.06724798708084448 | validation: 0.0392624703191505]
	TIME [epoch: 9.01 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06212793773198895		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.06212793773198895 | validation: 0.05594592953071454]
	TIME [epoch: 9.01 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05788855028417532		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.05788855028417532 | validation: 0.05020878301006689]
	TIME [epoch: 9.01 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054752954890696745		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.054752954890696745 | validation: 0.05943534455469196]
	TIME [epoch: 9.03 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05188177765538482		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.05188177765538482 | validation: 0.03973854646450989]
	TIME [epoch: 9.01 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05138695664447092		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.05138695664447092 | validation: 0.04288175852680191]
	TIME [epoch: 9.02 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058016858914390665		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.058016858914390665 | validation: 0.04886908083679628]
	TIME [epoch: 9.01 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057158406426868036		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.057158406426868036 | validation: 0.042916444559174594]
	TIME [epoch: 9.04 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05707135677932616		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.05707135677932616 | validation: 0.05556055311521385]
	TIME [epoch: 9.02 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059764617123883104		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.059764617123883104 | validation: 0.05376103860091218]
	TIME [epoch: 9.02 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056023090471578676		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.056023090471578676 | validation: 0.045461203291325344]
	TIME [epoch: 9.02 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0574193485905241		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.0574193485905241 | validation: 0.05545316510424283]
	TIME [epoch: 9.01 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061604066251760514		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.061604066251760514 | validation: 0.04957102900989159]
	TIME [epoch: 9.03 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058632550131534865		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.058632550131534865 | validation: 0.056287596613470235]
	TIME [epoch: 9.01 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053359465443136855		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.053359465443136855 | validation: 0.05112190140791529]
	TIME [epoch: 9.01 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0574197962191214		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.0574197962191214 | validation: 0.0520590461165663]
	TIME [epoch: 9.01 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054938405861474485		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.054938405861474485 | validation: 0.045599565515372885]
	TIME [epoch: 9 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576637746863675		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.0576637746863675 | validation: 0.051380692430363056]
	TIME [epoch: 9.03 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05058210467066112		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.05058210467066112 | validation: 0.04659711830834799]
	TIME [epoch: 9.02 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04873992283797385		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.04873992283797385 | validation: 0.04160234912204947]
	TIME [epoch: 9.02 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06038565799636616		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.06038565799636616 | validation: 0.0484240521071774]
	TIME [epoch: 9.02 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06447442669683416		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.06447442669683416 | validation: 0.06385425642171702]
	TIME [epoch: 9.02 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07241551906064073		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.07241551906064073 | validation: 0.05216142327301128]
	TIME [epoch: 9.01 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0604275579096535		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.0604275579096535 | validation: 0.052027970666317355]
	TIME [epoch: 9.01 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05786632881123591		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.05786632881123591 | validation: 0.045481929558493034]
	TIME [epoch: 9 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055767798078161235		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.055767798078161235 | validation: 0.04819065093188419]
	TIME [epoch: 9.01 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05536598263644622		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.05536598263644622 | validation: 0.05539720037774426]
	TIME [epoch: 9.02 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057180022361149385		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.057180022361149385 | validation: 0.049364546616060864]
	TIME [epoch: 9.01 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0527652444391609		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.0527652444391609 | validation: 0.05361906521572915]
	TIME [epoch: 9 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061353479939883396		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.061353479939883396 | validation: 0.04375641595695741]
	TIME [epoch: 9.01 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051805066039292226		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.051805066039292226 | validation: 0.04672464065744528]
	TIME [epoch: 9.02 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05621335002995698		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.05621335002995698 | validation: 0.0449445512736806]
	TIME [epoch: 9.02 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06027193508591473		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.06027193508591473 | validation: 0.06943631615423455]
	TIME [epoch: 9.01 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300948866129417		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.07300948866129417 | validation: 0.05039860782419357]
	TIME [epoch: 9.01 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05537120011579879		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.05537120011579879 | validation: 0.04918492386610205]
	TIME [epoch: 9 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06019122174493437		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.06019122174493437 | validation: 0.054034983885579924]
	TIME [epoch: 9.03 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052852516413752014		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.052852516413752014 | validation: 0.04534277284719647]
	TIME [epoch: 9.01 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055792656790082384		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.055792656790082384 | validation: 0.051959323990509565]
	TIME [epoch: 9.01 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05462435404671667		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.05462435404671667 | validation: 0.05560171851291845]
	TIME [epoch: 9 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05303636875028659		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.05303636875028659 | validation: 0.06426456166436552]
	TIME [epoch: 9.01 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059623375029733104		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.059623375029733104 | validation: 0.05271368803099732]
	TIME [epoch: 9.04 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05914763030011886		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.05914763030011886 | validation: 0.041201113844293015]
	TIME [epoch: 9.01 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05397139909502824		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.05397139909502824 | validation: 0.051209414614167253]
	TIME [epoch: 9.01 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05873634402875829		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.05873634402875829 | validation: 0.06085577649381516]
	TIME [epoch: 9.01 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05950246278860331		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.05950246278860331 | validation: 0.05175191891053439]
	TIME [epoch: 9.03 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05114726999114545		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.05114726999114545 | validation: 0.05077368351623189]
	TIME [epoch: 9.02 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059461020402467604		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.059461020402467604 | validation: 0.05621302604999187]
	TIME [epoch: 9.01 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061541592868578444		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.061541592868578444 | validation: 0.051782672032716165]
	TIME [epoch: 9.01 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06689458334312846		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.06689458334312846 | validation: 0.0698440582854446]
	TIME [epoch: 9.01 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05884674958790842		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.05884674958790842 | validation: 0.05278637681450983]
	TIME [epoch: 9.03 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06099647369808299		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.06099647369808299 | validation: 0.04421648377375094]
	TIME [epoch: 9.01 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06089768909499116		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.06089768909499116 | validation: 0.05435457669488607]
	TIME [epoch: 9.01 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054230829790586056		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.054230829790586056 | validation: 0.04801323589344404]
	TIME [epoch: 9.01 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053435443304815665		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.053435443304815665 | validation: 0.04481330996994366]
	TIME [epoch: 9.02 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05396483227160311		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.05396483227160311 | validation: 0.04524659765796207]
	TIME [epoch: 9.02 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05557690412658828		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.05557690412658828 | validation: 0.04624677965710598]
	TIME [epoch: 9.01 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056444725362102835		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.056444725362102835 | validation: 0.05079927085875441]
	TIME [epoch: 9.01 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05582703557791816		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.05582703557791816 | validation: 0.04298564814105098]
	TIME [epoch: 9 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061662135170893126		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.061662135170893126 | validation: 0.05975170766115041]
	TIME [epoch: 9.04 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270615884008665		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.06270615884008665 | validation: 0.05009730427037755]
	TIME [epoch: 9.02 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054261007076503054		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.054261007076503054 | validation: 0.048682640548589395]
	TIME [epoch: 9.02 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0468645270335661		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.0468645270335661 | validation: 0.057502200873105605]
	TIME [epoch: 9.01 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05370136100989821		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.05370136100989821 | validation: 0.04156385611974507]
	TIME [epoch: 9.01 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0546274785781834		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.0546274785781834 | validation: 0.04204091685127693]
	TIME [epoch: 9.04 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05262146282622372		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.05262146282622372 | validation: 0.04778282862188342]
	TIME [epoch: 9.01 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05751995585992884		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.05751995585992884 | validation: 0.06402191074567329]
	TIME [epoch: 9.01 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130588629413005		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.06130588629413005 | validation: 0.06280064360773975]
	TIME [epoch: 9.01 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06137142007965514		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.06137142007965514 | validation: 0.04340635112859555]
	TIME [epoch: 9.02 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0583364675525493		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.0583364675525493 | validation: 0.04926890448702804]
	TIME [epoch: 9.02 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05798050152353199		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.05798050152353199 | validation: 0.048132550576679214]
	TIME [epoch: 9 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05361720426940496		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.05361720426940496 | validation: 0.05116221463482243]
	TIME [epoch: 9.01 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061186331199813815		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.061186331199813815 | validation: 0.05235179298467244]
	TIME [epoch: 9.01 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06119704177334676		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.06119704177334676 | validation: 0.05740951684775437]
	TIME [epoch: 9.04 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05696312338773042		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.05696312338773042 | validation: 0.05760179218134322]
	TIME [epoch: 9.02 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05997304781766384		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.05997304781766384 | validation: 0.05617765172302998]
	TIME [epoch: 9.02 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05458108662963786		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.05458108662963786 | validation: 0.05414959906293228]
	TIME [epoch: 9.01 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04882863471728387		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.04882863471728387 | validation: 0.03322381245870837]
	TIME [epoch: 9.02 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056777444178882516		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.056777444178882516 | validation: 0.0551363306410701]
	TIME [epoch: 9.01 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056178384403387883		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.056178384403387883 | validation: 0.055074582558513586]
	TIME [epoch: 9.01 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056108968238650844		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.056108968238650844 | validation: 0.0483975061635704]
	TIME [epoch: 9.02 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059057018318436384		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.059057018318436384 | validation: 0.06408227929457952]
	TIME [epoch: 9 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05961872825535065		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.05961872825535065 | validation: 0.04732920129184051]
	TIME [epoch: 9.02 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05776725767325439		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.05776725767325439 | validation: 0.049868690273835295]
	TIME [epoch: 9 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06237715546624676		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.06237715546624676 | validation: 0.04548136997072054]
	TIME [epoch: 9 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205708089817086		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.06205708089817086 | validation: 0.049849749895136616]
	TIME [epoch: 9.01 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051995876783684926		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.051995876783684926 | validation: 0.04787144847343795]
	TIME [epoch: 9.01 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04937283760617829		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.04937283760617829 | validation: 0.039904529820627394]
	TIME [epoch: 9.04 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05246315834020521		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.05246315834020521 | validation: 0.05545304904163818]
	TIME [epoch: 9.01 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06131132344606751		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.06131132344606751 | validation: 0.03992363032421061]
	TIME [epoch: 9.01 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056939847381293984		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.056939847381293984 | validation: 0.044475761990508816]
	TIME [epoch: 9.01 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062441470311126825		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.062441470311126825 | validation: 0.05463480207249971]
	TIME [epoch: 9.02 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061743564598153576		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.061743564598153576 | validation: 0.04985926956104773]
	TIME [epoch: 9.02 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05106284309670135		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.05106284309670135 | validation: 0.042253094435556145]
	TIME [epoch: 9.01 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05155531430745221		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.05155531430745221 | validation: 0.05736347404426963]
	TIME [epoch: 9 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05889455759538341		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.05889455759538341 | validation: 0.05672737772830092]
	TIME [epoch: 9.01 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052161198952583435		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.052161198952583435 | validation: 0.05173980918925505]
	TIME [epoch: 9.03 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06367158201358827		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.06367158201358827 | validation: 0.045642001171669895]
	TIME [epoch: 9.01 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059977205207053866		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.059977205207053866 | validation: 0.05186418476635469]
	TIME [epoch: 9 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06056269963200458		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.06056269963200458 | validation: 0.05992831601562963]
	TIME [epoch: 9.01 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06739447603600549		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.06739447603600549 | validation: 0.05582452134952575]
	TIME [epoch: 9 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05648997416219774		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.05648997416219774 | validation: 0.0529671281523037]
	TIME [epoch: 9.02 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056049754591336175		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.056049754591336175 | validation: 0.04950925153133827]
	TIME [epoch: 9 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05512193476183488		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.05512193476183488 | validation: 0.04142535920072769]
	TIME [epoch: 9 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05554429659494253		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.05554429659494253 | validation: 0.0563411212657432]
	TIME [epoch: 9.01 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05488511988166957		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.05488511988166957 | validation: 0.05004650138976098]
	TIME [epoch: 9.03 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05501082981059311		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.05501082981059311 | validation: 0.04849003059026165]
	TIME [epoch: 9.01 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056669904505258384		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.056669904505258384 | validation: 0.04994462435561148]
	TIME [epoch: 9 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06048032062666571		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.06048032062666571 | validation: 0.05623384907929815]
	TIME [epoch: 9 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06462121309279159		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.06462121309279159 | validation: 0.051831286202767723]
	TIME [epoch: 9 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053782195260168066		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.053782195260168066 | validation: 0.04397255047139125]
	TIME [epoch: 9.02 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05687148319064084		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.05687148319064084 | validation: 0.045656219166939196]
	TIME [epoch: 9 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060057479696848735		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.060057479696848735 | validation: 0.05242606327583385]
	TIME [epoch: 9.01 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054600455642344656		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.054600455642344656 | validation: 0.04291061293037132]
	TIME [epoch: 9 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833209730104687		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.05833209730104687 | validation: 0.044556299058901384]
	TIME [epoch: 9.03 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058007294723526115		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.058007294723526115 | validation: 0.039792463121111385]
	TIME [epoch: 9.02 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057665494928075337		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.057665494928075337 | validation: 0.04900606899337418]
	TIME [epoch: 9.01 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05779700027544675		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.05779700027544675 | validation: 0.045366522371411616]
	TIME [epoch: 9.01 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05575549268600892		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.05575549268600892 | validation: 0.044229018096040955]
	TIME [epoch: 9 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04927983224352904		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.04927983224352904 | validation: 0.042799197097481236]
	TIME [epoch: 9.03 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054342595689845674		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.054342595689845674 | validation: 0.04756099511641995]
	TIME [epoch: 9.01 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0555432834919108		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.0555432834919108 | validation: 0.05230228223032536]
	TIME [epoch: 9 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05598171087166002		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.05598171087166002 | validation: 0.05027986017369587]
	TIME [epoch: 9 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05258588069754394		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.05258588069754394 | validation: 0.05611169777292878]
	TIME [epoch: 9 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06084017991583747		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.06084017991583747 | validation: 0.06104827452094938]
	TIME [epoch: 9.03 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853276213481619		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.05853276213481619 | validation: 0.05607821782472892]
	TIME [epoch: 9.01 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05909131211825884		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.05909131211825884 | validation: 0.060023977653936494]
	TIME [epoch: 9.02 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05653200141699164		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.05653200141699164 | validation: 0.052024659702287424]
	TIME [epoch: 9.01 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058744985067597025		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.058744985067597025 | validation: 0.05115280265325954]
	TIME [epoch: 9.03 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06309544224083367		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.06309544224083367 | validation: 0.05003311880115117]
	TIME [epoch: 9.01 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056199892406039766		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.056199892406039766 | validation: 0.055547382138225854]
	TIME [epoch: 9 sec]
Finished training in 18173.682 seconds.
