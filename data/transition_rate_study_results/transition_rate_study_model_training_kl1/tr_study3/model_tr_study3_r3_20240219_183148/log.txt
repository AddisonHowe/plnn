Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 688115669

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.396443988503956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.396443988503956 | validation: 8.425051267304042]
	TIME [epoch: 53.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.126881507161311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.126881507161311 | validation: 7.739820394304749]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.097356873620877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.097356873620877 | validation: 7.735585099236722]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.496809571448837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.496809571448837 | validation: 6.480558381608576]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.828207550752602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.828207550752602 | validation: 5.618520520053634]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.336878638102407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.336878638102407 | validation: 5.880387096910351]
	TIME [epoch: 8.62 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.330372348407646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.330372348407646 | validation: 5.846711652327057]
	TIME [epoch: 8.59 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.043614020339304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.043614020339304 | validation: 5.09573318567473]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.749065926349914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.749065926349914 | validation: 4.615903650248498]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.64723627324005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.64723627324005 | validation: 5.662414255599792]
	TIME [epoch: 8.63 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.588956885507238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.588956885507238 | validation: 5.272447587769403]
	TIME [epoch: 8.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.399920736842444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.399920736842444 | validation: 4.886438546277246]
	TIME [epoch: 8.62 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.405047895364766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.405047895364766 | validation: 4.740136478570696]
	TIME [epoch: 8.59 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.351515049226666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.351515049226666 | validation: 4.280141957120993]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.937488027986041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.937488027986041 | validation: 5.203345821517669]
	TIME [epoch: 8.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.991637144558073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.991637144558073 | validation: 4.743686882993408]
	TIME [epoch: 8.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.481200523443021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.481200523443021 | validation: 4.242560154019498]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.726339546235789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.726339546235789 | validation: 4.516873102048605]
	TIME [epoch: 8.63 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.765748171163464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.765748171163464 | validation: 4.171227693360653]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.498760534365427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.498760534365427 | validation: 4.316351285738596]
	TIME [epoch: 8.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.481647792817407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.481647792817407 | validation: 3.575337847959786]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.550236770181296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.550236770181296 | validation: 3.575557255691105]
	TIME [epoch: 8.61 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.534287616055009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.534287616055009 | validation: 3.5295720737283665]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.32627174219026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.32627174219026 | validation: 3.884268301831081]
	TIME [epoch: 8.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.247642663185027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.247642663185027 | validation: 4.629824480869961]
	TIME [epoch: 8.59 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.588079098762873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.588079098762873 | validation: 3.320318576257186]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.192738951244096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.192738951244096 | validation: 3.372849580944303]
	TIME [epoch: 8.59 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.22016802856838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.22016802856838 | validation: 4.411154201290845]
	TIME [epoch: 8.59 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.222413015570313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.222413015570313 | validation: 3.1790010856609277]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.390687619379928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.390687619379928 | validation: 4.521468595305578]
	TIME [epoch: 8.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.723440505962964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.723440505962964 | validation: 4.040407269193682]
	TIME [epoch: 8.59 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.202295284203222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.202295284203222 | validation: 3.229291404871387]
	TIME [epoch: 8.59 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.035639494240222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.035639494240222 | validation: 3.3862441445378066]
	TIME [epoch: 8.58 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.976489476311291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.976489476311291 | validation: 3.9785010178495357]
	TIME [epoch: 8.61 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.118246948953997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.118246948953997 | validation: 3.4094484346989837]
	TIME [epoch: 8.58 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.111697526826645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.111697526826645 | validation: 3.5907134752365906]
	TIME [epoch: 8.58 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.049194302747692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049194302747692 | validation: 3.4562456485497943]
	TIME [epoch: 8.59 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.975882579977155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.975882579977155 | validation: 3.1536408893531105]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.009662463334871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.009662463334871 | validation: 3.446979550269993]
	TIME [epoch: 8.59 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8859447415834287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8859447415834287 | validation: 3.2116433791981]
	TIME [epoch: 8.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.982799778718081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.982799778718081 | validation: 3.066711357606616]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.79823819313808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.79823819313808 | validation: 3.026923065978357]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.640350289525867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.640350289525867 | validation: 3.10826877877077]
	TIME [epoch: 8.61 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.693177756508181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.693177756508181 | validation: 2.841138030986215]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.505514782242276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.505514782242276 | validation: 2.940701852585227]
	TIME [epoch: 8.61 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.995344535433381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.995344535433381 | validation: 1.9828987822558628]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1160995489889314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1160995489889314 | validation: 2.580169321163985]
	TIME [epoch: 8.61 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1199638095040845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1199638095040845 | validation: 5.289364871135817]
	TIME [epoch: 8.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5580928526333633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5580928526333633 | validation: 1.563740089857279]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0243357140720617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0243357140720617 | validation: 1.6201696391163345]
	TIME [epoch: 8.62 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8587423122813096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8587423122813096 | validation: 2.268950341724254]
	TIME [epoch: 8.59 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.37922006340877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.37922006340877 | validation: 1.9728052099676092]
	TIME [epoch: 8.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7936296087627686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7936296087627686 | validation: 1.473221460524594]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.804624865368472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.804624865368472 | validation: 1.9866561516206565]
	TIME [epoch: 8.63 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9699274747209015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9699274747209015 | validation: 2.225838633138016]
	TIME [epoch: 8.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0235887074106023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0235887074106023 | validation: 1.5294723044773892]
	TIME [epoch: 8.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7070772005372468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7070772005372468 | validation: 2.534777323305935]
	TIME [epoch: 8.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.97254985883863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.97254985883863 | validation: 1.5109487058704787]
	TIME [epoch: 8.62 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6456644875339859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6456644875339859 | validation: 1.3386919867618048]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6210119144929909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6210119144929909 | validation: 1.4040744103723375]
	TIME [epoch: 8.59 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7602500661558267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7602500661558267 | validation: 1.6543520381475836]
	TIME [epoch: 8.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.563182595884684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.563182595884684 | validation: 1.3405203338810296]
	TIME [epoch: 8.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4486701356347904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4486701356347904 | validation: 1.5709658114284986]
	TIME [epoch: 8.59 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5227482905993217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5227482905993217 | validation: 2.368567457741662]
	TIME [epoch: 8.58 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5149033710340323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5149033710340323 | validation: 0.9503279525913997]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.690263347711009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.690263347711009 | validation: 1.2099878684274519]
	TIME [epoch: 8.61 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4215024570897064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4215024570897064 | validation: 1.7082349828408763]
	TIME [epoch: 8.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2989341881998953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2989341881998953 | validation: 1.2378407720390534]
	TIME [epoch: 8.59 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4205388586363994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4205388586363994 | validation: 1.753512382794269]
	TIME [epoch: 8.59 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4351293650601522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4351293650601522 | validation: 1.5678902243088848]
	TIME [epoch: 8.61 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.53139791273166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.53139791273166 | validation: 1.6733256373050982]
	TIME [epoch: 8.59 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.453415452663164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.453415452663164 | validation: 2.7738602880762633]
	TIME [epoch: 8.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6038339002307027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6038339002307027 | validation: 3.3003699139133564]
	TIME [epoch: 8.57 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.083011237600184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.083011237600184 | validation: 2.38758463284596]
	TIME [epoch: 8.61 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.49928257680675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.49928257680675 | validation: 1.1509366490209922]
	TIME [epoch: 8.57 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.931803160474539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.931803160474539 | validation: 5.836550037736904]
	TIME [epoch: 8.58 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.333663551363765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.333663551363765 | validation: 1.2550219165616503]
	TIME [epoch: 8.58 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2962406793637284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2962406793637284 | validation: 1.1633736159728358]
	TIME [epoch: 8.61 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2788934289439746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2788934289439746 | validation: 0.9028553745617338]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1380449512720403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1380449512720403 | validation: 0.715823574586408]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.282321097729408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.282321097729408 | validation: 0.8562848577810336]
	TIME [epoch: 8.61 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8351970397921533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8351970397921533 | validation: 2.4834557618058444]
	TIME [epoch: 8.63 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.926396178929058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.926396178929058 | validation: 1.7722318022452281]
	TIME [epoch: 8.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.390410120716208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.390410120716208 | validation: 1.0038032765164735]
	TIME [epoch: 8.61 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1787396855376764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1787396855376764 | validation: 1.7030058056133544]
	TIME [epoch: 8.61 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2962891892000177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2962891892000177 | validation: 1.3552409947681467]
	TIME [epoch: 8.63 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6172874704061972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6172874704061972 | validation: 1.6962876067135246]
	TIME [epoch: 8.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2296711502051243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2296711502051243 | validation: 1.1892548153465308]
	TIME [epoch: 8.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4662755915048984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4662755915048984 | validation: 1.3937795825635924]
	TIME [epoch: 8.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5931254517846267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5931254517846267 | validation: 0.7789630845393409]
	TIME [epoch: 8.63 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3531845251934553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3531845251934553 | validation: 0.859841089178567]
	TIME [epoch: 8.61 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.169199134290296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.169199134290296 | validation: 2.574206007832993]
	TIME [epoch: 8.61 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6536133697231423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6536133697231423 | validation: 1.6177304596869564]
	TIME [epoch: 8.61 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2671933190057585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2671933190057585 | validation: 1.6023882620242171]
	TIME [epoch: 8.62 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3762943313636522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3762943313636522 | validation: 1.0174850909241306]
	TIME [epoch: 8.61 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.202432057000146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.202432057000146 | validation: 1.020205645717918]
	TIME [epoch: 8.61 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.184612355199973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.184612355199973 | validation: 1.06658384149199]
	TIME [epoch: 8.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1897817469401946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1897817469401946 | validation: 0.6203842809351116]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1560015413531577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1560015413531577 | validation: 0.9053993419744645]
	TIME [epoch: 8.61 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1857200591652295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1857200591652295 | validation: 2.842714447686057]
	TIME [epoch: 8.61 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8322098281321773		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 1.8322098281321773 | validation: 1.1307133179027047]
	TIME [epoch: 8.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1213440597771873		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.1213440597771873 | validation: 1.1250405765421965]
	TIME [epoch: 8.63 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3592617316076805		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 1.3592617316076805 | validation: 0.8484769716677006]
	TIME [epoch: 8.61 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3610169281343605		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.3610169281343605 | validation: 1.470534190597197]
	TIME [epoch: 8.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2003560406597826		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 1.2003560406597826 | validation: 0.8791425976502356]
	TIME [epoch: 8.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0059726429857123		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.0059726429857123 | validation: 1.3754404556126345]
	TIME [epoch: 8.63 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0180316167023051		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 1.0180316167023051 | validation: 1.2127628519192477]
	TIME [epoch: 8.61 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9747933065488497		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.9747933065488497 | validation: 0.9680665584111591]
	TIME [epoch: 8.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9403560955447701		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.9403560955447701 | validation: 0.5327890147642234]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0295900093626933		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.0295900093626933 | validation: 1.1318820491274733]
	TIME [epoch: 8.63 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8495176407680967		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.8495176407680967 | validation: 0.6718374108749171]
	TIME [epoch: 8.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.03323705281105		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.03323705281105 | validation: 1.8031891217458489]
	TIME [epoch: 8.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0265336480638898		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 1.0265336480638898 | validation: 1.0638850672078246]
	TIME [epoch: 8.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1760029495723954		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.1760029495723954 | validation: 1.4985807526859505]
	TIME [epoch: 8.62 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3242339955897928		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 1.3242339955897928 | validation: 2.1197493978848314]
	TIME [epoch: 8.61 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3691537325923246		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.3691537325923246 | validation: 0.7062333197014345]
	TIME [epoch: 8.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8580600276109083		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.8580600276109083 | validation: 0.687711214661292]
	TIME [epoch: 8.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.348142862909161		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.348142862909161 | validation: 0.6571115412178723]
	TIME [epoch: 8.62 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8966946019937787		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.8966946019937787 | validation: 0.719692234704455]
	TIME [epoch: 8.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8704526674711243		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.8704526674711243 | validation: 1.1493829391905896]
	TIME [epoch: 8.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3159076256669562		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 1.3159076256669562 | validation: 0.7174450044171591]
	TIME [epoch: 8.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.91420134628113		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.91420134628113 | validation: 0.9465787382014413]
	TIME [epoch: 8.63 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8570800563302962		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.8570800563302962 | validation: 0.7305683407552754]
	TIME [epoch: 8.61 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8770124734289935		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.8770124734289935 | validation: 0.6277387456854373]
	TIME [epoch: 8.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9373921167652395		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.9373921167652395 | validation: 0.5224431989072353]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.96336941018817		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.96336941018817 | validation: 0.8229656693412695]
	TIME [epoch: 8.62 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.007005254793839		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 1.007005254793839 | validation: 0.7475332290097665]
	TIME [epoch: 8.59 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7508724474228649		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.7508724474228649 | validation: 0.6725915180586887]
	TIME [epoch: 8.59 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7925047398402222		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.7925047398402222 | validation: 0.46950497290796045]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8338827702057289		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.8338827702057289 | validation: 0.43174281310421037]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6487029545333185		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.6487029545333185 | validation: 1.145372930523403]
	TIME [epoch: 8.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7903321902363928		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.7903321902363928 | validation: 0.5227262080889227]
	TIME [epoch: 8.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.82718099151235		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.82718099151235 | validation: 0.5794272553326242]
	TIME [epoch: 8.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.007458554233293		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.007458554233293 | validation: 0.6362924281025341]
	TIME [epoch: 8.62 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9322559056263009		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.9322559056263009 | validation: 0.8279019342513703]
	TIME [epoch: 8.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8365219381668982		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.8365219381668982 | validation: 0.48517997212924835]
	TIME [epoch: 8.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7743120680273569		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.7743120680273569 | validation: 1.3117709980416863]
	TIME [epoch: 8.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8165216032114169		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.8165216032114169 | validation: 0.8028329074822856]
	TIME [epoch: 8.62 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.773530940577382		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.773530940577382 | validation: 1.0156087809651855]
	TIME [epoch: 8.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9787090005557427		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.9787090005557427 | validation: 0.503968212199845]
	TIME [epoch: 8.59 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7290768246893728		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.7290768246893728 | validation: 0.6357781313585766]
	TIME [epoch: 8.59 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.836215585413032		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.836215585413032 | validation: 0.5840690255285071]
	TIME [epoch: 8.62 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433124144078108		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.6433124144078108 | validation: 0.8121022464733241]
	TIME [epoch: 8.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7691673945256448		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.7691673945256448 | validation: 0.5829320660967926]
	TIME [epoch: 8.59 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447698696437239		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.7447698696437239 | validation: 0.851872590754847]
	TIME [epoch: 8.59 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7436653389024245		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.7436653389024245 | validation: 0.5764060933015464]
	TIME [epoch: 8.62 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9419444125824368		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.9419444125824368 | validation: 2.0800821709884776]
	TIME [epoch: 8.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9053156706684152		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.9053156706684152 | validation: 0.5403841724303018]
	TIME [epoch: 8.59 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.696782117860504		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.696782117860504 | validation: 0.6342886482313093]
	TIME [epoch: 8.59 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7151396653443298		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.7151396653443298 | validation: 0.6596670405743412]
	TIME [epoch: 8.62 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8158026615561621		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.8158026615561621 | validation: 0.36149069945991863]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.639381143245785		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.639381143245785 | validation: 0.4767807341750545]
	TIME [epoch: 8.59 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9078780150357482		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.9078780150357482 | validation: 1.7353970502632494]
	TIME [epoch: 8.58 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7530891599820756		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.7530891599820756 | validation: 0.804802954145287]
	TIME [epoch: 8.61 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6753288985202759		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.6753288985202759 | validation: 0.5577960943195724]
	TIME [epoch: 8.59 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5986213877104041		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.5986213877104041 | validation: 0.7986089994633905]
	TIME [epoch: 8.59 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6259575286021408		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.6259575286021408 | validation: 0.45090162468794653]
	TIME [epoch: 8.57 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7695967753700078		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.7695967753700078 | validation: 1.061480425903317]
	TIME [epoch: 8.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1314228673137743		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 1.1314228673137743 | validation: 0.9016281685740885]
	TIME [epoch: 8.59 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6664017441338981		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.6664017441338981 | validation: 0.5473883607568979]
	TIME [epoch: 8.58 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7658456932198817		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.7658456932198817 | validation: 0.971637966095576]
	TIME [epoch: 8.59 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8559475893857581		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.8559475893857581 | validation: 0.4219371300650455]
	TIME [epoch: 8.59 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6970223793727333		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.6970223793727333 | validation: 0.7890508488215393]
	TIME [epoch: 8.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5833653650296158		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.5833653650296158 | validation: 0.45783678971749164]
	TIME [epoch: 8.59 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8727913015285967		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.8727913015285967 | validation: 1.4944896856438485]
	TIME [epoch: 8.58 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1418827436193175		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.1418827436193175 | validation: 0.6192560335816424]
	TIME [epoch: 8.58 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6750926442459628		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.6750926442459628 | validation: 0.6221259711029294]
	TIME [epoch: 8.61 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5075275522327715		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.5075275522327715 | validation: 1.0037402755048541]
	TIME [epoch: 8.58 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7430939519318167		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.7430939519318167 | validation: 0.5276890823182765]
	TIME [epoch: 8.57 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8534163832462406		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.8534163832462406 | validation: 1.100805475621107]
	TIME [epoch: 8.58 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7639667605703411		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.7639667605703411 | validation: 0.7722564775879941]
	TIME [epoch: 8.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8009930943448724		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.8009930943448724 | validation: 1.811708699885595]
	TIME [epoch: 8.57 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.871533853935617		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.871533853935617 | validation: 0.5637355052170341]
	TIME [epoch: 8.58 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6718769953420269		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.6718769953420269 | validation: 1.6203544054487018]
	TIME [epoch: 8.59 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.813970925554629		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.813970925554629 | validation: 0.4585037512238703]
	TIME [epoch: 8.61 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5676288497028227		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.5676288497028227 | validation: 0.7312544114202058]
	TIME [epoch: 8.58 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7309221608312434		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.7309221608312434 | validation: 0.841940279537641]
	TIME [epoch: 8.58 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7423102899844004		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.7423102899844004 | validation: 0.775514185009296]
	TIME [epoch: 8.59 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7170141363762356		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.7170141363762356 | validation: 0.6796828142002661]
	TIME [epoch: 8.62 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.575770215123258		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.575770215123258 | validation: 0.6740510951666777]
	TIME [epoch: 8.59 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5869907368862618		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.5869907368862618 | validation: 0.6168413557649769]
	TIME [epoch: 8.58 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5552311982739206		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.5552311982739206 | validation: 0.8339411468325548]
	TIME [epoch: 8.59 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7567543162015691		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.7567543162015691 | validation: 0.34573384700710913]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5461029536694351		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.5461029536694351 | validation: 0.8432375623729138]
	TIME [epoch: 8.59 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7018070681160289		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.7018070681160289 | validation: 1.1934225537710632]
	TIME [epoch: 8.59 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8066309863783543		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.8066309863783543 | validation: 0.9575476139280663]
	TIME [epoch: 8.58 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.663552431842187		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.663552431842187 | validation: 0.5713032339250831]
	TIME [epoch: 8.61 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6147739829096566		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.6147739829096566 | validation: 0.5304901761999801]
	TIME [epoch: 8.59 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433322706890982		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.6433322706890982 | validation: 0.4373862587338032]
	TIME [epoch: 8.58 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4773006613500952		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.4773006613500952 | validation: 0.3687893780204638]
	TIME [epoch: 8.58 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8650617182528848		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.8650617182528848 | validation: 1.369864131505464]
	TIME [epoch: 8.61 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8571024398906635		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.8571024398906635 | validation: 0.6251708761359642]
	TIME [epoch: 8.58 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171432526737525		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.5171432526737525 | validation: 0.5712072920533635]
	TIME [epoch: 8.59 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6055564879195721		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.6055564879195721 | validation: 0.4637098609368082]
	TIME [epoch: 8.58 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5017902703845228		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.5017902703845228 | validation: 0.8762754345674979]
	TIME [epoch: 8.59 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.704187931946353		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.704187931946353 | validation: 0.5719649771060216]
	TIME [epoch: 8.58 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6810655398235259		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.6810655398235259 | validation: 0.8086079357412259]
	TIME [epoch: 8.58 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5594214766791323		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.5594214766791323 | validation: 0.7120564596711091]
	TIME [epoch: 8.59 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.705356937503301		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.705356937503301 | validation: 0.5790880938392217]
	TIME [epoch: 8.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8301625565635495		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.8301625565635495 | validation: 0.44970236394546104]
	TIME [epoch: 8.59 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5675279752888786		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.5675279752888786 | validation: 0.4792777143355296]
	TIME [epoch: 8.58 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9337532494822629		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.9337532494822629 | validation: 0.48239587781267773]
	TIME [epoch: 8.58 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6864490049464878		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.6864490049464878 | validation: 0.4454618019928698]
	TIME [epoch: 8.59 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6510121035174591		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.6510121035174591 | validation: 0.7892090251984665]
	TIME [epoch: 8.58 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6180813800066165		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.6180813800066165 | validation: 0.41650779432290563]
	TIME [epoch: 8.57 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6227826074142511		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.6227826074142511 | validation: 0.46768687943648846]
	TIME [epoch: 8.57 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6119787356410309		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.6119787356410309 | validation: 0.4623054071055238]
	TIME [epoch: 8.61 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5851064684755802		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.5851064684755802 | validation: 0.5739796424366714]
	TIME [epoch: 8.59 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7274942099322266		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.7274942099322266 | validation: 0.7387077229583852]
	TIME [epoch: 8.58 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7128466877181309		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.7128466877181309 | validation: 0.7363991144342894]
	TIME [epoch: 8.58 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5878438283996589		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.5878438283996589 | validation: 0.46759521685898364]
	TIME [epoch: 8.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5658405018605255		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.5658405018605255 | validation: 0.47215184421636697]
	TIME [epoch: 8.59 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5757486284472478		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.5757486284472478 | validation: 1.1773670797049314]
	TIME [epoch: 8.59 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6522241668836226		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.6522241668836226 | validation: 0.529963560212082]
	TIME [epoch: 8.58 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5888474314804681		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.5888474314804681 | validation: 0.43252837604878075]
	TIME [epoch: 8.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6168666659501395		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.6168666659501395 | validation: 0.4823046636825814]
	TIME [epoch: 8.58 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6335965561364991		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.6335965561364991 | validation: 0.6808993753402945]
	TIME [epoch: 8.59 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6507436119344278		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.6507436119344278 | validation: 1.1253892428460734]
	TIME [epoch: 8.57 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7005123059629007		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.7005123059629007 | validation: 0.6593476527823969]
	TIME [epoch: 8.61 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.672159772764114		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.672159772764114 | validation: 1.0288783062026474]
	TIME [epoch: 8.58 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6547348963837913		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.6547348963837913 | validation: 0.5298980817495986]
	TIME [epoch: 8.58 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6372876161605188		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.6372876161605188 | validation: 0.41129508386145863]
	TIME [epoch: 8.58 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4468578164574084		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.4468578164574084 | validation: 0.3032564921411389]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601436604268218		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.5601436604268218 | validation: 0.6336130910720393]
	TIME [epoch: 8.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6350217753313048		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.6350217753313048 | validation: 0.3703329749830513]
	TIME [epoch: 8.59 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7419131109996283		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.7419131109996283 | validation: 0.5732746246633545]
	TIME [epoch: 8.59 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.552223452450591		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.552223452450591 | validation: 0.6930883398795877]
	TIME [epoch: 8.59 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7140305368889441		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.7140305368889441 | validation: 0.3923675041488197]
	TIME [epoch: 8.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6578963128780639		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.6578963128780639 | validation: 0.46554122933547715]
	TIME [epoch: 8.58 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7069851366659355		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.7069851366659355 | validation: 0.44780676374990835]
	TIME [epoch: 8.59 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7157060336920826		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.7157060336920826 | validation: 0.4517562904843761]
	TIME [epoch: 8.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6344806966304363		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.6344806966304363 | validation: 0.371882985446814]
	TIME [epoch: 8.62 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6600169505964203		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.6600169505964203 | validation: 0.5096897351094103]
	TIME [epoch: 8.59 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6180750336276104		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.6180750336276104 | validation: 0.2900875835348305]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7144631895196103		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.7144631895196103 | validation: 0.5011995707783453]
	TIME [epoch: 8.61 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.748563764570749		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.748563764570749 | validation: 0.6281964809151278]
	TIME [epoch: 8.61 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5542160487146243		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.5542160487146243 | validation: 0.5848146780392787]
	TIME [epoch: 8.59 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6331033901907532		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.6331033901907532 | validation: 0.761650982370188]
	TIME [epoch: 8.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5520805807741488		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.5520805807741488 | validation: 1.0223656820797278]
	TIME [epoch: 8.59 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45963165739214923		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.45963165739214923 | validation: 0.6357900454312749]
	TIME [epoch: 8.62 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7175317512387857		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.7175317512387857 | validation: 0.3201052308302242]
	TIME [epoch: 8.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47760338793038565		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.47760338793038565 | validation: 0.7999417234367945]
	TIME [epoch: 8.59 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5717080941712865		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.5717080941712865 | validation: 0.818491226474484]
	TIME [epoch: 8.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5850313161278746		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.5850313161278746 | validation: 0.7557094926967622]
	TIME [epoch: 8.61 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9211196312860398		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.9211196312860398 | validation: 0.6009641971220463]
	TIME [epoch: 8.59 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6063886748205722		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.6063886748205722 | validation: 0.5580995627901386]
	TIME [epoch: 8.59 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49997268347551815		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.49997268347551815 | validation: 0.440246396256537]
	TIME [epoch: 8.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7475907155337642		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.7475907155337642 | validation: 0.5338852657309746]
	TIME [epoch: 8.61 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6826173748951161		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.6826173748951161 | validation: 0.7179592446380758]
	TIME [epoch: 8.59 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7152975650886002		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.7152975650886002 | validation: 0.5270659122375743]
	TIME [epoch: 8.59 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5316894200410874		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.5316894200410874 | validation: 0.6358490755180837]
	TIME [epoch: 8.59 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6720120445786026		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.6720120445786026 | validation: 0.6708319668751201]
	TIME [epoch: 8.61 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5388684434623243		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.5388684434623243 | validation: 0.42346690485302363]
	TIME [epoch: 8.59 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5682825091771179		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.5682825091771179 | validation: 0.47656369525322473]
	TIME [epoch: 8.59 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.566722918290121		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.566722918290121 | validation: 0.5376323394097522]
	TIME [epoch: 8.59 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.754514449418302		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.754514449418302 | validation: 0.40410044809600176]
	TIME [epoch: 8.61 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5070407062405585		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.5070407062405585 | validation: 0.3893536098869522]
	TIME [epoch: 8.59 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4569748982667856		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.4569748982667856 | validation: 0.41590435503018053]
	TIME [epoch: 8.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.426527764443578		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.426527764443578 | validation: 0.47420052415827363]
	TIME [epoch: 8.59 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.557889656552514		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.557889656552514 | validation: 0.7113813532486518]
	TIME [epoch: 8.61 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5198615345532709		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.5198615345532709 | validation: 0.3905877451242318]
	TIME [epoch: 8.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4314185706593146		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.4314185706593146 | validation: 0.27255050929720714]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5088536359053234		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.5088536359053234 | validation: 0.5841055968139826]
	TIME [epoch: 8.59 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5031559614565186		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.5031559614565186 | validation: 0.6591079539259623]
	TIME [epoch: 8.61 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45218017184929626		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.45218017184929626 | validation: 0.5264205539825235]
	TIME [epoch: 8.59 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44979724873872967		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.44979724873872967 | validation: 0.6167009951838994]
	TIME [epoch: 8.59 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4815691892369546		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.4815691892369546 | validation: 0.4881592381895082]
	TIME [epoch: 8.59 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.512099880369844		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.512099880369844 | validation: 0.48247145849549367]
	TIME [epoch: 8.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48310211710845524		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.48310211710845524 | validation: 0.3266723037011947]
	TIME [epoch: 8.59 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5366404238564144		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.5366404238564144 | validation: 0.6793401729327934]
	TIME [epoch: 8.59 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4531187122904884		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.4531187122904884 | validation: 0.43459534926338905]
	TIME [epoch: 8.59 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138632409678514		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.5138632409678514 | validation: 0.2620553807627897]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5815069551617598		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.5815069551617598 | validation: 0.35745031881414363]
	TIME [epoch: 8.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5135912867512171		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.5135912867512171 | validation: 1.3064113254832361]
	TIME [epoch: 8.59 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5687708481984617		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.5687708481984617 | validation: 0.5524330662058711]
	TIME [epoch: 8.58 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5749510278014102		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.5749510278014102 | validation: 0.4692601926481813]
	TIME [epoch: 8.61 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.544793206982886		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.544793206982886 | validation: 0.4017169885670624]
	TIME [epoch: 8.59 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5343507598409967		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.5343507598409967 | validation: 0.6167975312064766]
	TIME [epoch: 8.59 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5938316751257625		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.5938316751257625 | validation: 0.48394403621000964]
	TIME [epoch: 8.58 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5180085772563718		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.5180085772563718 | validation: 0.5182975015981366]
	TIME [epoch: 8.61 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5683138062036913		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.5683138062036913 | validation: 0.28874511423468696]
	TIME [epoch: 8.59 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191040041390705		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.4191040041390705 | validation: 0.5767519538419299]
	TIME [epoch: 8.59 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5650381071220598		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.5650381071220598 | validation: 0.4305027605902165]
	TIME [epoch: 8.58 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4803469452536703		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.4803469452536703 | validation: 0.3609620471772851]
	TIME [epoch: 8.61 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4166203641520624		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.4166203641520624 | validation: 0.2184870053679403]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44745311760189416		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.44745311760189416 | validation: 0.9192976889847224]
	TIME [epoch: 8.59 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5643771702881483		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.5643771702881483 | validation: 0.3818351543244758]
	TIME [epoch: 8.59 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4718737743460319		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.4718737743460319 | validation: 0.49811859550626864]
	TIME [epoch: 8.61 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4832367858669736		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.4832367858669736 | validation: 0.5660335088242]
	TIME [epoch: 8.59 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43228463974976383		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.43228463974976383 | validation: 0.473991970507464]
	TIME [epoch: 8.58 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677896196159914		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.3677896196159914 | validation: 0.5097795339461189]
	TIME [epoch: 8.59 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5279035635551718		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.5279035635551718 | validation: 0.3746198383368746]
	TIME [epoch: 8.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5787311959003003		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.5787311959003003 | validation: 0.7482121524502341]
	TIME [epoch: 8.59 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5595618303658197		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.5595618303658197 | validation: 0.5472663367231816]
	TIME [epoch: 8.58 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5623023602490267		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.5623023602490267 | validation: 0.47596295287499124]
	TIME [epoch: 8.58 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47522047346912155		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.47522047346912155 | validation: 0.43703966437650155]
	TIME [epoch: 8.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4884029619485286		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.4884029619485286 | validation: 0.5224979583028002]
	TIME [epoch: 8.59 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4585774353356629		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.4585774353356629 | validation: 0.26249301701854433]
	TIME [epoch: 8.58 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3859639586782547		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.3859639586782547 | validation: 0.6394615734322991]
	TIME [epoch: 8.59 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5204422433060394		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.5204422433060394 | validation: 0.4942410236193]
	TIME [epoch: 8.61 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8416053676344261		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.8416053676344261 | validation: 0.5998542358503479]
	TIME [epoch: 8.59 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.421291629959544		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.421291629959544 | validation: 0.4499706597920916]
	TIME [epoch: 8.59 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4541183078280744		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.4541183078280744 | validation: 0.43790410396846924]
	TIME [epoch: 8.59 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38445916379728917		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.38445916379728917 | validation: 0.32093680613609255]
	TIME [epoch: 8.61 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46663206717556144		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.46663206717556144 | validation: 0.7281877995640469]
	TIME [epoch: 8.59 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4412243041465881		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.4412243041465881 | validation: 0.40218043853508323]
	TIME [epoch: 8.59 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5127949418601074		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.5127949418601074 | validation: 0.3061947151480443]
	TIME [epoch: 8.59 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449390130130969		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.5449390130130969 | validation: 0.77614976865576]
	TIME [epoch: 8.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49613957554798055		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.49613957554798055 | validation: 0.687485715859366]
	TIME [epoch: 8.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5613512684102043		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.5613512684102043 | validation: 0.38293412933458876]
	TIME [epoch: 8.58 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37472202689937173		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.37472202689937173 | validation: 0.7462715384776539]
	TIME [epoch: 8.59 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5071946697792102		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.5071946697792102 | validation: 0.29856208846902893]
	TIME [epoch: 8.58 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34554756644083684		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.34554756644083684 | validation: 0.7661930962522174]
	TIME [epoch: 8.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5054619694799468		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.5054619694799468 | validation: 0.25815158511616076]
	TIME [epoch: 8.59 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46884961994330326		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.46884961994330326 | validation: 0.3666519310456453]
	TIME [epoch: 8.59 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5499959761818468		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.5499959761818468 | validation: 0.6778378700400235]
	TIME [epoch: 8.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4915975381724966		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.4915975381724966 | validation: 0.29281957598272224]
	TIME [epoch: 8.61 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3622846389362758		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.3622846389362758 | validation: 0.6093272334432567]
	TIME [epoch: 8.59 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3988437443154576		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.3988437443154576 | validation: 0.6164255696811467]
	TIME [epoch: 8.59 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4180289497263148		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.4180289497263148 | validation: 0.8547585995931293]
	TIME [epoch: 8.58 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44413079897544583		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.44413079897544583 | validation: 0.2823665928693732]
	TIME [epoch: 8.61 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39093619827721615		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.39093619827721615 | validation: 0.5553525148067348]
	TIME [epoch: 8.59 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40826661329541725		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.40826661329541725 | validation: 0.31564527293568156]
	TIME [epoch: 8.59 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4101204456928321		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.4101204456928321 | validation: 0.39904924736053193]
	TIME [epoch: 8.58 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9519322608110798		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.9519322608110798 | validation: 0.48424962642045266]
	TIME [epoch: 8.61 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.512154459993902		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.512154459993902 | validation: 0.3601477907054602]
	TIME [epoch: 8.59 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41037570997036427		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.41037570997036427 | validation: 0.4095327683832477]
	TIME [epoch: 8.58 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43866113722931044		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.43866113722931044 | validation: 0.5360481553111702]
	TIME [epoch: 8.58 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3465238006521437		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.3465238006521437 | validation: 0.5159413633807606]
	TIME [epoch: 8.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.588012039694491		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.588012039694491 | validation: 0.3244376109227203]
	TIME [epoch: 8.58 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4546435340132805		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.4546435340132805 | validation: 0.3329365379412535]
	TIME [epoch: 8.57 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485663058570426		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.3485663058570426 | validation: 0.21731870141808216]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5373480766003358		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.5373480766003358 | validation: 0.2656806036490773]
	TIME [epoch: 8.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37540668738570776		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.37540668738570776 | validation: 0.4291879087568816]
	TIME [epoch: 8.58 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.538690067836294		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.538690067836294 | validation: 0.37930798413455324]
	TIME [epoch: 8.57 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45902054394451575		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.45902054394451575 | validation: 0.7882921267966555]
	TIME [epoch: 8.58 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40989779999459797		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.40989779999459797 | validation: 0.22129160222860264]
	TIME [epoch: 8.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3218274928026156		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.3218274928026156 | validation: 0.5692575365189607]
	TIME [epoch: 8.58 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5067039512592838		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.5067039512592838 | validation: 0.29146601919172854]
	TIME [epoch: 8.58 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5346462838326624		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.5346462838326624 | validation: 0.6086092741376621]
	TIME [epoch: 8.58 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4841431385963736		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.4841431385963736 | validation: 0.6339101139695572]
	TIME [epoch: 8.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39861985642370945		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.39861985642370945 | validation: 0.318530284710247]
	TIME [epoch: 8.58 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4424659172511126		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.4424659172511126 | validation: 0.26336953847907096]
	TIME [epoch: 8.58 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.493188484271216		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.493188484271216 | validation: 0.7315549805616532]
	TIME [epoch: 8.58 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44588590078918705		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.44588590078918705 | validation: 0.32197527502839773]
	TIME [epoch: 8.59 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4069732649336951		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.4069732649336951 | validation: 0.3751096341622244]
	TIME [epoch: 8.58 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4823321589917062		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.4823321589917062 | validation: 0.24077261713383497]
	TIME [epoch: 8.58 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4226581511183741		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.4226581511183741 | validation: 0.5833719344926729]
	TIME [epoch: 8.58 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5202365684274282		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.5202365684274282 | validation: 0.6896383031344782]
	TIME [epoch: 8.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4604325678584706		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.4604325678584706 | validation: 0.547204406865001]
	TIME [epoch: 8.58 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6815893810072445		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.6815893810072445 | validation: 0.37339210329147343]
	TIME [epoch: 8.58 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42775883729466335		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.42775883729466335 | validation: 0.2975226583497193]
	TIME [epoch: 8.59 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3125059962869511		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.3125059962869511 | validation: 0.6397803167923086]
	TIME [epoch: 8.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171631362627632		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.5171631362627632 | validation: 0.37999867492754275]
	TIME [epoch: 8.58 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40201484794159914		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.40201484794159914 | validation: 0.26438323696687]
	TIME [epoch: 8.58 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40748016686378674		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.40748016686378674 | validation: 0.2955807821562434]
	TIME [epoch: 8.58 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30391264576298455		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.30391264576298455 | validation: 0.611049605610376]
	TIME [epoch: 8.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46617649651816223		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.46617649651816223 | validation: 0.5203513442114241]
	TIME [epoch: 8.58 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3872186503887363		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.3872186503887363 | validation: 0.43298511624810143]
	TIME [epoch: 8.59 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333623276318475		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.3333623276318475 | validation: 0.45887637922071206]
	TIME [epoch: 8.57 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35177796758912916		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.35177796758912916 | validation: 0.39317408899373807]
	TIME [epoch: 8.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3707018485205265		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.3707018485205265 | validation: 0.4797483967763916]
	TIME [epoch: 8.58 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41486101350830823		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.41486101350830823 | validation: 0.26438853226218106]
	TIME [epoch: 8.57 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34684064918362323		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.34684064918362323 | validation: 0.3575220331113119]
	TIME [epoch: 8.56 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38005059177512174		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.38005059177512174 | validation: 0.2148974426826332]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2951866915347274		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.2951866915347274 | validation: 0.5007203086003987]
	TIME [epoch: 8.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4506254923017957		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.4506254923017957 | validation: 0.4241454724156743]
	TIME [epoch: 8.59 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49058575096306756		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.49058575096306756 | validation: 0.4176025985776694]
	TIME [epoch: 8.58 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3708929737373365		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.3708929737373365 | validation: 0.2972239625947334]
	TIME [epoch: 8.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32147245746588327		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.32147245746588327 | validation: 0.46453786660408813]
	TIME [epoch: 8.58 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5044348661476067		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.5044348661476067 | validation: 0.4883530274976774]
	TIME [epoch: 8.59 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4229903152921759		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.4229903152921759 | validation: 0.45045359966383747]
	TIME [epoch: 8.58 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4173453032095299		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.4173453032095299 | validation: 0.3794443766367523]
	TIME [epoch: 8.61 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31812408690451893		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.31812408690451893 | validation: 0.39945629700525176]
	TIME [epoch: 8.58 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38115770603993837		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.38115770603993837 | validation: 0.3117406854539347]
	TIME [epoch: 8.58 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44228430423753806		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.44228430423753806 | validation: 0.6883322847884104]
	TIME [epoch: 8.58 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41199816808585243		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.41199816808585243 | validation: 0.3620323167040589]
	TIME [epoch: 8.59 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44062864740004953		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.44062864740004953 | validation: 0.458793026745994]
	TIME [epoch: 8.59 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.363579370864484		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.363579370864484 | validation: 0.4972254917852902]
	TIME [epoch: 8.58 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3969423639977766		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.3969423639977766 | validation: 0.3317982380580293]
	TIME [epoch: 8.58 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36880089029464536		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.36880089029464536 | validation: 0.4186573024219137]
	TIME [epoch: 8.58 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250436112749441		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.3250436112749441 | validation: 0.3728855527543541]
	TIME [epoch: 8.59 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38095141706782426		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.38095141706782426 | validation: 0.3421025726146798]
	TIME [epoch: 8.57 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40299141514306636		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.40299141514306636 | validation: 0.23514055872429374]
	TIME [epoch: 8.58 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32211813282268664		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.32211813282268664 | validation: 0.3431909992280058]
	TIME [epoch: 8.58 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39851896172098417		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.39851896172098417 | validation: 0.4484823623476336]
	TIME [epoch: 8.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4510669580619561		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.4510669580619561 | validation: 0.4397891049356476]
	TIME [epoch: 8.58 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3680418979723575		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.3680418979723575 | validation: 0.3856601503124461]
	TIME [epoch: 8.58 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4092100013289879		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.4092100013289879 | validation: 0.32941337859164155]
	TIME [epoch: 8.58 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42978625896200223		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.42978625896200223 | validation: 0.2446722032561656]
	TIME [epoch: 8.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3723416869359597		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.3723416869359597 | validation: 0.34553808562887517]
	TIME [epoch: 8.58 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3642962943784186		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.3642962943784186 | validation: 0.36205093985060266]
	TIME [epoch: 8.58 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3269706175870911		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.3269706175870911 | validation: 0.7972291291408609]
	TIME [epoch: 8.58 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4412684544494566		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.4412684544494566 | validation: 0.24945045106732786]
	TIME [epoch: 8.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35733508182287327		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.35733508182287327 | validation: 0.27574464898720813]
	TIME [epoch: 8.58 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3429237260865856		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.3429237260865856 | validation: 0.7690734465543729]
	TIME [epoch: 8.58 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37605103853059346		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.37605103853059346 | validation: 0.26289275661112266]
	TIME [epoch: 8.58 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35255939848902923		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.35255939848902923 | validation: 0.39558562563489674]
	TIME [epoch: 8.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43016276577807233		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.43016276577807233 | validation: 0.30063310363679285]
	TIME [epoch: 8.58 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30748376629276664		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.30748376629276664 | validation: 0.7177833580749902]
	TIME [epoch: 8.57 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4015994682004864		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.4015994682004864 | validation: 0.27627457196826066]
	TIME [epoch: 8.58 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4005994469356617		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.4005994469356617 | validation: 0.24659321674011717]
	TIME [epoch: 8.59 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671357671352521		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.3671357671352521 | validation: 0.2835839545768401]
	TIME [epoch: 8.58 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3635541750762978		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.3635541750762978 | validation: 0.5729073142616685]
	TIME [epoch: 8.58 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3532959754932162		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.3532959754932162 | validation: 0.4480889098198332]
	TIME [epoch: 8.58 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34069944865984875		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.34069944865984875 | validation: 0.7768569930193623]
	TIME [epoch: 8.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39828903924169456		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.39828903924169456 | validation: 0.371327698420581]
	TIME [epoch: 8.58 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3298682672454317		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.3298682672454317 | validation: 0.2536078859956152]
	TIME [epoch: 8.58 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31144431571558084		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.31144431571558084 | validation: 0.2358002484963027]
	TIME [epoch: 8.58 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2546564139983244		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.2546564139983244 | validation: 0.7397907029950845]
	TIME [epoch: 8.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3709646307013982		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.3709646307013982 | validation: 0.19629687203736426]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31276954566657894		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.31276954566657894 | validation: 0.2673248131333106]
	TIME [epoch: 8.58 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2590699070560253		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.2590699070560253 | validation: 0.3589186294770185]
	TIME [epoch: 8.58 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661343380806146		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.2661343380806146 | validation: 0.20550346269221068]
	TIME [epoch: 8.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33029860165732094		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.33029860165732094 | validation: 0.1982788402709438]
	TIME [epoch: 8.58 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28457261746182216		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.28457261746182216 | validation: 0.3817979547183257]
	TIME [epoch: 8.58 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45621328354228174		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.45621328354228174 | validation: 0.3848860263352747]
	TIME [epoch: 8.58 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2834055649029043		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.2834055649029043 | validation: 0.321964840311599]
	TIME [epoch: 8.61 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725688238358973		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.2725688238358973 | validation: 0.38089876760141983]
	TIME [epoch: 8.59 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26656387049510494		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.26656387049510494 | validation: 0.1512225868869258]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26548786454902606		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.26548786454902606 | validation: 0.547211879457046]
	TIME [epoch: 8.58 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31343270864482314		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.31343270864482314 | validation: 0.1598640272814511]
	TIME [epoch: 8.61 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3695419761288944		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.3695419761288944 | validation: 0.26955587045548324]
	TIME [epoch: 8.58 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700572896016261		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.2700572896016261 | validation: 0.19051394409536762]
	TIME [epoch: 8.58 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42244571016322413		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.42244571016322413 | validation: 0.25467314585642387]
	TIME [epoch: 8.59 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4194372121832065		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.4194372121832065 | validation: 0.17410936396909896]
	TIME [epoch: 8.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32304694501145204		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.32304694501145204 | validation: 0.3055874899637657]
	TIME [epoch: 8.58 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3590483569994917		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.3590483569994917 | validation: 0.4886809976578739]
	TIME [epoch: 8.58 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33828689718434013		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.33828689718434013 | validation: 0.34352975780446016]
	TIME [epoch: 8.58 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3652322443110816		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.3652322443110816 | validation: 0.44298070747469115]
	TIME [epoch: 8.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283634234035317		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.283634234035317 | validation: 0.4722426468425934]
	TIME [epoch: 8.58 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4871848769532393		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.4871848769532393 | validation: 0.4646030294541641]
	TIME [epoch: 8.58 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3111351554184732		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.3111351554184732 | validation: 0.2077163873821519]
	TIME [epoch: 8.59 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3276222846014723		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.3276222846014723 | validation: 0.3832673486295466]
	TIME [epoch: 8.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25609252963524554		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.25609252963524554 | validation: 0.24430630390308614]
	TIME [epoch: 8.58 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32512660236066193		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.32512660236066193 | validation: 0.7204339111739658]
	TIME [epoch: 8.58 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3074968782013222		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.3074968782013222 | validation: 0.3868096161488875]
	TIME [epoch: 8.58 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3288151513794302		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.3288151513794302 | validation: 0.2354932795906194]
	TIME [epoch: 8.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3210466923415932		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.3210466923415932 | validation: 0.35538730443559224]
	TIME [epoch: 8.58 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3159536452542025		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.3159536452542025 | validation: 0.34290025371075844]
	TIME [epoch: 8.58 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28212126870559845		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.28212126870559845 | validation: 0.47786814802330485]
	TIME [epoch: 8.58 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40861475237576117		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.40861475237576117 | validation: 0.4456448881477929]
	TIME [epoch: 8.61 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2719966552859755		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.2719966552859755 | validation: 0.5742291764262661]
	TIME [epoch: 8.58 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3297055988870041		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.3297055988870041 | validation: 0.2699558674755467]
	TIME [epoch: 8.58 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30283374429806226		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.30283374429806226 | validation: 0.4931720954052501]
	TIME [epoch: 8.58 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3943736942009092		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.3943736942009092 | validation: 0.5391923174393123]
	TIME [epoch: 8.59 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35079870691558745		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.35079870691558745 | validation: 0.1869664202215351]
	TIME [epoch: 8.59 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306646843778508		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.3306646843778508 | validation: 0.3702272102052362]
	TIME [epoch: 8.58 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4876609683062668		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.4876609683062668 | validation: 0.42971368677967103]
	TIME [epoch: 8.57 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610421966405931		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.3610421966405931 | validation: 0.324227860134416]
	TIME [epoch: 8.59 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29131169609941343		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.29131169609941343 | validation: 0.1268853032901039]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22822511748825797		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.22822511748825797 | validation: 0.3049495573856484]
	TIME [epoch: 8.58 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3057951707987568		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.3057951707987568 | validation: 0.16395806957143272]
	TIME [epoch: 8.58 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2858623787075183		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.2858623787075183 | validation: 0.15760208797604347]
	TIME [epoch: 8.59 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22697612853442012		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.22697612853442012 | validation: 0.22712034631159744]
	TIME [epoch: 8.59 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2432867130848972		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.2432867130848972 | validation: 0.11771160800497077]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.312461645884412		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.312461645884412 | validation: 0.6463407035418882]
	TIME [epoch: 8.81 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30416597099157794		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.30416597099157794 | validation: 0.3006948126481078]
	TIME [epoch: 8.59 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34203758830280384		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.34203758830280384 | validation: 0.28762183678598946]
	TIME [epoch: 8.59 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361931552883268		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.361931552883268 | validation: 0.39240409221176853]
	TIME [epoch: 8.58 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4240432685348841		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.4240432685348841 | validation: 0.8816434288310586]
	TIME [epoch: 8.58 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3715792590821334		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.3715792590821334 | validation: 0.2275944589767252]
	TIME [epoch: 8.58 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34757136903351016		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.34757136903351016 | validation: 0.3839232584115063]
	TIME [epoch: 8.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40726567257457297		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.40726567257457297 | validation: 0.5841157384025684]
	TIME [epoch: 8.58 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35210961644913374		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.35210961644913374 | validation: 0.5640666748330974]
	TIME [epoch: 8.58 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4580043058639129		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.4580043058639129 | validation: 0.47811848135564056]
	TIME [epoch: 8.58 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500551173810006		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.3500551173810006 | validation: 0.21953379024113098]
	TIME [epoch: 8.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28117688779997574		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.28117688779997574 | validation: 0.3969524896981408]
	TIME [epoch: 8.58 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3253649390305625		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.3253649390305625 | validation: 0.1692134163716067]
	TIME [epoch: 8.58 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34649016319394826		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.34649016319394826 | validation: 0.3292468851753817]
	TIME [epoch: 8.58 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277220774961804		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.2277220774961804 | validation: 0.5691211052227587]
	TIME [epoch: 8.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3210298417462035		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.3210298417462035 | validation: 0.19588516382910964]
	TIME [epoch: 8.58 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300237841056343		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.2300237841056343 | validation: 0.19025543566114028]
	TIME [epoch: 8.58 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24748143035444534		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.24748143035444534 | validation: 0.30600024486304667]
	TIME [epoch: 8.58 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21829069373482696		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.21829069373482696 | validation: 0.279135467141746]
	TIME [epoch: 8.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24114962599717296		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.24114962599717296 | validation: 0.16875010410407648]
	TIME [epoch: 8.58 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2199539826654225		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.2199539826654225 | validation: 0.2045556388560298]
	TIME [epoch: 8.58 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147376048446875		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.3147376048446875 | validation: 0.20530729562405048]
	TIME [epoch: 8.58 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.305761955929211		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.305761955929211 | validation: 0.44272659373171885]
	TIME [epoch: 8.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3587078970198421		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.3587078970198421 | validation: 0.2630242772311893]
	TIME [epoch: 8.59 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41162820791955196		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.41162820791955196 | validation: 0.6243062711125706]
	TIME [epoch: 8.58 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41374276546449507		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.41374276546449507 | validation: 0.15107580367366386]
	TIME [epoch: 8.58 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20234891202889838		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.20234891202889838 | validation: 0.48950652804601336]
	TIME [epoch: 8.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41582946461285497		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.41582946461285497 | validation: 0.3696905292243494]
	TIME [epoch: 8.58 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4952497816440317		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.4952497816440317 | validation: 0.3043527551338331]
	TIME [epoch: 8.58 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3954297051448063		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.3954297051448063 | validation: 0.35310208741581883]
	TIME [epoch: 8.58 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3429542619954786		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.3429542619954786 | validation: 0.34884791542685056]
	TIME [epoch: 8.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.367358091777882		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.367358091777882 | validation: 0.22690513354339475]
	TIME [epoch: 8.59 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33768385906230425		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.33768385906230425 | validation: 0.2217930867660593]
	TIME [epoch: 8.58 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3616209641411441		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.3616209641411441 | validation: 0.7159406532653217]
	TIME [epoch: 8.58 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3099843277415567		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.3099843277415567 | validation: 0.20749464447452073]
	TIME [epoch: 8.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.306535208312909		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.306535208312909 | validation: 0.38676925662839623]
	TIME [epoch: 8.59 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2801511210016569		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.2801511210016569 | validation: 0.19859583509520734]
	TIME [epoch: 8.58 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33008330984555007		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.33008330984555007 | validation: 0.4211406379490576]
	TIME [epoch: 8.58 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3742908060784767		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.3742908060784767 | validation: 0.22681025171949132]
	TIME [epoch: 8.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27067710425873603		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.27067710425873603 | validation: 0.22977885659549113]
	TIME [epoch: 8.59 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813532529663626		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.2813532529663626 | validation: 0.28602402519210024]
	TIME [epoch: 8.59 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22183042211182324		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.22183042211182324 | validation: 0.4531925504435991]
	TIME [epoch: 8.58 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5462861797310621		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.5462861797310621 | validation: 0.23999891918064697]
	TIME [epoch: 8.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3287071700218145		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.3287071700218145 | validation: 0.2570165366690552]
	TIME [epoch: 8.59 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2967844837332571		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.2967844837332571 | validation: 0.2418406788620108]
	TIME [epoch: 8.58 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30316980264262566		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.30316980264262566 | validation: 0.1727508866951265]
	TIME [epoch: 8.58 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24472624449401542		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.24472624449401542 | validation: 0.19267038131492908]
	TIME [epoch: 8.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31920944249136995		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.31920944249136995 | validation: 0.32787676494880835]
	TIME [epoch: 8.58 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37404051449247044		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.37404051449247044 | validation: 0.25304780149028927]
	TIME [epoch: 8.58 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29135415746311905		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.29135415746311905 | validation: 0.31213710289032776]
	TIME [epoch: 8.58 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24548246041953597		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.24548246041953597 | validation: 0.17508606084447792]
	TIME [epoch: 8.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23732687996686486		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.23732687996686486 | validation: 0.1821262015359934]
	TIME [epoch: 8.58 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25235288324075417		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.25235288324075417 | validation: 0.23224656918494913]
	TIME [epoch: 8.58 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754694269203023		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2754694269203023 | validation: 0.25503278588906475]
	TIME [epoch: 8.58 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30277353448710287		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.30277353448710287 | validation: 1.0741706163322307]
	TIME [epoch: 8.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45059776048338496		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.45059776048338496 | validation: 0.27185373441903105]
	TIME [epoch: 8.58 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30295152571313505		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.30295152571313505 | validation: 0.16780197988327666]
	TIME [epoch: 8.58 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3702758549707183		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.3702758549707183 | validation: 0.19205174467789912]
	TIME [epoch: 8.58 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2393832727510447		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.2393832727510447 | validation: 0.525154064839747]
	TIME [epoch: 8.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35337521303240754		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.35337521303240754 | validation: 0.3822148176088618]
	TIME [epoch: 8.58 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2780765165601016		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.2780765165601016 | validation: 0.43145469466448727]
	TIME [epoch: 8.58 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26398283558492514		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.26398283558492514 | validation: 0.21165115609473698]
	TIME [epoch: 8.58 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25658278638536525		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.25658278638536525 | validation: 0.2430601659918016]
	TIME [epoch: 8.59 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23283771837254133		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.23283771837254133 | validation: 0.8410800465276069]
	TIME [epoch: 8.59 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35648265914713284		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.35648265914713284 | validation: 0.32179076146381064]
	TIME [epoch: 8.58 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3799961381488952		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.3799961381488952 | validation: 0.2956389238175282]
	TIME [epoch: 8.58 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727372484546907		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.2727372484546907 | validation: 0.8676931198144973]
	TIME [epoch: 8.59 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500397805988546		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.3500397805988546 | validation: 0.35560118583144823]
	TIME [epoch: 8.59 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2692094427934152		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.2692094427934152 | validation: 0.17872248055947487]
	TIME [epoch: 8.58 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4711469295609076		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.4711469295609076 | validation: 0.1522430476614829]
	TIME [epoch: 8.58 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24086514220034486		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.24086514220034486 | validation: 0.2675562860520183]
	TIME [epoch: 8.58 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24121566712045706		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.24121566712045706 | validation: 0.18031724014874706]
	TIME [epoch: 8.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16031017899788705		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.16031017899788705 | validation: 0.17102832995098927]
	TIME [epoch: 8.58 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19663756774586486		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.19663756774586486 | validation: 0.10765812747065553]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24930597515499958		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.24930597515499958 | validation: 0.2256864098228376]
	TIME [epoch: 8.58 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2583150732541831		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.2583150732541831 | validation: 0.33378357592310764]
	TIME [epoch: 8.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22412162444730516		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.22412162444730516 | validation: 0.13115299988514248]
	TIME [epoch: 8.58 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20778966161619444		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.20778966161619444 | validation: 0.19418931265724682]
	TIME [epoch: 8.57 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3299572945591679		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.3299572945591679 | validation: 0.3240047225067913]
	TIME [epoch: 8.58 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.245801405993332		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.245801405993332 | validation: 0.202158579448781]
	TIME [epoch: 8.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2086108845781703		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.2086108845781703 | validation: 0.197833594595286]
	TIME [epoch: 8.58 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.273437392142036		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.273437392142036 | validation: 0.3872949944915478]
	TIME [epoch: 8.58 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24838021709095245		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.24838021709095245 | validation: 0.24003882462820234]
	TIME [epoch: 8.58 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21093525083136355		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.21093525083136355 | validation: 0.2265282454062311]
	TIME [epoch: 8.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22404750462087533		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.22404750462087533 | validation: 0.12617229592037196]
	TIME [epoch: 8.58 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19918515870698408		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.19918515870698408 | validation: 0.1838554439474716]
	TIME [epoch: 8.57 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26160519053477926		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.26160519053477926 | validation: 0.22417589726172285]
	TIME [epoch: 8.57 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24799290973583643		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.24799290973583643 | validation: 0.18961135635669685]
	TIME [epoch: 8.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2196536265334267		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.2196536265334267 | validation: 0.22034402155188298]
	TIME [epoch: 8.57 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23018887048780537		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.23018887048780537 | validation: 0.24474337304999982]
	TIME [epoch: 8.58 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16776696511160988		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.16776696511160988 | validation: 0.11482135300197184]
	TIME [epoch: 8.58 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056686445005468		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.2056686445005468 | validation: 0.2923901600047528]
	TIME [epoch: 8.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22640668988514762		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.22640668988514762 | validation: 0.36697490644631175]
	TIME [epoch: 8.58 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21242602877807237		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.21242602877807237 | validation: 0.3937579546350874]
	TIME [epoch: 8.58 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32341380920863705		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.32341380920863705 | validation: 0.23696861878084116]
	TIME [epoch: 8.58 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2379009975795494		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.2379009975795494 | validation: 0.22173315911117106]
	TIME [epoch: 8.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25412263916806593		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.25412263916806593 | validation: 0.26516592448827503]
	TIME [epoch: 8.58 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1869702754513412		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.1869702754513412 | validation: 0.3695111008042419]
	TIME [epoch: 8.58 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23280004222314377		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.23280004222314377 | validation: 0.2633938628751007]
	TIME [epoch: 8.58 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24024926496482446		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.24024926496482446 | validation: 0.22295244597980002]
	TIME [epoch: 8.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2557144372308905		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.2557144372308905 | validation: 0.5834347536544062]
	TIME [epoch: 8.58 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3616993883367794		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.3616993883367794 | validation: 0.22898790582212136]
	TIME [epoch: 8.58 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3987930883305239		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.3987930883305239 | validation: 0.23202752286096856]
	TIME [epoch: 8.58 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24935378145446002		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.24935378145446002 | validation: 0.11584794149952166]
	TIME [epoch: 8.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.265785709551648		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.265785709551648 | validation: 0.21333612137642638]
	TIME [epoch: 8.58 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22310246082950758		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.22310246082950758 | validation: 0.18145358811681322]
	TIME [epoch: 8.58 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080069090619563		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.2080069090619563 | validation: 0.41729540341259214]
	TIME [epoch: 8.58 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26961670213525857		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.26961670213525857 | validation: 0.6227607097120511]
	TIME [epoch: 8.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4187334361696652		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.4187334361696652 | validation: 0.2894136433783714]
	TIME [epoch: 8.59 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4754601817120732		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.4754601817120732 | validation: 0.1876171766080847]
	TIME [epoch: 8.58 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36905349436814716		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.36905349436814716 | validation: 0.4687681565764361]
	TIME [epoch: 8.59 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5896360413785842		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.5896360413785842 | validation: 0.28967550123340413]
	TIME [epoch: 8.61 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34155820372168316		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.34155820372168316 | validation: 0.22785261924923406]
	TIME [epoch: 8.58 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2657705891461565		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.2657705891461565 | validation: 0.2490375387882522]
	TIME [epoch: 8.58 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582123518016678		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.2582123518016678 | validation: 0.13000238271157655]
	TIME [epoch: 8.58 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2100472319740371		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.2100472319740371 | validation: 0.26920232915188247]
	TIME [epoch: 8.61 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3332000365202253		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.3332000365202253 | validation: 0.3384884309245325]
	TIME [epoch: 8.59 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26903101982599414		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.26903101982599414 | validation: 0.13573838473774474]
	TIME [epoch: 8.58 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.212157695593356		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.212157695593356 | validation: 0.1375427561104624]
	TIME [epoch: 8.58 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21093427586426255		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.21093427586426255 | validation: 0.16939751378409287]
	TIME [epoch: 8.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28469831327979217		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.28469831327979217 | validation: 0.23794826267106015]
	TIME [epoch: 8.58 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2515958252542352		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.2515958252542352 | validation: 0.3706623248190437]
	TIME [epoch: 8.58 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3213591612334942		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.3213591612334942 | validation: 0.20054944651148288]
	TIME [epoch: 8.58 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19957381194881557		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.19957381194881557 | validation: 0.1960050832657683]
	TIME [epoch: 8.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23780173465083232		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.23780173465083232 | validation: 0.24075356971080902]
	TIME [epoch: 8.58 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18868298044448956		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.18868298044448956 | validation: 0.10901387807194805]
	TIME [epoch: 8.58 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1761009352000114		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.1761009352000114 | validation: 0.2725795316826758]
	TIME [epoch: 8.58 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21599448128147403		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.21599448128147403 | validation: 0.4619422899794602]
	TIME [epoch: 8.59 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18189535007302837		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.18189535007302837 | validation: 0.10170100098799813]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21082582112933798		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.21082582112933798 | validation: 0.18677653551244452]
	TIME [epoch: 8.57 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21487495147856278		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.21487495147856278 | validation: 0.23417543146977396]
	TIME [epoch: 8.57 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1766844632084959		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.1766844632084959 | validation: 0.2492029760825735]
	TIME [epoch: 8.59 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19367364366704426		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.19367364366704426 | validation: 0.2656016291716729]
	TIME [epoch: 8.58 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5316174377381707		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.5316174377381707 | validation: 0.18831955633139713]
	TIME [epoch: 8.57 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19072186885265588		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.19072186885265588 | validation: 0.11529055970505453]
	TIME [epoch: 8.57 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22945864021710377		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.22945864021710377 | validation: 0.1241043882223454]
	TIME [epoch: 8.59 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1958520719127927		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.1958520719127927 | validation: 0.12840156750425602]
	TIME [epoch: 8.58 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24412393801201637		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.24412393801201637 | validation: 0.21496521853583372]
	TIME [epoch: 8.57 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.255126282155416		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.255126282155416 | validation: 0.4292609075154098]
	TIME [epoch: 8.57 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21036795985731643		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.21036795985731643 | validation: 0.16562575406627222]
	TIME [epoch: 8.57 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30306337434175057		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.30306337434175057 | validation: 0.13828791145976133]
	TIME [epoch: 8.59 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16302447755100147		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.16302447755100147 | validation: 0.1678681326355756]
	TIME [epoch: 8.58 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2402983811827339		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.2402983811827339 | validation: 0.17335215539877089]
	TIME [epoch: 8.57 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16662323662353334		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.16662323662353334 | validation: 0.2746071030881787]
	TIME [epoch: 8.57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17645328983424746		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.17645328983424746 | validation: 0.36558035600965133]
	TIME [epoch: 8.59 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21513073271219926		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.21513073271219926 | validation: 0.16105819254375275]
	TIME [epoch: 8.57 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21205918049065292		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.21205918049065292 | validation: 0.16158559754051238]
	TIME [epoch: 8.57 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21170598385959521		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.21170598385959521 | validation: 0.1720794854025553]
	TIME [epoch: 8.57 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19826657509604179		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.19826657509604179 | validation: 0.2793654332574374]
	TIME [epoch: 8.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834254723246322		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.1834254723246322 | validation: 0.3290949839395397]
	TIME [epoch: 8.58 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23985502107769027		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.23985502107769027 | validation: 0.17434007140522426]
	TIME [epoch: 8.57 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18256725365411927		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.18256725365411927 | validation: 0.1552883173961751]
	TIME [epoch: 8.58 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1726511130107835		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.1726511130107835 | validation: 0.3035537417428619]
	TIME [epoch: 8.59 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22363070136278657		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.22363070136278657 | validation: 0.27864246907583184]
	TIME [epoch: 8.57 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24262009142487218		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.24262009142487218 | validation: 0.1613277863018355]
	TIME [epoch: 8.57 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20867810066742493		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.20867810066742493 | validation: 0.1858536736999773]
	TIME [epoch: 8.57 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943897562249599		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.1943897562249599 | validation: 0.4711105573184315]
	TIME [epoch: 8.59 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32209978755430035		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.32209978755430035 | validation: 0.16636538020240652]
	TIME [epoch: 8.58 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21370339468703298		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.21370339468703298 | validation: 0.2603158374613973]
	TIME [epoch: 8.57 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26590822720215984		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.26590822720215984 | validation: 0.12543076077116116]
	TIME [epoch: 8.57 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14573384327846356		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.14573384327846356 | validation: 0.1655581238949998]
	TIME [epoch: 8.59 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19267865852456595		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.19267865852456595 | validation: 0.30794376818986924]
	TIME [epoch: 8.57 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19167242735244844		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.19167242735244844 | validation: 0.12751580406652394]
	TIME [epoch: 8.57 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23667752622413132		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.23667752622413132 | validation: 0.18677704236973983]
	TIME [epoch: 8.57 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16057066823881613		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.16057066823881613 | validation: 0.2772263284811466]
	TIME [epoch: 8.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20973976238425135		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.20973976238425135 | validation: 0.19998853825937346]
	TIME [epoch: 8.57 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26635533378583576		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.26635533378583576 | validation: 0.18319539108144645]
	TIME [epoch: 8.57 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21893606346523664		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.21893606346523664 | validation: 0.2343173659918953]
	TIME [epoch: 8.57 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18654012889819613		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.18654012889819613 | validation: 0.15892653965707385]
	TIME [epoch: 8.59 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18306363665316874		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.18306363665316874 | validation: 0.20527043795814306]
	TIME [epoch: 8.58 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22355831696058778		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.22355831696058778 | validation: 0.19520163313280892]
	TIME [epoch: 8.57 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17951840018309795		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.17951840018309795 | validation: 0.1686828649678419]
	TIME [epoch: 8.57 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17477058488269626		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.17477058488269626 | validation: 0.3024433721344905]
	TIME [epoch: 8.59 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2624264460417326		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.2624264460417326 | validation: 0.3793994587134686]
	TIME [epoch: 8.57 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2254280424784772		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.2254280424784772 | validation: 0.2545108463256675]
	TIME [epoch: 8.57 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19524200287923169		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.19524200287923169 | validation: 0.14674389633293672]
	TIME [epoch: 8.57 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.172885610899149		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.172885610899149 | validation: 0.20640393099704635]
	TIME [epoch: 8.59 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18209185033192396		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.18209185033192396 | validation: 0.21284555274665184]
	TIME [epoch: 8.58 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22167340880125366		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.22167340880125366 | validation: 0.19712035378892273]
	TIME [epoch: 8.57 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2083091100955164		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.2083091100955164 | validation: 0.13014327754935764]
	TIME [epoch: 8.57 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623767590883017		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.1623767590883017 | validation: 0.1695768966824322]
	TIME [epoch: 8.59 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17512878883894853		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.17512878883894853 | validation: 0.25264196596114136]
	TIME [epoch: 8.58 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17898021658895097		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.17898021658895097 | validation: 0.1266468931904257]
	TIME [epoch: 8.57 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22104371045902052		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.22104371045902052 | validation: 0.14867749266729535]
	TIME [epoch: 8.57 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18776677433729777		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.18776677433729777 | validation: 0.21821408398428233]
	TIME [epoch: 8.59 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22091620841714796		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.22091620841714796 | validation: 0.13669691450374494]
	TIME [epoch: 8.57 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21539970024983418		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.21539970024983418 | validation: 0.18097934348685613]
	TIME [epoch: 8.57 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1746866758554448		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.1746866758554448 | validation: 0.17726578497465179]
	TIME [epoch: 8.57 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19967748782409403		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.19967748782409403 | validation: 0.10574919324848903]
	TIME [epoch: 8.59 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1731822766603793		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.1731822766603793 | validation: 0.2501596043336742]
	TIME [epoch: 8.57 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922328474500757		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.1922328474500757 | validation: 0.10918890495808875]
	TIME [epoch: 8.57 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2293606094366699		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.2293606094366699 | validation: 0.36044730836480476]
	TIME [epoch: 8.57 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26386137498215617		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.26386137498215617 | validation: 0.14911205978845693]
	TIME [epoch: 8.59 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17763082811566638		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.17763082811566638 | validation: 0.11126519201919942]
	TIME [epoch: 8.58 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1743053812784291		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.1743053812784291 | validation: 0.6273423872003108]
	TIME [epoch: 8.57 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28609680580536256		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.28609680580536256 | validation: 0.20167460972830487]
	TIME [epoch: 8.57 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14582072081985564		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.14582072081985564 | validation: 0.5272926184383336]
	TIME [epoch: 8.59 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19344452738084905		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.19344452738084905 | validation: 0.18510202509442653]
	TIME [epoch: 8.58 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22688125023867203		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.22688125023867203 | validation: 0.12297728426815216]
	TIME [epoch: 8.57 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541099679592828		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.1541099679592828 | validation: 0.24092677227405018]
	TIME [epoch: 8.57 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20743268093173403		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.20743268093173403 | validation: 0.14957379469406393]
	TIME [epoch: 8.57 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20300704070438558		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.20300704070438558 | validation: 0.1598715329940313]
	TIME [epoch: 8.59 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2551802137703728		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.2551802137703728 | validation: 0.2261256139573456]
	TIME [epoch: 8.57 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21419040851060336		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.21419040851060336 | validation: 0.1847903794296006]
	TIME [epoch: 8.57 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25057230142645814		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.25057230142645814 | validation: 0.11053845570733402]
	TIME [epoch: 8.58 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21278850040469233		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.21278850040469233 | validation: 0.1370405131629103]
	TIME [epoch: 8.59 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16833496990086178		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.16833496990086178 | validation: 0.14408694116959864]
	TIME [epoch: 8.57 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20497286026767406		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.20497286026767406 | validation: 0.12002124557504676]
	TIME [epoch: 8.57 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1847182570384867		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.1847182570384867 | validation: 0.27809915082940984]
	TIME [epoch: 8.57 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23519147884270292		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.23519147884270292 | validation: 0.2194036294903144]
	TIME [epoch: 8.59 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20251714483235786		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.20251714483235786 | validation: 0.2824808729195546]
	TIME [epoch: 8.57 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16354097784712346		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.16354097784712346 | validation: 0.13996837494579112]
	TIME [epoch: 8.57 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656080309307963		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.1656080309307963 | validation: 0.11426991331021732]
	TIME [epoch: 8.57 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19854385706832378		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.19854385706832378 | validation: 0.25739830995424395]
	TIME [epoch: 8.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566030851050939		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.2566030851050939 | validation: 0.3486446262629347]
	TIME [epoch: 8.57 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19416968818361036		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.19416968818361036 | validation: 0.11587851710865474]
	TIME [epoch: 8.57 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18978864204032891		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.18978864204032891 | validation: 0.15611338953633103]
	TIME [epoch: 8.57 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13655972056731017		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.13655972056731017 | validation: 0.19374199129108316]
	TIME [epoch: 8.59 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16754710625661878		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.16754710625661878 | validation: 0.20243544110051398]
	TIME [epoch: 8.58 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1839360596619209		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.1839360596619209 | validation: 0.40973541627604526]
	TIME [epoch: 8.57 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2775700765290745		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.2775700765290745 | validation: 0.17762868773709634]
	TIME [epoch: 8.57 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17089534124571285		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.17089534124571285 | validation: 0.27670910699365864]
	TIME [epoch: 8.59 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18367069477579498		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.18367069477579498 | validation: 0.4347035480627903]
	TIME [epoch: 8.57 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1939993057858194		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.1939993057858194 | validation: 0.22427687864546822]
	TIME [epoch: 8.57 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19523612509394692		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.19523612509394692 | validation: 0.1665496276362938]
	TIME [epoch: 8.57 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906484631578327		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.1906484631578327 | validation: 0.2356806891776107]
	TIME [epoch: 8.59 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19245378479504463		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.19245378479504463 | validation: 0.16154562636288342]
	TIME [epoch: 8.58 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1979964565281262		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.1979964565281262 | validation: 0.10922292520768132]
	TIME [epoch: 8.57 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14070583364002015		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.14070583364002015 | validation: 0.11134457133826198]
	TIME [epoch: 8.57 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28995290600438417		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.28995290600438417 | validation: 0.15836677443127428]
	TIME [epoch: 8.59 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16066924364737362		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.16066924364737362 | validation: 0.20489853360424926]
	TIME [epoch: 8.58 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179666669884447		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.179666669884447 | validation: 0.1654058372268648]
	TIME [epoch: 8.57 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18932869478586367		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.18932869478586367 | validation: 0.13630424568046348]
	TIME [epoch: 8.57 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18702549216252476		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.18702549216252476 | validation: 0.16343649601845345]
	TIME [epoch: 8.59 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18213645694444983		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.18213645694444983 | validation: 0.12618394414241363]
	TIME [epoch: 8.57 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15583161260821846		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.15583161260821846 | validation: 0.17863672427155025]
	TIME [epoch: 8.57 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19570102855443047		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.19570102855443047 | validation: 0.07225494281011838]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1665103021836667		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.1665103021836667 | validation: 0.3303022521165563]
	TIME [epoch: 8.59 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21040034805939561		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.21040034805939561 | validation: 0.7357538778033793]
	TIME [epoch: 8.57 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2755011625560265		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.2755011625560265 | validation: 0.11680839662938594]
	TIME [epoch: 8.57 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17759013620895459		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.17759013620895459 | validation: 0.16240576207679258]
	TIME [epoch: 8.57 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17796235793909357		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.17796235793909357 | validation: 0.118705943098278]
	TIME [epoch: 8.59 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1576011081989807		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.1576011081989807 | validation: 0.1387294580584058]
	TIME [epoch: 8.57 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383171707802558		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.1383171707802558 | validation: 0.26166698755855183]
	TIME [epoch: 8.57 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15750422673651193		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.15750422673651193 | validation: 0.1534191004196378]
	TIME [epoch: 8.57 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20258310809397662		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.20258310809397662 | validation: 0.4028723484976496]
	TIME [epoch: 8.59 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21607630001225037		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.21607630001225037 | validation: 0.16039705412145613]
	TIME [epoch: 8.58 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24036532577634717		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.24036532577634717 | validation: 0.1423241612648951]
	TIME [epoch: 8.57 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084677345406694		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.2084677345406694 | validation: 0.20340361301423227]
	TIME [epoch: 8.57 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16328309127192592		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.16328309127192592 | validation: 0.11147960944839326]
	TIME [epoch: 8.59 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16617928087095085		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.16617928087095085 | validation: 0.12506870792910907]
	TIME [epoch: 8.57 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17511815350235146		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.17511815350235146 | validation: 0.2612200269979603]
	TIME [epoch: 8.57 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20359624465374146		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.20359624465374146 | validation: 0.16824067398579567]
	TIME [epoch: 8.57 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834240136722018		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.1834240136722018 | validation: 0.10654881097190935]
	TIME [epoch: 8.59 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23295262866835018		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.23295262866835018 | validation: 0.20316297372343758]
	TIME [epoch: 8.57 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14993356948061248		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.14993356948061248 | validation: 0.1631493465763523]
	TIME [epoch: 8.57 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670687211507738		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.1670687211507738 | validation: 0.18885423790240458]
	TIME [epoch: 8.57 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15320189179838326		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.15320189179838326 | validation: 0.1984096130154876]
	TIME [epoch: 8.58 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16111273421032032		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.16111273421032032 | validation: 0.2323505500965073]
	TIME [epoch: 8.58 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11962566533522782		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.11962566533522782 | validation: 0.19486965241914178]
	TIME [epoch: 8.57 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18635453898866366		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.18635453898866366 | validation: 0.27065822728467215]
	TIME [epoch: 8.58 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17877406918814945		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.17877406918814945 | validation: 0.19103962996464968]
	TIME [epoch: 8.58 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24275637680280107		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.24275637680280107 | validation: 0.12104807642764054]
	TIME [epoch: 8.58 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13817429947911103		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.13817429947911103 | validation: 0.12537242882353267]
	TIME [epoch: 8.57 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21745344375354683		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.21745344375354683 | validation: 0.19853768258988352]
	TIME [epoch: 8.57 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26887923476689946		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.26887923476689946 | validation: 0.3665385638957789]
	TIME [epoch: 8.57 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2559510992037405		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.2559510992037405 | validation: 0.2821545509045502]
	TIME [epoch: 8.59 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23509673982101384		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.23509673982101384 | validation: 0.3651620812989197]
	TIME [epoch: 8.57 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1606413763248714		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.1606413763248714 | validation: 0.14245692395577825]
	TIME [epoch: 8.57 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14949403246241497		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.14949403246241497 | validation: 0.09520766585699247]
	TIME [epoch: 8.57 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13870400913813535		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.13870400913813535 | validation: 0.3014586631420959]
	TIME [epoch: 8.59 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16427515233834927		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.16427515233834927 | validation: 0.13025038029788516]
	TIME [epoch: 8.58 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17226252146844256		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.17226252146844256 | validation: 0.22967059057499412]
	TIME [epoch: 8.57 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18689543583621088		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.18689543583621088 | validation: 0.15187598599164667]
	TIME [epoch: 8.57 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18691138755868544		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.18691138755868544 | validation: 0.14551524404443417]
	TIME [epoch: 8.59 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15538078894001045		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.15538078894001045 | validation: 0.1433219937518247]
	TIME [epoch: 8.57 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14703332432835503		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.14703332432835503 | validation: 0.1048270163406084]
	TIME [epoch: 8.57 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13138759615347936		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.13138759615347936 | validation: 0.1344527448746077]
	TIME [epoch: 8.58 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12169972854095656		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.12169972854095656 | validation: 0.22105261600787207]
	TIME [epoch: 8.59 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14745587708002192		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.14745587708002192 | validation: 0.25866648991457075]
	TIME [epoch: 8.57 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1838297822537017		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.1838297822537017 | validation: 0.1723276288194187]
	TIME [epoch: 8.58 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15248699521849152		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.15248699521849152 | validation: 0.18069380045982278]
	TIME [epoch: 8.57 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17964268921609108		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.17964268921609108 | validation: 0.16813106487437224]
	TIME [epoch: 8.59 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15902304440148593		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.15902304440148593 | validation: 0.17102900898783885]
	TIME [epoch: 8.58 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15283626635957628		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.15283626635957628 | validation: 0.09333186667589932]
	TIME [epoch: 8.57 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1177908596678405		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.1177908596678405 | validation: 0.2502413339591824]
	TIME [epoch: 8.57 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11749634749942184		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.11749634749942184 | validation: 0.1370588042960525]
	TIME [epoch: 8.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13563759494890484		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.13563759494890484 | validation: 0.15051341088385028]
	TIME [epoch: 8.58 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14494427846812794		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.14494427846812794 | validation: 0.11670334421998808]
	TIME [epoch: 8.58 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.225989475816781		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.225989475816781 | validation: 0.2993163554373135]
	TIME [epoch: 8.57 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17875629466502077		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.17875629466502077 | validation: 0.29498566590619923]
	TIME [epoch: 8.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14449090036773973		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.14449090036773973 | validation: 0.10176527662848281]
	TIME [epoch: 8.58 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12421918568314608		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.12421918568314608 | validation: 0.1905695887201179]
	TIME [epoch: 8.57 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12308790741044369		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.12308790741044369 | validation: 0.14755198842630526]
	TIME [epoch: 8.58 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18164010259563818		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.18164010259563818 | validation: 0.10743038371455702]
	TIME [epoch: 8.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1673159990184951		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.1673159990184951 | validation: 0.09800763438962379]
	TIME [epoch: 8.58 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124678596642915		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.11124678596642915 | validation: 0.10885886343092814]
	TIME [epoch: 8.57 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15174630510970785		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.15174630510970785 | validation: 0.14048006933918936]
	TIME [epoch: 8.57 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18280681379108732		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.18280681379108732 | validation: 0.1238108801490728]
	TIME [epoch: 8.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1936597607014045		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.1936597607014045 | validation: 0.07412128647016493]
	TIME [epoch: 8.58 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12192050531977368		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.12192050531977368 | validation: 0.14174004876098198]
	TIME [epoch: 8.57 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13804256579291527		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.13804256579291527 | validation: 0.07108058897834298]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14686514579248924		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.14686514579248924 | validation: 0.0702919105427372]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_759.pth
	Model improved!!!
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15954976194302095		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.15954976194302095 | validation: 0.09756848601805389]
	TIME [epoch: 8.58 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1424134828590347		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.1424134828590347 | validation: 0.22305829461515136]
	TIME [epoch: 8.58 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14882797482457422		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.14882797482457422 | validation: 0.13758445193801438]
	TIME [epoch: 8.58 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11562450964110275		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.11562450964110275 | validation: 0.11812432916495821]
	TIME [epoch: 8.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1916288162987619		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.1916288162987619 | validation: 0.07245302098743944]
	TIME [epoch: 8.58 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11253554001024349		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.11253554001024349 | validation: 0.2481602847411098]
	TIME [epoch: 8.57 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14416902939186238		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.14416902939186238 | validation: 0.09243293337301325]
	TIME [epoch: 8.58 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12048570670003558		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.12048570670003558 | validation: 0.12703666689944945]
	TIME [epoch: 8.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14956600790213923		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.14956600790213923 | validation: 0.2935298583577438]
	TIME [epoch: 8.57 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1720492546565375		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.1720492546565375 | validation: 0.12716786094708007]
	TIME [epoch: 8.58 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18400840528573814		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.18400840528573814 | validation: 0.2411606912515199]
	TIME [epoch: 8.57 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1419177264809607		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.1419177264809607 | validation: 0.098064834717519]
	TIME [epoch: 8.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14607683658691212		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.14607683658691212 | validation: 0.12458853401418424]
	TIME [epoch: 8.58 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19394375240973322		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.19394375240973322 | validation: 0.09323163745105584]
	TIME [epoch: 8.57 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11027840096717365		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.11027840096717365 | validation: 0.14824538546194127]
	TIME [epoch: 8.57 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13859455310701918		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.13859455310701918 | validation: 0.15891523903599797]
	TIME [epoch: 8.59 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14646857394747065		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.14646857394747065 | validation: 0.12500848793615532]
	TIME [epoch: 8.57 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1608083901083919		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.1608083901083919 | validation: 0.10850021309677463]
	TIME [epoch: 8.57 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12431494917570358		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.12431494917570358 | validation: 0.09238310478548649]
	TIME [epoch: 8.58 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13944999360219357		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.13944999360219357 | validation: 0.11509636119537936]
	TIME [epoch: 8.59 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18265466647998124		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.18265466647998124 | validation: 0.17425929813377158]
	TIME [epoch: 8.58 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16773179868287597		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.16773179868287597 | validation: 0.1726499934581981]
	TIME [epoch: 8.57 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12161534758906786		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.12161534758906786 | validation: 0.20396577447322028]
	TIME [epoch: 8.57 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16696567208921637		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.16696567208921637 | validation: 0.09322782706520931]
	TIME [epoch: 8.58 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15645017518168114		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.15645017518168114 | validation: 0.22307910053204555]
	TIME [epoch: 8.59 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267760667924675		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.1267760667924675 | validation: 0.07138752998759927]
	TIME [epoch: 8.58 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1298593259597008		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.1298593259597008 | validation: 0.09303991864371614]
	TIME [epoch: 8.58 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12815981337143736		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.12815981337143736 | validation: 0.0995353071205487]
	TIME [epoch: 8.59 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2100636041869189		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.2100636041869189 | validation: 0.12304190123912348]
	TIME [epoch: 8.58 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378610553806468		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.12378610553806468 | validation: 0.1049290157393398]
	TIME [epoch: 8.57 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11116294844466426		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.11116294844466426 | validation: 0.12025705197111294]
	TIME [epoch: 8.57 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17828114157589509		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.17828114157589509 | validation: 0.11322268165166033]
	TIME [epoch: 8.57 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11347977304146173		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.11347977304146173 | validation: 0.21982869699251267]
	TIME [epoch: 8.59 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1478359412963282		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.1478359412963282 | validation: 0.12352476841943835]
	TIME [epoch: 8.57 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12199727252159467		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.12199727252159467 | validation: 0.13366289498493722]
	TIME [epoch: 8.57 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12329840368136036		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.12329840368136036 | validation: 0.08625058379319414]
	TIME [epoch: 8.57 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11676020591597029		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.11676020591597029 | validation: 0.07946414778687787]
	TIME [epoch: 8.59 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1381948021409552		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.1381948021409552 | validation: 0.16647463846006522]
	TIME [epoch: 8.57 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12414749608422981		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.12414749608422981 | validation: 0.13301687415574526]
	TIME [epoch: 8.57 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13070224745949396		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.13070224745949396 | validation: 0.16617651111814147]
	TIME [epoch: 8.57 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1181377993296705		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.1181377993296705 | validation: 0.250563493978657]
	TIME [epoch: 8.59 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13828098824942853		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.13828098824942853 | validation: 0.18933652004021678]
	TIME [epoch: 8.57 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14402036163384951		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.14402036163384951 | validation: 0.08533185925162516]
	TIME [epoch: 8.56 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15404970048305738		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.15404970048305738 | validation: 0.08376088983301519]
	TIME [epoch: 8.57 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1441826355944113		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.1441826355944113 | validation: 0.08181145972838205]
	TIME [epoch: 8.59 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13556729856007335		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.13556729856007335 | validation: 0.14728422759122897]
	TIME [epoch: 8.57 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15293258757596848		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.15293258757596848 | validation: 0.10977132146017779]
	TIME [epoch: 8.57 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1439889462505965		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.1439889462505965 | validation: 0.11858390363818691]
	TIME [epoch: 8.57 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1574930800268391		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.1574930800268391 | validation: 0.1048288340499789]
	TIME [epoch: 8.59 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373366028761531		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.1373366028761531 | validation: 0.09358687145164962]
	TIME [epoch: 8.57 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1555201504923055		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.1555201504923055 | validation: 0.11771522043006127]
	TIME [epoch: 8.57 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16357496991416987		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.16357496991416987 | validation: 0.4866454119472947]
	TIME [epoch: 8.57 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18392160490150125		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.18392160490150125 | validation: 0.1010326767716061]
	TIME [epoch: 8.59 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.130480738628331		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.130480738628331 | validation: 0.17126328828920923]
	TIME [epoch: 8.58 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12588612140809935		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.12588612140809935 | validation: 0.15263195173174546]
	TIME [epoch: 8.57 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14516048282494548		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.14516048282494548 | validation: 0.09718606386852334]
	TIME [epoch: 8.57 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15872932520902938		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.15872932520902938 | validation: 0.13704847191189912]
	TIME [epoch: 8.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13143036755333223		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.13143036755333223 | validation: 0.15113068040486818]
	TIME [epoch: 8.57 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1209568147852538		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.1209568147852538 | validation: 0.18130901071063438]
	TIME [epoch: 8.57 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13490317120668044		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.13490317120668044 | validation: 0.13341595667446945]
	TIME [epoch: 8.57 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525491901043989		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.1525491901043989 | validation: 0.18600091483550318]
	TIME [epoch: 8.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14708381422425498		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.14708381422425498 | validation: 0.12437776448900432]
	TIME [epoch: 8.57 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11884923047573404		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.11884923047573404 | validation: 0.08307478666848087]
	TIME [epoch: 8.57 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11437598218552118		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.11437598218552118 | validation: 0.1308258730883102]
	TIME [epoch: 8.57 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13782025756959876		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.13782025756959876 | validation: 0.10272197039569672]
	TIME [epoch: 8.59 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1037858097521122		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.1037858097521122 | validation: 0.09513462262480422]
	TIME [epoch: 8.57 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12253241697259468		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.12253241697259468 | validation: 0.19488096812112884]
	TIME [epoch: 8.57 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279643916773908		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.1279643916773908 | validation: 0.10991897060186792]
	TIME [epoch: 8.57 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1542687725057845		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.1542687725057845 | validation: 0.14339418887663508]
	TIME [epoch: 8.59 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481513012620383		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.1481513012620383 | validation: 0.05926705991596321]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_829.pth
	Model improved!!!
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17998530654505968		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.17998530654505968 | validation: 0.16761337588745015]
	TIME [epoch: 8.58 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12834503670492378		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.12834503670492378 | validation: 0.12862125569978497]
	TIME [epoch: 8.58 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.140861411498789		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.140861411498789 | validation: 0.12136005073453063]
	TIME [epoch: 8.59 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12563460321585768		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.12563460321585768 | validation: 0.12369989678441141]
	TIME [epoch: 8.58 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12118014143867006		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.12118014143867006 | validation: 0.15322541853834803]
	TIME [epoch: 8.58 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12612420410989558		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.12612420410989558 | validation: 0.1960070683276081]
	TIME [epoch: 8.58 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18238784494989643		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.18238784494989643 | validation: 0.15114858339189965]
	TIME [epoch: 8.59 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14707718824286814		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.14707718824286814 | validation: 0.12305009610527692]
	TIME [epoch: 8.59 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15753451236315213		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.15753451236315213 | validation: 0.10303226803018287]
	TIME [epoch: 8.58 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22247922107825305		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.22247922107825305 | validation: 0.14205308865398858]
	TIME [epoch: 8.58 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13669111854409674		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.13669111854409674 | validation: 0.08745836955140174]
	TIME [epoch: 8.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1535048830594629		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.1535048830594629 | validation: 0.13639280651890176]
	TIME [epoch: 8.58 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1693524717362207		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.1693524717362207 | validation: 0.24542423000500768]
	TIME [epoch: 8.57 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10982233568502564		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.10982233568502564 | validation: 0.12572360925841317]
	TIME [epoch: 8.57 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1486280603715801		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.1486280603715801 | validation: 0.09588659308437468]
	TIME [epoch: 8.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1247535100344482		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.1247535100344482 | validation: 0.08353078041134773]
	TIME [epoch: 8.58 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09944954586376878		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.09944954586376878 | validation: 0.11341973849287122]
	TIME [epoch: 8.58 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12208478844020418		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.12208478844020418 | validation: 0.09148135023555776]
	TIME [epoch: 8.57 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15250214085562372		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.15250214085562372 | validation: 0.20328142525795487]
	TIME [epoch: 8.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14806034470795898		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.14806034470795898 | validation: 0.07914093334083618]
	TIME [epoch: 8.58 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12699857341819848		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.12699857341819848 | validation: 0.09246746802761693]
	TIME [epoch: 8.58 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16969951263734095		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.16969951263734095 | validation: 0.1101989839290292]
	TIME [epoch: 8.58 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15154976323017194		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.15154976323017194 | validation: 0.135186832257497]
	TIME [epoch: 8.59 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12137124240314826		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.12137124240314826 | validation: 0.20330197358245355]
	TIME [epoch: 8.59 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18104012100303563		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.18104012100303563 | validation: 0.16842564379729252]
	TIME [epoch: 8.58 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11609514105701117		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.11609514105701117 | validation: 0.09011777716336616]
	TIME [epoch: 8.58 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09590132001885521		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.09590132001885521 | validation: 0.08067340849347804]
	TIME [epoch: 8.59 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11770051978717924		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.11770051978717924 | validation: 0.15666854755357768]
	TIME [epoch: 8.59 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11162240632312226		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.11162240632312226 | validation: 0.1412077426511157]
	TIME [epoch: 8.58 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12355679325287983		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.12355679325287983 | validation: 0.13276453729384532]
	TIME [epoch: 8.58 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1085644550260018		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.1085644550260018 | validation: 0.16352188874040818]
	TIME [epoch: 8.58 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13523206301236634		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.13523206301236634 | validation: 0.3186316533185258]
	TIME [epoch: 8.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13001910247821083		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.13001910247821083 | validation: 0.11334552882386462]
	TIME [epoch: 8.58 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11317686915013872		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.11317686915013872 | validation: 0.12074526482140313]
	TIME [epoch: 8.58 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15207150243370776		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.15207150243370776 | validation: 0.20424948692794556]
	TIME [epoch: 8.58 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09665946985121757		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.09665946985121757 | validation: 0.1213050209609579]
	TIME [epoch: 8.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14978131116346183		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.14978131116346183 | validation: 0.12198157861569399]
	TIME [epoch: 8.59 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0898283461089469		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.0898283461089469 | validation: 0.12595103184973738]
	TIME [epoch: 8.58 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10721196464780289		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.10721196464780289 | validation: 0.156010387473689]
	TIME [epoch: 8.58 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11395602700671167		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.11395602700671167 | validation: 0.08532841238557504]
	TIME [epoch: 8.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11008806222852911		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.11008806222852911 | validation: 0.11568871241767975]
	TIME [epoch: 8.58 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528340857025624		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.10528340857025624 | validation: 0.16325432374811252]
	TIME [epoch: 8.57 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1774995644256519		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.1774995644256519 | validation: 0.10659872018519692]
	TIME [epoch: 8.58 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1112764914107954		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.1112764914107954 | validation: 0.11330061016774792]
	TIME [epoch: 8.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09252550137468857		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.09252550137468857 | validation: 0.10064616003605784]
	TIME [epoch: 8.58 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10696652906697754		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.10696652906697754 | validation: 0.16375837001525]
	TIME [epoch: 8.58 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013676502558744		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.1013676502558744 | validation: 0.10793221067324742]
	TIME [epoch: 8.58 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13569772011326672		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.13569772011326672 | validation: 0.13409277050360524]
	TIME [epoch: 8.59 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1515985092680513		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.1515985092680513 | validation: 0.13432315136915846]
	TIME [epoch: 8.58 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14125914337194348		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.14125914337194348 | validation: 0.09893579246568965]
	TIME [epoch: 8.58 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12649003379921614		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.12649003379921614 | validation: 0.12968344758162614]
	TIME [epoch: 8.58 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11874500635127468		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.11874500635127468 | validation: 0.10002916019303423]
	TIME [epoch: 8.59 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09276873615789		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.09276873615789 | validation: 0.09283198299580539]
	TIME [epoch: 8.58 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12704640842885767		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.12704640842885767 | validation: 0.08956192301271726]
	TIME [epoch: 8.58 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11155303465188357		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.11155303465188357 | validation: 0.07529919909400351]
	TIME [epoch: 8.57 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10621676096770194		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.10621676096770194 | validation: 0.09129524199239289]
	TIME [epoch: 8.63 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12182061331273424		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.12182061331273424 | validation: 0.1000059568793987]
	TIME [epoch: 8.57 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11544060987308886		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.11544060987308886 | validation: 0.13191775022934044]
	TIME [epoch: 8.58 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12850079337695397		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.12850079337695397 | validation: 0.12135626081566897]
	TIME [epoch: 8.57 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588075279173344		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.09588075279173344 | validation: 0.06485128668178897]
	TIME [epoch: 8.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17303123092074885		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.17303123092074885 | validation: 0.062209714233185234]
	TIME [epoch: 8.58 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10708624161687903		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.10708624161687903 | validation: 0.24502722645584832]
	TIME [epoch: 8.58 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2242855610160363		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.2242855610160363 | validation: 0.21080477564287625]
	TIME [epoch: 8.58 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13366303361130152		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.13366303361130152 | validation: 0.12695767509791728]
	TIME [epoch: 8.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16313896981943696		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.16313896981943696 | validation: 0.20053569470879348]
	TIME [epoch: 8.58 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11368592639730371		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.11368592639730371 | validation: 0.12588728538623145]
	TIME [epoch: 8.58 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772851686474994		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.11772851686474994 | validation: 0.10706316176712025]
	TIME [epoch: 8.58 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10299181008623352		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.10299181008623352 | validation: 0.11058779329430146]
	TIME [epoch: 8.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07364528785155705		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.07364528785155705 | validation: 0.06798755027586703]
	TIME [epoch: 8.58 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08756534170965574		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.08756534170965574 | validation: 0.08613912808141824]
	TIME [epoch: 8.57 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11699550102627174		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.11699550102627174 | validation: 0.13316578547284555]
	TIME [epoch: 8.58 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12482965042381744		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.12482965042381744 | validation: 0.1611622057675024]
	TIME [epoch: 8.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.121929997315353		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.121929997315353 | validation: 0.38548143452792716]
	TIME [epoch: 8.58 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1543664614032992		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.1543664614032992 | validation: 0.10456944477469488]
	TIME [epoch: 8.58 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10718751637904293		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.10718751637904293 | validation: 0.08727471317378734]
	TIME [epoch: 8.57 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09468084744725766		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.09468084744725766 | validation: 0.10770085340032903]
	TIME [epoch: 8.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0872546122690037		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.0872546122690037 | validation: 0.22967514637823838]
	TIME [epoch: 8.58 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256470475830253		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.1256470475830253 | validation: 0.1432149708982673]
	TIME [epoch: 8.57 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1206688787231057		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.1206688787231057 | validation: 0.08908522817760114]
	TIME [epoch: 8.58 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10189713965223417		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.10189713965223417 | validation: 0.1713059119757465]
	TIME [epoch: 8.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12176015720409236		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.12176015720409236 | validation: 0.14457594480487002]
	TIME [epoch: 8.58 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12665172045421144		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.12665172045421144 | validation: 0.08715593808811263]
	TIME [epoch: 8.58 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11674180549968813		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.11674180549968813 | validation: 0.10352869454752209]
	TIME [epoch: 8.57 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1078001877695209		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.1078001877695209 | validation: 0.17071671082806647]
	TIME [epoch: 8.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10167573680221134		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.10167573680221134 | validation: 0.09268989821287071]
	TIME [epoch: 8.58 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08742597815981677		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.08742597815981677 | validation: 0.09355480365123]
	TIME [epoch: 8.58 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11220171845334012		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.11220171845334012 | validation: 0.1084673858760731]
	TIME [epoch: 8.57 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11027205992720876		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.11027205992720876 | validation: 0.12717048971712197]
	TIME [epoch: 8.59 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08772337548909571		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.08772337548909571 | validation: 0.12008575808529487]
	TIME [epoch: 8.58 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.128221919530842		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.128221919530842 | validation: 0.18489402870782323]
	TIME [epoch: 8.57 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12397451145253298		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.12397451145253298 | validation: 0.1516341193062453]
	TIME [epoch: 8.57 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12472836431774734		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.12472836431774734 | validation: 0.13092149629383446]
	TIME [epoch: 8.58 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10096083578933128		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.10096083578933128 | validation: 0.15516343641302263]
	TIME [epoch: 8.58 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12111666945349635		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.12111666945349635 | validation: 0.1393163194211443]
	TIME [epoch: 8.57 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095248648185229		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.1095248648185229 | validation: 0.0973434065524858]
	TIME [epoch: 8.57 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08539456748899667		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.08539456748899667 | validation: 0.076224045585787]
	TIME [epoch: 8.57 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10929464380767703		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.10929464380767703 | validation: 0.0751438850058842]
	TIME [epoch: 8.59 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11918580694648777		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.11918580694648777 | validation: 0.1373369931250631]
	TIME [epoch: 8.57 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11254174596281923		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.11254174596281923 | validation: 0.11877569748676842]
	TIME [epoch: 8.57 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09763464730403557		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.09763464730403557 | validation: 0.10102493210395846]
	TIME [epoch: 8.57 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07578581932614518		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.07578581932614518 | validation: 0.0874731939174454]
	TIME [epoch: 8.59 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08587272268808528		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.08587272268808528 | validation: 0.18682891877283192]
	TIME [epoch: 8.57 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12764133705940825		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.12764133705940825 | validation: 0.05307224410095557]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_932.pth
	Model improved!!!
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10272291449053231		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.10272291449053231 | validation: 0.15312271670704758]
	TIME [epoch: 8.58 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14075943213247671		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.14075943213247671 | validation: 0.14581116934218608]
	TIME [epoch: 8.59 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12764848825576974		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.12764848825576974 | validation: 0.106950927566496]
	TIME [epoch: 8.57 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10614633528409985		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.10614633528409985 | validation: 0.11914080122025487]
	TIME [epoch: 8.57 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0973150614644604		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.0973150614644604 | validation: 0.13084303596461008]
	TIME [epoch: 8.57 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12897066314721978		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.12897066314721978 | validation: 0.18224214369496491]
	TIME [epoch: 8.59 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09098342394594743		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.09098342394594743 | validation: 0.10946780824384494]
	TIME [epoch: 8.57 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09267369021772194		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.09267369021772194 | validation: 0.13272899453746873]
	TIME [epoch: 8.57 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09742928248900605		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.09742928248900605 | validation: 0.09688474735763622]
	TIME [epoch: 8.57 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09782809017710624		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.09782809017710624 | validation: 0.06563631353343416]
	TIME [epoch: 8.59 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11395621102589773		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.11395621102589773 | validation: 0.1434651005726579]
	TIME [epoch: 8.57 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09147788239569563		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.09147788239569563 | validation: 0.145272721079506]
	TIME [epoch: 8.57 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08174113535229424		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.08174113535229424 | validation: 0.09529735272847717]
	TIME [epoch: 8.57 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09164663883533354		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.09164663883533354 | validation: 0.05581152336853258]
	TIME [epoch: 8.59 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08532604537229221		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.08532604537229221 | validation: 0.12955360289296466]
	TIME [epoch: 8.57 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863663810034758		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.0863663810034758 | validation: 0.13727368580462923]
	TIME [epoch: 8.56 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16444184731365932		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.16444184731365932 | validation: 0.11429532110112631]
	TIME [epoch: 8.57 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0902749757354657		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.0902749757354657 | validation: 0.10467441119260268]
	TIME [epoch: 8.59 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11200816614453075		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.11200816614453075 | validation: 0.12605564559384907]
	TIME [epoch: 8.57 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13071703052609204		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.13071703052609204 | validation: 0.09771059684571756]
	TIME [epoch: 8.57 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102206773329731		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.12102206773329731 | validation: 0.08756024535663723]
	TIME [epoch: 8.57 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18199161352793686		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.18199161352793686 | validation: 0.08864060512504318]
	TIME [epoch: 8.59 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09840645469678369		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.09840645469678369 | validation: 0.08984869332613764]
	TIME [epoch: 8.57 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08075979769242424		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.08075979769242424 | validation: 0.07686331988838455]
	TIME [epoch: 8.57 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10595008868850438		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.10595008868850438 | validation: 0.12285497417781366]
	TIME [epoch: 8.57 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11672095866147161		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.11672095866147161 | validation: 0.1551457472792592]
	TIME [epoch: 8.59 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13059576739377707		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.13059576739377707 | validation: 0.11114305267543159]
	TIME [epoch: 8.57 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08928400059034165		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.08928400059034165 | validation: 0.11218325109564153]
	TIME [epoch: 8.57 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08776082605141543		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.08776082605141543 | validation: 0.11597373653962056]
	TIME [epoch: 8.57 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09809969582356681		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.09809969582356681 | validation: 0.10028241691304571]
	TIME [epoch: 8.59 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11369733976599365		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.11369733976599365 | validation: 0.17111009419617335]
	TIME [epoch: 8.57 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10904577278557195		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.10904577278557195 | validation: 0.13645852994619495]
	TIME [epoch: 8.57 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09263279098534502		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.09263279098534502 | validation: 0.07032823727932005]
	TIME [epoch: 8.57 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11105899269643771		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.11105899269643771 | validation: 0.10489621641118435]
	TIME [epoch: 8.59 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1278367913587784		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.1278367913587784 | validation: 0.09689841978226885]
	TIME [epoch: 8.57 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07329428297491539		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.07329428297491539 | validation: 0.059404446963515684]
	TIME [epoch: 8.57 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09773367601767383		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.09773367601767383 | validation: 0.0802799006708197]
	TIME [epoch: 8.57 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12117972765869		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.12117972765869 | validation: 0.08610084602318115]
	TIME [epoch: 8.59 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1006342632046878		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.1006342632046878 | validation: 0.11000714843564621]
	TIME [epoch: 8.57 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10733678457286308		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.10733678457286308 | validation: 0.08103421797611607]
	TIME [epoch: 8.56 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08723436203479784		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.08723436203479784 | validation: 0.13596568189004243]
	TIME [epoch: 8.57 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13491502944978756		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.13491502944978756 | validation: 0.07742970961802718]
	TIME [epoch: 8.59 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08489355948956835		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.08489355948956835 | validation: 0.08664618194062929]
	TIME [epoch: 8.57 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12206096541941173		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.12206096541941173 | validation: 0.16295708706085676]
	TIME [epoch: 8.57 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12789599947901742		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.12789599947901742 | validation: 0.08069118578811832]
	TIME [epoch: 8.56 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09313294838700094		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.09313294838700094 | validation: 0.09833571972653701]
	TIME [epoch: 8.59 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761992673481478		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.0761992673481478 | validation: 0.07289829619560939]
	TIME [epoch: 8.57 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09198739105241305		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.09198739105241305 | validation: 0.08861768613573075]
	TIME [epoch: 8.57 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09327340970806076		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.09327340970806076 | validation: 0.09708166378370212]
	TIME [epoch: 8.57 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832895276065558		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.0832895276065558 | validation: 0.1844934162664268]
	TIME [epoch: 8.58 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11210459095846714		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.11210459095846714 | validation: 0.06994559711314366]
	TIME [epoch: 8.58 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07643563174675451		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.07643563174675451 | validation: 0.07126011547649047]
	TIME [epoch: 8.57 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08924592188441273		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.08924592188441273 | validation: 0.15443490881994454]
	TIME [epoch: 8.57 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1070258739923264		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.1070258739923264 | validation: 0.2126849097949816]
	TIME [epoch: 8.58 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1204170950578137		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.1204170950578137 | validation: 0.2964373733201281]
	TIME [epoch: 8.58 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10427399861868984		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.10427399861868984 | validation: 0.10598706892910506]
	TIME [epoch: 8.57 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09945250844507841		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.09945250844507841 | validation: 0.08047232048114908]
	TIME [epoch: 8.57 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07709707226013915		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.07709707226013915 | validation: 0.13376545705050924]
	TIME [epoch: 8.57 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08405048340015915		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.08405048340015915 | validation: 0.09311157636932524]
	TIME [epoch: 8.58 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09297359343804885		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.09297359343804885 | validation: 0.12056668757167294]
	TIME [epoch: 8.57 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11016336611190336		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.11016336611190336 | validation: 0.0626934798996549]
	TIME [epoch: 8.57 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07366416132176587		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.07366416132176587 | validation: 0.07525094472341069]
	TIME [epoch: 8.57 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08959414188908958		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.08959414188908958 | validation: 0.1421754420142814]
	TIME [epoch: 8.58 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08232156727208302		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.08232156727208302 | validation: 0.0844620673410528]
	TIME [epoch: 8.58 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09594677739873428		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.09594677739873428 | validation: 0.16470245507515863]
	TIME [epoch: 8.57 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09431104174597593		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.09431104174597593 | validation: 0.09019550384635025]
	TIME [epoch: 8.57 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851477710154369		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.0851477710154369 | validation: 0.0748506042916918]
	TIME [epoch: 8.58 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09539573713263086		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.09539573713263086 | validation: 0.14468508767963817]
	TIME [epoch: 8.57 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09683474716568138		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.09683474716568138 | validation: 0.09200798194959534]
	TIME [epoch: 8.57 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08497810141579937		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.08497810141579937 | validation: 0.09566419333347465]
	TIME [epoch: 8.57 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10445898363802344		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.10445898363802344 | validation: 0.06362881811567062]
	TIME [epoch: 8.59 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09742862236825275		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.09742862236825275 | validation: 0.10088957578546967]
	TIME [epoch: 8.56 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08934346197093664		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.08934346197093664 | validation: 0.10458198286533754]
	TIME [epoch: 8.57 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434585703613058		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.09434585703613058 | validation: 0.11546133901630964]
	TIME [epoch: 8.56 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07734951644086221		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.07734951644086221 | validation: 0.06779511514963944]
	TIME [epoch: 8.59 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07953829775841603		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.07953829775841603 | validation: 0.07258571848453854]
	TIME [epoch: 8.57 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07030493371721225		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.07030493371721225 | validation: 0.06025282651896788]
	TIME [epoch: 8.57 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599006442761781		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.07599006442761781 | validation: 0.10224902194466184]
	TIME [epoch: 8.58 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10193333174692916		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.10193333174692916 | validation: 0.11946803786688953]
	TIME [epoch: 8.57 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09510313482830299		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.09510313482830299 | validation: 0.10984537593823232]
	TIME [epoch: 8.56 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07737471987689541		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.07737471987689541 | validation: 0.07950563401132937]
	TIME [epoch: 8.57 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09057313665802663		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.09057313665802663 | validation: 0.1317988358634638]
	TIME [epoch: 8.59 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848862130159049		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.0848862130159049 | validation: 0.06020897709057191]
	TIME [epoch: 8.57 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07667925223150601		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.07667925223150601 | validation: 0.08053215098648421]
	TIME [epoch: 8.57 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08523630897649653		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.08523630897649653 | validation: 0.07925399981571478]
	TIME [epoch: 8.56 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10086277549178732		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.10086277549178732 | validation: 0.10432265605866056]
	TIME [epoch: 8.58 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10986681140204924		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.10986681140204924 | validation: 0.14735016538711762]
	TIME [epoch: 8.57 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0889156578572078		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.0889156578572078 | validation: 0.14904496783425014]
	TIME [epoch: 8.57 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1225904142403583		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.1225904142403583 | validation: 0.16238875014912393]
	TIME [epoch: 8.56 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09403846791572726		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.09403846791572726 | validation: 0.08238630969399069]
	TIME [epoch: 8.58 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11832983841331038		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.11832983841331038 | validation: 0.08239768894096376]
	TIME [epoch: 8.57 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10339700236573664		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.10339700236573664 | validation: 0.09447314996247376]
	TIME [epoch: 8.56 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10784600145186896		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.10784600145186896 | validation: 0.10741500773431886]
	TIME [epoch: 8.56 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11798252823845672		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.11798252823845672 | validation: 0.06658796119553358]
	TIME [epoch: 8.59 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09070736075672117		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.09070736075672117 | validation: 0.08715153986468731]
	TIME [epoch: 8.57 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10093838385205312		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.10093838385205312 | validation: 0.10307363629173286]
	TIME [epoch: 8.56 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10943232452972018		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.10943232452972018 | validation: 0.12698656439397207]
	TIME [epoch: 8.56 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09838062403125478		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.09838062403125478 | validation: 0.0950794786516844]
	TIME [epoch: 8.59 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09091299467763814		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.09091299467763814 | validation: 0.09192229866070123]
	TIME [epoch: 8.56 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08905029045245072		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.08905029045245072 | validation: 0.10046511982407769]
	TIME [epoch: 8.56 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08827446989726975		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.08827446989726975 | validation: 0.05019864668747293]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09276940541319478		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.09276940541319478 | validation: 0.10211177445978922]
	TIME [epoch: 8.58 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09023606717601476		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.09023606717601476 | validation: 0.11124992067207974]
	TIME [epoch: 8.56 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06987962604621142		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.06987962604621142 | validation: 0.08551019624476815]
	TIME [epoch: 8.57 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223680443652135		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.09223680443652135 | validation: 0.11204294091676309]
	TIME [epoch: 8.57 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09048388817877026		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.09048388817877026 | validation: 0.11142368933140813]
	TIME [epoch: 8.57 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08923092406918534		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.08923092406918534 | validation: 0.06458230780143033]
	TIME [epoch: 8.56 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08267918653338396		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.08267918653338396 | validation: 0.10149915223200395]
	TIME [epoch: 8.57 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07928980132379751		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.07928980132379751 | validation: 0.08064352768778621]
	TIME [epoch: 8.59 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09549244007919112		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.09549244007919112 | validation: 0.05975466210982393]
	TIME [epoch: 8.56 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07283206830850794		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.07283206830850794 | validation: 0.0754805976884544]
	TIME [epoch: 8.56 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09796959426014351		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.09796959426014351 | validation: 0.09030897537317517]
	TIME [epoch: 8.57 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08860139268172627		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.08860139268172627 | validation: 0.17509399095944705]
	TIME [epoch: 8.58 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09295966545389125		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.09295966545389125 | validation: 0.09474937482957119]
	TIME [epoch: 8.57 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09903239804222173		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.09903239804222173 | validation: 0.08895267290264562]
	TIME [epoch: 8.56 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10799755244814684		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.10799755244814684 | validation: 0.09147305544562662]
	TIME [epoch: 8.56 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09282459680225572		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.09282459680225572 | validation: 0.10340163047658377]
	TIME [epoch: 8.58 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09515065028524555		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.09515065028524555 | validation: 0.08345415003135986]
	TIME [epoch: 8.57 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764401785858109		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.0764401785858109 | validation: 0.15518438167735682]
	TIME [epoch: 8.56 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08842643552503644		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.08842643552503644 | validation: 0.08483579240196995]
	TIME [epoch: 8.56 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743512647039304		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.09743512647039304 | validation: 0.17364926860790705]
	TIME [epoch: 8.58 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1748182975808987		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.1748182975808987 | validation: 0.13418924211555716]
	TIME [epoch: 8.57 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11489585471404258		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.11489585471404258 | validation: 0.08331970362331279]
	TIME [epoch: 8.57 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08728854434696441		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.08728854434696441 | validation: 0.09452204527516278]
	TIME [epoch: 8.56 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08033033059858521		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.08033033059858521 | validation: 0.08855577480567445]
	TIME [epoch: 8.59 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07771059345492608		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.07771059345492608 | validation: 0.04407880960209723]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1058.pth
	Model improved!!!
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408302998372142		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.06408302998372142 | validation: 0.048608444027408534]
	TIME [epoch: 8.57 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.073908693221813		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.073908693221813 | validation: 0.10534103534091946]
	TIME [epoch: 8.57 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722983627921478		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.0722983627921478 | validation: 0.06457945729964472]
	TIME [epoch: 8.59 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08510354518493421		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.08510354518493421 | validation: 0.05625417234601769]
	TIME [epoch: 8.57 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10549166044347716		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.10549166044347716 | validation: 0.10448752097870803]
	TIME [epoch: 8.57 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08454272157311679		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.08454272157311679 | validation: 0.08382346637688118]
	TIME [epoch: 8.58 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07898590638646066		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.07898590638646066 | validation: 0.10119149880731751]
	TIME [epoch: 8.58 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07223025766404542		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.07223025766404542 | validation: 0.06821617518629422]
	TIME [epoch: 8.57 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0783348518337271		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.0783348518337271 | validation: 0.06268289428642919]
	TIME [epoch: 8.57 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09525903585784214		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.09525903585784214 | validation: 0.1229337174638071]
	TIME [epoch: 8.59 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08923324311299334		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.08923324311299334 | validation: 0.18205701403476116]
	TIME [epoch: 8.57 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10963114822099682		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.10963114822099682 | validation: 0.07144167077665001]
	TIME [epoch: 8.57 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09892434267710537		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.09892434267710537 | validation: 0.18753702374389744]
	TIME [epoch: 8.57 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10951354234886881		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.10951354234886881 | validation: 0.07708918190653641]
	TIME [epoch: 8.59 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382064771495137		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.08382064771495137 | validation: 0.05659091808668895]
	TIME [epoch: 8.57 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0754252305886283		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.0754252305886283 | validation: 0.06988264955253946]
	TIME [epoch: 8.57 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07690813430411061		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.07690813430411061 | validation: 0.07941073745858161]
	TIME [epoch: 8.57 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09150796117209564		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.09150796117209564 | validation: 0.08379258603668584]
	TIME [epoch: 8.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0804698247302336		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.0804698247302336 | validation: 0.0652308418032114]
	TIME [epoch: 8.57 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07805087995021714		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.07805087995021714 | validation: 0.09165157307134167]
	TIME [epoch: 8.57 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08813268883017246		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.08813268883017246 | validation: 0.09803872042326311]
	TIME [epoch: 8.57 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661438306862953		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.07661438306862953 | validation: 0.14612505251901786]
	TIME [epoch: 8.59 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08725507282378012		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.08725507282378012 | validation: 0.12056540826339324]
	TIME [epoch: 8.57 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11408462406294125		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.11408462406294125 | validation: 0.18344182840382894]
	TIME [epoch: 8.57 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08569425163043515		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.08569425163043515 | validation: 0.08544412504813717]
	TIME [epoch: 8.58 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07334797628975073		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.07334797628975073 | validation: 0.06461423436379175]
	TIME [epoch: 8.59 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.071964772842439		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.071964772842439 | validation: 0.11490236283130913]
	TIME [epoch: 8.57 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771324143696368		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.0771324143696368 | validation: 0.0684429101412999]
	TIME [epoch: 8.57 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07713312922084062		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.07713312922084062 | validation: 0.06718276865257243]
	TIME [epoch: 8.57 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092381523593208		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.092381523593208 | validation: 0.08611068310451603]
	TIME [epoch: 8.59 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09438570495689867		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.09438570495689867 | validation: 0.10302027691475414]
	TIME [epoch: 8.57 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0990874441460098		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.0990874441460098 | validation: 0.14303920890293426]
	TIME [epoch: 8.57 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10588991675529595		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.10588991675529595 | validation: 0.077090064399523]
	TIME [epoch: 8.58 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10548247454093737		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.10548247454093737 | validation: 0.05221897847410795]
	TIME [epoch: 8.57 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08218032054415925		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.08218032054415925 | validation: 0.04936672486768014]
	TIME [epoch: 8.57 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06468535562223421		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.06468535562223421 | validation: 0.04892610878958521]
	TIME [epoch: 8.56 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707171685137293		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.06707171685137293 | validation: 0.06085391896991696]
	TIME [epoch: 8.58 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08829431233029007		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.08829431233029007 | validation: 0.09447786616190249]
	TIME [epoch: 8.57 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06704394975683634		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.06704394975683634 | validation: 0.0746137915540805]
	TIME [epoch: 8.57 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07757910976394851		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.07757910976394851 | validation: 0.14054429556547593]
	TIME [epoch: 8.56 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08001167481408529		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.08001167481408529 | validation: 0.07429766198470164]
	TIME [epoch: 8.58 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0915575730636263		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.0915575730636263 | validation: 0.06988225704002958]
	TIME [epoch: 8.57 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08662479708428295		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.08662479708428295 | validation: 0.0879284855081377]
	TIME [epoch: 8.56 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07243003525516271		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.07243003525516271 | validation: 0.0621262534230501]
	TIME [epoch: 8.56 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07989995804842989		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.07989995804842989 | validation: 0.059388316824359313]
	TIME [epoch: 8.58 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05497524623062865		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.05497524623062865 | validation: 0.07101422142701275]
	TIME [epoch: 8.56 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058232608786158546		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.058232608786158546 | validation: 0.07112041381415847]
	TIME [epoch: 8.56 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09046008125033196		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.09046008125033196 | validation: 0.11306904681174396]
	TIME [epoch: 8.56 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08642186077840827		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.08642186077840827 | validation: 0.062103918712080056]
	TIME [epoch: 8.58 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06041037913003923		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.06041037913003923 | validation: 0.08037037688556439]
	TIME [epoch: 8.56 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08266502739840761		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.08266502739840761 | validation: 0.07611396268599173]
	TIME [epoch: 8.56 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061400025918915246		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.061400025918915246 | validation: 0.05334785334721851]
	TIME [epoch: 8.56 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06327474759962057		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.06327474759962057 | validation: 0.06437160047975977]
	TIME [epoch: 8.58 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08731670108611125		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.08731670108611125 | validation: 0.05803246915671279]
	TIME [epoch: 8.56 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08258906574623723		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.08258906574623723 | validation: 0.060152729529160925]
	TIME [epoch: 8.56 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08632317813533233		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.08632317813533233 | validation: 0.07242160861098902]
	TIME [epoch: 8.56 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09928357405138939		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.09928357405138939 | validation: 0.07221438360770094]
	TIME [epoch: 8.58 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07543783727323636		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.07543783727323636 | validation: 0.06521511938114082]
	TIME [epoch: 8.56 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643456024771438		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.06643456024771438 | validation: 0.07093782226918252]
	TIME [epoch: 8.56 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07259779066976782		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.07259779066976782 | validation: 0.06155709640443405]
	TIME [epoch: 8.57 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07092339783143113		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.07092339783143113 | validation: 0.06505283073406813]
	TIME [epoch: 8.57 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794448306849428		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.06794448306849428 | validation: 0.06900362885519282]
	TIME [epoch: 8.55 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07469852603891575		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.07469852603891575 | validation: 0.07756338330195778]
	TIME [epoch: 8.56 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07377699392594186		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.07377699392594186 | validation: 0.10115277851070828]
	TIME [epoch: 8.58 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816074678163146		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.07816074678163146 | validation: 0.09273989124629084]
	TIME [epoch: 8.56 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06987125452836493		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.06987125452836493 | validation: 0.0806786664899018]
	TIME [epoch: 8.56 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1090287859885786		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.1090287859885786 | validation: 0.11956159026240062]
	TIME [epoch: 8.56 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07883522909631532		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.07883522909631532 | validation: 0.11355373841980015]
	TIME [epoch: 8.58 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07151625560056071		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.07151625560056071 | validation: 0.07047660085442861]
	TIME [epoch: 8.56 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07327042463001185		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.07327042463001185 | validation: 0.15186380003180433]
	TIME [epoch: 8.56 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10694069082787869		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.10694069082787869 | validation: 0.06814099989826918]
	TIME [epoch: 8.56 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09212926439285499		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.09212926439285499 | validation: 0.1300241395997515]
	TIME [epoch: 8.58 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08752796239708596		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.08752796239708596 | validation: 0.05784348788009194]
	TIME [epoch: 8.56 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07339946966688907		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.07339946966688907 | validation: 0.06749579499968156]
	TIME [epoch: 8.55 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08793708225460432		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.08793708225460432 | validation: 0.047278920815968406]
	TIME [epoch: 8.56 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06915586528987469		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.06915586528987469 | validation: 0.05154610104481203]
	TIME [epoch: 8.58 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854668195755952		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.06854668195755952 | validation: 0.07114044304970335]
	TIME [epoch: 8.56 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08731927366468828		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.08731927366468828 | validation: 0.06769591418035142]
	TIME [epoch: 8.56 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07731492558870413		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.07731492558870413 | validation: 0.09421430538054545]
	TIME [epoch: 8.56 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0634635030982285		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.0634635030982285 | validation: 0.06468135494440648]
	TIME [epoch: 8.58 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08257898762851583		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.08257898762851583 | validation: 0.0783436950296311]
	TIME [epoch: 8.56 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05865151746600944		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.05865151746600944 | validation: 0.059931519769111666]
	TIME [epoch: 8.56 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062483306002194615		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.062483306002194615 | validation: 0.06544488115165392]
	TIME [epoch: 8.56 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073798648875259		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.08073798648875259 | validation: 0.09186072782643913]
	TIME [epoch: 8.58 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0903761603587653		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.0903761603587653 | validation: 0.07166272643107077]
	TIME [epoch: 8.56 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07184298809784043		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.07184298809784043 | validation: 0.05874021599391965]
	TIME [epoch: 8.56 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05619451484206418		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.05619451484206418 | validation: 0.05136776365334296]
	TIME [epoch: 8.56 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08101970061810146		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.08101970061810146 | validation: 0.06032979463839017]
	TIME [epoch: 8.58 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08068381764554952		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.08068381764554952 | validation: 0.05627872329388166]
	TIME [epoch: 8.56 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0773436315614314		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.0773436315614314 | validation: 0.0987705519276327]
	TIME [epoch: 8.56 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08798353860388378		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.08798353860388378 | validation: 0.07754629904325819]
	TIME [epoch: 8.57 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07154470583763076		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.07154470583763076 | validation: 0.07712721953120788]
	TIME [epoch: 8.57 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07926079137026738		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.07926079137026738 | validation: 0.05881031118519202]
	TIME [epoch: 8.56 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08973713604076092		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.08973713604076092 | validation: 0.057994820799994434]
	TIME [epoch: 8.56 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0718324130587962		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.0718324130587962 | validation: 0.060392555506992934]
	TIME [epoch: 8.58 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08741254439541846		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.08741254439541846 | validation: 0.09648500641768629]
	TIME [epoch: 8.57 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162977625360996		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.07162977625360996 | validation: 0.07950885034845473]
	TIME [epoch: 8.57 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06749016353448342		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.06749016353448342 | validation: 0.06148009265065106]
	TIME [epoch: 8.56 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07580586476388365		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.07580586476388365 | validation: 0.10592772268453288]
	TIME [epoch: 8.58 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08810663553963818		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.08810663553963818 | validation: 0.06009240938948751]
	TIME [epoch: 8.57 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1086091940687736		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.1086091940687736 | validation: 0.07713476526113007]
	TIME [epoch: 8.56 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09169063755253974		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.09169063755253974 | validation: 0.1383116295619542]
	TIME [epoch: 8.56 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0901505436352533		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.0901505436352533 | validation: 0.11778986313077401]
	TIME [epoch: 8.58 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10046133643721704		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.10046133643721704 | validation: 0.1155422072977959]
	TIME [epoch: 8.57 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09085707961827923		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.09085707961827923 | validation: 0.09342243084960408]
	TIME [epoch: 8.57 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07404796520185801		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.07404796520185801 | validation: 0.05032887191156776]
	TIME [epoch: 8.57 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06459111139532174		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.06459111139532174 | validation: 0.08726582984068657]
	TIME [epoch: 8.58 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08907712567005568		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.08907712567005568 | validation: 0.08567455557350523]
	TIME [epoch: 8.57 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08211294842685549		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.08211294842685549 | validation: 0.052420813024089574]
	TIME [epoch: 8.57 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06112114297610832		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.06112114297610832 | validation: 0.05599513664807881]
	TIME [epoch: 8.56 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06103235287828065		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.06103235287828065 | validation: 0.06340612433063067]
	TIME [epoch: 8.58 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06345462281312372		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.06345462281312372 | validation: 0.0818087847889358]
	TIME [epoch: 8.56 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06453315229694731		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.06453315229694731 | validation: 0.0857532894716769]
	TIME [epoch: 8.56 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08930495995532552		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.08930495995532552 | validation: 0.13032484614995377]
	TIME [epoch: 8.56 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08836093314207841		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.08836093314207841 | validation: 0.062180166616008864]
	TIME [epoch: 8.58 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.098440860040458		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.098440860040458 | validation: 0.1263058408650698]
	TIME [epoch: 8.57 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09369772594409502		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.09369772594409502 | validation: 0.10464644907004737]
	TIME [epoch: 8.56 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09540929486148839		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.09540929486148839 | validation: 0.10339556703750255]
	TIME [epoch: 8.57 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08867037303794999		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.08867037303794999 | validation: 0.06568843318019872]
	TIME [epoch: 8.57 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08420885283457802		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.08420885283457802 | validation: 0.10026358797230599]
	TIME [epoch: 8.56 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09525297754431167		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.09525297754431167 | validation: 0.0681099795090711]
	TIME [epoch: 8.57 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08119924885556137		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.08119924885556137 | validation: 0.05079707801640222]
	TIME [epoch: 8.58 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822032708066886		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.06822032708066886 | validation: 0.06946747094685013]
	TIME [epoch: 8.57 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059410999290878494		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.059410999290878494 | validation: 0.055494414883729526]
	TIME [epoch: 8.56 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0594124204362367		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.0594124204362367 | validation: 0.05982226471829306]
	TIME [epoch: 8.56 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07784835846949319		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.07784835846949319 | validation: 0.22629757107720283]
	TIME [epoch: 8.58 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11040371064090407		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.11040371064090407 | validation: 0.0482959725466924]
	TIME [epoch: 8.57 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05294252362081595		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.05294252362081595 | validation: 0.05094375810870272]
	TIME [epoch: 8.57 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534385435246477		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.06534385435246477 | validation: 0.05943678738248416]
	TIME [epoch: 8.57 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07705673369087322		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.07705673369087322 | validation: 0.06612508121060945]
	TIME [epoch: 8.58 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07128838165072879		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.07128838165072879 | validation: 0.08196449152226314]
	TIME [epoch: 8.57 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07508790386459527		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.07508790386459527 | validation: 0.06936075060762795]
	TIME [epoch: 8.56 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06913074767057473		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.06913074767057473 | validation: 0.08039236390022432]
	TIME [epoch: 8.56 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08408737128691092		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.08408737128691092 | validation: 0.06703676086928706]
	TIME [epoch: 8.58 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05657473969761325		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.05657473969761325 | validation: 0.051346970788355636]
	TIME [epoch: 8.57 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0515367534436201		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.0515367534436201 | validation: 0.0778643742321245]
	TIME [epoch: 8.56 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055797492570885066		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.055797492570885066 | validation: 0.07847313002300861]
	TIME [epoch: 8.56 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06621608534454829		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.06621608534454829 | validation: 0.1143307729871987]
	TIME [epoch: 8.58 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06014735381833249		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.06014735381833249 | validation: 0.05959043448346864]
	TIME [epoch: 8.56 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07265503980612634		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.07265503980612634 | validation: 0.065151441397989]
	TIME [epoch: 8.56 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07686038007897564		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.07686038007897564 | validation: 0.11636737846719805]
	TIME [epoch: 8.57 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083628923337288		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.083628923337288 | validation: 0.23978463272266767]
	TIME [epoch: 8.58 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09656724290343047		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.09656724290343047 | validation: 0.05109426871297665]
	TIME [epoch: 8.56 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930273610585246		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.05930273610585246 | validation: 0.08399282551837886]
	TIME [epoch: 8.56 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358506520420959		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.06358506520420959 | validation: 0.0657151819917765]
	TIME [epoch: 8.57 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058274785194656384		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.058274785194656384 | validation: 0.07596961693093236]
	TIME [epoch: 8.59 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06250217988188683		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.06250217988188683 | validation: 0.08686737187834584]
	TIME [epoch: 8.56 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251722436109883		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.06251722436109883 | validation: 0.09093587775847618]
	TIME [epoch: 8.57 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07050934217632045		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.07050934217632045 | validation: 0.07766428088285039]
	TIME [epoch: 8.59 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05805124791263039		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.05805124791263039 | validation: 0.06713514235772082]
	TIME [epoch: 8.57 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015609297432234		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.08015609297432234 | validation: 0.09871533064028779]
	TIME [epoch: 8.56 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07590977066031235		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.07590977066031235 | validation: 0.1667724154152479]
	TIME [epoch: 8.56 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08754557529274243		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.08754557529274243 | validation: 0.07126969025844038]
	TIME [epoch: 8.58 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07430419396293896		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.07430419396293896 | validation: 0.0852020361924408]
	TIME [epoch: 8.56 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204489141493886		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.09204489141493886 | validation: 0.07968410121757029]
	TIME [epoch: 8.56 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06790573864962084		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.06790573864962084 | validation: 0.0690617040398159]
	TIME [epoch: 8.57 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06421639650104018		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.06421639650104018 | validation: 0.07996765611633246]
	TIME [epoch: 8.58 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07534504264240795		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.07534504264240795 | validation: 0.08669285027853554]
	TIME [epoch: 8.57 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.063437765585544		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.063437765585544 | validation: 0.06065759383355686]
	TIME [epoch: 8.56 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06792068520617131		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.06792068520617131 | validation: 0.11856029030539487]
	TIME [epoch: 8.56 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770700076776997		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.07770700076776997 | validation: 0.059650837488783096]
	TIME [epoch: 8.58 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07301087219285289		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.07301087219285289 | validation: 0.08210033768329553]
	TIME [epoch: 8.57 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440204439486695		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.07440204439486695 | validation: 0.09101060337877272]
	TIME [epoch: 8.56 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0745119740517765		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.0745119740517765 | validation: 0.07478971169395333]
	TIME [epoch: 8.57 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07032756198572053		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.07032756198572053 | validation: 0.17756937441496548]
	TIME [epoch: 8.58 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10878836877935608		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.10878836877935608 | validation: 0.07556024053325952]
	TIME [epoch: 8.57 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905753023035614		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.06905753023035614 | validation: 0.06838716006931501]
	TIME [epoch: 8.56 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09520348837078865		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.09520348837078865 | validation: 0.11953812444742827]
	TIME [epoch: 8.57 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08491452906656546		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.08491452906656546 | validation: 0.05001069052815432]
	TIME [epoch: 8.59 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446453832675506		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.06446453832675506 | validation: 0.05376038852633967]
	TIME [epoch: 8.56 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07200631530061277		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.07200631530061277 | validation: 0.07571578712397793]
	TIME [epoch: 8.56 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07955209146062278		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.07955209146062278 | validation: 0.08107554082712212]
	TIME [epoch: 8.57 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0853365316585529		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.0853365316585529 | validation: 0.07107663923338306]
	TIME [epoch: 8.58 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07131898122390325		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.07131898122390325 | validation: 0.07481681991718835]
	TIME [epoch: 8.56 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05834814629592089		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.05834814629592089 | validation: 0.05471757030918736]
	TIME [epoch: 8.56 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06175945985876313		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.06175945985876313 | validation: 0.054612055028984474]
	TIME [epoch: 8.57 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08002248170928891		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.08002248170928891 | validation: 0.07106473665750172]
	TIME [epoch: 8.57 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07989398514832684		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.07989398514832684 | validation: 0.04649735686039461]
	TIME [epoch: 8.56 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06439106511332185		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.06439106511332185 | validation: 0.07061452478278732]
	TIME [epoch: 8.56 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06240363826922192		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.06240363826922192 | validation: 0.06738760537096425]
	TIME [epoch: 8.58 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10088824588506937		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.10088824588506937 | validation: 0.07820407465985064]
	TIME [epoch: 8.57 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08524174917050469		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.08524174917050469 | validation: 0.09179785640044125]
	TIME [epoch: 8.56 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07096793935837416		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.07096793935837416 | validation: 0.072557567797743]
	TIME [epoch: 8.56 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07822679395026107		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.07822679395026107 | validation: 0.060945230582413454]
	TIME [epoch: 8.58 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06613874067908511		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.06613874067908511 | validation: 0.05538841354036961]
	TIME [epoch: 8.57 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440816149150757		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.07440816149150757 | validation: 0.08226829902526303]
	TIME [epoch: 8.56 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07738311141040473		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.07738311141040473 | validation: 0.11044989034617567]
	TIME [epoch: 8.57 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717237775641999		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.0717237775641999 | validation: 0.0778946626416726]
	TIME [epoch: 8.58 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0712008177609941		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.0712008177609941 | validation: 0.10420952327220542]
	TIME [epoch: 8.57 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05817323432174674		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.05817323432174674 | validation: 0.06155849896744177]
	TIME [epoch: 8.56 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0588955394321404		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.0588955394321404 | validation: 0.06132629024626284]
	TIME [epoch: 8.56 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05902960967543942		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.05902960967543942 | validation: 0.07072265016935456]
	TIME [epoch: 8.59 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05812366137305471		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.05812366137305471 | validation: 0.05730617662265988]
	TIME [epoch: 8.57 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270003069106843		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.06270003069106843 | validation: 0.06694214818973535]
	TIME [epoch: 8.57 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.064558699550626		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.064558699550626 | validation: 0.06327161725921976]
	TIME [epoch: 8.57 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0596031663525025		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.0596031663525025 | validation: 0.08146186237250036]
	TIME [epoch: 8.59 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05970915919197591		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.05970915919197591 | validation: 0.09773048131603318]
	TIME [epoch: 8.57 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06529859178161353		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.06529859178161353 | validation: 0.08974475415988085]
	TIME [epoch: 8.56 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040458967950963		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.07040458967950963 | validation: 0.06379635751032497]
	TIME [epoch: 8.57 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06827086098453375		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.06827086098453375 | validation: 0.08386749935682007]
	TIME [epoch: 8.58 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0740361231681081		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.0740361231681081 | validation: 0.06967150617448796]
	TIME [epoch: 8.56 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09413868557948737		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.09413868557948737 | validation: 0.17780928258037185]
	TIME [epoch: 8.56 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09148467732534782		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.09148467732534782 | validation: 0.12607346268502012]
	TIME [epoch: 8.58 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10703275637032497		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.10703275637032497 | validation: 0.07958698467366089]
	TIME [epoch: 8.57 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096570595745837		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.06096570595745837 | validation: 0.03935833018003924]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1263.pth
	Model improved!!!
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056978207926414656		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.056978207926414656 | validation: 0.05151249059813569]
	TIME [epoch: 8.57 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07315617356066469		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.07315617356066469 | validation: 0.09748853570459115]
	TIME [epoch: 8.59 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07386220856998585		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.07386220856998585 | validation: 0.07137762298446189]
	TIME [epoch: 8.57 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05883507024779916		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.05883507024779916 | validation: 0.05969082924195043]
	TIME [epoch: 8.56 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06621094768651756		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.06621094768651756 | validation: 0.04998063455606007]
	TIME [epoch: 8.56 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08705250244584714		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.08705250244584714 | validation: 0.049264422284394954]
	TIME [epoch: 8.59 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0804119844487983		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.0804119844487983 | validation: 0.0691949241176621]
	TIME [epoch: 8.57 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655836427836565		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.05655836427836565 | validation: 0.062104542504640224]
	TIME [epoch: 8.57 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06202375871135296		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.06202375871135296 | validation: 0.08451172876376811]
	TIME [epoch: 8.56 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06266902473520837		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.06266902473520837 | validation: 0.05940811447897553]
	TIME [epoch: 8.58 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05694057336953623		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.05694057336953623 | validation: 0.0637487129714997]
	TIME [epoch: 8.57 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0450151452001594		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.0450151452001594 | validation: 0.06456406767167386]
	TIME [epoch: 8.56 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05393017109987232		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.05393017109987232 | validation: 0.0588783885446546]
	TIME [epoch: 8.56 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052751151448823363		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.052751151448823363 | validation: 0.06262522832225219]
	TIME [epoch: 8.58 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366954540219837		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.06366954540219837 | validation: 0.06999076579325576]
	TIME [epoch: 8.57 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366342082821369		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.06366342082821369 | validation: 0.14023377024561745]
	TIME [epoch: 8.56 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747014292854328		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.06747014292854328 | validation: 0.0498528914552611]
	TIME [epoch: 8.57 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052521753286265335		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.052521753286265335 | validation: 0.0735371647305045]
	TIME [epoch: 8.58 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08420382964088857		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.08420382964088857 | validation: 0.04761439533157597]
	TIME [epoch: 8.57 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08251824736596125		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.08251824736596125 | validation: 0.10960605161355995]
	TIME [epoch: 8.57 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07151852048555205		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.07151852048555205 | validation: 0.06185354826450677]
	TIME [epoch: 8.56 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05128162490702818		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.05128162490702818 | validation: 0.05307170379900342]
	TIME [epoch: 8.59 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058054111601536326		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.058054111601536326 | validation: 0.04321885955711259]
	TIME [epoch: 8.56 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04634310709041763		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.04634310709041763 | validation: 0.038240361863981]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1287.pth
	Model improved!!!
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0756369820049425		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.0756369820049425 | validation: 0.07825212407347776]
	TIME [epoch: 8.58 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07551575511895273		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.07551575511895273 | validation: 0.06028391758058303]
	TIME [epoch: 8.58 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324164651776087		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.07324164651776087 | validation: 0.08180518626726511]
	TIME [epoch: 8.57 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07687381336645369		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.07687381336645369 | validation: 0.08376251239800611]
	TIME [epoch: 8.57 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07349101196478064		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.07349101196478064 | validation: 0.050351716729332974]
	TIME [epoch: 8.59 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05649066204518496		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.05649066204518496 | validation: 0.05155006590741948]
	TIME [epoch: 8.57 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06989302690838253		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.06989302690838253 | validation: 0.04087301189840442]
	TIME [epoch: 8.57 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06362020171152498		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.06362020171152498 | validation: 0.09101927121075955]
	TIME [epoch: 8.57 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07626127419202891		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.07626127419202891 | validation: 0.06133986409458719]
	TIME [epoch: 8.59 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07001253914755125		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.07001253914755125 | validation: 0.0699977795477449]
	TIME [epoch: 8.57 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06597164774409821		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.06597164774409821 | validation: 0.04938134341888851]
	TIME [epoch: 8.57 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05434487370253409		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.05434487370253409 | validation: 0.06139719398887055]
	TIME [epoch: 8.57 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049250954901655694		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.049250954901655694 | validation: 0.08069979053036846]
	TIME [epoch: 8.59 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04644076734394141		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.04644076734394141 | validation: 0.05419165837117736]
	TIME [epoch: 8.57 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06347059672617522		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.06347059672617522 | validation: 0.08101810036239698]
	TIME [epoch: 8.57 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05945368167907872		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.05945368167907872 | validation: 0.056511872258276724]
	TIME [epoch: 8.57 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061171608335935636		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.061171608335935636 | validation: 0.08144385308129679]
	TIME [epoch: 8.59 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05469671953082691		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.05469671953082691 | validation: 0.04898141722402407]
	TIME [epoch: 8.57 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048978747345796846		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.048978747345796846 | validation: 0.054702493703355864]
	TIME [epoch: 8.57 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06509108735538784		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.06509108735538784 | validation: 0.0951193535104102]
	TIME [epoch: 8.57 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05832219935071814		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.05832219935071814 | validation: 0.04601676569823869]
	TIME [epoch: 8.59 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04655458607012919		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.04655458607012919 | validation: 0.03609053666605369]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1309.pth
	Model improved!!!
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05180322489072845		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.05180322489072845 | validation: 0.05431432370178187]
	TIME [epoch: 8.57 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06653004050121024		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.06653004050121024 | validation: 0.06731425633727395]
	TIME [epoch: 8.58 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06732152713559844		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.06732152713559844 | validation: 0.06598860121187475]
	TIME [epoch: 8.58 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05286516798397032		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.05286516798397032 | validation: 0.041735236066292244]
	TIME [epoch: 8.57 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0602432996047043		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.0602432996047043 | validation: 0.052732689951449516]
	TIME [epoch: 8.56 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04697903157167076		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.04697903157167076 | validation: 0.04368784978835803]
	TIME [epoch: 8.59 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06258006117502601		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.06258006117502601 | validation: 0.04977378292331727]
	TIME [epoch: 8.57 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056934510166888865		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.056934510166888865 | validation: 0.04253516094533534]
	TIME [epoch: 8.56 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05527508666132423		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.05527508666132423 | validation: 0.051560741405390215]
	TIME [epoch: 8.56 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05912032083034702		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.05912032083034702 | validation: 0.04749193359989572]
	TIME [epoch: 8.59 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615525889846122		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.06615525889846122 | validation: 0.04892759059834845]
	TIME [epoch: 8.57 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467210419812294		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.06467210419812294 | validation: 0.054585865326916165]
	TIME [epoch: 8.57 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07939356401269795		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.07939356401269795 | validation: 0.062208366350396636]
	TIME [epoch: 8.57 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05549790717254448		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.05549790717254448 | validation: 0.040315963072403864]
	TIME [epoch: 8.58 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04605273150856139		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.04605273150856139 | validation: 0.0581120623462483]
	TIME [epoch: 8.58 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058583882318563464		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.058583882318563464 | validation: 0.05184790228578984]
	TIME [epoch: 8.57 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664522510272937		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.05664522510272937 | validation: 0.05212041745148844]
	TIME [epoch: 8.56 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056325117449797624		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.056325117449797624 | validation: 0.052255557842190686]
	TIME [epoch: 8.59 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05822427635096859		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.05822427635096859 | validation: 0.04221863338672631]
	TIME [epoch: 8.57 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05693722617513101		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.05693722617513101 | validation: 0.057099057369208533]
	TIME [epoch: 8.57 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06569512545701374		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.06569512545701374 | validation: 0.054857047242263444]
	TIME [epoch: 8.57 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05652441883375736		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.05652441883375736 | validation: 0.053844720854738896]
	TIME [epoch: 8.59 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07031393442307242		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.07031393442307242 | validation: 0.08504420898421884]
	TIME [epoch: 8.57 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07430111164488883		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.07430111164488883 | validation: 0.14019167941106422]
	TIME [epoch: 8.56 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061073765923206735		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.061073765923206735 | validation: 0.043692109655194544]
	TIME [epoch: 8.57 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049471490106508066		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.049471490106508066 | validation: 0.11603368757797819]
	TIME [epoch: 8.59 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09048842172236433		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.09048842172236433 | validation: 0.0885570157285748]
	TIME [epoch: 8.57 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057165780250701945		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.057165780250701945 | validation: 0.06950677448916581]
	TIME [epoch: 8.57 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366698880161145		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.06366698880161145 | validation: 0.06758084606659323]
	TIME [epoch: 8.57 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07347709033578749		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.07347709033578749 | validation: 0.058825896708754453]
	TIME [epoch: 8.59 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055714380103111846		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.055714380103111846 | validation: 0.053771143528061116]
	TIME [epoch: 8.56 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06370550128169507		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.06370550128169507 | validation: 0.13457881016299808]
	TIME [epoch: 8.57 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05814861184900115		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.05814861184900115 | validation: 0.05176069234487593]
	TIME [epoch: 8.58 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053930475935784164		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.053930475935784164 | validation: 0.05968053392602421]
	TIME [epoch: 8.57 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07283561556634235		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.07283561556634235 | validation: 0.08662351776971797]
	TIME [epoch: 8.57 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05356785642393107		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.05356785642393107 | validation: 0.04514588635048852]
	TIME [epoch: 8.56 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05535951463103195		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.05535951463103195 | validation: 0.07458935447081455]
	TIME [epoch: 8.59 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800436516686815		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.05800436516686815 | validation: 0.0667360801680662]
	TIME [epoch: 8.57 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05381320161597776		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.05381320161597776 | validation: 0.1190090189174759]
	TIME [epoch: 8.57 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604649643702328		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.07604649643702328 | validation: 0.06090149482409896]
	TIME [epoch: 8.57 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06698922433672282		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.06698922433672282 | validation: 0.07011478251549018]
	TIME [epoch: 8.59 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0737336393131863		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.0737336393131863 | validation: 0.05545496162826325]
	TIME [epoch: 8.57 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04744460946237945		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.04744460946237945 | validation: 0.0659504757911279]
	TIME [epoch: 8.57 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332358378222813		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.06332358378222813 | validation: 0.08073664713381315]
	TIME [epoch: 8.57 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.063746824064159		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.063746824064159 | validation: 0.055987276992756824]
	TIME [epoch: 8.59 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05991724282602641		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.05991724282602641 | validation: 0.05621848003178673]
	TIME [epoch: 8.57 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05545698588551425		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.05545698588551425 | validation: 0.037791659622200775]
	TIME [epoch: 8.57 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05767232217753375		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.05767232217753375 | validation: 0.06456335961205274]
	TIME [epoch: 8.57 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06320477167574433		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.06320477167574433 | validation: 0.05356063484965139]
	TIME [epoch: 8.58 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05308764557261166		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.05308764557261166 | validation: 0.04740876136436995]
	TIME [epoch: 8.57 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05253755034552373		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.05253755034552373 | validation: 0.085986462620771]
	TIME [epoch: 8.57 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905416326762903		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.06905416326762903 | validation: 0.04506149671632617]
	TIME [epoch: 8.57 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05740833841885064		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.05740833841885064 | validation: 0.10200451221366423]
	TIME [epoch: 8.59 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05635305564140945		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.05635305564140945 | validation: 0.059308075447814676]
	TIME [epoch: 8.57 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0591791773600589		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.0591791773600589 | validation: 0.07556209896809055]
	TIME [epoch: 8.57 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060809565275066854		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.060809565275066854 | validation: 0.046652511782243104]
	TIME [epoch: 8.57 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05647507934482664		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.05647507934482664 | validation: 0.04918289668336367]
	TIME [epoch: 8.58 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05503015610951554		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.05503015610951554 | validation: 0.06908475660244476]
	TIME [epoch: 8.57 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05143470324575418		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.05143470324575418 | validation: 0.08678191620943834]
	TIME [epoch: 8.57 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049159485189599256		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.049159485189599256 | validation: 0.05883008944595536]
	TIME [epoch: 8.58 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043219371562233766		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.043219371562233766 | validation: 0.061369320671742944]
	TIME [epoch: 8.57 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07468586194914308		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.07468586194914308 | validation: 0.06293723631707221]
	TIME [epoch: 8.57 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06663241953170151		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.06663241953170151 | validation: 0.0685152067933737]
	TIME [epoch: 8.57 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052424803142703834		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.052424803142703834 | validation: 0.05487886134961469]
	TIME [epoch: 8.59 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05623537068358372		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.05623537068358372 | validation: 0.04752466313701561]
	TIME [epoch: 8.57 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07675614344452264		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.07675614344452264 | validation: 0.0679744577234227]
	TIME [epoch: 8.57 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07165558265989988		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.07165558265989988 | validation: 0.0845048727179453]
	TIME [epoch: 8.56 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0767664993647387		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.0767664993647387 | validation: 0.07742274963024309]
	TIME [epoch: 8.59 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06587345981504684		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.06587345981504684 | validation: 0.038138490204910364]
	TIME [epoch: 8.57 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058365729900873374		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.058365729900873374 | validation: 0.05135854799800316]
	TIME [epoch: 8.56 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264559781416232		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.05264559781416232 | validation: 0.08285213810156897]
	TIME [epoch: 8.56 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05938035504571515		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.05938035504571515 | validation: 0.05434395628106349]
	TIME [epoch: 8.58 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057904829547570105		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.057904829547570105 | validation: 0.05708072570318292]
	TIME [epoch: 8.56 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05517500307016261		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.05517500307016261 | validation: 0.04887041977311053]
	TIME [epoch: 8.56 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05762624057843505		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.05762624057843505 | validation: 0.07312494393113554]
	TIME [epoch: 8.56 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152716771391491		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.06152716771391491 | validation: 0.04533815078421036]
	TIME [epoch: 8.59 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05077769331699672		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.05077769331699672 | validation: 0.03603106581850969]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1386.pth
	Model improved!!!
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05973838867817608		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.05973838867817608 | validation: 0.06567473912224546]
	TIME [epoch: 8.57 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05604646755991686		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.05604646755991686 | validation: 0.03306244845554909]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1388.pth
	Model improved!!!
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576796971263792		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.0576796971263792 | validation: 0.05928693510613045]
	TIME [epoch: 8.59 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06074701652627891		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.06074701652627891 | validation: 0.056486506634000004]
	TIME [epoch: 8.56 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05435494396305007		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.05435494396305007 | validation: 0.06488929631542124]
	TIME [epoch: 8.56 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051219764850821345		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.051219764850821345 | validation: 0.03653149127130698]
	TIME [epoch: 8.57 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0725102143772666		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.0725102143772666 | validation: 0.0652803595109713]
	TIME [epoch: 8.57 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04920706409434096		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.04920706409434096 | validation: 0.053135814073660775]
	TIME [epoch: 8.56 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05228223324248844		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.05228223324248844 | validation: 0.05989263118366077]
	TIME [epoch: 8.57 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059452609615615305		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.059452609615615305 | validation: 0.05348845932249585]
	TIME [epoch: 8.58 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05682031152039979		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.05682031152039979 | validation: 0.03722859763034363]
	TIME [epoch: 8.57 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0634151200000504		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.0634151200000504 | validation: 0.049601061108991554]
	TIME [epoch: 8.56 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889211826937129		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.07889211826937129 | validation: 0.048247353839044146]
	TIME [epoch: 8.56 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060968002525113626		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.060968002525113626 | validation: 0.06613830628613826]
	TIME [epoch: 8.58 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06546834917834804		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.06546834917834804 | validation: 0.08603752686365773]
	TIME [epoch: 8.57 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07382638127422375		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.07382638127422375 | validation: 0.11956783818939093]
	TIME [epoch: 8.56 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07477528613100508		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.07477528613100508 | validation: 0.05191652496986282]
	TIME [epoch: 8.56 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05926098568935083		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.05926098568935083 | validation: 0.051283203292761995]
	TIME [epoch: 8.58 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06211442312684309		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.06211442312684309 | validation: 0.050621903890901696]
	TIME [epoch: 8.56 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06780002172465892		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.06780002172465892 | validation: 0.05468823820808259]
	TIME [epoch: 8.56 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0525796276470341		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.0525796276470341 | validation: 0.04973724112242037]
	TIME [epoch: 8.56 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05783803158443788		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.05783803158443788 | validation: 0.05553259337992006]
	TIME [epoch: 8.58 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689092853798707		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.0689092853798707 | validation: 0.0542488814779248]
	TIME [epoch: 8.57 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349189724527053		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.06349189724527053 | validation: 0.055817895110400896]
	TIME [epoch: 8.56 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053374433104341666		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.053374433104341666 | validation: 0.05827382091098053]
	TIME [epoch: 8.57 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056899602227031845		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.056899602227031845 | validation: 0.04776001452622116]
	TIME [epoch: 8.58 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04776422983561524		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.04776422983561524 | validation: 0.05435446114607884]
	TIME [epoch: 8.57 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045124768168276375		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.045124768168276375 | validation: 0.04308617264691886]
	TIME [epoch: 8.56 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044980034450689016		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.044980034450689016 | validation: 0.057279962987214314]
	TIME [epoch: 8.56 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047980243561353324		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.047980243561353324 | validation: 0.06501988719694447]
	TIME [epoch: 8.58 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0552822358510061		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.0552822358510061 | validation: 0.06309538937129691]
	TIME [epoch: 8.56 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534623339968584		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.06534623339968584 | validation: 0.05185844625710656]
	TIME [epoch: 8.56 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058114801110754954		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.058114801110754954 | validation: 0.05586339540934965]
	TIME [epoch: 8.57 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05570312097910003		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.05570312097910003 | validation: 0.06835705993967497]
	TIME [epoch: 8.57 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500947341671959		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.06500947341671959 | validation: 0.08903543568418273]
	TIME [epoch: 8.56 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651607751280054		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.06651607751280054 | validation: 0.08680826394855397]
	TIME [epoch: 8.56 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07084920292448804		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.07084920292448804 | validation: 0.07769524860298607]
	TIME [epoch: 8.59 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05571499742712803		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.05571499742712803 | validation: 0.06938144040517812]
	TIME [epoch: 8.57 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04919305714879807		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.04919305714879807 | validation: 0.0570701545092306]
	TIME [epoch: 8.56 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054683320550612355		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.054683320550612355 | validation: 0.05578416965359244]
	TIME [epoch: 8.57 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04562772336019076		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.04562772336019076 | validation: 0.056789908840618616]
	TIME [epoch: 8.58 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05722433542492078		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.05722433542492078 | validation: 0.05128989864503688]
	TIME [epoch: 8.57 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04946149275355831		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.04946149275355831 | validation: 0.06617097770436539]
	TIME [epoch: 8.56 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050684305322435876		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.050684305322435876 | validation: 0.03747125904115685]
	TIME [epoch: 8.56 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04145569380636199		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.04145569380636199 | validation: 0.06528128716055047]
	TIME [epoch: 8.59 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050450796868607026		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.050450796868607026 | validation: 0.06790274809320565]
	TIME [epoch: 8.57 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060918093922937656		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.060918093922937656 | validation: 0.04947224399560794]
	TIME [epoch: 8.56 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04789736934902556		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.04789736934902556 | validation: 0.046464925416308415]
	TIME [epoch: 8.57 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04993357329466263		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.04993357329466263 | validation: 0.038926387972397926]
	TIME [epoch: 8.59 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056908011276330474		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.056908011276330474 | validation: 0.05920920472873534]
	TIME [epoch: 8.57 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04347174661186082		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.04347174661186082 | validation: 0.05390374770236086]
	TIME [epoch: 8.57 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07067016039257593		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.07067016039257593 | validation: 0.06195994773981996]
	TIME [epoch: 8.56 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07180358489043073		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.07180358489043073 | validation: 0.060725174864245876]
	TIME [epoch: 8.59 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058482654784641167		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.058482654784641167 | validation: 0.07060491023098235]
	TIME [epoch: 8.57 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05765038446110358		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.05765038446110358 | validation: 0.06777030510658473]
	TIME [epoch: 8.57 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05040122584075694		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.05040122584075694 | validation: 0.043686296344245396]
	TIME [epoch: 8.57 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059021329029419554		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.059021329029419554 | validation: 0.09511064828652371]
	TIME [epoch: 8.58 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051972018252953535		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.051972018252953535 | validation: 0.05389431642675386]
	TIME [epoch: 8.57 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046020059328210586		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.046020059328210586 | validation: 0.05899368034521568]
	TIME [epoch: 8.56 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05224782933413358		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.05224782933413358 | validation: 0.07153020959141781]
	TIME [epoch: 8.57 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055938899251957254		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.055938899251957254 | validation: 0.04670501590034751]
	TIME [epoch: 8.58 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05737562410078506		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.05737562410078506 | validation: 0.07656925965681705]
	TIME [epoch: 8.56 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062247000535458244		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.062247000535458244 | validation: 0.054546557191102754]
	TIME [epoch: 8.57 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359071837726627		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.05359071837726627 | validation: 0.06549728642421337]
	TIME [epoch: 8.58 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057044683669824424		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.057044683669824424 | validation: 0.06079523910693811]
	TIME [epoch: 8.57 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07315521038255904		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.07315521038255904 | validation: 0.07114176064853185]
	TIME [epoch: 8.57 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05498177740740399		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.05498177740740399 | validation: 0.08625593592605497]
	TIME [epoch: 8.56 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494778274772564		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.06494778274772564 | validation: 0.09559143136164142]
	TIME [epoch: 8.59 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678475981188605		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.0678475981188605 | validation: 0.06509016909966278]
	TIME [epoch: 8.57 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05846699637249858		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.05846699637249858 | validation: 0.06732883956628691]
	TIME [epoch: 8.57 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048975987582100755		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.048975987582100755 | validation: 0.05872083553177046]
	TIME [epoch: 8.57 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05252068982594914		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.05252068982594914 | validation: 0.05627164036048365]
	TIME [epoch: 8.58 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04789296720449902		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.04789296720449902 | validation: 0.05663024035311298]
	TIME [epoch: 8.57 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04549258741314017		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.04549258741314017 | validation: 0.08721651441304482]
	TIME [epoch: 8.56 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059072545384873776		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.059072545384873776 | validation: 0.049231846786858595]
	TIME [epoch: 8.57 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04635118592935158		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.04635118592935158 | validation: 0.04325748342416992]
	TIME [epoch: 8.59 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04444681221098193		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.04444681221098193 | validation: 0.05243370713220141]
	TIME [epoch: 8.57 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06387184955272834		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.06387184955272834 | validation: 0.05397806808898903]
	TIME [epoch: 8.57 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06106118535203327		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.06106118535203327 | validation: 0.05574460424241525]
	TIME [epoch: 8.57 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06778278213704092		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.06778278213704092 | validation: 0.05345785653559626]
	TIME [epoch: 8.58 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05825293703112907		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.05825293703112907 | validation: 0.04992336866744251]
	TIME [epoch: 8.57 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052884395175141666		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.052884395175141666 | validation: 0.05515970325842321]
	TIME [epoch: 8.57 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054282510598907804		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.054282510598907804 | validation: 0.04729121135399853]
	TIME [epoch: 8.57 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04609522444609056		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.04609522444609056 | validation: 0.0538268004317072]
	TIME [epoch: 8.58 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05486656106708589		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.05486656106708589 | validation: 0.0500660599313448]
	TIME [epoch: 8.57 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04547200910076253		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.04547200910076253 | validation: 0.06382129759308133]
	TIME [epoch: 8.57 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05635843410538367		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.05635843410538367 | validation: 0.07894360345048437]
	TIME [epoch: 8.57 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05899550361032154		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.05899550361032154 | validation: 0.05276638568615844]
	TIME [epoch: 8.59 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051467383158244895		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.051467383158244895 | validation: 0.06768396834139315]
	TIME [epoch: 8.57 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06485045222881215		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.06485045222881215 | validation: 0.07613664226473552]
	TIME [epoch: 8.57 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672601358071964		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.0672601358071964 | validation: 0.05675389861985229]
	TIME [epoch: 8.58 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05818026249895406		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.05818026249895406 | validation: 0.04641199753735701]
	TIME [epoch: 8.58 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06090752470354466		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.06090752470354466 | validation: 0.06069602283891093]
	TIME [epoch: 8.57 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05355649463011423		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.05355649463011423 | validation: 0.041791747975544545]
	TIME [epoch: 8.57 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04738243981112229		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.04738243981112229 | validation: 0.04830798509005971]
	TIME [epoch: 8.58 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05095688744800081		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.05095688744800081 | validation: 0.05606494189670386]
	TIME [epoch: 8.57 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05623148239208622		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.05623148239208622 | validation: 0.06896114922943855]
	TIME [epoch: 8.57 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819247574464972		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.05819247574464972 | validation: 0.03869668720649675]
	TIME [epoch: 8.56 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04117648045013901		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.04117648045013901 | validation: 0.05574396938210901]
	TIME [epoch: 8.58 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0585091046563143		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.0585091046563143 | validation: 0.06209592845449753]
	TIME [epoch: 8.57 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049412836503601246		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.049412836503601246 | validation: 0.04629744332360976]
	TIME [epoch: 8.57 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04906645273295339		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.04906645273295339 | validation: 0.07118949425003776]
	TIME [epoch: 8.57 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0561232771103065		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.0561232771103065 | validation: 0.05670461047872008]
	TIME [epoch: 8.58 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051321588666510376		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.051321588666510376 | validation: 0.05257998248440647]
	TIME [epoch: 8.57 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04293616835871132		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.04293616835871132 | validation: 0.058180481014153636]
	TIME [epoch: 8.56 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04549126695444468		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.04549126695444468 | validation: 0.0640201574020728]
	TIME [epoch: 8.56 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05851859655938587		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.05851859655938587 | validation: 0.03992967180041414]
	TIME [epoch: 8.58 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052552975225789535		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.052552975225789535 | validation: 0.08602247485834275]
	TIME [epoch: 8.56 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0598236657683036		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.0598236657683036 | validation: 0.06231147199416781]
	TIME [epoch: 8.56 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04800307761655659		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.04800307761655659 | validation: 0.06148096185388735]
	TIME [epoch: 8.57 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056617975303161074		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.056617975303161074 | validation: 0.05962835189122822]
	TIME [epoch: 8.58 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05397808997685134		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.05397808997685134 | validation: 0.056503335967578214]
	TIME [epoch: 8.56 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04706601163053851		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.04706601163053851 | validation: 0.09346564277018274]
	TIME [epoch: 8.56 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05585964591504013		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.05585964591504013 | validation: 0.03927577687922745]
	TIME [epoch: 8.56 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04734560014938756		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.04734560014938756 | validation: 0.04725840317982482]
	TIME [epoch: 8.58 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05155409803612356		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.05155409803612356 | validation: 0.04763219977869263]
	TIME [epoch: 8.56 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050541502352873816		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.050541502352873816 | validation: 0.048509230109780185]
	TIME [epoch: 8.56 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229373525663921		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.06229373525663921 | validation: 0.09604008051766932]
	TIME [epoch: 8.58 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059878154915651426		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.059878154915651426 | validation: 0.048905997054682945]
	TIME [epoch: 8.57 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043306694756542294		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.043306694756542294 | validation: 0.07933046933487387]
	TIME [epoch: 8.56 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05964618964680142		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.05964618964680142 | validation: 0.06745681929578128]
	TIME [epoch: 8.56 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05846079770874303		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.05846079770874303 | validation: 0.05460360620847259]
	TIME [epoch: 8.58 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052192924807075006		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.052192924807075006 | validation: 0.05130732255895136]
	TIME [epoch: 8.56 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05803497284578494		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.05803497284578494 | validation: 0.06307863031452413]
	TIME [epoch: 8.56 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060147616950642836		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.060147616950642836 | validation: 0.05499811093087594]
	TIME [epoch: 8.56 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04595825043233762		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.04595825043233762 | validation: 0.04413026740609591]
	TIME [epoch: 8.58 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044109463656566254		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.044109463656566254 | validation: 0.040978199857304665]
	TIME [epoch: 8.57 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05422637800888454		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.05422637800888454 | validation: 0.030827140387144663]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1514.pth
	Model improved!!!
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05037856883327948		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.05037856883327948 | validation: 0.0600712750089486]
	TIME [epoch: 8.57 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04909752873461777		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.04909752873461777 | validation: 0.06205606363896486]
	TIME [epoch: 8.58 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05202600791790592		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.05202600791790592 | validation: 0.05996512684102316]
	TIME [epoch: 8.57 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061887603658751844		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.061887603658751844 | validation: 0.058514082491985836]
	TIME [epoch: 8.56 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052909775085092384		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.052909775085092384 | validation: 0.05148648924587523]
	TIME [epoch: 8.57 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04684598658760021		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.04684598658760021 | validation: 0.04224828051747291]
	TIME [epoch: 8.58 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047719387976240694		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.047719387976240694 | validation: 0.05343843110610863]
	TIME [epoch: 8.57 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05005384833887975		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.05005384833887975 | validation: 0.05624394374640551]
	TIME [epoch: 8.56 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05622380129807707		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.05622380129807707 | validation: 0.04671808523362986]
	TIME [epoch: 8.56 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0479530070020927		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.0479530070020927 | validation: 0.061793763918090695]
	TIME [epoch: 8.58 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05857555267992548		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.05857555267992548 | validation: 0.05267081930060475]
	TIME [epoch: 8.57 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04865143522445734		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.04865143522445734 | validation: 0.05026033343411351]
	TIME [epoch: 8.56 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264242060732449		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.05264242060732449 | validation: 0.04710218991613535]
	TIME [epoch: 8.57 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05644781353929616		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.05644781353929616 | validation: 0.054696126281017526]
	TIME [epoch: 8.59 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043019958866209025		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.043019958866209025 | validation: 0.05208397112553013]
	TIME [epoch: 8.57 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04728255629123825		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.04728255629123825 | validation: 0.06304300881273181]
	TIME [epoch: 8.56 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04804259246752779		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.04804259246752779 | validation: 0.04106326131805349]
	TIME [epoch: 8.57 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05089570044172115		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.05089570044172115 | validation: 0.049631665109754045]
	TIME [epoch: 8.57 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0697989818492754		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.0697989818492754 | validation: 0.1221219984533242]
	TIME [epoch: 8.56 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07852989320542196		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.07852989320542196 | validation: 0.05997544435846071]
	TIME [epoch: 8.56 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0534780517404846		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.0534780517404846 | validation: 0.07386233743732411]
	TIME [epoch: 8.58 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653786145805478		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.0653786145805478 | validation: 0.08531789525528337]
	TIME [epoch: 8.57 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06406589979551078		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.06406589979551078 | validation: 0.046188373660008206]
	TIME [epoch: 8.57 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0564065879099583		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.0564065879099583 | validation: 0.06181385086312717]
	TIME [epoch: 8.57 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05691568392971634		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.05691568392971634 | validation: 0.056293461238904025]
	TIME [epoch: 8.58 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05240648835056365		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.05240648835056365 | validation: 0.08274188134636169]
	TIME [epoch: 8.56 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05210938275756042		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.05210938275756042 | validation: 0.05349479456282]
	TIME [epoch: 8.57 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213106613663625		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.05213106613663625 | validation: 0.05121663189738626]
	TIME [epoch: 8.56 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044562728941556703		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.044562728941556703 | validation: 0.04507890598271477]
	TIME [epoch: 8.58 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043063504917446274		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.043063504917446274 | validation: 0.0447188136821298]
	TIME [epoch: 8.57 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044476063334414846		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.044476063334414846 | validation: 0.043969640911447935]
	TIME [epoch: 8.57 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058298017574193194		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.058298017574193194 | validation: 0.04473286462290417]
	TIME [epoch: 8.57 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04971039276382451		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.04971039276382451 | validation: 0.04268658782279131]
	TIME [epoch: 8.58 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05572403502082972		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.05572403502082972 | validation: 0.06210717397404415]
	TIME [epoch: 8.57 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058380156239478495		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.058380156239478495 | validation: 0.03966449503482168]
	TIME [epoch: 8.57 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05689134784379626		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.05689134784379626 | validation: 0.06806022623363517]
	TIME [epoch: 8.57 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04881413657641835		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.04881413657641835 | validation: 0.032526327644725316]
	TIME [epoch: 8.59 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048661563465555766		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.048661563465555766 | validation: 0.07245325776749176]
	TIME [epoch: 8.56 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04764253061415261		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.04764253061415261 | validation: 0.04016678341133055]
	TIME [epoch: 8.57 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050853271152722944		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.050853271152722944 | validation: 0.05188204458885877]
	TIME [epoch: 8.57 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04917789806901483		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.04917789806901483 | validation: 0.039408290425291384]
	TIME [epoch: 8.59 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04612623661370978		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.04612623661370978 | validation: 0.043457939037383694]
	TIME [epoch: 8.57 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04809873807087144		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.04809873807087144 | validation: 0.05434598190820389]
	TIME [epoch: 8.56 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04220358098021896		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.04220358098021896 | validation: 0.046276363878732726]
	TIME [epoch: 8.58 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05769583940214549		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.05769583940214549 | validation: 0.07899945969869315]
	TIME [epoch: 8.58 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05105615907288484		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.05105615907288484 | validation: 0.04688850863901259]
	TIME [epoch: 8.57 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05442942164818197		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.05442942164818197 | validation: 0.03858048531319185]
	TIME [epoch: 8.57 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039778994940800935		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.039778994940800935 | validation: 0.05900472248256608]
	TIME [epoch: 8.59 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041764954396627925		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.041764954396627925 | validation: 0.03644748009694609]
	TIME [epoch: 8.57 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042464389371086354		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.042464389371086354 | validation: 0.042628020588870885]
	TIME [epoch: 8.57 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047189889226290235		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.047189889226290235 | validation: 0.05653800220568131]
	TIME [epoch: 8.57 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048427488710832974		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.048427488710832974 | validation: 0.0447740958895389]
	TIME [epoch: 8.59 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04931678998486687		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.04931678998486687 | validation: 0.04908120221450439]
	TIME [epoch: 8.57 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04660275503389708		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.04660275503389708 | validation: 0.056046424494690175]
	TIME [epoch: 8.56 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673851084564795		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.04673851084564795 | validation: 0.06346570758447054]
	TIME [epoch: 8.57 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04944685077771575		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.04944685077771575 | validation: 0.0572204008190586]
	TIME [epoch: 8.59 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050527784473742995		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.050527784473742995 | validation: 0.040378165182498316]
	TIME [epoch: 8.57 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05300220407313999		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.05300220407313999 | validation: 0.050918758450285505]
	TIME [epoch: 8.57 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04744181071930929		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.04744181071930929 | validation: 0.05770701020965012]
	TIME [epoch: 8.57 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049567574638377285		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.049567574638377285 | validation: 0.04571441250597573]
	TIME [epoch: 8.58 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05015101234799089		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.05015101234799089 | validation: 0.05081977660195124]
	TIME [epoch: 8.57 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042423892419325857		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.042423892419325857 | validation: 0.03641394192596651]
	TIME [epoch: 8.57 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042700794548651506		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.042700794548651506 | validation: 0.04805823751478786]
	TIME [epoch: 8.57 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05099182876183182		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.05099182876183182 | validation: 0.05723123389145293]
	TIME [epoch: 8.59 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936810345888834		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.05936810345888834 | validation: 0.04462969366617892]
	TIME [epoch: 8.57 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05073883722334995		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.05073883722334995 | validation: 0.059130523309502386]
	TIME [epoch: 8.57 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04760848694595439		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.04760848694595439 | validation: 0.05262845201214251]
	TIME [epoch: 8.57 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04836072135475651		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.04836072135475651 | validation: 0.04495793547792243]
	TIME [epoch: 8.59 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0440684860854812		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.0440684860854812 | validation: 0.04159058132450807]
	TIME [epoch: 8.57 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05361325358902147		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.05361325358902147 | validation: 0.05143711331242832]
	TIME [epoch: 8.57 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04153596135657924		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.04153596135657924 | validation: 0.0598604449876653]
	TIME [epoch: 8.59 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05176023429280675		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.05176023429280675 | validation: 0.04446286363848881]
	TIME [epoch: 8.58 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046312723029885774		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.046312723029885774 | validation: 0.06540803790191128]
	TIME [epoch: 8.57 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04740046658145017		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.04740046658145017 | validation: 0.04768191581393615]
	TIME [epoch: 8.57 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04922718065511942		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.04922718065511942 | validation: 0.0443464485135736]
	TIME [epoch: 8.59 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04638118807970247		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.04638118807970247 | validation: 0.04757256023299762]
	TIME [epoch: 8.57 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03730536135347061		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.03730536135347061 | validation: 0.05502538801535742]
	TIME [epoch: 8.57 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04298492386577722		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.04298492386577722 | validation: 0.06158677019928315]
	TIME [epoch: 8.57 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05214386642590092		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.05214386642590092 | validation: 0.06472639488368304]
	TIME [epoch: 8.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05038132958465463		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.05038132958465463 | validation: 0.04914378775380593]
	TIME [epoch: 8.57 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053107986905917615		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.053107986905917615 | validation: 0.0555390771715167]
	TIME [epoch: 8.57 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04921930462266143		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.04921930462266143 | validation: 0.05348018514931574]
	TIME [epoch: 8.57 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393586283030281		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.06393586283030281 | validation: 0.04771818723567391]
	TIME [epoch: 8.59 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856596838052278		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.04856596838052278 | validation: 0.05067695790404935]
	TIME [epoch: 8.57 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05447345647104055		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.05447345647104055 | validation: 0.07737799751552121]
	TIME [epoch: 8.57 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05168813910275464		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.05168813910275464 | validation: 0.06134974706380253]
	TIME [epoch: 8.57 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05786066619959098		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.05786066619959098 | validation: 0.045473859726954606]
	TIME [epoch: 8.59 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04517685473229199		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.04517685473229199 | validation: 0.042869827915192976]
	TIME [epoch: 8.57 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04415581797254499		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.04415581797254499 | validation: 0.04133526442436094]
	TIME [epoch: 8.56 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046419928881009126		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.046419928881009126 | validation: 0.03968068514528522]
	TIME [epoch: 8.57 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03585546370238175		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.03585546370238175 | validation: 0.035612947486094185]
	TIME [epoch: 8.59 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04000617686589243		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.04000617686589243 | validation: 0.0381110341165998]
	TIME [epoch: 8.56 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0395065178528365		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.0395065178528365 | validation: 0.04839012191998759]
	TIME [epoch: 8.57 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048608335799127794		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.048608335799127794 | validation: 0.05368022523034334]
	TIME [epoch: 8.57 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05197640438441936		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.05197640438441936 | validation: 0.06061827997548823]
	TIME [epoch: 8.59 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04808597695278219		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.04808597695278219 | validation: 0.03764400665720056]
	TIME [epoch: 8.56 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04572503354090087		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.04572503354090087 | validation: 0.0445173055722661]
	TIME [epoch: 8.57 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04693922711025667		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.04693922711025667 | validation: 0.050319005272397396]
	TIME [epoch: 8.58 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057001537508828526		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.057001537508828526 | validation: 0.05959874967941915]
	TIME [epoch: 8.58 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05728738083671595		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.05728738083671595 | validation: 0.055988804078936]
	TIME [epoch: 8.57 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05375126801388049		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.05375126801388049 | validation: 0.06067369042035059]
	TIME [epoch: 8.57 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05547671772583217		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.05547671772583217 | validation: 0.038455633672204434]
	TIME [epoch: 8.58 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04681047401174975		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.04681047401174975 | validation: 0.042800337944034456]
	TIME [epoch: 8.57 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05223162241519572		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.05223162241519572 | validation: 0.03635769079125244]
	TIME [epoch: 8.56 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044984125725961076		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.044984125725961076 | validation: 0.042938786075739074]
	TIME [epoch: 8.58 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04718070824843885		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.04718070824843885 | validation: 0.0385205083077864]
	TIME [epoch: 8.58 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045100359201164106		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.045100359201164106 | validation: 0.03774852188444235]
	TIME [epoch: 8.57 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049077783532765824		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.049077783532765824 | validation: 0.04176306111860257]
	TIME [epoch: 8.56 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04812866681086414		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.04812866681086414 | validation: 0.04426119120256548]
	TIME [epoch: 8.57 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05266389202039166		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.05266389202039166 | validation: 0.04065063570523495]
	TIME [epoch: 8.58 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051242183515325314		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.051242183515325314 | validation: 0.04434939844358866]
	TIME [epoch: 8.57 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04552379457732092		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.04552379457732092 | validation: 0.0594032562821793]
	TIME [epoch: 8.57 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05015052232553424		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.05015052232553424 | validation: 0.0395158666858873]
	TIME [epoch: 8.57 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04976836884158713		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.04976836884158713 | validation: 0.04691182606866855]
	TIME [epoch: 8.58 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046063475546749534		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.046063475546749534 | validation: 0.04543285864504863]
	TIME [epoch: 8.57 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0419026645855883		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.0419026645855883 | validation: 0.040124431719252486]
	TIME [epoch: 8.57 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047273230146112274		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.047273230146112274 | validation: 0.06320482077820042]
	TIME [epoch: 8.57 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050347873721901346		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.050347873721901346 | validation: 0.03897346138481936]
	TIME [epoch: 8.59 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03842459334679876		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.03842459334679876 | validation: 0.06324630106683869]
	TIME [epoch: 8.56 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0431358032674621		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.0431358032674621 | validation: 0.03942491726619417]
	TIME [epoch: 8.56 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04539770062804264		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.04539770062804264 | validation: 0.03732655611146829]
	TIME [epoch: 8.57 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05659586293287496		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.05659586293287496 | validation: 0.04675577812810146]
	TIME [epoch: 8.58 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04241072456724719		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.04241072456724719 | validation: 0.04532901667905468]
	TIME [epoch: 8.57 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0440787840585178		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.0440787840585178 | validation: 0.051256237215371245]
	TIME [epoch: 8.56 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048507789262947076		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.048507789262947076 | validation: 0.059689541277260706]
	TIME [epoch: 8.58 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04702776707782894		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.04702776707782894 | validation: 0.05154425676937101]
	TIME [epoch: 8.58 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0498724291031353		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.0498724291031353 | validation: 0.042750472793172775]
	TIME [epoch: 8.57 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04965168638764761		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.04965168638764761 | validation: 0.051059432535080516]
	TIME [epoch: 8.57 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680042488027387		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.04680042488027387 | validation: 0.05614751090291595]
	TIME [epoch: 8.58 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051084464123955606		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.051084464123955606 | validation: 0.05384544689210145]
	TIME [epoch: 8.57 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04308091263497075		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.04308091263497075 | validation: 0.050901952617594774]
	TIME [epoch: 8.56 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043578465508576227		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.043578465508576227 | validation: 0.0449377895363136]
	TIME [epoch: 8.56 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04435040232118588		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.04435040232118588 | validation: 0.03843732222446227]
	TIME [epoch: 8.58 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041730289862809675		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.041730289862809675 | validation: 0.0425579206795187]
	TIME [epoch: 8.58 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04661509161101697		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.04661509161101697 | validation: 0.04483414529226635]
	TIME [epoch: 8.57 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039330298279804124		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.039330298279804124 | validation: 0.03525057947409726]
	TIME [epoch: 8.57 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041675824035746524		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.041675824035746524 | validation: 0.058061301792491915]
	TIME [epoch: 8.59 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05211685907407787		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.05211685907407787 | validation: 0.04364145961557022]
	TIME [epoch: 8.57 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04578468339753602		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.04578468339753602 | validation: 0.0323763297255273]
	TIME [epoch: 8.56 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04385175929321505		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.04385175929321505 | validation: 0.0409441188608615]
	TIME [epoch: 8.57 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04081353151286271		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.04081353151286271 | validation: 0.05125952957696788]
	TIME [epoch: 8.58 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04382376930680465		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.04382376930680465 | validation: 0.049064856086064396]
	TIME [epoch: 8.57 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986842383093143		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.04986842383093143 | validation: 0.04886268861096385]
	TIME [epoch: 8.57 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049659539925018134		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.049659539925018134 | validation: 0.036439088258818815]
	TIME [epoch: 8.57 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053311527459608564		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.053311527459608564 | validation: 0.0450805339410116]
	TIME [epoch: 8.58 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04721820157797106		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.04721820157797106 | validation: 0.05886144676174289]
	TIME [epoch: 8.57 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282203571745739		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.04282203571745739 | validation: 0.0396742082846981]
	TIME [epoch: 8.56 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043132749561312814		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.043132749561312814 | validation: 0.041942486939241116]
	TIME [epoch: 8.57 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04125483303412987		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.04125483303412987 | validation: 0.05657513076015737]
	TIME [epoch: 8.59 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05537628249069469		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.05537628249069469 | validation: 0.05808865668873092]
	TIME [epoch: 8.57 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03833179053658291		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.03833179053658291 | validation: 0.05171251546318428]
	TIME [epoch: 8.56 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04870516515320746		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.04870516515320746 | validation: 0.05692922065505294]
	TIME [epoch: 8.57 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049621177442229		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.049621177442229 | validation: 0.04648204718798918]
	TIME [epoch: 8.57 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043934305922990705		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.043934305922990705 | validation: 0.03662393712635429]
	TIME [epoch: 8.56 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870140769495643		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.05870140769495643 | validation: 0.08197544485388346]
	TIME [epoch: 8.57 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06161699107975843		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.06161699107975843 | validation: 0.03813564566749493]
	TIME [epoch: 8.59 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04666483724661353		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.04666483724661353 | validation: 0.040082089184773094]
	TIME [epoch: 8.57 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04913751632852804		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.04913751632852804 | validation: 0.04236268366676705]
	TIME [epoch: 8.57 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042481915812073966		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.042481915812073966 | validation: 0.04000624488127824]
	TIME [epoch: 8.57 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052096025385496195		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.052096025385496195 | validation: 0.04509843807809724]
	TIME [epoch: 8.59 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047209821863744415		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.047209821863744415 | validation: 0.052545306081155194]
	TIME [epoch: 8.57 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051324919765002155		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.051324919765002155 | validation: 0.053087451802722264]
	TIME [epoch: 8.56 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04790117763404617		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.04790117763404617 | validation: 0.04809316682250958]
	TIME [epoch: 8.56 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04876004884045411		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.04876004884045411 | validation: 0.04855137934361048]
	TIME [epoch: 8.58 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04384214227492668		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.04384214227492668 | validation: 0.04712019139051743]
	TIME [epoch: 8.57 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0505099502076977		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.0505099502076977 | validation: 0.056353160124451164]
	TIME [epoch: 8.57 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06773598746417342		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.06773598746417342 | validation: 0.07729339464561966]
	TIME [epoch: 8.57 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06335623287128987		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.06335623287128987 | validation: 0.05451376608211198]
	TIME [epoch: 8.59 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05184320491723887		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.05184320491723887 | validation: 0.059200007701724705]
	TIME [epoch: 8.57 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04763498889494397		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.04763498889494397 | validation: 0.04265539296082345]
	TIME [epoch: 8.56 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04449849451877563		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.04449849451877563 | validation: 0.04569195648777449]
	TIME [epoch: 8.57 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04255513981494713		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.04255513981494713 | validation: 0.032666887648360225]
	TIME [epoch: 8.59 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043517739256600456		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.043517739256600456 | validation: 0.051963449211523]
	TIME [epoch: 8.56 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044671795506959586		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.044671795506959586 | validation: 0.040352640173989984]
	TIME [epoch: 8.57 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042693244899985924		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.042693244899985924 | validation: 0.031514790441454416]
	TIME [epoch: 8.57 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04103864355122612		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.04103864355122612 | validation: 0.04267909055795217]
	TIME [epoch: 8.58 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04795558532396311		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.04795558532396311 | validation: 0.033485442067720514]
	TIME [epoch: 8.57 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042602844567387436		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.042602844567387436 | validation: 0.04917327594548159]
	TIME [epoch: 8.56 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04210597571752746		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.04210597571752746 | validation: 0.04266624488351601]
	TIME [epoch: 8.58 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03867337300709602		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.03867337300709602 | validation: 0.041990091091794954]
	TIME [epoch: 8.58 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04455248714477706		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.04455248714477706 | validation: 0.03981853231485375]
	TIME [epoch: 8.56 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044450833915459786		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.044450833915459786 | validation: 0.030283622008979896]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1696.pth
	Model improved!!!
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0403832131866835		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.0403832131866835 | validation: 0.03565758094011886]
	TIME [epoch: 8.59 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0377613549560931		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.0377613549560931 | validation: 0.044845030560448154]
	TIME [epoch: 8.57 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046025392996238944		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.046025392996238944 | validation: 0.05320616070868359]
	TIME [epoch: 8.57 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04517455001142485		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.04517455001142485 | validation: 0.04795703667072611]
	TIME [epoch: 8.57 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04727601028350557		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.04727601028350557 | validation: 0.04770419838350197]
	TIME [epoch: 8.59 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04787584626503163		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.04787584626503163 | validation: 0.044080312084454044]
	TIME [epoch: 8.57 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04219335228524372		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.04219335228524372 | validation: 0.03848321315445327]
	TIME [epoch: 8.57 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856043550157922		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.04856043550157922 | validation: 0.039599701825460416]
	TIME [epoch: 8.57 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04323744035194186		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.04323744035194186 | validation: 0.047581072707255964]
	TIME [epoch: 8.59 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043906235915664296		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.043906235915664296 | validation: 0.05428909723214882]
	TIME [epoch: 8.57 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053148451074477944		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.053148451074477944 | validation: 0.06818085839330519]
	TIME [epoch: 8.57 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04148006764177971		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.04148006764177971 | validation: 0.05693196862474506]
	TIME [epoch: 8.57 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0508133727578526		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.0508133727578526 | validation: 0.05935618941974428]
	TIME [epoch: 8.58 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045630726732572666		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.045630726732572666 | validation: 0.04424245176268754]
	TIME [epoch: 8.57 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042430221786403176		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.042430221786403176 | validation: 0.051530089843980845]
	TIME [epoch: 8.57 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044151814866625484		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.044151814866625484 | validation: 0.04480438385714221]
	TIME [epoch: 8.57 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04056979753754229		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.04056979753754229 | validation: 0.04958782252349343]
	TIME [epoch: 8.58 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03824678201354979		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.03824678201354979 | validation: 0.05239470798886732]
	TIME [epoch: 8.57 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04817431611390911		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.04817431611390911 | validation: 0.037944918244066594]
	TIME [epoch: 8.57 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04297206547418932		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.04297206547418932 | validation: 0.04069462250297827]
	TIME [epoch: 8.57 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03958598713517107		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.03958598713517107 | validation: 0.0452443242975861]
	TIME [epoch: 8.59 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036269564127484395		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.036269564127484395 | validation: 0.044979071423129985]
	TIME [epoch: 8.57 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0353859079271979		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.0353859079271979 | validation: 0.0580138597714993]
	TIME [epoch: 8.57 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04643102513266874		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.04643102513266874 | validation: 0.05075790401260445]
	TIME [epoch: 8.58 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04478699729125918		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.04478699729125918 | validation: 0.04288117097692613]
	TIME [epoch: 8.58 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04051876443371287		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.04051876443371287 | validation: 0.04301299350859457]
	TIME [epoch: 8.57 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042574154213043405		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.042574154213043405 | validation: 0.045164070740090864]
	TIME [epoch: 8.57 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043677930275551044		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.043677930275551044 | validation: 0.043790294731644905]
	TIME [epoch: 8.59 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04470853494313076		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.04470853494313076 | validation: 0.043722522107782075]
	TIME [epoch: 8.57 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045169297401167076		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.045169297401167076 | validation: 0.05417618688455805]
	TIME [epoch: 8.57 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04290146094837666		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.04290146094837666 | validation: 0.03604123877124027]
	TIME [epoch: 8.57 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04598081835805014		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.04598081835805014 | validation: 0.0532355155989077]
	TIME [epoch: 8.58 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04415399854889239		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.04415399854889239 | validation: 0.036690663544375]
	TIME [epoch: 8.57 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04307472602974686		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.04307472602974686 | validation: 0.04218115053725241]
	TIME [epoch: 8.57 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04121400737956185		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.04121400737956185 | validation: 0.030864710575509914]
	TIME [epoch: 8.57 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04642944308686969		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.04642944308686969 | validation: 0.03694678917440775]
	TIME [epoch: 8.59 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03711287197097493		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.03711287197097493 | validation: 0.042954132970770026]
	TIME [epoch: 8.57 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03651562724602696		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.03651562724602696 | validation: 0.026640450968691845]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1734.pth
	Model improved!!!
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036713522023950965		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.036713522023950965 | validation: 0.04122380036335883]
	TIME [epoch: 8.57 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03887261006536705		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.03887261006536705 | validation: 0.04642805067756346]
	TIME [epoch: 8.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03708115723063761		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.03708115723063761 | validation: 0.047258008197219085]
	TIME [epoch: 8.57 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05103226731769198		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.05103226731769198 | validation: 0.0692357713340654]
	TIME [epoch: 8.57 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04827214074734058		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.04827214074734058 | validation: 0.047503980180696834]
	TIME [epoch: 8.58 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043370383366176504		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.043370383366176504 | validation: 0.04043691928566397]
	TIME [epoch: 8.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04753177917526042		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.04753177917526042 | validation: 0.06599400369799668]
	TIME [epoch: 8.58 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052677034799985756		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.052677034799985756 | validation: 0.04013945796074375]
	TIME [epoch: 8.57 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03742798163072374		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.03742798163072374 | validation: 0.04238862947897535]
	TIME [epoch: 8.59 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04488382621167689		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.04488382621167689 | validation: 0.055000751939488654]
	TIME [epoch: 8.58 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04290878988512981		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.04290878988512981 | validation: 0.03645461967234958]
	TIME [epoch: 8.57 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05900090194883203		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.05900090194883203 | validation: 0.058823354905786385]
	TIME [epoch: 8.57 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046183600379402945		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.046183600379402945 | validation: 0.04740826771141368]
	TIME [epoch: 8.59 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04411092284247077		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.04411092284247077 | validation: 0.035435137684036534]
	TIME [epoch: 8.58 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043234518236950306		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.043234518236950306 | validation: 0.04086298072715334]
	TIME [epoch: 8.57 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04547801608078435		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.04547801608078435 | validation: 0.04058415442138156]
	TIME [epoch: 8.57 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04369335186184754		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.04369335186184754 | validation: 0.044979482123697526]
	TIME [epoch: 8.59 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04798949113471545		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.04798949113471545 | validation: 0.04776547169838544]
	TIME [epoch: 8.57 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04529981518838991		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.04529981518838991 | validation: 0.04692771515185205]
	TIME [epoch: 8.57 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0509793747637017		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.0509793747637017 | validation: 0.0508394636814653]
	TIME [epoch: 8.57 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04374061108829201		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.04374061108829201 | validation: 0.04892512548381779]
	TIME [epoch: 8.59 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04560438323364981		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.04560438323364981 | validation: 0.06064580592339232]
	TIME [epoch: 8.58 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04601081106423703		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.04601081106423703 | validation: 0.036382746453849354]
	TIME [epoch: 8.57 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04378839380965463		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.04378839380965463 | validation: 0.0424784344474124]
	TIME [epoch: 8.57 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03799731251261523		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.03799731251261523 | validation: 0.04107975131439641]
	TIME [epoch: 8.59 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03930779572256199		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.03930779572256199 | validation: 0.04092067597978287]
	TIME [epoch: 8.58 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03890690172396284		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.03890690172396284 | validation: 0.039337354208006596]
	TIME [epoch: 8.57 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04070277902714998		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.04070277902714998 | validation: 0.038009552690807746]
	TIME [epoch: 8.57 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044719841120730845		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.044719841120730845 | validation: 0.04788191167577598]
	TIME [epoch: 8.59 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052232746123510906		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.052232746123510906 | validation: 0.05851112492909391]
	TIME [epoch: 8.57 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04528010442730425		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.04528010442730425 | validation: 0.03975024059329608]
	TIME [epoch: 8.57 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282971352624068		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.04282971352624068 | validation: 0.0416715998538372]
	TIME [epoch: 8.57 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0439069280437907		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.0439069280437907 | validation: 0.04222861803513519]
	TIME [epoch: 8.59 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041337532924596576		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.041337532924596576 | validation: 0.04903672722970971]
	TIME [epoch: 8.57 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039419293062220515		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.039419293062220515 | validation: 0.05945905761194072]
	TIME [epoch: 8.57 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043299618856954755		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.043299618856954755 | validation: 0.04708362298559328]
	TIME [epoch: 8.58 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05141449744261974		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.05141449744261974 | validation: 0.05928806308981312]
	TIME [epoch: 8.58 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04127767990099365		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.04127767990099365 | validation: 0.040569156401629274]
	TIME [epoch: 8.57 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04029768570758403		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.04029768570758403 | validation: 0.03914709052537397]
	TIME [epoch: 8.57 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03448176616073481		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.03448176616073481 | validation: 0.045556571763938014]
	TIME [epoch: 8.59 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03847538954424412		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.03847538954424412 | validation: 0.040903753257797715]
	TIME [epoch: 8.58 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04531689756963632		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.04531689756963632 | validation: 0.044091934134168335]
	TIME [epoch: 8.57 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042928909376921676		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.042928909376921676 | validation: 0.03282995463135278]
	TIME [epoch: 8.56 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872546316002476		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.03872546316002476 | validation: 0.0331611893973179]
	TIME [epoch: 8.59 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042144633159984075		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.042144633159984075 | validation: 0.05077280918943205]
	TIME [epoch: 8.57 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04217581238475697		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.04217581238475697 | validation: 0.032185073922865376]
	TIME [epoch: 8.57 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037011050802508036		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.037011050802508036 | validation: 0.038886249694291726]
	TIME [epoch: 8.57 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04259363848080658		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.04259363848080658 | validation: 0.036718743567230844]
	TIME [epoch: 8.59 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04762475015340461		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.04762475015340461 | validation: 0.049501722657733845]
	TIME [epoch: 8.57 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04386444879024137		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.04386444879024137 | validation: 0.04162133117179058]
	TIME [epoch: 8.57 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040947630572714555		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.040947630572714555 | validation: 0.039859208716299485]
	TIME [epoch: 8.57 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04055627477647444		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.04055627477647444 | validation: 0.039788154094679985]
	TIME [epoch: 8.59 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045356096828198564		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.045356096828198564 | validation: 0.035059273912338665]
	TIME [epoch: 8.57 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037383632623532025		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.037383632623532025 | validation: 0.02773423413457883]
	TIME [epoch: 8.57 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038658820379147356		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.038658820379147356 | validation: 0.0391129682199556]
	TIME [epoch: 8.56 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03928905106385823		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.03928905106385823 | validation: 0.04280113746306011]
	TIME [epoch: 8.59 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04132614998760677		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.04132614998760677 | validation: 0.05579293215077284]
	TIME [epoch: 8.56 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04698656962566876		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.04698656962566876 | validation: 0.03284369215413606]
	TIME [epoch: 8.57 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04004574020845253		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.04004574020845253 | validation: 0.029875099075203082]
	TIME [epoch: 8.57 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04185636484186388		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.04185636484186388 | validation: 0.04035083824362247]
	TIME [epoch: 8.59 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044938037856184235		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.044938037856184235 | validation: 0.03536320189809711]
	TIME [epoch: 8.57 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04190932595284567		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.04190932595284567 | validation: 0.04767210917903536]
	TIME [epoch: 8.57 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04255539439715531		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.04255539439715531 | validation: 0.03760751539348514]
	TIME [epoch: 8.58 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041777149759003526		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.041777149759003526 | validation: 0.04031702153407924]
	TIME [epoch: 8.57 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046565144900936904		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.046565144900936904 | validation: 0.027280736620658472]
	TIME [epoch: 8.57 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036952766613417246		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.036952766613417246 | validation: 0.02895277819643454]
	TIME [epoch: 8.57 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043682033078541314		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.043682033078541314 | validation: 0.04227728690091923]
	TIME [epoch: 8.58 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037482154079286456		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.037482154079286456 | validation: 0.03765296425952955]
	TIME [epoch: 8.57 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04500184587837941		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.04500184587837941 | validation: 0.044136206399816844]
	TIME [epoch: 8.57 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0462140686499349		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.0462140686499349 | validation: 0.03101931197618462]
	TIME [epoch: 8.57 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044301704534504535		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.044301704534504535 | validation: 0.047064649017609435]
	TIME [epoch: 8.58 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05012506028655874		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.05012506028655874 | validation: 0.023694357740926354]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1806.pth
	Model improved!!!
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03979849392589222		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.03979849392589222 | validation: 0.025937329876425216]
	TIME [epoch: 8.56 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03523132349479945		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.03523132349479945 | validation: 0.032823558967227454]
	TIME [epoch: 8.56 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037125341611326516		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.037125341611326516 | validation: 0.03701874560591378]
	TIME [epoch: 8.59 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0399170914696508		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.0399170914696508 | validation: 0.0397749121637672]
	TIME [epoch: 8.57 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03818153454612348		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.03818153454612348 | validation: 0.03439485740653403]
	TIME [epoch: 8.57 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04473477954330077		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.04473477954330077 | validation: 0.03313200158396799]
	TIME [epoch: 8.56 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03606230968564614		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.03606230968564614 | validation: 0.032648475094585676]
	TIME [epoch: 8.58 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03588648418209195		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.03588648418209195 | validation: 0.03838975674830978]
	TIME [epoch: 8.56 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03598494891487311		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.03598494891487311 | validation: 0.03621451201703883]
	TIME [epoch: 8.56 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03932770422366164		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.03932770422366164 | validation: 0.055935623893342515]
	TIME [epoch: 8.57 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0451384021930102		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.0451384021930102 | validation: 0.04169835663320506]
	TIME [epoch: 8.58 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041326066197657954		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.041326066197657954 | validation: 0.041075100862815454]
	TIME [epoch: 8.57 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03741628711215301		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.03741628711215301 | validation: 0.03760835764336119]
	TIME [epoch: 8.56 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03783702356341345		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.03783702356341345 | validation: 0.045169917046146715]
	TIME [epoch: 8.57 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03888357854982176		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.03888357854982176 | validation: 0.031248225233196578]
	TIME [epoch: 8.58 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036375244809286375		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.036375244809286375 | validation: 0.040700688029935345]
	TIME [epoch: 8.56 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03750239298754724		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.03750239298754724 | validation: 0.047030060693169284]
	TIME [epoch: 8.56 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04114441471095699		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.04114441471095699 | validation: 0.04039023158646876]
	TIME [epoch: 8.57 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0364180140235514		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.0364180140235514 | validation: 0.04018338259765026]
	TIME [epoch: 8.57 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03867223438567435		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.03867223438567435 | validation: 0.03301153812935392]
	TIME [epoch: 8.56 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0345409053388951		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.0345409053388951 | validation: 0.046721417049296485]
	TIME [epoch: 8.58 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03617908714476088		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.03617908714476088 | validation: 0.0480538600810925]
	TIME [epoch: 8.58 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039311311672481655		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.039311311672481655 | validation: 0.03716196715013952]
	TIME [epoch: 8.57 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03156041611336653		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.03156041611336653 | validation: 0.04343872288363218]
	TIME [epoch: 8.56 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039532742323064585		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.039532742323064585 | validation: 0.038804152668943395]
	TIME [epoch: 8.56 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040435713381101454		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.040435713381101454 | validation: 0.04050426237089092]
	TIME [epoch: 8.58 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04172280014334752		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.04172280014334752 | validation: 0.057568517773565836]
	TIME [epoch: 8.56 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045343288582582554		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.045343288582582554 | validation: 0.05808708385009418]
	TIME [epoch: 8.56 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04367387642135732		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.04367387642135732 | validation: 0.03742385207609652]
	TIME [epoch: 8.56 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041516711975287376		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.041516711975287376 | validation: 0.05467712962964283]
	TIME [epoch: 8.58 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04553838254712097		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.04553838254712097 | validation: 0.036124744203979556]
	TIME [epoch: 8.57 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037637078886202956		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.037637078886202956 | validation: 0.038414490567058736]
	TIME [epoch: 8.57 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036212104529858125		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.036212104529858125 | validation: 0.04428824750119982]
	TIME [epoch: 8.56 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04419775532341847		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.04419775532341847 | validation: 0.031204241111552553]
	TIME [epoch: 8.58 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03553410373990674		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.03553410373990674 | validation: 0.037832773943068956]
	TIME [epoch: 8.57 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032362598694568784		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.032362598694568784 | validation: 0.03305555137318232]
	TIME [epoch: 8.57 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872140870324808		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.03872140870324808 | validation: 0.028881313820699528]
	TIME [epoch: 8.57 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042908291162823124		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.042908291162823124 | validation: 0.03676134319193882]
	TIME [epoch: 8.58 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04057033142163653		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.04057033142163653 | validation: 0.04013557041662864]
	TIME [epoch: 8.57 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040569592661628115		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.040569592661628115 | validation: 0.04798996898670349]
	TIME [epoch: 8.57 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043241444741161025		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.043241444741161025 | validation: 0.0548394657709486]
	TIME [epoch: 8.56 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044094283571744775		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.044094283571744775 | validation: 0.04149083494325323]
	TIME [epoch: 8.59 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03684013413826537		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.03684013413826537 | validation: 0.03760284222446579]
	TIME [epoch: 8.57 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03725068479116199		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.03725068479116199 | validation: 0.044133529034347335]
	TIME [epoch: 8.56 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0405383038557706		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.0405383038557706 | validation: 0.03015172345436536]
	TIME [epoch: 8.58 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037269633557714885		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.037269633557714885 | validation: 0.03245208883245635]
	TIME [epoch: 8.58 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037227948467826365		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.037227948467826365 | validation: 0.03186878596883487]
	TIME [epoch: 8.57 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042659497168586205		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.042659497168586205 | validation: 0.030946960883587782]
	TIME [epoch: 8.57 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03857618736590817		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.03857618736590817 | validation: 0.02889921866153817]
	TIME [epoch: 8.58 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037382811694516835		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.037382811694516835 | validation: 0.03789054629203299]
	TIME [epoch: 8.57 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03948939962544952		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.03948939962544952 | validation: 0.044129178403446614]
	TIME [epoch: 8.56 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046688480774041995		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.046688480774041995 | validation: 0.05350289984397448]
	TIME [epoch: 8.56 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060616323013269593		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.060616323013269593 | validation: 0.0405633522519621]
	TIME [epoch: 8.58 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04466347205518833		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.04466347205518833 | validation: 0.03688845651429733]
	TIME [epoch: 8.57 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0444237773568703		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.0444237773568703 | validation: 0.054578163568431384]
	TIME [epoch: 8.56 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04263077585675082		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.04263077585675082 | validation: 0.04104012921562865]
	TIME [epoch: 8.56 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04283355058928277		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.04283355058928277 | validation: 0.045594953979700814]
	TIME [epoch: 8.58 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040712615424474435		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.040712615424474435 | validation: 0.04933099224486602]
	TIME [epoch: 8.57 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03908316687459244		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.03908316687459244 | validation: 0.04635122008573059]
	TIME [epoch: 8.57 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046717980297974436		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.046717980297974436 | validation: 0.036528395658151316]
	TIME [epoch: 8.56 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039962351133490906		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.039962351133490906 | validation: 0.04106463722587127]
	TIME [epoch: 8.58 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041172008788904396		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.041172008788904396 | validation: 0.0461504679467424]
	TIME [epoch: 8.57 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03625792333219916		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.03625792333219916 | validation: 0.03604511569280254]
	TIME [epoch: 8.57 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0396844321815632		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.0396844321815632 | validation: 0.04204008160923803]
	TIME [epoch: 8.57 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03751226186010655		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.03751226186010655 | validation: 0.03574761307520515]
	TIME [epoch: 8.59 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036279792537227615		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.036279792537227615 | validation: 0.0345803078632487]
	TIME [epoch: 8.57 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04079731977445775		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.04079731977445775 | validation: 0.04116099781324997]
	TIME [epoch: 8.56 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03767195204079813		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.03767195204079813 | validation: 0.05099654492575892]
	TIME [epoch: 8.57 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039173589942745		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.039173589942745 | validation: 0.03627251971835754]
	TIME [epoch: 8.58 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0397222455175422		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.0397222455175422 | validation: 0.044356689957940315]
	TIME [epoch: 8.56 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0378299077925713		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.0378299077925713 | validation: 0.04389231686584764]
	TIME [epoch: 8.56 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04190231793255643		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.04190231793255643 | validation: 0.04521847241230979]
	TIME [epoch: 8.58 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035805084536366036		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.035805084536366036 | validation: 0.04258671442157083]
	TIME [epoch: 8.57 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040097014932169606		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.040097014932169606 | validation: 0.03184822534058721]
	TIME [epoch: 8.57 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043599688544065124		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.043599688544065124 | validation: 0.05966797128858652]
	TIME [epoch: 8.57 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043322715727657134		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.043322715727657134 | validation: 0.04406118460813892]
	TIME [epoch: 8.58 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03747454297235681		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.03747454297235681 | validation: 0.0357662367601147]
	TIME [epoch: 8.57 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039252665592746226		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.039252665592746226 | validation: 0.05609432344615528]
	TIME [epoch: 8.56 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04264034842064102		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.04264034842064102 | validation: 0.03857356717869401]
	TIME [epoch: 8.55 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0423948650563941		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.0423948650563941 | validation: 0.05361598135579219]
	TIME [epoch: 8.58 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047480611101986606		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.047480611101986606 | validation: 0.03666129199414335]
	TIME [epoch: 8.57 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040803759845332625		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.040803759845332625 | validation: 0.03186544163358612]
	TIME [epoch: 8.56 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044379228176070776		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.044379228176070776 | validation: 0.046748119453755496]
	TIME [epoch: 8.56 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0420117576577431		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.0420117576577431 | validation: 0.02779662331746168]
	TIME [epoch: 8.59 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03801357468275232		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.03801357468275232 | validation: 0.030339022484796176]
	TIME [epoch: 8.56 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03886715188475236		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.03886715188475236 | validation: 0.029167856056784857]
	TIME [epoch: 8.57 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038838952023593096		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.038838952023593096 | validation: 0.0386234734082872]
	TIME [epoch: 8.57 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039433119025314343		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.039433119025314343 | validation: 0.03510334116618611]
	TIME [epoch: 8.58 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042887406510529816		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.042887406510529816 | validation: 0.04554185741420283]
	TIME [epoch: 8.57 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04689243174396297		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.04689243174396297 | validation: 0.04706394432586583]
	TIME [epoch: 8.56 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03951002347161592		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.03951002347161592 | validation: 0.04158844308337255]
	TIME [epoch: 8.57 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03959033143195757		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.03959033143195757 | validation: 0.04269185468949922]
	TIME [epoch: 8.59 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03932009904700976		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.03932009904700976 | validation: 0.042816333393022515]
	TIME [epoch: 8.57 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040451768184592424		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.040451768184592424 | validation: 0.04549224418340831]
	TIME [epoch: 8.56 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03703250162765627		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.03703250162765627 | validation: 0.040726714099477715]
	TIME [epoch: 8.56 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03656150853336049		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.03656150853336049 | validation: 0.0348034066880548]
	TIME [epoch: 8.58 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03263871007923656		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.03263871007923656 | validation: 0.0334296496312924]
	TIME [epoch: 8.57 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034715096006662644		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.034715096006662644 | validation: 0.036669128602821066]
	TIME [epoch: 8.57 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03776726493924689		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.03776726493924689 | validation: 0.03553515509859701]
	TIME [epoch: 8.58 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04194804645069184		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.04194804645069184 | validation: 0.04171447688726532]
	TIME [epoch: 8.57 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03790350969556579		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.03790350969556579 | validation: 0.037330963357953884]
	TIME [epoch: 8.57 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041033956104660305		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.041033956104660305 | validation: 0.031361901155073105]
	TIME [epoch: 8.57 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03558034683074092		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.03558034683074092 | validation: 0.029901205940743303]
	TIME [epoch: 8.58 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035808956135775186		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.035808956135775186 | validation: 0.047510164904707455]
	TIME [epoch: 8.56 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033760387249878024		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.033760387249878024 | validation: 0.035971331453367984]
	TIME [epoch: 8.56 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03857522514985118		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.03857522514985118 | validation: 0.03149118867660497]
	TIME [epoch: 8.56 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04672583111367369		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.04672583111367369 | validation: 0.053974563378971434]
	TIME [epoch: 8.58 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040991899530024474		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.040991899530024474 | validation: 0.03369764741518814]
	TIME [epoch: 8.57 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035062705529090056		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.035062705529090056 | validation: 0.042589113110596835]
	TIME [epoch: 8.56 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034486725329565655		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.034486725329565655 | validation: 0.04408047255526239]
	TIME [epoch: 8.56 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033658278530360644		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.033658278530360644 | validation: 0.07089981067111746]
	TIME [epoch: 8.58 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04092963994893144		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.04092963994893144 | validation: 0.03852751182559052]
	TIME [epoch: 8.57 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04187593933927377		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.04187593933927377 | validation: 0.03726033419002392]
	TIME [epoch: 8.56 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960409141544956		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.03960409141544956 | validation: 0.0432901799207626]
	TIME [epoch: 8.57 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03503853451833283		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.03503853451833283 | validation: 0.04592852153236326]
	TIME [epoch: 8.58 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03398830765026979		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.03398830765026979 | validation: 0.02907276941425457]
	TIME [epoch: 8.57 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040205763044110714		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.040205763044110714 | validation: 0.03457166899948343]
	TIME [epoch: 8.56 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04195934167575181		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.04195934167575181 | validation: 0.035276595194593495]
	TIME [epoch: 8.56 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0359370114480155		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.0359370114480155 | validation: 0.04087073028223778]
	TIME [epoch: 8.58 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033564496259280444		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.033564496259280444 | validation: 0.03208566095515969]
	TIME [epoch: 8.57 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03624376799955435		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.03624376799955435 | validation: 0.035850027076104726]
	TIME [epoch: 8.56 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0379406400903426		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.0379406400903426 | validation: 0.033301033310564755]
	TIME [epoch: 8.56 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04309647565720218		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.04309647565720218 | validation: 0.04519542376146424]
	TIME [epoch: 8.59 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03154101934475698		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.03154101934475698 | validation: 0.03981526868993797]
	TIME [epoch: 8.57 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032545692444973164		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.032545692444973164 | validation: 0.03943283300338229]
	TIME [epoch: 8.57 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03641578298006586		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.03641578298006586 | validation: 0.035214925038277875]
	TIME [epoch: 8.58 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03785065180543818		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.03785065180543818 | validation: 0.04367867817207328]
	TIME [epoch: 8.57 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03938005081859468		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.03938005081859468 | validation: 0.04562679138270094]
	TIME [epoch: 8.57 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03864148422960288		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.03864148422960288 | validation: 0.028189359710147268]
	TIME [epoch: 8.57 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0423653484996533		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.0423653484996533 | validation: 0.043722073940781016]
	TIME [epoch: 8.59 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036437834946819334		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.036437834946819334 | validation: 0.039982281289102965]
	TIME [epoch: 8.57 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04700134646471833		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.04700134646471833 | validation: 0.03293170854187129]
	TIME [epoch: 8.56 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04092517211211764		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.04092517211211764 | validation: 0.03807581513113564]
	TIME [epoch: 8.57 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03719711051023177		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.03719711051023177 | validation: 0.03874184502443928]
	TIME [epoch: 8.58 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04155764809153934		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.04155764809153934 | validation: 0.04248322237817523]
	TIME [epoch: 8.57 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04180430798377752		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.04180430798377752 | validation: 0.048144595157208425]
	TIME [epoch: 8.57 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04450431440233364		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.04450431440233364 | validation: 0.03754365231100626]
	TIME [epoch: 8.57 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04260144593033975		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.04260144593033975 | validation: 0.036019596841973776]
	TIME [epoch: 8.58 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039004635256482345		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.039004635256482345 | validation: 0.042492784550105245]
	TIME [epoch: 8.58 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03861195740094349		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.03861195740094349 | validation: 0.030730859921637613]
	TIME [epoch: 8.57 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033675708288207803		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.033675708288207803 | validation: 0.034131099536556506]
	TIME [epoch: 8.58 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03322715448006524		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.03322715448006524 | validation: 0.03985582008921026]
	TIME [epoch: 8.59 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03548914473590341		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.03548914473590341 | validation: 0.04618249231979956]
	TIME [epoch: 8.59 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03337632263083114		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.03337632263083114 | validation: 0.03482263693504696]
	TIME [epoch: 8.59 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03949357877524514		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.03949357877524514 | validation: 0.04051336236918487]
	TIME [epoch: 8.58 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04537456549597611		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.04537456549597611 | validation: 0.04347251866771346]
	TIME [epoch: 8.61 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03761807726188806		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.03761807726188806 | validation: 0.030953772169081482]
	TIME [epoch: 8.59 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04040241447137953		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.04040241447137953 | validation: 0.047652660545826814]
	TIME [epoch: 8.58 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03944587235221519		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.03944587235221519 | validation: 0.038278168764277545]
	TIME [epoch: 8.59 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03452695592727789		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.03452695592727789 | validation: 0.04878808154704348]
	TIME [epoch: 8.61 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039894023269938614		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.039894023269938614 | validation: 0.03967517261079967]
	TIME [epoch: 8.59 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04072315434321401		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.04072315434321401 | validation: 0.03929610420970727]
	TIME [epoch: 8.58 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038586838965853534		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.038586838965853534 | validation: 0.04196059075723976]
	TIME [epoch: 8.6 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03911224176515278		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.03911224176515278 | validation: 0.02806064883098704]
	TIME [epoch: 8.59 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03193208586458386		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.03193208586458386 | validation: 0.04494354702643302]
	TIME [epoch: 8.59 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03649183497092835		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.03649183497092835 | validation: 0.035910836380375954]
	TIME [epoch: 8.59 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03589235731790238		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.03589235731790238 | validation: 0.029038605825152115]
	TIME [epoch: 8.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035701536130824475		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.035701536130824475 | validation: 0.03454806220949654]
	TIME [epoch: 8.59 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04028218926509588		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.04028218926509588 | validation: 0.03429810527839742]
	TIME [epoch: 8.59 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03514853806915527		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.03514853806915527 | validation: 0.0386395343263219]
	TIME [epoch: 8.59 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044872916787878886		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.044872916787878886 | validation: 0.03864344636253221]
	TIME [epoch: 8.61 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03933701657413238		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.03933701657413238 | validation: 0.050254399408605134]
	TIME [epoch: 8.59 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043611086658928766		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.043611086658928766 | validation: 0.0334945380339414]
	TIME [epoch: 8.59 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04113000613054393		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.04113000613054393 | validation: 0.0513976532797653]
	TIME [epoch: 8.58 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04446533492967154		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.04446533492967154 | validation: 0.030572523405871892]
	TIME [epoch: 8.6 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03837286200783151		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.03837286200783151 | validation: 0.037821027524073465]
	TIME [epoch: 8.59 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039439066499661175		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.039439066499661175 | validation: 0.030110422993726963]
	TIME [epoch: 8.59 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03861967987399829		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.03861967987399829 | validation: 0.03659626674079922]
	TIME [epoch: 8.59 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03822488662906913		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.03822488662906913 | validation: 0.03964681782477119]
	TIME [epoch: 8.61 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03483524196844551		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.03483524196844551 | validation: 0.027361527847489863]
	TIME [epoch: 8.59 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0353831337848109		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.0353831337848109 | validation: 0.04212297169497509]
	TIME [epoch: 8.59 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03537227656165122		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.03537227656165122 | validation: 0.03667088566290768]
	TIME [epoch: 8.59 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038541998189869794		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.038541998189869794 | validation: 0.03711483493203572]
	TIME [epoch: 8.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03452757467471005		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.03452757467471005 | validation: 0.05305780865719531]
	TIME [epoch: 8.59 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044189234472230596		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.044189234472230596 | validation: 0.0410062115579046]
	TIME [epoch: 8.59 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04400523187416889		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.04400523187416889 | validation: 0.04041917885304045]
	TIME [epoch: 8.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03714012273057799		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.03714012273057799 | validation: 0.0342616231832226]
	TIME [epoch: 8.59 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039965626374157716		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.039965626374157716 | validation: 0.03455007538497422]
	TIME [epoch: 8.58 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034953854088288584		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.034953854088288584 | validation: 0.04323156230973204]
	TIME [epoch: 8.58 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03336790459592246		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.03336790459592246 | validation: 0.03812529913448926]
	TIME [epoch: 8.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04021618267747888		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.04021618267747888 | validation: 0.035932498876673415]
	TIME [epoch: 8.59 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03834219842526203		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.03834219842526203 | validation: 0.029103444967247125]
	TIME [epoch: 8.59 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034438722545945766		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.034438722545945766 | validation: 0.049927632559043866]
	TIME [epoch: 8.58 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03806504909642354		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.03806504909642354 | validation: 0.02380853745952198]
	TIME [epoch: 8.59 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03640720932557578		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.03640720932557578 | validation: 0.04056628320260584]
	TIME [epoch: 8.58 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03675597235726581		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.03675597235726581 | validation: 0.036415139537852304]
	TIME [epoch: 8.58 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036869966344321645		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.036869966344321645 | validation: 0.03878030108848995]
	TIME [epoch: 8.58 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03587127174994663		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.03587127174994663 | validation: 0.043677414392548984]
	TIME [epoch: 8.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03679893862498577		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.03679893862498577 | validation: 0.03723049345280535]
	TIME [epoch: 8.58 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03695069304464193		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.03695069304464193 | validation: 0.039027334708256256]
	TIME [epoch: 8.59 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03860030390738619		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.03860030390738619 | validation: 0.03571924316767915]
	TIME [epoch: 8.58 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03880634342397059		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.03880634342397059 | validation: 0.03127861202216036]
	TIME [epoch: 8.62 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03906112426187184		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.03906112426187184 | validation: 0.01864325223073162]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240219_183148/states/model_tr_study3_1999.pth
	Model improved!!!
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03854443353662854		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.03854443353662854 | validation: 0.03204596441430628]
	TIME [epoch: 8.59 sec]
Finished training in 17285.319 seconds.
