Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3553640214

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.829867050007879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.829867050007879 | validation: 10.122438073611944]
	TIME [epoch: 53.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.17372147153943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.17372147153943 | validation: 8.717232307857127]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.845013699170925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.845013699170925 | validation: 7.471713678750646]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.593514266354487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.593514266354487 | validation: 7.801964515722775]
	TIME [epoch: 8.43 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.671771415477139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.671771415477139 | validation: 12.234933439869529]
	TIME [epoch: 8.42 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.88628696324967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.88628696324967 | validation: 8.83426840516197]
	TIME [epoch: 8.43 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.274161114380722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.274161114380722 | validation: 6.748421090006945]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.349353063281692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.349353063281692 | validation: 6.557604519524729]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.314250444630134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.314250444630134 | validation: 6.33981677466636]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.159215396710449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.159215396710449 | validation: 6.287498323223248]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.8573355451302405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8573355451302405 | validation: 6.118128172799054]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.66327460282168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.66327460282168 | validation: 5.925330276645148]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.413714479268418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.413714479268418 | validation: 5.635740271872541]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6131826213037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6131826213037 | validation: 7.7255281819939565]
	TIME [epoch: 8.44 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.79024703532515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.79024703532515 | validation: 5.631437731196006]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.442022497178971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.442022497178971 | validation: 5.467544105835691]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.411745321232631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.411745321232631 | validation: 5.932506941684861]
	TIME [epoch: 8.42 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.383814376341209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.383814376341209 | validation: 6.32598715035032]
	TIME [epoch: 8.45 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.549333815165367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.549333815165367 | validation: 5.434278359229772]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.290797347324823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.290797347324823 | validation: 5.686300225121168]
	TIME [epoch: 8.43 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.353492199365921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.353492199365921 | validation: 5.661474731817752]
	TIME [epoch: 8.43 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.387249059110211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.387249059110211 | validation: 5.387011596085884]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.366739681717464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.366739681717464 | validation: 5.616109919152218]
	TIME [epoch: 8.45 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.609117229744493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.609117229744493 | validation: 5.515042364827911]
	TIME [epoch: 8.43 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.061685591938895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.061685591938895 | validation: 5.893807045713548]
	TIME [epoch: 8.44 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.260945353919569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.260945353919569 | validation: 5.0169233281925525]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.110213658761114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.110213658761114 | validation: 4.662543975969184]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.869418394432725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.869418394432725 | validation: 4.640090763699416]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.683919764659789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.683919764659789 | validation: 5.795509837141992]
	TIME [epoch: 8.41 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.8437802441436135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8437802441436135 | validation: 4.807532617900886]
	TIME [epoch: 8.42 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.434216749681924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.434216749681924 | validation: 4.179447245346642]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.02164281007022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.02164281007022 | validation: 3.6995250743490455]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.57801253955177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.57801253955177 | validation: 6.890417041994601]
	TIME [epoch: 8.41 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.883365983117043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.883365983117043 | validation: 6.753540425117574]
	TIME [epoch: 8.41 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.708876825967626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.708876825967626 | validation: 6.338253654193991]
	TIME [epoch: 8.43 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.985843744202119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.985843744202119 | validation: 6.592442648102098]
	TIME [epoch: 8.41 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.047203900546699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.047203900546699 | validation: 3.9043875217126036]
	TIME [epoch: 8.41 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1915549758185113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1915549758185113 | validation: 2.8121769123230242]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3653899931721263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3653899931721263 | validation: 2.5952395523812544]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.437162025811688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.437162025811688 | validation: 2.4262610758077843]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6430596551274217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6430596551274217 | validation: 2.681726467073953]
	TIME [epoch: 8.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.386942899979199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.386942899979199 | validation: 2.0979675321179303]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3385103603769513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3385103603769513 | validation: 1.7823189005652034]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.19615179747905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.19615179747905 | validation: 1.8005564532287484]
	TIME [epoch: 8.43 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.620627820623773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.620627820623773 | validation: 1.9238218057534149]
	TIME [epoch: 8.42 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.925964080496966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.925964080496966 | validation: 1.8778624528594472]
	TIME [epoch: 8.41 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8354338292838634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8354338292838634 | validation: 1.729101654898857]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.12185339369432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.12185339369432 | validation: 1.85346643565524]
	TIME [epoch: 8.43 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9458977717635861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9458977717635861 | validation: 1.5311581635606788]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.823616398061994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.823616398061994 | validation: 1.5585377150168767]
	TIME [epoch: 8.43 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6553676280035323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6553676280035323 | validation: 1.4572681165606092]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.242728471951721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.242728471951721 | validation: 2.0104266095339587]
	TIME [epoch: 8.43 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8673098095091154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8673098095091154 | validation: 4.2371812117982195]
	TIME [epoch: 8.42 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2147392130537598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2147392130537598 | validation: 1.9260357976987792]
	TIME [epoch: 8.42 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.815668868726266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.815668868726266 | validation: 1.6248880079430092]
	TIME [epoch: 8.42 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.655446988575266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.655446988575266 | validation: 1.536378119927611]
	TIME [epoch: 8.45 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7307282933981152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7307282933981152 | validation: 2.8551862729108217]
	TIME [epoch: 8.42 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7958367984435122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7958367984435122 | validation: 1.313929614223802]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7828023594127977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7828023594127977 | validation: 1.4753591157826604]
	TIME [epoch: 8.43 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4637498844864811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4637498844864811 | validation: 2.9365050272073185]
	TIME [epoch: 8.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0781119868646036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0781119868646036 | validation: 1.961418893900337]
	TIME [epoch: 8.42 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8440197286919329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8440197286919329 | validation: 1.6964620780997461]
	TIME [epoch: 8.42 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5509607844600626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5509607844600626 | validation: 1.7344177859533987]
	TIME [epoch: 8.42 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8590586580319528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8590586580319528 | validation: 1.5045940369333617]
	TIME [epoch: 8.44 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5550005586893432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5550005586893432 | validation: 1.8886557801924124]
	TIME [epoch: 8.42 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.607681947363711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.607681947363711 | validation: 1.879575857103667]
	TIME [epoch: 8.42 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9181665487716557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9181665487716557 | validation: 1.61744392823605]
	TIME [epoch: 8.42 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.645760796478489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.645760796478489 | validation: 1.2282339643040934]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.164577645260746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.164577645260746 | validation: 1.9569210788293874]
	TIME [epoch: 8.42 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7876162398330102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7876162398330102 | validation: 1.4850557528685098]
	TIME [epoch: 8.42 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5686272464132236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5686272464132236 | validation: 1.1825939516763078]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6747559455102965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6747559455102965 | validation: 1.3611272074867067]
	TIME [epoch: 8.45 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.650237246418423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.650237246418423 | validation: 1.75479107074168]
	TIME [epoch: 8.43 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6749460055963676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6749460055963676 | validation: 1.8203939286780602]
	TIME [epoch: 8.42 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6532886005101939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6532886005101939 | validation: 2.246903850249113]
	TIME [epoch: 8.42 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6660265418276616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6660265418276616 | validation: 1.244973365299002]
	TIME [epoch: 8.43 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5041051097516722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5041051097516722 | validation: 1.5864816962924528]
	TIME [epoch: 8.42 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7980128506700346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7980128506700346 | validation: 1.3712493356548543]
	TIME [epoch: 8.42 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.012286288299957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.012286288299957 | validation: 2.587300145965746]
	TIME [epoch: 8.42 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.759125088068115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.759125088068115 | validation: 1.2872864331672185]
	TIME [epoch: 8.44 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.658203318929073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.658203318929073 | validation: 1.1614895877199727]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8070002015238973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8070002015238973 | validation: 1.3573015659029695]
	TIME [epoch: 8.41 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7535288000604698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7535288000604698 | validation: 1.3751044813514217]
	TIME [epoch: 8.41 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4749649676463938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4749649676463938 | validation: 2.876360234588839]
	TIME [epoch: 8.43 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.772642599968617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.772642599968617 | validation: 2.4271813834411384]
	TIME [epoch: 8.42 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.00972843302715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.00972843302715 | validation: 1.3660343328844817]
	TIME [epoch: 8.42 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4113082934635226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4113082934635226 | validation: 1.3897163473283591]
	TIME [epoch: 8.42 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8946851927302184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8946851927302184 | validation: 1.3295447042612611]
	TIME [epoch: 8.42 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0950776610264774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0950776610264774 | validation: 2.027435651550972]
	TIME [epoch: 8.43 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.981927872834423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.981927872834423 | validation: 1.7264564768142976]
	TIME [epoch: 8.41 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9665467346259806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9665467346259806 | validation: 1.6176695383942827]
	TIME [epoch: 8.41 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7802339513154233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7802339513154233 | validation: 1.9138232290777875]
	TIME [epoch: 8.41 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7638172733102884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7638172733102884 | validation: 2.8387297174160895]
	TIME [epoch: 8.44 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6977168914627248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6977168914627248 | validation: 1.682876628335484]
	TIME [epoch: 8.41 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7743244375458542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7743244375458542 | validation: 3.588813061484715]
	TIME [epoch: 8.42 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3343533837244417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3343533837244417 | validation: 1.8574046169788097]
	TIME [epoch: 8.41 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8761212243165368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8761212243165368 | validation: 1.5780743200891394]
	TIME [epoch: 8.44 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.295524046387781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.295524046387781 | validation: 7.594582144173521]
	TIME [epoch: 8.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.645579686740172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.645579686740172 | validation: 6.458816996130748]
	TIME [epoch: 8.41 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.446058128564557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.446058128564557 | validation: 4.994463955801538]
	TIME [epoch: 8.42 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.067400110083333		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 3.067400110083333 | validation: 2.4581131981402127]
	TIME [epoch: 8.44 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.263659694558498		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 2.263659694558498 | validation: 1.5326022352325546]
	TIME [epoch: 8.43 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.005613899136914		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 2.005613899136914 | validation: 1.5185916477004637]
	TIME [epoch: 8.41 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2129290450164616		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 2.2129290450164616 | validation: 2.3831196608386858]
	TIME [epoch: 8.42 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9571025944311766		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 1.9571025944311766 | validation: 2.2393342916753514]
	TIME [epoch: 8.44 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0994856351797733		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 2.0994856351797733 | validation: 2.5149117540120747]
	TIME [epoch: 8.42 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9777952286201437		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 1.9777952286201437 | validation: 1.3781736244582825]
	TIME [epoch: 8.41 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8953336855385285		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.8953336855385285 | validation: 2.0625424789637865]
	TIME [epoch: 8.41 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1652767795246612		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 2.1652767795246612 | validation: 2.8040377037113995]
	TIME [epoch: 8.44 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7232346101639884		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 2.7232346101639884 | validation: 2.0963304807058525]
	TIME [epoch: 8.42 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0596293451153462		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 2.0596293451153462 | validation: 1.9789016403659723]
	TIME [epoch: 8.42 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7497379503570198		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.7497379503570198 | validation: 1.6080954722406642]
	TIME [epoch: 8.41 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1413450643389687		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 2.1413450643389687 | validation: 2.944342867948146]
	TIME [epoch: 8.43 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2278329261381495		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 2.2278329261381495 | validation: 2.1773596098261474]
	TIME [epoch: 8.42 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9260890445238545		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 1.9260890445238545 | validation: 1.6324075864134953]
	TIME [epoch: 8.42 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9923676221730604		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 2.9923676221730604 | validation: 3.4742305407550806]
	TIME [epoch: 8.41 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2780321359109097		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 2.2780321359109097 | validation: 1.7897770805296203]
	TIME [epoch: 8.41 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.096056527458681		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 2.096056527458681 | validation: 1.880729628106561]
	TIME [epoch: 8.43 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1944419460052056		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 2.1944419460052056 | validation: 1.7252610554376062]
	TIME [epoch: 8.41 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6133516236426177		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.6133516236426177 | validation: 1.6399334230334677]
	TIME [epoch: 8.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3684919624846743		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 2.3684919624846743 | validation: 2.809459292469199]
	TIME [epoch: 8.41 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2755770987226605		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 2.2755770987226605 | validation: 2.252824148119228]
	TIME [epoch: 8.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.867379867318719		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 1.867379867318719 | validation: 1.8765551025952318]
	TIME [epoch: 8.41 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.354095737379176		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 2.354095737379176 | validation: 2.650849970509265]
	TIME [epoch: 8.41 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3217279604043917		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 2.3217279604043917 | validation: 1.7227975976527778]
	TIME [epoch: 8.41 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9689674149313035		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.9689674149313035 | validation: 1.6039394172991983]
	TIME [epoch: 8.43 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.01622569639384		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 2.01622569639384 | validation: 1.657072035197835]
	TIME [epoch: 8.42 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.024722037703043		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 2.024722037703043 | validation: 2.040859077742319]
	TIME [epoch: 8.41 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0783003020027255		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 2.0783003020027255 | validation: 3.2702755161949835]
	TIME [epoch: 8.42 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4460480310975896		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 2.4460480310975896 | validation: 1.8301951401890646]
	TIME [epoch: 8.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1462268747335065		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 2.1462268747335065 | validation: 1.7059167209085628]
	TIME [epoch: 8.42 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9306220423057145		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 1.9306220423057145 | validation: 1.7033568709325106]
	TIME [epoch: 8.41 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7983259052668565		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 1.7983259052668565 | validation: 1.9880359730247479]
	TIME [epoch: 8.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7998037707075074		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.7998037707075074 | validation: 1.5971516826454186]
	TIME [epoch: 8.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9469485262731112		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 1.9469485262731112 | validation: 1.9414726102864512]
	TIME [epoch: 8.42 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.823961641871962		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 1.823961641871962 | validation: 1.4308145951760551]
	TIME [epoch: 8.41 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7891683892216854		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 1.7891683892216854 | validation: 1.8634768260673327]
	TIME [epoch: 8.41 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7367516805675076		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 1.7367516805675076 | validation: 1.5874755980139243]
	TIME [epoch: 8.43 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6447124503450614		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 1.6447124503450614 | validation: 1.8092008599225142]
	TIME [epoch: 8.42 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6774195713250006		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 1.6774195713250006 | validation: 1.4115495587415778]
	TIME [epoch: 8.41 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.589497185028523		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 1.589497185028523 | validation: 1.7735627507537792]
	TIME [epoch: 8.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6553519895340547		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 1.6553519895340547 | validation: 2.0213465471741223]
	TIME [epoch: 8.43 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.634614153856786		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 1.634614153856786 | validation: 1.7730416435962155]
	TIME [epoch: 8.42 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7604914947450243		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.7604914947450243 | validation: 2.132156035196694]
	TIME [epoch: 8.41 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0334384903481717		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 2.0334384903481717 | validation: 2.6292515348417442]
	TIME [epoch: 8.42 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9374511231990272		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 1.9374511231990272 | validation: 2.4888988664410503]
	TIME [epoch: 8.42 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8166584874967953		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 1.8166584874967953 | validation: 1.4016709632885354]
	TIME [epoch: 8.43 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0741707097710806		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 2.0741707097710806 | validation: 1.6996063165428286]
	TIME [epoch: 8.41 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8596364604328461		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 1.8596364604328461 | validation: 1.5095219923738394]
	TIME [epoch: 8.41 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8162844985315427		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 1.8162844985315427 | validation: 1.7024432058942258]
	TIME [epoch: 8.42 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9477751128029055		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 1.9477751128029055 | validation: 1.4575197237641553]
	TIME [epoch: 8.43 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.833035446799728		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 1.833035446799728 | validation: 1.549583411564551]
	TIME [epoch: 8.41 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.74093656519666		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 1.74093656519666 | validation: 1.5177327093458701]
	TIME [epoch: 8.42 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9098883096118464		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 1.9098883096118464 | validation: 1.5458343702837178]
	TIME [epoch: 8.41 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7845788503300881		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 1.7845788503300881 | validation: 1.5594575046779307]
	TIME [epoch: 8.43 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.524955914080396		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 1.524955914080396 | validation: 1.412896551009796]
	TIME [epoch: 8.41 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4663834770830064		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 1.4663834770830064 | validation: 1.6149327065076746]
	TIME [epoch: 8.41 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.577569556359267		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 1.577569556359267 | validation: 1.299468379392477]
	TIME [epoch: 8.41 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4495314623331237		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 1.4495314623331237 | validation: 1.2791676617907968]
	TIME [epoch: 8.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6589757789659771		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 1.6589757789659771 | validation: 1.7367689500860783]
	TIME [epoch: 8.42 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5417309123545744		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 1.5417309123545744 | validation: 1.876560058292442]
	TIME [epoch: 8.42 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5040699509618407		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 1.5040699509618407 | validation: 1.2839344568757332]
	TIME [epoch: 8.41 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4927636563833109		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 1.4927636563833109 | validation: 1.2882591706510222]
	TIME [epoch: 8.44 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.26731946151151		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 1.26731946151151 | validation: 1.2136483283716548]
	TIME [epoch: 8.42 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6806020814349067		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 1.6806020814349067 | validation: 1.1836603412123063]
	TIME [epoch: 8.41 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3278613931045793		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.3278613931045793 | validation: 1.3058450752860455]
	TIME [epoch: 8.41 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4689517412965645		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 1.4689517412965645 | validation: 1.2602767523461211]
	TIME [epoch: 8.43 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4653226194102809		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 1.4653226194102809 | validation: 1.781264283638974]
	TIME [epoch: 8.41 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4459733809726043		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 1.4459733809726043 | validation: 1.405201550475117]
	TIME [epoch: 8.41 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4087853926459806		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 1.4087853926459806 | validation: 2.2756692342614775]
	TIME [epoch: 8.41 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4984747430614536		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 1.4984747430614536 | validation: 2.029085694527848]
	TIME [epoch: 8.42 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6514906302301415		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 1.6514906302301415 | validation: 1.2872074088568675]
	TIME [epoch: 8.42 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.53462868987452		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 1.53462868987452 | validation: 2.0894868791050865]
	TIME [epoch: 8.41 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9113714920921605		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 1.9113714920921605 | validation: 1.413946871967008]
	TIME [epoch: 8.41 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8378025734333676		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 1.8378025734333676 | validation: 1.2711425674930545]
	TIME [epoch: 8.42 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.67811035749262		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 1.67811035749262 | validation: 1.4386703967562224]
	TIME [epoch: 8.44 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.544999585648025		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 1.544999585648025 | validation: 1.5661148348641512]
	TIME [epoch: 8.42 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3498271516095763		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 1.3498271516095763 | validation: 1.3318026663434397]
	TIME [epoch: 8.41 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4445146906378532		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 1.4445146906378532 | validation: 1.4871389877183363]
	TIME [epoch: 8.41 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7026090735878252		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 1.7026090735878252 | validation: 1.453278145202301]
	TIME [epoch: 8.43 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4114464631972374		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 1.4114464631972374 | validation: 1.3454871610668035]
	TIME [epoch: 8.41 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.42579623172751		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 1.42579623172751 | validation: 1.4836846234582328]
	TIME [epoch: 8.41 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5077991501361059		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 1.5077991501361059 | validation: 1.7754661031677361]
	TIME [epoch: 8.41 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5516641770348323		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 1.5516641770348323 | validation: 1.845191738526299]
	TIME [epoch: 8.43 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5362098836706817		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 1.5362098836706817 | validation: 1.9788006888359964]
	TIME [epoch: 8.41 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.498534886392107		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 1.498534886392107 | validation: 1.2499769652934747]
	TIME [epoch: 8.42 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5242956116573523		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 1.5242956116573523 | validation: 1.334651588795701]
	TIME [epoch: 8.41 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5834027720715953		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 1.5834027720715953 | validation: 1.8760555259028049]
	TIME [epoch: 8.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4098270876814587		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 1.4098270876814587 | validation: 1.52908561600846]
	TIME [epoch: 8.41 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4209035282917148		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 1.4209035282917148 | validation: 1.633592047285212]
	TIME [epoch: 8.41 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3873011236523067		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 1.3873011236523067 | validation: 1.4543630800641896]
	TIME [epoch: 8.41 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4103880175509378		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 1.4103880175509378 | validation: 1.1812291907045496]
	TIME [epoch: 8.43 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.482468335171728		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 1.482468335171728 | validation: 1.3262128021141482]
	TIME [epoch: 8.42 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4052512778021582		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 1.4052512778021582 | validation: 1.2329305505222607]
	TIME [epoch: 8.42 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2895012136506545		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 1.2895012136506545 | validation: 1.7607187851384891]
	TIME [epoch: 8.41 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.327591612942385		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 1.327591612942385 | validation: 1.4601443016563431]
	TIME [epoch: 8.44 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4258629187097305		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 1.4258629187097305 | validation: 1.267167956546333]
	TIME [epoch: 8.42 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3512737185675285		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 1.3512737185675285 | validation: 1.2708480436678498]
	TIME [epoch: 8.42 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.221701829877595		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 1.221701829877595 | validation: 1.2303936065276782]
	TIME [epoch: 8.41 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.239608676305638		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 1.239608676305638 | validation: 1.409169903616979]
	TIME [epoch: 8.42 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2948535246390613		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 1.2948535246390613 | validation: 1.136757347216209]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.528841952825525		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 1.528841952825525 | validation: 1.2990715729139466]
	TIME [epoch: 8.42 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.281089120960155		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 1.281089120960155 | validation: 1.438213505196663]
	TIME [epoch: 8.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3101806718296953		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 1.3101806718296953 | validation: 1.461704549714136]
	TIME [epoch: 8.42 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4584813670985297		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 1.4584813670985297 | validation: 1.2620366449221343]
	TIME [epoch: 8.43 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4447835077313813		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 1.4447835077313813 | validation: 1.3947418816117838]
	TIME [epoch: 8.42 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3959508797342015		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 1.3959508797342015 | validation: 1.1856960889364165]
	TIME [epoch: 8.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3586704938725582		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 1.3586704938725582 | validation: 1.3040396401618881]
	TIME [epoch: 8.41 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.245992630698381		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 1.245992630698381 | validation: 1.791462122698082]
	TIME [epoch: 8.44 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4239924635410044		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 1.4239924635410044 | validation: 1.148723534239953]
	TIME [epoch: 8.42 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4912614750856403		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 1.4912614750856403 | validation: 1.1745707060251491]
	TIME [epoch: 8.42 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2346467497309952		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 1.2346467497309952 | validation: 1.5436120599073244]
	TIME [epoch: 8.41 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3518913334569953		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 1.3518913334569953 | validation: 1.1527972248187308]
	TIME [epoch: 8.43 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4266931067884872		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 1.4266931067884872 | validation: 1.1975531570374711]
	TIME [epoch: 8.42 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2138191012431543		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 1.2138191012431543 | validation: 1.573644349693086]
	TIME [epoch: 8.42 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3605398370988788		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 1.3605398370988788 | validation: 1.338591796627703]
	TIME [epoch: 8.41 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3505218618171748		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 1.3505218618171748 | validation: 1.2524748292466104]
	TIME [epoch: 8.43 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.24244594418149		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 1.24244594418149 | validation: 1.4413531106228568]
	TIME [epoch: 8.41 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2691288331514197		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 1.2691288331514197 | validation: 1.2604124715957048]
	TIME [epoch: 8.41 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5374863084561106		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 1.5374863084561106 | validation: 1.4367159169860075]
	TIME [epoch: 8.41 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.475426773609502		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 1.475426773609502 | validation: 1.2776302732875704]
	TIME [epoch: 8.43 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3867637986333308		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 1.3867637986333308 | validation: 1.3636439562252822]
	TIME [epoch: 8.41 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.307816573001705		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 1.307816573001705 | validation: 1.2061318840780366]
	TIME [epoch: 8.41 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.36988790443692		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 1.36988790443692 | validation: 1.46054908555729]
	TIME [epoch: 8.41 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3071683570753758		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 1.3071683570753758 | validation: 1.3293054104368665]
	TIME [epoch: 8.43 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4256707395515082		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 1.4256707395515082 | validation: 1.386084547098986]
	TIME [epoch: 8.41 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3819663694025022		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 1.3819663694025022 | validation: 1.3871767940040518]
	TIME [epoch: 8.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.20776312763249		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 1.20776312763249 | validation: 1.1597795865114182]
	TIME [epoch: 8.41 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.249225880259653		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 1.249225880259653 | validation: 1.4791922514290374]
	TIME [epoch: 8.42 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2199877019988183		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 1.2199877019988183 | validation: 1.3516809921991537]
	TIME [epoch: 8.42 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3223477638875887		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 1.3223477638875887 | validation: 1.4682450763524901]
	TIME [epoch: 8.41 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.288277530510529		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 1.288277530510529 | validation: 1.2330762570463216]
	TIME [epoch: 8.41 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4168053785951755		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 1.4168053785951755 | validation: 1.398285496891952]
	TIME [epoch: 8.41 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2464736630709294		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 1.2464736630709294 | validation: 1.4768225057452464]
	TIME [epoch: 8.45 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3617680820273228		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 1.3617680820273228 | validation: 1.1816916958527168]
	TIME [epoch: 8.41 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2616973103618354		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 1.2616973103618354 | validation: 1.2017736370797083]
	TIME [epoch: 8.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1894904408053075		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 1.1894904408053075 | validation: 1.2203452633368694]
	TIME [epoch: 8.41 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1621263378048399		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 1.1621263378048399 | validation: 1.0811189136555734]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.316401142233044		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 1.316401142233044 | validation: 1.3412595391624134]
	TIME [epoch: 8.41 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0903050917215433		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 1.0903050917215433 | validation: 1.017680221305421]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2879019903283924		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 1.2879019903283924 | validation: 1.2061757315442503]
	TIME [epoch: 8.41 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0652209849727154		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 1.0652209849727154 | validation: 1.2336183343934426]
	TIME [epoch: 8.44 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.21747783561039		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 1.21747783561039 | validation: 1.1626526298437732]
	TIME [epoch: 8.42 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1694928345793527		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 1.1694928345793527 | validation: 1.3037958679510702]
	TIME [epoch: 8.41 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1091194837558151		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 1.1091194837558151 | validation: 1.1381549481662274]
	TIME [epoch: 8.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.152403419217953		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 1.152403419217953 | validation: 1.3923191811256785]
	TIME [epoch: 8.43 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1893454954959233		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 1.1893454954959233 | validation: 1.1882018913364671]
	TIME [epoch: 8.41 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0359834606234988		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 1.0359834606234988 | validation: 1.288481710847015]
	TIME [epoch: 8.42 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3386448505579742		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 1.3386448505579742 | validation: 1.3738193732847446]
	TIME [epoch: 8.42 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1595619951353084		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 1.1595619951353084 | validation: 0.9712838425944436]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.050373180524727		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 1.050373180524727 | validation: 1.0539125842423798]
	TIME [epoch: 8.41 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2378129956084103		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 1.2378129956084103 | validation: 1.2553461508203156]
	TIME [epoch: 8.42 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1141082850656123		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 1.1141082850656123 | validation: 1.3650422523322505]
	TIME [epoch: 8.42 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1726724471361		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 1.1726724471361 | validation: 1.3115910080701716]
	TIME [epoch: 8.44 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1385080648825485		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 1.1385080648825485 | validation: 1.1193674950670793]
	TIME [epoch: 8.42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.271711054249328		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 1.271711054249328 | validation: 1.1112304909029502]
	TIME [epoch: 8.41 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.203440171981757		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 1.203440171981757 | validation: 1.127055281638602]
	TIME [epoch: 8.41 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1458920481780062		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 1.1458920481780062 | validation: 1.2903033190390423]
	TIME [epoch: 8.43 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1283845980399136		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 1.1283845980399136 | validation: 1.0786121720101844]
	TIME [epoch: 8.41 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.157493956588231		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 1.157493956588231 | validation: 1.0568819263118634]
	TIME [epoch: 8.41 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.031161489317698		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 1.031161489317698 | validation: 1.167185877775232]
	TIME [epoch: 8.42 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0770382089901736		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 1.0770382089901736 | validation: 1.0645506547469092]
	TIME [epoch: 8.42 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3438015748933294		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 1.3438015748933294 | validation: 2.6638824482516723]
	TIME [epoch: 8.42 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6046257257975767		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 3.6046257257975767 | validation: 2.643851503465986]
	TIME [epoch: 8.41 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0164583308302975		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 3.0164583308302975 | validation: 2.6484274375055428]
	TIME [epoch: 8.42 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3458476394434564		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 2.3458476394434564 | validation: 1.9144333750038975]
	TIME [epoch: 8.41 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.389976492058826		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 1.389976492058826 | validation: 1.1333811259989717]
	TIME [epoch: 8.44 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.413095216975635		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 1.413095216975635 | validation: 2.0455957791446933]
	TIME [epoch: 8.42 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4524805056454144		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 1.4524805056454144 | validation: 2.2133006298737055]
	TIME [epoch: 8.42 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5049022770423128		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 1.5049022770423128 | validation: 1.0738499925796914]
	TIME [epoch: 8.42 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.103709419381227		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 1.103709419381227 | validation: 1.1506427026233514]
	TIME [epoch: 8.44 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4107516592754787		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 1.4107516592754787 | validation: 1.0688502935454618]
	TIME [epoch: 8.42 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1544642423354925		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 1.1544642423354925 | validation: 0.9771465056568027]
	TIME [epoch: 8.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1781418128618562		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 1.1781418128618562 | validation: 1.3423586606064588]
	TIME [epoch: 8.41 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0401297913256107		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 1.0401297913256107 | validation: 1.61171569940718]
	TIME [epoch: 8.43 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0479154704681894		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 1.0479154704681894 | validation: 0.9789152124027856]
	TIME [epoch: 8.41 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0401507733651438		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 1.0401507733651438 | validation: 0.7886430877264061]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0129081185955542		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 1.0129081185955542 | validation: 1.0261646434423068]
	TIME [epoch: 8.43 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1264795923430273		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 1.1264795923430273 | validation: 0.7392555202020898]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8933666680034664		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.8933666680034664 | validation: 1.339025350421378]
	TIME [epoch: 8.43 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0780054386830922		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 1.0780054386830922 | validation: 0.9271922702612616]
	TIME [epoch: 8.42 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9563918538757653		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.9563918538757653 | validation: 0.8274362781282796]
	TIME [epoch: 8.43 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0306460801021273		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 1.0306460801021273 | validation: 0.9910604645902781]
	TIME [epoch: 8.44 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0287168560534392		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 1.0287168560534392 | validation: 0.8275128247474517]
	TIME [epoch: 8.44 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.001157847716541		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 1.001157847716541 | validation: 1.0088542487733854]
	TIME [epoch: 8.42 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0217358485570585		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 1.0217358485570585 | validation: 1.1123746331835513]
	TIME [epoch: 8.42 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1254608771154027		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 1.1254608771154027 | validation: 1.065445744584895]
	TIME [epoch: 8.43 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0368288103870162		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 1.0368288103870162 | validation: 0.8706813944252122]
	TIME [epoch: 8.45 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0087099198502893		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 1.0087099198502893 | validation: 0.8900060138562009]
	TIME [epoch: 8.42 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9828094903205221		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.9828094903205221 | validation: 0.7437776196244108]
	TIME [epoch: 8.43 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.012059715225474		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 1.012059715225474 | validation: 0.8872109179314912]
	TIME [epoch: 8.43 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0946284803963233		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 1.0946284803963233 | validation: 1.100731733630326]
	TIME [epoch: 8.45 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1995511308295574		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 1.1995511308295574 | validation: 0.9306598066921477]
	TIME [epoch: 8.42 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9890714411789089		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.9890714411789089 | validation: 1.0697928782804471]
	TIME [epoch: 8.43 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.109653184962759		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 1.109653184962759 | validation: 1.1446345861908414]
	TIME [epoch: 8.42 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1287962276222792		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 1.1287962276222792 | validation: 1.3226916124533799]
	TIME [epoch: 8.45 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.087814113077906		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 1.087814113077906 | validation: 0.8774850764597577]
	TIME [epoch: 8.43 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.000835717481197		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 1.000835717481197 | validation: 0.9389456877273259]
	TIME [epoch: 8.43 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2195433790716104		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 1.2195433790716104 | validation: 1.3620082242312703]
	TIME [epoch: 8.42 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0146354935501516		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 1.0146354935501516 | validation: 0.813587444497657]
	TIME [epoch: 8.45 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9808667019657304		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.9808667019657304 | validation: 0.9049108963011763]
	TIME [epoch: 8.43 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8930306211362916		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.8930306211362916 | validation: 0.7121412210467408]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8341183618186199		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.8341183618186199 | validation: 1.0300717204414709]
	TIME [epoch: 8.43 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7726116805062117		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.7726116805062117 | validation: 0.7477690909638472]
	TIME [epoch: 8.45 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9525756010937009		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.9525756010937009 | validation: 1.530479385196655]
	TIME [epoch: 8.43 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9414916732656797		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.9414916732656797 | validation: 0.9664501998379595]
	TIME [epoch: 8.43 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8432293343829992		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.8432293343829992 | validation: 0.8659324126612146]
	TIME [epoch: 8.43 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7826012751084233		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.7826012751084233 | validation: 1.0724768767388413]
	TIME [epoch: 8.45 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8678314250260895		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.8678314250260895 | validation: 0.9030556904670424]
	TIME [epoch: 8.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9657777493538415		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.9657777493538415 | validation: 1.0725848591917841]
	TIME [epoch: 8.42 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9468439253417508		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.9468439253417508 | validation: 0.9328913895821288]
	TIME [epoch: 8.43 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9922670330257638		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.9922670330257638 | validation: 0.6875818166326122]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8752004158970571		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.8752004158970571 | validation: 0.8504488410820515]
	TIME [epoch: 8.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8728495848804908		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.8728495848804908 | validation: 1.2838884223913427]
	TIME [epoch: 8.42 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0378664039133425		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 1.0378664039133425 | validation: 1.0072949775865552]
	TIME [epoch: 8.42 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.061385875897609		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 1.061385875897609 | validation: 2.423894069548309]
	TIME [epoch: 8.44 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1532852773544504		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 1.1532852773544504 | validation: 1.142112639435254]
	TIME [epoch: 8.44 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8688267240408013		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.8688267240408013 | validation: 0.7650356392429158]
	TIME [epoch: 8.43 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8589250467676948		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.8589250467676948 | validation: 1.277536794036529]
	TIME [epoch: 8.42 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9254026269350641		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.9254026269350641 | validation: 0.6674132378590845]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9033005543344735		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.9033005543344735 | validation: 1.0142204651230622]
	TIME [epoch: 8.45 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8833005111546715		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.8833005111546715 | validation: 1.0999012623725037]
	TIME [epoch: 8.43 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.910484536892836		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.910484536892836 | validation: 0.8127341198020483]
	TIME [epoch: 8.42 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8309643310079528		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.8309643310079528 | validation: 0.8329252803413584]
	TIME [epoch: 8.43 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8219922958886163		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.8219922958886163 | validation: 1.031656563609034]
	TIME [epoch: 8.45 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7885236647953243		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.7885236647953243 | validation: 1.027174160874073]
	TIME [epoch: 8.44 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0751969066720164		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 1.0751969066720164 | validation: 0.9350326621338755]
	TIME [epoch: 8.43 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0852286878162816		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 1.0852286878162816 | validation: 0.9787103213348092]
	TIME [epoch: 8.43 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0376469566883477		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 1.0376469566883477 | validation: 0.7963260953051325]
	TIME [epoch: 8.46 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.922427012330493		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.922427012330493 | validation: 0.7029923876985325]
	TIME [epoch: 8.43 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9196964592827609		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.9196964592827609 | validation: 0.694333902971257]
	TIME [epoch: 8.42 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8400986720263843		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.8400986720263843 | validation: 1.06486824182961]
	TIME [epoch: 8.43 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9085780091284184		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.9085780091284184 | validation: 0.6930643116622331]
	TIME [epoch: 8.45 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.778632264975381		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.778632264975381 | validation: 1.289939979228264]
	TIME [epoch: 8.43 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.771432575122225		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.771432575122225 | validation: 1.060141136525934]
	TIME [epoch: 8.43 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9236794996528607		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.9236794996528607 | validation: 0.8688550488494973]
	TIME [epoch: 8.43 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8758296516044275		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.8758296516044275 | validation: 0.8465444953152138]
	TIME [epoch: 8.45 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8852686601287989		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.8852686601287989 | validation: 0.9689038174506804]
	TIME [epoch: 8.43 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8901679603835632		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.8901679603835632 | validation: 0.7043088007322182]
	TIME [epoch: 8.43 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8036621536952124		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.8036621536952124 | validation: 1.0465410143485676]
	TIME [epoch: 8.43 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8372496985747568		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.8372496985747568 | validation: 0.7708725364316362]
	TIME [epoch: 8.45 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7574795375885184		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.7574795375885184 | validation: 0.7088273268221004]
	TIME [epoch: 8.43 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0667067732548463		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 1.0667067732548463 | validation: 0.833504660368008]
	TIME [epoch: 8.44 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9636817888756619		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.9636817888756619 | validation: 0.729772363260095]
	TIME [epoch: 8.42 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.820896520323282		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.820896520323282 | validation: 0.8283847483926263]
	TIME [epoch: 8.45 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7700584910567223		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.7700584910567223 | validation: 0.7185338807219517]
	TIME [epoch: 8.43 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8730166286350662		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.8730166286350662 | validation: 0.8674636527884967]
	TIME [epoch: 8.43 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7713880996269223		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.7713880996269223 | validation: 0.5809138695046366]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240219_183148/states/model_tr_study3_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.784740781889388		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.784740781889388 | validation: 1.261276739152755]
	TIME [epoch: 8.45 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.306792419610209		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 7.306792419610209 | validation: 8.269983500192204]
	TIME [epoch: 8.44 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.108069422213429		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 9.108069422213429 | validation: 9.301295865713096]
	TIME [epoch: 8.43 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.302829602187838		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 9.302829602187838 | validation: 10.400753094853519]
	TIME [epoch: 8.43 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.932530924074873		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 9.932530924074873 | validation: 9.782715574719926]
	TIME [epoch: 8.43 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.20624932072528		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 8.20624932072528 | validation: 8.15352172336485]
	TIME [epoch: 8.45 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.754286638219466		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 6.754286638219466 | validation: 5.092022584868502]
	TIME [epoch: 8.43 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.21779973255948		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 5.21779973255948 | validation: 6.2207112471744574]
	TIME [epoch: 8.42 sec]
EPOCH 357/2000:
	Training over batches...
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
