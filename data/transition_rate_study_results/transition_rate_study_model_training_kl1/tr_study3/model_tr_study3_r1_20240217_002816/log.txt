Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4136981947

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.017096530885519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.017096530885519 | validation: 10.780853246443435]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.176047085055318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.176047085055318 | validation: 10.07265335624647]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.437921684973572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.437921684973572 | validation: 9.225013790218252]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.603859498971456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.603859498971456 | validation: 8.611598235316983]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.008473278522878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.008473278522878 | validation: 8.422248895839598]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.496572962222949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.496572962222949 | validation: 7.973331104607734]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.139701439222678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.139701439222678 | validation: 7.447170152942081]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.7260698777834325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7260698777834325 | validation: 7.025940430363983]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.212025256839235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.212025256839235 | validation: 6.651105024454765]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.1091727183696865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1091727183696865 | validation: 6.369080656588845]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.8405443977358615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8405443977358615 | validation: 6.392660960116212]
	TIME [epoch: 9.11 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.690195941509054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.690195941509054 | validation: 5.846088169692839]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.549936192156466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.549936192156466 | validation: 5.926241909914384]
	TIME [epoch: 9.11 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.505317141565817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.505317141565817 | validation: 5.596782390163986]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.462082723531146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.462082723531146 | validation: 5.752183935236516]
	TIME [epoch: 9.11 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6296071840163755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6296071840163755 | validation: 5.605334077576302]
	TIME [epoch: 9.12 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.355103435186666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.355103435186666 | validation: 5.4814844669961476]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.222753514208824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.222753514208824 | validation: 5.387051032458283]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.142542726947542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.142542726947542 | validation: 6.882469003445424]
	TIME [epoch: 9.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.3316900482207865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3316900482207865 | validation: 5.019843507913261]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.9492527407502065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9492527407502065 | validation: 5.052113492023981]
	TIME [epoch: 9.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.868555966733432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.868555966733432 | validation: 5.173327161599622]
	TIME [epoch: 9.09 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.112867740739224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.112867740739224 | validation: 5.439673832162079]
	TIME [epoch: 9.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.306485669927257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.306485669927257 | validation: 4.49987419762885]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.0093061341744685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0093061341744685 | validation: 6.328700932354131]
	TIME [epoch: 9.09 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.5059648497573646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5059648497573646 | validation: 6.849580483206264]
	TIME [epoch: 9.09 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.488272134510108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.488272134510108 | validation: 5.263116800981689]
	TIME [epoch: 9.09 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.557466252476301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.557466252476301 | validation: 5.356262464517347]
	TIME [epoch: 9.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.114258027887535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.114258027887535 | validation: 5.131840367344433]
	TIME [epoch: 9.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.6898086194508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6898086194508 | validation: 5.080202294449252]
	TIME [epoch: 9.09 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.288398781091862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.288398781091862 | validation: 5.710419004017534]
	TIME [epoch: 9.09 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.86836635085856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.86836635085856 | validation: 5.060922968858215]
	TIME [epoch: 9.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.291529126722974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.291529126722974 | validation: 3.97478032869354]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9821910089010535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9821910089010535 | validation: 4.284445609822549]
	TIME [epoch: 9.09 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.879643051929694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.879643051929694 | validation: 3.661191370923801]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.441138842512105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.441138842512105 | validation: 3.711945145307795]
	TIME [epoch: 9.11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.476399654638059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.476399654638059 | validation: 3.367899531507821]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1908258870311688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1908258870311688 | validation: 3.094509951863466]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.09992556537863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.09992556537863 | validation: 2.7591249514439613]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8107177840639466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8107177840639466 | validation: 2.640250359180507]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.932093838901145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.932093838901145 | validation: 2.5832459727405457]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5467010485343127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5467010485343127 | validation: 2.7370954711559383]
	TIME [epoch: 9.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5973863556204932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5973863556204932 | validation: 2.375785444204009]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3907390214380078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3907390214380078 | validation: 2.0958372987225244]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2899836561365086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2899836561365086 | validation: 1.8512378485834113]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2041775937942507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2041775937942507 | validation: 1.8710162521773115]
	TIME [epoch: 9.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0956392630947875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0956392630947875 | validation: 2.3572813678218085]
	TIME [epoch: 9.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.43713137358504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.43713137358504 | validation: 2.0261717089692404]
	TIME [epoch: 9.09 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2532501515199987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2532501515199987 | validation: 1.9329073566356207]
	TIME [epoch: 9.11 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0863732802987647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0863732802987647 | validation: 2.128144269723265]
	TIME [epoch: 9.09 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3490208395508594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3490208395508594 | validation: 2.1392604158297055]
	TIME [epoch: 9.09 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9664779106010066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9664779106010066 | validation: 2.066680404716907]
	TIME [epoch: 9.08 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.042638124350006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.042638124350006 | validation: 1.951187590763471]
	TIME [epoch: 9.08 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7647221032800169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7647221032800169 | validation: 1.800136052818212]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8313166555904516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8313166555904516 | validation: 1.8913595612123886]
	TIME [epoch: 9.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1262593163654597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1262593163654597 | validation: 1.43207140983094]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.908904959800509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.908904959800509 | validation: 2.1217981556016667]
	TIME [epoch: 9.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9025895672735984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9025895672735984 | validation: 1.6464692980231779]
	TIME [epoch: 9.09 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9146145821255647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9146145821255647 | validation: 1.5045494915224804]
	TIME [epoch: 9.11 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9421959971819294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9421959971819294 | validation: 2.207524526995127]
	TIME [epoch: 9.1 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1208998188321857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1208998188321857 | validation: 3.1911352540753284]
	TIME [epoch: 9.09 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9455172984961955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9455172984961955 | validation: 1.9773050534387013]
	TIME [epoch: 9.08 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1949375553272192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1949375553272192 | validation: 1.6545301981518428]
	TIME [epoch: 9.08 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.860192842032788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.860192842032788 | validation: 1.5183876773834153]
	TIME [epoch: 9.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7651026967957653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7651026967957653 | validation: 1.3117948509462458]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.321917718585558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.321917718585558 | validation: 1.9868880286081128]
	TIME [epoch: 9.09 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6746597687902756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6746597687902756 | validation: 1.871548828894035]
	TIME [epoch: 9.08 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7627879698565092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7627879698565092 | validation: 1.3914627995698932]
	TIME [epoch: 9.09 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9380640462823717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9380640462823717 | validation: 2.4825661484347084]
	TIME [epoch: 9.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9342513083108492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9342513083108492 | validation: 1.558010870523648]
	TIME [epoch: 9.08 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5991363185731582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5991363185731582 | validation: 1.2774168665260448]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7523495009934327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7523495009934327 | validation: 2.0410763962683145]
	TIME [epoch: 9.09 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.75090900431112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.75090900431112 | validation: 2.029780614360133]
	TIME [epoch: 9.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7118520809039843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7118520809039843 | validation: 2.0252366110674287]
	TIME [epoch: 9.11 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.704324291163012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.704324291163012 | validation: 2.0054689269251877]
	TIME [epoch: 9.08 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6659370809716898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6659370809716898 | validation: 1.8443038067215756]
	TIME [epoch: 9.08 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6828000890670989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6828000890670989 | validation: 1.8402813133105338]
	TIME [epoch: 9.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7958073833394486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7958073833394486 | validation: 1.6461406007653938]
	TIME [epoch: 9.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6875293172974062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6875293172974062 | validation: 1.8291964450397376]
	TIME [epoch: 9.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6806183973278295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6806183973278295 | validation: 1.921229284505346]
	TIME [epoch: 9.09 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.874077506974523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.874077506974523 | validation: 1.6530603234729622]
	TIME [epoch: 9.09 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6230740605549943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6230740605549943 | validation: 1.846192096722313]
	TIME [epoch: 9.09 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5405981588712203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5405981588712203 | validation: 1.6647652461326474]
	TIME [epoch: 9.11 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.832705611744262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.832705611744262 | validation: 1.9220213556516297]
	TIME [epoch: 9.09 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6537960080061616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6537960080061616 | validation: 1.4265486553282627]
	TIME [epoch: 9.09 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6572569214592399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6572569214592399 | validation: 1.3522578988659117]
	TIME [epoch: 9.09 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7597745544078318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7597745544078318 | validation: 1.942634468556364]
	TIME [epoch: 9.08 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7976724188370388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7976724188370388 | validation: 2.3105344731194943]
	TIME [epoch: 9.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7469296729490922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7469296729490922 | validation: 1.8294068258365885]
	TIME [epoch: 9.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.612799431996096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.612799431996096 | validation: 1.7245872903921664]
	TIME [epoch: 9.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7067499365592205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7067499365592205 | validation: 1.464147229312455]
	TIME [epoch: 9.08 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6760458908186027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6760458908186027 | validation: 1.4135817091141392]
	TIME [epoch: 9.11 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.547279188564154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.547279188564154 | validation: 3.194437767273647]
	TIME [epoch: 9.09 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8643147005255005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8643147005255005 | validation: 2.0107719516463214]
	TIME [epoch: 9.08 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6165940808974633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6165940808974633 | validation: 1.485259924679215]
	TIME [epoch: 9.08 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6979352879817113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6979352879817113 | validation: 1.722280544265102]
	TIME [epoch: 9.08 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6230095506944067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6230095506944067 | validation: 1.8392086082434465]
	TIME [epoch: 9.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6881251164991251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6881251164991251 | validation: 2.195368066536523]
	TIME [epoch: 9.07 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6534997090551928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6534997090551928 | validation: 1.8157085025940194]
	TIME [epoch: 9.08 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5456009849057613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5456009849057613 | validation: 1.7830117088993864]
	TIME [epoch: 9.08 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6061868895726892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6061868895726892 | validation: 1.3303955090959498]
	TIME [epoch: 9.09 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5274967168698281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5274967168698281 | validation: 1.5140234893462512]
	TIME [epoch: 9.07 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.525025044674171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.525025044674171 | validation: 1.8317857206184494]
	TIME [epoch: 9.08 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4316817871320313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4316817871320313 | validation: 2.517916079277838]
	TIME [epoch: 9.08 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5711297042743313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5711297042743313 | validation: 1.6018865408764844]
	TIME [epoch: 9.08 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2942959895655297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2942959895655297 | validation: 1.6659886030225763]
	TIME [epoch: 9.11 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5042375451910825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5042375451910825 | validation: 1.871180610985475]
	TIME [epoch: 9.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.490857280194228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.490857280194228 | validation: 3.436497507862515]
	TIME [epoch: 9.09 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7457317169456985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7457317169456985 | validation: 3.0795481565209144]
	TIME [epoch: 9.08 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.42069463354922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.42069463354922 | validation: 1.2747457837188274]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3039886268242113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3039886268242113 | validation: 1.8176821448345333]
	TIME [epoch: 9.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3511011366446346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3511011366446346 | validation: 1.6244563132857066]
	TIME [epoch: 9.08 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.561422831426356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.561422831426356 | validation: 2.43392789757237]
	TIME [epoch: 9.08 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5874021730476238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5874021730476238 | validation: 1.590361669650146]
	TIME [epoch: 9.08 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4281089879218078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4281089879218078 | validation: 1.0957973140877508]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1970076294293694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1970076294293694 | validation: 5.1205111284675215]
	TIME [epoch: 9.11 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3798564717013435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3798564717013435 | validation: 0.9531985384247114]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5047753395245267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5047753395245267 | validation: 1.176614853430471]
	TIME [epoch: 9.09 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4717394711769622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4717394711769622 | validation: 1.6631783748164992]
	TIME [epoch: 9.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.641867727598158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.641867727598158 | validation: 1.4647907065365247]
	TIME [epoch: 9.11 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2793205332049562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2793205332049562 | validation: 1.1017560430055422]
	TIME [epoch: 9.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3332477235965876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3332477235965876 | validation: 1.6736959491109034]
	TIME [epoch: 9.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3683203110780844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3683203110780844 | validation: 1.0566332129116316]
	TIME [epoch: 9.09 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3846556946268027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3846556946268027 | validation: 1.2175206874698516]
	TIME [epoch: 9.09 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5144974592500775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5144974592500775 | validation: 2.703587472037543]
	TIME [epoch: 9.11 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4233097517581974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4233097517581974 | validation: 1.283355088155661]
	TIME [epoch: 9.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6107455502233567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6107455502233567 | validation: 1.3336060155009488]
	TIME [epoch: 9.09 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.494834855729266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.494834855729266 | validation: 1.5606755033264301]
	TIME [epoch: 9.09 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6927450791172283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6927450791172283 | validation: 1.3843236709826003]
	TIME [epoch: 9.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.428148635566822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.428148635566822 | validation: 1.1987968637223607]
	TIME [epoch: 9.12 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1695683044541503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1695683044541503 | validation: 1.547267026179594]
	TIME [epoch: 9.09 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3559484051244979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3559484051244979 | validation: 1.8021547709372596]
	TIME [epoch: 9.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.448194411990529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.448194411990529 | validation: 1.9177520311782077]
	TIME [epoch: 9.09 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4357955386082317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4357955386082317 | validation: 1.4546722479081051]
	TIME [epoch: 9.11 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.092690681560609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.092690681560609 | validation: 1.7324278708833534]
	TIME [epoch: 9.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7196348909728472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7196348909728472 | validation: 2.0503740475606875]
	TIME [epoch: 9.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5620142621409063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5620142621409063 | validation: 1.3326832974006775]
	TIME [epoch: 9.09 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.494978943740354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.494978943740354 | validation: 1.5296395821231108]
	TIME [epoch: 9.09 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4405273353095345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4405273353095345 | validation: 1.7127248130942299]
	TIME [epoch: 9.11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8448228956961135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8448228956961135 | validation: 1.2531086457949252]
	TIME [epoch: 9.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7415989925175346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7415989925175346 | validation: 1.8085580874483795]
	TIME [epoch: 9.09 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7046706408565115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7046706408565115 | validation: 1.8833133936255568]
	TIME [epoch: 9.09 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4309011442774402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4309011442774402 | validation: 1.358893800552035]
	TIME [epoch: 9.09 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4286992134421255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4286992134421255 | validation: 1.3253911472709965]
	TIME [epoch: 9.11 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2034832564639208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2034832564639208 | validation: 3.2766793659175733]
	TIME [epoch: 9.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.534619276294347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.534619276294347 | validation: 1.6896018576146634]
	TIME [epoch: 9.09 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3408194755307306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3408194755307306 | validation: 1.0719745077090939]
	TIME [epoch: 9.09 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.57010368453012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.57010368453012 | validation: 1.4679922538914076]
	TIME [epoch: 9.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0821658167440422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0821658167440422 | validation: 2.6491328448931766]
	TIME [epoch: 9.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4519903067115518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4519903067115518 | validation: 1.1788668830077782]
	TIME [epoch: 9.09 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3049353423913665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3049353423913665 | validation: 1.7973407850056657]
	TIME [epoch: 9.09 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3700867290807586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3700867290807586 | validation: 1.4603659678698562]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5082926595045247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5082926595045247 | validation: 1.1868756310163544]
	TIME [epoch: 9.11 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3102175350809122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3102175350809122 | validation: 1.0884497525740033]
	TIME [epoch: 9.09 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.191416590874714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.191416590874714 | validation: 1.5102634631726897]
	TIME [epoch: 9.09 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2948584290246663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2948584290246663 | validation: 1.3575797656091764]
	TIME [epoch: 9.09 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4680714269267345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4680714269267345 | validation: 1.2537126695098342]
	TIME [epoch: 9.11 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.46029130984142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.46029130984142 | validation: 1.2604510959227757]
	TIME [epoch: 9.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.633732483383696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.633732483383696 | validation: 1.4066628410973363]
	TIME [epoch: 9.09 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6041211519868193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6041211519868193 | validation: 1.855859867912321]
	TIME [epoch: 9.09 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.295746100405127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.295746100405127 | validation: 1.2830359100903688]
	TIME [epoch: 9.08 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4994644766724328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4994644766724328 | validation: 1.3966450762488658]
	TIME [epoch: 9.11 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3418177411930026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3418177411930026 | validation: 0.8783353085299109]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1626696051491556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1626696051491556 | validation: 1.1307408424910355]
	TIME [epoch: 9.08 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.154084901647026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.154084901647026 | validation: 1.6497051340966407]
	TIME [epoch: 9.08 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8385178122023151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8385178122023151 | validation: 2.360697552840765]
	TIME [epoch: 9.09 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7315246528477086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7315246528477086 | validation: 1.134645505382275]
	TIME [epoch: 9.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3181619925627943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3181619925627943 | validation: 1.2413719639625158]
	TIME [epoch: 9.08 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3458513035981965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3458513035981965 | validation: 1.574697698609794]
	TIME [epoch: 9.08 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4860550508032453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4860550508032453 | validation: 1.2383900589861234]
	TIME [epoch: 9.08 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0459768482416683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0459768482416683 | validation: 1.4734346001264937]
	TIME [epoch: 9.09 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3430230353003896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3430230353003896 | validation: 1.6620910491387182]
	TIME [epoch: 9.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2347228552951177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2347228552951177 | validation: 1.0814752559691918]
	TIME [epoch: 9.08 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.238977808331231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.238977808331231 | validation: 1.4250600014597503]
	TIME [epoch: 9.08 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2194813407708405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2194813407708405 | validation: 1.7015143866643563]
	TIME [epoch: 9.08 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.461362487863709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.461362487863709 | validation: 1.1536504118777842]
	TIME [epoch: 9.11 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.188816316432071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.188816316432071 | validation: 1.0026110780096102]
	TIME [epoch: 9.08 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4430726437812085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4430726437812085 | validation: 0.9183049429832612]
	TIME [epoch: 9.08 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0242717779444324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0242717779444324 | validation: 1.209251630854312]
	TIME [epoch: 9.08 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2538906731371204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2538906731371204 | validation: 0.8458100228131173]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1214079060257418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1214079060257418 | validation: 1.339067544091287]
	TIME [epoch: 9.12 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3097007597831305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3097007597831305 | validation: 1.6278138209581297]
	TIME [epoch: 9.09 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0833934649678318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0833934649678318 | validation: 0.954021106735702]
	TIME [epoch: 9.09 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9463052807025407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9463052807025407 | validation: 0.6284375400919581]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1245398977524452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1245398977524452 | validation: 1.10516519073884]
	TIME [epoch: 9.09 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9237434410937153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9237434410937153 | validation: 0.8604921203128437]
	TIME [epoch: 9.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9544459250333818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9544459250333818 | validation: 0.7664350438683319]
	TIME [epoch: 9.09 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1091603423094853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1091603423094853 | validation: 0.8190191478437194]
	TIME [epoch: 9.08 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0220809712537475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0220809712537475 | validation: 0.9293478308786017]
	TIME [epoch: 9.08 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1280335120336162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1280335120336162 | validation: 0.7896510899467577]
	TIME [epoch: 9.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9000340071047106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9000340071047106 | validation: 1.1161793753977722]
	TIME [epoch: 9.11 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.00950491649288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.00950491649288 | validation: 1.0466179843214474]
	TIME [epoch: 9.08 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8575951176900745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8575951176900745 | validation: 1.2900127409653588]
	TIME [epoch: 9.08 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1234334642289228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1234334642289228 | validation: 1.360594845844237]
	TIME [epoch: 9.08 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.131465643043858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.131465643043858 | validation: 1.015896262332836]
	TIME [epoch: 9.09 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4000772267676687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4000772267676687 | validation: 1.33241188872659]
	TIME [epoch: 9.08 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0330170588194292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0330170588194292 | validation: 1.080161729091842]
	TIME [epoch: 9.08 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0482008126297782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0482008126297782 | validation: 0.7264213156946397]
	TIME [epoch: 9.08 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.157760772513671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.157760772513671 | validation: 1.1271137605647377]
	TIME [epoch: 9.07 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.418626745142537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.418626745142537 | validation: 1.170957968200954]
	TIME [epoch: 9.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.915968149259854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.915968149259854 | validation: 0.794320845881684]
	TIME [epoch: 9.08 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0767889841995801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0767889841995801 | validation: 0.8364293650432835]
	TIME [epoch: 9.07 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8065318761440379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8065318761440379 | validation: 1.6788387008353611]
	TIME [epoch: 9.07 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.249169086341413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.249169086341413 | validation: 1.6065494603409636]
	TIME [epoch: 9.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0187112018103226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0187112018103226 | validation: 1.3044012596743892]
	TIME [epoch: 9.09 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0425821978963214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0425821978963214 | validation: 0.9445001207349125]
	TIME [epoch: 9.07 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9414112094968458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9414112094968458 | validation: 0.8284987187343696]
	TIME [epoch: 9.08 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3738067607977897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3738067607977897 | validation: 2.0038013043339813]
	TIME [epoch: 9.08 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.104315962388558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.104315962388558 | validation: 0.9340794598418262]
	TIME [epoch: 9.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1092674041386976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1092674041386976 | validation: 1.3207356345362298]
	TIME [epoch: 9.08 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4518752978528406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4518752978528406 | validation: 1.1818145709192207]
	TIME [epoch: 9.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1030922551136633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1030922551136633 | validation: 1.110559895838794]
	TIME [epoch: 9.07 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2268447150371142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2268447150371142 | validation: 1.9178891937537035]
	TIME [epoch: 9.08 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3546555121767816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3546555121767816 | validation: 1.4461415742521533]
	TIME [epoch: 9.09 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5073367251616587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5073367251616587 | validation: 0.8306168610493255]
	TIME [epoch: 9.08 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9176133498464258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9176133498464258 | validation: 1.3438324890961981]
	TIME [epoch: 9.08 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.122090471330289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.122090471330289 | validation: 0.7840934091507186]
	TIME [epoch: 9.08 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0241052914632978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0241052914632978 | validation: 1.6676917773666302]
	TIME [epoch: 9.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1438131883622553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1438131883622553 | validation: 0.8448946967002067]
	TIME [epoch: 9.09 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9123827699406585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9123827699406585 | validation: 0.8223116180575873]
	TIME [epoch: 9.08 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8506506978656472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8506506978656472 | validation: 0.7578551231237924]
	TIME [epoch: 9.08 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3291333867353794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3291333867353794 | validation: 0.958460497404076]
	TIME [epoch: 9.08 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.042773869196287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.042773869196287 | validation: 0.6869394943304246]
	TIME [epoch: 9.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.083059351514643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.083059351514643 | validation: 1.16581891693623]
	TIME [epoch: 9.07 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1385500303586735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1385500303586735 | validation: 1.1556265819762022]
	TIME [epoch: 9.08 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9635569275219444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9635569275219444 | validation: 2.613688748427054]
	TIME [epoch: 9.07 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2194540482726284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2194540482726284 | validation: 1.435684066600678]
	TIME [epoch: 9.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2845100210296778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2845100210296778 | validation: 1.2486948605853554]
	TIME [epoch: 9.08 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1123126920189574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1123126920189574 | validation: 1.5435001450884318]
	TIME [epoch: 9.08 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9087325354289341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9087325354289341 | validation: 0.6637801382202331]
	TIME [epoch: 9.08 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.477287857685726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.477287857685726 | validation: 0.8074068021761326]
	TIME [epoch: 9.08 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0742099740609397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0742099740609397 | validation: 0.9954866741200532]
	TIME [epoch: 9.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9180520928528138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9180520928528138 | validation: 0.61723000484793]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240217_002816/states/model_tr_study3_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8989831905474486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8989831905474486 | validation: 1.3947224972089542]
	TIME [epoch: 9.08 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7774761757366349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7774761757366349 | validation: 1.4559011698066113]
	TIME [epoch: 9.08 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9569325649616237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9569325649616237 | validation: 1.586816910083462]
	TIME [epoch: 9.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.107136816022359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.107136816022359 | validation: 1.1121840711891169]
	TIME [epoch: 9.09 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9671488291571386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9671488291571386 | validation: 0.931581983829807]
	TIME [epoch: 9.08 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1284161642360186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1284161642360186 | validation: 1.6775401644926111]
	TIME [epoch: 9.08 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0596185265856917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0596185265856917 | validation: 1.296350512371374]
	TIME [epoch: 9.08 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: nan		[learning rate: 0.01]
ERROR:
nan encountered in epoch 240 (training loss).
