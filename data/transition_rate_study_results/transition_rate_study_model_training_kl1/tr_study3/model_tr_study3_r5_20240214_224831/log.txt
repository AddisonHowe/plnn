Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1198766835

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 11.297825080029032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.297825080029032 | validation: 10.126733177203906]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 10.263382745456678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.263382745456678 | validation: 9.263199442783307]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 9.528363201562865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.528363201562865 | validation: 9.408905957261709]
	TIME [epoch: 9.09 sec]
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 9.36563310414458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.36563310414458 | validation: 8.424538719935533]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 9.159609996474254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.159609996474254 | validation: 8.31513737975547]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 9.096160147726613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.096160147726613 | validation: 8.681702029500496]
	TIME [epoch: 9.07 sec]
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 9.0569045827279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.0569045827279 | validation: 8.131930785894852]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 8.783039006937186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.783039006937186 | validation: 7.312152025645872]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 7.461004482685036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.461004482685036 | validation: 6.098862899599073]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 6.68400193260629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.68400193260629 | validation: 6.304297290214224]
	TIME [epoch: 9.07 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 6.2872372719061245		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 6.2872372719061245 | validation: 5.623966600111492]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 5.842149546069777		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 5.842149546069777 | validation: 4.43774243483513]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 5.443906442920802		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 5.443906442920802 | validation: 4.437566555539229]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 5.024623870570198		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 5.024623870570198 | validation: 4.289026533568567]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 5.226491875904072		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 5.226491875904072 | validation: 4.446582037616148]
	TIME [epoch: 9.1 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 5.561779349159928		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 5.561779349159928 | validation: 8.302897350531358]
	TIME [epoch: 9.08 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 9.048952197119892		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 9.048952197119892 | validation: 8.142606242038308]
	TIME [epoch: 9.07 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 7.605065868932094		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 7.605065868932094 | validation: 5.624508217165657]
	TIME [epoch: 9.07 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 5.5950137233928725		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 5.5950137233928725 | validation: 4.837974632926384]
	TIME [epoch: 9.08 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 5.233036435550334		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 5.233036435550334 | validation: 4.150703568323056]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 5.284754659945263		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 5.284754659945263 | validation: 4.713094376796828]
	TIME [epoch: 9.07 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 5.02481746583545		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 5.02481746583545 | validation: 4.64828171702025]
	TIME [epoch: 9.07 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 4.923905368752087		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 4.923905368752087 | validation: 4.132040466558422]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 5.0551028811836805		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 5.0551028811836805 | validation: 4.31088345374217]
	TIME [epoch: 9.09 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 4.809210410757929		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 4.809210410757929 | validation: 3.89600591877831]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 4.8484145938350816		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 4.8484145938350816 | validation: 3.8926610880976584]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 4.629935886639982		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 4.629935886639982 | validation: 4.1316772845387755]
	TIME [epoch: 9.07 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 4.613003443647966		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 4.613003443647966 | validation: 4.280323698394314]
	TIME [epoch: 9.09 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 4.836157064981434		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 4.836157064981434 | validation: 3.658656365257409]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 4.642845454378186		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 4.642845454378186 | validation: 3.6873853986086726]
	TIME [epoch: 9.07 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 4.543405990317201		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 4.543405990317201 | validation: 3.634233203537919]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 4.357268901911949		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 4.357268901911949 | validation: 4.815073494152716]
	TIME [epoch: 9.09 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 4.7037782482710835		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 4.7037782482710835 | validation: 3.60244806022854]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 4.458965971937471		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 4.458965971937471 | validation: 3.887803074221638]
	TIME [epoch: 9.06 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 4.401307106969532		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 4.401307106969532 | validation: 3.5740728761558165]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 4.467079297997114		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 4.467079297997114 | validation: 3.727019301796741]
	TIME [epoch: 9.08 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 4.495231841308377		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 4.495231841308377 | validation: 3.5491239475677228]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 4.402919751635042		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 4.402919751635042 | validation: 3.4168270085295296]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 4.4458114722376285		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 4.4458114722376285 | validation: 3.5631246307349684]
	TIME [epoch: 9.07 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 4.500974014981558		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 4.500974014981558 | validation: 3.8867320936284484]
	TIME [epoch: 9.08 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 5.385909012458449		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 5.385909012458449 | validation: 3.4360774993275607]
	TIME [epoch: 9.07 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 4.235876842274899		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 4.235876842274899 | validation: 3.5728745908982744]
	TIME [epoch: 9.07 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 4.190854663643958		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 4.190854663643958 | validation: 3.8292942796589426]
	TIME [epoch: 9.06 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 4.358336135849789		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 4.358336135849789 | validation: 3.9611175641409626]
	TIME [epoch: 9.07 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 4.158927637838526		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 4.158927637838526 | validation: 3.3445456758227876]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 4.223364355784855		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 4.223364355784855 | validation: 3.368246739260357]
	TIME [epoch: 9.06 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 3.203358531589258		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 3.203358531589258 | validation: 3.4251683763242564]
	TIME [epoch: 9.06 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2532372244518077		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 2.2532372244518077 | validation: 1.970190774025807]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 2.291891662251478		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 2.291891662251478 | validation: 1.8864356967902731]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 2.369186652162285		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 2.369186652162285 | validation: 2.0967227116479745]
	TIME [epoch: 9.06 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0114605267899455		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 2.0114605267899455 | validation: 2.1148513610078084]
	TIME [epoch: 9.06 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9770539545090713		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 1.9770539545090713 | validation: 2.0490082091064616]
	TIME [epoch: 9.06 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8121844790600607		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 1.8121844790600607 | validation: 1.9105203514859923]
	TIME [epoch: 9.08 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3323987643178836		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 2.3323987643178836 | validation: 1.77319622450361]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0086971091032466		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 2.0086971091032466 | validation: 2.134475667169694]
	TIME [epoch: 9.07 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8450760810948452		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 1.8450760810948452 | validation: 1.7572350297084167]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7767392403401843		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 1.7767392403401843 | validation: 2.357980585820079]
	TIME [epoch: 9.08 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9791232531551042		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 1.9791232531551042 | validation: 2.309130197766482]
	TIME [epoch: 9.06 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 2.121890108640873		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 2.121890108640873 | validation: 2.1654492835257892]
	TIME [epoch: 9.06 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 1.894454699211043		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 1.894454699211043 | validation: 3.2444272858911805]
	TIME [epoch: 9.06 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 2.192473426265294		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 2.192473426265294 | validation: 1.6098729120968942]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7954993228497564		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 1.7954993228497564 | validation: 1.4290851524209236]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 1.605857002217914		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 1.605857002217914 | validation: 1.3958231118257909]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9197645224855364		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 1.9197645224855364 | validation: 1.4783912253950091]
	TIME [epoch: 9.07 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6768467157201847		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 1.6768467157201847 | validation: 1.668773022618951]
	TIME [epoch: 9.06 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7544431113618295		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 1.7544431113618295 | validation: 1.285450129241232]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7086694659909867		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 1.7086694659909867 | validation: 1.6998525471318113]
	TIME [epoch: 9.08 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6514771574424867		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 1.6514771574424867 | validation: 1.4515667053319379]
	TIME [epoch: 9.07 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7942334968920328		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 1.7942334968920328 | validation: 1.390094734985714]
	TIME [epoch: 9.07 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.659693946670681		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 1.659693946670681 | validation: 1.6050233653076502]
	TIME [epoch: 9.08 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 1.695760462574901		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 1.695760462574901 | validation: 1.368215488333476]
	TIME [epoch: 9.09 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6210530927816413		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 1.6210530927816413 | validation: 1.5031990842071803]
	TIME [epoch: 9.08 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4858340680906674		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 1.4858340680906674 | validation: 1.3365117325587086]
	TIME [epoch: 9.07 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5901368753347433		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 1.5901368753347433 | validation: 1.6245651704751276]
	TIME [epoch: 9.07 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5905444296148912		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 1.5905444296148912 | validation: 1.4694800180114678]
	TIME [epoch: 9.07 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 1.739306555049854		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 1.739306555049854 | validation: 1.4039089436224605]
	TIME [epoch: 9.09 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5239338190382892		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 1.5239338190382892 | validation: 1.7952699474806701]
	TIME [epoch: 9.08 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 1.686052773137801		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 1.686052773137801 | validation: 1.387956825802434]
	TIME [epoch: 9.07 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4363754911303162		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 1.4363754911303162 | validation: 1.1728838690985897]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5792437381533133		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 1.5792437381533133 | validation: 1.5439436855706754]
	TIME [epoch: 9.09 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4959961064088403		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 1.4959961064088403 | validation: 1.4273298462239687]
	TIME [epoch: 9.07 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 1.971897940661765		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 1.971897940661765 | validation: 4.200769994297092]
	TIME [epoch: 9.07 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 2.5947651896354627		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 2.5947651896354627 | validation: 1.1724762024184967]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4023453149027374		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 1.4023453149027374 | validation: 1.5118986462625197]
	TIME [epoch: 9.07 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 1.673377418897396		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 1.673377418897396 | validation: 1.1843635844416918]
	TIME [epoch: 9.09 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4524092729382376		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 1.4524092729382376 | validation: 1.5775372177890938]
	TIME [epoch: 9.07 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0741065091814526		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 2.0741065091814526 | validation: 1.2878133922145056]
	TIME [epoch: 9.07 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 1.395841171695111		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 1.395841171695111 | validation: 1.716775632262665]
	TIME [epoch: 9.07 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4609080101615104		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 1.4609080101615104 | validation: 1.6452708608249265]
	TIME [epoch: 9.07 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4066510304386792		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 1.4066510304386792 | validation: 1.4307929951636569]
	TIME [epoch: 9.09 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5189471464100395		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 1.5189471464100395 | validation: 1.6369231030181817]
	TIME [epoch: 9.08 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3598911370296796		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 1.3598911370296796 | validation: 1.4829707859544872]
	TIME [epoch: 9.07 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7969815161911782		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 1.7969815161911782 | validation: 1.6076897036014257]
	TIME [epoch: 9.08 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 1.424093989929909		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 1.424093989929909 | validation: 1.5323764033131306]
	TIME [epoch: 9.07 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 1.349862444948792		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 1.349862444948792 | validation: 1.3085870562840052]
	TIME [epoch: 9.09 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4030446841705289		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 1.4030446841705289 | validation: 1.3622988216612177]
	TIME [epoch: 9.07 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4138026408816018		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 1.4138026408816018 | validation: 1.1534626734836047]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8620004179270595		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 1.8620004179270595 | validation: 1.8071710072751488]
	TIME [epoch: 9.07 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4994897385487787		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 1.4994897385487787 | validation: 1.2437423039454159]
	TIME [epoch: 9.09 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5844790427727085		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 1.5844790427727085 | validation: 1.4964463505167274]
	TIME [epoch: 9.07 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8438169094124608		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 1.8438169094124608 | validation: 1.3776685590494766]
	TIME [epoch: 9.07 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3784674999795425		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 1.3784674999795425 | validation: 1.3506450504403533]
	TIME [epoch: 9.07 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3265117482086326		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 1.3265117482086326 | validation: 1.214765408712894]
	TIME [epoch: 9.07 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3397801511632406		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 1.3397801511632406 | validation: 1.3373185117051758]
	TIME [epoch: 9.09 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3711225743827125		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 1.3711225743827125 | validation: 1.1136631861632063]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2808450910746818		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 1.2808450910746818 | validation: 2.2678765046131666]
	TIME [epoch: 9.07 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 1.409740497420315		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 1.409740497420315 | validation: 4.682840491026606]
	TIME [epoch: 9.07 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 2.245241667950544		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 2.245241667950544 | validation: 1.2263638302472488]
	TIME [epoch: 9.07 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2828439329443972		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 1.2828439329443972 | validation: 1.442825835814644]
	TIME [epoch: 9.09 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 1.408791007573613		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 1.408791007573613 | validation: 2.586429554827926]
	TIME [epoch: 9.07 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5297568297884172		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 1.5297568297884172 | validation: 1.196314700851652]
	TIME [epoch: 9.06 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3189053784048972		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 1.3189053784048972 | validation: 1.2416651807979213]
	TIME [epoch: 9.07 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2955671307030188		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 1.2955671307030188 | validation: 1.0654397198370074]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5053937988517487		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 1.5053937988517487 | validation: 1.0065352114302548]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2847066188977754		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 1.2847066188977754 | validation: 1.1757457903382789]
	TIME [epoch: 9.07 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3848630495760852		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 1.3848630495760852 | validation: 1.1240166959652713]
	TIME [epoch: 9.07 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2336559691971885		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 1.2336559691971885 | validation: 1.2611788238029629]
	TIME [epoch: 9.06 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1745649216907363		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 1.1745649216907363 | validation: 2.291865100782366]
	TIME [epoch: 9.06 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4489210800490269		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 1.4489210800490269 | validation: 1.327227367266366]
	TIME [epoch: 9.08 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9607374285196653		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 1.9607374285196653 | validation: 1.1675633694456216]
	TIME [epoch: 9.06 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3226345408652271		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 1.3226345408652271 | validation: 1.107767870608371]
	TIME [epoch: 9.06 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2802119118703243		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 1.2802119118703243 | validation: 1.3448347443427315]
	TIME [epoch: 9.06 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5285428535510506		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 1.5285428535510506 | validation: 1.0158176656125881]
	TIME [epoch: 9.07 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2674712739596692		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 1.2674712739596692 | validation: 1.0488883362056698]
	TIME [epoch: 9.07 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3405919837571314		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 1.3405919837571314 | validation: 0.9671387239831752]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1907224316015554		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 1.1907224316015554 | validation: 0.9644025536891383]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_126.pth
	Model improved!!!
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1524575486653659		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 1.1524575486653659 | validation: 1.2326119590262024]
	TIME [epoch: 9.06 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3671788767313415		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 1.3671788767313415 | validation: 1.3270824109525718]
	TIME [epoch: 9.08 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2043688338950689		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 1.2043688338950689 | validation: 1.0355967596548648]
	TIME [epoch: 9.06 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4643843407632042		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 1.4643843407632042 | validation: 1.0341107213976617]
	TIME [epoch: 9.06 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1666268682938732		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 1.1666268682938732 | validation: 0.9072895268614509]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 1.267094645040099		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 1.267094645040099 | validation: 1.340943922257292]
	TIME [epoch: 9.06 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2602705875363283		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 1.2602705875363283 | validation: 1.2977095746325868]
	TIME [epoch: 9.08 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1486966696755885		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 1.1486966696755885 | validation: 0.9770752546825137]
	TIME [epoch: 9.06 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1835748633190226		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 1.1835748633190226 | validation: 1.0368182814399511]
	TIME [epoch: 9.06 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3688909113353664		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 1.3688909113353664 | validation: 1.2972042170700813]
	TIME [epoch: 9.05 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1892631686794695		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 1.1892631686794695 | validation: 1.0611178651883773]
	TIME [epoch: 9.06 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1614339508887728		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 1.1614339508887728 | validation: 1.343468425155423]
	TIME [epoch: 9.08 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2253146467811193		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 1.2253146467811193 | validation: 1.2666354241551558]
	TIME [epoch: 9.06 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2763702433628104		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 1.2763702433628104 | validation: 1.2458570549199837]
	TIME [epoch: 9.06 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2386428093769415		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 1.2386428093769415 | validation: 0.9942948761286332]
	TIME [epoch: 9.06 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1590863684557915		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 1.1590863684557915 | validation: 0.8688342013882698]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0971765752826672		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 1.0971765752826672 | validation: 1.31190827616507]
	TIME [epoch: 9.08 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2571693586699149		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 1.2571693586699149 | validation: 2.383680098054645]
	TIME [epoch: 9.06 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3125344515344337		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 1.3125344515344337 | validation: 0.9453495924486276]
	TIME [epoch: 9.06 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1565194514207104		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 1.1565194514207104 | validation: 1.0556604338952924]
	TIME [epoch: 9.06 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4000458516376997		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 1.4000458516376997 | validation: 1.3148319766605807]
	TIME [epoch: 9.06 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1584690691290571		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 1.1584690691290571 | validation: 2.34499056275192]
	TIME [epoch: 9.08 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3234106514481745		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 1.3234106514481745 | validation: 1.064330893173608]
	TIME [epoch: 9.06 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 1.159517926013446		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 1.159517926013446 | validation: 1.0972458699856196]
	TIME [epoch: 9.06 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 1.269655529950623		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 1.269655529950623 | validation: 2.167099024051802]
	TIME [epoch: 9.05 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3228177374497547		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 1.3228177374497547 | validation: 0.9805670029643734]
	TIME [epoch: 9.08 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2117696281282053		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 1.2117696281282053 | validation: 1.3659202234815813]
	TIME [epoch: 9.06 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 1.065199472420935		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 1.065199472420935 | validation: 1.1245352222457048]
	TIME [epoch: 9.06 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1162396209476433		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 1.1162396209476433 | validation: 0.9005457045226728]
	TIME [epoch: 9.06 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1114920881439996		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 1.1114920881439996 | validation: 0.9203473119272902]
	TIME [epoch: 9.06 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9878795066014844		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.9878795066014844 | validation: 1.3067628397158073]
	TIME [epoch: 9.08 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 1.248641650368691		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 1.248641650368691 | validation: 1.0525160037556867]
	TIME [epoch: 9.06 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0330138046270678		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 1.0330138046270678 | validation: 1.014781764380964]
	TIME [epoch: 9.06 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 1.192201886486384		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 1.192201886486384 | validation: 0.8439978954451609]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1591046572832528		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 1.1591046572832528 | validation: 0.8884901645896233]
	TIME [epoch: 9.08 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 1.133394889308381		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 1.133394889308381 | validation: 1.1025628534794745]
	TIME [epoch: 9.06 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1002026355808616		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 1.1002026355808616 | validation: 1.2932075480898462]
	TIME [epoch: 9.05 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0801251615158978		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 1.0801251615158978 | validation: 0.7423186945199597]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_164.pth
	Model improved!!!
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0905339707885244		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 1.0905339707885244 | validation: 1.2145024645771691]
	TIME [epoch: 9.06 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0634238812232526		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 1.0634238812232526 | validation: 0.7765413994020758]
	TIME [epoch: 9.08 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2123069107796396		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 1.2123069107796396 | validation: 1.0909477923858935]
	TIME [epoch: 9.06 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9715014292181587		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.9715014292181587 | validation: 1.2342831795354035]
	TIME [epoch: 9.05 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0776961122048043		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 1.0776961122048043 | validation: 0.8529751187624652]
	TIME [epoch: 9.05 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0908686489117088		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 1.0908686489117088 | validation: 0.9322250404717989]
	TIME [epoch: 9.06 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 1.030628477279507		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 1.030628477279507 | validation: 1.0842432928924335]
	TIME [epoch: 9.07 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1798964950926412		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 1.1798964950926412 | validation: 0.9656453899334001]
	TIME [epoch: 9.06 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9812717091225679		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.9812717091225679 | validation: 0.8828687900719109]
	TIME [epoch: 9.05 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 1.108468656303136		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 1.108468656303136 | validation: 1.1415474192081674]
	TIME [epoch: 9.05 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2794469062502476		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 1.2794469062502476 | validation: 0.8718675303899202]
	TIME [epoch: 9.05 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1363370423994696		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 1.1363370423994696 | validation: 0.9064807298561737]
	TIME [epoch: 9.07 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1090646835704716		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 1.1090646835704716 | validation: 1.0222339395746152]
	TIME [epoch: 9.06 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3638836326194297		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 1.3638836326194297 | validation: 0.8258245636878189]
	TIME [epoch: 9.05 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2687238542430637		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 1.2687238542430637 | validation: 0.9447493259393702]
	TIME [epoch: 9.05 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0090054007230338		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 1.0090054007230338 | validation: 1.0577450093708647]
	TIME [epoch: 9.06 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9995746192164983		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.9995746192164983 | validation: 0.9362213281932174]
	TIME [epoch: 9.08 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9161405478929343		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.9161405478929343 | validation: 0.9534521419848112]
	TIME [epoch: 9.05 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0885087370284936		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 1.0885087370284936 | validation: 0.8515402765270781]
	TIME [epoch: 9.05 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0617440829675566		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 1.0617440829675566 | validation: 1.3252059186241494]
	TIME [epoch: 9.05 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 1.036502212841572		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 1.036502212841572 | validation: 0.7982422885384366]
	TIME [epoch: 9.07 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9938892236032665		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.9938892236032665 | validation: 0.7228054076959525]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_186.pth
	Model improved!!!
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 1.464434734679722		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 1.464434734679722 | validation: 0.8579222618030947]
	TIME [epoch: 9.05 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9146419866349961		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.9146419866349961 | validation: 0.8310699971288553]
	TIME [epoch: 9.06 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1558507960246034		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 1.1558507960246034 | validation: 1.3077173819068588]
	TIME [epoch: 9.05 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9859732486859487		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.9859732486859487 | validation: 0.9890444347710621]
	TIME [epoch: 9.07 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0012502832119492		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 1.0012502832119492 | validation: 1.0636282920919413]
	TIME [epoch: 9.06 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0368243396220842		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 1.0368243396220842 | validation: 0.8325959475338205]
	TIME [epoch: 9.06 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9440719131536751		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.9440719131536751 | validation: 0.8108334121540324]
	TIME [epoch: 9.05 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8795574530865149		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.8795574530865149 | validation: 1.427084349749152]
	TIME [epoch: 9.05 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0912546842668267		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 1.0912546842668267 | validation: 1.0028096936708446]
	TIME [epoch: 9.08 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 1.242557397172083		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 1.242557397172083 | validation: 1.0008731241265827]
	TIME [epoch: 9.05 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1131736572877045		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 1.1131736572877045 | validation: 0.9850665500901534]
	TIME [epoch: 9.06 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0841596773899225		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 1.0841596773899225 | validation: 0.8535515295389203]
	TIME [epoch: 9.06 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0507652489184671		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 1.0507652489184671 | validation: 0.8665968145858067]
	TIME [epoch: 9.08 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9739297195378477		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.9739297195378477 | validation: 0.9891738608295788]
	TIME [epoch: 9.06 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9942939119535389		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.9942939119535389 | validation: 1.2477418261267217]
	TIME [epoch: 9.06 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3459161568997595		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 1.3459161568997595 | validation: 0.8016057532600286]
	TIME [epoch: 9.06 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9485612944679346		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.9485612944679346 | validation: 0.9299078406698151]
	TIME [epoch: 9.06 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9752228636248962		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.9752228636248962 | validation: 0.9973942534656505]
	TIME [epoch: 9.08 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9639853321736785		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.9639853321736785 | validation: 0.9362603968666265]
	TIME [epoch: 9.06 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9641190142700298		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.9641190142700298 | validation: 0.7769886986355038]
	TIME [epoch: 9.06 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9174426036522709		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.9174426036522709 | validation: 0.7052568112890311]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_207.pth
	Model improved!!!
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 1.084885901004328		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 1.084885901004328 | validation: 0.7506687317710039]
	TIME [epoch: 9.06 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9281253609854501		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.9281253609854501 | validation: 1.1851736376795388]
	TIME [epoch: 9.08 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1969938358665193		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 1.1969938358665193 | validation: 0.8501932354345978]
	TIME [epoch: 9.05 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 1.021212240048309		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 1.021212240048309 | validation: 0.9627207996864862]
	TIME [epoch: 9.05 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9646002031242012		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.9646002031242012 | validation: 0.8458293975932445]
	TIME [epoch: 9.05 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9941897174501596		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.9941897174501596 | validation: 0.9959217638560545]
	TIME [epoch: 9.06 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0141171931821786		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 1.0141171931821786 | validation: 0.8048968810250983]
	TIME [epoch: 9.08 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 1.073167665586595		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 1.073167665586595 | validation: 0.9330780221438311]
	TIME [epoch: 9.06 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0469210335174042		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 1.0469210335174042 | validation: 1.0435259353756725]
	TIME [epoch: 9.05 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 1.123866912052131		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 1.123866912052131 | validation: 1.7935064172862627]
	TIME [epoch: 9.06 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3107919517584694		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 1.3107919517584694 | validation: 0.7183038222806337]
	TIME [epoch: 9.08 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0533057012102773		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 1.0533057012102773 | validation: 0.8166568667973287]
	TIME [epoch: 9.07 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9713818156302452		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.9713818156302452 | validation: 0.8680619144926323]
	TIME [epoch: 9.06 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0811215103303629		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 1.0811215103303629 | validation: 1.166053556161897]
	TIME [epoch: 9.06 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0492528027768142		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 1.0492528027768142 | validation: 0.826354167652571]
	TIME [epoch: 9.06 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3414304305426994		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 1.3414304305426994 | validation: 0.8580643269840825]
	TIME [epoch: 9.08 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0520659740809908		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 1.0520659740809908 | validation: 0.9508288401820995]
	TIME [epoch: 9.06 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0170670961563564		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 1.0170670961563564 | validation: 1.020694370616257]
	TIME [epoch: 9.06 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2290397253399021		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 1.2290397253399021 | validation: 1.0168104697169094]
	TIME [epoch: 9.06 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1523557193886336		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 1.1523557193886336 | validation: 0.8330845356486872]
	TIME [epoch: 9.08 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.980909383960436		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.980909383960436 | validation: 0.8091702805906567]
	TIME [epoch: 9.07 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9612019538160382		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.9612019538160382 | validation: 1.080629927922419]
	TIME [epoch: 9.06 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1719118769650962		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 1.1719118769650962 | validation: 0.922308858348191]
	TIME [epoch: 9.05 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.996708188916019		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.996708188916019 | validation: 0.8399914450668351]
	TIME [epoch: 9.06 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9653443962346557		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.9653443962346557 | validation: 0.8947853466128586]
	TIME [epoch: 9.08 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8753733118212914		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.8753733118212914 | validation: 0.6629326273794187]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_233.pth
	Model improved!!!
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9203485461343138		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.9203485461343138 | validation: 1.026397781379213]
	TIME [epoch: 9.06 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0280131445889644		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 1.0280131445889644 | validation: 0.7474024839764776]
	TIME [epoch: 9.06 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9789173855517499		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.9789173855517499 | validation: 0.7837450279344251]
	TIME [epoch: 9.07 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 1.056685004967748		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 1.056685004967748 | validation: 0.9305859811575382]
	TIME [epoch: 9.08 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9119575104806532		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.9119575104806532 | validation: 0.7007108645286819]
	TIME [epoch: 9.06 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4104191764876302		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 1.4104191764876302 | validation: 0.8412742433669671]
	TIME [epoch: 9.06 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9245315048316435		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.9245315048316435 | validation: 0.8070313841337043]
	TIME [epoch: 9.06 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0833617799067257		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 1.0833617799067257 | validation: 0.7288890594675099]
	TIME [epoch: 9.05 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9835131353039366		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.9835131353039366 | validation: 0.7970731189340287]
	TIME [epoch: 9.08 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9003804246363603		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.9003804246363603 | validation: 0.9123330766775616]
	TIME [epoch: 9.05 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9885168636357864		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.9885168636357864 | validation: 0.9860012359668725]
	TIME [epoch: 9.05 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9446393847041186		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.9446393847041186 | validation: 0.8520655770208747]
	TIME [epoch: 9.05 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0119310909835815		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 1.0119310909835815 | validation: 0.8207390855338572]
	TIME [epoch: 9.08 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8859193003420083		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.8859193003420083 | validation: 1.1537407255719843]
	TIME [epoch: 9.06 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0184994130567133		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 1.0184994130567133 | validation: 0.8088175003995262]
	TIME [epoch: 9.06 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8799031578581868		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.8799031578581868 | validation: 1.1271768069356458]
	TIME [epoch: 9.05 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0025900908426537		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 1.0025900908426537 | validation: 1.078907323146857]
	TIME [epoch: 9.06 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1482478032474843		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 1.1482478032474843 | validation: 1.2462451839186992]
	TIME [epoch: 9.08 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9560879101413491		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.9560879101413491 | validation: 1.0908964878748717]
	TIME [epoch: 9.06 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9483705679792624		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.9483705679792624 | validation: 0.7152342744652267]
	TIME [epoch: 9.05 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8657270400344098		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.8657270400344098 | validation: 0.8596513780852149]
	TIME [epoch: 9.05 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9668118708632726		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.9668118708632726 | validation: 1.157492948195741]
	TIME [epoch: 9.07 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0142920829413025		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 1.0142920829413025 | validation: 0.8119183718441785]
	TIME [epoch: 9.05 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9002639226172976		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.9002639226172976 | validation: 0.7947451624897783]
	TIME [epoch: 9.05 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.96210893254938		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.96210893254938 | validation: 0.8864500680944096]
	TIME [epoch: 9.05 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9340931908025653		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.9340931908025653 | validation: 0.8549690315454453]
	TIME [epoch: 9.05 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9238598725912375		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.9238598725912375 | validation: 0.9201748514633741]
	TIME [epoch: 9.08 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1675095275799674		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 1.1675095275799674 | validation: 0.9059510574808698]
	TIME [epoch: 9.06 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8988029711413954		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.8988029711413954 | validation: 0.969546486082846]
	TIME [epoch: 9.05 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0451002288134055		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 1.0451002288134055 | validation: 0.964076952488815]
	TIME [epoch: 9.05 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8737471109898539		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.8737471109898539 | validation: 0.8254047966801248]
	TIME [epoch: 9.06 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1852644089623774		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 1.1852644089623774 | validation: 0.8210864531922588]
	TIME [epoch: 9.08 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6845172636166321		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 1.6845172636166321 | validation: 1.333848641382808]
	TIME [epoch: 9.06 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1457055420709332		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 1.1457055420709332 | validation: 0.8154963093519987]
	TIME [epoch: 9.05 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1101529643306125		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 1.1101529643306125 | validation: 1.133721451313166]
	TIME [epoch: 9.05 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 1.101771163871436		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 1.101771163871436 | validation: 0.9912048958903548]
	TIME [epoch: 9.07 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4754382940768624		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 1.4754382940768624 | validation: 0.8877536107315782]
	TIME [epoch: 9.06 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1030171230272052		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 1.1030171230272052 | validation: 0.8533033790774056]
	TIME [epoch: 9.05 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4197984427650436		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 1.4197984427650436 | validation: 0.9250139239009563]
	TIME [epoch: 9.05 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9555233222686116		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.9555233222686116 | validation: 1.2651647550523988]
	TIME [epoch: 9.05 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.976776037800273		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.976776037800273 | validation: 0.8429268252995059]
	TIME [epoch: 9.08 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1300420177255546		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 1.1300420177255546 | validation: 0.9622317110708916]
	TIME [epoch: 9.06 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9870016188702261		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.9870016188702261 | validation: 0.8807629413665156]
	TIME [epoch: 9.06 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9051711866828903		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.9051711866828903 | validation: 0.8733027996336316]
	TIME [epoch: 9.06 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9140748564023717		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.9140748564023717 | validation: 0.7534750660799143]
	TIME [epoch: 9.07 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9033991977243241		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.9033991977243241 | validation: 0.7538213732763763]
	TIME [epoch: 9.06 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8947524751336008		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.8947524751336008 | validation: 0.9795326383578469]
	TIME [epoch: 9.05 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9581732988302987		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.9581732988302987 | validation: 0.7830314624793921]
	TIME [epoch: 9.05 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8547884692824242		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.8547884692824242 | validation: 0.8139658719694789]
	TIME [epoch: 9.05 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9186530786898215		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.9186530786898215 | validation: 0.8440767557975366]
	TIME [epoch: 9.08 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9143832004372351		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.9143832004372351 | validation: 0.7248929168919459]
	TIME [epoch: 9.06 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0517493113208483		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 1.0517493113208483 | validation: 0.9610266038158484]
	TIME [epoch: 9.05 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1869223705940413		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 1.1869223705940413 | validation: 0.8215959875338773]
	TIME [epoch: 9.05 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0800382841061793		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 1.0800382841061793 | validation: 0.9148380878944713]
	TIME [epoch: 9.05 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9510373628192064		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.9510373628192064 | validation: 0.970425876954965]
	TIME [epoch: 9.08 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9187985937254173		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.9187985937254173 | validation: 0.8024003626612155]
	TIME [epoch: 9.05 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0519410949008527		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 1.0519410949008527 | validation: 0.8468540100247415]
	TIME [epoch: 9.05 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0128003075981342		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 1.0128003075981342 | validation: 1.4086851751542764]
	TIME [epoch: 9.05 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1936383763235607		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 1.1936383763235607 | validation: 0.7970944743453456]
	TIME [epoch: 9.07 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 1.199701255018483		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 1.199701255018483 | validation: 0.924351828343188]
	TIME [epoch: 9.06 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 1.097973769634995		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 1.097973769634995 | validation: 1.0320099512682754]
	TIME [epoch: 9.06 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2016714128068056		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 1.2016714128068056 | validation: 1.1160866857122105]
	TIME [epoch: 9.05 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2473591376094235		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 1.2473591376094235 | validation: 1.1682016125326158]
	TIME [epoch: 9.05 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3543390894574692		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 1.3543390894574692 | validation: 1.0907634411281073]
	TIME [epoch: 9.08 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2864179399714302		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 1.2864179399714302 | validation: 1.3715698332649988]
	TIME [epoch: 9.06 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1225337284297958		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 1.1225337284297958 | validation: 0.7129313670287964]
	TIME [epoch: 9.05 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9504435392963076		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.9504435392963076 | validation: 0.882490246115542]
	TIME [epoch: 9.05 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9312705742020947		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.9312705742020947 | validation: 0.7887980992481582]
	TIME [epoch: 9.08 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8980195055134785		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.8980195055134785 | validation: 1.0008238575480024]
	TIME [epoch: 9.06 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9357395007473736		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.9357395007473736 | validation: 0.8982950034982915]
	TIME [epoch: 9.05 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 1.16177018224543		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 1.16177018224543 | validation: 1.2714948094471663]
	TIME [epoch: 9.05 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0804167965036744		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 1.0804167965036744 | validation: 0.8227694220864021]
	TIME [epoch: 9.05 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1415763276656565		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 1.1415763276656565 | validation: 1.0826157759861585]
	TIME [epoch: 9.07 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9255836268129473		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.9255836268129473 | validation: 0.9009921065501898]
	TIME [epoch: 9.06 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1257625867464047		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 1.1257625867464047 | validation: 0.981480661505594]
	TIME [epoch: 9.05 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 1.13115338392315		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 1.13115338392315 | validation: 1.7243758533748836]
	TIME [epoch: 9.06 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2766682265010039		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 1.2766682265010039 | validation: 0.9984283260356117]
	TIME [epoch: 9.06 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 1.761513147528495		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 1.761513147528495 | validation: 1.6936189417371308]
	TIME [epoch: 9.08 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5093168347642023		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 1.5093168347642023 | validation: 0.8492483854236287]
	TIME [epoch: 9.06 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9738111332415945		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.9738111332415945 | validation: 0.8180675344940528]
	TIME [epoch: 9.06 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9614712486277306		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.9614712486277306 | validation: 0.8101726585327998]
	TIME [epoch: 9.06 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 1.067992266722054		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 1.067992266722054 | validation: 0.9404709220096252]
	TIME [epoch: 9.08 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 1.310641587546899		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 1.310641587546899 | validation: 0.9036476937160127]
	TIME [epoch: 9.06 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 1.301231164057295		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 1.301231164057295 | validation: 1.060513082479251]
	TIME [epoch: 9.06 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2242117672343007		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 1.2242117672343007 | validation: 0.8774655476897234]
	TIME [epoch: 9.06 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9218199521078327		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.9218199521078327 | validation: 0.7665709849067646]
	TIME [epoch: 9.06 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0537035773420018		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 1.0537035773420018 | validation: 0.8240719275674617]
	TIME [epoch: 9.08 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1741458294083333		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 1.1741458294083333 | validation: 0.7763403026475346]
	TIME [epoch: 9.06 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 1.099654563383925		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 1.099654563383925 | validation: 1.4907427095106673]
	TIME [epoch: 9.05 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6410577215952007		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 1.6410577215952007 | validation: 0.8182992906448769]
	TIME [epoch: 9.06 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3322659892602613		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 1.3322659892602613 | validation: 1.0737397321434505]
	TIME [epoch: 9.07 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1376799820680028		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 1.1376799820680028 | validation: 0.8881566422632134]
	TIME [epoch: 9.06 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9274990096577836		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.9274990096577836 | validation: 0.7245014883865626]
	TIME [epoch: 9.06 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9662770159447291		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.9662770159447291 | validation: 0.8010522916264131]
	TIME [epoch: 9.06 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2481487444621815		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 1.2481487444621815 | validation: 0.7594127412583649]
	TIME [epoch: 9.06 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9274906551835722		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.9274906551835722 | validation: 0.775571089060971]
	TIME [epoch: 9.09 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0204148124273047		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 1.0204148124273047 | validation: 0.7329820334038823]
	TIME [epoch: 9.06 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9147970518502504		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.9147970518502504 | validation: 0.9708352243917222]
	TIME [epoch: 9.06 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0029559478533758		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 1.0029559478533758 | validation: 0.8206731739264141]
	TIME [epoch: 9.06 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9400909996432105		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.9400909996432105 | validation: 0.7805497761153095]
	TIME [epoch: 9.06 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8902788591672579		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.8902788591672579 | validation: 0.7286075547105098]
	TIME [epoch: 9.08 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0856165638331778		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 1.0856165638331778 | validation: 0.8905386275578209]
	TIME [epoch: 9.06 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.871233027295462		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.871233027295462 | validation: 0.74588759325881]
	TIME [epoch: 9.06 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9167681313925353		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.9167681313925353 | validation: 0.7525044034377955]
	TIME [epoch: 9.06 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9183121085138455		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.9183121085138455 | validation: 0.8406964618002276]
	TIME [epoch: 9.08 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 1.053746833690574		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 1.053746833690574 | validation: 0.8859005838480569]
	TIME [epoch: 9.06 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0355940631658604		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 1.0355940631658604 | validation: 1.0216736996835765]
	TIME [epoch: 9.1 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9371834685526812		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.9371834685526812 | validation: 0.7357491641132057]
	TIME [epoch: 9.06 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1252930381271677		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 1.1252930381271677 | validation: 0.896818990179634]
	TIME [epoch: 9.06 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8885142991626782		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.8885142991626782 | validation: 0.8244770883380558]
	TIME [epoch: 9.08 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9149938214442652		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.9149938214442652 | validation: 0.8270824499827241]
	TIME [epoch: 9.06 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0031368340829476		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 1.0031368340829476 | validation: 0.8557497105668601]
	TIME [epoch: 9.05 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.92087910751506		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.92087910751506 | validation: 0.7043908991683685]
	TIME [epoch: 9.05 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8871426974676249		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.8871426974676249 | validation: 0.6552966280099646]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_347.pth
	Model improved!!!
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8431167306246918		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.8431167306246918 | validation: 0.7530550886656036]
	TIME [epoch: 9.06 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8373479968894957		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.8373479968894957 | validation: 0.7454010757305796]
	TIME [epoch: 9.05 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8495852418890358		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.8495852418890358 | validation: 0.6869044463458485]
	TIME [epoch: 9.05 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8837331410811847		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.8837331410811847 | validation: 0.6763073181173931]
	TIME [epoch: 9.05 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8904902413347994		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.8904902413347994 | validation: 0.694156117279207]
	TIME [epoch: 9.07 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.834424556799908		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.834424556799908 | validation: 0.6751166977136599]
	TIME [epoch: 9.06 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8188642675034178		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.8188642675034178 | validation: 0.6798186388847589]
	TIME [epoch: 9.05 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.817512061629931		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.817512061629931 | validation: 0.913866032395134]
	TIME [epoch: 9.05 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8920676073253097		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.8920676073253097 | validation: 0.6991014583761893]
	TIME [epoch: 9.05 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8476715700726801		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.8476715700726801 | validation: 0.7248404397675484]
	TIME [epoch: 9.07 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9681402345094426		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.9681402345094426 | validation: 0.8580163145987801]
	TIME [epoch: 9.05 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0400364516719542		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 1.0400364516719542 | validation: 0.7646598775369087]
	TIME [epoch: 9.06 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9840048861307642		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.9840048861307642 | validation: 0.8753049104079913]
	TIME [epoch: 9.05 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9211486485843432		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.9211486485843432 | validation: 0.9033476411639421]
	TIME [epoch: 9.05 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9357156215110362		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.9357156215110362 | validation: 0.8304039321389943]
	TIME [epoch: 9.07 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8549264445257772		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.8549264445257772 | validation: 0.7675984592655334]
	TIME [epoch: 9.05 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9411948546225195		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.9411948546225195 | validation: 0.8031251830531168]
	TIME [epoch: 9.05 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0763720873450253		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 1.0763720873450253 | validation: 1.32360423025574]
	TIME [epoch: 9.05 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.918024431839647		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.918024431839647 | validation: 0.7250905580333783]
	TIME [epoch: 9.07 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8082834039846647		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.8082834039846647 | validation: 0.7755168852921595]
	TIME [epoch: 9.05 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8502853116825694		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.8502853116825694 | validation: 0.7227735761693388]
	TIME [epoch: 9.05 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7478739898274992		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.7478739898274992 | validation: 0.7161174033137505]
	TIME [epoch: 9.05 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7556982392990105		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.7556982392990105 | validation: 0.8728547474358316]
	TIME [epoch: 9.05 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9652563745405441		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.9652563745405441 | validation: 0.8566931984089856]
	TIME [epoch: 9.07 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8943689860779026		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.8943689860779026 | validation: 0.6753560532855165]
	TIME [epoch: 9.05 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7881920886247258		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.7881920886247258 | validation: 0.821633342154324]
	TIME [epoch: 9.05 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7976643790627517		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.7976643790627517 | validation: 0.678749528742193]
	TIME [epoch: 9.05 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8330959038829306		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.8330959038829306 | validation: 0.6646974577095954]
	TIME [epoch: 9.06 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7793299698717363		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.7793299698717363 | validation: 0.7522551790940312]
	TIME [epoch: 9.11 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7579414049728603		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.7579414049728603 | validation: 0.7009461022359197]
	TIME [epoch: 9.05 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7834447569677455		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.7834447569677455 | validation: 0.7508357645409449]
	TIME [epoch: 9.05 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8985677657054305		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.8985677657054305 | validation: 0.9873204364286147]
	TIME [epoch: 9.05 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9070051359697839		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.9070051359697839 | validation: 0.6892106503394918]
	TIME [epoch: 9.07 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9037874378672368		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.9037874378672368 | validation: 0.7857507787460043]
	TIME [epoch: 9.05 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9854783929921884		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.9854783929921884 | validation: 0.7462422935694926]
	TIME [epoch: 9.05 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9734577398406747		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.9734577398406747 | validation: 0.9381198279162246]
	TIME [epoch: 9.05 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9481359491101108		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.9481359491101108 | validation: 0.6671822603839304]
	TIME [epoch: 9.05 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8084013639352531		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.8084013639352531 | validation: 0.7773670467288469]
	TIME [epoch: 9.07 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.867853044241669		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.867853044241669 | validation: 0.8218642560196803]
	TIME [epoch: 9.04 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8260667644510196		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.8260667644510196 | validation: 0.6281369323035708]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_387.pth
	Model improved!!!
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7941714261924167		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.7941714261924167 | validation: 0.6907447011842056]
	TIME [epoch: 9.04 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8934775691868785		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.8934775691868785 | validation: 0.7224622687280111]
	TIME [epoch: 9.07 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9392094636244416		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.9392094636244416 | validation: 0.822573536870991]
	TIME [epoch: 9.05 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8612752688625426		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.8612752688625426 | validation: 0.6968559451272717]
	TIME [epoch: 9.05 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.800141401031019		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.800141401031019 | validation: 0.7372643298289263]
	TIME [epoch: 9.05 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8535851153067286		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.8535851153067286 | validation: 0.8808108162691671]
	TIME [epoch: 9.05 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8221989203620353		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.8221989203620353 | validation: 0.6660209549469893]
	TIME [epoch: 9.09 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7498256162122645		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.7498256162122645 | validation: 0.6193270754494481]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_395.pth
	Model improved!!!
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8285719093915432		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.8285719093915432 | validation: 0.7397857865599502]
	TIME [epoch: 9.07 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8463729024934379		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.8463729024934379 | validation: 0.7523610752652237]
	TIME [epoch: 9.08 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8468593794008689		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.8468593794008689 | validation: 1.0772725533189398]
	TIME [epoch: 9.06 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2005214605924561		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 1.2005214605924561 | validation: 0.7402555895691971]
	TIME [epoch: 9.09 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8997192160024298		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.8997192160024298 | validation: 0.6444938219853062]
	TIME [epoch: 9.08 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8270362169641938		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.8270362169641938 | validation: 0.759783125718087]
	TIME [epoch: 9.07 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2220260285236333		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 1.2220260285236333 | validation: 0.7665561632493341]
	TIME [epoch: 9.05 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9413409697299183		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.9413409697299183 | validation: 0.749335606588265]
	TIME [epoch: 9.06 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8636532824916996		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.8636532824916996 | validation: 0.7585903918748708]
	TIME [epoch: 9.08 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7814076043991514		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.7814076043991514 | validation: 0.7635371289352195]
	TIME [epoch: 9.05 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8199946594099525		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.8199946594099525 | validation: 0.7067640947972758]
	TIME [epoch: 9.05 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7587692216919949		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.7587692216919949 | validation: 0.6539164642402439]
	TIME [epoch: 9.05 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7566390332414205		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.7566390332414205 | validation: 0.6234507916351214]
	TIME [epoch: 9.06 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8126992061155616		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.8126992061155616 | validation: 0.6659077552248889]
	TIME [epoch: 9.07 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8291534571705516		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.8291534571705516 | validation: 0.63427600539727]
	TIME [epoch: 9.05 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7865485439407565		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.7865485439407565 | validation: 0.6669646403070976]
	TIME [epoch: 9.05 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7286615310190929		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.7286615310190929 | validation: 0.6999420528596416]
	TIME [epoch: 9.05 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8420630709313084		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.8420630709313084 | validation: 0.780804800664582]
	TIME [epoch: 9.07 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8053991001914405		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.8053991001914405 | validation: 0.7668008331027457]
	TIME [epoch: 9.05 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.899153019468066		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.899153019468066 | validation: 0.7625521481506721]
	TIME [epoch: 9.05 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8701475817220322		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.8701475817220322 | validation: 0.7359442558024324]
	TIME [epoch: 9.05 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8227422631278973		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.8227422631278973 | validation: 0.810865887455667]
	TIME [epoch: 9.05 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8155902042060925		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.8155902042060925 | validation: 0.7308756545876074]
	TIME [epoch: 9.07 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.850783240333967		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.850783240333967 | validation: 0.6234101013792688]
	TIME [epoch: 9.05 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.792282109849193		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.792282109849193 | validation: 0.7456290692079706]
	TIME [epoch: 9.05 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7926425643641294		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.7926425643641294 | validation: 0.7455302677655743]
	TIME [epoch: 9.05 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7772758938448819		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.7772758938448819 | validation: 0.7757228835517546]
	TIME [epoch: 9.09 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7782048846096881		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.7782048846096881 | validation: 0.6927018936258269]
	TIME [epoch: 9.07 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7909924732916062		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.7909924732916062 | validation: 0.666726718271878]
	TIME [epoch: 9.07 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7922040400195549		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.7922040400195549 | validation: 0.6411395690745583]
	TIME [epoch: 9.06 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7811039486585635		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.7811039486585635 | validation: 0.8371753904877843]
	TIME [epoch: 9.06 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9074952841937962		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.9074952841937962 | validation: 0.6975572419948733]
	TIME [epoch: 9.07 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7881721657987716		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.7881721657987716 | validation: 0.6902711125096601]
	TIME [epoch: 9.07 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7538851144551321		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.7538851144551321 | validation: 0.6145155158158625]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_429.pth
	Model improved!!!
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7751140807661885		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.7751140807661885 | validation: 0.6791370261131328]
	TIME [epoch: 9.07 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7670158126369613		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.7670158126369613 | validation: 0.6231495216757273]
	TIME [epoch: 9.08 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7223839722633988		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.7223839722633988 | validation: 0.619858621663651]
	TIME [epoch: 9.06 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7592954398042642		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.7592954398042642 | validation: 0.7740247432198541]
	TIME [epoch: 9.06 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8712387018136869		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.8712387018136869 | validation: 0.7046406712767381]
	TIME [epoch: 9.06 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7192099274678072		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.7192099274678072 | validation: 1.0295062787756744]
	TIME [epoch: 9.06 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7633347621086708		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.7633347621086708 | validation: 0.6307368822582249]
	TIME [epoch: 9.08 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7287020526586167		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.7287020526586167 | validation: 0.660840563967013]
	TIME [epoch: 9.07 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7652351703043122		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.7652351703043122 | validation: 0.6145091187663453]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_438.pth
	Model improved!!!
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7335728368473353		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.7335728368473353 | validation: 0.625648548002186]
	TIME [epoch: 9.06 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7312046708895193		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.7312046708895193 | validation: 0.6886214031297719]
	TIME [epoch: 9.06 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7324858088825933		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.7324858088825933 | validation: 0.5760160106801624]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_441.pth
	Model improved!!!
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7308148612861107		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.7308148612861107 | validation: 0.6492856817621235]
	TIME [epoch: 9.07 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7216677889146522		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.7216677889146522 | validation: 0.6985515454608193]
	TIME [epoch: 9.06 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7377379221608249		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.7377379221608249 | validation: 0.6608335760897108]
	TIME [epoch: 9.06 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7458220556747037		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.7458220556747037 | validation: 0.5865120369966441]
	TIME [epoch: 9.07 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7091063238786365		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.7091063238786365 | validation: 0.6501768148712239]
	TIME [epoch: 9.08 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.697512569647021		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.697512569647021 | validation: 0.7667117082990137]
	TIME [epoch: 9.07 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6964382649434357		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.6964382649434357 | validation: 0.630033142973677]
	TIME [epoch: 9.07 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7284670249178992		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.7284670249178992 | validation: 0.7159670461999013]
	TIME [epoch: 9.06 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7190381599058248		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.7190381599058248 | validation: 0.732603233071436]
	TIME [epoch: 9.07 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8163958136928431		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.8163958136928431 | validation: 0.6159905659694349]
	TIME [epoch: 9.08 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7624256500775043		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.7624256500775043 | validation: 0.6152340737960503]
	TIME [epoch: 9.07 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7449849801477165		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.7449849801477165 | validation: 0.594166129005508]
	TIME [epoch: 9.07 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7159123195090303		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.7159123195090303 | validation: 0.7055318367161426]
	TIME [epoch: 9.06 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7316556089810271		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.7316556089810271 | validation: 0.6993805943836883]
	TIME [epoch: 9.08 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7531992881806953		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.7531992881806953 | validation: 0.6895344344071948]
	TIME [epoch: 9.07 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7844193824122174		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.7844193824122174 | validation: 0.606938787984751]
	TIME [epoch: 9.06 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7162809786685087		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.7162809786685087 | validation: 0.6088194623832325]
	TIME [epoch: 9.07 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6824921160511688		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.6824921160511688 | validation: 0.6380612547636163]
	TIME [epoch: 9.06 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7081788710397807		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.7081788710397807 | validation: 0.6393825078669586]
	TIME [epoch: 9.09 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.725441738981718		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.725441738981718 | validation: 0.6778739506788843]
	TIME [epoch: 9.06 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6711459024552868		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.6711459024552868 | validation: 0.6114464479175481]
	TIME [epoch: 9.06 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7244147094008122		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.7244147094008122 | validation: 0.6359845457901923]
	TIME [epoch: 9.06 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6858496296235264		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.6858496296235264 | validation: 0.639306159379897]
	TIME [epoch: 9.08 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6763323488275039		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.6763323488275039 | validation: 0.6055876988415623]
	TIME [epoch: 9.07 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7003491141407552		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.7003491141407552 | validation: 0.6448710098575744]
	TIME [epoch: 9.07 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7526535215001124		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.7526535215001124 | validation: 0.6035842273582273]
	TIME [epoch: 9.06 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7108040022176446		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.7108040022176446 | validation: 0.6202913657768883]
	TIME [epoch: 9.07 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7046498579566418		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.7046498579566418 | validation: 0.6351721440497782]
	TIME [epoch: 9.08 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7195481380742038		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.7195481380742038 | validation: 0.5717605958347456]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_470.pth
	Model improved!!!
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7058629036936052		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.7058629036936052 | validation: 0.6091044235669227]
	TIME [epoch: 9.06 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6829827776339944		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.6829827776339944 | validation: 0.6124690388789045]
	TIME [epoch: 9.06 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6710677404467362		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.6710677404467362 | validation: 0.6745445944155364]
	TIME [epoch: 9.07 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6994414204806871		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.6994414204806871 | validation: 0.6809593516051191]
	TIME [epoch: 9.07 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.67293932299626		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.67293932299626 | validation: 0.6173519298824385]
	TIME [epoch: 9.06 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6766007797952638		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.6766007797952638 | validation: 0.7054537549466778]
	TIME [epoch: 9.06 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.66731322802176		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.66731322802176 | validation: 0.61860461263796]
	TIME [epoch: 9.06 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6837020965308247		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.6837020965308247 | validation: 0.6407433074345794]
	TIME [epoch: 9.08 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7433807428125903		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.7433807428125903 | validation: 0.6276964876820001]
	TIME [epoch: 9.08 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7368796144702242		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.7368796144702242 | validation: 0.614620666014112]
	TIME [epoch: 9.06 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.717761673959311		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.717761673959311 | validation: 0.6147782617094373]
	TIME [epoch: 9.07 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7204810601269268		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.7204810601269268 | validation: 0.7367759192671972]
	TIME [epoch: 9.06 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8088946909349511		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.8088946909349511 | validation: 0.6907746628956435]
	TIME [epoch: 9.08 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6735277573580197		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.6735277573580197 | validation: 0.6719073819828012]
	TIME [epoch: 9.06 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7022492716920834		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.7022492716920834 | validation: 0.5938143271833567]
	TIME [epoch: 9.06 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7078627033226897		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.7078627033226897 | validation: 0.6867782728724499]
	TIME [epoch: 9.06 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7308985001765856		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.7308985001765856 | validation: 0.6890842997771678]
	TIME [epoch: 9.06 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6892390300145699		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.6892390300145699 | validation: 0.7414308639635194]
	TIME [epoch: 9.08 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7060698856649738		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.7060698856649738 | validation: 0.6519487609201635]
	TIME [epoch: 9.06 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7006557189057179		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.7006557189057179 | validation: 0.5806674086315042]
	TIME [epoch: 9.06 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6925505669066478		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.6925505669066478 | validation: 0.5871829259624236]
	TIME [epoch: 9.06 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6676217924348814		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.6676217924348814 | validation: 0.8132866077916341]
	TIME [epoch: 9.08 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.669901775860249		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.669901775860249 | validation: 0.6752022139430449]
	TIME [epoch: 9.06 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6600117445065045		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.6600117445065045 | validation: 0.565503515356355]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240214_224831/states/model_tr_study3_494.pth
	Model improved!!!
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6820959938636882		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.6820959938636882 | validation: 0.6003723741710085]
	TIME [epoch: 9.06 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6466286680711313		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.6466286680711313 | validation: 0.6187795687629809]
	TIME [epoch: 9.06 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6783295809341598		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.6783295809341598 | validation: 0.59029582279174]
	TIME [epoch: 9.08 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6875176055941903		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.6875176055941903 | validation: 0.6611985376375757]
	TIME [epoch: 9.06 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6499354175501415		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.6499354175501415 | validation: 0.5990968951732589]
	TIME [epoch: 9.05 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6426523890289233		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.6426523890289233 | validation: 0.59516182749566]
	TIME [epoch: 9.06 sec]
Finished training in 4596.576 seconds.
