Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2726583243

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 10.798963813280716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.798963813280716 | validation: 10.025471650016108]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 9.478935035860989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.478935035860989 | validation: 9.560311830042162]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 9.035333716150792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.035333716150792 | validation: 9.162988618430665]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 8.660527180496882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.660527180496882 | validation: 8.43919476228961]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 7.988812084677375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.988812084677375 | validation: 8.10298295347507]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 7.434901045182099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.434901045182099 | validation: 8.237226758743084]
	TIME [epoch: 9.09 sec]
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 7.219320346055238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.219320346055238 | validation: 7.968902142178843]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 6.976522364250572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.976522364250572 | validation: 7.159003731911658]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 6.475478131798747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.475478131798747 | validation: 7.255750943464519]
	TIME [epoch: 9.09 sec]
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 6.4007726566837375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4007726566837375 | validation: 6.5410225356929566]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 5.935301434655166		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 5.935301434655166 | validation: 6.138833553393347]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 5.71733723980206		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 5.71733723980206 | validation: 6.213869729244211]
	TIME [epoch: 9.09 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 5.798179004142834		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 5.798179004142834 | validation: 5.952883048012416]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 6.0930923490756985		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 6.0930923490756985 | validation: 6.222691189459319]
	TIME [epoch: 9.08 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 5.912948175998804		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 5.912948175998804 | validation: 5.876520010020775]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 5.5375893016460696		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 5.5375893016460696 | validation: 5.672638902362643]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 5.5649208383847695		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 5.5649208383847695 | validation: 6.102376108116524]
	TIME [epoch: 9.1 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 5.605589259731852		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 5.605589259731852 | validation: 5.188896220142292]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 5.1438792793767645		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 5.1438792793767645 | validation: 5.192988794990605]
	TIME [epoch: 9.13 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 5.046908971445854		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 5.046908971445854 | validation: 6.292096008002549]
	TIME [epoch: 9.1 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 5.408368177834836		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 5.408368177834836 | validation: 5.996513910799697]
	TIME [epoch: 9.09 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 4.962666018809719		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 4.962666018809719 | validation: 4.549031813339106]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 6.514308452692705		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 6.514308452692705 | validation: 7.178048061701518]
	TIME [epoch: 9.1 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 7.399884320890602		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 7.399884320890602 | validation: 6.793307938865814]
	TIME [epoch: 9.09 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 5.731098910365856		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 5.731098910365856 | validation: 5.931395511028681]
	TIME [epoch: 9.09 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 5.460770620007727		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 5.460770620007727 | validation: 5.910505643909373]
	TIME [epoch: 9.07 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 5.479801372496167		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 5.479801372496167 | validation: 4.904817879980754]
	TIME [epoch: 9.09 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 5.02817456757852		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 5.02817456757852 | validation: 5.006709602076341]
	TIME [epoch: 9.1 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 4.68954244753788		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 4.68954244753788 | validation: 4.474165189419395]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 4.563277476925715		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 4.563277476925715 | validation: 4.779772032622953]
	TIME [epoch: 9.09 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 4.641987219368477		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 4.641987219368477 | validation: 5.049809175898357]
	TIME [epoch: 9.09 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 4.459515649112767		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 4.459515649112767 | validation: 4.191432122441257]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 3.9821263707398336		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 3.9821263707398336 | validation: 3.587983539461434]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 3.4882138399575764		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 3.4882138399575764 | validation: 4.6350017594454]
	TIME [epoch: 9.08 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 3.3767407071696818		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 3.3767407071696818 | validation: 2.840975077780092]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 2.9006083348056317		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 2.9006083348056317 | validation: 3.052441250726914]
	TIME [epoch: 9.11 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 2.5388620473772052		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 2.5388620473772052 | validation: 2.452034918184149]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 2.26610888764734		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 2.26610888764734 | validation: 3.1647476957875957]
	TIME [epoch: 9.09 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2755912357218517		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 2.2755912357218517 | validation: 2.3699687511373155]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3278131326139047		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 2.3278131326139047 | validation: 2.6107842311472433]
	TIME [epoch: 9.1 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 2.411092822346002		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 2.411092822346002 | validation: 1.8719376866048227]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0507182604234857		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 2.0507182604234857 | validation: 1.8209998810789285]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 2.032035470303379		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 2.032035470303379 | validation: 1.5768391039119147]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7082675436457706		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 1.7082675436457706 | validation: 2.4020892953822077]
	TIME [epoch: 9.09 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6941713792178383		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 1.6941713792178383 | validation: 2.268934644849144]
	TIME [epoch: 9.08 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7338139666394725		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 1.7338139666394725 | validation: 1.3676134459359781]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7198122564614546		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 1.7198122564614546 | validation: 1.6915970847193735]
	TIME [epoch: 9.08 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6747709000335533		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 1.6747709000335533 | validation: 1.468556231835797]
	TIME [epoch: 9.1 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 2.25330545387513		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 2.25330545387513 | validation: 1.9161538302024304]
	TIME [epoch: 9.08 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7936518052065018		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 1.7936518052065018 | validation: 1.9656994525499045]
	TIME [epoch: 9.08 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0684580242246233		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 2.0684580242246233 | validation: 3.3354680854274585]
	TIME [epoch: 9.08 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8454006232719489		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 1.8454006232719489 | validation: 1.9790499177471408]
	TIME [epoch: 9.1 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7330748054164449		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 1.7330748054164449 | validation: 1.754941988036394]
	TIME [epoch: 9.09 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6447015236298612		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 1.6447015236298612 | validation: 1.710628983364526]
	TIME [epoch: 9.08 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5667692771308133		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 1.5667692771308133 | validation: 1.9570539848688207]
	TIME [epoch: 9.08 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6186938306806002		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 1.6186938306806002 | validation: 2.026997793179346]
	TIME [epoch: 9.09 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 1.710615314552653		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 1.710615314552653 | validation: 1.755410160239994]
	TIME [epoch: 9.09 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5774898743807877		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 1.5774898743807877 | validation: 1.6554188825280303]
	TIME [epoch: 9.08 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5703461397561769		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 1.5703461397561769 | validation: 1.390522701128166]
	TIME [epoch: 9.07 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4821780707152818		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 1.4821780707152818 | validation: 2.0548573695167773]
	TIME [epoch: 9.08 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4385110374738974		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 1.4385110374738974 | validation: 1.4547774347054936]
	TIME [epoch: 9.1 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4488406038780655		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 1.4488406038780655 | validation: 1.2906558230206826]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5085091507420607		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 1.5085091507420607 | validation: 1.578951328762849]
	TIME [epoch: 9.08 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6695184759648036		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 1.6695184759648036 | validation: 1.3894586634449537]
	TIME [epoch: 9.07 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5101205610060116		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 1.5101205610060116 | validation: 1.589754725161487]
	TIME [epoch: 9.1 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4114154329478459		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 1.4114154329478459 | validation: 1.7157771509010602]
	TIME [epoch: 9.08 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 1.425850904231193		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 1.425850904231193 | validation: 1.5711246454206669]
	TIME [epoch: 9.07 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4873033922699122		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 1.4873033922699122 | validation: 1.4289179056097283]
	TIME [epoch: 9.07 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3725338036507828		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 1.3725338036507828 | validation: 1.4846025896094814]
	TIME [epoch: 9.09 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1521362158653148		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 1.1521362158653148 | validation: 1.9302383333851219]
	TIME [epoch: 9.08 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1813307112808342		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 1.1813307112808342 | validation: 1.4217124294470214]
	TIME [epoch: 9.07 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1350200074175996		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 1.1350200074175996 | validation: 2.3512989022497495]
	TIME [epoch: 9.07 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 1.185711701023789		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 1.185711701023789 | validation: 1.0828297203383808]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0204012923286572		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 1.0204012923286572 | validation: 1.6134279976547867]
	TIME [epoch: 9.09 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1872600509111693		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 1.1872600509111693 | validation: 1.0098566771672957]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1113288610770529		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 1.1113288610770529 | validation: 0.9962036025041032]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1127641329076323		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 1.1127641329076323 | validation: 1.2659474268380602]
	TIME [epoch: 9.09 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3349154421539362		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 1.3349154421539362 | validation: 1.1084351435679323]
	TIME [epoch: 9.11 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 1.220113762752155		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 1.220113762752155 | validation: 1.4140925876463541]
	TIME [epoch: 9.09 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1536403086053983		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 1.1536403086053983 | validation: 1.0970822127991768]
	TIME [epoch: 9.09 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2890633055592144		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 1.2890633055592144 | validation: 1.124733231556371]
	TIME [epoch: 9.08 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0864820611787214		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 1.0864820611787214 | validation: 1.1695730125575792]
	TIME [epoch: 9.09 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0957688426588066		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 1.0957688426588066 | validation: 0.9525720256613885]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0215143518108971		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 1.0215143518108971 | validation: 1.2812902985174293]
	TIME [epoch: 9.08 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9776663830317862		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 0.9776663830317862 | validation: 1.0945308257182005]
	TIME [epoch: 9.08 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9717009814573532		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 0.9717009814573532 | validation: 1.1320792551105274]
	TIME [epoch: 9.08 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0419243822938475		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 1.0419243822938475 | validation: 0.9878288438874236]
	TIME [epoch: 9.1 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0643471862449887		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 1.0643471862449887 | validation: 1.2165696385295846]
	TIME [epoch: 9.08 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2658068024461822		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 1.2658068024461822 | validation: 0.9317456454330739]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1854028792909286		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 1.1854028792909286 | validation: 1.0137636498254454]
	TIME [epoch: 9.09 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0648711644846116		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 1.0648711644846116 | validation: 1.0450850452340337]
	TIME [epoch: 9.1 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1827375115172276		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 1.1827375115172276 | validation: 0.9350085493778129]
	TIME [epoch: 9.09 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3018726645082217		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 1.3018726645082217 | validation: 1.414979697379599]
	TIME [epoch: 9.09 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2063886568566191		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 1.2063886568566191 | validation: 1.3207601638972615]
	TIME [epoch: 9.09 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 1.051523329189998		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 1.051523329189998 | validation: 1.5596271790448382]
	TIME [epoch: 9.09 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0711953309730213		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 1.0711953309730213 | validation: 0.9575779075394165]
	TIME [epoch: 9.11 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3270550066901117		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 1.3270550066901117 | validation: 0.922160304908583]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9911683799702902		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 0.9911683799702902 | validation: 1.4649430550686706]
	TIME [epoch: 9.1 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0780642854199756		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 1.0780642854199756 | validation: 1.1815634701431588]
	TIME [epoch: 9.09 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9978608130852796		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.9978608130852796 | validation: 1.072582507811012]
	TIME [epoch: 9.11 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0227412486062828		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 1.0227412486062828 | validation: 1.407339083834144]
	TIME [epoch: 9.1 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1202146122145717		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 1.1202146122145717 | validation: 1.427623414722091]
	TIME [epoch: 9.1 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 1.097525165463816		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 1.097525165463816 | validation: 1.0364353044135406]
	TIME [epoch: 9.11 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9367943850771484		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 0.9367943850771484 | validation: 1.0833319383855302]
	TIME [epoch: 9.11 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9589936797749121		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 0.9589936797749121 | validation: 1.4445108352625795]
	TIME [epoch: 9.11 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 1.33817330725002		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 1.33817330725002 | validation: 1.0159563649656815]
	TIME [epoch: 9.08 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.842109358935567		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.842109358935567 | validation: 1.8560671926214165]
	TIME [epoch: 9.1 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0163618524205031		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 1.0163618524205031 | validation: 1.4242038599543907]
	TIME [epoch: 9.1 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 1.099723593682103		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 1.099723593682103 | validation: 1.115203690196205]
	TIME [epoch: 9.11 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.915160743706957		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.915160743706957 | validation: 1.7001306518976027]
	TIME [epoch: 9.08 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2864182809143183		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 1.2864182809143183 | validation: 0.8817347756740169]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8839745390257076		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.8839745390257076 | validation: 1.1730009401947012]
	TIME [epoch: 9.08 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9625406691373598		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.9625406691373598 | validation: 1.020359278284267]
	TIME [epoch: 9.11 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9386758856046358		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.9386758856046358 | validation: 1.2748982924834695]
	TIME [epoch: 9.08 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9960274333753822		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.9960274333753822 | validation: 1.0283975562137364]
	TIME [epoch: 9.08 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8991632471128395		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.8991632471128395 | validation: 1.0356474018749857]
	TIME [epoch: 9.08 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9836540419529888		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.9836540419529888 | validation: 1.2818467935994753]
	TIME [epoch: 9.09 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9560734945327137		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.9560734945327137 | validation: 1.2677017752905395]
	TIME [epoch: 9.1 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9516220491015803		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 0.9516220491015803 | validation: 1.0728371143063795]
	TIME [epoch: 9.08 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9694971500812677		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.9694971500812677 | validation: 1.0827161761314987]
	TIME [epoch: 9.08 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9535626640701164		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.9535626640701164 | validation: 1.0472966898660636]
	TIME [epoch: 9.09 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 1.09227702370015		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 1.09227702370015 | validation: 1.0160685415636423]
	TIME [epoch: 9.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9882732635032785		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.9882732635032785 | validation: 1.0820099539504675]
	TIME [epoch: 9.09 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.929427497703656		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.929427497703656 | validation: 1.4027967603996976]
	TIME [epoch: 9.08 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 1.156665807231223		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 1.156665807231223 | validation: 1.0043722089293932]
	TIME [epoch: 9.08 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 1.020983017788631		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 1.020983017788631 | validation: 1.1673180659504154]
	TIME [epoch: 9.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1089877375419308		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 1.1089877375419308 | validation: 0.9131095016974884]
	TIME [epoch: 9.08 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9425325770851722		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.9425325770851722 | validation: 1.0944717699738526]
	TIME [epoch: 9.08 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.952557757603007		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.952557757603007 | validation: 1.0647964391084312]
	TIME [epoch: 9.08 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8485588431036171		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.8485588431036171 | validation: 0.8916126694724591]
	TIME [epoch: 9.11 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8874567311510514		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.8874567311510514 | validation: 0.8566255761162503]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8427792614207927		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.8427792614207927 | validation: 0.7891173287403842]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0293337091381896		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 1.0293337091381896 | validation: 0.9898703704310958]
	TIME [epoch: 9.08 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.888128059198664		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.888128059198664 | validation: 0.7651789865660363]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_134.pth
	Model improved!!!
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9531107704078197		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.9531107704078197 | validation: 0.8724224416039537]
	TIME [epoch: 9.09 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8331538316612352		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.8331538316612352 | validation: 0.8694590269264751]
	TIME [epoch: 9.08 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8861480853279072		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.8861480853279072 | validation: 1.6209716599928718]
	TIME [epoch: 9.08 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8723621715376748		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.8723621715376748 | validation: 0.8733391658010781]
	TIME [epoch: 9.09 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8014087599690469		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.8014087599690469 | validation: 0.9230249373435508]
	TIME [epoch: 9.09 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9087259856910563		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 0.9087259856910563 | validation: 1.1133720947576493]
	TIME [epoch: 9.07 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8950729201966083		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.8950729201966083 | validation: 0.7219969252874674]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9852937754695974		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.9852937754695974 | validation: 0.97235193260765]
	TIME [epoch: 9.08 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7929267770623347		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.7929267770623347 | validation: 0.7775509492576578]
	TIME [epoch: 9.09 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8889171677665063		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.8889171677665063 | validation: 0.7674081691055206]
	TIME [epoch: 9.08 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8569239088582611		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.8569239088582611 | validation: 1.0087349598221236]
	TIME [epoch: 9.07 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0988443299148505		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 1.0988443299148505 | validation: 1.136774034156229]
	TIME [epoch: 9.07 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9057687809440038		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.9057687809440038 | validation: 0.8275774655138881]
	TIME [epoch: 9.09 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7814138390984313		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.7814138390984313 | validation: 1.054475265975119]
	TIME [epoch: 9.07 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8733924260474758		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.8733924260474758 | validation: 0.8176196785440868]
	TIME [epoch: 9.07 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7904025014719063		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.7904025014719063 | validation: 1.0096189380243548]
	TIME [epoch: 9.07 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8709831757215328		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.8709831757215328 | validation: 0.8517309399500238]
	TIME [epoch: 9.08 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8131786898588095		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.8131786898588095 | validation: 1.2204722587204888]
	TIME [epoch: 9.09 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.804929336431709		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.804929336431709 | validation: 0.8408241787708115]
	TIME [epoch: 9.07 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7791098637278746		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.7791098637278746 | validation: 0.7936698865367154]
	TIME [epoch: 9.07 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8949643291017593		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.8949643291017593 | validation: 0.8246188332837907]
	TIME [epoch: 9.07 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.838118673042936		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.838118673042936 | validation: 0.8641859790640063]
	TIME [epoch: 9.1 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7943159461698059		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.7943159461698059 | validation: 1.0561670524562459]
	TIME [epoch: 9.07 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8033399327973889		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.8033399327973889 | validation: 1.0077942853262103]
	TIME [epoch: 9.06 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.784116091197505		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.784116091197505 | validation: 0.742086779832923]
	TIME [epoch: 9.07 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7689326063318326		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.7689326063318326 | validation: 0.6832839011254837]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7517318048459208		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.7517318048459208 | validation: 0.9202991415671538]
	TIME [epoch: 9.08 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7406711555741353		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.7406711555741353 | validation: 0.7723103852924398]
	TIME [epoch: 9.07 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6782819982090059		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.6782819982090059 | validation: 0.9362443600673427]
	TIME [epoch: 9.07 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7431018076884605		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.7431018076884605 | validation: 0.9786837023212802]
	TIME [epoch: 9.1 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9150930511811317		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.9150930511811317 | validation: 1.0125675939824668]
	TIME [epoch: 9.08 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8445941816838267		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.8445941816838267 | validation: 1.1625688314938232]
	TIME [epoch: 9.07 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8809154776897593		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.8809154776897593 | validation: 0.9628880562890609]
	TIME [epoch: 9.07 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9215122084810272		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.9215122084810272 | validation: 0.7528990105430375]
	TIME [epoch: 9.08 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6309177933030112		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.6309177933030112 | validation: 1.4601036022491498]
	TIME [epoch: 9.09 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7454893207836893		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.7454893207836893 | validation: 0.8449714336825357]
	TIME [epoch: 9.07 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9932334508280027		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.9932334508280027 | validation: 0.8421694754403652]
	TIME [epoch: 9.07 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7023363245298272		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.7023363245298272 | validation: 1.4893916733105144]
	TIME [epoch: 9.08 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8742825674143188		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.8742825674143188 | validation: 0.8541190427757679]
	TIME [epoch: 9.1 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7259668247056905		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.7259668247056905 | validation: 0.8031682521142085]
	TIME [epoch: 9.08 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8426194774014627		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.8426194774014627 | validation: 0.7981418790126451]
	TIME [epoch: 9.08 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7291981722181714		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.7291981722181714 | validation: 0.7473127131017432]
	TIME [epoch: 9.08 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7963115142842131		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.7963115142842131 | validation: 0.9791786021350051]
	TIME [epoch: 9.1 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8206162779155968		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.8206162779155968 | validation: 1.1421367472941382]
	TIME [epoch: 9.08 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7742375534176326		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.7742375534176326 | validation: 0.9182473908572315]
	TIME [epoch: 9.07 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6541791121665895		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.6541791121665895 | validation: 0.8104609065957069]
	TIME [epoch: 9.07 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7456511339965102		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.7456511339965102 | validation: 0.7477111777590949]
	TIME [epoch: 9.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8064388498434711		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.8064388498434711 | validation: 0.8397043801423393]
	TIME [epoch: 9.08 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.672050531169216		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.672050531169216 | validation: 1.0049553537523108]
	TIME [epoch: 9.07 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.83801169018124		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.83801169018124 | validation: 0.7309720004904571]
	TIME [epoch: 9.07 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7350508714893582		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.7350508714893582 | validation: 1.2974517241320094]
	TIME [epoch: 9.09 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7165551637957269		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.7165551637957269 | validation: 0.7574254468540504]
	TIME [epoch: 9.08 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6293801859489256		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.6293801859489256 | validation: 0.5732034386804248]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_187.pth
	Model improved!!!
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7226656275248067		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.7226656275248067 | validation: 0.8932028226605745]
	TIME [epoch: 9.07 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.916023999605313		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.916023999605313 | validation: 0.6640399945589129]
	TIME [epoch: 9.08 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6126653509838219		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.6126653509838219 | validation: 0.6826380157507566]
	TIME [epoch: 9.08 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5121687784678522		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.5121687784678522 | validation: 0.6477945646829517]
	TIME [epoch: 9.07 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5912889737403378		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.5912889737403378 | validation: 0.6735519345127343]
	TIME [epoch: 9.07 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6694301355288761		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.6694301355288761 | validation: 0.6987610843301554]
	TIME [epoch: 9.06 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6633769373452111		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.6633769373452111 | validation: 0.7914650347679457]
	TIME [epoch: 9.09 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.654427051772924		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.654427051772924 | validation: 0.535163066270701]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_195.pth
	Model improved!!!
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.578808884248544		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.578808884248544 | validation: 0.7854396117310193]
	TIME [epoch: 9.07 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6040577070794786		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.6040577070794786 | validation: 0.6542960196901653]
	TIME [epoch: 9.07 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6647638475500777		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.6647638475500777 | validation: 0.704287926297849]
	TIME [epoch: 9.09 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6518599811626079		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.6518599811626079 | validation: 0.5656863741573874]
	TIME [epoch: 9.07 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5972021861827184		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.5972021861827184 | validation: 0.8711365089591433]
	TIME [epoch: 9.07 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6273338244452473		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.6273338244452473 | validation: 0.7292285012590554]
	TIME [epoch: 9.07 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6114269627371922		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.6114269627371922 | validation: 0.7404839074431646]
	TIME [epoch: 9.07 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.611003166005708		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.611003166005708 | validation: 0.6066167943852212]
	TIME [epoch: 9.09 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5727780268134302		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.5727780268134302 | validation: 0.5631967995774498]
	TIME [epoch: 9.07 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6395699890424033		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.6395699890424033 | validation: 0.6982334994389239]
	TIME [epoch: 9.07 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7082776873228382		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.7082776873228382 | validation: 0.6398501949186085]
	TIME [epoch: 9.07 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6939661962956012		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.6939661962956012 | validation: 0.5376046264767758]
	TIME [epoch: 9.09 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.547426848003759		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.547426848003759 | validation: 0.6271297166637403]
	TIME [epoch: 9.07 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.613623630291796		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.613623630291796 | validation: 0.536910676653554]
	TIME [epoch: 9.07 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5861147385399399		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.5861147385399399 | validation: 0.5518568802269322]
	TIME [epoch: 9.08 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6277125344439475		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.6277125344439475 | validation: 0.7328887584086774]
	TIME [epoch: 9.09 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.689665624553658		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.689665624553658 | validation: 0.7152922763199954]
	TIME [epoch: 9.07 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6101126144336262		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.6101126144336262 | validation: 0.7312745051337064]
	TIME [epoch: 9.07 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5585579667224758		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.5585579667224758 | validation: 0.6168314115846787]
	TIME [epoch: 9.07 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5863645288653527		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.5863645288653527 | validation: 0.4332285977765641]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_215.pth
	Model improved!!!
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5942849185849141		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.5942849185849141 | validation: 0.4363010244788511]
	TIME [epoch: 9.07 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5791271822784008		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.5791271822784008 | validation: 0.6841226400470792]
	TIME [epoch: 9.06 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5601669119462331		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.5601669119462331 | validation: 0.6015628236215114]
	TIME [epoch: 9.07 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5066115568219669		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.5066115568219669 | validation: 0.5310102201462193]
	TIME [epoch: 9.07 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5602149318045182		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.5602149318045182 | validation: 0.4052858793385793]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_220.pth
	Model improved!!!
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5420665320296317		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.5420665320296317 | validation: 0.5384697737596672]
	TIME [epoch: 9.07 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5926555979065242		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.5926555979065242 | validation: 0.9518551595198339]
	TIME [epoch: 9.07 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6044554357587366		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.6044554357587366 | validation: 0.5134712590993222]
	TIME [epoch: 9.06 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5681167563440419		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.5681167563440419 | validation: 0.6545226096722186]
	TIME [epoch: 9.1 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5447278132203504		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.5447278132203504 | validation: 0.7549660236248834]
	TIME [epoch: 9.07 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4848681284368396		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.4848681284368396 | validation: 0.5325809090935691]
	TIME [epoch: 9.07 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6476975677545752		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.6476975677545752 | validation: 0.619418470783945]
	TIME [epoch: 9.07 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5739439699541784		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.5739439699541784 | validation: 0.6099700066873421]
	TIME [epoch: 9.08 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5642044138133031		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.5642044138133031 | validation: 0.8873050606748303]
	TIME [epoch: 9.08 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6219196400888098		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.6219196400888098 | validation: 0.3851991954773794]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_230.pth
	Model improved!!!
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45521323785773377		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.45521323785773377 | validation: 0.45272644907504156]
	TIME [epoch: 9.08 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5038378276344464		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.5038378276344464 | validation: 0.402208356331449]
	TIME [epoch: 9.08 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5195159313646479		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.5195159313646479 | validation: 0.4413838711169292]
	TIME [epoch: 9.08 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5093818641515536		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.5093818641515536 | validation: 0.6591917579286706]
	TIME [epoch: 9.07 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5865702582730893		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.5865702582730893 | validation: 0.4708244588761281]
	TIME [epoch: 9.07 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6852344370609561		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.6852344370609561 | validation: 0.6319824131489548]
	TIME [epoch: 9.07 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.569918923295772		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.569918923295772 | validation: 0.6165187580237521]
	TIME [epoch: 9.1 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5185423077888152		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.5185423077888152 | validation: 0.41360449410392464]
	TIME [epoch: 9.07 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5117118587129919		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.5117118587129919 | validation: 0.5598672473763677]
	TIME [epoch: 9.08 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4910883601422696		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.4910883601422696 | validation: 0.522588657190048]
	TIME [epoch: 9.07 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4994272158502138		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.4994272158502138 | validation: 0.5237062720640133]
	TIME [epoch: 9.08 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5948153091583197		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.5948153091583197 | validation: 0.6728921252226037]
	TIME [epoch: 9.09 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5436136351915316		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.5436136351915316 | validation: 0.6662679165299139]
	TIME [epoch: 9.06 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41541236098181916		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.41541236098181916 | validation: 0.9612014636328969]
	TIME [epoch: 9.07 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5077601491226217		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.5077601491226217 | validation: 0.7370216441079]
	TIME [epoch: 9.08 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5055588623055961		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.5055588623055961 | validation: 0.44258151936908996]
	TIME [epoch: 9.09 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5609022622757586		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.5609022622757586 | validation: 0.5460095185858644]
	TIME [epoch: 9.07 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44397005433071246		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.44397005433071246 | validation: 0.41595232813432226]
	TIME [epoch: 9.07 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4875397496282211		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.4875397496282211 | validation: 1.0387823484493526]
	TIME [epoch: 9.07 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9611814874746344		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.9611814874746344 | validation: 0.4151696914285326]
	TIME [epoch: 9.09 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44800396254684893		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.44800396254684893 | validation: 0.3638930954792214]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_251.pth
	Model improved!!!
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5906443685124783		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.5906443685124783 | validation: 0.800438717928549]
	TIME [epoch: 9.07 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5034998757771227		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.5034998757771227 | validation: 0.452682663175046]
	TIME [epoch: 9.06 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5071605841761792		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.5071605841761792 | validation: 0.6870953215302182]
	TIME [epoch: 9.09 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43593081618250384		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.43593081618250384 | validation: 0.4259080224620754]
	TIME [epoch: 9.06 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4867376456137663		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.4867376456137663 | validation: 0.4213166702417691]
	TIME [epoch: 9.07 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5430030435488697		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.5430030435488697 | validation: 0.5776747566380726]
	TIME [epoch: 9.07 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5749104840599153		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.5749104840599153 | validation: 0.5796024550324366]
	TIME [epoch: 9.08 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5034150810289494		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.5034150810289494 | validation: 0.4511621602610723]
	TIME [epoch: 9.09 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.403080062468821		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.403080062468821 | validation: 0.42076741833905096]
	TIME [epoch: 9.07 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5708233975675647		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.5708233975675647 | validation: 0.7216230293162147]
	TIME [epoch: 9.07 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6168151285941125		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.6168151285941125 | validation: 0.6711581677077028]
	TIME [epoch: 9.08 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4855623291246454		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.4855623291246454 | validation: 0.41225257321412895]
	TIME [epoch: 9.08 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8645158804519525		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.8645158804519525 | validation: 0.7702010406618219]
	TIME [epoch: 9.07 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8151275243875572		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.8151275243875572 | validation: 0.6665407824457272]
	TIME [epoch: 9.07 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.666545774932059		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.666545774932059 | validation: 0.6198887643600317]
	TIME [epoch: 9.06 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5233027261616633		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.5233027261616633 | validation: 0.43789795367671336]
	TIME [epoch: 9.09 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4188137237198063		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.4188137237198063 | validation: 0.5483771278894062]
	TIME [epoch: 9.06 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5574043175903463		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.5574043175903463 | validation: 0.446500252255817]
	TIME [epoch: 9.05 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5921824558970192		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.5921824558970192 | validation: 0.5068754642765186]
	TIME [epoch: 9.06 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45729689741967655		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.45729689741967655 | validation: 0.41053275234091846]
	TIME [epoch: 9.08 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5525674254902113		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.5525674254902113 | validation: 0.4808189203600878]
	TIME [epoch: 9.06 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4195095833850564		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.4195095833850564 | validation: 0.45858845894071654]
	TIME [epoch: 9.07 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4269380614520527		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.4269380614520527 | validation: 0.36743912321576305]
	TIME [epoch: 9.06 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41372535228996166		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.41372535228996166 | validation: 0.5261592610625714]
	TIME [epoch: 9.08 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6456648586839809		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.6456648586839809 | validation: 0.5382141021835063]
	TIME [epoch: 9.05 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49085652015963194		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.49085652015963194 | validation: 0.4193188894008423]
	TIME [epoch: 9.07 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38302148151649695		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.38302148151649695 | validation: 0.5281856095194107]
	TIME [epoch: 9.06 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48056862657219945		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.48056862657219945 | validation: 0.41686587107399364]
	TIME [epoch: 9.08 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4130078237460969		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.4130078237460969 | validation: 0.37557752274661205]
	TIME [epoch: 9.06 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4283428087652779		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.4283428087652779 | validation: 0.37850792923800003]
	TIME [epoch: 9.05 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39235811190409364		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.39235811190409364 | validation: 0.32591439810234146]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_282.pth
	Model improved!!!
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31155233985655206		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.31155233985655206 | validation: 0.39394723627053263]
	TIME [epoch: 9.07 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3670332738320093		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.3670332738320093 | validation: 0.35646195370209843]
	TIME [epoch: 9.07 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41754887848253147		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.41754887848253147 | validation: 0.3037905311025406]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_285.pth
	Model improved!!!
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39819504499961733		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.39819504499961733 | validation: 0.32931533361556353]
	TIME [epoch: 9.07 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.345114053444337		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.345114053444337 | validation: 0.27750874394632497]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_287.pth
	Model improved!!!
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3534526282905174		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.3534526282905174 | validation: 0.7276402731008784]
	TIME [epoch: 9.08 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3857665261351335		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.3857665261351335 | validation: 0.7206610509611234]
	TIME [epoch: 9.06 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44037817377630306		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.44037817377630306 | validation: 0.4049087285714297]
	TIME [epoch: 9.05 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34829533959309583		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.34829533959309583 | validation: 0.4030650175960345]
	TIME [epoch: 9.05 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3771045749834486		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.3771045749834486 | validation: 0.3278107576093058]
	TIME [epoch: 9.06 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3985569913450331		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.3985569913450331 | validation: 0.3181778019479755]
	TIME [epoch: 9.07 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3401769835402735		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.3401769835402735 | validation: 0.33818711869982]
	TIME [epoch: 9.05 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34180619854284394		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.34180619854284394 | validation: 0.42654894568878676]
	TIME [epoch: 9.05 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4760493023732678		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.4760493023732678 | validation: 0.3925363576202245]
	TIME [epoch: 9.07 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4026187966918597		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.4026187966918597 | validation: 0.3080227335622854]
	TIME [epoch: 9.08 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3526826194875616		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.3526826194875616 | validation: 0.3277790987677097]
	TIME [epoch: 9.06 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33029428351585655		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.33029428351585655 | validation: 0.4624174658041633]
	TIME [epoch: 9.07 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4053470712960198		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.4053470712960198 | validation: 0.6284658051955063]
	TIME [epoch: 9.06 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39011305058513446		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.39011305058513446 | validation: 0.4449586139650741]
	TIME [epoch: 9.08 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3780494315795213		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.3780494315795213 | validation: 0.31004457004601704]
	TIME [epoch: 9.06 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33250751476840984		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.33250751476840984 | validation: 0.6196061173204926]
	TIME [epoch: 9.07 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4816351280658154		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.4816351280658154 | validation: 0.36397748867501056]
	TIME [epoch: 9.06 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35242604208962763		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.35242604208962763 | validation: 0.862249297629397]
	TIME [epoch: 9.07 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3704606450424585		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.3704606450424585 | validation: 0.641220258725952]
	TIME [epoch: 9.06 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37496166439887174		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.37496166439887174 | validation: 0.35840835508303415]
	TIME [epoch: 9.05 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3430670838431278		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.3430670838431278 | validation: 0.25766507454300336]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_308.pth
	Model improved!!!
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45138099508954105		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.45138099508954105 | validation: 0.2732134194044058]
	TIME [epoch: 9.09 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33982952014486356		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.33982952014486356 | validation: 0.4003350329892758]
	TIME [epoch: 9.07 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3792786064899827		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.3792786064899827 | validation: 0.5115115959739953]
	TIME [epoch: 9.06 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.405038164804184		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.405038164804184 | validation: 0.40745616749533664]
	TIME [epoch: 9.05 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3246494188932064		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.3246494188932064 | validation: 0.47512807031171195]
	TIME [epoch: 9.06 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3488409582569249		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.3488409582569249 | validation: 0.3480426492190799]
	TIME [epoch: 9.09 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3710274318814627		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.3710274318814627 | validation: 0.4024113058530131]
	TIME [epoch: 9.06 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36382958929909226		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.36382958929909226 | validation: 0.25125980392231306]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_316.pth
	Model improved!!!
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3214657840897619		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.3214657840897619 | validation: 0.3836592084297503]
	TIME [epoch: 9.06 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37338905147689394		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.37338905147689394 | validation: 0.36387251714308966]
	TIME [epoch: 9.08 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32313503494487666		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.32313503494487666 | validation: 0.3745103517266146]
	TIME [epoch: 9.06 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36584784115389973		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.36584784115389973 | validation: 0.3617921481536285]
	TIME [epoch: 9.06 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5930895269702137		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.5930895269702137 | validation: 0.7034046821289727]
	TIME [epoch: 9.06 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40004218262066304		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.40004218262066304 | validation: 0.32574525704515467]
	TIME [epoch: 9.07 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.336624810989154		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.336624810989154 | validation: 0.49328429285420194]
	TIME [epoch: 9.08 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3600676720340844		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.3600676720340844 | validation: 0.40467929006371717]
	TIME [epoch: 9.07 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3668031905800161		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.3668031905800161 | validation: 0.2913583962320875]
	TIME [epoch: 9.06 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4035323955281617		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.4035323955281617 | validation: 0.5191989040778568]
	TIME [epoch: 9.07 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34030015839273203		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.34030015839273203 | validation: 0.5079162337801677]
	TIME [epoch: 9.09 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41726150909658494		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.41726150909658494 | validation: 0.5297107304516913]
	TIME [epoch: 9.06 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40040446752205094		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.40040446752205094 | validation: 0.36585921266375065]
	TIME [epoch: 9.06 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36218801854951205		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.36218801854951205 | validation: 0.33305666093483965]
	TIME [epoch: 9.07 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36242392311012306		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.36242392311012306 | validation: 0.45911947849135726]
	TIME [epoch: 9.08 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3738901173323731		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.3738901173323731 | validation: 0.4783371528582667]
	TIME [epoch: 9.06 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29571450629382146		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.29571450629382146 | validation: 0.3429586475174463]
	TIME [epoch: 9.07 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3455907158180321		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.3455907158180321 | validation: 0.44639163685313715]
	TIME [epoch: 9.06 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3322147916166086		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.3322147916166086 | validation: 0.435734784051113]
	TIME [epoch: 9.08 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3702053175075477		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.3702053175075477 | validation: 0.3579308551921333]
	TIME [epoch: 9.07 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36727019235822866		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.36727019235822866 | validation: 0.3624350713737211]
	TIME [epoch: 9.06 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49140952718906555		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.49140952718906555 | validation: 0.3956144026684889]
	TIME [epoch: 9.06 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34853309439547586		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.34853309439547586 | validation: 0.2880668048728701]
	TIME [epoch: 9.09 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2988760544090881		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.2988760544090881 | validation: 0.3479418363193585]
	TIME [epoch: 9.07 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3644647858425981		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.3644647858425981 | validation: 0.27347464706772334]
	TIME [epoch: 9.07 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3388754523496473		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.3388754523496473 | validation: 0.4632426235217152]
	TIME [epoch: 9.07 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.413938327386875		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.413938327386875 | validation: 0.4704282107155894]
	TIME [epoch: 9.07 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30066248075422725		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.30066248075422725 | validation: 0.3101762657599547]
	TIME [epoch: 9.08 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2982949868322399		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.2982949868322399 | validation: 0.37588148450695646]
	TIME [epoch: 9.06 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3147446894890019		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.3147446894890019 | validation: 0.40514899444202357]
	TIME [epoch: 9.06 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2581880554295913		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.2581880554295913 | validation: 0.31351032278261715]
	TIME [epoch: 9.06 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.266713923236744		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.266713923236744 | validation: 0.36855338192707787]
	TIME [epoch: 9.08 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3284602098519622		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.3284602098519622 | validation: 0.19889993492200356]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_349.pth
	Model improved!!!
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22614763969758575		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.22614763969758575 | validation: 0.31114250893880274]
	TIME [epoch: 9.07 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31777526287758723		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.31777526287758723 | validation: 0.35972831861278043]
	TIME [epoch: 9.06 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32966115961160436		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.32966115961160436 | validation: 0.35241261713867006]
	TIME [epoch: 9.09 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27138698466458777		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.27138698466458777 | validation: 0.24262191812918155]
	TIME [epoch: 9.06 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30074174889317545		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.30074174889317545 | validation: 0.46890177961177837]
	TIME [epoch: 9.06 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4104439750454537		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.4104439750454537 | validation: 0.7295991180006374]
	TIME [epoch: 9.06 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3801177507513899		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.3801177507513899 | validation: 0.23806990027395294]
	TIME [epoch: 9.07 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2789532891959142		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.2789532891959142 | validation: 0.23766640667661412]
	TIME [epoch: 9.08 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42339024823065863		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.42339024823065863 | validation: 0.4139699364920067]
	TIME [epoch: 9.06 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2651702848750195		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.2651702848750195 | validation: 0.3761842324938588]
	TIME [epoch: 9.07 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2501805285582183		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.2501805285582183 | validation: 0.2020341584434664]
	TIME [epoch: 9.07 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21959073541305804		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.21959073541305804 | validation: 0.30940094654960154]
	TIME [epoch: 9.07 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30898806384658983		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.30898806384658983 | validation: 0.2935340111651187]
	TIME [epoch: 9.07 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3610161710049721		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.3610161710049721 | validation: 0.23088253637375544]
	TIME [epoch: 9.06 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.277662870672903		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.277662870672903 | validation: 0.19486785999464173]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_364.pth
	Model improved!!!
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2327873715450012		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.2327873715450012 | validation: 0.5096760863706984]
	TIME [epoch: 9.09 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29160430776304713		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.29160430776304713 | validation: 0.28232313160558553]
	TIME [epoch: 9.07 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29924402277339757		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.29924402277339757 | validation: 0.28828093826932033]
	TIME [epoch: 9.07 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2544860527894127		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.2544860527894127 | validation: 0.255929733302405]
	TIME [epoch: 9.07 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22304937168342262		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.22304937168342262 | validation: 0.22483742121969938]
	TIME [epoch: 9.09 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26963604173059436		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.26963604173059436 | validation: 0.26433624000331035]
	TIME [epoch: 9.07 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21669130124086694		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.21669130124086694 | validation: 0.2175567858327601]
	TIME [epoch: 9.07 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24075399017036445		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.24075399017036445 | validation: 0.2591824039158289]
	TIME [epoch: 9.07 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2923659136339318		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.2923659136339318 | validation: 0.28440185598249756]
	TIME [epoch: 9.07 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26522657986768694		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.26522657986768694 | validation: 0.32771930558808193]
	TIME [epoch: 9.09 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26139041955151593		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.26139041955151593 | validation: 0.3004414485551079]
	TIME [epoch: 9.07 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30180945406192894		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.30180945406192894 | validation: 0.2719810364798646]
	TIME [epoch: 9.07 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29816154527456207		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.29816154527456207 | validation: 0.25933204638491053]
	TIME [epoch: 9.06 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35688719276324926		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.35688719276324926 | validation: 0.29341387793953116]
	TIME [epoch: 9.09 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29122889450694706		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.29122889450694706 | validation: 0.34004353496714007]
	TIME [epoch: 9.07 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41510210741515985		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.41510210741515985 | validation: 0.2567537388997928]
	TIME [epoch: 9.07 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23327705237768045		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.23327705237768045 | validation: 0.2826282237925977]
	TIME [epoch: 9.07 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43047211293334453		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.43047211293334453 | validation: 0.5983429763415072]
	TIME [epoch: 9.09 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35477281783716086		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.35477281783716086 | validation: 0.276436551778646]
	TIME [epoch: 9.07 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2623166997565063		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.2623166997565063 | validation: 0.4260661284755636]
	TIME [epoch: 9.07 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3044591643088069		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.3044591643088069 | validation: 0.2280090007285953]
	TIME [epoch: 9.07 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23097744992993513		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.23097744992993513 | validation: 0.40237644037914044]
	TIME [epoch: 9.07 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26262940320528794		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.26262940320528794 | validation: 0.26480431714996977]
	TIME [epoch: 9.08 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27217756723834646		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.27217756723834646 | validation: 0.2813019249580815]
	TIME [epoch: 9.07 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26625919446726215		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.26625919446726215 | validation: 0.20737894143533533]
	TIME [epoch: 9.07 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19364518772415687		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.19364518772415687 | validation: 0.2569094175728909]
	TIME [epoch: 9.08 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2601559250441712		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.2601559250441712 | validation: 0.23786141072059325]
	TIME [epoch: 9.08 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3032099270251938		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.3032099270251938 | validation: 0.25382295198045896]
	TIME [epoch: 9.07 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26640303300469		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.26640303300469 | validation: 0.5215200228618964]
	TIME [epoch: 9.07 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27370865197503585		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.27370865197503585 | validation: 0.4777239954950466]
	TIME [epoch: 9.07 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3530080170514168		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.3530080170514168 | validation: 0.34439808218787604]
	TIME [epoch: 9.09 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3465146121458429		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.3465146121458429 | validation: 0.2311307423443472]
	TIME [epoch: 9.07 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2337756666999465		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.2337756666999465 | validation: 0.3555684744633791]
	TIME [epoch: 9.07 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32446864529409675		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.32446864529409675 | validation: 0.34619204940424575]
	TIME [epoch: 9.07 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2746642372539344		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.2746642372539344 | validation: 0.3089527661198952]
	TIME [epoch: 9.09 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22912663788848292		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.22912663788848292 | validation: 0.3223998017735553]
	TIME [epoch: 9.07 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.253907843879527		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.253907843879527 | validation: 0.24118556860243368]
	TIME [epoch: 9.06 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26912961256800094		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.26912961256800094 | validation: 0.28220809894906834]
	TIME [epoch: 9.07 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22801058158063953		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.22801058158063953 | validation: 0.2538108331035402]
	TIME [epoch: 9.09 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25905554187306623		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.25905554187306623 | validation: 0.5790464993089801]
	TIME [epoch: 9.07 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39059624705832413		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.39059624705832413 | validation: 0.22943652171337808]
	TIME [epoch: 9.07 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27534178564742867		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.27534178564742867 | validation: 0.30345959269695794]
	TIME [epoch: 9.07 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2687333087354403		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.2687333087354403 | validation: 0.2579113690766309]
	TIME [epoch: 9.09 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26593181739154403		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.26593181739154403 | validation: 0.2299261868674526]
	TIME [epoch: 9.07 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2824891450213197		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.2824891450213197 | validation: 0.21555098231919154]
	TIME [epoch: 9.07 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23511893707919923		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.23511893707919923 | validation: 0.30518293797689716]
	TIME [epoch: 9.07 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24192034244811872		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.24192034244811872 | validation: 0.22206724373222375]
	TIME [epoch: 9.08 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23739803128230777		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.23739803128230777 | validation: 0.22736589597399315]
	TIME [epoch: 9.08 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22533204978879393		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.22533204978879393 | validation: 0.3066013642557872]
	TIME [epoch: 9.07 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25422444571266023		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.25422444571266023 | validation: 0.27205892839885715]
	TIME [epoch: 9.07 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3185694847043599		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.3185694847043599 | validation: 0.41978563184896484]
	TIME [epoch: 9.09 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3197568320538823		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.3197568320538823 | validation: 0.2706918391845242]
	TIME [epoch: 9.09 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19732343078177497		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.19732343078177497 | validation: 0.32923054422674825]
	TIME [epoch: 9.07 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26079576619951117		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.26079576619951117 | validation: 0.303523467749789]
	TIME [epoch: 9.07 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2569293059134816		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.2569293059134816 | validation: 0.3573266033853184]
	TIME [epoch: 9.07 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2891921097142454		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.2891921097142454 | validation: 0.2842136236640536]
	TIME [epoch: 9.09 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28747191106994224		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.28747191106994224 | validation: 0.22587892843770835]
	TIME [epoch: 9.07 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2055906698247219		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.2055906698247219 | validation: 0.3197278436536394]
	TIME [epoch: 9.07 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24391284358232662		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.24391284358232662 | validation: 0.16182384329538838]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_423.pth
	Model improved!!!
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22014527984148308		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.22014527984148308 | validation: 0.19148451427401553]
	TIME [epoch: 9.09 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2754783417747743		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.2754783417747743 | validation: 0.31825331062851847]
	TIME [epoch: 9.07 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.261193608225982		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.261193608225982 | validation: 0.271037770336487]
	TIME [epoch: 9.07 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26813379460504433		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.26813379460504433 | validation: 0.2052675761462986]
	TIME [epoch: 9.07 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24750576299631857		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.24750576299631857 | validation: 0.23762822935322225]
	TIME [epoch: 9.08 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2345620196929416		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.2345620196929416 | validation: 0.3673579303877515]
	TIME [epoch: 9.09 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2578185662639707		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.2578185662639707 | validation: 0.23285140565456622]
	TIME [epoch: 9.07 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24072229703553588		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.24072229703553588 | validation: 0.24331232709143036]
	TIME [epoch: 9.07 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2321849480856327		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.2321849480856327 | validation: 0.2716656687346003]
	TIME [epoch: 9.07 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20257333774494288		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.20257333774494288 | validation: 0.20100291476216683]
	TIME [epoch: 9.09 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19620183141006411		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.19620183141006411 | validation: 0.19929115610781123]
	TIME [epoch: 9.07 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1931532366235811		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.1931532366235811 | validation: 0.22517886246845195]
	TIME [epoch: 9.07 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20213941347095754		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.20213941347095754 | validation: 0.2766119510579006]
	TIME [epoch: 9.07 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22173675773059948		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.22173675773059948 | validation: 0.3864306663936639]
	TIME [epoch: 9.09 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2843157386533509		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.2843157386533509 | validation: 0.29286816507913516]
	TIME [epoch: 9.07 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25185917693341764		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.25185917693341764 | validation: 0.3384786113304965]
	TIME [epoch: 9.07 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2754688377792194		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.2754688377792194 | validation: 0.22133679821892166]
	TIME [epoch: 9.07 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2730442310812669		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.2730442310812669 | validation: 0.1926156331118002]
	TIME [epoch: 9.08 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2356954442676506		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.2356954442676506 | validation: 0.26105783775369396]
	TIME [epoch: 9.08 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24407545743688708		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.24407545743688708 | validation: 0.23728566145849117]
	TIME [epoch: 9.07 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22040628750651461		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.22040628750651461 | validation: 0.25563121055280896]
	TIME [epoch: 9.07 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2271903792093765		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.2271903792093765 | validation: 0.22442539014236992]
	TIME [epoch: 9.08 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21470749780129655		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.21470749780129655 | validation: 0.25981853329843907]
	TIME [epoch: 9.08 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1862145363202819		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.1862145363202819 | validation: 0.17760421331575876]
	TIME [epoch: 9.07 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19203735284386877		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.19203735284386877 | validation: 0.256792074198103]
	TIME [epoch: 9.07 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23840359481247447		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.23840359481247447 | validation: 0.308139730845735]
	TIME [epoch: 9.07 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24037546674593852		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.24037546674593852 | validation: 0.16091680932250016]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_450.pth
	Model improved!!!
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20595796796155613		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.20595796796155613 | validation: 0.23231104228271499]
	TIME [epoch: 9.07 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26256882904446976		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.26256882904446976 | validation: 0.18797525382687155]
	TIME [epoch: 9.07 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2028893388789037		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.2028893388789037 | validation: 0.32338881149285137]
	TIME [epoch: 9.07 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22673237580985034		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.22673237580985034 | validation: 0.30643828918868327]
	TIME [epoch: 9.09 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1965652422271748		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.1965652422271748 | validation: 0.29587091612275274]
	TIME [epoch: 9.07 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21350519628067857		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.21350519628067857 | validation: 0.2126035218058671]
	TIME [epoch: 9.07 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23906857820210448		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.23906857820210448 | validation: 0.3427198010218966]
	TIME [epoch: 9.07 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2511958028374276		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.2511958028374276 | validation: 0.21400417473025915]
	TIME [epoch: 9.08 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21922952215535635		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.21922952215535635 | validation: 0.19619270289099577]
	TIME [epoch: 9.08 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2399622612430722		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.2399622612430722 | validation: 0.17284733183611745]
	TIME [epoch: 9.07 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20929864050093466		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.20929864050093466 | validation: 0.20270340759625413]
	TIME [epoch: 9.07 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17060723126467275		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.17060723126467275 | validation: 0.2392869283787169]
	TIME [epoch: 9.08 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2218920250418852		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.2218920250418852 | validation: 0.1807621621865716]
	TIME [epoch: 9.08 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20664470704289445		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.20664470704289445 | validation: 0.30929018559040145]
	TIME [epoch: 9.06 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20610743423558125		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.20610743423558125 | validation: 0.21250860781514636]
	TIME [epoch: 9.06 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18937610406390817		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.18937610406390817 | validation: 0.2025111602746785]
	TIME [epoch: 9.06 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18541993899207426		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.18541993899207426 | validation: 0.14267190749216507]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_467.pth
	Model improved!!!
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23473727316091103		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.23473727316091103 | validation: 0.17105366376083114]
	TIME [epoch: 9.08 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1636045974573584		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.1636045974573584 | validation: 0.15373677965766142]
	TIME [epoch: 9.08 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20267565827256195		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.20267565827256195 | validation: 0.18362565226527267]
	TIME [epoch: 9.07 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17266363522517952		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.17266363522517952 | validation: 0.1759025212851989]
	TIME [epoch: 9.07 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.189872269702357		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.189872269702357 | validation: 0.37905367942094087]
	TIME [epoch: 9.1 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22130017974030572		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.22130017974030572 | validation: 0.1674292518425562]
	TIME [epoch: 9.07 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21551086690850121		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.21551086690850121 | validation: 0.15998726281209674]
	TIME [epoch: 9.07 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1449293775868339		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.1449293775868339 | validation: 0.1242296216815798]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_475.pth
	Model improved!!!
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20609570635845392		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.20609570635845392 | validation: 0.20454198524865838]
	TIME [epoch: 9.08 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22346438400579344		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.22346438400579344 | validation: 0.17017244654840458]
	TIME [epoch: 9.06 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19426044573979925		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.19426044573979925 | validation: 0.2201470038714589]
	TIME [epoch: 9.05 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1903699895955951		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.1903699895955951 | validation: 0.2781577625570354]
	TIME [epoch: 9.06 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1855977372051447		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.1855977372051447 | validation: 0.22561594393248033]
	TIME [epoch: 9.06 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16686794541373406		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.16686794541373406 | validation: 0.1685276280651345]
	TIME [epoch: 9.09 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16473068730312074		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.16473068730312074 | validation: 0.16000988897898127]
	TIME [epoch: 9.06 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15043903924618673		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.15043903924618673 | validation: 0.18555463217362125]
	TIME [epoch: 9.06 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17679230871990423		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.17679230871990423 | validation: 0.23325950984102597]
	TIME [epoch: 9.06 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1728403375316346		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.1728403375316346 | validation: 0.1961464051423165]
	TIME [epoch: 9.08 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17655181577063103		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.17655181577063103 | validation: 0.21047166619290847]
	TIME [epoch: 9.06 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25704617448577954		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.25704617448577954 | validation: 0.17690034197238996]
	TIME [epoch: 9.06 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20736489639872152		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.20736489639872152 | validation: 0.1358216751649258]
	TIME [epoch: 9.06 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14644930688204272		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.14644930688204272 | validation: 0.1291585862122721]
	TIME [epoch: 9.08 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19596394482963736		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.19596394482963736 | validation: 0.2276785954009408]
	TIME [epoch: 9.06 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16842719724065408		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.16842719724065408 | validation: 0.12209344940735672]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240214_223210/states/model_tr_study3_491.pth
	Model improved!!!
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14146516544028076		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.14146516544028076 | validation: 0.22185012068245902]
	TIME [epoch: 9.06 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2445458037331787		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.2445458037331787 | validation: 0.21315276360710683]
	TIME [epoch: 9.07 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18405459708394942		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.18405459708394942 | validation: 0.2073985646996408]
	TIME [epoch: 9.08 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19080087053534825		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.19080087053534825 | validation: 0.16573613172451673]
	TIME [epoch: 9.06 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1502660336338644		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.1502660336338644 | validation: 0.15988612680864223]
	TIME [epoch: 9.07 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18226985439166807		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.18226985439166807 | validation: 0.1913892677751557]
	TIME [epoch: 9.07 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19744504495259935		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.19744504495259935 | validation: 0.21472685878040404]
	TIME [epoch: 9.09 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19609907656238176		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.19609907656238176 | validation: 0.28687704368947625]
	TIME [epoch: 9.07 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21452010848608244		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.21452010848608244 | validation: 0.30868436961518475]
	TIME [epoch: 9.07 sec]
Finished training in 4602.738 seconds.
