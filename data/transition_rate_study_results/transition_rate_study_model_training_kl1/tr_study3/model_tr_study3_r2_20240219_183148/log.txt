Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r2', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2274742498

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.376194809229847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.376194809229847 | validation: 10.983609752357447]
	TIME [epoch: 53.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.725375080132471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.725375080132471 | validation: 10.599395962520159]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.023197025905857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.023197025905857 | validation: 9.823513247582884]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.408427596646487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.408427596646487 | validation: 10.16868182904574]
	TIME [epoch: 8.55 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.998721332218324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.998721332218324 | validation: 7.18720358050882]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.20781191410466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.20781191410466 | validation: 6.691984833422179]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.247052747902677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.247052747902677 | validation: 6.944376083817072]
	TIME [epoch: 8.56 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.851181778559026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.851181778559026 | validation: 6.705089560325545]
	TIME [epoch: 8.55 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.746311444837983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.746311444837983 | validation: 6.80499182423787]
	TIME [epoch: 8.56 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.248398371455989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.248398371455989 | validation: 6.679626345680255]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.6034914943347145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6034914943347145 | validation: 6.753859392344413]
	TIME [epoch: 8.56 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.968473972836949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.968473972836949 | validation: 7.226437747520265]
	TIME [epoch: 8.55 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.8275454592417475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8275454592417475 | validation: 6.865303874678153]
	TIME [epoch: 8.55 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.65162656320189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.65162656320189 | validation: 6.668319160211728]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.49879544037662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.49879544037662 | validation: 6.571795015474261]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.2602233737970145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2602233737970145 | validation: 6.1250378959208565]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.0045400394245645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0045400394245645 | validation: 6.050695808024088]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.030117073821822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.030117073821822 | validation: 6.514547407412722]
	TIME [epoch: 8.57 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.979744500727708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.979744500727708 | validation: 5.860554283192399]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.896078026831936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.896078026831936 | validation: 6.042733423214166]
	TIME [epoch: 8.55 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.85765049028564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.85765049028564 | validation: 5.948231660275018]
	TIME [epoch: 8.55 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.890644578661629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.890644578661629 | validation: 5.9689442020382]
	TIME [epoch: 8.56 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.897680731935719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.897680731935719 | validation: 5.753548065936712]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.907171406884693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.907171406884693 | validation: 5.788323210786622]
	TIME [epoch: 8.56 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.907854944021457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.907854944021457 | validation: 5.715771459457697]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.663034795791258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.663034795791258 | validation: 5.533887862390229]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.73086173933022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.73086173933022 | validation: 5.889281984595126]
	TIME [epoch: 8.55 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.75894813709232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.75894813709232 | validation: 6.4513847800418604]
	TIME [epoch: 8.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.701383141431501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.701383141431501 | validation: 5.5541193109380735]
	TIME [epoch: 8.54 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.428825387413646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.428825387413646 | validation: 5.026648762112293]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.4425144071232525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4425144071232525 | validation: 9.831025263916594]
	TIME [epoch: 8.56 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.599485105179172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.599485105179172 | validation: 6.082568204166241]
	TIME [epoch: 8.55 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.548734089269145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.548734089269145 | validation: 5.6634416151878035]
	TIME [epoch: 8.55 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.439978398243834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.439978398243834 | validation: 5.244270293459746]
	TIME [epoch: 8.56 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.305359596148074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.305359596148074 | validation: 6.106833966001391]
	TIME [epoch: 8.55 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.471793816287451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.471793816287451 | validation: 5.2341766688311155]
	TIME [epoch: 8.54 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.170665975495763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.170665975495763 | validation: 5.4416258108296125]
	TIME [epoch: 8.53 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.967037861020489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.967037861020489 | validation: 4.909684131595322]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0313390119011006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0313390119011006 | validation: 4.822621918177208]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.718568866306791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.718568866306791 | validation: 4.042523231066391]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.358035897642379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.358035897642379 | validation: 4.266172277949454]
	TIME [epoch: 8.57 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1873427360349424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1873427360349424 | validation: 3.875344809406721]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.97513583955879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.97513583955879 | validation: 3.700725988204269]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7154282264575853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7154282264575853 | validation: 3.324209712338647]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.971478131441188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.971478131441188 | validation: 4.25288063672289]
	TIME [epoch: 8.55 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.469112323897056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.469112323897056 | validation: 3.853017280513705]
	TIME [epoch: 8.56 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.751978612566309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.751978612566309 | validation: 3.227379136629924]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3780104676330667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3780104676330667 | validation: 2.9661260300157455]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.059874699271381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.059874699271381 | validation: 3.2115828057833085]
	TIME [epoch: 8.55 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.161263608090535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.161263608090535 | validation: 3.4627282612181083]
	TIME [epoch: 8.57 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.79590783270348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.79590783270348 | validation: 2.646231447831987]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.595207123397691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.595207123397691 | validation: 2.1954792189656196]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6279713501779467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6279713501779467 | validation: 2.2238595006433504]
	TIME [epoch: 8.54 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5415268016373425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5415268016373425 | validation: 2.43575688797202]
	TIME [epoch: 8.57 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4313843373773034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4313843373773034 | validation: 1.9390640889269803]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6996313913654033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6996313913654033 | validation: 2.4560998364116036]
	TIME [epoch: 8.55 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4070957247614975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4070957247614975 | validation: 3.3291573721802052]
	TIME [epoch: 8.55 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.37025308696119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.37025308696119 | validation: 1.8140414253248545]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.026263031209667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.026263031209667 | validation: 2.2329296146537323]
	TIME [epoch: 8.56 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.171570149093932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.171570149093932 | validation: 2.5272835459905267]
	TIME [epoch: 8.55 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1496805658780285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1496805658780285 | validation: 2.2014016296547174]
	TIME [epoch: 8.55 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0187094257242193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0187094257242193 | validation: 1.7882937829067274]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.071318836628404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.071318836628404 | validation: 1.9873245802962738]
	TIME [epoch: 8.55 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.96151525141374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.96151525141374 | validation: 1.5617776585025438]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.952332858888104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.952332858888104 | validation: 1.886452500884691]
	TIME [epoch: 8.56 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0397681706677533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0397681706677533 | validation: 2.0278416425738]
	TIME [epoch: 8.57 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7389383457272491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7389383457272491 | validation: 1.6153167457421247]
	TIME [epoch: 8.55 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8069373081833704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8069373081833704 | validation: 1.4879432295562824]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7050557573533311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7050557573533311 | validation: 3.084980409694916]
	TIME [epoch: 8.56 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9397284530163172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9397284530163172 | validation: 1.5389030975269433]
	TIME [epoch: 8.56 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6616725310092488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6616725310092488 | validation: 1.4912189960372446]
	TIME [epoch: 8.55 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8449259140409247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8449259140409247 | validation: 1.4599269381586204]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8528377077037876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8528377077037876 | validation: 1.792212751190958]
	TIME [epoch: 8.57 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.106245010150591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.106245010150591 | validation: 1.3401472950388784]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6911472427208776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6911472427208776 | validation: 1.290698149725865]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6449715305550037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6449715305550037 | validation: 1.1674414907229023]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5616595001774496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5616595001774496 | validation: 1.3422938943690652]
	TIME [epoch: 8.56 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5871841030572453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5871841030572453 | validation: 1.5412994467241232]
	TIME [epoch: 8.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8877214480504285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8877214480504285 | validation: 2.462937793637219]
	TIME [epoch: 8.53 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0605429554872527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0605429554872527 | validation: 2.8679424158822515]
	TIME [epoch: 8.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.703065430692033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.703065430692033 | validation: 1.9898846228462057]
	TIME [epoch: 8.55 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2558468802140283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2558468802140283 | validation: 1.3728896639084494]
	TIME [epoch: 8.54 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.773950111646661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.773950111646661 | validation: 2.7645798973157953]
	TIME [epoch: 8.53 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9714278559560126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9714278559560126 | validation: 1.8327506158121245]
	TIME [epoch: 8.53 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8004592291909283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8004592291909283 | validation: 1.0784848241580542]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7954938928055468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7954938928055468 | validation: 1.189147867253884]
	TIME [epoch: 8.56 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5522341790866787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5522341790866787 | validation: 1.12730379072798]
	TIME [epoch: 8.55 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.464693878872804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.464693878872804 | validation: 1.143752204821511]
	TIME [epoch: 8.56 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6038391621565928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6038391621565928 | validation: 1.2475447145811467]
	TIME [epoch: 8.57 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2245166709228164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2245166709228164 | validation: 1.2487530774878575]
	TIME [epoch: 8.55 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3777431189550284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3777431189550284 | validation: 1.09177040440224]
	TIME [epoch: 8.55 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8719168447262162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8719168447262162 | validation: 1.6853832637880282]
	TIME [epoch: 8.57 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9317811123907944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9317811123907944 | validation: 1.9706260168281218]
	TIME [epoch: 8.56 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6982633153180338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6982633153180338 | validation: 1.4711634993128022]
	TIME [epoch: 8.56 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9072333776344563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9072333776344563 | validation: 1.5320754971062158]
	TIME [epoch: 8.55 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5207762459842376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5207762459842376 | validation: 1.5913642226991045]
	TIME [epoch: 8.57 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3437623043168951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3437623043168951 | validation: 1.4735047903736285]
	TIME [epoch: 8.56 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.571176159230278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.571176159230278 | validation: 1.4556947452534155]
	TIME [epoch: 8.56 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5834688147156768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5834688147156768 | validation: 0.9656984671779945]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4193908599695289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4193908599695289 | validation: 1.4284130203403766]
	TIME [epoch: 8.57 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7926199500598794		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 1.7926199500598794 | validation: 1.3960843414886321]
	TIME [epoch: 8.56 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.468461846198831		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.468461846198831 | validation: 0.9995047212426049]
	TIME [epoch: 8.55 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4413860834030399		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 1.4413860834030399 | validation: 0.9266948565246704]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3867269602888794		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.3867269602888794 | validation: 0.9283340369210346]
	TIME [epoch: 8.57 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.570082317720944		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 1.570082317720944 | validation: 1.580405111860863]
	TIME [epoch: 8.55 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5953206376508235		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.5953206376508235 | validation: 1.9446244586405648]
	TIME [epoch: 8.54 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6016213704918916		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 1.6016213704918916 | validation: 1.1560968404943912]
	TIME [epoch: 8.54 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.443290174045808		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.443290174045808 | validation: 1.321684273302853]
	TIME [epoch: 8.56 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4923498244189068		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 1.4923498244189068 | validation: 1.1857477008649076]
	TIME [epoch: 8.54 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5985111379785995		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.5985111379785995 | validation: 1.5852069842420224]
	TIME [epoch: 8.54 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4146325374147355		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 1.4146325374147355 | validation: 1.3715818571080367]
	TIME [epoch: 8.54 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4566887313696046		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.4566887313696046 | validation: 1.0247974042057761]
	TIME [epoch: 8.56 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.50616512847402		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 1.50616512847402 | validation: 1.897428207527185]
	TIME [epoch: 8.55 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.577278358723486		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.577278358723486 | validation: 1.3247855505509674]
	TIME [epoch: 8.54 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4193388222717778		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 1.4193388222717778 | validation: 1.341801751066167]
	TIME [epoch: 8.54 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6025478232636245		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.6025478232636245 | validation: 1.0553213562325836]
	TIME [epoch: 8.56 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3885276951194532		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 1.3885276951194532 | validation: 1.0531218839154906]
	TIME [epoch: 8.54 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4677283370297687		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.4677283370297687 | validation: 0.8846009804585078]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1876079366782215		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 1.1876079366782215 | validation: 1.8473872473428368]
	TIME [epoch: 8.56 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2260040069318792		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.2260040069318792 | validation: 1.1230726754476459]
	TIME [epoch: 8.55 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2633758980314478		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 1.2633758980314478 | validation: 1.0747137451847055]
	TIME [epoch: 8.54 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1845106283031304		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.1845106283031304 | validation: 0.9624530735528256]
	TIME [epoch: 8.54 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.13900503820641		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 1.13900503820641 | validation: 1.1278601530091719]
	TIME [epoch: 8.56 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5156709603279026		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 1.5156709603279026 | validation: 1.304329464754629]
	TIME [epoch: 8.55 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.351889972859993		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 1.351889972859993 | validation: 1.0622596719254522]
	TIME [epoch: 8.54 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4044521352883366		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.4044521352883366 | validation: 1.4884398509695365]
	TIME [epoch: 8.54 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1955624088073784		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 1.1955624088073784 | validation: 0.9674249662064449]
	TIME [epoch: 8.56 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4275950626555793		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.4275950626555793 | validation: 1.6100215992220206]
	TIME [epoch: 8.54 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1707880469579057		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 1.1707880469579057 | validation: 1.309734594641573]
	TIME [epoch: 8.54 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1779454502563391		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.1779454502563391 | validation: 0.8935543292382742]
	TIME [epoch: 8.54 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2102942447937246		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 1.2102942447937246 | validation: 1.8930738837871108]
	TIME [epoch: 8.56 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5449390478477256		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 1.5449390478477256 | validation: 1.249601853787477]
	TIME [epoch: 8.54 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3414434804375883		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 1.3414434804375883 | validation: 1.5159383586974502]
	TIME [epoch: 8.54 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1506432135192688		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.1506432135192688 | validation: 1.5934507386581354]
	TIME [epoch: 8.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2217188119932783		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 1.2217188119932783 | validation: 1.6749853642998165]
	TIME [epoch: 8.56 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5260590353249028		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 1.5260590353249028 | validation: 0.9518364416641416]
	TIME [epoch: 8.54 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2835680238641307		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 1.2835680238641307 | validation: 1.2473335539924955]
	TIME [epoch: 8.54 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6297695836840174		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 1.6297695836840174 | validation: 1.0815093046436273]
	TIME [epoch: 8.54 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3108747626509372		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 1.3108747626509372 | validation: 1.395845119065646]
	TIME [epoch: 8.56 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4238106591470412		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 1.4238106591470412 | validation: 0.9924007764334399]
	TIME [epoch: 8.54 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2763787829436049		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 1.2763787829436049 | validation: 1.1831273262967943]
	TIME [epoch: 8.54 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.152118239692615		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 1.152118239692615 | validation: 1.1646183016124783]
	TIME [epoch: 8.54 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1873081571966346		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 1.1873081571966346 | validation: 1.5600702551872485]
	TIME [epoch: 8.56 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.205329472270288		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.205329472270288 | validation: 1.1986341744253886]
	TIME [epoch: 8.54 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2135611220930043		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 1.2135611220930043 | validation: 0.9976338650379581]
	TIME [epoch: 8.54 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.326966669631221		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 1.326966669631221 | validation: 1.4539739105984344]
	TIME [epoch: 8.54 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4378179400356397		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 1.4378179400356397 | validation: 1.0535735810743017]
	TIME [epoch: 8.55 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1637914641398228		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 1.1637914641398228 | validation: 1.0501750620319503]
	TIME [epoch: 8.54 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1541336194586256		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 1.1541336194586256 | validation: 0.716680752789141]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1569226537333273		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 1.1569226537333273 | validation: 1.3920184296485718]
	TIME [epoch: 8.56 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2751241292440523		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 1.2751241292440523 | validation: 1.0039746845870452]
	TIME [epoch: 8.54 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3264067193079467		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 1.3264067193079467 | validation: 1.2733454459341602]
	TIME [epoch: 8.54 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0211690317347852		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 1.0211690317347852 | validation: 1.3984925720763668]
	TIME [epoch: 8.54 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.037685644420862		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 1.037685644420862 | validation: 0.798548250085998]
	TIME [epoch: 8.56 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1026411438943386		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 1.1026411438943386 | validation: 0.9222660906582691]
	TIME [epoch: 8.54 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0620570907245974		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 1.0620570907245974 | validation: 1.868938084557251]
	TIME [epoch: 8.54 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1039778047310427		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 1.1039778047310427 | validation: 1.3837682547065993]
	TIME [epoch: 8.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0150831951725603		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 1.0150831951725603 | validation: 0.6197881743645164]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9150694589148983		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.9150694589148983 | validation: 0.7879371812053091]
	TIME [epoch: 8.54 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9530768689482507		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.9530768689482507 | validation: 0.6853919726077904]
	TIME [epoch: 8.54 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0451665439633693		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 1.0451665439633693 | validation: 0.6802505219523023]
	TIME [epoch: 8.54 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9618500312475561		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.9618500312475561 | validation: 0.6150160337571638]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0117889767910506		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 1.0117889767910506 | validation: 1.2754154661183001]
	TIME [epoch: 8.55 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1213618265085425		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 1.1213618265085425 | validation: 1.2202639875941106]
	TIME [epoch: 8.54 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9707246873204083		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.9707246873204083 | validation: 1.1450707614004358]
	TIME [epoch: 8.54 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.231386609344529		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.231386609344529 | validation: 1.6346237383003863]
	TIME [epoch: 8.56 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2179478218940951		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 1.2179478218940951 | validation: 0.665766471263441]
	TIME [epoch: 8.54 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0290309786629845		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 1.0290309786629845 | validation: 1.1104519060188003]
	TIME [epoch: 8.54 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0538752132345797		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 1.0538752132345797 | validation: 0.8425852015414279]
	TIME [epoch: 8.55 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.236110668745314		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 1.236110668745314 | validation: 1.9555308306463912]
	TIME [epoch: 8.56 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1832159489141654		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 1.1832159489141654 | validation: 1.0822908998229543]
	TIME [epoch: 8.54 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.131676087474771		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 1.131676087474771 | validation: 1.1079785320052613]
	TIME [epoch: 8.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9715410957758008		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.9715410957758008 | validation: 0.9869004896377778]
	TIME [epoch: 8.55 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0600843163650004		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 1.0600843163650004 | validation: 0.5681720428294027]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9349755629804986		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.9349755629804986 | validation: 0.6051932448519143]
	TIME [epoch: 8.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1374546207018457		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 1.1374546207018457 | validation: 0.7488659821240583]
	TIME [epoch: 8.54 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8272569624916561		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.8272569624916561 | validation: 0.6437802781279381]
	TIME [epoch: 8.56 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9771848023264551		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.9771848023264551 | validation: 0.7356372742933702]
	TIME [epoch: 8.55 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8997478566460897		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.8997478566460897 | validation: 0.8107431911081235]
	TIME [epoch: 8.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9164725628701422		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.9164725628701422 | validation: 1.0560233314169651]
	TIME [epoch: 8.53 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8997317901276111		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.8997317901276111 | validation: 1.530921537777252]
	TIME [epoch: 8.56 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.169486585121162		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 1.169486585121162 | validation: 0.9115795202665277]
	TIME [epoch: 8.54 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.129380229460873		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 1.129380229460873 | validation: 0.8330360520339313]
	TIME [epoch: 8.54 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8393524864333504		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.8393524864333504 | validation: 1.1596241784064056]
	TIME [epoch: 8.54 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8470621354508513		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.8470621354508513 | validation: 0.9938690023354697]
	TIME [epoch: 8.56 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8683791716157103		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.8683791716157103 | validation: 0.6779211988433633]
	TIME [epoch: 8.54 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7617650265055065		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.7617650265055065 | validation: 0.4522045240355612]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9950579879617354		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.9950579879617354 | validation: 0.8589176710181666]
	TIME [epoch: 8.54 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9358977226764503		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.9358977226764503 | validation: 1.0973153331390932]
	TIME [epoch: 8.56 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7895992260866465		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.7895992260866465 | validation: 0.9850688095433606]
	TIME [epoch: 8.55 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9844381051336757		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.9844381051336757 | validation: 0.7525540054048339]
	TIME [epoch: 8.54 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8480445175863975		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.8480445175863975 | validation: 1.013545312566017]
	TIME [epoch: 8.53 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.123666172550529		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 1.123666172550529 | validation: 0.48146139931899534]
	TIME [epoch: 8.56 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9202772617774533		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.9202772617774533 | validation: 0.9407241441889429]
	TIME [epoch: 8.54 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0752496631263337		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 1.0752496631263337 | validation: 1.4659309996677319]
	TIME [epoch: 8.54 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0806174987451214		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 1.0806174987451214 | validation: 0.893337455094432]
	TIME [epoch: 8.54 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8894084500133191		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.8894084500133191 | validation: 0.8817240321519374]
	TIME [epoch: 8.56 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.125268880218439		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 1.125268880218439 | validation: 0.9039843489750585]
	TIME [epoch: 8.54 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9462718670792498		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.9462718670792498 | validation: 0.8596526306243641]
	TIME [epoch: 8.54 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8673753696768056		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.8673753696768056 | validation: 0.4753995065549236]
	TIME [epoch: 8.54 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0439704904452884		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 1.0439704904452884 | validation: 0.8297209141726007]
	TIME [epoch: 8.56 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9136274767403654		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.9136274767403654 | validation: 0.9218501300416926]
	TIME [epoch: 8.54 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1827059189418496		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 1.1827059189418496 | validation: 0.6193315966761794]
	TIME [epoch: 8.54 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0451914324453813		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 1.0451914324453813 | validation: 1.3665269357903247]
	TIME [epoch: 8.56 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.904398732981669		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.904398732981669 | validation: 0.7342962824000319]
	TIME [epoch: 8.55 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8535159023921624		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.8535159023921624 | validation: 0.8031130415506282]
	TIME [epoch: 8.54 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7478795951586747		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.7478795951586747 | validation: 0.4105421294787559]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.928267826548506		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.928267826548506 | validation: 0.9294982288187139]
	TIME [epoch: 8.58 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9384221631857533		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.9384221631857533 | validation: 0.507244775235906]
	TIME [epoch: 8.55 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1499996977487417		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 1.1499996977487417 | validation: 1.083524198375367]
	TIME [epoch: 8.55 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9185514457757764		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.9185514457757764 | validation: 0.8504003752800559]
	TIME [epoch: 8.54 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1248914749544412		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 1.1248914749544412 | validation: 1.0289502492591966]
	TIME [epoch: 8.57 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8964290896307681		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.8964290896307681 | validation: 0.613904843587308]
	TIME [epoch: 8.55 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8100182529606492		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.8100182529606492 | validation: 0.5779758680869103]
	TIME [epoch: 8.55 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9252301217760557		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.9252301217760557 | validation: 0.687854414461555]
	TIME [epoch: 8.54 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7763621061689493		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.7763621061689493 | validation: 0.8447000399099037]
	TIME [epoch: 8.56 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8296670597445587		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.8296670597445587 | validation: 0.5725543442781404]
	TIME [epoch: 8.55 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8002435829999797		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.8002435829999797 | validation: 0.5215350850293671]
	TIME [epoch: 8.55 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9452541894681181		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.9452541894681181 | validation: 0.8161295520909662]
	TIME [epoch: 8.54 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8033055798706584		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.8033055798706584 | validation: 1.1101942008098018]
	TIME [epoch: 8.57 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8923667386415357		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.8923667386415357 | validation: 0.7221710407113946]
	TIME [epoch: 8.55 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6992280321808714		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.6992280321808714 | validation: 1.1222804352396079]
	TIME [epoch: 8.53 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.092750217285365		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 1.092750217285365 | validation: 0.8486035766184776]
	TIME [epoch: 8.53 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9180875869755336		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.9180875869755336 | validation: 0.9701706016787242]
	TIME [epoch: 8.55 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8948714717453834		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.8948714717453834 | validation: 1.5625783445568089]
	TIME [epoch: 8.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7933181410235983		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.7933181410235983 | validation: 0.5889651225998707]
	TIME [epoch: 8.53 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9208921338188562		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.9208921338188562 | validation: 1.0981379587644373]
	TIME [epoch: 8.53 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0024878720961934		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 1.0024878720961934 | validation: 1.150366570916302]
	TIME [epoch: 8.55 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9040394710951627		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.9040394710951627 | validation: 0.5831096769526087]
	TIME [epoch: 8.78 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7909082797521356		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.7909082797521356 | validation: 0.5057622904432222]
	TIME [epoch: 8.55 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8255860975453164		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.8255860975453164 | validation: 0.8167480482568408]
	TIME [epoch: 8.56 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.748856621232891		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.748856621232891 | validation: 0.3980261968634309]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7631054419505027		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.7631054419505027 | validation: 0.7969838393762435]
	TIME [epoch: 8.54 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8996110633787506		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.8996110633787506 | validation: 0.5615748729369888]
	TIME [epoch: 8.54 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7605264046720229		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.7605264046720229 | validation: 0.5911159879893169]
	TIME [epoch: 8.56 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8297179309500471		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.8297179309500471 | validation: 0.6145622058132065]
	TIME [epoch: 8.55 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6850078104778892		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.6850078104778892 | validation: 1.2015946504731554]
	TIME [epoch: 8.55 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7656494903041873		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.7656494903041873 | validation: 0.5454790203563409]
	TIME [epoch: 8.54 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1187150964604728		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 1.1187150964604728 | validation: 0.8695416704170011]
	TIME [epoch: 8.56 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7976557118243068		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.7976557118243068 | validation: 0.6658941717853444]
	TIME [epoch: 8.55 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7564282338993829		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.7564282338993829 | validation: 0.6839951549730569]
	TIME [epoch: 8.54 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7485862630103945		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.7485862630103945 | validation: 0.5716648829545062]
	TIME [epoch: 8.54 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8480875528291667		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.8480875528291667 | validation: 0.5997595012440577]
	TIME [epoch: 8.57 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7948540064141999		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.7948540064141999 | validation: 0.771497849043749]
	TIME [epoch: 8.55 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6964213567469885		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.6964213567469885 | validation: 1.1706786053732947]
	TIME [epoch: 8.54 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7511282756568495		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.7511282756568495 | validation: 0.5884324417780875]
	TIME [epoch: 8.54 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6086166515215132		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.6086166515215132 | validation: 1.3544593291621068]
	TIME [epoch: 8.56 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3354960915047152		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 1.3354960915047152 | validation: 1.3012641805951009]
	TIME [epoch: 8.54 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0059335679053112		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 1.0059335679053112 | validation: 0.5962241584933765]
	TIME [epoch: 8.54 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.587354321713462		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.587354321713462 | validation: 1.523509678616409]
	TIME [epoch: 8.53 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.280495291947172		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 1.280495291947172 | validation: 0.7864968382207216]
	TIME [epoch: 8.56 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7404081164194072		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.7404081164194072 | validation: 0.852902325951275]
	TIME [epoch: 8.55 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.759502352320123		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.759502352320123 | validation: 0.48159791268910257]
	TIME [epoch: 8.55 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.723585879306974		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.723585879306974 | validation: 0.9012122626435901]
	TIME [epoch: 8.55 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.774030388100668		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.774030388100668 | validation: 1.0570707087814497]
	TIME [epoch: 8.56 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7098040427725999		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.7098040427725999 | validation: 0.8987199559750172]
	TIME [epoch: 8.54 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7354174416716935		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.7354174416716935 | validation: 1.5140671905069722]
	TIME [epoch: 8.54 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9041844792427012		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.9041844792427012 | validation: 0.6311892188234466]
	TIME [epoch: 8.54 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.705630670067861		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.705630670067861 | validation: 1.087401290587684]
	TIME [epoch: 8.56 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7732536288866563		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.7732536288866563 | validation: 0.5917673592989603]
	TIME [epoch: 8.54 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4608092174033378		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 1.4608092174033378 | validation: 1.646845936236418]
	TIME [epoch: 8.54 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.790221423474658		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 1.790221423474658 | validation: 1.2260030981046497]
	TIME [epoch: 8.55 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5129454358571675		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 1.5129454358571675 | validation: 1.1252157792596607]
	TIME [epoch: 8.55 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8524785733209891		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.8524785733209891 | validation: 0.7251744557754527]
	TIME [epoch: 8.54 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670540927503879		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.8670540927503879 | validation: 1.0718392307204454]
	TIME [epoch: 8.54 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8341610120444706		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.8341610120444706 | validation: 0.7692524251668921]
	TIME [epoch: 8.55 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9769816311022094		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.9769816311022094 | validation: 0.6102351351275705]
	TIME [epoch: 8.54 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7538047611843164		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.7538047611843164 | validation: 0.6987903456632502]
	TIME [epoch: 8.54 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8246776191478169		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.8246776191478169 | validation: 0.6495995311755842]
	TIME [epoch: 8.53 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7086614617859875		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.7086614617859875 | validation: 0.5430604625845916]
	TIME [epoch: 8.55 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6480172510361906		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.6480172510361906 | validation: 0.4378555963125473]
	TIME [epoch: 8.54 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6444972113498129		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.6444972113498129 | validation: 0.6258099785928308]
	TIME [epoch: 8.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6485955942735412		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.6485955942735412 | validation: 0.8954603795758578]
	TIME [epoch: 8.54 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8037894204595663		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.8037894204595663 | validation: 2.015957654492221]
	TIME [epoch: 8.56 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9698527956367657		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.9698527956367657 | validation: 1.181173419492338]
	TIME [epoch: 8.54 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6776327499425776		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.6776327499425776 | validation: 1.1355805024277057]
	TIME [epoch: 8.54 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.667943532450451		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.667943532450451 | validation: 0.5312542367606459]
	TIME [epoch: 8.54 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7921752547650697		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.7921752547650697 | validation: 0.9201991592769696]
	TIME [epoch: 8.56 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7045002793922432		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.7045002793922432 | validation: 0.9886817980062643]
	TIME [epoch: 8.54 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6774559270120243		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.6774559270120243 | validation: 0.954431308131445]
	TIME [epoch: 8.54 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7518454847065003		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.7518454847065003 | validation: 0.7259557603313985]
	TIME [epoch: 8.54 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6327953445509154		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.6327953445509154 | validation: 0.5534228302644986]
	TIME [epoch: 8.56 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5652974333870942		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.5652974333870942 | validation: 0.4853986245795363]
	TIME [epoch: 8.54 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6613752239776438		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.6613752239776438 | validation: 1.217487537398414]
	TIME [epoch: 8.54 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6394071352788137		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.6394071352788137 | validation: 0.3321891473435129]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554980801137859		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.5554980801137859 | validation: 0.7011080274628738]
	TIME [epoch: 8.55 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6785251136873296		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.6785251136873296 | validation: 0.5437591082616849]
	TIME [epoch: 8.54 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.630999434478258		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.630999434478258 | validation: 1.0119823208414878]
	TIME [epoch: 8.53 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6947934276212898		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.6947934276212898 | validation: 0.3180124451764743]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5739146955349875		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.5739146955349875 | validation: 0.6745551477890812]
	TIME [epoch: 8.56 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6019717088333121		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.6019717088333121 | validation: 0.48017389811054334]
	TIME [epoch: 8.54 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.56025489687988		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.56025489687988 | validation: 0.3872466765183592]
	TIME [epoch: 8.54 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6861961958951205		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.6861961958951205 | validation: 0.5151167117206878]
	TIME [epoch: 8.55 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4401229697063448		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.4401229697063448 | validation: 0.4637117675589262]
	TIME [epoch: 8.55 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6822859094288922		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.6822859094288922 | validation: 0.5178592130219553]
	TIME [epoch: 8.54 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6035610558980966		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.6035610558980966 | validation: 0.4486082609591017]
	TIME [epoch: 8.54 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5382686432297078		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.5382686432297078 | validation: 1.5545422554626165]
	TIME [epoch: 8.56 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5617009141976481		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.5617009141976481 | validation: 0.3845675942557172]
	TIME [epoch: 8.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5406669237169008		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.5406669237169008 | validation: 0.3573124014783253]
	TIME [epoch: 8.54 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4673183991901867		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.4673183991901867 | validation: 0.2968846905313818]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5395333889491262		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.5395333889491262 | validation: 0.446327799292744]
	TIME [epoch: 8.56 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5430892264117047		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.5430892264117047 | validation: 0.3876902704527241]
	TIME [epoch: 8.54 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5732526263412252		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.5732526263412252 | validation: 0.8892927806257311]
	TIME [epoch: 8.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7552172986276996		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.7552172986276996 | validation: 0.5765581894167171]
	TIME [epoch: 8.54 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5661920688579676		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.5661920688579676 | validation: 0.36067495042953707]
	TIME [epoch: 8.56 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5153297302491876		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.5153297302491876 | validation: 0.7811803901726095]
	TIME [epoch: 8.54 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6285072658244227		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.6285072658244227 | validation: 0.5842754687956939]
	TIME [epoch: 8.54 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5016219154246191		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.5016219154246191 | validation: 0.3042505682262687]
	TIME [epoch: 8.54 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4961417523432462		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.4961417523432462 | validation: 0.45764567254952315]
	TIME [epoch: 8.55 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5678023130597453		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.5678023130597453 | validation: 0.8201402204998108]
	TIME [epoch: 8.54 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.73676137976428		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.73676137976428 | validation: 0.6361462148638715]
	TIME [epoch: 8.53 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6495876848976181		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.6495876848976181 | validation: 0.7623214444272729]
	TIME [epoch: 8.54 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5735079243538834		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.5735079243538834 | validation: 0.7779886024107089]
	TIME [epoch: 8.55 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.574331117924493		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.574331117924493 | validation: 0.5298349899772195]
	TIME [epoch: 8.54 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5075309775864932		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.5075309775864932 | validation: 0.4014087287457623]
	TIME [epoch: 8.54 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5167479127542115		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.5167479127542115 | validation: 0.4438424957265401]
	TIME [epoch: 8.54 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7359399398509527		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.7359399398509527 | validation: 0.5930944979467013]
	TIME [epoch: 8.56 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5857561407668241		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.5857561407668241 | validation: 0.5977213186957175]
	TIME [epoch: 8.54 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5826079454576217		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.5826079454576217 | validation: 0.3775980196223825]
	TIME [epoch: 8.53 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6022920604111508		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.6022920604111508 | validation: 0.4673281513387224]
	TIME [epoch: 8.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48697529989724603		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.48697529989724603 | validation: 0.5312452188064724]
	TIME [epoch: 8.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.58628852413345		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.58628852413345 | validation: 0.6821730728171382]
	TIME [epoch: 8.54 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6670985982004086		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.6670985982004086 | validation: 0.4857626465228113]
	TIME [epoch: 8.53 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7973235843937857		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.7973235843937857 | validation: 0.43515577663732335]
	TIME [epoch: 8.56 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6136467786561365		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.6136467786561365 | validation: 0.34393566964897104]
	TIME [epoch: 8.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5566912009760208		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.5566912009760208 | validation: 0.47755549716716816]
	TIME [epoch: 8.53 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5565044795903102		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.5565044795903102 | validation: 0.5263633460752444]
	TIME [epoch: 8.53 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5317398992105031		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.5317398992105031 | validation: 1.5693848012520357]
	TIME [epoch: 8.56 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6933501289194006		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.6933501289194006 | validation: 0.579206904590574]
	TIME [epoch: 8.54 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6138453442606803		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.6138453442606803 | validation: 0.7039729828577322]
	TIME [epoch: 8.53 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5211265909670572		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.5211265909670572 | validation: 0.42223877984413877]
	TIME [epoch: 8.53 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5540974858823164		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.5540974858823164 | validation: 0.577578263315647]
	TIME [epoch: 8.54 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7522434036309155		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.7522434036309155 | validation: 0.4589104525933789]
	TIME [epoch: 8.53 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5977421320530236		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.5977421320530236 | validation: 0.6369108706250333]
	TIME [epoch: 8.53 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48294759787246794		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.48294759787246794 | validation: 0.4042036546003882]
	TIME [epoch: 8.53 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5590290600369727		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.5590290600369727 | validation: 0.5072334566797359]
	TIME [epoch: 8.55 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5522381496774054		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.5522381496774054 | validation: 0.5567143070431094]
	TIME [epoch: 8.54 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597551114025422		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.6597551114025422 | validation: 0.8832196353661717]
	TIME [epoch: 8.53 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5196644021946188		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.5196644021946188 | validation: 0.5409550068241197]
	TIME [epoch: 8.53 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4758494043066044		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.4758494043066044 | validation: 0.31659611714480096]
	TIME [epoch: 8.55 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4767979733785873		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.4767979733785873 | validation: 0.4565264360012214]
	TIME [epoch: 8.53 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48342131059410287		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.48342131059410287 | validation: 0.39691363675264013]
	TIME [epoch: 8.53 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5058621240963304		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.5058621240963304 | validation: 0.3086642134552289]
	TIME [epoch: 8.53 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5157972691124741		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.5157972691124741 | validation: 0.3569014496067634]
	TIME [epoch: 8.55 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4443923130720754		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.4443923130720754 | validation: 0.42265280834849295]
	TIME [epoch: 8.53 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5517865784123759		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.5517865784123759 | validation: 0.2891046653106635]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40858587531374857		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.40858587531374857 | validation: 0.4722024780839562]
	TIME [epoch: 8.54 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4267221356006143		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.4267221356006143 | validation: 0.4090868960364561]
	TIME [epoch: 8.55 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5337107614094344		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.5337107614094344 | validation: 0.30477483963833785]
	TIME [epoch: 8.53 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4420713544769507		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.4420713544769507 | validation: 0.3132303532923607]
	TIME [epoch: 8.53 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.507140599283084		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.507140599283084 | validation: 0.4085121704474915]
	TIME [epoch: 8.54 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.473498315554747		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.473498315554747 | validation: 0.6052684691965495]
	TIME [epoch: 8.55 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6075744532223135		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.6075744532223135 | validation: 0.6736342127647453]
	TIME [epoch: 8.55 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6673564658828488		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.6673564658828488 | validation: 0.3481235966101727]
	TIME [epoch: 8.55 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5350533232835544		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.5350533232835544 | validation: 0.7729144276518526]
	TIME [epoch: 8.57 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5241252814721644		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.5241252814721644 | validation: 0.35286701085261063]
	TIME [epoch: 8.56 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.465923766037241		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.465923766037241 | validation: 0.5803071188604623]
	TIME [epoch: 8.54 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6065734116558549		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.6065734116558549 | validation: 0.3662535464142962]
	TIME [epoch: 8.55 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7385156507570272		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.7385156507570272 | validation: 0.4460884781977792]
	TIME [epoch: 8.57 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39819724315967286		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.39819724315967286 | validation: 0.2317662158250522]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4227218226935137		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.4227218226935137 | validation: 0.27355580712782746]
	TIME [epoch: 8.56 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6964107723675725		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.6964107723675725 | validation: 1.1078291132106213]
	TIME [epoch: 8.55 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5551411328072143		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.5551411328072143 | validation: 0.4453276462003949]
	TIME [epoch: 8.56 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4701447116937957		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.4701447116937957 | validation: 0.29685908081179624]
	TIME [epoch: 8.56 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4484207242181988		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.4484207242181988 | validation: 0.3897202563115907]
	TIME [epoch: 8.52 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5316174706875556		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.5316174706875556 | validation: 0.41062071984419335]
	TIME [epoch: 8.55 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42360688712061656		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.42360688712061656 | validation: 0.5420004837082188]
	TIME [epoch: 8.58 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5051983059517464		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.5051983059517464 | validation: 0.4519168328577826]
	TIME [epoch: 8.56 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4286201951298948		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.4286201951298948 | validation: 0.5235282735083733]
	TIME [epoch: 8.55 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5060136280210825		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.5060136280210825 | validation: 0.5002296211580296]
	TIME [epoch: 8.55 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5000083255171285		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.5000083255171285 | validation: 0.7459415598532508]
	TIME [epoch: 8.56 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5209408145168594		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.5209408145168594 | validation: 0.30629454494268027]
	TIME [epoch: 8.55 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.569446989892267		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.569446989892267 | validation: 0.22202568340890938]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4225598161483141		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.4225598161483141 | validation: 0.46997851259277745]
	TIME [epoch: 8.56 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4900409987458317		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.4900409987458317 | validation: 0.6756935921796028]
	TIME [epoch: 8.57 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49848751111759454		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.49848751111759454 | validation: 0.3959021178973863]
	TIME [epoch: 8.55 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3900202899268022		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.3900202899268022 | validation: 0.35740615162470635]
	TIME [epoch: 8.55 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40785999798748007		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.40785999798748007 | validation: 0.24471853422835554]
	TIME [epoch: 8.56 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4921938494672425		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.4921938494672425 | validation: 0.3307811582254206]
	TIME [epoch: 8.56 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5141309914650021		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.5141309914650021 | validation: 0.33060528287073054]
	TIME [epoch: 8.55 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5160251144646495		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.5160251144646495 | validation: 0.5945925965951839]
	TIME [epoch: 8.55 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44809093545590545		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.44809093545590545 | validation: 0.4306602136580079]
	TIME [epoch: 8.56 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.585225706462124		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.585225706462124 | validation: 0.18647336815945598]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4052958353187699		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.4052958353187699 | validation: 0.2431126535051013]
	TIME [epoch: 8.55 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38294708592159155		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.38294708592159155 | validation: 0.2530736544072358]
	TIME [epoch: 8.55 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3864942356008493		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.3864942356008493 | validation: 0.331434809638681]
	TIME [epoch: 8.57 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7151539658535586		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.7151539658535586 | validation: 0.4244177505673209]
	TIME [epoch: 8.55 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48559663509832		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.48559663509832 | validation: 0.5671334775595616]
	TIME [epoch: 8.55 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41959313603753207		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.41959313603753207 | validation: 0.34234704423679485]
	TIME [epoch: 8.54 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.365240298858161		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.365240298858161 | validation: 0.4889356204368828]
	TIME [epoch: 8.56 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44852525837482365		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.44852525837482365 | validation: 0.25268339418399677]
	TIME [epoch: 8.54 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44018432656138645		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.44018432656138645 | validation: 0.211059517951652]
	TIME [epoch: 8.55 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.507960241611443		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.507960241611443 | validation: 0.3714721718414493]
	TIME [epoch: 8.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6405468477967754		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.6405468477967754 | validation: 0.4056489292556651]
	TIME [epoch: 8.57 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3933050714556354		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.3933050714556354 | validation: 0.5076306676783882]
	TIME [epoch: 8.55 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5512166260372131		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.5512166260372131 | validation: 0.2754223926585284]
	TIME [epoch: 8.54 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4531018816367177		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.4531018816367177 | validation: 0.4996232737868055]
	TIME [epoch: 8.54 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40674331536423364		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.40674331536423364 | validation: 0.3796265401435942]
	TIME [epoch: 8.56 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3480492258354266		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.3480492258354266 | validation: 0.42277609844036645]
	TIME [epoch: 8.55 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42165781302266037		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.42165781302266037 | validation: 0.36582217336183276]
	TIME [epoch: 8.55 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40669191752892553		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.40669191752892553 | validation: 0.634625709490193]
	TIME [epoch: 8.55 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4437726807538935		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.4437726807538935 | validation: 0.5708248408715451]
	TIME [epoch: 8.56 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41641911513083174		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.41641911513083174 | validation: 0.30256639161983867]
	TIME [epoch: 8.55 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3746227020584157		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.3746227020584157 | validation: 0.4151759846087272]
	TIME [epoch: 8.53 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4575450409537075		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.4575450409537075 | validation: 0.47740691055479]
	TIME [epoch: 8.54 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5248216779344672		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.5248216779344672 | validation: 0.23512797961489984]
	TIME [epoch: 8.56 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4089393303000695		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.4089393303000695 | validation: 0.39554496876924045]
	TIME [epoch: 8.54 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35623393749912236		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.35623393749912236 | validation: 0.2100206529843157]
	TIME [epoch: 8.54 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44832820587137256		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.44832820587137256 | validation: 0.32694615483925815]
	TIME [epoch: 8.56 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4607574055069025		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.4607574055069025 | validation: 0.8209225624699357]
	TIME [epoch: 8.55 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48679499413991384		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.48679499413991384 | validation: 0.5156117969493056]
	TIME [epoch: 8.53 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42873032230065017		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.42873032230065017 | validation: 0.38552439731197397]
	TIME [epoch: 8.54 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29843290618268875		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.29843290618268875 | validation: 0.3006065699470095]
	TIME [epoch: 8.56 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3880731195282662		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.3880731195282662 | validation: 0.5086382054496407]
	TIME [epoch: 8.54 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37780412428209886		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.37780412428209886 | validation: 0.3289688933913467]
	TIME [epoch: 8.55 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3781919305750162		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.3781919305750162 | validation: 0.7170520536582704]
	TIME [epoch: 8.54 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5078445285840123		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.5078445285840123 | validation: 0.5585894580124271]
	TIME [epoch: 8.57 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5048607855232259		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.5048607855232259 | validation: 1.0071847630353714]
	TIME [epoch: 8.54 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43481300870522055		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.43481300870522055 | validation: 0.4448759979080723]
	TIME [epoch: 8.55 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37316970941170996		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.37316970941170996 | validation: 0.2657623094441588]
	TIME [epoch: 8.54 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3573414802534159		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.3573414802534159 | validation: 0.6656831720677188]
	TIME [epoch: 8.57 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49354422478883836		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.49354422478883836 | validation: 0.4313515196784086]
	TIME [epoch: 8.55 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3663405483523251		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.3663405483523251 | validation: 0.37964272641795566]
	TIME [epoch: 8.55 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3913179492994511		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.3913179492994511 | validation: 0.4663792524330461]
	TIME [epoch: 8.54 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4854862226003718		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.4854862226003718 | validation: 0.5857105332006904]
	TIME [epoch: 8.57 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4803543341513346		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.4803543341513346 | validation: 0.5111824646453472]
	TIME [epoch: 8.55 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4129473384927704		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.4129473384927704 | validation: 0.3144573113005582]
	TIME [epoch: 8.55 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42494769752609296		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.42494769752609296 | validation: 0.44185806113059234]
	TIME [epoch: 8.55 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3502067631299617		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.3502067631299617 | validation: 0.24267986279153053]
	TIME [epoch: 8.57 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684379066271962		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.3684379066271962 | validation: 0.5377559095870446]
	TIME [epoch: 8.55 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520029206655756		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.3520029206655756 | validation: 0.29804435375056965]
	TIME [epoch: 8.55 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3657880722143084		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.3657880722143084 | validation: 0.1663303785252923]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4246633187376923		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.4246633187376923 | validation: 0.5009360194193716]
	TIME [epoch: 8.79 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4067989874819576		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.4067989874819576 | validation: 0.39680346238446074]
	TIME [epoch: 8.55 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5130180438982134		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.5130180438982134 | validation: 0.28327102405477433]
	TIME [epoch: 8.54 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41089682081750994		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.41089682081750994 | validation: 0.24150684148149484]
	TIME [epoch: 8.56 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40863855973150526		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.40863855973150526 | validation: 0.3897132365618592]
	TIME [epoch: 8.55 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7010542679427794		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.7010542679427794 | validation: 0.9090792616663586]
	TIME [epoch: 8.55 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40644236413693025		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.40644236413693025 | validation: 0.2772676915261527]
	TIME [epoch: 8.55 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3541457042817166		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.3541457042817166 | validation: 0.222114764687859]
	TIME [epoch: 8.57 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37330458803373334		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.37330458803373334 | validation: 0.5848624999504086]
	TIME [epoch: 8.55 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42256905634304254		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.42256905634304254 | validation: 0.28921914828908324]
	TIME [epoch: 8.54 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4239531103048898		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.4239531103048898 | validation: 0.19627833784786036]
	TIME [epoch: 8.55 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40346109351824655		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.40346109351824655 | validation: 0.22727636198858292]
	TIME [epoch: 8.57 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41952163000061676		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.41952163000061676 | validation: 0.6380248359162767]
	TIME [epoch: 8.55 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4109105234695497		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.4109105234695497 | validation: 0.8428867577517292]
	TIME [epoch: 8.55 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39850976012537204		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.39850976012537204 | validation: 0.2095869888359089]
	TIME [epoch: 8.55 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4217586509233954		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.4217586509233954 | validation: 0.2928724627146739]
	TIME [epoch: 8.57 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34218460858390815		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.34218460858390815 | validation: 0.26244999727341556]
	TIME [epoch: 8.55 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3755545657887711		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.3755545657887711 | validation: 0.258804770950799]
	TIME [epoch: 8.55 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31708818684914303		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.31708818684914303 | validation: 0.21837419320360485]
	TIME [epoch: 8.54 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258140371719087		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.3258140371719087 | validation: 0.19454656824342953]
	TIME [epoch: 8.57 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35560179104855505		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.35560179104855505 | validation: 0.4603325794868287]
	TIME [epoch: 8.55 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4114963371063574		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.4114963371063574 | validation: 0.4715615275703271]
	TIME [epoch: 8.55 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333542992774479		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.3333542992774479 | validation: 0.34176401161558634]
	TIME [epoch: 8.55 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28005664748875614		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.28005664748875614 | validation: 0.3448852475489341]
	TIME [epoch: 8.56 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3638559823365055		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.3638559823365055 | validation: 0.22238837882578683]
	TIME [epoch: 8.55 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32276869183602414		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.32276869183602414 | validation: 0.338236345988945]
	TIME [epoch: 8.55 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3337351815520509		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.3337351815520509 | validation: 0.31177442356441043]
	TIME [epoch: 8.55 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49518531704584745		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.49518531704584745 | validation: 0.2506633012594883]
	TIME [epoch: 8.57 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611502681576213		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.3611502681576213 | validation: 0.5922516456939222]
	TIME [epoch: 8.55 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39314637386278173		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.39314637386278173 | validation: 0.1730880974649997]
	TIME [epoch: 8.55 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32728632308002925		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.32728632308002925 | validation: 0.224896515533567]
	TIME [epoch: 8.55 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27786617858555324		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.27786617858555324 | validation: 0.17000172477387337]
	TIME [epoch: 8.57 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.320970251225866		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.320970251225866 | validation: 0.17658769655331696]
	TIME [epoch: 8.54 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37432687006693416		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.37432687006693416 | validation: 0.5700273491666745]
	TIME [epoch: 8.55 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3974376554672239		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.3974376554672239 | validation: 1.000455106594751]
	TIME [epoch: 8.56 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5680742206670546		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.5680742206670546 | validation: 0.3615525037684847]
	TIME [epoch: 8.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43326181765467614		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.43326181765467614 | validation: 0.25567456645706316]
	TIME [epoch: 8.55 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3615854062101323		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.3615854062101323 | validation: 0.8326902555233976]
	TIME [epoch: 8.55 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.094540048784222		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 1.094540048784222 | validation: 0.34958594199292936]
	TIME [epoch: 8.57 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4177064227775703		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.4177064227775703 | validation: 0.14776709766594803]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30121003762451354		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.30121003762451354 | validation: 0.331985244866882]
	TIME [epoch: 8.54 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47467227684633817		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.47467227684633817 | validation: 0.41192922919140373]
	TIME [epoch: 8.54 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3897057790986881		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.3897057790986881 | validation: 0.2529816076252971]
	TIME [epoch: 8.56 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29756686077584565		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.29756686077584565 | validation: 0.21191905470635616]
	TIME [epoch: 8.55 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8006671073265625		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.8006671073265625 | validation: 0.7555402066844255]
	TIME [epoch: 8.54 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41933214815361736		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.41933214815361736 | validation: 0.26912351623297404]
	TIME [epoch: 8.54 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.339064912975243		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.339064912975243 | validation: 0.3108265653092533]
	TIME [epoch: 8.56 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39025638600602386		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.39025638600602386 | validation: 0.20112811747250373]
	TIME [epoch: 8.55 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35737669788617416		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.35737669788617416 | validation: 0.8058963803459582]
	TIME [epoch: 8.54 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38608120040163146		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.38608120040163146 | validation: 0.28181697700508945]
	TIME [epoch: 8.54 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37580015487423146		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.37580015487423146 | validation: 0.31715122064931545]
	TIME [epoch: 8.56 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35431287220037466		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.35431287220037466 | validation: 0.37346207588335734]
	TIME [epoch: 8.54 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3638717390027749		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.3638717390027749 | validation: 1.1556255510805937]
	TIME [epoch: 8.54 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5892904208437365		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.5892904208437365 | validation: 0.2779493173765752]
	TIME [epoch: 8.55 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39431707844786		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.39431707844786 | validation: 0.4122823650850379]
	TIME [epoch: 8.56 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4091344242548153		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.4091344242548153 | validation: 0.302427206252852]
	TIME [epoch: 8.55 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093578086828337		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.3093578086828337 | validation: 0.19475002038045872]
	TIME [epoch: 8.54 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33132869441711243		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.33132869441711243 | validation: 0.3021353155733865]
	TIME [epoch: 8.55 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45238479822601185		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.45238479822601185 | validation: 0.4829289690456089]
	TIME [epoch: 8.57 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37177251308102033		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.37177251308102033 | validation: 0.287958703287033]
	TIME [epoch: 8.55 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34490439038667703		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.34490439038667703 | validation: 0.4030252596221725]
	TIME [epoch: 8.54 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4178701180567367		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.4178701180567367 | validation: 0.38442117333506276]
	TIME [epoch: 8.54 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3182820471198039		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.3182820471198039 | validation: 0.25228498179534053]
	TIME [epoch: 8.56 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839972304277173		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.2839972304277173 | validation: 0.32983286711366716]
	TIME [epoch: 8.54 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46565338703382164		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.46565338703382164 | validation: 0.3340766408234166]
	TIME [epoch: 8.55 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4285604024049047		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.4285604024049047 | validation: 0.2132631727693583]
	TIME [epoch: 8.56 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3212000402702492		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.3212000402702492 | validation: 0.35905985556506176]
	TIME [epoch: 8.55 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41983703768764447		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.41983703768764447 | validation: 0.25863501846533754]
	TIME [epoch: 8.54 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37307627733163023		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.37307627733163023 | validation: 0.3778507162790868]
	TIME [epoch: 8.54 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35778349041131285		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.35778349041131285 | validation: 0.26908937672142824]
	TIME [epoch: 8.57 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3582813209071155		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.3582813209071155 | validation: 0.2909299143661992]
	TIME [epoch: 8.54 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3495819606477115		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.3495819606477115 | validation: 0.4876282182732249]
	TIME [epoch: 8.54 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35216030979036395		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.35216030979036395 | validation: 0.13672775027519882]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27641252022266327		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.27641252022266327 | validation: 0.3096450140796263]
	TIME [epoch: 8.55 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25147961752394055		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.25147961752394055 | validation: 0.26785382963576776]
	TIME [epoch: 8.55 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34875374609435633		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.34875374609435633 | validation: 0.22930489855596514]
	TIME [epoch: 8.54 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.536873992774633		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.536873992774633 | validation: 0.3400942923615272]
	TIME [epoch: 8.54 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2528688353059104		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2528688353059104 | validation: 0.3772354645565199]
	TIME [epoch: 8.56 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35262556917678184		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.35262556917678184 | validation: 0.4330513375968295]
	TIME [epoch: 8.55 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306050985325334		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.3306050985325334 | validation: 0.251369186449653]
	TIME [epoch: 8.54 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037226294102803		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.3037226294102803 | validation: 0.21944611003721765]
	TIME [epoch: 8.54 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3488462711969978		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.3488462711969978 | validation: 0.26730223769948713]
	TIME [epoch: 8.56 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728967335041239		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.2728967335041239 | validation: 0.2937880898316151]
	TIME [epoch: 8.55 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25029253677493163		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.25029253677493163 | validation: 0.12766930607171548]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4358134717034251		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.4358134717034251 | validation: 0.20144634161322392]
	TIME [epoch: 8.53 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3884730454662258		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.3884730454662258 | validation: 0.22644514089792725]
	TIME [epoch: 8.56 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.397346751692504		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.397346751692504 | validation: 0.4461101649301788]
	TIME [epoch: 8.53 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33176087474073446		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.33176087474073446 | validation: 0.1653869272427883]
	TIME [epoch: 8.53 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3416819714346231		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.3416819714346231 | validation: 0.43094374029950633]
	TIME [epoch: 8.53 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27559628625017596		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.27559628625017596 | validation: 0.2798712849081498]
	TIME [epoch: 8.56 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30762707933116845		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.30762707933116845 | validation: 0.1303581193403925]
	TIME [epoch: 8.53 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36304845806403485		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.36304845806403485 | validation: 0.36929590819168656]
	TIME [epoch: 8.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34555085250773027		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.34555085250773027 | validation: 0.3296458966564393]
	TIME [epoch: 8.54 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2795303118990076		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.2795303118990076 | validation: 0.2408213050520565]
	TIME [epoch: 8.54 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3794706591108494		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.3794706591108494 | validation: 0.27021099510631613]
	TIME [epoch: 8.53 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2840568526079763		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.2840568526079763 | validation: 0.20305329641657488]
	TIME [epoch: 8.53 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3338469582170182		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.3338469582170182 | validation: 0.3993601832766013]
	TIME [epoch: 8.55 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959383467649303		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.2959383467649303 | validation: 0.3718243580382913]
	TIME [epoch: 8.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41202654317557474		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.41202654317557474 | validation: 0.568376273208477]
	TIME [epoch: 8.53 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39619527378377406		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.39619527378377406 | validation: 0.20308899977814043]
	TIME [epoch: 8.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39998774920661356		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.39998774920661356 | validation: 0.29240194657486535]
	TIME [epoch: 8.55 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31360898429571743		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.31360898429571743 | validation: 0.2178229242494161]
	TIME [epoch: 8.54 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29327752159252357		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.29327752159252357 | validation: 0.35271450367405677]
	TIME [epoch: 8.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2758906345183111		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.2758906345183111 | validation: 0.22816687102746636]
	TIME [epoch: 8.54 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2868639372601908		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.2868639372601908 | validation: 0.42921280128947303]
	TIME [epoch: 8.55 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3499429235530286		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.3499429235530286 | validation: 0.21777650486209577]
	TIME [epoch: 8.53 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39098142232830374		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.39098142232830374 | validation: 0.4153910602473583]
	TIME [epoch: 8.53 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32037168199391874		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.32037168199391874 | validation: 0.26089588832702226]
	TIME [epoch: 8.53 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32728912249523257		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.32728912249523257 | validation: 0.16491731120927083]
	TIME [epoch: 8.55 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3547903827429582		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.3547903827429582 | validation: 0.4657848592209056]
	TIME [epoch: 8.54 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33934080131736516		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.33934080131736516 | validation: 0.38268573247301463]
	TIME [epoch: 8.53 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39594858264827604		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.39594858264827604 | validation: 0.42250356566023733]
	TIME [epoch: 8.53 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40678060940575556		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.40678060940575556 | validation: 0.17817715030096443]
	TIME [epoch: 8.55 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3908452211615813		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.3908452211615813 | validation: 0.2955497329883669]
	TIME [epoch: 8.53 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069482965156015		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.3069482965156015 | validation: 0.17864560696692938]
	TIME [epoch: 8.53 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3862979045943221		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.3862979045943221 | validation: 0.22437572324873872]
	TIME [epoch: 8.53 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41523606454165324		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.41523606454165324 | validation: 0.15001884718129677]
	TIME [epoch: 8.55 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23850073786263848		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.23850073786263848 | validation: 0.24217064492005957]
	TIME [epoch: 8.53 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35452567557088416		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.35452567557088416 | validation: 0.39102140864168544]
	TIME [epoch: 8.53 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3492927310667274		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.3492927310667274 | validation: 0.36773984632252554]
	TIME [epoch: 8.54 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4513821171568629		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.4513821171568629 | validation: 0.42975510538619144]
	TIME [epoch: 8.55 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3837540337076022		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.3837540337076022 | validation: 0.2070802934717586]
	TIME [epoch: 8.54 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31819102620465933		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.31819102620465933 | validation: 0.23570485957054352]
	TIME [epoch: 8.53 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32636282037982844		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.32636282037982844 | validation: 0.22164673040328559]
	TIME [epoch: 8.55 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2883599574883583		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.2883599574883583 | validation: 0.33033578559665294]
	TIME [epoch: 8.54 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449133633002845		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.5449133633002845 | validation: 0.37792267761421594]
	TIME [epoch: 8.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4312240565674023		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.4312240565674023 | validation: 0.2442195835337473]
	TIME [epoch: 8.54 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3723136322814192		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.3723136322814192 | validation: 0.2829506093920948]
	TIME [epoch: 8.55 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5812845927137639		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.5812845927137639 | validation: 0.22421770730372306]
	TIME [epoch: 8.53 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20186516453002593		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.20186516453002593 | validation: 0.21694766376733088]
	TIME [epoch: 8.54 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25748061618571155		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.25748061618571155 | validation: 0.25996900510588783]
	TIME [epoch: 8.53 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798036750783613		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.2798036750783613 | validation: 0.2517094410118264]
	TIME [epoch: 8.55 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30864123502720864		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.30864123502720864 | validation: 0.4164243310736252]
	TIME [epoch: 8.54 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727852892591155		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.2727852892591155 | validation: 0.3511117373308682]
	TIME [epoch: 8.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27233856777026055		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.27233856777026055 | validation: 0.21460564959748135]
	TIME [epoch: 8.54 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3174400354238399		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.3174400354238399 | validation: 0.3577437172453274]
	TIME [epoch: 8.56 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30484211856089516		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.30484211856089516 | validation: 0.1392566216110875]
	TIME [epoch: 8.54 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650212694859418		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.2650212694859418 | validation: 0.3302043696466257]
	TIME [epoch: 8.54 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38914102559136793		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.38914102559136793 | validation: 0.267630300939972]
	TIME [epoch: 8.54 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830532639239095		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.2830532639239095 | validation: 0.14712474458764863]
	TIME [epoch: 8.55 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682485736197408		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.2682485736197408 | validation: 0.37431323773016373]
	TIME [epoch: 8.54 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38057967661103387		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.38057967661103387 | validation: 0.22882864530125352]
	TIME [epoch: 8.54 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24017533903077756		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.24017533903077756 | validation: 0.1952150886887789]
	TIME [epoch: 8.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25628621557501347		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.25628621557501347 | validation: 0.33496986873926177]
	TIME [epoch: 8.56 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34553511850060614		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.34553511850060614 | validation: 0.25699157798056727]
	TIME [epoch: 8.54 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698537719507456		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.2698537719507456 | validation: 0.1709411034084284]
	TIME [epoch: 8.54 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5375950503716245		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.5375950503716245 | validation: 0.22474717903466856]
	TIME [epoch: 8.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3606192978247843		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.3606192978247843 | validation: 0.25396277396150846]
	TIME [epoch: 8.55 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.259380358021145		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.259380358021145 | validation: 0.3111278933132807]
	TIME [epoch: 8.54 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25850743348994		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.25850743348994 | validation: 0.48019860060937647]
	TIME [epoch: 8.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.348162140624417		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.348162140624417 | validation: 0.338739381738196]
	TIME [epoch: 8.53 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4050084368789563		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.4050084368789563 | validation: 0.15576710104333774]
	TIME [epoch: 8.55 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5176941633575958		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.5176941633575958 | validation: 0.3449945371280503]
	TIME [epoch: 8.53 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329134777430189		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.3329134777430189 | validation: 0.4698029659292081]
	TIME [epoch: 8.53 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2812084120605873		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.2812084120605873 | validation: 0.3527933921696983]
	TIME [epoch: 8.53 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4450210664273847		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.4450210664273847 | validation: 0.3988407288100506]
	TIME [epoch: 8.55 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29256135273711187		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.29256135273711187 | validation: 0.18403744266443972]
	TIME [epoch: 8.53 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2631649840367683		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.2631649840367683 | validation: 0.21787100419837557]
	TIME [epoch: 8.53 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698339883920977		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.2698339883920977 | validation: 0.7266676998522795]
	TIME [epoch: 8.54 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310289857990888		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.3310289857990888 | validation: 0.2192500482462951]
	TIME [epoch: 8.53 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865812483202768		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.2865812483202768 | validation: 0.22172299106101928]
	TIME [epoch: 8.53 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2866802182618883		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.2866802182618883 | validation: 0.6884738111673201]
	TIME [epoch: 8.53 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37718319781464527		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.37718319781464527 | validation: 0.1086063585085788]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2309008214490726		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.2309008214490726 | validation: 0.12239984719348604]
	TIME [epoch: 8.55 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3354232627731456		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.3354232627731456 | validation: 0.19377516620150712]
	TIME [epoch: 8.54 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760443117483952		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.2760443117483952 | validation: 0.3571913983897354]
	TIME [epoch: 8.53 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45055323459177893		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.45055323459177893 | validation: 0.294768819426352]
	TIME [epoch: 8.55 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2806765301775712		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.2806765301775712 | validation: 0.12628330856559966]
	TIME [epoch: 8.54 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32647551597755875		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.32647551597755875 | validation: 0.23808875160786291]
	TIME [epoch: 8.54 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3038247078811895		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.3038247078811895 | validation: 0.13082636895021893]
	TIME [epoch: 8.54 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25413015168214165		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.25413015168214165 | validation: 0.2452671199803385]
	TIME [epoch: 8.56 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941271079482946		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.2941271079482946 | validation: 0.28146713208735974]
	TIME [epoch: 8.54 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3181000606561342		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.3181000606561342 | validation: 0.2633548262602984]
	TIME [epoch: 8.53 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25113255359326925		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.25113255359326925 | validation: 0.22343595069347316]
	TIME [epoch: 8.54 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3299872189058617		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.3299872189058617 | validation: 0.14173298885846763]
	TIME [epoch: 8.56 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33232280880686055		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.33232280880686055 | validation: 0.29812706819072354]
	TIME [epoch: 8.54 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28661667597424156		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.28661667597424156 | validation: 0.28185831171642]
	TIME [epoch: 8.53 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21524432031392574		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.21524432031392574 | validation: 0.3716677179219112]
	TIME [epoch: 8.54 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42977570242511065		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.42977570242511065 | validation: 0.2759285840466045]
	TIME [epoch: 8.56 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24713475247955025		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.24713475247955025 | validation: 0.16352338249511883]
	TIME [epoch: 8.54 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3554595593451254		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.3554595593451254 | validation: 0.3317117446809995]
	TIME [epoch: 8.54 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3296261647504926		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.3296261647504926 | validation: 0.5141914900518847]
	TIME [epoch: 8.54 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3587765597665614		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.3587765597665614 | validation: 0.4342350590844031]
	TIME [epoch: 8.56 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34969378627923514		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.34969378627923514 | validation: 0.166097300119185]
	TIME [epoch: 8.54 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2160925880716454		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.2160925880716454 | validation: 0.19521761134110815]
	TIME [epoch: 8.54 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813686798304338		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.2813686798304338 | validation: 0.26198820660807876]
	TIME [epoch: 8.55 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25584155405411957		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.25584155405411957 | validation: 0.13440252904378397]
	TIME [epoch: 8.55 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3025402560864971		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.3025402560864971 | validation: 0.18556290410223675]
	TIME [epoch: 8.54 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769686603355166		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.2769686603355166 | validation: 0.1387639200620067]
	TIME [epoch: 8.54 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22901533326425697		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.22901533326425697 | validation: 0.1958367190399155]
	TIME [epoch: 8.56 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3200069321387991		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.3200069321387991 | validation: 0.265568975832282]
	TIME [epoch: 8.54 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954542198600211		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.2954542198600211 | validation: 0.20725658292261467]
	TIME [epoch: 8.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250876830733798		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.250876830733798 | validation: 0.13136136404614557]
	TIME [epoch: 8.54 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26955117064696626		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.26955117064696626 | validation: 0.4369325855081425]
	TIME [epoch: 8.55 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2779104147931315		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.2779104147931315 | validation: 0.5225711691903643]
	TIME [epoch: 8.53 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4200595328092761		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.4200595328092761 | validation: 0.320116695497509]
	TIME [epoch: 8.54 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3546623336582895		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.3546623336582895 | validation: 0.3574769049041912]
	TIME [epoch: 8.53 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3381827718401009		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.3381827718401009 | validation: 0.1732026910858569]
	TIME [epoch: 8.56 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506119157512846		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.2506119157512846 | validation: 0.49454729555328225]
	TIME [epoch: 8.54 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3198393214764737		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.3198393214764737 | validation: 0.2843361398133481]
	TIME [epoch: 8.53 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24480366837562953		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.24480366837562953 | validation: 0.4221234324219944]
	TIME [epoch: 8.54 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30618726101415283		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.30618726101415283 | validation: 0.19238261341564006]
	TIME [epoch: 8.56 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941792608660913		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.2941792608660913 | validation: 0.17808506939858404]
	TIME [epoch: 8.54 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35315290237675784		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.35315290237675784 | validation: 0.1643735691280123]
	TIME [epoch: 8.54 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2517309230357085		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.2517309230357085 | validation: 0.22613573414451688]
	TIME [epoch: 8.53 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2652297580403617		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.2652297580403617 | validation: 0.33443958702628773]
	TIME [epoch: 8.56 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33038140009736394		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.33038140009736394 | validation: 0.2205393513753643]
	TIME [epoch: 8.54 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22216959505311387		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.22216959505311387 | validation: 0.24699559738138646]
	TIME [epoch: 8.54 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23338812497221753		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.23338812497221753 | validation: 0.3096508108561256]
	TIME [epoch: 8.53 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23235589157517778		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.23235589157517778 | validation: 0.18407504872358627]
	TIME [epoch: 8.57 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29362031541779715		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.29362031541779715 | validation: 0.2217057908507286]
	TIME [epoch: 8.54 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2604373064109416		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.2604373064109416 | validation: 0.19244713979846612]
	TIME [epoch: 8.54 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2445628342429546		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.2445628342429546 | validation: 0.5122952066278418]
	TIME [epoch: 8.54 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31137714101836544		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.31137714101836544 | validation: 0.5240134456847247]
	TIME [epoch: 8.56 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989815713901477		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.2989815713901477 | validation: 0.20198360435994112]
	TIME [epoch: 8.52 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2878663564550367		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.2878663564550367 | validation: 0.2829493496314106]
	TIME [epoch: 8.54 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3722995602618038		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.3722995602618038 | validation: 0.724621740820373]
	TIME [epoch: 8.53 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3473667725626305		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.3473667725626305 | validation: 0.21068349140489662]
	TIME [epoch: 8.56 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121598617810676		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.3121598617810676 | validation: 0.4066906075615325]
	TIME [epoch: 8.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26983637224110335		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.26983637224110335 | validation: 0.2884025040521789]
	TIME [epoch: 8.54 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36564174867005034		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.36564174867005034 | validation: 0.29441613960336477]
	TIME [epoch: 8.54 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2677746093786294		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.2677746093786294 | validation: 0.20010747017125008]
	TIME [epoch: 8.55 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23612027213888123		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.23612027213888123 | validation: 0.22412526015052775]
	TIME [epoch: 8.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2685022751888154		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.2685022751888154 | validation: 0.1429106492421089]
	TIME [epoch: 8.53 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20521713143815293		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.20521713143815293 | validation: 0.1827785014144269]
	TIME [epoch: 8.55 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20469011447473742		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.20469011447473742 | validation: 0.11000991865631503]
	TIME [epoch: 8.54 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2000103399182292		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.2000103399182292 | validation: 0.16980955151876231]
	TIME [epoch: 8.54 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31195988709907796		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.31195988709907796 | validation: 0.3481298385445406]
	TIME [epoch: 8.54 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1862221702764494		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.1862221702764494 | validation: 0.10616600536400539]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_661.pth
	Model improved!!!
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2379781705950755		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.2379781705950755 | validation: 0.13497842425659212]
	TIME [epoch: 8.54 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31516397573373506		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.31516397573373506 | validation: 0.24934535672444177]
	TIME [epoch: 8.54 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19333000744248802		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.19333000744248802 | validation: 0.3700588642954139]
	TIME [epoch: 8.53 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23883011546530092		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.23883011546530092 | validation: 0.1652403581738945]
	TIME [epoch: 8.55 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19682783168675683		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.19682783168675683 | validation: 0.14499968624385023]
	TIME [epoch: 8.54 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23966848575181915		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.23966848575181915 | validation: 0.09203976145348414]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18846383752162832		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.18846383752162832 | validation: 0.16230052959731103]
	TIME [epoch: 8.53 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2584849318812549		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.2584849318812549 | validation: 0.26841042187502473]
	TIME [epoch: 8.56 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22821454531825944		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.22821454531825944 | validation: 0.41119527152784063]
	TIME [epoch: 8.54 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2573524262197856		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.2573524262197856 | validation: 0.2266698562050643]
	TIME [epoch: 8.53 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21000939454082762		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.21000939454082762 | validation: 0.19868481533223797]
	TIME [epoch: 8.53 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24464249087672138		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.24464249087672138 | validation: 0.21743598930119745]
	TIME [epoch: 8.56 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34137852304450905		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.34137852304450905 | validation: 0.7124491959209298]
	TIME [epoch: 8.54 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4124314690016738		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.4124314690016738 | validation: 0.22066940987974593]
	TIME [epoch: 8.54 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2877617443005199		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.2877617443005199 | validation: 0.393895127333156]
	TIME [epoch: 8.55 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23944202681523108		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.23944202681523108 | validation: 0.18478161145754954]
	TIME [epoch: 8.55 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20004586402264352		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.20004586402264352 | validation: 0.12930618778206368]
	TIME [epoch: 8.53 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18265987676130716		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.18265987676130716 | validation: 0.21631638143319348]
	TIME [epoch: 8.54 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22206491100917525		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.22206491100917525 | validation: 0.21050604950913426]
	TIME [epoch: 8.55 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288570129357714		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.288570129357714 | validation: 0.1681213102699266]
	TIME [epoch: 8.55 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21518848486885825		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.21518848486885825 | validation: 0.1887714759555824]
	TIME [epoch: 8.53 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3521769449179712		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.3521769449179712 | validation: 0.18178803789287126]
	TIME [epoch: 8.53 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28927771933298535		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.28927771933298535 | validation: 0.3484127868744496]
	TIME [epoch: 8.56 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3429253785440951		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.3429253785440951 | validation: 0.738707912650898]
	TIME [epoch: 8.54 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35008702472933256		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.35008702472933256 | validation: 0.19272684452514682]
	TIME [epoch: 8.54 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3291084193627772		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.3291084193627772 | validation: 0.26236190172785334]
	TIME [epoch: 8.53 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3981264309153425		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.3981264309153425 | validation: 0.19632815207216525]
	TIME [epoch: 8.56 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23826209854138383		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.23826209854138383 | validation: 0.2682074034020308]
	TIME [epoch: 8.54 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24074068722538772		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.24074068722538772 | validation: 0.19239500511872734]
	TIME [epoch: 8.54 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35409731164507796		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.35409731164507796 | validation: 0.25117981629725156]
	TIME [epoch: 8.53 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28342315305085886		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.28342315305085886 | validation: 0.29555561448786566]
	TIME [epoch: 8.55 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959700770472698		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.2959700770472698 | validation: 0.37757640224121225]
	TIME [epoch: 8.53 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904020786434048		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.2904020786434048 | validation: 0.15155362919163065]
	TIME [epoch: 8.54 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22963969758563177		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.22963969758563177 | validation: 0.16909618669438303]
	TIME [epoch: 8.53 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22991514225354673		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.22991514225354673 | validation: 0.13091612823335486]
	TIME [epoch: 8.55 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2355795097670678		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.2355795097670678 | validation: 0.2977338411166432]
	TIME [epoch: 8.54 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20633758778530464		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.20633758778530464 | validation: 0.14056121727411017]
	TIME [epoch: 8.53 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18504603515303814		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.18504603515303814 | validation: 0.28444276338122876]
	TIME [epoch: 8.53 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23511170143812885		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.23511170143812885 | validation: 0.12044523163411193]
	TIME [epoch: 8.55 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19409129954166138		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.19409129954166138 | validation: 0.09921557752683624]
	TIME [epoch: 8.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17840508633956534		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.17840508633956534 | validation: 0.18791092201006154]
	TIME [epoch: 8.54 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981822804790868		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.2981822804790868 | validation: 0.21047575907158328]
	TIME [epoch: 8.54 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23863363871434884		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.23863363871434884 | validation: 0.2758059058856397]
	TIME [epoch: 8.55 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046192516461753		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.3046192516461753 | validation: 0.32882368770430614]
	TIME [epoch: 8.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2521426688976108		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.2521426688976108 | validation: 0.34075009367415565]
	TIME [epoch: 8.54 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23652402862390692		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.23652402862390692 | validation: 0.29157722497140137]
	TIME [epoch: 8.54 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3100716838538281		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.3100716838538281 | validation: 0.16431851039296458]
	TIME [epoch: 8.56 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19651823946675118		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.19651823946675118 | validation: 0.18598809208138134]
	TIME [epoch: 8.54 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2509308746487368		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.2509308746487368 | validation: 0.1797518394796911]
	TIME [epoch: 8.54 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23005150010049719		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.23005150010049719 | validation: 0.18139467038942086]
	TIME [epoch: 8.55 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2291354485939308		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.2291354485939308 | validation: 0.137790457568219]
	TIME [epoch: 8.55 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22594619154474307		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.22594619154474307 | validation: 0.15556636648166128]
	TIME [epoch: 8.54 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26329589677591264		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.26329589677591264 | validation: 0.14128664991830597]
	TIME [epoch: 8.54 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23062195532807256		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.23062195532807256 | validation: 0.3367269803793753]
	TIME [epoch: 8.56 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2672156646935063		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.2672156646935063 | validation: 0.23496420427008025]
	TIME [epoch: 8.55 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25183505952110075		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.25183505952110075 | validation: 0.16212983106577883]
	TIME [epoch: 8.54 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2595799004603282		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.2595799004603282 | validation: 0.24819239557966943]
	TIME [epoch: 8.54 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23561362526495047		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.23561362526495047 | validation: 0.15376048579717805]
	TIME [epoch: 8.55 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22414179499898226		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.22414179499898226 | validation: 0.13071191559740272]
	TIME [epoch: 8.54 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21129692319625182		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.21129692319625182 | validation: 0.16140013290741148]
	TIME [epoch: 8.54 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24758564248853393		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.24758564248853393 | validation: 0.27125081594535094]
	TIME [epoch: 8.54 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036799904095669		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.2036799904095669 | validation: 0.21880620136653095]
	TIME [epoch: 8.56 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21335137241141872		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.21335137241141872 | validation: 0.12714645017053733]
	TIME [epoch: 8.54 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2339502644198958		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.2339502644198958 | validation: 0.2019760683461141]
	TIME [epoch: 8.53 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.238399457029944		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.238399457029944 | validation: 0.09826073631443281]
	TIME [epoch: 8.53 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16872106033890716		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.16872106033890716 | validation: 0.08045615113152411]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2217088744054782		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.2217088744054782 | validation: 0.09574718663682158]
	TIME [epoch: 8.55 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2526697979422041		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.2526697979422041 | validation: 0.2630839107985452]
	TIME [epoch: 8.54 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5760990565754465		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.5760990565754465 | validation: 0.3781806632291089]
	TIME [epoch: 8.55 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33815835121819526		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.33815835121819526 | validation: 0.23046666549960537]
	TIME [epoch: 8.56 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3454086317209732		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.3454086317209732 | validation: 0.8715733196333493]
	TIME [epoch: 8.54 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7492208060709842		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 1.7492208060709842 | validation: 0.939995766880555]
	TIME [epoch: 8.54 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3859216181260817		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.3859216181260817 | validation: 0.28284746793724513]
	TIME [epoch: 8.54 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29099717827863253		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.29099717827863253 | validation: 0.2823299827029425]
	TIME [epoch: 8.56 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807986459351031		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.2807986459351031 | validation: 0.19349386916786604]
	TIME [epoch: 8.55 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22178303735619642		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.22178303735619642 | validation: 0.21016856807593634]
	TIME [epoch: 8.55 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27806583897531234		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.27806583897531234 | validation: 0.28042788274616137]
	TIME [epoch: 8.55 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31742193560885806		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.31742193560885806 | validation: 0.19450882605628833]
	TIME [epoch: 8.56 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3427563943547018		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.3427563943547018 | validation: 0.3000183622560099]
	TIME [epoch: 8.54 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172702851149661		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.3172702851149661 | validation: 0.24565742646985572]
	TIME [epoch: 8.55 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2677627346241245		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.2677627346241245 | validation: 0.4042966361211974]
	TIME [epoch: 8.57 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2655775803752845		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.2655775803752845 | validation: 0.13804731223051525]
	TIME [epoch: 8.54 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15873705307318414		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.15873705307318414 | validation: 0.12615760130670362]
	TIME [epoch: 8.54 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626458248335754		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.2626458248335754 | validation: 0.25105639082136766]
	TIME [epoch: 8.54 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19847081304983305		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.19847081304983305 | validation: 0.15227617433422885]
	TIME [epoch: 8.56 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21876386969933712		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.21876386969933712 | validation: 0.2648908686917685]
	TIME [epoch: 8.54 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19864182226007226		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.19864182226007226 | validation: 0.17571208258322563]
	TIME [epoch: 8.54 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23806649748440548		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.23806649748440548 | validation: 0.11308215060125408]
	TIME [epoch: 8.54 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18863355286986289		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.18863355286986289 | validation: 0.20901388355009848]
	TIME [epoch: 8.56 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20948938866046585		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.20948938866046585 | validation: 0.15492326564039538]
	TIME [epoch: 8.54 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23570225397842162		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.23570225397842162 | validation: 0.16244009166265755]
	TIME [epoch: 8.54 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1849325945508429		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.1849325945508429 | validation: 0.10445812908481286]
	TIME [epoch: 8.54 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18249639183561947		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.18249639183561947 | validation: 0.17740926121253425]
	TIME [epoch: 8.56 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22240031824611445		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.22240031824611445 | validation: 0.23154852950008054]
	TIME [epoch: 8.54 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30269322523416764		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.30269322523416764 | validation: 0.3179961629951539]
	TIME [epoch: 8.54 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26568604084912484		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.26568604084912484 | validation: 0.2694266252634049]
	TIME [epoch: 8.54 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25311497712421765		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.25311497712421765 | validation: 0.15611300503532355]
	TIME [epoch: 8.56 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544883382963378		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.20544883382963378 | validation: 0.14859320556656513]
	TIME [epoch: 8.54 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32131959604702004		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.32131959604702004 | validation: 0.18810544231269016]
	TIME [epoch: 8.54 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348868711256163		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.2348868711256163 | validation: 0.1863051375707549]
	TIME [epoch: 8.54 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21835831897901192		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.21835831897901192 | validation: 0.14356724105886007]
	TIME [epoch: 8.55 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2419453342135749		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.2419453342135749 | validation: 0.16645517217077851]
	TIME [epoch: 8.55 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25016704170793963		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.25016704170793963 | validation: 0.12128318509512698]
	TIME [epoch: 8.54 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18306419349914244		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.18306419349914244 | validation: 0.36515696525627916]
	TIME [epoch: 8.55 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26943149955618867		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.26943149955618867 | validation: 0.1132385191443927]
	TIME [epoch: 8.56 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25347860330807254		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.25347860330807254 | validation: 0.3188893868591868]
	TIME [epoch: 8.54 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1974325727815109		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.1974325727815109 | validation: 0.2867184234919059]
	TIME [epoch: 8.53 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19367715374113878		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.19367715374113878 | validation: 0.181178231119579]
	TIME [epoch: 8.55 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17286020353732398		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.17286020353732398 | validation: 0.11582344704793064]
	TIME [epoch: 8.55 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1903574422515593		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.1903574422515593 | validation: 0.16642243986407287]
	TIME [epoch: 8.54 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24785272429870892		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.24785272429870892 | validation: 0.20382230835858356]
	TIME [epoch: 8.54 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16202919303658064		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.16202919303658064 | validation: 0.13484127376858518]
	TIME [epoch: 8.56 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22333743661365202		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.22333743661365202 | validation: 0.32187117574085633]
	TIME [epoch: 8.54 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26772177068402975		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.26772177068402975 | validation: 0.13894135634339438]
	TIME [epoch: 8.54 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20983084417899348		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.20983084417899348 | validation: 0.27124292725479465]
	TIME [epoch: 8.55 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17447248104645383		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.17447248104645383 | validation: 0.14010092085857379]
	TIME [epoch: 8.56 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20042574971467747		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.20042574971467747 | validation: 0.22965210654007978]
	TIME [epoch: 8.55 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.210278239777334		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.210278239777334 | validation: 0.1938346323762294]
	TIME [epoch: 8.53 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1786688940034334		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.1786688940034334 | validation: 0.11880367283344262]
	TIME [epoch: 8.54 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19628008650355983		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.19628008650355983 | validation: 0.27213873343933775]
	TIME [epoch: 8.56 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20500179814536273		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.20500179814536273 | validation: 0.16344542038095872]
	TIME [epoch: 8.55 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18073624369785746		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.18073624369785746 | validation: 0.13958094169503366]
	TIME [epoch: 8.54 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19188804163835774		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.19188804163835774 | validation: 0.11707184457579956]
	TIME [epoch: 8.55 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16720209969791058		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.16720209969791058 | validation: 0.14019646601014274]
	TIME [epoch: 8.57 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18335327568191748		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.18335327568191748 | validation: 0.16623284145961514]
	TIME [epoch: 8.54 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20522650285814753		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.20522650285814753 | validation: 0.15788957060380518]
	TIME [epoch: 8.54 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21482119095189325		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.21482119095189325 | validation: 0.19614264087483058]
	TIME [epoch: 8.55 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22073216577958849		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.22073216577958849 | validation: 0.14713528884342716]
	TIME [epoch: 8.56 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14848239419787004		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.14848239419787004 | validation: 0.19548608430726722]
	TIME [epoch: 8.55 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23803896046403214		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.23803896046403214 | validation: 0.18729886004021473]
	TIME [epoch: 8.54 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22083568544055338		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.22083568544055338 | validation: 0.13215577598693462]
	TIME [epoch: 8.54 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508120247143898		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.2508120247143898 | validation: 0.16393381341981206]
	TIME [epoch: 8.57 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16185960895178086		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.16185960895178086 | validation: 0.15588263788386486]
	TIME [epoch: 8.54 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21783733828726365		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.21783733828726365 | validation: 0.06411864337666426]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15988002403180462		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.15988002403180462 | validation: 0.11170617164943428]
	TIME [epoch: 8.55 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15752705413075496		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.15752705413075496 | validation: 0.2589297120072311]
	TIME [epoch: 8.56 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24094026425103993		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.24094026425103993 | validation: 0.13625059175252124]
	TIME [epoch: 8.54 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16776261179943625		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.16776261179943625 | validation: 0.10570524264256095]
	TIME [epoch: 8.54 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15959854568910783		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.15959854568910783 | validation: 0.12617150507243655]
	TIME [epoch: 8.55 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22671488176629903		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.22671488176629903 | validation: 0.1425500927040083]
	TIME [epoch: 8.55 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2336888836106934		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.2336888836106934 | validation: 0.13859040681946477]
	TIME [epoch: 8.55 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18433449978653052		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.18433449978653052 | validation: 0.10639353137952268]
	TIME [epoch: 8.54 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20662868268253387		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.20662868268253387 | validation: 0.14718894799587207]
	TIME [epoch: 8.55 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901213099190467		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.15901213099190467 | validation: 0.08103721536200437]
	TIME [epoch: 8.55 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.173540211847067		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.173540211847067 | validation: 0.08252770730114278]
	TIME [epoch: 8.54 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1798498875702475		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.1798498875702475 | validation: 0.22333786623171742]
	TIME [epoch: 8.55 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790279534327069		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.1790279534327069 | validation: 0.10968658252260843]
	TIME [epoch: 8.57 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915755019932159		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.1915755019932159 | validation: 0.08563825993318439]
	TIME [epoch: 8.55 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13604581607605418		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.13604581607605418 | validation: 0.2111307554597673]
	TIME [epoch: 8.55 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1719863476267087		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.1719863476267087 | validation: 0.11732536224340534]
	TIME [epoch: 8.55 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22254271520841523		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.22254271520841523 | validation: 0.6505946227355544]
	TIME [epoch: 8.55 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3558811368518138		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.3558811368518138 | validation: 0.1555337559317815]
	TIME [epoch: 8.54 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16018367235135353		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.16018367235135353 | validation: 0.10538422251475964]
	TIME [epoch: 8.54 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16709147405563501		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.16709147405563501 | validation: 0.163924909856706]
	TIME [epoch: 8.54 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20317080125547982		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.20317080125547982 | validation: 0.12038800320368749]
	TIME [epoch: 8.57 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15776998925314895		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.15776998925314895 | validation: 0.09360604178776484]
	TIME [epoch: 8.54 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14530037451236236		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.14530037451236236 | validation: 0.19892593800032526]
	TIME [epoch: 8.53 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456814060196944		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.2456814060196944 | validation: 0.13308973801808444]
	TIME [epoch: 8.53 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20621143303982228		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.20621143303982228 | validation: 0.12826621343348085]
	TIME [epoch: 8.56 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1686256994602832		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.1686256994602832 | validation: 0.10153418838011838]
	TIME [epoch: 8.53 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1708671139500902		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.1708671139500902 | validation: 0.22499572302464782]
	TIME [epoch: 8.53 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16493180605640134		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.16493180605640134 | validation: 0.1616061590618946]
	TIME [epoch: 8.53 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14359560274067304		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.14359560274067304 | validation: 0.17933445610232066]
	TIME [epoch: 8.55 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14600163124125		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.14600163124125 | validation: 0.12874236603783526]
	TIME [epoch: 8.53 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1828489760577837		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.1828489760577837 | validation: 0.24574860868475112]
	TIME [epoch: 8.54 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16070056431288698		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.16070056431288698 | validation: 0.17422420295704394]
	TIME [epoch: 8.54 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18885213467883644		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.18885213467883644 | validation: 0.13274824084578618]
	TIME [epoch: 8.56 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752713077226455		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.1752713077226455 | validation: 0.3088156288891793]
	TIME [epoch: 8.54 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23548799196894468		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.23548799196894468 | validation: 0.14925580087026702]
	TIME [epoch: 8.54 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16351047581159625		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.16351047581159625 | validation: 0.09815165598898748]
	TIME [epoch: 8.54 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17378476925344769		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.17378476925344769 | validation: 0.2090436522732903]
	TIME [epoch: 8.55 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19448243673104887		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.19448243673104887 | validation: 0.24541717573426391]
	TIME [epoch: 8.54 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21056860237469008		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.21056860237469008 | validation: 0.1450209676657207]
	TIME [epoch: 8.54 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16526720473030482		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.16526720473030482 | validation: 0.10889449903100833]
	TIME [epoch: 8.56 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14999797890783945		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.14999797890783945 | validation: 0.15557806934245128]
	TIME [epoch: 8.54 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1450736240162928		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.1450736240162928 | validation: 0.16232096082390385]
	TIME [epoch: 8.53 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1690900915982078		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.1690900915982078 | validation: 0.14031702558482723]
	TIME [epoch: 8.54 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20579916163570694		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.20579916163570694 | validation: 0.12877696280600867]
	TIME [epoch: 8.55 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17313604142424374		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.17313604142424374 | validation: 0.15522665348796777]
	TIME [epoch: 8.54 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16306007766445438		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.16306007766445438 | validation: 0.08406042977973158]
	TIME [epoch: 8.53 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20293676565767224		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.20293676565767224 | validation: 0.1441067858417605]
	TIME [epoch: 8.53 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18825761728723767		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.18825761728723767 | validation: 0.11837844805064537]
	TIME [epoch: 8.55 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1411156164436754		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.1411156164436754 | validation: 0.24076916522189368]
	TIME [epoch: 8.53 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15007590742506186		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.15007590742506186 | validation: 0.22889398741438854]
	TIME [epoch: 8.53 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19767453247403705		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.19767453247403705 | validation: 0.11612771713760561]
	TIME [epoch: 8.53 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1945490977842586		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.1945490977842586 | validation: 0.22582847997466676]
	TIME [epoch: 8.55 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841465117753338		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.16841465117753338 | validation: 0.11500268243823546]
	TIME [epoch: 8.53 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19674604504981402		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.19674604504981402 | validation: 0.26975185344304936]
	TIME [epoch: 8.54 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16649528698466803		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.16649528698466803 | validation: 0.07957356985399752]
	TIME [epoch: 8.53 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13101068713638184		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.13101068713638184 | validation: 0.15176976224965433]
	TIME [epoch: 8.54 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17971475834156872		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.17971475834156872 | validation: 0.16802605285450134]
	TIME [epoch: 8.53 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.159005383991853		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.159005383991853 | validation: 0.11132428618345996]
	TIME [epoch: 8.52 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14480748471382693		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.14480748471382693 | validation: 0.0807824399087463]
	TIME [epoch: 8.54 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18908853964627834		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.18908853964627834 | validation: 0.25527934143304953]
	TIME [epoch: 8.55 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25908964063148293		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.25908964063148293 | validation: 0.13455486791512083]
	TIME [epoch: 8.54 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801948492012893		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.1801948492012893 | validation: 0.3758400845464911]
	TIME [epoch: 8.53 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2181155895109196		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.2181155895109196 | validation: 0.3105091661607115]
	TIME [epoch: 8.54 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23561110757152837		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.23561110757152837 | validation: 0.10682513103921917]
	TIME [epoch: 8.55 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16017166730105004		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.16017166730105004 | validation: 0.10343727695323716]
	TIME [epoch: 8.53 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399608984454705		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.1399608984454705 | validation: 0.09299556012493652]
	TIME [epoch: 8.53 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20042172222756785		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.20042172222756785 | validation: 0.2612192896167604]
	TIME [epoch: 8.54 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20229894301058265		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.20229894301058265 | validation: 0.11068966005238876]
	TIME [epoch: 8.55 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2341701703991943		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.2341701703991943 | validation: 0.09110717321139432]
	TIME [epoch: 8.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16325683968479177		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.16325683968479177 | validation: 0.08303135224656272]
	TIME [epoch: 8.53 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1643103137724571		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.1643103137724571 | validation: 0.1777175152288614]
	TIME [epoch: 8.55 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16971114835688786		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.16971114835688786 | validation: 0.08945169451464834]
	TIME [epoch: 8.53 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16157527379260767		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.16157527379260767 | validation: 0.09630733588134642]
	TIME [epoch: 8.53 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1723400568268306		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.1723400568268306 | validation: 0.10975300789197037]
	TIME [epoch: 8.53 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16554626726242652		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.16554626726242652 | validation: 0.10359369365847845]
	TIME [epoch: 8.55 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.138521203935778		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.138521203935778 | validation: 0.08260642175321598]
	TIME [epoch: 8.53 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11991023136858128		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.11991023136858128 | validation: 0.12353912231761185]
	TIME [epoch: 8.53 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640871636256379		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.1640871636256379 | validation: 0.19063653509754455]
	TIME [epoch: 8.53 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18483620071383608		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.18483620071383608 | validation: 0.16554479042526568]
	TIME [epoch: 8.55 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14816983729565508		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.14816983729565508 | validation: 0.15920181851590373]
	TIME [epoch: 8.53 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382802481487459		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.1382802481487459 | validation: 0.12367242497520191]
	TIME [epoch: 8.53 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15277527260834814		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.15277527260834814 | validation: 0.12055713918700395]
	TIME [epoch: 8.53 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1570044897045107		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.1570044897045107 | validation: 0.10871361211286401]
	TIME [epoch: 8.55 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15430302562075554		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.15430302562075554 | validation: 0.1541132208982533]
	TIME [epoch: 8.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2291676670462442		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.2291676670462442 | validation: 0.10116733743135503]
	TIME [epoch: 8.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13726695426164348		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.13726695426164348 | validation: 0.13678578596953495]
	TIME [epoch: 8.53 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297647094060031		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.1297647094060031 | validation: 0.1790283945919286]
	TIME [epoch: 8.55 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1199952510713489		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.1199952510713489 | validation: 0.07271954677904534]
	TIME [epoch: 8.53 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17890581241783937		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.17890581241783937 | validation: 0.3573911987461166]
	TIME [epoch: 8.54 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17809650473108402		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.17809650473108402 | validation: 0.10749945147226629]
	TIME [epoch: 8.54 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15813329259344414		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.15813329259344414 | validation: 0.18891885512963694]
	TIME [epoch: 8.56 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19682721035559358		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.19682721035559358 | validation: 0.11026423601405189]
	TIME [epoch: 8.53 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700382792094505		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.1700382792094505 | validation: 0.06311142398439437]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_888.pth
	Model improved!!!
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11639006748292849		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.11639006748292849 | validation: 0.15832258160362445]
	TIME [epoch: 8.56 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2129893865203653		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.2129893865203653 | validation: 0.08596841865394658]
	TIME [epoch: 8.56 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12655568534041706		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.12655568534041706 | validation: 0.12611220822376573]
	TIME [epoch: 8.55 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656133704345464		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.1656133704345464 | validation: 0.1371464843745409]
	TIME [epoch: 8.54 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313879457688218		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.1313879457688218 | validation: 0.1754983490206271]
	TIME [epoch: 8.57 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1305952304214824		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.1305952304214824 | validation: 0.09110007484750546]
	TIME [epoch: 8.55 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12296927376558413		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.12296927376558413 | validation: 0.07851816900419606]
	TIME [epoch: 8.55 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15747251959520436		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.15747251959520436 | validation: 0.09284178191226058]
	TIME [epoch: 8.55 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1679391282165177		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.1679391282165177 | validation: 0.12995719825447732]
	TIME [epoch: 8.56 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1419618286981938		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.1419618286981938 | validation: 0.08432775270933976]
	TIME [epoch: 8.55 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1174376641380637		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.1174376641380637 | validation: 0.14053487341608878]
	TIME [epoch: 8.55 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12533559518534426		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.12533559518534426 | validation: 0.10799266542410671]
	TIME [epoch: 8.55 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13469014457069928		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.13469014457069928 | validation: 0.1325968460960533]
	TIME [epoch: 8.57 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11444851433806269		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.11444851433806269 | validation: 0.07899416523885369]
	TIME [epoch: 8.55 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15591405049721732		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.15591405049721732 | validation: 0.10318014081875021]
	TIME [epoch: 8.55 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14079607653115364		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.14079607653115364 | validation: 0.14984666296924473]
	TIME [epoch: 8.55 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841957734756602		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.16841957734756602 | validation: 0.16632575809288164]
	TIME [epoch: 8.57 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14545971091737947		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.14545971091737947 | validation: 0.1325590350457419]
	TIME [epoch: 8.55 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15192310117058405		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.15192310117058405 | validation: 0.101192761196865]
	TIME [epoch: 8.55 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11912518813372157		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.11912518813372157 | validation: 0.06836238002184375]
	TIME [epoch: 8.55 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1343081035108093		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.1343081035108093 | validation: 0.11092986772314213]
	TIME [epoch: 8.56 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1672513715331708		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.1672513715331708 | validation: 0.12358386393194094]
	TIME [epoch: 8.55 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16854283601232375		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.16854283601232375 | validation: 0.18700277465059073]
	TIME [epoch: 8.54 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14461096651711466		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.14461096651711466 | validation: 0.177691062022779]
	TIME [epoch: 8.55 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18161264034076305		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.18161264034076305 | validation: 0.1935075281825297]
	TIME [epoch: 8.57 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316372360752975		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.1316372360752975 | validation: 0.12784073939847618]
	TIME [epoch: 8.55 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11312273328673476		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.11312273328673476 | validation: 0.11449907225598074]
	TIME [epoch: 8.55 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14914491243446823		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.14914491243446823 | validation: 0.08937194328193573]
	TIME [epoch: 8.54 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1598894441660313		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.1598894441660313 | validation: 0.11258958601569502]
	TIME [epoch: 8.57 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1521476002299006		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.1521476002299006 | validation: 0.08669157373454436]
	TIME [epoch: 8.54 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557004913592287		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.1557004913592287 | validation: 0.1263432025100025]
	TIME [epoch: 8.54 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16092170044006784		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.16092170044006784 | validation: 0.15627418195997406]
	TIME [epoch: 8.56 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13371944430627616		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.13371944430627616 | validation: 0.05569712194677069]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12565828510946633		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.12565828510946633 | validation: 0.12138202453802172]
	TIME [epoch: 8.54 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12149324130249708		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.12149324130249708 | validation: 0.07967590345424974]
	TIME [epoch: 8.53 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14083559351439973		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.14083559351439973 | validation: 0.08624000479347071]
	TIME [epoch: 8.55 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13357486526833268		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.13357486526833268 | validation: 0.0978296031199857]
	TIME [epoch: 8.53 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19567730408733924		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.19567730408733924 | validation: 0.10875188146559953]
	TIME [epoch: 8.53 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15256909201331767		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.15256909201331767 | validation: 0.11157664766254774]
	TIME [epoch: 8.53 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1300699876374375		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.1300699876374375 | validation: 0.33046877468894853]
	TIME [epoch: 8.55 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15701809235167846		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.15701809235167846 | validation: 0.11337708322395729]
	TIME [epoch: 8.54 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09873628988777963		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.09873628988777963 | validation: 0.14387889959795197]
	TIME [epoch: 8.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12204812880994007		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.12204812880994007 | validation: 0.10807137311083533]
	TIME [epoch: 8.54 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17054479613204773		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.17054479613204773 | validation: 0.1221841356944928]
	TIME [epoch: 8.55 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14846940019941232		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.14846940019941232 | validation: 0.12096263088947876]
	TIME [epoch: 8.54 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1544040843997536		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.1544040843997536 | validation: 0.09531126550973365]
	TIME [epoch: 8.53 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281116847230917		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.1281116847230917 | validation: 0.09156367452348366]
	TIME [epoch: 8.53 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476728719276717		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.1476728719276717 | validation: 0.08529680422321012]
	TIME [epoch: 8.55 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10775828530814306		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.10775828530814306 | validation: 0.12589897098300054]
	TIME [epoch: 8.53 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11770311834237215		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.11770311834237215 | validation: 0.0924593173471601]
	TIME [epoch: 8.53 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1608793831661201		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.1608793831661201 | validation: 0.08150016724589583]
	TIME [epoch: 8.53 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13525053578256824		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.13525053578256824 | validation: 0.13809251500537326]
	TIME [epoch: 8.55 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11504751308483871		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.11504751308483871 | validation: 0.11835806437134039]
	TIME [epoch: 8.53 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837953343968494		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.1837953343968494 | validation: 0.08967193501085087]
	TIME [epoch: 8.53 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10815245513906188		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.10815245513906188 | validation: 0.11298847108340636]
	TIME [epoch: 8.53 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12854364123293818		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.12854364123293818 | validation: 0.12585930481829674]
	TIME [epoch: 8.55 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12900409791848125		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.12900409791848125 | validation: 0.144791387153422]
	TIME [epoch: 8.53 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14913268570941443		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.14913268570941443 | validation: 0.13325049486449558]
	TIME [epoch: 8.53 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12523058264617026		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.12523058264617026 | validation: 0.07842712535338538]
	TIME [epoch: 8.54 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14558698392492714		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.14558698392492714 | validation: 0.22255746607006427]
	TIME [epoch: 8.54 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16870237592860965		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.16870237592860965 | validation: 0.07126076831545146]
	TIME [epoch: 8.53 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11964150481738049		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.11964150481738049 | validation: 0.12730536970926337]
	TIME [epoch: 8.53 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11880374976892798		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.11880374976892798 | validation: 0.11001506997903585]
	TIME [epoch: 8.54 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13008865242383705		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.13008865242383705 | validation: 0.13499126826360952]
	TIME [epoch: 8.53 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1273724429766058		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.1273724429766058 | validation: 0.10521043814822856]
	TIME [epoch: 8.53 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15317182191555215		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.15317182191555215 | validation: 0.10849982253746107]
	TIME [epoch: 8.52 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16705546524203577		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.16705546524203577 | validation: 0.09853173502361931]
	TIME [epoch: 8.54 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20662370144839062		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.20662370144839062 | validation: 0.14133840775910683]
	TIME [epoch: 8.53 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15223356398270588		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.15223356398270588 | validation: 0.1756135072096171]
	TIME [epoch: 8.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10878479125648517		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.10878479125648517 | validation: 0.0919065901784369]
	TIME [epoch: 8.52 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12132950513540916		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.12132950513540916 | validation: 0.06939412424703569]
	TIME [epoch: 8.55 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373830799316229		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.1373830799316229 | validation: 0.17701087964022288]
	TIME [epoch: 8.53 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12540111188966996		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.12540111188966996 | validation: 0.06583266391891365]
	TIME [epoch: 8.53 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13352118775013638		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.13352118775013638 | validation: 0.08364628877247093]
	TIME [epoch: 8.52 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1368876086503336		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.1368876086503336 | validation: 0.06486039944887145]
	TIME [epoch: 8.55 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14223488259416456		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.14223488259416456 | validation: 0.09556947361710069]
	TIME [epoch: 8.53 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14672778664187383		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.14672778664187383 | validation: 0.14770675460430915]
	TIME [epoch: 8.53 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14349964518261998		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.14349964518261998 | validation: 0.09320689586490893]
	TIME [epoch: 8.53 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13287747912446246		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.13287747912446246 | validation: 0.09782967379346504]
	TIME [epoch: 8.54 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10247893923013243		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.10247893923013243 | validation: 0.061279075797978325]
	TIME [epoch: 8.53 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10892957625396923		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.10892957625396923 | validation: 0.24600122327828955]
	TIME [epoch: 8.52 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17776826467464907		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.17776826467464907 | validation: 0.13415064909971403]
	TIME [epoch: 8.53 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14253262713508857		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.14253262713508857 | validation: 0.08773162771929749]
	TIME [epoch: 8.54 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13555741440653016		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.13555741440653016 | validation: 0.10579392189119341]
	TIME [epoch: 8.53 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1174588644495154		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.1174588644495154 | validation: 0.10234172459325716]
	TIME [epoch: 8.52 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1198325715069271		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.1198325715069271 | validation: 0.12629392944877102]
	TIME [epoch: 8.53 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14004922248241589		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.14004922248241589 | validation: 0.09222953036158447]
	TIME [epoch: 8.55 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20526548642122117		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.20526548642122117 | validation: 0.13615599498012426]
	TIME [epoch: 8.53 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14501963765731554		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.14501963765731554 | validation: 0.14550827649539794]
	TIME [epoch: 8.52 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10561701214680756		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.10561701214680756 | validation: 0.05824121830748649]
	TIME [epoch: 8.53 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14995188620063313		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.14995188620063313 | validation: 0.16020275042092358]
	TIME [epoch: 8.55 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12971860624597334		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.12971860624597334 | validation: 0.11509117866696228]
	TIME [epoch: 8.53 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11658366002886629		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.11658366002886629 | validation: 0.1362155259839377]
	TIME [epoch: 8.52 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14500437740669575		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.14500437740669575 | validation: 0.11340751982306314]
	TIME [epoch: 8.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09756999311671803		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.09756999311671803 | validation: 0.09132210506932138]
	TIME [epoch: 8.54 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14648054967335625		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.14648054967335625 | validation: 0.08364548869057159]
	TIME [epoch: 8.53 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11810477092092882		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.11810477092092882 | validation: 0.11502632623827702]
	TIME [epoch: 8.53 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15872622116374646		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.15872622116374646 | validation: 0.11055247463853424]
	TIME [epoch: 8.55 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12681369636572076		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.12681369636572076 | validation: 0.07039498891631821]
	TIME [epoch: 8.54 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10970647737529451		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.10970647737529451 | validation: 0.07299722801805937]
	TIME [epoch: 8.53 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262759682923198		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.10262759682923198 | validation: 0.1861693506651041]
	TIME [epoch: 8.54 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1445133650039016		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.1445133650039016 | validation: 0.1606075370249941]
	TIME [epoch: 8.55 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710505705300276		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.12710505705300276 | validation: 0.17019630588030554]
	TIME [epoch: 8.53 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509024663727817		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.1509024663727817 | validation: 0.20625188831980854]
	TIME [epoch: 8.53 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1696011748302161		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.1696011748302161 | validation: 0.30198522142827633]
	TIME [epoch: 8.53 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22509306208595592		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.22509306208595592 | validation: 0.1784907123940076]
	TIME [epoch: 8.55 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15841773390052605		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.15841773390052605 | validation: 0.10477518430472285]
	TIME [epoch: 8.53 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13426183153796323		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.13426183153796323 | validation: 0.22017673822092254]
	TIME [epoch: 8.54 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20372752667272104		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.20372752667272104 | validation: 0.11388503035243339]
	TIME [epoch: 8.53 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12586220774468262		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.12586220774468262 | validation: 0.09375897421320911]
	TIME [epoch: 8.55 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15027599998564642		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.15027599998564642 | validation: 0.11232887613430603]
	TIME [epoch: 8.53 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16556138195817965		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.16556138195817965 | validation: 0.11703732835379535]
	TIME [epoch: 8.53 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12795363382799757		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.12795363382799757 | validation: 0.2122974080051956]
	TIME [epoch: 8.53 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16402555457200835		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.16402555457200835 | validation: 0.10864957819762386]
	TIME [epoch: 8.55 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1349689432907577		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.1349689432907577 | validation: 0.14344063924601433]
	TIME [epoch: 8.53 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11450778071776044		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.11450778071776044 | validation: 0.1013838373382038]
	TIME [epoch: 8.53 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11623538560577076		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.11623538560577076 | validation: 0.09976064235453466]
	TIME [epoch: 8.53 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1333527546157386		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.1333527546157386 | validation: 0.11663313079937546]
	TIME [epoch: 8.55 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13338531149979288		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.13338531149979288 | validation: 0.11290114693379323]
	TIME [epoch: 8.53 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12548318225953686		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.12548318225953686 | validation: 0.0975522833676788]
	TIME [epoch: 8.53 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1108942961118079		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.1108942961118079 | validation: 0.07484422586877731]
	TIME [epoch: 8.54 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11774529454536205		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.11774529454536205 | validation: 0.2010896785676236]
	TIME [epoch: 8.55 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13621383074170548		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.13621383074170548 | validation: 0.06891891252949953]
	TIME [epoch: 8.53 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11033720528694686		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.11033720528694686 | validation: 0.06272875862958074]
	TIME [epoch: 8.53 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12678958159774917		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.12678958159774917 | validation: 0.0854496215572085]
	TIME [epoch: 8.55 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11485904228682284		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.11485904228682284 | validation: 0.10520611258473314]
	TIME [epoch: 8.54 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13692363214070485		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.13692363214070485 | validation: 0.0709932898543599]
	TIME [epoch: 8.53 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10112180760771383		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.10112180760771383 | validation: 0.13113149075195013]
	TIME [epoch: 8.53 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10228055369974536		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.10228055369974536 | validation: 0.20957188317229006]
	TIME [epoch: 8.55 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12777074054644816		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.12777074054644816 | validation: 0.06762604513505512]
	TIME [epoch: 8.54 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10114289521487958		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.10114289521487958 | validation: 0.08486438879210137]
	TIME [epoch: 8.53 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.115277412284651		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.115277412284651 | validation: 0.11038171705961046]
	TIME [epoch: 8.53 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10536013470189771		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.10536013470189771 | validation: 0.09941539562179902]
	TIME [epoch: 8.55 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.100980053559322		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.100980053559322 | validation: 0.07665286819776132]
	TIME [epoch: 8.53 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.100020915196948		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.100020915196948 | validation: 0.10565605263127827]
	TIME [epoch: 8.53 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10013675097679357		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.10013675097679357 | validation: 0.0762283087854542]
	TIME [epoch: 8.53 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08747739930931477		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.08747739930931477 | validation: 0.0996239160757531]
	TIME [epoch: 8.55 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13322202732777816		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.13322202732777816 | validation: 0.05833663695483737]
	TIME [epoch: 8.53 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15084605896710812		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.15084605896710812 | validation: 0.1723108464248538]
	TIME [epoch: 8.53 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14509202757880194		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.14509202757880194 | validation: 0.08622890067407674]
	TIME [epoch: 8.53 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11996744377564386		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.11996744377564386 | validation: 0.10725572155276245]
	TIME [epoch: 8.55 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12394159872449273		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.12394159872449273 | validation: 0.0699774056397628]
	TIME [epoch: 8.53 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13672630684501497		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.13672630684501497 | validation: 0.11148160047671696]
	TIME [epoch: 8.53 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1195596599044785		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.1195596599044785 | validation: 0.068158063333678]
	TIME [epoch: 8.53 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11705448520586155		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.11705448520586155 | validation: 0.047922262317210404]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10805842903286114		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.10805842903286114 | validation: 0.0558015026750429]
	TIME [epoch: 8.54 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11163309500967011		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.11163309500967011 | validation: 0.08180781945671933]
	TIME [epoch: 8.53 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14264232741164157		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.14264232741164157 | validation: 0.09184780195677862]
	TIME [epoch: 8.54 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373271463234582		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.1373271463234582 | validation: 0.0957952367383903]
	TIME [epoch: 8.55 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14898208169013605		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.14898208169013605 | validation: 0.09405522945227533]
	TIME [epoch: 8.53 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11330437426069742		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.11330437426069742 | validation: 0.09499772471604338]
	TIME [epoch: 8.53 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09583869889236082		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.09583869889236082 | validation: 0.10527599688960185]
	TIME [epoch: 8.54 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13643961863198698		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.13643961863198698 | validation: 0.05774487139762435]
	TIME [epoch: 8.54 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15025944371986727		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.15025944371986727 | validation: 0.15410580413140396]
	TIME [epoch: 8.53 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16576253530413224		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.16576253530413224 | validation: 0.05342066363999666]
	TIME [epoch: 8.53 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472380740556304		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.10472380740556304 | validation: 0.07921233345624096]
	TIME [epoch: 8.55 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11362046807244822		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.11362046807244822 | validation: 0.08096397664606576]
	TIME [epoch: 8.54 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1164495199057077		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.1164495199057077 | validation: 0.15167317008978842]
	TIME [epoch: 8.54 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21296805939068028		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.21296805939068028 | validation: 0.11322848391957019]
	TIME [epoch: 8.53 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10459016403490529		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.10459016403490529 | validation: 0.08184606662794518]
	TIME [epoch: 8.55 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11162105980474506		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.11162105980474506 | validation: 0.15896305133097005]
	TIME [epoch: 8.54 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13893197280970135		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.13893197280970135 | validation: 0.09618396287574126]
	TIME [epoch: 8.53 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10679516160508262		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.10679516160508262 | validation: 0.0953198087138191]
	TIME [epoch: 8.53 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0843315652684304		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.0843315652684304 | validation: 0.09438216712689451]
	TIME [epoch: 8.55 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254470389837078		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.1254470389837078 | validation: 0.06428570231539088]
	TIME [epoch: 8.54 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10643948764787954		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.10643948764787954 | validation: 0.05125043916359684]
	TIME [epoch: 8.53 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10911253197301482		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.10911253197301482 | validation: 0.1350782865793067]
	TIME [epoch: 8.53 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14030579798598194		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.14030579798598194 | validation: 0.09901504378286376]
	TIME [epoch: 8.55 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09519976264434604		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.09519976264434604 | validation: 0.058568581520535096]
	TIME [epoch: 8.54 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1236548753962888		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.1236548753962888 | validation: 0.19253174350224628]
	TIME [epoch: 8.53 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18697263383239487		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.18697263383239487 | validation: 0.1333909605785572]
	TIME [epoch: 8.53 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143088603872616		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.08143088603872616 | validation: 0.06130468334411203]
	TIME [epoch: 8.55 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1198260284830025		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.1198260284830025 | validation: 0.11193989574768176]
	TIME [epoch: 8.53 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1036307299274358		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.1036307299274358 | validation: 0.10023539968647188]
	TIME [epoch: 8.53 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11077539468573801		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.11077539468573801 | validation: 0.12955673314280652]
	TIME [epoch: 8.53 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12099028868657598		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.12099028868657598 | validation: 0.09105931021203359]
	TIME [epoch: 8.55 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11677663744909779		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.11677663744909779 | validation: 0.08819736395889116]
	TIME [epoch: 8.53 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12049148288272923		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.12049148288272923 | validation: 0.1277129534128815]
	TIME [epoch: 8.53 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1092630373026409		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.1092630373026409 | validation: 0.11618155331275849]
	TIME [epoch: 8.53 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11529041265900344		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.11529041265900344 | validation: 0.09703767644967685]
	TIME [epoch: 8.55 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1321970073052464		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.1321970073052464 | validation: 0.12175379679100409]
	TIME [epoch: 8.53 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10926023584898684		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.10926023584898684 | validation: 0.0806072363971293]
	TIME [epoch: 8.53 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09489073116502253		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.09489073116502253 | validation: 0.09921215050566157]
	TIME [epoch: 8.54 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09690377999397129		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.09690377999397129 | validation: 0.07850490720566353]
	TIME [epoch: 8.54 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12420750066767158		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.12420750066767158 | validation: 0.1761137495276104]
	TIME [epoch: 8.53 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11144722019045636		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.11144722019045636 | validation: 0.09031836170957994]
	TIME [epoch: 8.53 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10355082460918505		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.10355082460918505 | validation: 0.216387772018235]
	TIME [epoch: 8.55 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10102407108207637		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.10102407108207637 | validation: 0.13921264188199223]
	TIME [epoch: 8.53 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12158911755034232		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.12158911755034232 | validation: 0.10716764699131491]
	TIME [epoch: 8.53 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08520430367291623		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.08520430367291623 | validation: 0.11306345205013373]
	TIME [epoch: 8.53 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730186601301558		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.10730186601301558 | validation: 0.07574610314943103]
	TIME [epoch: 8.55 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08919306092351448		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.08919306092351448 | validation: 0.08015842506193968]
	TIME [epoch: 8.53 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11276687464453734		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.11276687464453734 | validation: 0.0559908425814348]
	TIME [epoch: 8.53 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0794474972852602		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.0794474972852602 | validation: 0.06570268379060651]
	TIME [epoch: 8.53 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10510618487618033		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.10510618487618033 | validation: 0.08239141739358681]
	TIME [epoch: 8.55 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14201021260031854		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.14201021260031854 | validation: 0.07103026277711852]
	TIME [epoch: 8.54 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1030708083695884		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.1030708083695884 | validation: 0.14272756648644808]
	TIME [epoch: 8.53 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15624873833319536		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.15624873833319536 | validation: 0.1548993534359681]
	TIME [epoch: 8.53 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14835883033936068		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.14835883033936068 | validation: 0.15802743053150003]
	TIME [epoch: 8.55 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13966254331978992		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.13966254331978992 | validation: 0.10064246393308661]
	TIME [epoch: 8.54 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12757718757823816		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.12757718757823816 | validation: 0.07590598389414985]
	TIME [epoch: 8.53 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15091335213659146		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.15091335213659146 | validation: 0.06826141867834525]
	TIME [epoch: 8.53 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11442083465731671		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.11442083465731671 | validation: 0.059613572177620526]
	TIME [epoch: 8.54 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10026660091743016		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.10026660091743016 | validation: 0.06264033795711849]
	TIME [epoch: 8.54 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11305968225077548		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.11305968225077548 | validation: 0.06468407682161237]
	TIME [epoch: 8.53 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10616438567318731		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.10616438567318731 | validation: 0.08128443096628385]
	TIME [epoch: 8.53 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10386274740460004		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.10386274740460004 | validation: 0.04783771685709457]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1095.pth
	Model improved!!!
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09425156790683616		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.09425156790683616 | validation: 0.07607000312485833]
	TIME [epoch: 8.54 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10727949276258633		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.10727949276258633 | validation: 0.19367856240936437]
	TIME [epoch: 8.53 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12725048193599944		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.12725048193599944 | validation: 0.07430717548156261]
	TIME [epoch: 8.53 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10250509941752953		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.10250509941752953 | validation: 0.057512838728572914]
	TIME [epoch: 8.56 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11017333015159418		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.11017333015159418 | validation: 0.16884167970218344]
	TIME [epoch: 8.53 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10454951879553069		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.10454951879553069 | validation: 0.1473805234847935]
	TIME [epoch: 8.54 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10908917940761413		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.10908917940761413 | validation: 0.08238717764505374]
	TIME [epoch: 8.55 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09508271271879212		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.09508271271879212 | validation: 0.048618287731488796]
	TIME [epoch: 8.55 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1088859523719504		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.1088859523719504 | validation: 0.10655432228776096]
	TIME [epoch: 8.54 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1426834712719769		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.1426834712719769 | validation: 0.06937786653386108]
	TIME [epoch: 8.54 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11538013435436886		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.11538013435436886 | validation: 0.11885926709262906]
	TIME [epoch: 8.56 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09029796476781458		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.09029796476781458 | validation: 0.05630446232260604]
	TIME [epoch: 8.54 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09792304905073182		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.09792304905073182 | validation: 0.047145650814539586]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1108.pth
	Model improved!!!
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09498330175237397		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.09498330175237397 | validation: 0.04892706440730051]
	TIME [epoch: 8.53 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09252613092627725		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.09252613092627725 | validation: 0.06771445053062607]
	TIME [epoch: 8.55 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10810232515101177		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.10810232515101177 | validation: 0.07996733790968809]
	TIME [epoch: 8.53 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08830016557682366		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.08830016557682366 | validation: 0.08375225914817133]
	TIME [epoch: 8.53 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11632415386808029		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.11632415386808029 | validation: 0.1560282763915236]
	TIME [epoch: 8.53 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0956719824672511		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.0956719824672511 | validation: 0.09639696505013125]
	TIME [epoch: 8.55 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10050106473076145		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.10050106473076145 | validation: 0.08999538960490538]
	TIME [epoch: 8.54 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11977148511591465		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.11977148511591465 | validation: 0.13170821033378527]
	TIME [epoch: 8.53 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225074053615977		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.11225074053615977 | validation: 0.14186105177784802]
	TIME [epoch: 8.53 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12499431414483983		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.12499431414483983 | validation: 0.07515218029668189]
	TIME [epoch: 8.55 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09447577232551949		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.09447577232551949 | validation: 0.14866875607208146]
	TIME [epoch: 8.53 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11030093407134893		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.11030093407134893 | validation: 0.06855727020731497]
	TIME [epoch: 8.53 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1285057026687146		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.1285057026687146 | validation: 0.06005584723181974]
	TIME [epoch: 8.53 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10826959947511863		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.10826959947511863 | validation: 0.10251062527432397]
	TIME [epoch: 8.55 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11812139640742374		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.11812139640742374 | validation: 0.08990771419863476]
	TIME [epoch: 8.53 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10463529724992734		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.10463529724992734 | validation: 0.05184276960312971]
	TIME [epoch: 8.53 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09465674665703794		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.09465674665703794 | validation: 0.051295201128069276]
	TIME [epoch: 8.53 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08535541629902563		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.08535541629902563 | validation: 0.08182679990187833]
	TIME [epoch: 8.55 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08129684709474569		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.08129684709474569 | validation: 0.08568120754771114]
	TIME [epoch: 8.54 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1160066143443308		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.1160066143443308 | validation: 0.08403184765597373]
	TIME [epoch: 8.53 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10283073352412872		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.10283073352412872 | validation: 0.09214107208748604]
	TIME [epoch: 8.54 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11957702692827743		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.11957702692827743 | validation: 0.07551010596222953]
	TIME [epoch: 8.54 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09633075315084136		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.09633075315084136 | validation: 0.09131964809790538]
	TIME [epoch: 8.53 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16192294975563143		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.16192294975563143 | validation: 0.15978169548788834]
	TIME [epoch: 8.53 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12300564213267609		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.12300564213267609 | validation: 0.08402010220472643]
	TIME [epoch: 8.55 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15716520428706246		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.15716520428706246 | validation: 0.1497114162267544]
	TIME [epoch: 8.53 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10983061101878284		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.10983061101878284 | validation: 0.06878023389519214]
	TIME [epoch: 8.53 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0866952128323283		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.0866952128323283 | validation: 0.054101938211399477]
	TIME [epoch: 8.53 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720622052242082		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.08720622052242082 | validation: 0.060452387654573524]
	TIME [epoch: 8.55 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09844611666004557		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.09844611666004557 | validation: 0.07780809606468919]
	TIME [epoch: 8.54 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0844761979684061		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.0844761979684061 | validation: 0.04816863564550614]
	TIME [epoch: 8.54 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10669237720304243		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.10669237720304243 | validation: 0.08481618121254955]
	TIME [epoch: 8.53 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10862989591418568		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.10862989591418568 | validation: 0.06494963631657179]
	TIME [epoch: 8.55 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14309075476807154		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.14309075476807154 | validation: 0.11388811225319195]
	TIME [epoch: 8.53 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12621056624029875		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.12621056624029875 | validation: 0.09545772301884585]
	TIME [epoch: 8.53 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11194387652808739		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.11194387652808739 | validation: 0.09879440956535006]
	TIME [epoch: 8.53 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12274659225598217		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.12274659225598217 | validation: 0.15799996781435358]
	TIME [epoch: 8.55 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10497682960598295		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.10497682960598295 | validation: 0.08913034678351406]
	TIME [epoch: 8.54 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12215835027838502		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.12215835027838502 | validation: 0.05029665074967524]
	TIME [epoch: 8.53 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653675993974573		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.09653675993974573 | validation: 0.07727584210948865]
	TIME [epoch: 8.53 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11146764684038735		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.11146764684038735 | validation: 0.12115714212160714]
	TIME [epoch: 8.55 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10876638606856619		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.10876638606856619 | validation: 0.09640386548346648]
	TIME [epoch: 8.54 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10130794037060095		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.10130794037060095 | validation: 0.06714368852305394]
	TIME [epoch: 8.54 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08796148786556876		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.08796148786556876 | validation: 0.09624672906831938]
	TIME [epoch: 8.54 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10334262152936331		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.10334262152936331 | validation: 0.06795617028515419]
	TIME [epoch: 8.55 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09942996553731595		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.09942996553731595 | validation: 0.10181662684126999]
	TIME [epoch: 8.53 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12902126491036803		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.12902126491036803 | validation: 0.10446217270386282]
	TIME [epoch: 8.53 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10925961286236349		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.10925961286236349 | validation: 0.1164200022389272]
	TIME [epoch: 8.53 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1224125213907751		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.1224125213907751 | validation: 0.1136755576223549]
	TIME [epoch: 8.55 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1376508553608243		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.1376508553608243 | validation: 0.1304330137120447]
	TIME [epoch: 8.53 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08714563933533714		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.08714563933533714 | validation: 0.14574943144869734]
	TIME [epoch: 8.53 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11454567842763926		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.11454567842763926 | validation: 0.05792232970025363]
	TIME [epoch: 8.55 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0787592321922024		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.0787592321922024 | validation: 0.042966955039373415]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1161.pth
	Model improved!!!
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143654272423215		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.08143654272423215 | validation: 0.06573026571067941]
	TIME [epoch: 8.52 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1314077693901932		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.1314077693901932 | validation: 0.08171942070647406]
	TIME [epoch: 8.53 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14393940115074827		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.14393940115074827 | validation: 0.13580019293781456]
	TIME [epoch: 8.54 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09828892505582326		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.09828892505582326 | validation: 0.09169525141054063]
	TIME [epoch: 8.53 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858365183810664		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.0858365183810664 | validation: 0.17387249212348838]
	TIME [epoch: 8.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10869865119709399		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.10869865119709399 | validation: 0.09678146887156555]
	TIME [epoch: 8.53 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14298360898545315		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.14298360898545315 | validation: 0.1328324038000801]
	TIME [epoch: 8.54 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14907968596174853		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.14907968596174853 | validation: 0.10461460800400776]
	TIME [epoch: 8.53 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11716681575674663		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.11716681575674663 | validation: 0.08642424981871166]
	TIME [epoch: 8.53 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0874913644456306		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.0874913644456306 | validation: 0.045992097901500634]
	TIME [epoch: 8.52 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204715229586058		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.09204715229586058 | validation: 0.11586015833070294]
	TIME [epoch: 8.54 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09572683088611221		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.09572683088611221 | validation: 0.04021619346349859]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1173.pth
	Model improved!!!
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0972473055491903		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.0972473055491903 | validation: 0.06774810666685496]
	TIME [epoch: 8.53 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678725877725788		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.07678725877725788 | validation: 0.10304838578728734]
	TIME [epoch: 8.52 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10916918753069674		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.10916918753069674 | validation: 0.09350940040429233]
	TIME [epoch: 8.54 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09548514616740744		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.09548514616740744 | validation: 0.07774999131430374]
	TIME [epoch: 8.53 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12453104040805404		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.12453104040805404 | validation: 0.12381153115740935]
	TIME [epoch: 8.52 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11404150238707515		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.11404150238707515 | validation: 0.09953442217596113]
	TIME [epoch: 8.52 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0944040259991174		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.0944040259991174 | validation: 0.08133080123492203]
	TIME [epoch: 8.55 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707656816726538		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.08707656816726538 | validation: 0.16460110720929905]
	TIME [epoch: 8.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09989444804613629		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.09989444804613629 | validation: 0.06387707466681432]
	TIME [epoch: 8.51 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10288257954593616		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.10288257954593616 | validation: 0.07372139948249785]
	TIME [epoch: 8.53 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08930693319968146		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.08930693319968146 | validation: 0.06029785945252543]
	TIME [epoch: 8.54 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10214409086288881		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.10214409086288881 | validation: 0.10665801193272094]
	TIME [epoch: 8.53 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08537121462972769		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.08537121462972769 | validation: 0.05532444720410157]
	TIME [epoch: 8.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14170140469732434		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.14170140469732434 | validation: 0.09411827191489161]
	TIME [epoch: 8.53 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09503219050880601		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.09503219050880601 | validation: 0.06225739462063402]
	TIME [epoch: 8.53 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0754807727777598		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.0754807727777598 | validation: 0.060122244725071994]
	TIME [epoch: 8.53 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08333288069545892		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.08333288069545892 | validation: 0.05494307579193502]
	TIME [epoch: 8.53 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09804938891876072		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.09804938891876072 | validation: 0.04735784503499245]
	TIME [epoch: 8.54 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08486707742944977		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.08486707742944977 | validation: 0.04461472342371699]
	TIME [epoch: 8.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06527924685485442		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.06527924685485442 | validation: 0.036561785143545925]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1193.pth
	Model improved!!!
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10171451156320654		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.10171451156320654 | validation: 0.07066899769391469]
	TIME [epoch: 8.52 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08171249757499029		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.08171249757499029 | validation: 0.06710221213731767]
	TIME [epoch: 8.54 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627933379147763		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.11627933379147763 | validation: 0.09373621351014888]
	TIME [epoch: 8.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10000839465578056		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.10000839465578056 | validation: 0.08754477181513792]
	TIME [epoch: 8.52 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08766357725498748		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.08766357725498748 | validation: 0.07150871610243202]
	TIME [epoch: 8.52 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0815762602781223		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.0815762602781223 | validation: 0.11601928217436318]
	TIME [epoch: 8.53 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11377965208483479		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.11377965208483479 | validation: 0.044799046202886265]
	TIME [epoch: 8.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06219314395824956		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.06219314395824956 | validation: 0.06659618099611206]
	TIME [epoch: 8.52 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08456025438132511		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.08456025438132511 | validation: 0.07094042243011092]
	TIME [epoch: 8.53 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0950632081408876		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.0950632081408876 | validation: 0.072044661118532]
	TIME [epoch: 8.54 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06767354068901935		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.06767354068901935 | validation: 0.06243099570720631]
	TIME [epoch: 8.52 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08280323109174784		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.08280323109174784 | validation: 0.0769296431677254]
	TIME [epoch: 8.52 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10199623033013187		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.10199623033013187 | validation: 0.08241939389735381]
	TIME [epoch: 8.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10236769367437033		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.10236769367437033 | validation: 0.07452556302354466]
	TIME [epoch: 8.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09301295411093254		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.09301295411093254 | validation: 0.1344124845141546]
	TIME [epoch: 8.53 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09565484803929516		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.09565484803929516 | validation: 0.05215728977870278]
	TIME [epoch: 8.53 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07590891541404063		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.07590891541404063 | validation: 0.07704125826248677]
	TIME [epoch: 8.53 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12753054499219507		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.12753054499219507 | validation: 0.13685287049160894]
	TIME [epoch: 8.54 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11657583719943568		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.11657583719943568 | validation: 0.10183902791824334]
	TIME [epoch: 8.53 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08137806146911405		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.08137806146911405 | validation: 0.05950669987615766]
	TIME [epoch: 8.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08765412389543588		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.08765412389543588 | validation: 0.047077853504748246]
	TIME [epoch: 8.53 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09025481232296256		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.09025481232296256 | validation: 0.11694280093817011]
	TIME [epoch: 8.54 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10842901347441525		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.10842901347441525 | validation: 0.09971609422321859]
	TIME [epoch: 8.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09039532018654046		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.09039532018654046 | validation: 0.06255038102754318]
	TIME [epoch: 8.51 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0770224921150397		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.0770224921150397 | validation: 0.07647859537937471]
	TIME [epoch: 8.54 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09924882658448844		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.09924882658448844 | validation: 0.0591343142618999]
	TIME [epoch: 8.53 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09577361392467484		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.09577361392467484 | validation: 0.0734343754017212]
	TIME [epoch: 8.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07989588953221455		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.07989588953221455 | validation: 0.059839293361594464]
	TIME [epoch: 8.52 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09117204214367793		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.09117204214367793 | validation: 0.04725956449015857]
	TIME [epoch: 8.53 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141946134642142		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.1141946134642142 | validation: 0.056865643926486936]
	TIME [epoch: 8.53 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273776073286552		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.09273776073286552 | validation: 0.08564834105947972]
	TIME [epoch: 8.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09029699610757447		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.09029699610757447 | validation: 0.09125643062588171]
	TIME [epoch: 8.53 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08851480489473952		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.08851480489473952 | validation: 0.05340049076711084]
	TIME [epoch: 8.54 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09461566822974952		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.09461566822974952 | validation: 0.058917205095086356]
	TIME [epoch: 8.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08910388247324755		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.08910388247324755 | validation: 0.06171063829122102]
	TIME [epoch: 8.52 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07597862512063802		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.07597862512063802 | validation: 0.05864798830391482]
	TIME [epoch: 8.52 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10645309216683727		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.10645309216683727 | validation: 0.07330555542306827]
	TIME [epoch: 8.54 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868797939236366		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.08868797939236366 | validation: 0.0885882796846123]
	TIME [epoch: 8.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0882203009129979		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.0882203009129979 | validation: 0.06650231090556534]
	TIME [epoch: 8.52 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07295832142110423		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.07295832142110423 | validation: 0.037277249610088055]
	TIME [epoch: 8.52 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07649798324416643		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.07649798324416643 | validation: 0.06348831766468915]
	TIME [epoch: 8.54 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0612297347100975		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.0612297347100975 | validation: 0.052640420560187716]
	TIME [epoch: 8.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10905878950509504		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.10905878950509504 | validation: 0.07524109020442846]
	TIME [epoch: 8.51 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09340817871735554		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.09340817871735554 | validation: 0.07981531358200444]
	TIME [epoch: 8.52 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0857090958605617		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.0857090958605617 | validation: 0.04947173040718847]
	TIME [epoch: 8.54 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814694241672345		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.0814694241672345 | validation: 0.08530792932005127]
	TIME [epoch: 8.52 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08491351955052266		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.08491351955052266 | validation: 0.0625002182751578]
	TIME [epoch: 8.52 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10542529126145632		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.10542529126145632 | validation: 0.05303816754751019]
	TIME [epoch: 8.52 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07393951442955345		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.07393951442955345 | validation: 0.12215515549578443]
	TIME [epoch: 8.54 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11820730646332978		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.11820730646332978 | validation: 0.0701291154574492]
	TIME [epoch: 8.53 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08358545825762165		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.08358545825762165 | validation: 0.05418051554701271]
	TIME [epoch: 8.52 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07808316597102546		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.07808316597102546 | validation: 0.08993859750001329]
	TIME [epoch: 8.52 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723775697107111		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.0723775697107111 | validation: 0.03903042265139832]
	TIME [epoch: 8.55 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06953701017590823		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.06953701017590823 | validation: 0.054550696784780486]
	TIME [epoch: 8.52 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09046340614230987		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.09046340614230987 | validation: 0.07082788353517017]
	TIME [epoch: 8.53 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07024593557836993		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.07024593557836993 | validation: 0.034134475608594575]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1249.pth
	Model improved!!!
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175903474985199		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.07175903474985199 | validation: 0.04717603039061667]
	TIME [epoch: 8.78 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06943870540177599		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.06943870540177599 | validation: 0.06147325530706553]
	TIME [epoch: 8.54 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.086422160922469		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.086422160922469 | validation: 0.08653538560849311]
	TIME [epoch: 8.54 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09416073453321079		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.09416073453321079 | validation: 0.08872807400491439]
	TIME [epoch: 8.55 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08694783602613712		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.08694783602613712 | validation: 0.04968606924730126]
	TIME [epoch: 8.54 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08736893158087866		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.08736893158087866 | validation: 0.09374349906987105]
	TIME [epoch: 8.54 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0784366170053353		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.0784366170053353 | validation: 0.047814181190072004]
	TIME [epoch: 8.54 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07881460291185766		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.07881460291185766 | validation: 0.11769398861962621]
	TIME [epoch: 8.55 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09780029719443173		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.09780029719443173 | validation: 0.05852339792724488]
	TIME [epoch: 8.54 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08486168451625929		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.08486168451625929 | validation: 0.09927907747509121]
	TIME [epoch: 8.54 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08794903271553398		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.08794903271553398 | validation: 0.0669921006023867]
	TIME [epoch: 8.54 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08101274136484485		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.08101274136484485 | validation: 0.11342857093945335]
	TIME [epoch: 8.56 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10805661490706922		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.10805661490706922 | validation: 0.09244660305830493]
	TIME [epoch: 8.54 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14354622994337715		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.14354622994337715 | validation: 0.053057255454262875]
	TIME [epoch: 8.54 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07512728372196337		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.07512728372196337 | validation: 0.04569491550484618]
	TIME [epoch: 8.54 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09061850126419738		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.09061850126419738 | validation: 0.09187441241574715]
	TIME [epoch: 8.56 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09911862673919415		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.09911862673919415 | validation: 0.0643894057518266]
	TIME [epoch: 8.54 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07102901834863731		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.07102901834863731 | validation: 0.0866872525528921]
	TIME [epoch: 8.54 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07494388008527413		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.07494388008527413 | validation: 0.05291517171357945]
	TIME [epoch: 8.54 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392611559844581		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.07392611559844581 | validation: 0.04426786632358588]
	TIME [epoch: 8.56 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407059433686092		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.07407059433686092 | validation: 0.07909790919982151]
	TIME [epoch: 8.54 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09530120987383535		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.09530120987383535 | validation: 0.0703887112223284]
	TIME [epoch: 8.54 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982558045737682		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.06982558045737682 | validation: 0.05356125059678195]
	TIME [epoch: 8.54 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066011532370449		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.066011532370449 | validation: 0.06790732342144754]
	TIME [epoch: 8.56 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08581593983421476		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.08581593983421476 | validation: 0.10324912584202767]
	TIME [epoch: 8.54 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09381889754690369		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.09381889754690369 | validation: 0.0852918313854319]
	TIME [epoch: 8.54 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09307152276657568		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.09307152276657568 | validation: 0.09319142169266734]
	TIME [epoch: 8.55 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08449902212472096		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.08449902212472096 | validation: 0.08085978292956311]
	TIME [epoch: 8.55 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07005196099762279		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.07005196099762279 | validation: 0.07658713400464698]
	TIME [epoch: 8.54 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07048590412598377		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.07048590412598377 | validation: 0.05725648760348814]
	TIME [epoch: 8.54 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08664318661197731		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.08664318661197731 | validation: 0.0983073718912984]
	TIME [epoch: 8.56 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10702422398157092		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.10702422398157092 | validation: 0.09261664480371176]
	TIME [epoch: 8.55 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378661233398044		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.12378661233398044 | validation: 0.13186253455276262]
	TIME [epoch: 8.54 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11969682969882964		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.11969682969882964 | validation: 0.09530370398384988]
	TIME [epoch: 8.54 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10003307999325535		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.10003307999325535 | validation: 0.05196831725288468]
	TIME [epoch: 8.56 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661949889236547		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.07661949889236547 | validation: 0.07106630408954989]
	TIME [epoch: 8.54 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10996943728031436		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.10996943728031436 | validation: 0.07151443025865782]
	TIME [epoch: 8.54 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07617760334554416		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.07617760334554416 | validation: 0.032778937344067255]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1287.pth
	Model improved!!!
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09414536278162258		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.09414536278162258 | validation: 0.09073158858160632]
	TIME [epoch: 8.55 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460053521965137		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.09460053521965137 | validation: 0.1265819887814745]
	TIME [epoch: 8.53 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10725260845586745		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.10725260845586745 | validation: 0.0889017909316085]
	TIME [epoch: 8.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08996726946349985		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.08996726946349985 | validation: 0.07122427857480121]
	TIME [epoch: 8.53 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07668520833409047		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.07668520833409047 | validation: 0.06175520965251785]
	TIME [epoch: 8.55 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07695965156215848		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.07695965156215848 | validation: 0.04889336598967786]
	TIME [epoch: 8.54 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0734921523241697		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.0734921523241697 | validation: 0.09363855747279756]
	TIME [epoch: 8.53 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08357586888952809		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.08357586888952809 | validation: 0.04022812652523575]
	TIME [epoch: 8.54 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706177690568477		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.08706177690568477 | validation: 0.05187255547400964]
	TIME [epoch: 8.56 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852500365126231		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.0852500365126231 | validation: 0.05592916118503502]
	TIME [epoch: 8.53 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10433512162734235		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.10433512162734235 | validation: 0.07010399424141832]
	TIME [epoch: 8.53 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07663968203586555		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.07663968203586555 | validation: 0.049775794607184065]
	TIME [epoch: 8.53 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08038086386801838		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.08038086386801838 | validation: 0.05700165062239484]
	TIME [epoch: 8.55 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07607849863282186		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.07607849863282186 | validation: 0.07960784926043224]
	TIME [epoch: 8.53 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10725685232712864		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.10725685232712864 | validation: 0.11429867900230771]
	TIME [epoch: 8.52 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0763106400342492		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.0763106400342492 | validation: 0.0642922642403592]
	TIME [epoch: 8.53 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06701736885760479		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.06701736885760479 | validation: 0.04785710921243394]
	TIME [epoch: 8.55 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07992870014291587		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.07992870014291587 | validation: 0.05272199098431883]
	TIME [epoch: 8.53 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07753173358537281		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.07753173358537281 | validation: 0.05330564594177793]
	TIME [epoch: 8.53 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770228318429208		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.07770228318429208 | validation: 0.101418310470172]
	TIME [epoch: 8.54 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08989997785529967		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.08989997785529967 | validation: 0.10088371028383686]
	TIME [epoch: 8.53 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1015206331463437		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.1015206331463437 | validation: 0.07838767084863536]
	TIME [epoch: 8.53 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11186752360355692		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.11186752360355692 | validation: 0.17594499083601864]
	TIME [epoch: 8.53 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14175893525065014		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.14175893525065014 | validation: 0.0873810028269941]
	TIME [epoch: 8.55 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09898117131208524		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.09898117131208524 | validation: 0.08229412418961685]
	TIME [epoch: 8.55 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07687775145557903		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.07687775145557903 | validation: 0.07389043365176529]
	TIME [epoch: 8.53 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08756535938366594		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.08756535938366594 | validation: 0.05723058984403606]
	TIME [epoch: 8.52 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1024546686875091		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.1024546686875091 | validation: 0.043766274515851716]
	TIME [epoch: 8.54 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10156391681183372		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.10156391681183372 | validation: 0.0785535442032525]
	TIME [epoch: 8.53 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08384727412911286		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.08384727412911286 | validation: 0.06280954073997944]
	TIME [epoch: 8.53 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07665773519757113		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.07665773519757113 | validation: 0.09190003750048134]
	TIME [epoch: 8.52 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08148376621582812		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.08148376621582812 | validation: 0.07526797370221647]
	TIME [epoch: 8.54 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0660754010756164		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.0660754010756164 | validation: 0.03345101593471032]
	TIME [epoch: 8.53 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08125795361770881		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.08125795361770881 | validation: 0.07543106005868]
	TIME [epoch: 8.52 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0693336801108793		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.0693336801108793 | validation: 0.061042321837400146]
	TIME [epoch: 8.52 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08503214821498725		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.08503214821498725 | validation: 0.06661817396944211]
	TIME [epoch: 8.54 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0913819409179701		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.0913819409179701 | validation: 0.0912401703704987]
	TIME [epoch: 8.53 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07732577176149483		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.07732577176149483 | validation: 0.04840330310821546]
	TIME [epoch: 8.52 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07397486093220713		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.07397486093220713 | validation: 0.05141668847267025]
	TIME [epoch: 8.53 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06987977757980603		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.06987977757980603 | validation: 0.04703705795748099]
	TIME [epoch: 8.54 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061510480239412704		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.061510480239412704 | validation: 0.10190718262384965]
	TIME [epoch: 8.53 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10428446781950493		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.10428446781950493 | validation: 0.07548179644427228]
	TIME [epoch: 8.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09826906119598128		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.09826906119598128 | validation: 0.08841472277987189]
	TIME [epoch: 8.53 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10848779045931678		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.10848779045931678 | validation: 0.04720813189954063]
	TIME [epoch: 8.54 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09086812658939325		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.09086812658939325 | validation: 0.05206115307836419]
	TIME [epoch: 8.53 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06840597047149835		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.06840597047149835 | validation: 0.05589165415031011]
	TIME [epoch: 8.52 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06647835224630291		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.06647835224630291 | validation: 0.09387633458454918]
	TIME [epoch: 8.53 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07304543383639157		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.07304543383639157 | validation: 0.032212609929775426]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1335.pth
	Model improved!!!
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06753836045734236		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.06753836045734236 | validation: 0.049261382714056445]
	TIME [epoch: 8.53 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08579029759579963		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.08579029759579963 | validation: 0.09058393179032886]
	TIME [epoch: 8.53 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09491256489757627		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.09491256489757627 | validation: 0.10187808206793159]
	TIME [epoch: 8.54 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08732372365760097		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.08732372365760097 | validation: 0.09167174909999926]
	TIME [epoch: 8.53 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07561597854925618		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.07561597854925618 | validation: 0.0586346308930421]
	TIME [epoch: 8.53 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07735854215394102		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.07735854215394102 | validation: 0.07607607974994685]
	TIME [epoch: 8.52 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060325468352415444		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.060325468352415444 | validation: 0.05628535212456774]
	TIME [epoch: 8.54 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07159375147829468		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.07159375147829468 | validation: 0.05783512419137552]
	TIME [epoch: 8.53 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09958514184885063		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.09958514184885063 | validation: 0.03223485654355071]
	TIME [epoch: 8.53 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06578589552192944		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.06578589552192944 | validation: 0.09833833621826668]
	TIME [epoch: 8.53 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446935161465348		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.06446935161465348 | validation: 0.03405990746912163]
	TIME [epoch: 8.55 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06275569089804951		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.06275569089804951 | validation: 0.06220132538342791]
	TIME [epoch: 8.54 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0698809123608503		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.0698809123608503 | validation: 0.0640734306499957]
	TIME [epoch: 8.54 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08171988032619883		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.08171988032619883 | validation: 0.06899787334431401]
	TIME [epoch: 8.54 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09476421923218319		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.09476421923218319 | validation: 0.04462247500268186]
	TIME [epoch: 8.55 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10346559035936727		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.10346559035936727 | validation: 0.07097036324452344]
	TIME [epoch: 8.54 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07705323775153824		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.07705323775153824 | validation: 0.04732888935911905]
	TIME [epoch: 8.53 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666169490156108		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.06666169490156108 | validation: 0.06337873469856421]
	TIME [epoch: 8.54 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06134794374903859		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.06134794374903859 | validation: 0.05589932611024659]
	TIME [epoch: 8.55 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06201204383235122		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.06201204383235122 | validation: 0.08025230151751121]
	TIME [epoch: 8.54 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06294572526123128		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.06294572526123128 | validation: 0.029891366808576014]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1356.pth
	Model improved!!!
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06801412517173036		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.06801412517173036 | validation: 0.06690432429082847]
	TIME [epoch: 8.52 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832753982979215		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.0832753982979215 | validation: 0.044786392870142855]
	TIME [epoch: 8.54 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07063428513669816		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.07063428513669816 | validation: 0.06255094419818173]
	TIME [epoch: 8.52 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06853597688776342		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.06853597688776342 | validation: 0.061683557655798624]
	TIME [epoch: 8.52 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06981603648655779		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.06981603648655779 | validation: 0.0629222594456609]
	TIME [epoch: 8.52 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0630710558703903		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.0630710558703903 | validation: 0.07268699794638725]
	TIME [epoch: 8.54 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08092827502818886		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.08092827502818886 | validation: 0.06854991745732789]
	TIME [epoch: 8.52 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10184315341687318		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.10184315341687318 | validation: 0.07894045287646012]
	TIME [epoch: 8.52 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0776730735975991		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.0776730735975991 | validation: 0.06773192783784121]
	TIME [epoch: 8.53 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08692736262161602		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.08692736262161602 | validation: 0.059202146541394884]
	TIME [epoch: 8.53 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06538771398466336		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.06538771398466336 | validation: 0.10491511240320114]
	TIME [epoch: 8.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06548401856624833		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.06548401856624833 | validation: 0.03099833232232163]
	TIME [epoch: 8.52 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277379783393041		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.07277379783393041 | validation: 0.07522238127104691]
	TIME [epoch: 8.54 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0801681871512872		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.0801681871512872 | validation: 0.09045586471861794]
	TIME [epoch: 8.52 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11694891772120966		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.11694891772120966 | validation: 0.08813192277763629]
	TIME [epoch: 8.52 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07537328083086844		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.07537328083086844 | validation: 0.036999267436045244]
	TIME [epoch: 8.53 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09331908461127425		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.09331908461127425 | validation: 0.13259224644034537]
	TIME [epoch: 8.54 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10425871140961748		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.10425871140961748 | validation: 0.051815094999124275]
	TIME [epoch: 8.53 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07907898797573101		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.07907898797573101 | validation: 0.05235397954888545]
	TIME [epoch: 8.52 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07762871323547006		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.07762871323547006 | validation: 0.05086674418593129]
	TIME [epoch: 8.52 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07345003674217296		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.07345003674217296 | validation: 0.032087201391947436]
	TIME [epoch: 8.54 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062486652100299314		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.062486652100299314 | validation: 0.02938670662972598]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1378.pth
	Model improved!!!
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223327825239929		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.08223327825239929 | validation: 0.0851632375785357]
	TIME [epoch: 8.53 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06876786847061535		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.06876786847061535 | validation: 0.060434146223748916]
	TIME [epoch: 8.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06373180649465524		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.06373180649465524 | validation: 0.04506116701862513]
	TIME [epoch: 8.54 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07611137000168851		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.07611137000168851 | validation: 0.07374549452024046]
	TIME [epoch: 8.53 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06788147560037158		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.06788147560037158 | validation: 0.04363427635693379]
	TIME [epoch: 8.52 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05895820097625633		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.05895820097625633 | validation: 0.05960284356507768]
	TIME [epoch: 8.52 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06923087045104134		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.06923087045104134 | validation: 0.054178993067427905]
	TIME [epoch: 8.54 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08657364520810751		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.08657364520810751 | validation: 0.07125898945340578]
	TIME [epoch: 8.53 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11184055915876141		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.11184055915876141 | validation: 0.06426401929010235]
	TIME [epoch: 8.52 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0922932108105711		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.0922932108105711 | validation: 0.061489383005199336]
	TIME [epoch: 8.52 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0693546392393146		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.0693546392393146 | validation: 0.0514989243868063]
	TIME [epoch: 8.54 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06774578017415275		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.06774578017415275 | validation: 0.05651003821428606]
	TIME [epoch: 8.53 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08294536075723802		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.08294536075723802 | validation: 0.03532957638661517]
	TIME [epoch: 8.52 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055484341820944104		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.055484341820944104 | validation: 0.03238751412265481]
	TIME [epoch: 8.53 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05280223065033919		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.05280223065033919 | validation: 0.046654046741265325]
	TIME [epoch: 8.54 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06627858879569837		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.06627858879569837 | validation: 0.0478405173001622]
	TIME [epoch: 8.52 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204501003924113		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.09204501003924113 | validation: 0.06340938862418953]
	TIME [epoch: 8.52 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434110955687089		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.06434110955687089 | validation: 0.05811996446956709]
	TIME [epoch: 8.53 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291436370038809		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.07291436370038809 | validation: 0.06527283899428055]
	TIME [epoch: 8.53 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07692730078998897		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.07692730078998897 | validation: 0.09274360602459615]
	TIME [epoch: 8.52 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08273250708144954		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.08273250708144954 | validation: 0.09418566400561379]
	TIME [epoch: 8.52 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10426959418161226		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.10426959418161226 | validation: 0.06326127916308324]
	TIME [epoch: 8.54 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1006827594896857		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.1006827594896857 | validation: 0.0652310414201567]
	TIME [epoch: 8.52 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07336158112849653		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.07336158112849653 | validation: 0.041966086918165155]
	TIME [epoch: 8.52 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09296901574283915		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.09296901574283915 | validation: 0.08656159170081341]
	TIME [epoch: 8.52 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0935671310668957		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.0935671310668957 | validation: 0.059045565331960356]
	TIME [epoch: 8.54 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05691996802723197		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.05691996802723197 | validation: 0.04937911546309087]
	TIME [epoch: 8.52 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06642678448230713		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.06642678448230713 | validation: 0.06263958221985802]
	TIME [epoch: 8.52 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08617742264062137		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.08617742264062137 | validation: 0.06277784372852899]
	TIME [epoch: 8.52 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08750880248329329		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.08750880248329329 | validation: 0.06252850570759616]
	TIME [epoch: 8.54 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07209985815490093		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.07209985815490093 | validation: 0.04178751108385713]
	TIME [epoch: 8.53 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05716161705114982		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.05716161705114982 | validation: 0.04002575227307899]
	TIME [epoch: 8.53 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05056282034872939		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.05056282034872939 | validation: 0.05471939494508263]
	TIME [epoch: 8.52 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05890805177763836		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.05890805177763836 | validation: 0.037384005991195096]
	TIME [epoch: 8.54 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06331997495219856		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.06331997495219856 | validation: 0.03047309377657384]
	TIME [epoch: 8.52 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06035528660998731		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.06035528660998731 | validation: 0.04499866898590329]
	TIME [epoch: 8.52 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06483676482657062		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.06483676482657062 | validation: 0.08062092839958883]
	TIME [epoch: 8.52 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06404351360161911		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.06404351360161911 | validation: 0.04444093536222679]
	TIME [epoch: 8.54 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057394206491674926		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.057394206491674926 | validation: 0.037516379566593434]
	TIME [epoch: 8.52 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0718399299922717		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.0718399299922717 | validation: 0.08483450634773407]
	TIME [epoch: 8.52 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09300888859244652		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.09300888859244652 | validation: 0.03998650900461387]
	TIME [epoch: 8.52 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657545572936222		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.0657545572936222 | validation: 0.07731222129180985]
	TIME [epoch: 8.54 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0658145778502072		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.0658145778502072 | validation: 0.04251293056520128]
	TIME [epoch: 8.52 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04726668355869613		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.04726668355869613 | validation: 0.06593294877803971]
	TIME [epoch: 8.52 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06365512099200228		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.06365512099200228 | validation: 0.056797041147814586]
	TIME [epoch: 8.52 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0776547668048118		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.0776547668048118 | validation: 0.09497741992250866]
	TIME [epoch: 8.54 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08754588888645487		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.08754588888645487 | validation: 0.04249207913034357]
	TIME [epoch: 8.52 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06348741820077393		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.06348741820077393 | validation: 0.04335634834349238]
	TIME [epoch: 8.52 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06492749438837496		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.06492749438837496 | validation: 0.05940516518911798]
	TIME [epoch: 8.53 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058106979386554236		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.058106979386554236 | validation: 0.04161940329839327]
	TIME [epoch: 8.53 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07478919796903036		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.07478919796903036 | validation: 0.06768349496424134]
	TIME [epoch: 8.52 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812384100844406		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.07812384100844406 | validation: 0.04425120766674737]
	TIME [epoch: 8.52 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056810190867924604		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.056810190867924604 | validation: 0.034345531715293975]
	TIME [epoch: 8.54 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06637354228267325		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.06637354228267325 | validation: 0.02622878186709125]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1432.pth
	Model improved!!!
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06182593871473191		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.06182593871473191 | validation: 0.03977546736486198]
	TIME [epoch: 8.52 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06487595474257438		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.06487595474257438 | validation: 0.03874149090497417]
	TIME [epoch: 8.52 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407694548301143		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.07407694548301143 | validation: 0.049355889624364276]
	TIME [epoch: 8.53 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06183292902647969		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.06183292902647969 | validation: 0.03240884006412974]
	TIME [epoch: 8.52 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05835614455078343		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.05835614455078343 | validation: 0.028166306645416042]
	TIME [epoch: 8.52 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06099424740700508		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.06099424740700508 | validation: 0.05513038648807372]
	TIME [epoch: 8.52 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993618489380846		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.05993618489380846 | validation: 0.03817759947038272]
	TIME [epoch: 8.54 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06191371250356882		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.06191371250356882 | validation: 0.05233735231005609]
	TIME [epoch: 8.52 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06405304515268044		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.06405304515268044 | validation: 0.050772893999797765]
	TIME [epoch: 8.52 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06672713996321007		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.06672713996321007 | validation: 0.061690725034388834]
	TIME [epoch: 8.52 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061120011529844406		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.061120011529844406 | validation: 0.06487671585501036]
	TIME [epoch: 8.54 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0708789776722286		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.0708789776722286 | validation: 0.052816968391814725]
	TIME [epoch: 8.52 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691387797745694		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.07691387797745694 | validation: 0.15061657288186406]
	TIME [epoch: 8.52 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10522312804045453		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.10522312804045453 | validation: 0.055825901173147244]
	TIME [epoch: 8.52 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06397507475618057		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.06397507475618057 | validation: 0.05011970784966945]
	TIME [epoch: 8.53 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061623983625387554		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.061623983625387554 | validation: 0.06560644921674744]
	TIME [epoch: 8.51 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07115513660313869		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.07115513660313869 | validation: 0.08731374375413145]
	TIME [epoch: 8.52 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07575356047357007		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.07575356047357007 | validation: 0.04607832332684246]
	TIME [epoch: 8.52 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07891022028378594		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.07891022028378594 | validation: 0.0696259918755369]
	TIME [epoch: 8.54 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0671304494543666		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.0671304494543666 | validation: 0.0493302696291882]
	TIME [epoch: 8.52 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06570828791590586		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.06570828791590586 | validation: 0.04431550406805286]
	TIME [epoch: 8.51 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06772255711162734		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.06772255711162734 | validation: 0.05406472202218282]
	TIME [epoch: 8.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124013962820916		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.06124013962820916 | validation: 0.03978786189311912]
	TIME [epoch: 8.53 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07557082955981141		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.07557082955981141 | validation: 0.06527793505067332]
	TIME [epoch: 8.51 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06476354363693812		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.06476354363693812 | validation: 0.04137596886944247]
	TIME [epoch: 8.52 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903030999489972		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.05903030999489972 | validation: 0.03279448137652273]
	TIME [epoch: 8.54 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05508718717305211		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.05508718717305211 | validation: 0.04832384552268122]
	TIME [epoch: 8.52 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07454892327134637		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.07454892327134637 | validation: 0.04856621325012545]
	TIME [epoch: 8.52 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378095102787681		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.06378095102787681 | validation: 0.04138623478684039]
	TIME [epoch: 8.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047115717918993924		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.047115717918993924 | validation: 0.03049450078621009]
	TIME [epoch: 8.54 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489534910717194		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.06489534910717194 | validation: 0.04978686013765143]
	TIME [epoch: 8.52 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721086300931104		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.0721086300931104 | validation: 0.07164666600028205]
	TIME [epoch: 8.52 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06998711011747857		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.06998711011747857 | validation: 0.039199170124605415]
	TIME [epoch: 8.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06153467533043292		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.06153467533043292 | validation: 0.06710355059383037]
	TIME [epoch: 8.53 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07499150307071425		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.07499150307071425 | validation: 0.05446524959841549]
	TIME [epoch: 8.52 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372773764027776		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.07372773764027776 | validation: 0.061226110147303024]
	TIME [epoch: 8.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08022988636755317		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.08022988636755317 | validation: 0.05481903009285834]
	TIME [epoch: 8.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09285715640520971		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.09285715640520971 | validation: 0.08158461289664337]
	TIME [epoch: 8.54 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556565271745899		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.07556565271745899 | validation: 0.050737335258543334]
	TIME [epoch: 8.52 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050954126560444415		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.050954126560444415 | validation: 0.041282878731110154]
	TIME [epoch: 8.52 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04932938869749195		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.04932938869749195 | validation: 0.06813299226122907]
	TIME [epoch: 8.52 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0582127286967315		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.0582127286967315 | validation: 0.04588904345732768]
	TIME [epoch: 8.54 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06269571435567108		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.06269571435567108 | validation: 0.04416626468783325]
	TIME [epoch: 8.52 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05417500664862344		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.05417500664862344 | validation: 0.06960173867166661]
	TIME [epoch: 8.52 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545307135511588		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.06545307135511588 | validation: 0.06925101611059958]
	TIME [epoch: 8.52 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06870701984686885		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.06870701984686885 | validation: 0.034703947691213086]
	TIME [epoch: 8.54 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06037204871961395		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.06037204871961395 | validation: 0.049110363340177654]
	TIME [epoch: 8.52 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05681806647958583		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.05681806647958583 | validation: 0.048089317358944776]
	TIME [epoch: 8.52 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408046357255708		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.06408046357255708 | validation: 0.11265337720674087]
	TIME [epoch: 8.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398218732384449		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.08398218732384449 | validation: 0.04192195745302015]
	TIME [epoch: 8.54 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06809945291429871		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.06809945291429871 | validation: 0.07163327329891118]
	TIME [epoch: 8.52 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060847139782476425		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.060847139782476425 | validation: 0.034829448705755515]
	TIME [epoch: 8.52 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913182970444795		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.05913182970444795 | validation: 0.051686166875389974]
	TIME [epoch: 8.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05145819109064602		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.05145819109064602 | validation: 0.05863944823833771]
	TIME [epoch: 8.54 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06960543692119935		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.06960543692119935 | validation: 0.05587474273656718]
	TIME [epoch: 8.52 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654702472139772		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.0654702472139772 | validation: 0.06849510955117577]
	TIME [epoch: 8.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060538943438260315		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.060538943438260315 | validation: 0.02826195578900123]
	TIME [epoch: 8.53 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057167962657648244		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.057167962657648244 | validation: 0.044318712334800066]
	TIME [epoch: 8.53 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06357505970390218		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.06357505970390218 | validation: 0.02935890723147087]
	TIME [epoch: 8.52 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052712203769381585		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.052712203769381585 | validation: 0.04426140349686751]
	TIME [epoch: 8.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05090047192969325		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.05090047192969325 | validation: 0.06614623087407702]
	TIME [epoch: 8.54 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053109670211903916		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.053109670211903916 | validation: 0.0642611477034334]
	TIME [epoch: 8.52 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06056853596092069		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.06056853596092069 | validation: 0.04359748680194675]
	TIME [epoch: 8.52 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05708711856584758		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.05708711856584758 | validation: 0.024702462725431855]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1496.pth
	Model improved!!!
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05557980624930211		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.05557980624930211 | validation: 0.034819680766369064]
	TIME [epoch: 8.54 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05133305751494714		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.05133305751494714 | validation: 0.05623685305413133]
	TIME [epoch: 8.52 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05810440767234235		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.05810440767234235 | validation: 0.024483237182691638]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1499.pth
	Model improved!!!
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541603904727726		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.0541603904727726 | validation: 0.047943978422277066]
	TIME [epoch: 8.52 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04756184518468437		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.04756184518468437 | validation: 0.02093250909749644]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1501.pth
	Model improved!!!
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05237777622339614		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.05237777622339614 | validation: 0.05336201243982591]
	TIME [epoch: 8.53 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054024922288456664		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.054024922288456664 | validation: 0.03201782052844906]
	TIME [epoch: 8.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05556030328750813		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.05556030328750813 | validation: 0.03228202453295143]
	TIME [epoch: 8.53 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04592177010516622		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.04592177010516622 | validation: 0.03537117739009313]
	TIME [epoch: 8.55 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0464980392806492		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.0464980392806492 | validation: 0.025984195957743053]
	TIME [epoch: 8.53 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643402410220689		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.06643402410220689 | validation: 0.03255752387863571]
	TIME [epoch: 8.53 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05794160329352034		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.05794160329352034 | validation: 0.02546676278036656]
	TIME [epoch: 8.53 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058683860524853394		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.058683860524853394 | validation: 0.08021797815538234]
	TIME [epoch: 8.55 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05314918271376022		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.05314918271376022 | validation: 0.04132064249145785]
	TIME [epoch: 8.53 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05569377708623743		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.05569377708623743 | validation: 0.03862429252914762]
	TIME [epoch: 8.52 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06179146749364454		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.06179146749364454 | validation: 0.05254545739367204]
	TIME [epoch: 8.54 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05875611665216649		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.05875611665216649 | validation: 0.0385732479617818]
	TIME [epoch: 8.54 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07328302963203846		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.07328302963203846 | validation: 0.04424113180269021]
	TIME [epoch: 8.53 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054089172361550406		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.054089172361550406 | validation: 0.040621185792271336]
	TIME [epoch: 8.53 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05754549460928473		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.05754549460928473 | validation: 0.03774186978118555]
	TIME [epoch: 8.55 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999441572506438		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.04999441572506438 | validation: 0.04786196242987172]
	TIME [epoch: 8.53 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05260232006017177		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.05260232006017177 | validation: 0.04151918300613436]
	TIME [epoch: 8.53 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06944780128566772		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.06944780128566772 | validation: 0.06769564419243379]
	TIME [epoch: 8.54 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06899902577918386		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.06899902577918386 | validation: 0.04726862876150677]
	TIME [epoch: 8.55 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059150700138066434		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.059150700138066434 | validation: 0.04567517458601933]
	TIME [epoch: 8.53 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05119156843361451		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.05119156843361451 | validation: 0.046398076560210486]
	TIME [epoch: 8.53 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0703294419605933		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.0703294419605933 | validation: 0.04085252451161209]
	TIME [epoch: 8.53 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057456537986550614		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.057456537986550614 | validation: 0.027604430044215436]
	TIME [epoch: 8.55 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060158591485463174		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.060158591485463174 | validation: 0.03435870672937105]
	TIME [epoch: 8.53 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05803667958383647		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.05803667958383647 | validation: 0.06857180843139402]
	TIME [epoch: 8.53 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06110998698038246		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.06110998698038246 | validation: 0.05875270885260425]
	TIME [epoch: 8.53 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0847262982605134		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.0847262982605134 | validation: 0.08040035486255728]
	TIME [epoch: 8.54 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061172335785353235		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.061172335785353235 | validation: 0.05451444598259206]
	TIME [epoch: 8.53 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07398807679751158		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.07398807679751158 | validation: 0.06613464299251412]
	TIME [epoch: 8.53 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05718137547182982		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.05718137547182982 | validation: 0.03777920890731906]
	TIME [epoch: 8.53 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06821135491482888		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.06821135491482888 | validation: 0.053283691614359724]
	TIME [epoch: 8.55 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05633758844985672		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.05633758844985672 | validation: 0.058265025590952806]
	TIME [epoch: 8.53 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0703840350873204		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.0703840350873204 | validation: 0.03780865530441677]
	TIME [epoch: 8.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05144547126849917		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.05144547126849917 | validation: 0.036105922426066965]
	TIME [epoch: 8.52 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055013021746007765		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.055013021746007765 | validation: 0.09872342629055131]
	TIME [epoch: 8.55 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06283625094527834		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.06283625094527834 | validation: 0.04173436848295688]
	TIME [epoch: 8.53 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050037045632080536		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.050037045632080536 | validation: 0.04064405437635646]
	TIME [epoch: 8.53 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05534007430647174		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.05534007430647174 | validation: 0.054549929742397064]
	TIME [epoch: 8.53 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062120536809228036		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.062120536809228036 | validation: 0.035065421002109035]
	TIME [epoch: 8.55 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05189457014015073		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.05189457014015073 | validation: 0.0336704722827061]
	TIME [epoch: 8.52 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046639107588870285		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.046639107588870285 | validation: 0.038525525673517094]
	TIME [epoch: 8.52 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05894666808597253		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.05894666808597253 | validation: 0.02840993358954516]
	TIME [epoch: 8.53 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05962671392894807		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.05962671392894807 | validation: 0.0521266562575354]
	TIME [epoch: 8.54 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054755672497369		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.054755672497369 | validation: 0.062205948235383515]
	TIME [epoch: 8.53 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052079119634760085		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.052079119634760085 | validation: 0.02845613185388874]
	TIME [epoch: 8.52 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048310822065612526		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.048310822065612526 | validation: 0.03583396724058356]
	TIME [epoch: 8.54 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055106970947687295		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.055106970947687295 | validation: 0.06253363205836482]
	TIME [epoch: 8.53 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05920438764843964		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.05920438764843964 | validation: 0.039839047212876455]
	TIME [epoch: 8.53 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052158979904141686		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.052158979904141686 | validation: 0.03992006456650988]
	TIME [epoch: 8.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04529745006020014		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.04529745006020014 | validation: 0.03793454388456462]
	TIME [epoch: 8.54 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903476487846413		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.05903476487846413 | validation: 0.037658242337894346]
	TIME [epoch: 8.52 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05926673443676865		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.05926673443676865 | validation: 0.0578532715947227]
	TIME [epoch: 8.53 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609246110932682		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.06609246110932682 | validation: 0.056833895988799794]
	TIME [epoch: 8.53 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610922348556273		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.0610922348556273 | validation: 0.04669184514684563]
	TIME [epoch: 8.54 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05750453942106767		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.05750453942106767 | validation: 0.04735090249676212]
	TIME [epoch: 8.53 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053614233314263085		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.053614233314263085 | validation: 0.032081184097769]
	TIME [epoch: 8.52 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05639142929426037		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.05639142929426037 | validation: 0.026489734954013765]
	TIME [epoch: 8.52 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07271688955249558		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.07271688955249558 | validation: 0.06122831191580119]
	TIME [epoch: 8.54 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0516507718503996		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.0516507718503996 | validation: 0.03682684063132394]
	TIME [epoch: 8.53 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04821181042810628		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.04821181042810628 | validation: 0.049040588741144836]
	TIME [epoch: 8.53 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05499696665908797		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.05499696665908797 | validation: 0.04039148429890357]
	TIME [epoch: 8.52 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04576975510630399		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.04576975510630399 | validation: 0.03809173435757074]
	TIME [epoch: 8.53 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04659412735200669		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.04659412735200669 | validation: 0.035449598788449194]
	TIME [epoch: 8.53 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04948983101140516		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.04948983101140516 | validation: 0.059032986554874683]
	TIME [epoch: 8.52 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07134250412313602		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.07134250412313602 | validation: 0.049311712975574976]
	TIME [epoch: 8.53 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05711617406269751		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.05711617406269751 | validation: 0.03662710576516902]
	TIME [epoch: 8.55 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054570455574059054		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.054570455574059054 | validation: 0.025537630731360016]
	TIME [epoch: 8.53 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936816364328822		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.04936816364328822 | validation: 0.04878177587721601]
	TIME [epoch: 8.52 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06649317315746765		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.06649317315746765 | validation: 0.024467504217479133]
	TIME [epoch: 8.52 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04848141789320201		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.04848141789320201 | validation: 0.03947866954844719]
	TIME [epoch: 8.54 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044246179617924854		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.044246179617924854 | validation: 0.026249422596983478]
	TIME [epoch: 8.53 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04651116407256119		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.04651116407256119 | validation: 0.022766482752252792]
	TIME [epoch: 8.52 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05197923971500952		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.05197923971500952 | validation: 0.021574390591848482]
	TIME [epoch: 8.53 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05266800422093376		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.05266800422093376 | validation: 0.02683660708382067]
	TIME [epoch: 8.53 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05198977008901314		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.05198977008901314 | validation: 0.03213263545718104]
	TIME [epoch: 8.53 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051677996699352434		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.051677996699352434 | validation: 0.04790656993541364]
	TIME [epoch: 8.52 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08008570553028657		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.08008570553028657 | validation: 0.03966394702658651]
	TIME [epoch: 8.54 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043798021042182625		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.043798021042182625 | validation: 0.023553319343250945]
	TIME [epoch: 8.53 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052324390505793364		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.052324390505793364 | validation: 0.03459094854955436]
	TIME [epoch: 8.52 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06212166223661716		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.06212166223661716 | validation: 0.05161302979475421]
	TIME [epoch: 8.52 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705670960771376		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.0705670960771376 | validation: 0.09015448285917946]
	TIME [epoch: 8.55 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06726912404609588		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.06726912404609588 | validation: 0.028167909596132412]
	TIME [epoch: 8.52 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05360159563240646		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.05360159563240646 | validation: 0.03128969021229068]
	TIME [epoch: 8.53 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051021065733321616		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.051021065733321616 | validation: 0.04440188493152912]
	TIME [epoch: 8.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054619807144582574		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.054619807144582574 | validation: 0.02028749000675817]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1586.pth
	Model improved!!!
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0514897644258109		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.0514897644258109 | validation: 0.03820795847345681]
	TIME [epoch: 8.53 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049864483953055386		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.049864483953055386 | validation: 0.026743544067096718]
	TIME [epoch: 8.53 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055933983245247565		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.055933983245247565 | validation: 0.02796539175546981]
	TIME [epoch: 8.54 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051074589881156686		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.051074589881156686 | validation: 0.028413810446129423]
	TIME [epoch: 8.55 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04866390600708008		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.04866390600708008 | validation: 0.040803064809176545]
	TIME [epoch: 8.54 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05466989537346205		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.05466989537346205 | validation: 0.038414426342474585]
	TIME [epoch: 8.54 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993630521666673		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.05993630521666673 | validation: 0.03720112098814503]
	TIME [epoch: 8.54 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052294569188401606		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.052294569188401606 | validation: 0.03596868025156631]
	TIME [epoch: 8.56 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055180139934285354		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.055180139934285354 | validation: 0.030604753053310264]
	TIME [epoch: 8.53 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055682994934841856		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.055682994934841856 | validation: 0.04861707322714859]
	TIME [epoch: 8.54 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467359060978846		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.06467359060978846 | validation: 0.04092315840188583]
	TIME [epoch: 8.54 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05813627592934212		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.05813627592934212 | validation: 0.04401938323834267]
	TIME [epoch: 8.56 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059478365852244454		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.059478365852244454 | validation: 0.031689184021801126]
	TIME [epoch: 8.54 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04596517988406402		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.04596517988406402 | validation: 0.030899024705867913]
	TIME [epoch: 8.54 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045790742274173145		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.045790742274173145 | validation: 0.04138578855846731]
	TIME [epoch: 8.55 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062239570735282336		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.062239570735282336 | validation: 0.023006898578500787]
	TIME [epoch: 8.54 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05087686335466716		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.05087686335466716 | validation: 0.02775693957144965]
	TIME [epoch: 8.54 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05077359742172879		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.05077359742172879 | validation: 0.028033581163831967]
	TIME [epoch: 8.54 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049639589280771355		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.049639589280771355 | validation: 0.030140773954271317]
	TIME [epoch: 8.56 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04724172111137283		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.04724172111137283 | validation: 0.03560985479090305]
	TIME [epoch: 8.55 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0516517192850526		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.0516517192850526 | validation: 0.033716157857456956]
	TIME [epoch: 8.54 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05445707871935505		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.05445707871935505 | validation: 0.0435990032270456]
	TIME [epoch: 8.54 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060660482134848995		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.060660482134848995 | validation: 0.059934565794032515]
	TIME [epoch: 8.55 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06346207556270939		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.06346207556270939 | validation: 0.037519191381329545]
	TIME [epoch: 8.54 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800183025127179		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.05800183025127179 | validation: 0.03602460094499361]
	TIME [epoch: 8.54 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04592944636141037		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.04592944636141037 | validation: 0.029838206746752582]
	TIME [epoch: 8.54 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04672588219344507		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.04672588219344507 | validation: 0.021733732119355212]
	TIME [epoch: 8.56 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04551352072540213		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.04551352072540213 | validation: 0.023668169796534785]
	TIME [epoch: 8.54 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051095527488236966		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.051095527488236966 | validation: 0.031198118898080284]
	TIME [epoch: 8.54 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050935467130873456		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.050935467130873456 | validation: 0.0368815794516856]
	TIME [epoch: 8.54 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05660311910965412		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.05660311910965412 | validation: 0.046010145262805446]
	TIME [epoch: 8.55 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04607210105578764		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.04607210105578764 | validation: 0.03537871923547564]
	TIME [epoch: 8.54 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04509075327430466		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.04509075327430466 | validation: 0.04359342380118132]
	TIME [epoch: 8.54 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047435997582286636		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.047435997582286636 | validation: 0.040257206651014]
	TIME [epoch: 8.53 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046220196543668206		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.046220196543668206 | validation: 0.03300515200139451]
	TIME [epoch: 8.56 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04592868620338107		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.04592868620338107 | validation: 0.040954447154398145]
	TIME [epoch: 8.54 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047982682030319		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.047982682030319 | validation: 0.038163776887188416]
	TIME [epoch: 8.54 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052718736929647424		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.052718736929647424 | validation: 0.03436544831903157]
	TIME [epoch: 8.54 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871131576715015		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.05871131576715015 | validation: 0.030117914631783843]
	TIME [epoch: 8.56 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05054180244273778		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.05054180244273778 | validation: 0.0498732895729148]
	TIME [epoch: 8.54 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05749709882180533		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.05749709882180533 | validation: 0.039890273241891074]
	TIME [epoch: 8.54 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171410156898633		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.05171410156898633 | validation: 0.04863117087533454]
	TIME [epoch: 8.54 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05043713803835683		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.05043713803835683 | validation: 0.030671222770413967]
	TIME [epoch: 8.55 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046221077553783844		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.046221077553783844 | validation: 0.05154029976510909]
	TIME [epoch: 8.54 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05338978398896834		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.05338978398896834 | validation: 0.046881373813594765]
	TIME [epoch: 8.54 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04899990998014803		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.04899990998014803 | validation: 0.0427804772703317]
	TIME [epoch: 8.55 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058326387712317095		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.058326387712317095 | validation: 0.04646210584876973]
	TIME [epoch: 8.55 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049780076507624886		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.049780076507624886 | validation: 0.0298859102857814]
	TIME [epoch: 8.54 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05574115404697203		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.05574115404697203 | validation: 0.044936505884717245]
	TIME [epoch: 8.54 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04733923136172274		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.04733923136172274 | validation: 0.07136498285931342]
	TIME [epoch: 8.56 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06300365325290781		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.06300365325290781 | validation: 0.038542454234004236]
	TIME [epoch: 8.54 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05947641106699943		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.05947641106699943 | validation: 0.04178045187524201]
	TIME [epoch: 8.54 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05776599357711175		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.05776599357711175 | validation: 0.03646311193062124]
	TIME [epoch: 8.54 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050392215347831115		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.050392215347831115 | validation: 0.03460942187855966]
	TIME [epoch: 8.56 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05127826043420849		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.05127826043420849 | validation: 0.04752261469615934]
	TIME [epoch: 8.54 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060239421229605815		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.060239421229605815 | validation: 0.05917482157342474]
	TIME [epoch: 8.54 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053735187929310826		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.053735187929310826 | validation: 0.042357535438016236]
	TIME [epoch: 8.54 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04520191707876191		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.04520191707876191 | validation: 0.03830998797218166]
	TIME [epoch: 8.55 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0435754035042947		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.0435754035042947 | validation: 0.031981643177182065]
	TIME [epoch: 8.54 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05744585068672616		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.05744585068672616 | validation: 0.026818266276700215]
	TIME [epoch: 8.53 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062404702783702394		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.062404702783702394 | validation: 0.03330780407263148]
	TIME [epoch: 8.54 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05435891108352044		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.05435891108352044 | validation: 0.05046419130545522]
	TIME [epoch: 8.55 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06969865085343868		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.06969865085343868 | validation: 0.037494788412323794]
	TIME [epoch: 8.54 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853775461236482		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.05853775461236482 | validation: 0.038805424018630005]
	TIME [epoch: 8.54 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332527331404804		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.06332527331404804 | validation: 0.04138354709404071]
	TIME [epoch: 8.54 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057161393565066755		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.057161393565066755 | validation: 0.04643120977528985]
	TIME [epoch: 8.56 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051031554365951734		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.051031554365951734 | validation: 0.034243909922861915]
	TIME [epoch: 8.53 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04596327307321184		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.04596327307321184 | validation: 0.04054428749465441]
	TIME [epoch: 8.54 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0450524926684235		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.0450524926684235 | validation: 0.026242012605914238]
	TIME [epoch: 8.54 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04531772046537204		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.04531772046537204 | validation: 0.040404269968136425]
	TIME [epoch: 8.56 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052355515170292445		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.052355515170292445 | validation: 0.039031617854278666]
	TIME [epoch: 8.54 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061546501983045586		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.061546501983045586 | validation: 0.03346892525090835]
	TIME [epoch: 8.53 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05275742834967678		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.05275742834967678 | validation: 0.03746948415891814]
	TIME [epoch: 8.55 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052388901678022425		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.052388901678022425 | validation: 0.03329724134752796]
	TIME [epoch: 8.54 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04839694486615836		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.04839694486615836 | validation: 0.04364118036160084]
	TIME [epoch: 8.53 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06278792012406917		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.06278792012406917 | validation: 0.044863385879120386]
	TIME [epoch: 8.54 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048053624207899034		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.048053624207899034 | validation: 0.023634418102668014]
	TIME [epoch: 8.55 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0575821909642633		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.0575821909642633 | validation: 0.024949087674782287]
	TIME [epoch: 8.54 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04701209805793456		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.04701209805793456 | validation: 0.029025749821093648]
	TIME [epoch: 8.53 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06945622684262419		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.06945622684262419 | validation: 0.04682340195509423]
	TIME [epoch: 8.53 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06836881463063177		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.06836881463063177 | validation: 0.03185994973578174]
	TIME [epoch: 8.55 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05802192773425545		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.05802192773425545 | validation: 0.036244518225387906]
	TIME [epoch: 8.54 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05509127070475076		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.05509127070475076 | validation: 0.07085799173367693]
	TIME [epoch: 8.53 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05502306341495152		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.05502306341495152 | validation: 0.056926164180000634]
	TIME [epoch: 8.53 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04852423148618158		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.04852423148618158 | validation: 0.03399877814056299]
	TIME [epoch: 8.55 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05733633380360768		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.05733633380360768 | validation: 0.03708609200621777]
	TIME [epoch: 8.54 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050463731628210586		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.050463731628210586 | validation: 0.04918320653164]
	TIME [epoch: 8.53 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06099595887595645		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.06099595887595645 | validation: 0.04139388152974588]
	TIME [epoch: 8.53 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05615428426088283		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.05615428426088283 | validation: 0.04400171818803854]
	TIME [epoch: 8.55 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05564343758307999		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.05564343758307999 | validation: 0.043697411540052994]
	TIME [epoch: 8.54 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048928351852999326		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.048928351852999326 | validation: 0.03230468310399554]
	TIME [epoch: 8.54 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04045240311517413		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.04045240311517413 | validation: 0.05415878501974104]
	TIME [epoch: 8.54 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04539477715069355		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.04539477715069355 | validation: 0.02580472911240949]
	TIME [epoch: 8.54 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048620049431758544		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.048620049431758544 | validation: 0.034871045936767]
	TIME [epoch: 8.54 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04561654286595408		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.04561654286595408 | validation: 0.01978633621761439]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1681.pth
	Model improved!!!
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044766428689957345		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.044766428689957345 | validation: 0.03562623916132031]
	TIME [epoch: 8.53 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04534644284790633		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.04534644284790633 | validation: 0.0333985278359617]
	TIME [epoch: 8.54 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04398962751474565		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.04398962751474565 | validation: 0.048298974291334576]
	TIME [epoch: 8.52 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04135612816501745		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.04135612816501745 | validation: 0.0325786034018062]
	TIME [epoch: 8.53 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044798839874570874		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.044798839874570874 | validation: 0.0330555880592565]
	TIME [epoch: 8.53 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04458945174105565		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.04458945174105565 | validation: 0.05152124040988143]
	TIME [epoch: 8.54 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052149426783119956		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.052149426783119956 | validation: 0.0396461298252581]
	TIME [epoch: 8.52 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04958109532829505		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.04958109532829505 | validation: 0.03721144139957619]
	TIME [epoch: 8.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0485682814413254		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.0485682814413254 | validation: 0.04778882924096621]
	TIME [epoch: 8.53 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05241224121551956		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.05241224121551956 | validation: 0.04831209220818301]
	TIME [epoch: 8.54 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05242899628461915		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.05242899628461915 | validation: 0.05378682814893732]
	TIME [epoch: 8.53 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936141942592771		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.05936141942592771 | validation: 0.04196002646742923]
	TIME [epoch: 8.52 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054186888165598066		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.054186888165598066 | validation: 0.029867221253915485]
	TIME [epoch: 8.54 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044412685616380274		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.044412685616380274 | validation: 0.03226035272685237]
	TIME [epoch: 8.53 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046446889680544744		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.046446889680544744 | validation: 0.046227007983935364]
	TIME [epoch: 8.53 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05694346073784808		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.05694346073784808 | validation: 0.03602484236255581]
	TIME [epoch: 8.53 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056827817616477774		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.056827817616477774 | validation: 0.04325795919419463]
	TIME [epoch: 8.54 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05576096680593917		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.05576096680593917 | validation: 0.03846532049731874]
	TIME [epoch: 8.52 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04875667459686839		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.04875667459686839 | validation: 0.029739692058421172]
	TIME [epoch: 8.52 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05223086400566879		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.05223086400566879 | validation: 0.03547470089548979]
	TIME [epoch: 8.53 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05585445927296193		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.05585445927296193 | validation: 0.04382300875848094]
	TIME [epoch: 8.54 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05054456586465417		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.05054456586465417 | validation: 0.044483381354163326]
	TIME [epoch: 8.53 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0504376023405226		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.0504376023405226 | validation: 0.047790181161244484]
	TIME [epoch: 8.53 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04041615212500981		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.04041615212500981 | validation: 0.03747926931103086]
	TIME [epoch: 8.53 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05115521781205508		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.05115521781205508 | validation: 0.06096911144390979]
	TIME [epoch: 8.54 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050300023205192335		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.050300023205192335 | validation: 0.0397586463945016]
	TIME [epoch: 8.53 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05318095060254543		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.05318095060254543 | validation: 0.030992240173814255]
	TIME [epoch: 8.53 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06030043208588738		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.06030043208588738 | validation: 0.03631699176639441]
	TIME [epoch: 8.53 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046194411606231014		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.046194411606231014 | validation: 0.03711805788745194]
	TIME [epoch: 8.54 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04320122113893518		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.04320122113893518 | validation: 0.024568920252960563]
	TIME [epoch: 8.53 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05044217444289857		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.05044217444289857 | validation: 0.03705683577529921]
	TIME [epoch: 8.53 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05037151538015966		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.05037151538015966 | validation: 0.04744214963312249]
	TIME [epoch: 8.53 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050460914511937585		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.050460914511937585 | validation: 0.045891991228171086]
	TIME [epoch: 8.55 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04491978964666594		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.04491978964666594 | validation: 0.03807493530442295]
	TIME [epoch: 8.53 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0523217563856998		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.0523217563856998 | validation: 0.030392838146823413]
	TIME [epoch: 8.53 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04335157687617261		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.04335157687617261 | validation: 0.033383365617959675]
	TIME [epoch: 8.53 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047610572250000635		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.047610572250000635 | validation: 0.047268655227503946]
	TIME [epoch: 8.53 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05401583377274695		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.05401583377274695 | validation: 0.04099264589554822]
	TIME [epoch: 8.52 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04666177999045665		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.04666177999045665 | validation: 0.019361383633486155]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1720.pth
	Model improved!!!
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05501338625644586		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.05501338625644586 | validation: 0.03515221703250808]
	TIME [epoch: 8.54 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03661205264345515		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.03661205264345515 | validation: 0.025875008916399718]
	TIME [epoch: 8.52 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04219997654252474		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.04219997654252474 | validation: 0.04075566938177627]
	TIME [epoch: 8.53 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05613589696385204		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.05613589696385204 | validation: 0.043696475236825176]
	TIME [epoch: 8.52 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0688246886522915		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.0688246886522915 | validation: 0.055202419717626655]
	TIME [epoch: 8.54 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057644133924317074		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.057644133924317074 | validation: 0.047657675193719336]
	TIME [epoch: 8.53 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05537599295350502		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.05537599295350502 | validation: 0.03833686081010679]
	TIME [epoch: 8.53 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050838161589952705		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.050838161589952705 | validation: 0.041425797269160444]
	TIME [epoch: 8.53 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04790748746258152		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.04790748746258152 | validation: 0.030765557832517332]
	TIME [epoch: 8.54 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044677762524670074		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.044677762524670074 | validation: 0.04092964105443364]
	TIME [epoch: 8.53 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041815976810243585		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.041815976810243585 | validation: 0.03292580095035941]
	TIME [epoch: 8.51 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05536698043236945		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.05536698043236945 | validation: 0.036156512095688986]
	TIME [epoch: 8.52 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05954928735331857		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.05954928735331857 | validation: 0.03934418616071368]
	TIME [epoch: 8.54 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502792087385756		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.06502792087385756 | validation: 0.0410740993635888]
	TIME [epoch: 8.52 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061797895049669746		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.061797895049669746 | validation: 0.04016978230722824]
	TIME [epoch: 8.53 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05754007345586235		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.05754007345586235 | validation: 0.03745338096151582]
	TIME [epoch: 8.53 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05717303121475827		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.05717303121475827 | validation: 0.03949243985961626]
	TIME [epoch: 8.55 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05049496244306841		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.05049496244306841 | validation: 0.03149941687443014]
	TIME [epoch: 8.53 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05327103159718727		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.05327103159718727 | validation: 0.0412431501011512]
	TIME [epoch: 8.53 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058953296501524546		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.058953296501524546 | validation: 0.03987429088529773]
	TIME [epoch: 8.53 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06360386621286243		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.06360386621286243 | validation: 0.05198677258976705]
	TIME [epoch: 8.55 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057398308647247306		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.057398308647247306 | validation: 0.036312781474349395]
	TIME [epoch: 8.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0533146729826234		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.0533146729826234 | validation: 0.0383901560817457]
	TIME [epoch: 8.52 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05610061393480488		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.05610061393480488 | validation: 0.03951379838015517]
	TIME [epoch: 8.53 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05510077157915855		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.05510077157915855 | validation: 0.041310136395580246]
	TIME [epoch: 8.54 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387994549744266		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.05387994549744266 | validation: 0.03669767499782001]
	TIME [epoch: 8.53 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045667851368721445		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.045667851368721445 | validation: 0.05607839691786255]
	TIME [epoch: 8.52 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06475446481303662		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.06475446481303662 | validation: 0.04503155684366987]
	TIME [epoch: 8.54 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04934139217287005		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.04934139217287005 | validation: 0.031822630247321904]
	TIME [epoch: 8.53 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051931138958884036		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.051931138958884036 | validation: 0.03243855023752226]
	TIME [epoch: 8.53 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046371540515364455		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.046371540515364455 | validation: 0.03534044490159807]
	TIME [epoch: 8.52 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04020431722366917		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.04020431722366917 | validation: 0.03170465263884473]
	TIME [epoch: 8.55 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856764821544474		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.04856764821544474 | validation: 0.03620223438578474]
	TIME [epoch: 8.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0453582150826732		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.0453582150826732 | validation: 0.03613303013947544]
	TIME [epoch: 8.52 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04390089703768249		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.04390089703768249 | validation: 0.035128315605995976]
	TIME [epoch: 8.53 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04263554277244157		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.04263554277244157 | validation: 0.019353830495281252]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1756.pth
	Model improved!!!
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04434119487384469		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.04434119487384469 | validation: 0.04220757092050599]
	TIME [epoch: 8.54 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04365566786042378		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.04365566786042378 | validation: 0.03229226181644242]
	TIME [epoch: 8.53 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0427417577112512		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.0427417577112512 | validation: 0.05160870677508231]
	TIME [epoch: 8.52 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833507226817321		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.05833507226817321 | validation: 0.03727340356131923]
	TIME [epoch: 8.55 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04507440720037623		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.04507440720037623 | validation: 0.03692394279987962]
	TIME [epoch: 8.53 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04034709008187732		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.04034709008187732 | validation: 0.0338180259541516]
	TIME [epoch: 8.53 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05514196491542095		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.05514196491542095 | validation: 0.054171317150410216]
	TIME [epoch: 8.52 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0466513446112918		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0466513446112918 | validation: 0.03077520054096127]
	TIME [epoch: 8.54 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04463835285979416		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.04463835285979416 | validation: 0.033224586878867965]
	TIME [epoch: 8.53 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047392382195831424		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.047392382195831424 | validation: 0.043741544915902576]
	TIME [epoch: 8.53 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04874166222781388		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.04874166222781388 | validation: 0.03034613596361122]
	TIME [epoch: 8.53 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04947595039833337		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.04947595039833337 | validation: 0.04686776671404985]
	TIME [epoch: 8.55 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05590129141751636		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.05590129141751636 | validation: 0.03735672389159471]
	TIME [epoch: 8.53 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04505873860955727		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.04505873860955727 | validation: 0.03350716498571234]
	TIME [epoch: 8.53 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04367016031136932		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.04367016031136932 | validation: 0.04227195591284011]
	TIME [epoch: 8.53 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047108742229325117		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.047108742229325117 | validation: 0.031082185388132108]
	TIME [epoch: 8.54 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04840625870886184		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.04840625870886184 | validation: 0.021092861989185162]
	TIME [epoch: 8.53 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04400381247415102		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.04400381247415102 | validation: 0.032672989952181666]
	TIME [epoch: 8.52 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04224772125397645		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.04224772125397645 | validation: 0.03227049455447416]
	TIME [epoch: 8.54 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04755278286275017		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.04755278286275017 | validation: 0.0381895904077815]
	TIME [epoch: 8.54 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04550129581327929		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.04550129581327929 | validation: 0.030811012814697246]
	TIME [epoch: 8.53 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04498140202911551		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.04498140202911551 | validation: 0.03806539880761513]
	TIME [epoch: 8.53 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04582467105801729		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.04582467105801729 | validation: 0.025293331630263385]
	TIME [epoch: 8.54 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04217355010622126		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.04217355010622126 | validation: 0.02903234950521687]
	TIME [epoch: 8.53 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04979691596838034		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.04979691596838034 | validation: 0.030404746227065522]
	TIME [epoch: 8.52 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05715524023850954		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.05715524023850954 | validation: 0.05798307857428342]
	TIME [epoch: 8.53 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05383508113787511		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.05383508113787511 | validation: 0.04181442487792884]
	TIME [epoch: 8.54 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04419246110301002		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.04419246110301002 | validation: 0.03490481552709687]
	TIME [epoch: 8.53 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0444650843985821		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.0444650843985821 | validation: 0.029885351588673954]
	TIME [epoch: 8.53 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04941849053163853		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.04941849053163853 | validation: 0.014686947894722791]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1786.pth
	Model improved!!!
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04390996565440648		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.04390996565440648 | validation: 0.01840362818232743]
	TIME [epoch: 8.55 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04832020776716945		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.04832020776716945 | validation: 0.01843648558975392]
	TIME [epoch: 8.52 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04719465931070156		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.04719465931070156 | validation: 0.02619614172889977]
	TIME [epoch: 8.53 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04054858399313135		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.04054858399313135 | validation: 0.02531002917112417]
	TIME [epoch: 8.52 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04536925154819426		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.04536925154819426 | validation: 0.023357670251583806]
	TIME [epoch: 8.54 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04304916547747975		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.04304916547747975 | validation: 0.03159693577824957]
	TIME [epoch: 8.53 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04454688602959884		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.04454688602959884 | validation: 0.04145606096177906]
	TIME [epoch: 8.52 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03995076024927906		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.03995076024927906 | validation: 0.02355819916577439]
	TIME [epoch: 8.53 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040451468045177956		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.040451468045177956 | validation: 0.043594583867655315]
	TIME [epoch: 8.54 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04847528816060596		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.04847528816060596 | validation: 0.032099954900906794]
	TIME [epoch: 8.53 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046715805938941944		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.046715805938941944 | validation: 0.02905260267215152]
	TIME [epoch: 8.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04230648704613973		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.04230648704613973 | validation: 0.035832777001414524]
	TIME [epoch: 8.53 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04741957276817523		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.04741957276817523 | validation: 0.0329937497581445]
	TIME [epoch: 8.55 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05951916554699532		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.05951916554699532 | validation: 0.04114672449978263]
	TIME [epoch: 8.53 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06112677702253021		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.06112677702253021 | validation: 0.06606504255841437]
	TIME [epoch: 8.52 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06456735029055775		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.06456735029055775 | validation: 0.056378225035425306]
	TIME [epoch: 8.53 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04740113073073841		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.04740113073073841 | validation: 0.03406770364942471]
	TIME [epoch: 8.53 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048605932437697966		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.048605932437697966 | validation: 0.03497020031753716]
	TIME [epoch: 8.53 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04964178295900819		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.04964178295900819 | validation: 0.03688561327055901]
	TIME [epoch: 8.52 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04652634647529302		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.04652634647529302 | validation: 0.04127582285363839]
	TIME [epoch: 8.54 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046083350223735185		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.046083350223735185 | validation: 0.03724870171193341]
	TIME [epoch: 8.53 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04993178365555821		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.04993178365555821 | validation: 0.04708133924741425]
	TIME [epoch: 8.53 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04718716751492168		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.04718716751492168 | validation: 0.03964823818704]
	TIME [epoch: 8.53 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041430586839924434		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.041430586839924434 | validation: 0.025721083370887486]
	TIME [epoch: 8.54 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04637408357089929		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.04637408357089929 | validation: 0.02653782788569129]
	TIME [epoch: 8.53 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049579524132726885		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.049579524132726885 | validation: 0.042215987034185144]
	TIME [epoch: 8.53 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041648189317400254		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.041648189317400254 | validation: 0.032225106409158176]
	TIME [epoch: 8.53 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045370034360640604		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.045370034360640604 | validation: 0.03924562772425982]
	TIME [epoch: 8.54 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047720225241996		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.047720225241996 | validation: 0.03947512450635915]
	TIME [epoch: 8.53 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044106260758149794		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.044106260758149794 | validation: 0.03596664720060972]
	TIME [epoch: 8.53 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046046850367570516		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.046046850367570516 | validation: 0.029086589376642664]
	TIME [epoch: 8.52 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03929047897981222		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.03929047897981222 | validation: 0.03783527157505641]
	TIME [epoch: 8.54 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04528444278160022		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.04528444278160022 | validation: 0.046252802211602856]
	TIME [epoch: 8.53 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04137374857906837		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.04137374857906837 | validation: 0.03778707519406602]
	TIME [epoch: 8.53 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049498197667798415		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.049498197667798415 | validation: 0.023754682869998968]
	TIME [epoch: 8.53 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05170266153383122		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.05170266153383122 | validation: 0.04076358744626906]
	TIME [epoch: 8.54 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05401135635478135		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.05401135635478135 | validation: 0.044642762505517755]
	TIME [epoch: 8.53 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04869877233534577		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.04869877233534577 | validation: 0.042527176577543485]
	TIME [epoch: 8.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04763800863146306		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.04763800863146306 | validation: 0.04681538698058413]
	TIME [epoch: 8.52 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05255071781160401		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.05255071781160401 | validation: 0.030983168451579092]
	TIME [epoch: 8.53 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04873185584546961		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.04873185584546961 | validation: 0.04668684247307088]
	TIME [epoch: 8.53 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05682416251825315		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.05682416251825315 | validation: 0.03373602330763488]
	TIME [epoch: 8.52 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055541052176089636		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.055541052176089636 | validation: 0.039700814165739604]
	TIME [epoch: 8.53 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05946619545899088		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.05946619545899088 | validation: 0.037078146965365925]
	TIME [epoch: 8.54 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052009874318711714		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.052009874318711714 | validation: 0.03889921691561494]
	TIME [epoch: 8.53 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051635218025595564		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.051635218025595564 | validation: 0.04502099544098617]
	TIME [epoch: 8.53 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054729146831615824		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.054729146831615824 | validation: 0.028013071664350485]
	TIME [epoch: 8.53 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05806129245979399		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.05806129245979399 | validation: 0.03609196651858574]
	TIME [epoch: 8.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05311566482896226		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.05311566482896226 | validation: 0.04178179907052548]
	TIME [epoch: 8.52 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05438422377660329		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.05438422377660329 | validation: 0.03557526651892766]
	TIME [epoch: 8.52 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221181708462473		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.06221181708462473 | validation: 0.04756432877014766]
	TIME [epoch: 8.54 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0640931277796781		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.0640931277796781 | validation: 0.03741040187999349]
	TIME [epoch: 8.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05333566350066939		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.05333566350066939 | validation: 0.0378488692178577]
	TIME [epoch: 8.53 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049942650211277376		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.049942650211277376 | validation: 0.05450709140216371]
	TIME [epoch: 8.52 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05782419610859291		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.05782419610859291 | validation: 0.053021446665466515]
	TIME [epoch: 8.53 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048196204726335214		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.048196204726335214 | validation: 0.038448350960109415]
	TIME [epoch: 8.53 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04469955115682506		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.04469955115682506 | validation: 0.04415004087059605]
	TIME [epoch: 8.53 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04469575839491045		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.04469575839491045 | validation: 0.057007594644046075]
	TIME [epoch: 8.52 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05382152599636193		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.05382152599636193 | validation: 0.04452723990763319]
	TIME [epoch: 8.54 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04648050651336623		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.04648050651336623 | validation: 0.023489203171144276]
	TIME [epoch: 8.53 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0553896638388028		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.0553896638388028 | validation: 0.028254119420013622]
	TIME [epoch: 8.52 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05477531983837005		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.05477531983837005 | validation: 0.03557457319792852]
	TIME [epoch: 8.52 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05953673711453069		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.05953673711453069 | validation: 0.037581551585278775]
	TIME [epoch: 8.53 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052253913698499486		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.052253913698499486 | validation: 0.03988061295824251]
	TIME [epoch: 8.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055791521532459434		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.055791521532459434 | validation: 0.05588728136022991]
	TIME [epoch: 8.51 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0671031085334172		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.0671031085334172 | validation: 0.04082920042057431]
	TIME [epoch: 8.51 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05642160540539485		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.05642160540539485 | validation: 0.041185250584645686]
	TIME [epoch: 8.53 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674516555725591		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.05674516555725591 | validation: 0.050530386010179174]
	TIME [epoch: 8.52 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05898227138631904		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.05898227138631904 | validation: 0.04198291854982734]
	TIME [epoch: 8.52 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04847855572051401		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.04847855572051401 | validation: 0.027159040907336236]
	TIME [epoch: 8.53 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042724105038510304		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.042724105038510304 | validation: 0.035001778929178884]
	TIME [epoch: 8.54 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043266429233065624		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.043266429233065624 | validation: 0.03786987297812954]
	TIME [epoch: 8.52 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04036796052592652		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.04036796052592652 | validation: 0.01954259575137269]
	TIME [epoch: 8.52 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04085807978217635		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.04085807978217635 | validation: 0.03559787561478474]
	TIME [epoch: 8.52 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043226681029518196		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.043226681029518196 | validation: 0.03157175865652273]
	TIME [epoch: 8.54 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04825376676568431		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.04825376676568431 | validation: 0.0341602772665237]
	TIME [epoch: 8.52 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042113731605177646		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.042113731605177646 | validation: 0.03452224736144636]
	TIME [epoch: 8.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04840728703971331		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.04840728703971331 | validation: 0.029843301064346524]
	TIME [epoch: 8.54 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04375362864801137		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.04375362864801137 | validation: 0.03605317647720102]
	TIME [epoch: 8.53 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04113119244516127		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.04113119244516127 | validation: 0.02551676495242617]
	TIME [epoch: 8.52 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03949701277200977		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.03949701277200977 | validation: 0.02941021571348347]
	TIME [epoch: 8.52 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043001727068036164		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.043001727068036164 | validation: 0.04516545690153556]
	TIME [epoch: 8.53 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050258003790732406		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.050258003790732406 | validation: 0.027382890207175985]
	TIME [epoch: 8.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050588869524531586		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.050588869524531586 | validation: 0.03091861472352993]
	TIME [epoch: 8.52 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052793546853703965		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.052793546853703965 | validation: 0.030781668499118328]
	TIME [epoch: 8.51 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05263865652410182		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.05263865652410182 | validation: 0.04037360252364687]
	TIME [epoch: 8.54 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05328465719062205		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.05328465719062205 | validation: 0.04495325721627552]
	TIME [epoch: 8.52 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049772686225750415		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.049772686225750415 | validation: 0.03689965492092255]
	TIME [epoch: 8.52 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03992574846281563		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.03992574846281563 | validation: 0.03601347899262493]
	TIME [epoch: 8.52 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0417241815128187		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.0417241815128187 | validation: 0.03620373943002637]
	TIME [epoch: 8.54 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04462645125022304		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.04462645125022304 | validation: 0.02726884436797114]
	TIME [epoch: 8.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04987353473934371		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.04987353473934371 | validation: 0.03506933595661482]
	TIME [epoch: 8.52 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045206064131917086		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.045206064131917086 | validation: 0.037005230129643935]
	TIME [epoch: 8.52 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04198524325783713		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.04198524325783713 | validation: 0.03491180218700436]
	TIME [epoch: 8.54 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04437713509294907		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.04437713509294907 | validation: 0.0487580151747063]
	TIME [epoch: 8.52 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04993236070157272		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.04993236070157272 | validation: 0.03643044001784926]
	TIME [epoch: 8.52 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039227633510427615		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.039227633510427615 | validation: 0.03904821198727122]
	TIME [epoch: 8.53 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04350963493979983		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.04350963493979983 | validation: 0.029434358340528786]
	TIME [epoch: 8.54 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044539389601461254		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.044539389601461254 | validation: 0.028483795794357565]
	TIME [epoch: 8.53 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05472283609355651		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.05472283609355651 | validation: 0.04264665541680376]
	TIME [epoch: 8.53 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06307123561848726		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.06307123561848726 | validation: 0.02843623365971827]
	TIME [epoch: 8.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04227388708220263		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.04227388708220263 | validation: 0.03472508355248738]
	TIME [epoch: 8.55 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04289333109198599		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.04289333109198599 | validation: 0.048678585460986544]
	TIME [epoch: 8.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03734690272222939		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.03734690272222939 | validation: 0.03471205303296626]
	TIME [epoch: 8.51 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039565333008652705		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.039565333008652705 | validation: 0.0376274862303172]
	TIME [epoch: 8.53 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218143606371074		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.04218143606371074 | validation: 0.04457350536399171]
	TIME [epoch: 8.54 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03991779875912911		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.03991779875912911 | validation: 0.029278422720735307]
	TIME [epoch: 8.52 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04312967031382239		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.04312967031382239 | validation: 0.020583394053084625]
	TIME [epoch: 8.52 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041351167671163994		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.041351167671163994 | validation: 0.02857308920192772]
	TIME [epoch: 8.53 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04458870837655791		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.04458870837655791 | validation: 0.022932419117583897]
	TIME [epoch: 8.53 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04520342052238657		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.04520342052238657 | validation: 0.03183909112885463]
	TIME [epoch: 8.52 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04416404519006169		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.04416404519006169 | validation: 0.031489450246102314]
	TIME [epoch: 8.51 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045222325822390316		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.045222325822390316 | validation: 0.04334995686268621]
	TIME [epoch: 8.53 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045365288608604525		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.045365288608604525 | validation: 0.023922078939234124]
	TIME [epoch: 8.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05320979157082869		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.05320979157082869 | validation: 0.049590700440420854]
	TIME [epoch: 8.53 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924223039763507		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.04924223039763507 | validation: 0.04033866281439449]
	TIME [epoch: 8.53 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04746843319678804		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.04746843319678804 | validation: 0.05654696491923451]
	TIME [epoch: 8.55 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06276596068297684		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.06276596068297684 | validation: 0.04853438870711524]
	TIME [epoch: 8.52 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04864503364936894		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.04864503364936894 | validation: 0.024046869584610556]
	TIME [epoch: 8.53 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041603017725260275		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.041603017725260275 | validation: 0.03523146159399346]
	TIME [epoch: 8.52 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04412756121002751		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.04412756121002751 | validation: 0.039809303627095685]
	TIME [epoch: 8.54 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04451199265002852		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.04451199265002852 | validation: 0.02261222285315137]
	TIME [epoch: 8.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045803597334643766		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.045803597334643766 | validation: 0.02315659716845132]
	TIME [epoch: 8.52 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038593986500765017		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.038593986500765017 | validation: 0.026681922972166164]
	TIME [epoch: 8.52 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04108748940597127		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.04108748940597127 | validation: 0.03298278007172934]
	TIME [epoch: 8.54 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04622962515352271		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.04622962515352271 | validation: 0.03383709994306862]
	TIME [epoch: 8.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05313985607242712		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.05313985607242712 | validation: 0.03746952865384746]
	TIME [epoch: 8.52 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045434301251425994		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.045434301251425994 | validation: 0.037221926898062314]
	TIME [epoch: 8.53 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04405454408104462		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.04405454408104462 | validation: 0.0395732966278986]
	TIME [epoch: 8.54 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045784604859330474		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.045784604859330474 | validation: 0.04876776768772759]
	TIME [epoch: 8.53 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04321521509930017		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.04321521509930017 | validation: 0.02385886982320683]
	TIME [epoch: 8.53 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04168979418406209		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.04168979418406209 | validation: 0.028927964532268348]
	TIME [epoch: 8.54 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05161403428454823		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.05161403428454823 | validation: 0.034048222275018594]
	TIME [epoch: 8.54 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053615597795676415		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.053615597795676415 | validation: 0.019501091994709875]
	TIME [epoch: 8.52 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04878446255336753		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.04878446255336753 | validation: 0.02732549215983591]
	TIME [epoch: 8.54 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040235701248343955		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.040235701248343955 | validation: 0.034407096338449614]
	TIME [epoch: 8.53 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042928239700260565		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.042928239700260565 | validation: 0.0354118142889651]
	TIME [epoch: 8.55 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04202556029310139		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.04202556029310139 | validation: 0.0376443265031043]
	TIME [epoch: 8.53 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041091324941126765		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.041091324941126765 | validation: 0.032281912973409446]
	TIME [epoch: 8.53 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039797465282876754		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.039797465282876754 | validation: 0.024687203366341344]
	TIME [epoch: 8.54 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04019546751738296		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.04019546751738296 | validation: 0.032641024241434426]
	TIME [epoch: 8.54 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03979010100624732		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.03979010100624732 | validation: 0.027523020129524227]
	TIME [epoch: 8.53 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04174658078961438		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.04174658078961438 | validation: 0.021952054098813414]
	TIME [epoch: 8.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04397103866134887		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.04397103866134887 | validation: 0.030648435166163834]
	TIME [epoch: 8.54 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043180497797550677		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.043180497797550677 | validation: 0.03160267645147586]
	TIME [epoch: 8.52 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04699943473624398		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.04699943473624398 | validation: 0.030483928456017988]
	TIME [epoch: 8.53 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04201613950935848		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.04201613950935848 | validation: 0.024206006229549208]
	TIME [epoch: 8.52 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037166678014744194		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.037166678014744194 | validation: 0.038815143564970636]
	TIME [epoch: 8.54 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04415731042679675		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.04415731042679675 | validation: 0.034714127593416425]
	TIME [epoch: 8.53 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03757680489324487		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.03757680489324487 | validation: 0.024798409866692624]
	TIME [epoch: 8.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04122658870119027		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.04122658870119027 | validation: 0.028227004048584442]
	TIME [epoch: 8.53 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04703271131414023		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.04703271131414023 | validation: 0.032756132160333296]
	TIME [epoch: 8.54 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04274851389737105		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.04274851389737105 | validation: 0.03290062165242358]
	TIME [epoch: 8.53 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034862893084759275		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.034862893084759275 | validation: 0.029026650256072248]
	TIME [epoch: 8.52 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03881403940600112		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.03881403940600112 | validation: 0.03134888234916951]
	TIME [epoch: 8.51 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960879591279138		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.03960879591279138 | validation: 0.031639727366173175]
	TIME [epoch: 8.54 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04558426192536236		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.04558426192536236 | validation: 0.032166427199363835]
	TIME [epoch: 8.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043745853563016725		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.043745853563016725 | validation: 0.039215704383111394]
	TIME [epoch: 8.52 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047269712633090336		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.047269712633090336 | validation: 0.039131198797641445]
	TIME [epoch: 8.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040116871471959886		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.040116871471959886 | validation: 0.03327142006538153]
	TIME [epoch: 8.54 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043703672080787875		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.043703672080787875 | validation: 0.03279836671989394]
	TIME [epoch: 8.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872480623215853		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.03872480623215853 | validation: 0.031242339603363686]
	TIME [epoch: 8.52 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04310473870725569		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.04310473870725569 | validation: 0.03367396778390771]
	TIME [epoch: 8.53 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04130091742498865		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.04130091742498865 | validation: 0.030013756570867647]
	TIME [epoch: 8.54 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0416108314617546		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.0416108314617546 | validation: 0.03313151580237784]
	TIME [epoch: 8.52 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039859148509558094		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.039859148509558094 | validation: 0.03202110139541439]
	TIME [epoch: 8.52 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036317348925482676		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.036317348925482676 | validation: 0.021951248914963084]
	TIME [epoch: 8.52 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036949195483560196		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.036949195483560196 | validation: 0.019203451903850553]
	TIME [epoch: 8.54 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03478118079767436		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.03478118079767436 | validation: 0.02994628515839968]
	TIME [epoch: 8.53 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872527623917447		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.03872527623917447 | validation: 0.03318378559846557]
	TIME [epoch: 8.54 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04216706946530141		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.04216706946530141 | validation: 0.031198797484064306]
	TIME [epoch: 8.55 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033499934145636026		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.033499934145636026 | validation: 0.036522424315536754]
	TIME [epoch: 8.54 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04261336448610524		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.04261336448610524 | validation: 0.03621915117507106]
	TIME [epoch: 8.53 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04121841594777863		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.04121841594777863 | validation: 0.02283996324506107]
	TIME [epoch: 8.53 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041815538236109825		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.041815538236109825 | validation: 0.0270846939025881]
	TIME [epoch: 8.55 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04195608868616903		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.04195608868616903 | validation: 0.03440695555506713]
	TIME [epoch: 8.54 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0436119716775115		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.0436119716775115 | validation: 0.018307695510777457]
	TIME [epoch: 8.54 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03314399326145617		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.03314399326145617 | validation: 0.020466586266438755]
	TIME [epoch: 8.53 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03729934919339396		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.03729934919339396 | validation: 0.02491205630726038]
	TIME [epoch: 8.55 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040246120106414075		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.040246120106414075 | validation: 0.033392585217785875]
	TIME [epoch: 8.54 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03805936969614264		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.03805936969614264 | validation: 0.025663220697174603]
	TIME [epoch: 8.54 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04068656207896192		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.04068656207896192 | validation: 0.03471262675906388]
	TIME [epoch: 8.54 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04395519444264605		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.04395519444264605 | validation: 0.02173374714458115]
	TIME [epoch: 8.56 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04226178201960871		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.04226178201960871 | validation: 0.032576603092339215]
	TIME [epoch: 8.54 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042269498853605564		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.042269498853605564 | validation: 0.029368571285221995]
	TIME [epoch: 8.54 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036521488365536		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.036521488365536 | validation: 0.02317993937314579]
	TIME [epoch: 8.53 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03490630270254201		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.03490630270254201 | validation: 0.031367121098033024]
	TIME [epoch: 8.55 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05309456101868547		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.05309456101868547 | validation: 0.02092190355675255]
	TIME [epoch: 8.54 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045271250698816864		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.045271250698816864 | validation: 0.03079064070524262]
	TIME [epoch: 8.54 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036021176022265615		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.036021176022265615 | validation: 0.03704477707312103]
	TIME [epoch: 8.54 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042451192438240984		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.042451192438240984 | validation: 0.03141553095390402]
	TIME [epoch: 8.56 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043030916750430206		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.043030916750430206 | validation: 0.014807351475858335]
	TIME [epoch: 8.54 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03877744863522237		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.03877744863522237 | validation: 0.022075886501326473]
	TIME [epoch: 8.53 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042360390201265426		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.042360390201265426 | validation: 0.028519726296802893]
	TIME [epoch: 8.53 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04136680684879409		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.04136680684879409 | validation: 0.025398461193868946]
	TIME [epoch: 8.56 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218971586414421		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.04218971586414421 | validation: 0.01950075741817838]
	TIME [epoch: 8.53 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040124453077523374		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.040124453077523374 | validation: 0.012143157679343708]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r2_20240219_183148/states/model_tr_study3_1983.pth
	Model improved!!!
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03840714068133495		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.03840714068133495 | validation: 0.037329707138977784]
	TIME [epoch: 8.55 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046742129349929426		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.046742129349929426 | validation: 0.018370921417183245]
	TIME [epoch: 8.55 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03898055092111408		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.03898055092111408 | validation: 0.027886333602419745]
	TIME [epoch: 8.55 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040449053176503616		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.040449053176503616 | validation: 0.03634582549140871]
	TIME [epoch: 8.54 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04386683552734963		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.04386683552734963 | validation: 0.02685375890938485]
	TIME [epoch: 8.57 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042147077489886574		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.042147077489886574 | validation: 0.02348029184668727]
	TIME [epoch: 8.55 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04064586822014894		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.04064586822014894 | validation: 0.0330048630822751]
	TIME [epoch: 8.54 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04405271939507723		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.04405271939507723 | validation: 0.03967526961532804]
	TIME [epoch: 8.54 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039922882512528915		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.039922882512528915 | validation: 0.02530318159678821]
	TIME [epoch: 8.56 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03876015360204575		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.03876015360204575 | validation: 0.03269956415836198]
	TIME [epoch: 8.54 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04807074049344075		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.04807074049344075 | validation: 0.03416737926627644]
	TIME [epoch: 8.54 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056305952248752775		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.056305952248752775 | validation: 0.04234628433375519]
	TIME [epoch: 8.54 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05268507415317939		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.05268507415317939 | validation: 0.029406678918373667]
	TIME [epoch: 8.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037367921570665055		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.037367921570665055 | validation: 0.023507514122936744]
	TIME [epoch: 8.54 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040471749479727724		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.040471749479727724 | validation: 0.0278470455556552]
	TIME [epoch: 8.54 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04015145896428972		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.04015145896428972 | validation: 0.03135176942060552]
	TIME [epoch: 8.53 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03727558660792818		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.03727558660792818 | validation: 0.02918776439949566]
	TIME [epoch: 8.56 sec]
Finished training in 17218.217 seconds.
