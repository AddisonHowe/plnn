Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3944694057

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.387327961750806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.387327961750806 | validation: 10.06483708508436]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.047067200850844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.047067200850844 | validation: 9.404025801671313]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.25388507851304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.25388507851304 | validation: 9.024814218552462]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.13148912551005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.13148912551005 | validation: 8.78620158388249]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.507035539066021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.507035539066021 | validation: 8.004444000166904]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.482321344933232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.482321344933232 | validation: 7.227969647880764]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.767041145178198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.767041145178198 | validation: 7.254289303759638]
	TIME [epoch: 24.9 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.247140506511317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.247140506511317 | validation: 7.2957609944192185]
	TIME [epoch: 25 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.940316872735121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.940316872735121 | validation: 7.443559066941443]
	TIME [epoch: 24.9 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.756452244382701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.756452244382701 | validation: 7.114193087343481]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.771598728198103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.771598728198103 | validation: 7.247486753094615]
	TIME [epoch: 25 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.740783893615944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.740783893615944 | validation: 7.90188351048327]
	TIME [epoch: 24.9 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.975534647075709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.975534647075709 | validation: 7.179151663767898]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.686537236193487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.686537236193487 | validation: 7.000080561343828]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.597504497840566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.597504497840566 | validation: 7.008114876418624]
	TIME [epoch: 25 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.452877549857401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.452877549857401 | validation: 6.047116550174496]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.006829461173389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.006829461173389 | validation: 6.086781266466625]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8482178994848155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8482178994848155 | validation: 5.862683350829251]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.799017227666446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.799017227666446 | validation: 5.7685507229834325]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768370000679044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.768370000679044 | validation: 5.761880807123134]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.857733054548735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.857733054548735 | validation: 5.705764515148751]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.905420760974972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.905420760974972 | validation: 5.705542688791698]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.702873504624591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.702873504624591 | validation: 7.634559928034178]
	TIME [epoch: 24.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.281126490879111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.281126490879111 | validation: 5.763128777628026]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747777249500151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.747777249500151 | validation: 5.865705611944931]
	TIME [epoch: 25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.655845377085693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.655845377085693 | validation: 5.629224280283538]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6805437065873425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6805437065873425 | validation: 5.548835204144312]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.614781451942537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.614781451942537 | validation: 5.504985963885811]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558723280891501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.558723280891501 | validation: 5.95139648297755]
	TIME [epoch: 24.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.618606256576302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.618606256576302 | validation: 5.798594860668048]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.895897944741709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.895897944741709 | validation: 5.695687294955596]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.623590115744574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.623590115744574 | validation: 5.647802915049247]
	TIME [epoch: 24.9 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.945749687210852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.945749687210852 | validation: 8.503584742010553]
	TIME [epoch: 25 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.480666473523343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.480666473523343 | validation: 5.6955426467937045]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.589077085088865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.589077085088865 | validation: 5.244522930264086]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.281114152966048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.281114152966048 | validation: 5.192974032664749]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.381249757896843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.381249757896843 | validation: 5.213046082530805]
	TIME [epoch: 24.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.440807780608732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.440807780608732 | validation: 5.112112972859777]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.030260792041291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.030260792041291 | validation: 5.042880298194553]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.13961916907161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.13961916907161 | validation: 5.09067906466385]
	TIME [epoch: 25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.075789068148912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.075789068148912 | validation: 5.8897124757736625]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.275935246056751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.275935246056751 | validation: 6.594438991305601]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.209940870678866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.209940870678866 | validation: 7.010358242261587]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3404039801453465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3404039801453465 | validation: 7.235948191570972]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.752468994953624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.752468994953624 | validation: 7.021820636728994]
	TIME [epoch: 25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.687402598618927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.687402598618927 | validation: 6.9420236179235575]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.421387083352445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.421387083352445 | validation: 5.717548277265746]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.36174731991583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.36174731991583 | validation: 5.241381949006116]
	TIME [epoch: 25 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.348259807244985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.348259807244985 | validation: 5.293437983249851]
	TIME [epoch: 24.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8901969387482325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8901969387482325 | validation: 5.491363332584649]
	TIME [epoch: 25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.284569469757408		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.284569469757408 | validation: 5.869600737175747]
	TIME [epoch: 25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.669170881269073		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.669170881269073 | validation: 5.372668732778152]
	TIME [epoch: 24.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2688479605322245		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.2688479605322245 | validation: 5.224611261046788]
	TIME [epoch: 25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.147200592214444		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.147200592214444 | validation: 5.0508078548088955]
	TIME [epoch: 25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.118908311984425		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 6.118908311984425 | validation: 6.4284743286730235]
	TIME [epoch: 24.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.269853391604987		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 6.269853391604987 | validation: 7.158824886236106]
	TIME [epoch: 25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.668886094764788		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 6.668886094764788 | validation: 6.337169217189394]
	TIME [epoch: 25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.924956260328047		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.924956260328047 | validation: 5.8502864646646575]
	TIME [epoch: 24.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4044962108913035		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.4044962108913035 | validation: 5.242981764150689]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.266299295639179		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.266299295639179 | validation: 5.095198631585877]
	TIME [epoch: 25 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.267500077733377		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.267500077733377 | validation: 5.216311616218875]
	TIME [epoch: 24.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.333651758256626		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.333651758256626 | validation: 5.320762757196705]
	TIME [epoch: 25 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.320086360775645		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.320086360775645 | validation: 4.938770611252776]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.202063259531778		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.202063259531778 | validation: 5.749108874194803]
	TIME [epoch: 24.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4723179716406944		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.4723179716406944 | validation: 4.967094984475043]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.885408220964016		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.885408220964016 | validation: 4.778604815734479]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.016358070984262		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.016358070984262 | validation: 5.420999965543376]
	TIME [epoch: 24.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.938801166178632		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.938801166178632 | validation: 4.714361890477083]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517773177364813		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.517773177364813 | validation: 4.51381478359875]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496755473450442		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.496755473450442 | validation: 4.699302912835992]
	TIME [epoch: 24.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.813765541212462		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.813765541212462 | validation: 4.826544270082852]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.110136954818478		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.110136954818478 | validation: 4.939547099356544]
	TIME [epoch: 25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541726619318794		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.541726619318794 | validation: 4.56896645351808]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479906967555339		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.479906967555339 | validation: 4.482142726115099]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.307721896930081		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.307721896930081 | validation: 4.816953350630118]
	TIME [epoch: 25 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785762354330042		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.785762354330042 | validation: 4.4054819655594155]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.24323171686444		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.24323171686444 | validation: 4.430708863074438]
	TIME [epoch: 24.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.329879157144787		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.329879157144787 | validation: 4.38489638357049]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.198760037189318		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.198760037189318 | validation: 4.215094108761462]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096813205804251		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.096813205804251 | validation: 4.124294730380725]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9430628640187315		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.9430628640187315 | validation: 5.000776004386117]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.245996533409411		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.245996533409411 | validation: 4.142555579866962]
	TIME [epoch: 24.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.060861756934564		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.060861756934564 | validation: 4.021489147313411]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.979003663751729		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.979003663751729 | validation: 3.9652726610345654]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.758521156565707		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.758521156565707 | validation: 4.303587779961463]
	TIME [epoch: 24.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.314627061316606		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.314627061316606 | validation: 4.161782127182816]
	TIME [epoch: 24.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8159388909074323		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.8159388909074323 | validation: 3.942425673966973]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9688124097665756		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.9688124097665756 | validation: 4.05524268319387]
	TIME [epoch: 24.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040899145676652		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.040899145676652 | validation: 3.891829755136567]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6259099511975985		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.6259099511975985 | validation: 3.913916611327504]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6606750680503746		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.6606750680503746 | validation: 3.8405589416358783]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4712724041220167		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.4712724041220167 | validation: 4.504295252410154]
	TIME [epoch: 24.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8171869017346474		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.8171869017346474 | validation: 3.802755956587528]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6464840319013536		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.6464840319013536 | validation: 3.623787749315196]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5534930529623225		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.5534930529623225 | validation: 3.598858249588951]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5115631983156392		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.5115631983156392 | validation: 3.672469448317361]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.648355639632644		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.648355639632644 | validation: 3.820501948217587]
	TIME [epoch: 24.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4594550114362934		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.4594550114362934 | validation: 3.718926388592488]
	TIME [epoch: 24.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457271477275202		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.457271477275202 | validation: 4.444792234331553]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4869458835279823		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.4869458835279823 | validation: 3.3388863133213182]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369789716103334		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.369789716103334 | validation: 3.5572009013643155]
	TIME [epoch: 24.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.359012859109364		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.359012859109364 | validation: 3.573579735753776]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4380282779079865		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.4380282779079865 | validation: 4.232732023697533]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.725175349741069		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.725175349741069 | validation: 3.468119357229515]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391523801841555		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.391523801841555 | validation: 4.04809223596297]
	TIME [epoch: 25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5315371693816338		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.5315371693816338 | validation: 3.3192567941804407]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.140876671430865		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.140876671430865 | validation: 3.513262661277295]
	TIME [epoch: 24.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.194112779041399		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.194112779041399 | validation: 3.8169845290918443]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1243162158169904		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.1243162158169904 | validation: 3.59771360177974]
	TIME [epoch: 24.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2837545186640313		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.2837545186640313 | validation: 3.919167548403558]
	TIME [epoch: 24.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2305350037543676		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.2305350037543676 | validation: 3.5093974430133303]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182462789890245		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.2182462789890245 | validation: 3.3875995553956906]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.954401010082443		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.954401010082443 | validation: 3.0976363456323663]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3092196264474105		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.3092196264474105 | validation: 3.334779512312356]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9660835694068504		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.9660835694068504 | validation: 3.293545662723525]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207896212555643		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.207896212555643 | validation: 3.1476436256692386]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9836924015629616		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.9836924015629616 | validation: 3.0504094047979824]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8084743243398695		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.8084743243398695 | validation: 2.8380774616560056]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7142397432994017		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.7142397432994017 | validation: 3.00581444473363]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8098901496538025		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.8098901496538025 | validation: 3.38325769140841]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0127512356449206		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.0127512356449206 | validation: 2.7787202335076415]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8295068277771183		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.8295068277771183 | validation: 3.0579514170863473]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.564613658410381		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.564613658410381 | validation: 2.8381367658141845]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.730748615844639		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.730748615844639 | validation: 4.438570442544051]
	TIME [epoch: 25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0855007029619808		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.0855007029619808 | validation: 2.6269452489528327]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7874635785112822		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.7874635785112822 | validation: 3.0619854124471915]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.626663595435172		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.626663595435172 | validation: 3.201319916816573]
	TIME [epoch: 25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.769435990675757		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.769435990675757 | validation: 3.0955636179730415]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5205783438696003		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.5205783438696003 | validation: 3.423057218116527]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639457124719977		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.639457124719977 | validation: 3.606822898755901]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8054453104419235		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.8054453104419235 | validation: 2.913301726468504]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8218338457166237		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.8218338457166237 | validation: 2.6321366565838913]
	TIME [epoch: 25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.831547298828131		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.831547298828131 | validation: 2.8197384721329217]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.527309762500831		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.527309762500831 | validation: 3.3429817773115906]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7934458677063834		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.7934458677063834 | validation: 2.632985212057643]
	TIME [epoch: 24.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7302733107269845		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.7302733107269845 | validation: 2.8229106695845094]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387971022620781		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.387971022620781 | validation: 2.8387113455041866]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2454752003658918		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.2454752003658918 | validation: 3.079349691023624]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0446693519853176		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.0446693519853176 | validation: 4.947465726892111]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.92958196861737		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.92958196861737 | validation: 3.5907355762117836]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.156023745112092		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.156023745112092 | validation: 2.8276669978002413]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.602280319783564		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.602280319783564 | validation: 2.8660237288988935]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523706388545839		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.523706388545839 | validation: 3.5473187150185588]
	TIME [epoch: 24.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9214001766731097		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.9214001766731097 | validation: 2.7633228743954827]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4509551354615		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.4509551354615 | validation: 3.3143054094959004]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1612687401990023		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.1612687401990023 | validation: 3.105896187815324]
	TIME [epoch: 24.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6316647924327645		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.6316647924327645 | validation: 2.8119015716059756]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.633047211907022		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.633047211907022 | validation: 2.781655615245327]
	TIME [epoch: 25 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6616072855543518		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.6616072855543518 | validation: 2.697229754505506]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3767216746514577		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.3767216746514577 | validation: 2.74856862860368]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4644756066771607		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.4644756066771607 | validation: 4.453846835220037]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7461454650174524		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.7461454650174524 | validation: 7.137676997916962]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.546374952502192		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 7.546374952502192 | validation: 7.297828889873173]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.853203058401133		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 6.853203058401133 | validation: 7.177408789008073]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.918247880000838		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 4.918247880000838 | validation: 3.4806126055725977]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.048566574911022		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.048566574911022 | validation: 2.7776209239634087]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734869738121069		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.734869738121069 | validation: 3.0067879323852913]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.003343415755591		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.003343415755591 | validation: 4.653541383815222]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7371052066168353		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.7371052066168353 | validation: 4.447545090659869]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5126961701511528		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.5126961701511528 | validation: 3.3706082641456767]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6868872153091066		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.6868872153091066 | validation: 2.785227380307335]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4781894484668205		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.4781894484668205 | validation: 3.1852498316991773]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.522820924416377		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.522820924416377 | validation: 2.5791567789127328]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.090907119253387		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 5.090907119253387 | validation: 7.423836072073206]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.984821504874233		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 6.984821504874233 | validation: 7.323271242933276]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.773497104405167		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 6.773497104405167 | validation: 7.144492978475621]
	TIME [epoch: 24.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.920893505004418		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 6.920893505004418 | validation: 7.12618391189596]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.781427145722036		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 6.781427145722036 | validation: 7.161713449755719]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.731959603118195		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 6.731959603118195 | validation: 7.025946948134151]
	TIME [epoch: 24.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.012785801475458		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 6.012785801475458 | validation: 3.754578632138059]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9967012238522486		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.9967012238522486 | validation: 3.0688685828038422]
	TIME [epoch: 24.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5630757892939515		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.5630757892939515 | validation: 3.305600085404533]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7244207909934444		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.7244207909934444 | validation: 2.7405847158965964]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4646649743978792		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.4646649743978792 | validation: 2.571958079389509]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4478775594707325		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.4478775594707325 | validation: 2.6601948341987973]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4690860952947826		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.4690860952947826 | validation: 2.624998150404954]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5384883722656277		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.5384883722656277 | validation: 2.585619091514315]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4770557734516347		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.4770557734516347 | validation: 2.9290290002345523]
	TIME [epoch: 24.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490710645131732		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.490710645131732 | validation: 2.420524486676954]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2735594874623235		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.2735594874623235 | validation: 2.6144952109681094]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2995113529058697		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.2995113529058697 | validation: 2.387630150052339]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2991673987887036		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.2991673987887036 | validation: 2.864599852740472]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484208231365532		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.484208231365532 | validation: 2.557802363255907]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2533060842091213		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.2533060842091213 | validation: 2.4546609503502306]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4808791219696213		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.4808791219696213 | validation: 2.8911287020906435]
	TIME [epoch: 24.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.447598680480876		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.447598680480876 | validation: 2.907944755263857]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4403731453409843		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.4403731453409843 | validation: 2.512694060153153]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3099620855196203		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.3099620855196203 | validation: 2.45519230315524]
	TIME [epoch: 24.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.846384107094958		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.846384107094958 | validation: 3.5469412437058145]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8592986755811225		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.8592986755811225 | validation: 2.7641677282731765]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7457863493327626		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.7457863493327626 | validation: 3.104687168182497]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.628571841750043		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.628571841750043 | validation: 2.690373987397075]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282262641647326		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.282262641647326 | validation: 2.331833298617527]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360987570847976		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.360987570847976 | validation: 2.5709524212119423]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858501311877296		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.858501311877296 | validation: 4.796010034815128]
	TIME [epoch: 24.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9518671333653463		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.9518671333653463 | validation: 2.804398411348733]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1663342921050335		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.1663342921050335 | validation: 2.557068335579389]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177589560198043		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.177589560198043 | validation: 2.425910471260639]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3471515390122617		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.3471515390122617 | validation: 3.2889089442172725]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354920669033767		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.354920669033767 | validation: 3.445368993735663]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.608005648916181		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.608005648916181 | validation: 2.5900187226375575]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2202767361374174		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.2202767361374174 | validation: 2.8876697757932464]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329464038936755		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.329464038936755 | validation: 2.2882423519496955]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1636620153786668		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.1636620153786668 | validation: 2.295365888782466]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3078515735739398		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.3078515735739398 | validation: 2.3772184562496914]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2120534438015103		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.2120534438015103 | validation: 2.3411669978644096]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12423639106443		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.12423639106443 | validation: 2.31867688032844]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1948034704387087		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.1948034704387087 | validation: 2.978618753303534]
	TIME [epoch: 25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3274086076573965		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.3274086076573965 | validation: 2.298325240790638]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.176655827096274		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.176655827096274 | validation: 2.414800782225203]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1226873992186217		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.1226873992186217 | validation: 2.261037910994869]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045562758640788		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.045562758640788 | validation: 2.9480703106548822]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247462361863044		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.247462361863044 | validation: 2.386747720823259]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083426396924282		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.083426396924282 | validation: 2.5992922540684296]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0872930821941282		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.0872930821941282 | validation: 2.240805238318247]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9322648248176173		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.9322648248176173 | validation: 2.6079083928590685]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1209625460211616		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.1209625460211616 | validation: 2.5902344948175675]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.081680992025407		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.081680992025407 | validation: 2.303440263992037]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0805271963150016		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.0805271963150016 | validation: 2.3833929020629627]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030439000170154		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.030439000170154 | validation: 2.175822780386281]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367405588088502		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.367405588088502 | validation: 2.4900646259905375]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1891572476719983		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.1891572476719983 | validation: 2.1585046586212293]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075291528731073		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.075291528731073 | validation: 3.0538311777352414]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322719017674756		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.322719017674756 | validation: 2.326574056586124]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9339533832655018		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.9339533832655018 | validation: 2.4320669062610802]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050780644463551		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.050780644463551 | validation: 2.3909319163607843]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089905757425262		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.089905757425262 | validation: 2.1660874635673166]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1754568159919123		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.1754568159919123 | validation: 2.45022090241918]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0636126867199813		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.0636126867199813 | validation: 2.280138988001019]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0501093579712157		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.0501093579712157 | validation: 2.1773134390762823]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9176076105223672		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.9176076105223672 | validation: 2.330088449091486]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8900650596563189		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.8900650596563189 | validation: 2.4075101399636494]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.363157207196314		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.363157207196314 | validation: 2.458153979714691]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110648726300507		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.110648726300507 | validation: 2.515834213211929]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9374419492506227		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.9374419492506227 | validation: 2.086775709652843]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8842314816798953		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.8842314816798953 | validation: 2.0605957373139754]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277438818879353		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.277438818879353 | validation: 2.180263620102465]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9804131983357967		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.9804131983357967 | validation: 2.2562380712120684]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8828602660982754		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.8828602660982754 | validation: 2.4617126584107574]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.982915700936783		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.982915700936783 | validation: 2.1891705635838656]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0478984033474195		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.0478984033474195 | validation: 2.156636582154983]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0675360165402563		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.0675360165402563 | validation: 2.5148066921470122]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2997632004315207		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.2997632004315207 | validation: 2.5481077423233334]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1189751816205464		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.1189751816205464 | validation: 1.6935524815286747]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5069221035487979		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.5069221035487979 | validation: 1.844955231679776]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4660601210482758		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.4660601210482758 | validation: 1.1491029866121303]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3187176009150643		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.3187176009150643 | validation: 1.345469840987362]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5761540190361112		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.5761540190361112 | validation: 2.102689769665503]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9460138660989368		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.9460138660989368 | validation: 2.0940043664542833]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9959967087338475		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.9959967087338475 | validation: 1.3504691677165246]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2178819715602685		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.2178819715602685 | validation: 2.58156939052292]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1408918937842403		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.1408918937842403 | validation: 2.2819455990557085]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9274140490497114		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.9274140490497114 | validation: 2.1629166054159503]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5806610617425392		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.5806610617425392 | validation: 1.9421258332272546]
	TIME [epoch: 25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2818285537274154		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.2818285537274154 | validation: 2.2095404127735714]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4545412672200275		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.4545412672200275 | validation: 1.4014528876309271]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4689840966000616		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.4689840966000616 | validation: 1.4952845131011514]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1904982302220208		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.1904982302220208 | validation: 0.9602042758276048]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629461093518768		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.0629461093518768 | validation: 0.9998792061160547]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579922464434377		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.0579922464434377 | validation: 1.1719012193851044]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577728182713995		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0577728182713995 | validation: 1.147441897135733]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1534225099749174		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.1534225099749174 | validation: 1.0868400285505073]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0367200043588713		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.0367200043588713 | validation: 1.495256113326655]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4252074659134344		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.4252074659134344 | validation: 1.0313942810344123]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235698996622582		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.235698996622582 | validation: 1.5473612290172796]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2379252910826917		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.2379252910826917 | validation: 0.9399121017341867]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3672817949273395		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.3672817949273395 | validation: 2.543697560006418]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6330664836437507		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.6330664836437507 | validation: 1.607261733542445]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1202964482943427		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.1202964482943427 | validation: 1.0457217293567487]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9271442252733508		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.9271442252733508 | validation: 0.8495293851397895]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2048004551255551		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.2048004551255551 | validation: 1.8513697433139527]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1070432453393095		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.1070432453393095 | validation: 1.6778240993417135]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2017736767709541		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2017736767709541 | validation: 0.8941935810743047]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391056770741752		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.1391056770741752 | validation: 1.980520407649906]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4514908345340753		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.4514908345340753 | validation: 1.0871191644129186]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.996098348240536		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.996098348240536 | validation: 1.1323455742088333]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.99998139860843		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.99998139860843 | validation: 1.1874891450029412]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2936759792153185		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.2936759792153185 | validation: 1.1739088029378562]
	TIME [epoch: 25 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9666363265325368		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.9666363265325368 | validation: 1.8686860836650445]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4971018612708935		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.4971018612708935 | validation: 1.8705735785680708]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9474990509618255		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.9474990509618255 | validation: 1.6479210429156852]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6602556788933391		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.6602556788933391 | validation: 1.8950183843018102]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.607010224715509		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.607010224715509 | validation: 0.9907626535134625]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07809778091748		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.07809778091748 | validation: 0.8364125751443802]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9574307158230575		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.9574307158230575 | validation: 0.9096304659315948]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4863838645297787		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.4863838645297787 | validation: 1.7606213728449356]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.548767700678553		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.548767700678553 | validation: 1.3506511890465884]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2580153003383736		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.2580153003383736 | validation: 0.8264070041453703]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094433219731821		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.094433219731821 | validation: 0.8113650919355412]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9510337908597517		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.9510337908597517 | validation: 1.3573650325796243]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039918897870364		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.039918897870364 | validation: 1.1861266901663314]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1663779608893519		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.1663779608893519 | validation: 0.9851549235910934]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.007867644968722		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.007867644968722 | validation: 1.431658130510357]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2073404139982964		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.2073404139982964 | validation: 0.8673458553288357]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9020093799003099		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9020093799003099 | validation: 1.1430147780113773]
	TIME [epoch: 24.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.503006696771179		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.503006696771179 | validation: 1.8067475403640116]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1907691389867887		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.1907691389867887 | validation: 1.505330962118932]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240509966950028		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.240509966950028 | validation: 1.6881601355433185]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2522775009094365		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.2522775009094365 | validation: 1.1612958665518351]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9998223779893821		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.9998223779893821 | validation: 1.0501568739955502]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9344371012079822		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.9344371012079822 | validation: 1.5165711770315649]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.122336481537764		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.122336481537764 | validation: 2.442037249232769]
	TIME [epoch: 25 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7957028016654284		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.7957028016654284 | validation: 1.6560542910434677]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296261118708396		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.2296261118708396 | validation: 1.3392365224975402]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1850901947940293		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.1850901947940293 | validation: 1.7988537332489245]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9768819893785077		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.9768819893785077 | validation: 2.1474545339834537]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5108215059917214		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.5108215059917214 | validation: 1.8547909387679906]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.456771743407877		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.456771743407877 | validation: 1.630150770889868]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2169644955348031		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.2169644955348031 | validation: 1.030739438170186]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1805190268967167		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.1805190268967167 | validation: 0.9324393551285427]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9414104050991391		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.9414104050991391 | validation: 1.6434946635633403]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0448073348669626		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.0448073348669626 | validation: 0.9884811073948092]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.001141075980597		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.001141075980597 | validation: 1.1288727921215769]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1140891446691281		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.1140891446691281 | validation: 1.6096461965017357]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3282148017574849		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.3282148017574849 | validation: 0.9936028268819999]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.843460878352112		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.843460878352112 | validation: 0.7810251520386843]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9168663599179557		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.9168663599179557 | validation: 0.7726585564097146]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0200303698861979		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.0200303698861979 | validation: 1.2427235796720448]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1973781432437762		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.1973781432437762 | validation: 1.7443275629789186]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2599862149635301		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.2599862149635301 | validation: 0.922413527488543]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8966370280452407		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.8966370280452407 | validation: 0.8901627664032552]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075574304768161		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.9075574304768161 | validation: 1.2044755904868933]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033257048022671		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.033257048022671 | validation: 0.8992291839099926]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0454960079389644		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.0454960079389644 | validation: 0.7441878915624256]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8653803968671201		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8653803968671201 | validation: 1.0160752027587703]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5542606815059705		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.5542606815059705 | validation: 0.9834702633794506]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9185480374889032		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.9185480374889032 | validation: 1.0025670237063438]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9349458276687201		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9349458276687201 | validation: 1.30058592780072]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4078249295502931		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.4078249295502931 | validation: 2.1674106491393834]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.596801011425774		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.596801011425774 | validation: 1.112293046973405]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400713157349804		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8400713157349804 | validation: 1.2565108509030756]
	TIME [epoch: 24.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0198994766126028		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0198994766126028 | validation: 1.0718686439905556]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8347927689388194		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8347927689388194 | validation: 0.8830113069074039]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8694142973886163		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8694142973886163 | validation: 0.8725428069005233]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421376175302049		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8421376175302049 | validation: 1.4573438577224287]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3910761702801269		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.3910761702801269 | validation: 1.188683256484353]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9569515587483033		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.9569515587483033 | validation: 0.7489934472529529]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8513638177728504		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8513638177728504 | validation: 0.776032545583738]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8730109463322134		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.8730109463322134 | validation: 0.6236300443200361]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850283711498981		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6850283711498981 | validation: 0.6612867655943003]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782298457726272		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6782298457726272 | validation: 1.4982072558640038]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2222251914019222		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.2222251914019222 | validation: 0.8334069364627077]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8586391454173325		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8586391454173325 | validation: 0.6753518489471931]
	TIME [epoch: 24.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8548146621093136		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8548146621093136 | validation: 1.0156847296663234]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8144291557063873		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8144291557063873 | validation: 0.927407168603408]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704462937959672		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.704462937959672 | validation: 0.5538398514682402]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154497129500362		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8154497129500362 | validation: 0.7625348353702467]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8778551825110128		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.8778551825110128 | validation: 0.9226531156957378]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9340786357959545		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.9340786357959545 | validation: 0.5574139452804016]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7104447705491606		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7104447705491606 | validation: 1.0646402602046658]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034404898961287		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7034404898961287 | validation: 0.5789770822678463]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61730433718271		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.61730433718271 | validation: 0.9425208042802083]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8804531477684673		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.8804531477684673 | validation: 0.483258043406875]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004429466115528		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7004429466115528 | validation: 0.7293760908344729]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545297029530142		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7545297029530142 | validation: 0.7130948326486987]
	TIME [epoch: 24.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6654178804479152		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6654178804479152 | validation: 0.7864383344521051]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7298944444829862		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7298944444829862 | validation: 1.0125458328900214]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8485977531811526		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8485977531811526 | validation: 1.4115762757978128]
	TIME [epoch: 24.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0734462792798636		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.0734462792798636 | validation: 0.6911217343047005]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581263824849068		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6581263824849068 | validation: 1.0500837347136793]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961399859600436		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6961399859600436 | validation: 0.6409715267718277]
	TIME [epoch: 24.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493609517726603		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6493609517726603 | validation: 0.720060268544431]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6417054635426684		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6417054635426684 | validation: 0.5391158693374951]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694131480832288		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.694131480832288 | validation: 0.6448483904354031]
	TIME [epoch: 24.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6380244090385426		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6380244090385426 | validation: 0.5750215604291916]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486567640344725		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5486567640344725 | validation: 1.4204012838617548]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3728023553338575		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.3728023553338575 | validation: 0.6015811757678582]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9059203481368449		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.9059203481368449 | validation: 0.5765459677319449]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834701226175236		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5834701226175236 | validation: 0.5072863026885315]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525506048064191		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6525506048064191 | validation: 0.7885411957609634]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6666848163956001		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6666848163956001 | validation: 0.6033566471685756]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232193613892183		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6232193613892183 | validation: 0.6931485642470077]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830353726059627		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6830353726059627 | validation: 0.5792309685129233]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444877247060536		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6444877247060536 | validation: 0.6411520223789193]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9138954306770202		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9138954306770202 | validation: 0.8841309511245626]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941240285051625		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.941240285051625 | validation: 0.8339161264254941]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6627396185444168		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6627396185444168 | validation: 0.5802316421331737]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685050040113056		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6685050040113056 | validation: 0.6893000106814572]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629108720179926		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.6629108720179926 | validation: 0.4773703386514876]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65304450216163		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.65304450216163 | validation: 0.5257988064580706]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022303213034167		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7022303213034167 | validation: 0.6169992316758639]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839797732036764		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5839797732036764 | validation: 1.8627562985811728]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0134890193061905		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.0134890193061905 | validation: 0.6050472101999833]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677668373535049		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7677668373535049 | validation: 0.6618523055646712]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8390109293730263		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8390109293730263 | validation: 0.7561587234122111]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6355712194811354		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6355712194811354 | validation: 1.0806101196634277]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8693685794961391		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.8693685794961391 | validation: 0.6317533480279933]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.798102242718545		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.798102242718545 | validation: 1.1146941184485846]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019525096443492		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.019525096443492 | validation: 1.0068044326912282]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9905761104550326		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.9905761104550326 | validation: 1.1101492517878122]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9187636966526765		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.9187636966526765 | validation: 1.044287801280464]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729983333108963		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6729983333108963 | validation: 0.6047274665260548]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6659578096216556		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.6659578096216556 | validation: 0.635304554988195]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066327569152559		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.8066327569152559 | validation: 1.2052455413358616]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0415242073512752		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.0415242073512752 | validation: 0.6419372083626681]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347579667246833		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.9347579667246833 | validation: 0.8915576764976336]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551966454177728		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.6551966454177728 | validation: 0.5798660462523698]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636977786364463		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5636977786364463 | validation: 0.5620133375464842]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6460090127235272		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6460090127235272 | validation: 1.1796245529532288]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7539858936732311		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7539858936732311 | validation: 1.8193096994040077]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2765796970842482		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.2765796970842482 | validation: 0.6502480242022202]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859550265958059		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.6859550265958059 | validation: 0.6652632246546257]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9395867021213667		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.9395867021213667 | validation: 0.7203604976024051]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236569739968358		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7236569739968358 | validation: 0.630957686668574]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049065265152664		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6049065265152664 | validation: 0.48570905748232024]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540692243783219		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.6540692243783219 | validation: 0.7217315037940327]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9606280904505788		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.9606280904505788 | validation: 1.0603382785146807]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520519290381954		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.1520519290381954 | validation: 0.8264517568426771]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426688643560322		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7426688643560322 | validation: 0.5914883729170416]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911753271908422		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7911753271908422 | validation: 0.7457809495499237]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839372625525441		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.839372625525441 | validation: 1.310192464017651]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0327186410422273		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.0327186410422273 | validation: 1.4714702547403744]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9489506634600456		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.9489506634600456 | validation: 0.7437722182144699]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110257179991495		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7110257179991495 | validation: 0.640456497651657]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496730662009566		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.6496730662009566 | validation: 0.503770768764269]
	TIME [epoch: 24.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297677351673917		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5297677351673917 | validation: 0.8366225528816841]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6898675934201658		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.6898675934201658 | validation: 0.5854003119738898]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073673203035074		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6073673203035074 | validation: 0.47821415907816694]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5777209960082942		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5777209960082942 | validation: 1.3217323951842568]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176665687180758		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.9176665687180758 | validation: 0.666817781146049]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.583580125042922		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.583580125042922 | validation: 0.9397152743032087]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6636827244739181		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6636827244739181 | validation: 0.5668551330834355]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161861897749336		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5161861897749336 | validation: 0.9457616301164512]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626289308855129		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.7626289308855129 | validation: 0.9036650748002555]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8494684154211143		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8494684154211143 | validation: 0.9327506998763357]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734918380165883		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7734918380165883 | validation: 1.0279320846049127]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1944741495043365		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.1944741495043365 | validation: 1.5665502916780016]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1122585198523267		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.1122585198523267 | validation: 1.0132643816427414]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8258631691891958		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.8258631691891958 | validation: 0.8681508306102288]
	TIME [epoch: 25 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935293345062838		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6935293345062838 | validation: 0.6326130542960284]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288895358781216		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5288895358781216 | validation: 0.5592305178681849]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073698907307491		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7073698907307491 | validation: 0.53053016930649]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6144202895604047		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6144202895604047 | validation: 0.48976529610993413]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4958622700169958		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.4958622700169958 | validation: 0.5234649294635426]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686383013407523		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5686383013407523 | validation: 0.8736601598389961]
	TIME [epoch: 25 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403612755896722		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7403612755896722 | validation: 1.0909479138218239]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9355786182120867		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.9355786182120867 | validation: 1.4191055536656219]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7770312592669953		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.7770312592669953 | validation: 0.6515781644671177]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973764097243981		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5973764097243981 | validation: 0.46088292512235407]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255180141269312		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.6255180141269312 | validation: 1.0361448330888652]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7836302727539302		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7836302727539302 | validation: 0.8125507508127728]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055383897176947		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7055383897176947 | validation: 0.7011144483938401]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938832855187238		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5938832855187238 | validation: 0.5658945448152556]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764252821807327		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5764252821807327 | validation: 0.5064399732291478]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642927759684568		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5642927759684568 | validation: 0.8218908389571769]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464495202040314		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7464495202040314 | validation: 0.49232120529285556]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626802307967355		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5626802307967355 | validation: 0.5997034691980744]
	TIME [epoch: 25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100539857779579		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.6100539857779579 | validation: 0.5194319819198409]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6783804495024572		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6783804495024572 | validation: 0.5300871280832054]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681317716564073		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.681317716564073 | validation: 0.46434742551713426]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183686509657799		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5183686509657799 | validation: 0.703719600462301]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549379160417107		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.5549379160417107 | validation: 0.9263833684540587]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5969288696014683		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.5969288696014683 | validation: 0.6440097741874486]
	TIME [epoch: 25 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486699265163524		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7486699265163524 | validation: 1.2566288647177992]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9427631258659898		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.9427631258659898 | validation: 0.9955354053668655]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651588771502305		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7651588771502305 | validation: 0.8747868024642179]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.774899151593532		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.774899151593532 | validation: 0.5045931658952029]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671205967395878		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4671205967395878 | validation: 0.40187202736510613]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4889116479264968		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.4889116479264968 | validation: 0.5457626854791248]
	TIME [epoch: 25 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636850551713662		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.636850551713662 | validation: 1.2849430880480517]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6686915159774831		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6686915159774831 | validation: 0.53573748247524]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470591081090035		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5470591081090035 | validation: 0.6905984332632091]
	TIME [epoch: 25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5420940676306378		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5420940676306378 | validation: 0.5126908158773769]
	TIME [epoch: 25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329756078196209		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.6329756078196209 | validation: 0.5095063961711291]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.580482013455121		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.580482013455121 | validation: 0.6084674600883142]
	TIME [epoch: 25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306052817107224		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5306052817107224 | validation: 1.0371756844115998]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531916265881446		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7531916265881446 | validation: 0.7330854880450913]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8728374745967203		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.8728374745967203 | validation: 0.6643644361304192]
	TIME [epoch: 25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582160183653952		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.582160183653952 | validation: 0.8354554721424483]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.524531088316164		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.524531088316164 | validation: 0.44958740285860005]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4922456643576024		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.4922456643576024 | validation: 0.37596758427882476]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278371535322753		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6278371535322753 | validation: 0.46538066100436043]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625397869630574		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.4625397869630574 | validation: 0.6193794014358954]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542858867136051		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.542858867136051 | validation: 0.4469387758450813]
	TIME [epoch: 25 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720752500581416		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.3720752500581416 | validation: 0.709999149160133]
	TIME [epoch: 25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501550428418817		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5501550428418817 | validation: 0.8584915725508667]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6182168382628048		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.6182168382628048 | validation: 1.0748285927707466]
	TIME [epoch: 25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728015962262688		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7728015962262688 | validation: 0.5543459925588637]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055366291430792		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5055366291430792 | validation: 0.5100075187066261]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509496026374556		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5509496026374556 | validation: 0.4840944541406226]
	TIME [epoch: 25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789971331715619		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.4789971331715619 | validation: 0.3680301065138946]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129378608064478		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4129378608064478 | validation: 0.4317511187586468]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492903839697169		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4492903839697169 | validation: 0.5964823698222846]
	TIME [epoch: 25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281415832187112		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5281415832187112 | validation: 0.7297590174826496]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525758778225105		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5525758778225105 | validation: 0.8400133750766563]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312930528931997		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5312930528931997 | validation: 0.907470399994668]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.778302493538579		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.778302493538579 | validation: 0.5097828355060463]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427706381093104		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7427706381093104 | validation: 0.591581496951717]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044644245098528		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.7044644245098528 | validation: 0.6846546761025332]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5798679667897525		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5798679667897525 | validation: 0.49740803903935643]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685878962951979		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.6685878962951979 | validation: 1.0499458082671087]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337044683742369		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6337044683742369 | validation: 0.6965804584935475]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390086506711232		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6390086506711232 | validation: 0.7754365605300061]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739736984498078		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.739736984498078 | validation: 0.6685209157584835]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961918154582739		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5961918154582739 | validation: 0.9491663762061877]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554842002402333		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.554842002402333 | validation: 0.9831417674128884]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044851875206215		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6044851875206215 | validation: 0.5687140114823174]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598391108415134		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.6598391108415134 | validation: 0.6428238542725743]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696414857954939		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5696414857954939 | validation: 0.7843500229384813]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662187623110813		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.662187623110813 | validation: 0.785404530502048]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49690324102865996		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.49690324102865996 | validation: 0.5460268756086759]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662625692713059		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.662625692713059 | validation: 0.8754014503845947]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8267512335735694		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.8267512335735694 | validation: 0.9586405988377987]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925062595556092		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5925062595556092 | validation: 0.4912616498673698]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42328493996652516		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.42328493996652516 | validation: 0.37339814363303653]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074738911943308		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.4074738911943308 | validation: 0.8935670091016837]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763169282042998		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6763169282042998 | validation: 0.5408307000772262]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5990603572620175		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5990603572620175 | validation: 0.46577792326261075]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45691474388830877		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.45691474388830877 | validation: 0.4337010859241226]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42609955302133834		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.42609955302133834 | validation: 0.5660460776660005]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548595279964873		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.6548595279964873 | validation: 0.40248823385116134]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51967392787782		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.51967392787782 | validation: 0.44354803904178275]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916675045059767		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3916675045059767 | validation: 0.6193200860046923]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173711839429082		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5173711839429082 | validation: 0.4028695058765349]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201039309468253		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.4201039309468253 | validation: 0.3940494829297627]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208535023735309		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5208535023735309 | validation: 0.630379282843485]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016001432923909		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5016001432923909 | validation: 0.4677550185845658]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297557125616805		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.4297557125616805 | validation: 0.401881116213889]
	TIME [epoch: 24.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49739551582764996		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.49739551582764996 | validation: 0.42699076560208915]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579319009192705		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5579319009192705 | validation: 0.36592399092666805]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36569786752110955		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.36569786752110955 | validation: 1.3425217374860752]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207367184862399		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.7207367184862399 | validation: 0.5238674156807133]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687255214601315		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.4687255214601315 | validation: 0.4641636366047449]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45802755487572544		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.45802755487572544 | validation: 0.31466477855841923]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448604383896404		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4448604383896404 | validation: 0.5078352673735684]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199128603065459		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5199128603065459 | validation: 0.46415135831787996]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152048045144242		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6152048045144242 | validation: 0.5654589862212076]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.64561663156616		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.64561663156616 | validation: 0.7554224428288996]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086691534796613		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6086691534796613 | validation: 0.43497598180192387]
	TIME [epoch: 24.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37568929463681205		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.37568929463681205 | validation: 0.545260621213349]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6380937813720147		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6380937813720147 | validation: 0.789775434738791]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797144627971996		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.6797144627971996 | validation: 0.5715880175771798]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44445637075589806		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.44445637075589806 | validation: 0.47088445176051763]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39144479525081993		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.39144479525081993 | validation: 0.7282570396448774]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49536398310545887		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.49536398310545887 | validation: 0.43333919603940446]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728168438551914		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.3728168438551914 | validation: 0.42457020460288647]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227462536203125		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4227462536203125 | validation: 0.5433605725672124]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727241898629039		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.4727241898629039 | validation: 0.40873164798401007]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555855872323971		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3555855872323971 | validation: 0.46979774548273456]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5276414508058321		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5276414508058321 | validation: 0.5475127637250097]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933093193169337		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.3933093193169337 | validation: 0.40507564261439727]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34643671430242196		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.34643671430242196 | validation: 0.5477416808543407]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41612536040670983		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.41612536040670983 | validation: 0.42503989824183463]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35809735135617304		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.35809735135617304 | validation: 0.810799448845298]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186501058549625		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6186501058549625 | validation: 0.4614449735510979]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505815947371214		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.505815947371214 | validation: 0.7798970597584339]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398588629902188		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5398588629902188 | validation: 0.5301040494171528]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4758121664433146		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.4758121664433146 | validation: 0.5146045198672691]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38210544538497215		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.38210544538497215 | validation: 0.42820092404892424]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44538892039676437		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.44538892039676437 | validation: 0.5708661076253512]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4099428628299606		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.4099428628299606 | validation: 0.8130369747704249]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943402128655152		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.5943402128655152 | validation: 0.7283003150054159]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816694885880582		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.5816694885880582 | validation: 0.6252097732103133]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48794987129883916		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.48794987129883916 | validation: 0.716520334462883]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5439059274987355		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5439059274987355 | validation: 0.6683302620173877]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076864604226705		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.5076864604226705 | validation: 0.4407671526494195]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3830427100778617		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.3830427100778617 | validation: 0.38565559699030316]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3265077347180903		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3265077347180903 | validation: 0.27179235715620353]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41781698259980676		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.41781698259980676 | validation: 0.413635528425252]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44460978062335116		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.44460978062335116 | validation: 0.3574465456755535]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46671382459661215		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.46671382459661215 | validation: 0.41216012720462575]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4051597263377638		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.4051597263377638 | validation: 0.5210034147375479]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3965123759985263		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3965123759985263 | validation: 0.6482022101106049]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5555600796658642		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5555600796658642 | validation: 0.32443801191766836]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34234633862205893		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.34234633862205893 | validation: 0.4026950085713976]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3845710930289119		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3845710930289119 | validation: 0.5053661738882702]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022551192564072		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5022551192564072 | validation: 0.5878782670523244]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49801577305473066		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.49801577305473066 | validation: 0.4361229254926358]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46009780150215257		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.46009780150215257 | validation: 0.4849378926243828]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48184923021195747		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.48184923021195747 | validation: 0.3026684057609338]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411161638751192		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3411161638751192 | validation: 0.6462008828837458]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057321156059407		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5057321156059407 | validation: 0.7007728187111464]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4665745439678443		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.4665745439678443 | validation: 0.5298423065330787]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38985373955721964		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.38985373955721964 | validation: 0.35531561637259346]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049964673886378		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3049964673886378 | validation: 0.5043368301550163]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219448125597138		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3219448125597138 | validation: 0.5192635036295478]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709557987784275		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4709557987784275 | validation: 0.4977047631002148]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737147730431396		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5737147730431396 | validation: 0.4341315115487295]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064758755554496		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.4064758755554496 | validation: 0.3137231744882419]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835267291837276		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3835267291837276 | validation: 0.4360995432133295]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38135423754369974		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.38135423754369974 | validation: 0.27529590184038366]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256376740931638		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.3256376740931638 | validation: 0.3866653727598336]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931711803968458		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3931711803968458 | validation: 0.35769491653006996]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39275659413904546		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.39275659413904546 | validation: 0.3571381923104844]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451202829547568		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.451202829547568 | validation: 0.23414546800724104]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36865305619321376		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.36865305619321376 | validation: 0.3349902566659326]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42219508274501816		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.42219508274501816 | validation: 0.5160129902307796]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775358041730399		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.3775358041730399 | validation: 0.365474299859607]
	TIME [epoch: 24.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34783009851557495		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.34783009851557495 | validation: 0.28621132742242755]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42683241769287583		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.42683241769287583 | validation: 0.40405403064559736]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501324336073794		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.0501324336073794 | validation: 1.063592238831711]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016164368319273		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7016164368319273 | validation: 0.4123918299210479]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036130925218153		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.4036130925218153 | validation: 0.42926550142013215]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584940719293313		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3584940719293313 | validation: 0.252781932972708]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3188491655141289		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.3188491655141289 | validation: 0.618090611966769]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1170731034276775		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.1170731034276775 | validation: 0.8208983233194763]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839842282139065		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.839842282139065 | validation: 0.9056270274455759]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685795386182646		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.7685795386182646 | validation: 0.48244379452634045]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47545607864823175		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.47545607864823175 | validation: 0.3308427620239236]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339931708142275		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3339931708142275 | validation: 0.3892038049980746]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585495066875616		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5585495066875616 | validation: 1.1182049309632829]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730497220688449		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.730497220688449 | validation: 0.6252690770470821]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293973701643817		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5293973701643817 | validation: 0.7180432057488505]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44391743805962747		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.44391743805962747 | validation: 0.4595705144380287]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39490531737138057		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.39490531737138057 | validation: 0.45498530451036795]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643286033104274		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.3643286033104274 | validation: 0.4403682789417931]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282179005429254		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3282179005429254 | validation: 0.2799598017552298]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860023082090579		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3860023082090579 | validation: 0.40310208504280487]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5249685764357128		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5249685764357128 | validation: 0.37766410778970766]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189378810865668		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.4189378810865668 | validation: 0.6007807954836024]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022905157127545		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5022905157127545 | validation: 0.33237267092197614]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33297700670718816		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.33297700670718816 | validation: 0.3215721443454001]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33314045272420784		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.33314045272420784 | validation: 0.47368118527687586]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019983947571696		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4019983947571696 | validation: 0.36690942241973923]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359951387593547		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3359951387593547 | validation: 0.34775358876906043]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716368261599222		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3716368261599222 | validation: 0.2601698800292058]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33976264816565704		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.33976264816565704 | validation: 0.523573250799744]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44089522708041967		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.44089522708041967 | validation: 0.5308596991890725]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46540727319186004		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.46540727319186004 | validation: 0.32157015317859755]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31261887806545513		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.31261887806545513 | validation: 0.3066486601881761]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3699347745127471		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.3699347745127471 | validation: 0.31490285379540334]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3148229154474339		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3148229154474339 | validation: 0.5443690159109597]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42673538016783585		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.42673538016783585 | validation: 0.4320062375575509]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36525767747964183		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.36525767747964183 | validation: 0.3977739875274978]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609571148787182		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3609571148787182 | validation: 0.597692206235808]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42532035024611997		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.42532035024611997 | validation: 0.4529804198072879]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881708141679357		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.3881708141679357 | validation: 0.5632862772566609]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120901091250306		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.4120901091250306 | validation: 0.4169138065798053]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40100436195091843		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.40100436195091843 | validation: 0.2695078667581199]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41166168318612106		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.41166168318612106 | validation: 0.4298215144589436]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35807979759591746		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.35807979759591746 | validation: 0.2862918175060971]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778774134648543		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2778774134648543 | validation: 0.34617836022898474]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4355606137830662		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.4355606137830662 | validation: 0.5142932163789913]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6129766881322505		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6129766881322505 | validation: 0.30502752399768585]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29325400749344954		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.29325400749344954 | validation: 0.38433578771482135]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038865525932314		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3038865525932314 | validation: 0.271489141342302]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175250993785544		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3175250993785544 | validation: 0.44632262716072035]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30749171216305954		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.30749171216305954 | validation: 0.25347270608729455]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017939365790943		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.3017939365790943 | validation: 0.2541811240333326]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30467489547897497		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.30467489547897497 | validation: 0.25923762168423264]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727568034992058		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2727568034992058 | validation: 0.24744869048233895]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23469916477290007		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.23469916477290007 | validation: 0.3751439304733657]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601044188146337		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.3601044188146337 | validation: 0.29395887806596394]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39204352163337686		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.39204352163337686 | validation: 0.36860254410108795]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4624747009831516		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.4624747009831516 | validation: 0.3650283585742055]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42756870477728776		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.42756870477728776 | validation: 0.3324535440989662]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36487644283252296		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.36487644283252296 | validation: 0.3509454832152271]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36588247497710813		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.36588247497710813 | validation: 0.4272575799259002]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.425468242626184		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.425468242626184 | validation: 0.4963898829740742]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41846136415100343		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.41846136415100343 | validation: 0.2740752776127972]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978675053515605		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2978675053515605 | validation: 0.25383768064303525]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730330067307217		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2730330067307217 | validation: 0.38097057654288846]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671673028197664		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3671673028197664 | validation: 0.5253664768611949]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359668642801079		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.359668642801079 | validation: 0.28548187277869264]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33615768425811465		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.33615768425811465 | validation: 0.3323256778673129]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27808420241303666		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.27808420241303666 | validation: 0.3644248635901593]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40142478871751275		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.40142478871751275 | validation: 0.370485072880073]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33945276372081934		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.33945276372081934 | validation: 0.36969040037231865]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212510072178699		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3212510072178699 | validation: 0.4133110640415565]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871952291733141		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.2871952291733141 | validation: 0.29599625627684734]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695664052216029		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2695664052216029 | validation: 0.276012076106292]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943370088688408		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2943370088688408 | validation: 0.3104096327485965]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3734071066232478		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.3734071066232478 | validation: 0.28387776425781275]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970633238827526		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2970633238827526 | validation: 0.3760970184598402]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585293779456224		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2585293779456224 | validation: 0.3017434468645393]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30232000583577745		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.30232000583577745 | validation: 0.3718486860991818]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26470624870553106		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.26470624870553106 | validation: 0.4220456963190168]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361521064735027		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.361521064735027 | validation: 0.2958556275810257]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29080950334228983		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.29080950334228983 | validation: 0.31379262158962606]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274911917276817		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.3274911917276817 | validation: 0.3652162331678599]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47087789973384586		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.47087789973384586 | validation: 0.31049244365424145]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172838365420238		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.3172838365420238 | validation: 0.2772090170283797]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338954856225491		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3338954856225491 | validation: 0.32192426654990386]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27110474924045785		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.27110474924045785 | validation: 0.3612722447405035]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089744369377537		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.3089744369377537 | validation: 0.33908808536979335]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354905186788633		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.3354905186788633 | validation: 0.5654367902392587]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34513248896589294		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.34513248896589294 | validation: 0.5227233522146579]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42736946628921213		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.42736946628921213 | validation: 1.9901485878524616]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0450198942727469		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.0450198942727469 | validation: 0.6810227053733288]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4210450891222414		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.4210450891222414 | validation: 0.4993985056492779]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38121829048789174		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.38121829048789174 | validation: 0.5871967598515058]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853868747441311		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.3853868747441311 | validation: 0.8174383551687138]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449083600120631		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.4449083600120631 | validation: 0.38653938825431206]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569387493371583		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.2569387493371583 | validation: 0.3070635306457702]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23852859348914396		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.23852859348914396 | validation: 0.26873398209442956]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26153261158431995		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.26153261158431995 | validation: 0.2355284573571727]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22948194591002172		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.22948194591002172 | validation: 0.2668520823831516]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24447026322543025		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.24447026322543025 | validation: 0.2594827956400162]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617323023773812		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2617323023773812 | validation: 0.24807121403417234]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27182170379297216		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.27182170379297216 | validation: 0.26385795166896214]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26840277697547654		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.26840277697547654 | validation: 0.536048190218083]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34657334988976374		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.34657334988976374 | validation: 0.4458171352223549]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39395315278111886		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.39395315278111886 | validation: 0.5053715831197321]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36266852850787434		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.36266852850787434 | validation: 0.30682708358469024]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898528709101635		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2898528709101635 | validation: 0.31618830792739144]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911634955904612		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.2911634955904612 | validation: 0.30080216770417806]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518123491068971		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.2518123491068971 | validation: 0.46171478906321156]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958606976942598		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2958606976942598 | validation: 0.21417938246127713]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24622869872662595		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.24622869872662595 | validation: 0.22877701113093799]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2330963491331911		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.2330963491331911 | validation: 0.2678878488992555]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25939002601519034		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.25939002601519034 | validation: 0.3141101673704314]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756724858309881		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.2756724858309881 | validation: 0.390366567805391]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27478195619154605		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.27478195619154605 | validation: 0.40628858304114496]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051287544987047		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.3051287544987047 | validation: 0.37044137953326667]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793483075093868		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2793483075093868 | validation: 0.2869461451150842]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289139241889502		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.289139241889502 | validation: 0.3605717639265031]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650876741509834		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.2650876741509834 | validation: 0.33657002900865945]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532436849390146		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.2532436849390146 | validation: 0.23854212025916763]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26279468536839595		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.26279468536839595 | validation: 0.21679645372101097]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783015006271387		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2783015006271387 | validation: 0.34716360464468254]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793654120400008		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2793654120400008 | validation: 0.2714705849405825]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28758812594838057		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.28758812594838057 | validation: 0.26958309641371137]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754198766747766		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.2754198766747766 | validation: 0.3099720038842391]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750208555289658		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.2750208555289658 | validation: 0.24882680559441123]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24777729838430324		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.24777729838430324 | validation: 0.30895017532032665]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797136170568766		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.2797136170568766 | validation: 0.3294535229108543]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28700421241096274		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.28700421241096274 | validation: 0.23761354047002506]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25634061192487434		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.25634061192487434 | validation: 0.3701965139855568]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771969847355775		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.2771969847355775 | validation: 0.2644694445739325]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31116577599000206		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.31116577599000206 | validation: 0.32545895304579847]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634814645919188		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2634814645919188 | validation: 0.24047577295169467]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24116804726983898		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.24116804726983898 | validation: 0.25924630059309534]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27694738225777327		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.27694738225777327 | validation: 0.45467107607991863]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33432995238969754		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.33432995238969754 | validation: 0.23089504501404087]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849283868721998		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.2849283868721998 | validation: 0.23783938426199597]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23210287095340087		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.23210287095340087 | validation: 0.26105974775596935]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23001052995906254		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.23001052995906254 | validation: 0.21000810176548343]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19623081506396683		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.19623081506396683 | validation: 0.2541545991174051]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582218358142623		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.2582218358142623 | validation: 0.3436055346448962]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28917868331449487		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.28917868331449487 | validation: 0.27643958083542514]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32014030767639096		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.32014030767639096 | validation: 0.22631093726214438]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391512136253295		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.2391512136253295 | validation: 0.622437921563689]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442895063259679		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3442895063259679 | validation: 0.2258196118864404]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19743604043885438		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.19743604043885438 | validation: 0.18279136309283772]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20891519850691598		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.20891519850691598 | validation: 0.21418371674436196]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24122925588079874		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.24122925588079874 | validation: 0.23715150240375465]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22011110187663316		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.22011110187663316 | validation: 0.2189023796423627]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408990215139071		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2408990215139071 | validation: 0.18538563084282839]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166489157903547		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.166489157903547 | validation: 0.29820373800293665]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2425746211396451		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2425746211396451 | validation: 0.1741732101037212]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770941541005443		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1770941541005443 | validation: 0.27296598617032275]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20825706619365641		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.20825706619365641 | validation: 0.17315021400809547]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19057256267864994		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.19057256267864994 | validation: 0.1878625415884545]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21736794938860718		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.21736794938860718 | validation: 0.21584448730338665]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22156883271936698		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.22156883271936698 | validation: 0.27353404354631544]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22800656300874056		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.22800656300874056 | validation: 0.18739916021714273]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20207690199158726		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.20207690199158726 | validation: 0.2902823064680203]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592312440483513		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.2592312440483513 | validation: 0.26998882173179845]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21369864000765143		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.21369864000765143 | validation: 0.19022737113387458]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20610952523647127		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.20610952523647127 | validation: 0.21227333752639574]
	TIME [epoch: 24.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23608493477622405		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.23608493477622405 | validation: 0.1902916283402966]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751636968172472		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.18751636968172472 | validation: 0.2780683025309127]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26036221285234606		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.26036221285234606 | validation: 0.19311481823493468]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21384765340341555		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.21384765340341555 | validation: 0.18774784834395356]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061670561398573		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2061670561398573 | validation: 0.19461666768240576]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.287072942543201		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.287072942543201 | validation: 0.21601799928399765]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19493072789118293		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.19493072789118293 | validation: 0.2554190705837124]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23027142287959101		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.23027142287959101 | validation: 0.21993763140301403]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20458326931372028		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.20458326931372028 | validation: 0.19821072229682452]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17375328575355592		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.17375328575355592 | validation: 0.2942573601503315]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22908280268029071		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.22908280268029071 | validation: 0.216421222467547]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925332406230246		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.20925332406230246 | validation: 0.4783528981527917]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749235651667936		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.2749235651667936 | validation: 0.26459513784498745]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21161318110658386		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.21161318110658386 | validation: 0.18258702009593705]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967467074285073		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.17967467074285073 | validation: 0.19000956581727163]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26433357228010995		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.26433357228010995 | validation: 0.22215065099285142]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2154507562045358		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.2154507562045358 | validation: 0.23090533547059935]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20676298165882084		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.20676298165882084 | validation: 0.466392452723306]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33125560925600545		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.33125560925600545 | validation: 0.3508359789732553]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871584814370213		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.2871584814370213 | validation: 0.29167419281133455]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2277003074898215		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2277003074898215 | validation: 0.3152672369646056]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25678471714342305		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.25678471714342305 | validation: 0.32770418732035345]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27826841794734697		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.27826841794734697 | validation: 0.320598580262768]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722337702501377		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2722337702501377 | validation: 0.30733405843878725]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931504640616375		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2931504640616375 | validation: 0.29872390799729026]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612829444544613		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.2612829444544613 | validation: 0.2967680565941074]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327687509865412		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.327687509865412 | validation: 0.2613126811798069]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692964032893891		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2692964032893891 | validation: 0.40870918815251744]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798061888243105		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2798061888243105 | validation: 0.2571947125064217]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22852008068565363		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.22852008068565363 | validation: 0.21057015322513883]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22345843226281054		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.22345843226281054 | validation: 0.2960622913983734]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26232496717512965		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.26232496717512965 | validation: 0.30341720593914573]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680012604560263		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.2680012604560263 | validation: 0.2719665549652231]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27698260657670287		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.27698260657670287 | validation: 0.33962527634187095]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354430793669588		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.3354430793669588 | validation: 0.506880470090698]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314217041810618		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.3314217041810618 | validation: 0.3669731642883548]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33237324775583504		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.33237324775583504 | validation: 0.35032534919030456]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614053859683202		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.2614053859683202 | validation: 0.2589054974748687]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25203982327763025		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.25203982327763025 | validation: 0.30536429582376284]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523924755643101		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.2523924755643101 | validation: 0.26600899147509305]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674700615377235		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.2674700615377235 | validation: 0.31503242969974876]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23707680579230211		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.23707680579230211 | validation: 0.3120745882520317]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.241309224314864		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.241309224314864 | validation: 0.19816361499597235]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21568493074150255		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.21568493074150255 | validation: 0.19462987175461302]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265968404823695		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.2265968404823695 | validation: 0.24649784899929192]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22017995826949277		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.22017995826949277 | validation: 0.17346097045861264]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22443647355656776		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.22443647355656776 | validation: 0.23317056895157198]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134170285340879		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.2134170285340879 | validation: 0.17843642214129873]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18197011949176076		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.18197011949176076 | validation: 0.17541516621238779]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1999848487321732		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1999848487321732 | validation: 0.20880473349322098]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19075572592875645		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.19075572592875645 | validation: 0.2266601060064494]
	TIME [epoch: 24.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740396982511165		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2740396982511165 | validation: 0.3802194962388428]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879210111983217		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2879210111983217 | validation: 0.1929220859938324]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134506712981456		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.2134506712981456 | validation: 0.1704359434080434]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2315201032024188		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2315201032024188 | validation: 0.20527277083195877]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2264769246106776		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.2264769246106776 | validation: 0.27991646760965794]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20517998289099387		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.20517998289099387 | validation: 0.15246379164305196]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_807.pth
	Model improved!!!
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15504970088652564		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.15504970088652564 | validation: 0.1798312789109702]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829653150163164		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1829653150163164 | validation: 0.17047885839072408]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21972554352985577		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.21972554352985577 | validation: 0.2700784741556788]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26487928359796664		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.26487928359796664 | validation: 0.23537435305281112]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934919180208041		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1934919180208041 | validation: 0.17117712443235364]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18632221466225712		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.18632221466225712 | validation: 0.25468774786024745]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19845482615317683		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.19845482615317683 | validation: 0.2475644013987305]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20515728006408898		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.20515728006408898 | validation: 0.18639799353913936]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19178819764611668		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.19178819764611668 | validation: 0.17563866371487077]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18647338643373754		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.18647338643373754 | validation: 0.21095251217688965]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886904963971276		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.20886904963971276 | validation: 0.20904332047023935]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21720662716288405		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.21720662716288405 | validation: 0.23512643913901174]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119456028329068		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2119456028329068 | validation: 0.1835853059520628]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1961191354435125		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1961191354435125 | validation: 0.25112779394382506]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19069593066309193		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.19069593066309193 | validation: 0.18525592603358595]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17069143136962694		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.17069143136962694 | validation: 0.2463035411788522]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18477641664178152		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.18477641664178152 | validation: 0.23388777721975196]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21630712702249305		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.21630712702249305 | validation: 0.20820515967786762]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23711827248258377		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.23711827248258377 | validation: 0.24286186845468238]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023615790849478		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.2023615790849478 | validation: 0.17873729840952765]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20039547228915627		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.20039547228915627 | validation: 0.2329990165694548]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171117229274473		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.2171117229274473 | validation: 0.16581255654908894]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573430683088945		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.1573430683088945 | validation: 0.23782384784662455]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20404094161870473		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.20404094161870473 | validation: 0.27494387670658454]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18723207043852838		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.18723207043852838 | validation: 0.19144407618129308]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992227862042866		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.1992227862042866 | validation: 0.233845063670588]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18936159409385597		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.18936159409385597 | validation: 0.19371388608896056]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18666163632769034		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.18666163632769034 | validation: 0.17477142069713505]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16536309605628227		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.16536309605628227 | validation: 0.20865261610203092]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2483078511360049		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2483078511360049 | validation: 0.2423229804886828]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23521227739215847		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.23521227739215847 | validation: 0.2214489618611993]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869956875237336		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.1869956875237336 | validation: 0.17964164987057257]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20340732119332944		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.20340732119332944 | validation: 0.15937463605454993]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171333802143002		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.171333802143002 | validation: 0.16560692308439126]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17493540546817657		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.17493540546817657 | validation: 0.21392704471718665]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096060755628565		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.2096060755628565 | validation: 0.2023513986353116]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22917555745908386		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.22917555745908386 | validation: 0.3095178980614178]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21373741114041817		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.21373741114041817 | validation: 0.14751994786419143]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16645767969806138		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.16645767969806138 | validation: 0.163249920257364]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16244285618513027		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.16244285618513027 | validation: 0.13779511984504322]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16021775788855475		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.16021775788855475 | validation: 0.13478269186944433]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_848.pth
	Model improved!!!
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17070902877310887		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.17070902877310887 | validation: 0.12196604841622176]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240309_135656/states/model_tr_study5_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798632166271082		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.15798632166271082 | validation: 0.16279924655276617]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20306208694296654		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.20306208694296654 | validation: 0.147235113715875]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2379432757003661		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2379432757003661 | validation: 0.3057999529718737]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26050615063434496		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.26050615063434496 | validation: 0.2129992365129901]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21957159357030903		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.21957159357030903 | validation: 0.22124322579583588]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802476574104957		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1802476574104957 | validation: 0.18344026293134089]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17830547947687822		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.17830547947687822 | validation: 0.25588617120160995]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778019969856655		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.1778019969856655 | validation: 0.21812480068161275]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23183348644791307		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.23183348644791307 | validation: 0.30324257290865125]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21403639874800456		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.21403639874800456 | validation: 0.170593469415428]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20450102958572286		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.20450102958572286 | validation: 0.2274373219409135]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19159527335107235		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.19159527335107235 | validation: 0.3573687125883815]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29155923452363375		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.29155923452363375 | validation: 0.21853221268964582]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19831538632337348		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.19831538632337348 | validation: 0.21944013738961254]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20946798581866702		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.20946798581866702 | validation: 0.2642353636500412]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757564625381317		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2757564625381317 | validation: 0.2531411176220177]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25322335308911537		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.25322335308911537 | validation: 0.21061221053253193]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20633649362833376		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.20633649362833376 | validation: 0.17432742132329715]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17672955389943276		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.17672955389943276 | validation: 0.2213144406705112]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22089398467971913		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.22089398467971913 | validation: 0.32584088765523256]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2333455611938317		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.2333455611938317 | validation: 0.2273233841229623]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
