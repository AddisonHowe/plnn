Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4061417755

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.837361310962393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.837361310962393 | validation: 10.116517792692077]
	TIME [epoch: 114 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.640082564692612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.640082564692612 | validation: 9.371419085900976]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.79757568779944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.79757568779944 | validation: 8.959864887767312]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.208826614368368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.208826614368368 | validation: 8.271062674467]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.728326869714939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.728326869714939 | validation: 8.04964563998254]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.384973440487315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.384973440487315 | validation: 7.620336007218557]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.009952020328715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.009952020328715 | validation: 7.320352770771766]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.685794291376148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.685794291376148 | validation: 6.693836906921993]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.242011200332925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.242011200332925 | validation: 6.399485784888473]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9066922754513875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9066922754513875 | validation: 6.047631764275943]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.693625587201844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.693625587201844 | validation: 5.934168076660951]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6813904287465355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6813904287465355 | validation: 5.937083950210776]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.584308892859725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.584308892859725 | validation: 5.732867327061427]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.490981554356159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.490981554356159 | validation: 5.764386865042484]
	TIME [epoch: 24.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.485095979357282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.485095979357282 | validation: 5.570058777134878]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.518688115073591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.518688115073591 | validation: 5.791102728402087]
	TIME [epoch: 24.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.419733780974951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.419733780974951 | validation: 5.650667686271263]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.151076501474831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.151076501474831 | validation: 5.951640527097315]
	TIME [epoch: 24.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.528163498021773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.528163498021773 | validation: 5.659875583271892]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.267249673723489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.267249673723489 | validation: 5.396844354424714]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.168037249137134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.168037249137134 | validation: 6.027484942208501]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.367641872302497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.367641872302497 | validation: 5.369655682422656]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.109069536159776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.109069536159776 | validation: 5.283883678957558]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.122450861640858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.122450861640858 | validation: 5.737436058009191]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605724400811365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.605724400811365 | validation: 5.64014868505321]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.229791650537454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.229791650537454 | validation: 5.254162262014852]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.042779656847629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042779656847629 | validation: 5.446510008975743]
	TIME [epoch: 24.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.098396403997854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.098396403997854 | validation: 5.400578665060993]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0165804185102925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0165804185102925 | validation: 5.167331175417144]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.033544965455705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.033544965455705 | validation: 5.246772585427254]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.002046710637144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.002046710637144 | validation: 5.597582681542865]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.198624291326349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.198624291326349 | validation: 5.2258427278442]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.091365900218732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.091365900218732 | validation: 5.020664927156141]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.946393005600859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.946393005600859 | validation: 5.402780127090899]
	TIME [epoch: 24.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.862609956835849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.862609956835849 | validation: 7.48627720938645]
	TIME [epoch: 24.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.843695657019925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.843695657019925 | validation: 8.852132125281676]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.674355421923721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.674355421923721 | validation: 6.587982608385751]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.12357571484697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.12357571484697 | validation: 6.025055842099552]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.703418335064945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703418335064945 | validation: 5.7424947302433775]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.431648509489249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.431648509489249 | validation: 5.656253712618632]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.444466929108461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.444466929108461 | validation: 5.494104622421832]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.360672242734049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.360672242734049 | validation: 5.301396846786418]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.322935864550997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.322935864550997 | validation: 7.994849820321518]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.590538713840305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.590538713840305 | validation: 5.805261728971664]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.640761658171522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.640761658171522 | validation: 7.303403125148261]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.662231107280327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.662231107280327 | validation: 7.338131634221083]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.08434806409008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.08434806409008 | validation: 7.2211135209180455]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.4446580233234165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4446580233234165 | validation: 6.353530104379845]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0364917404410665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0364917404410665 | validation: 5.865000343487777]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.637693087595363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.637693087595363 | validation: 5.786553977615686]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.349466053519653		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.349466053519653 | validation: 5.4264019411248094]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.246929655316315		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.246929655316315 | validation: 5.667708180695775]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.278858496444855		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.278858496444855 | validation: 5.535811734479896]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.115798656919371		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.115798656919371 | validation: 5.108445969323472]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.395221230165977		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.395221230165977 | validation: 5.242862867446818]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.992969270974721		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.992969270974721 | validation: 5.053561063001737]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.720424842808724		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.720424842808724 | validation: 4.906656142493823]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.618255636508496		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.618255636508496 | validation: 4.8912058264717695]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.188954319356872		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.188954319356872 | validation: 4.638380749531986]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000804191017555		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.000804191017555 | validation: 3.7937206655965903]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1866991550225725		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.1866991550225725 | validation: 5.235824322524468]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.784318896943124		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.784318896943124 | validation: 4.026237886300289]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5520304141497316		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.5520304141497316 | validation: 3.5923162701182587]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.608436699465613		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.608436699465613 | validation: 3.5857021761169108]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8224074810205333		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8224074810205333 | validation: 4.4906884215449745]
	TIME [epoch: 24.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8864985117945725		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.8864985117945725 | validation: 5.029671218525155]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4173106043123544		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.4173106043123544 | validation: 4.673574154777476]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78095196818416		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.78095196818416 | validation: 7.781101227913141]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.423354089053476		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 6.423354089053476 | validation: 4.377804490667936]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.057380105803781		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.057380105803781 | validation: 3.9024043537249407]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.735674756290436		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.735674756290436 | validation: 3.987984292377062]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.703774013995633		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.703774013995633 | validation: 3.888080078367111]
	TIME [epoch: 24.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5028395756572435		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.5028395756572435 | validation: 3.6851307368433504]
	TIME [epoch: 24.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.104077283042583		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.104077283042583 | validation: 7.709256256411152]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.049465479161813		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 6.049465479161813 | validation: 3.9971267290245276]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4662875671592692		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.4662875671592692 | validation: 3.803806554580124]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2540963588204463		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.2540963588204463 | validation: 4.345563135124641]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.918704022586873		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.918704022586873 | validation: 4.2618835579638805]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.398097571922991		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.398097571922991 | validation: 5.386924190058898]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8434401985388584		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.8434401985388584 | validation: 3.527628961743726]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.735373774409425		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.735373774409425 | validation: 4.057675822448553]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4602217806877675		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.4602217806877675 | validation: 4.397489706297831]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.295674892428957		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.295674892428957 | validation: 3.7110944864444493]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268826710596479		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.268826710596479 | validation: 3.407303405820021]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9844042768793826		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.9844042768793826 | validation: 4.117041156752326]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3198344355344895		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.3198344355344895 | validation: 3.38066108220238]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.092728604738849		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.092728604738849 | validation: 3.9510550614992166]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227621362011411		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.227621362011411 | validation: 3.4389407753499035]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5501465316791534		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.5501465316791534 | validation: 3.572649317865863]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.152431136257872		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.152431136257872 | validation: 3.210371676921022]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.905013600509414		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.905013600509414 | validation: 3.3210459083468344]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.153081917291368		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.153081917291368 | validation: 4.184619007597627]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3956010958341407		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.3956010958341407 | validation: 3.840310726413349]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.099320552095368		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.099320552095368 | validation: 3.0657901705332997]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.092530617499051		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.092530617499051 | validation: 2.9774984955715253]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7538324998465593		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.7538324998465593 | validation: 3.162704763144034]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7829774343273534		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.7829774343273534 | validation: 3.202184674642272]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0874863293299892		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.0874863293299892 | validation: 2.97762681808959]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6784501489906547		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.6784501489906547 | validation: 2.7401904527496135]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.071315118957296		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.071315118957296 | validation: 2.758378960591347]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6515691591778876		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.6515691591778876 | validation: 2.9703713586120877]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5579616210432383		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.5579616210432383 | validation: 3.0111590528972374]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.671537830281208		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.671537830281208 | validation: 2.761111725396105]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5427705103296097		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.5427705103296097 | validation: 3.1639333920098514]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866304662567175		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.866304662567175 | validation: 3.4442686595630936]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.160025181182072		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.160025181182072 | validation: 4.840689010824383]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.532285517166704		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.532285517166704 | validation: 2.709804258704373]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5816233827410002		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.5816233827410002 | validation: 2.3497783095573834]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365881261442922		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.365881261442922 | validation: 2.2971510113520335]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410144996537213		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.410144996537213 | validation: 2.871994111069635]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7209620108036874		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.7209620108036874 | validation: 2.159905719314561]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380115977386953		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.380115977386953 | validation: 3.3638976652475203]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.755557367390038		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.755557367390038 | validation: 2.47870157535724]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289946085291116		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.289946085291116 | validation: 2.6885111807102704]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4637987948012703		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.4637987948012703 | validation: 3.0261916282531436]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.776488274489318		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.776488274489318 | validation: 4.1880510983566515]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0877870747377316		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.0877870747377316 | validation: 3.250609046004016]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7744867693975577		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.7744867693975577 | validation: 2.9115543835335056]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4910595253181333		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.4910595253181333 | validation: 2.2566795297977906]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288167266469485		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.288167266469485 | validation: 2.886118296042567]
	TIME [epoch: 24.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.619282420789982		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.619282420789982 | validation: 2.513296068688962]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28331137626522		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.28331137626522 | validation: 2.7802850924930613]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438547897624122		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.438547897624122 | validation: 2.9527687066532065]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348168262296942		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.348168262296942 | validation: 2.1821654613517234]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.139244645186598		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.139244645186598 | validation: 2.17147247567477]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1906400256639116		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.1906400256639116 | validation: 1.9186540204607445]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8039304463110897		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.8039304463110897 | validation: 2.169060596712281]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053352669894461		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.053352669894461 | validation: 2.559046554945259]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.026497347986484		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.026497347986484 | validation: 2.5290336724214457]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5504647665538474		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.5504647665538474 | validation: 2.518477348663736]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2598918139160613		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.2598918139160613 | validation: 2.1829033934929543]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414300601496891		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.414300601496891 | validation: 1.9965111765133572]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0495492701287366		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.0495492701287366 | validation: 2.1831953969039914]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08224840275117		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.08224840275117 | validation: 2.370821793626553]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2818202914983887		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.2818202914983887 | validation: 1.9688571986124224]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244416545699871		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.244416545699871 | validation: 2.820642922676542]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298755028732881		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.298755028732881 | validation: 2.1059813489184553]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9715692336611572		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.9715692336611572 | validation: 2.419440693631485]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2652487285132685		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.2652487285132685 | validation: 1.9708591627685115]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.707017231054638		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.707017231054638 | validation: 3.953055733874138]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.563893153261112		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.563893153261112 | validation: 2.1164654284330915]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0710814334249656		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.0710814334249656 | validation: 2.6862907377372007]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.66039379318366		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.66039379318366 | validation: 2.305509069999606]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252990703950997		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.252990703950997 | validation: 2.015903274597905]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244374587186591		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.244374587186591 | validation: 3.7563416868684225]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7154314184300015		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.7154314184300015 | validation: 2.010718467261409]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9431034961739342		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.9431034961739342 | validation: 1.895854291689886]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7569880124892756		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7569880124892756 | validation: 2.0095457853277017]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.73442990435941		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.73442990435941 | validation: 2.420267166108266]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0147726396958943		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.0147726396958943 | validation: 2.015201664790198]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355538240063368		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.355538240063368 | validation: 2.308345397886947]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4327935045008076		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.4327935045008076 | validation: 1.9073262469593804]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0241607978563905		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.0241607978563905 | validation: 1.9211561953303187]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325659299572118		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.325659299572118 | validation: 2.4107103932211613]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9629332011832616		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.9629332011832616 | validation: 2.089489449502329]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390882076939855		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.7390882076939855 | validation: 2.333761158130252]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0893097253574004		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.0893097253574004 | validation: 1.9995957030900433]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7795901301694175		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.7795901301694175 | validation: 2.1161006025305484]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0053191271928608		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.0053191271928608 | validation: 4.355724750608561]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.141049968900713		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.141049968900713 | validation: 1.8826966894558457]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8611588600824434		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.8611588600824434 | validation: 1.6391552660235293]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7045053732734878		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.7045053732734878 | validation: 1.8432205909155437]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.784166691709459		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.784166691709459 | validation: 1.9462244647815692]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9234319258510846		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.9234319258510846 | validation: 1.6225897422576412]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.520764199241677		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.520764199241677 | validation: 1.6261959139477866]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9374300773701651		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.9374300773701651 | validation: 1.9548676202250141]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8043157889950123		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.8043157889950123 | validation: 1.509494697021051]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0365319438711573		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.0365319438711573 | validation: 2.087703711720974]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7483049789716696		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.7483049789716696 | validation: 1.5314186359408932]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6805614993581224		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.6805614993581224 | validation: 1.9793567100836316]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6030024585139735		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.6030024585139735 | validation: 1.6216441835798976]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.567181167655173		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.567181167655173 | validation: 3.3029534471419355]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444562185137876		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.444562185137876 | validation: 2.020935319815369]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5353314562321776		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.5353314562321776 | validation: 2.9120316060106526]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313940077111692		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.313940077111692 | validation: 1.8354858770595794]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7400608757488267		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.7400608757488267 | validation: 1.7205651207303674]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7907888668752308		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.7907888668752308 | validation: 1.98143008156827]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6968199745773132		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.6968199745773132 | validation: 2.2677902937087784]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9192905069484814		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.9192905069484814 | validation: 1.8825286963033672]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5955930674577286		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.5955930674577286 | validation: 1.6879739414620099]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.821577386482066		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.821577386482066 | validation: 1.6062924799775555]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5629290936596196		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.5629290936596196 | validation: 1.4988482099727691]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4845510596068874		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4845510596068874 | validation: 2.8880187430656252]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8751360754899948		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.8751360754899948 | validation: 1.6536176484674865]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4741050291178381		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.4741050291178381 | validation: 2.1815123740475806]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049949840434951		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.049949840434951 | validation: 2.034035396535053]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6455298826559115		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.6455298826559115 | validation: 1.6729864631940898]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4330191294210368		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.4330191294210368 | validation: 1.5275919819613706]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3506819611007472		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3506819611007472 | validation: 2.1088415846174478]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5661555855177618		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.5661555855177618 | validation: 1.645964794671673]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4437493806386974		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.4437493806386974 | validation: 1.621652356810834]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.51716567611302		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.51716567611302 | validation: 1.4787204627128006]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4333243765643047		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.4333243765643047 | validation: 1.603914315507028]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5422013585688155		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.5422013585688155 | validation: 1.5750110824188142]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.458315647572141		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.458315647572141 | validation: 1.7617248629821434]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.414078344001049		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.414078344001049 | validation: 1.6859286772566997]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711668691334328		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.711668691334328 | validation: 1.5848690769523972]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4181812159192755		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.4181812159192755 | validation: 2.2687331355420093]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.637885671961722		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.637885671961722 | validation: 1.3015039218528728]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6490331146902408		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.6490331146902408 | validation: 1.331420205819726]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8412672646839194		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.8412672646839194 | validation: 1.4168931937145746]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4397771470370095		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.4397771470370095 | validation: 1.5194038800258607]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4879056707966802		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.4879056707966802 | validation: 4.017631183951178]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810661617584696		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.810661617584696 | validation: 1.5578615433743213]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6666747948105016		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.6666747948105016 | validation: 1.5527291450259202]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6197692476410537		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.6197692476410537 | validation: 1.368732119667181]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085640263458666		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.085640263458666 | validation: 3.569982550493098]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333096709133728		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.333096709133728 | validation: 1.66321481779525]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5896802948465556		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.5896802948465556 | validation: 2.6322532416025712]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5195716140271647		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.5195716140271647 | validation: 1.632695838125207]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6003334498960449		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6003334498960449 | validation: 1.4085403800788852]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6214635719468236		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.6214635719468236 | validation: 2.2768447767548317]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.721792792787288		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.721792792787288 | validation: 1.3582728981737686]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4874128500377173		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.4874128500377173 | validation: 1.4890837151936802]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7159829237969535		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.7159829237969535 | validation: 1.683807590505922]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.599658883272184		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.599658883272184 | validation: 1.6187424837699342]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5621112457893898		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.5621112457893898 | validation: 1.4215918419637308]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4307777832992552		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4307777832992552 | validation: 1.8738549545926912]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4549246668652671		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.4549246668652671 | validation: 1.3325946785642993]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425539275119117		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.2425539275119117 | validation: 1.3674837600701935]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5243375137952906		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.5243375137952906 | validation: 1.6505782602453574]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5995969149633231		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.5995969149633231 | validation: 2.017469162074612]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5825638775747433		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.5825638775747433 | validation: 1.2186084412742897]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154928540522124		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.154928540522124 | validation: 1.41287436266205]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5428302019163445		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.5428302019163445 | validation: 1.7108161338349903]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.57005502656515		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.57005502656515 | validation: 1.2649800983162396]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2791269055604846		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.2791269055604846 | validation: 2.7101677412344363]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6951841543537893		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.6951841543537893 | validation: 1.3165039417645141]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3384031428486503		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.3384031428486503 | validation: 1.6320023441074392]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.510951589539098		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.510951589539098 | validation: 1.5051041482221388]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9471492908135497		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.9471492908135497 | validation: 5.066397112834728]
	TIME [epoch: 24.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7478665888932827		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.7478665888932827 | validation: 1.877932357969849]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.797916859170852		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.797916859170852 | validation: 1.5981359649531168]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.461039377412607		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.461039377412607 | validation: 1.3187668761450373]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3367163610269628		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.3367163610269628 | validation: 1.4036733354224185]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6321127740196655		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.6321127740196655 | validation: 1.3971142462996724]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3091633900644908		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.3091633900644908 | validation: 1.3298350041352343]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5084594001485025		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.5084594001485025 | validation: 1.3207031285223887]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3902891064519172		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.3902891064519172 | validation: 1.5490818232135446]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866586734046155		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.2866586734046155 | validation: 1.2582915270543782]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1912926735976541		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1912926735976541 | validation: 1.4980224908505253]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2875153835696986		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.2875153835696986 | validation: 1.3508697268584933]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4901700030315244		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.4901700030315244 | validation: 1.4418466931958893]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5449478554614353		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.5449478554614353 | validation: 1.3107285896766518]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3296282885122577		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.3296282885122577 | validation: 1.7468373796392194]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2683913232399509		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.2683913232399509 | validation: 1.153886166216117]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4187587494666503		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.4187587494666503 | validation: 2.0982172845916085]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6108331615227958		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.6108331615227958 | validation: 1.9813209194233263]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4707725563262461		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.4707725563262461 | validation: 1.2910537245895126]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5262214942609131		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.5262214942609131 | validation: 1.969267466879443]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4516459942840194		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.4516459942840194 | validation: 1.3727989587698084]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.289701262847257		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.289701262847257 | validation: 1.5878169078484874]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2635290428795303		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.2635290428795303 | validation: 1.2566088356826104]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.628015493060476		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.628015493060476 | validation: 1.8385436750416884]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6515930084593513		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.6515930084593513 | validation: 1.1353317090816712]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2871434460837867		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.2871434460837867 | validation: 1.415946503768863]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4609488773384811		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.4609488773384811 | validation: 1.530117157523042]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3908133547512302		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.3908133547512302 | validation: 1.2047780338679668]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162714873523097		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.2162714873523097 | validation: 2.0775265427336125]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.105447117139492		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.105447117139492 | validation: 1.3018306344644026]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.434864600057281		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.434864600057281 | validation: 1.6570203632280336]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5126145586200952		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.5126145586200952 | validation: 1.2816316550400821]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246011304383827		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.246011304383827 | validation: 1.5047885760006292]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2265421365013016		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.2265421365013016 | validation: 1.15005872523158]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2420643670674278		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.2420643670674278 | validation: 1.4918806964092153]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5252061715443694		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.5252061715443694 | validation: 1.376364098332476]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2842372317006696		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.2842372317006696 | validation: 1.2221583320019762]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5908709325489419		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.5908709325489419 | validation: 1.8103214207126563]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2841762463656978		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.2841762463656978 | validation: 1.5410332102596964]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116557048037252		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.116557048037252 | validation: 1.2531511982627697]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3299962511702041		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.3299962511702041 | validation: 1.6500987103690719]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3858620204937242		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.3858620204937242 | validation: 1.387575964943881]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1314285319023587		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1314285319023587 | validation: 1.643081608271693]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1607491450788343		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.1607491450788343 | validation: 1.3671710702238558]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2256920699067388		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.2256920699067388 | validation: 1.2595217023596725]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1946034879976795		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.1946034879976795 | validation: 1.6249161351632768]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1038067045174995		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.1038067045174995 | validation: 1.5390661281004867]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1149015230220742		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.1149015230220742 | validation: 1.208692281254228]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1489204255901797		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.1489204255901797 | validation: 1.430554071262862]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4904719188872004		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.4904719188872004 | validation: 1.4287228782048842]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7844724568629928		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.7844724568629928 | validation: 2.4261448905167375]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5443573113861273		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.5443573113861273 | validation: 1.8138175042999842]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3934510901085515		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.3934510901085515 | validation: 1.3695029487743688]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1716071920723086		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.1716071920723086 | validation: 1.0020870520832876]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1663553734035277		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1663553734035277 | validation: 1.0250578266647794]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5423805931819068		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.5423805931819068 | validation: 2.163184535953064]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4732531609040387		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.4732531609040387 | validation: 1.1583366644749813]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112465104906777		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.112465104906777 | validation: 1.2912668970960957]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1392908373785824		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1392908373785824 | validation: 1.1209357069232444]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3695202098048656		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.3695202098048656 | validation: 1.6973793708829035]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3964155161067449		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.3964155161067449 | validation: 1.1466273815603696]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2380553193255486		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.2380553193255486 | validation: 1.296205321459321]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4091956447481138		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.4091956447481138 | validation: 1.1431756895321674]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3154576607779527		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.3154576607779527 | validation: 1.6169790249936917]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2095181346417576		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.2095181346417576 | validation: 1.2719827952098195]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147298836841821		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.147298836841821 | validation: 2.2278255618523164]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6884632194089924		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.6884632194089924 | validation: 1.3355108133292708]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2465522572184309		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.2465522572184309 | validation: 1.0552163690098981]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1389518781731258		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.1389518781731258 | validation: 1.2325265796390938]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271942285012132		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.2271942285012132 | validation: 1.3427648677452857]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2003427404968539		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.2003427404968539 | validation: 1.246546448688808]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4242609200638574		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.4242609200638574 | validation: 1.2128546801451734]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2341000167671092		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.2341000167671092 | validation: 1.816933739316122]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4574193895540888		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.4574193895540888 | validation: 1.6654471502761465]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8200448210680304		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.8200448210680304 | validation: 2.147367012786721]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2796632229532474		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.2796632229532474 | validation: 1.725768366542219]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273477994334387		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.273477994334387 | validation: 1.3921079807301382]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3161379107464104		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.3161379107464104 | validation: 1.1729696141393202]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1712056442285377		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.1712056442285377 | validation: 1.1657477201770383]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2034287480857773		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.2034287480857773 | validation: 1.585824462099755]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2669899142345966		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.2669899142345966 | validation: 1.2956392136449255]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0762977141084598		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.0762977141084598 | validation: 2.124573842155689]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5958303160658565		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.5958303160658565 | validation: 1.2104512755033094]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5582715097261772		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.5582715097261772 | validation: 1.517425601509925]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3253512247695114		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.3253512247695114 | validation: 1.0932298605020798]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1787090671328981		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.1787090671328981 | validation: 0.9908979290988967]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.376299784677643		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.376299784677643 | validation: 1.452962186687347]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1060607765822605		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.1060607765822605 | validation: 1.5144360340438483]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5399242692319892		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.5399242692319892 | validation: 1.4440327390816274]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147312277231269		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.147312277231269 | validation: 1.0406899691620717]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1870946567730392		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.1870946567730392 | validation: 1.1696115949234527]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0746215842478497		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.0746215842478497 | validation: 1.1440627312111744]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1807471668665972		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.1807471668665972 | validation: 1.7206231678212363]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.318011162382728		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.318011162382728 | validation: 1.1998487509267834]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528314085355515		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.0528314085355515 | validation: 1.4357848398786137]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0437243117841057		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.0437243117841057 | validation: 1.1205515344352308]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0106745967792385		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.0106745967792385 | validation: 2.1576420742894618]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6726543656745902		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.6726543656745902 | validation: 1.4091085479114183]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0459135630559524		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.0459135630559524 | validation: 1.0814351274578844]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2171331212925922		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.2171331212925922 | validation: 1.3294541252121268]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5338499485994868		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.5338499485994868 | validation: 1.4466307849830853]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1691229467059663		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.1691229467059663 | validation: 1.2030951216187342]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236565924598479		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.236565924598479 | validation: 1.5791031566710598]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2481698233082816		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.2481698233082816 | validation: 1.1210148520779901]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.478707319365532		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.478707319365532 | validation: 1.618839387431982]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123310998603605		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.123310998603605 | validation: 0.9425845372288489]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9755098034043364		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.9755098034043364 | validation: 1.0734148978411655]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0137897329112888		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.0137897329112888 | validation: 1.0557371056488531]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9673804803595556		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9673804803595556 | validation: 1.009216964566562]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9447947487353611		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.9447947487353611 | validation: 1.6677013280530153]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.261534226580045		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.261534226580045 | validation: 0.9721022458274774]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1118626066563166		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.1118626066563166 | validation: 0.9661200316223655]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1415293995296283		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.1415293995296283 | validation: 1.5387616932258883]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3765785263472112		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.3765785263472112 | validation: 1.5269569935592133]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.225665711191482		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.225665711191482 | validation: 1.4030029080581914]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433464505750321		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.1433464505750321 | validation: 1.5141915438792892]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0373476960472294		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.0373476960472294 | validation: 1.4688639307558018]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1526616375209189		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.1526616375209189 | validation: 1.2787321964068852]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0100944067323883		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.0100944067323883 | validation: 1.1229668273916704]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0091332741804795		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.0091332741804795 | validation: 1.1523046739170533]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783422231151818		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.9783422231151818 | validation: 1.1053938619798438]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0210168351160829		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.0210168351160829 | validation: 1.1822909693282053]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501061583780704		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.0501061583780704 | validation: 1.1322031487941318]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098427803612194		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.098427803612194 | validation: 1.1772562773359476]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523810605110057		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.523810605110057 | validation: 1.356531374050192]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292654451159851		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.1292654451159851 | validation: 1.2127353315606408]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2746769773971125		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.2746769773971125 | validation: 1.8911350457344014]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5064149486490068		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.5064149486490068 | validation: 1.818001500759138]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4722322910944678		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.4722322910944678 | validation: 1.3313467817528664]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901014468740814		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.9901014468740814 | validation: 1.117277452947307]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344421990112157		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.1344421990112157 | validation: 1.3751559020664896]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0671265713914095		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.0671265713914095 | validation: 1.1195847448347582]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9482700369187747		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.9482700369187747 | validation: 1.0490850971975452]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2291316745055707		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.2291316745055707 | validation: 1.130154321991869]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0888552640320897		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.0888552640320897 | validation: 0.9571212877152597]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2244283099723279		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.2244283099723279 | validation: 1.5969805672996211]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2413196102300623		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.2413196102300623 | validation: 0.9572287458196865]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8599405813865192		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8599405813865192 | validation: 1.2993640797785173]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9920139084671213		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.9920139084671213 | validation: 1.107495649338774]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1093884459903287		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.1093884459903287 | validation: 1.081951093134027]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9913642503233948		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.9913642503233948 | validation: 1.617619394617032]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1577105860221335		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.1577105860221335 | validation: 1.3575941745445814]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0131162017599336		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0131162017599336 | validation: 3.0006426238456556]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8295810384282007		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.8295810384282007 | validation: 1.0242050766189286]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8522750282481181		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.8522750282481181 | validation: 0.9145394862532118]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9190820360176386		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.9190820360176386 | validation: 1.460163259504887]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0953561269229444		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.0953561269229444 | validation: 1.5979538380660592]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257673034454553		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.257673034454553 | validation: 1.0492575622993316]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049791004925713		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.049791004925713 | validation: 1.3790376572082061]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295794576338375		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.0295794576338375 | validation: 1.176906765437779]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.920688156858477		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.920688156858477 | validation: 1.0504000491366616]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1741373424981845		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.1741373424981845 | validation: 1.0440399140201801]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006802700270444		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.006802700270444 | validation: 1.1184364914040874]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617553892436659		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.9617553892436659 | validation: 1.0254246539224383]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8554682033771753		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8554682033771753 | validation: 1.6260528563192431]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370949514615588		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.370949514615588 | validation: 1.360146322066821]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.231821396176187		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.231821396176187 | validation: 2.213095594657506]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5005154828020015		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.5005154828020015 | validation: 1.559616736020735]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1747789654018759		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.1747789654018759 | validation: 1.2683861559416294]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9812578940579076		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.9812578940579076 | validation: 1.0845778898466183]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8992831745613195		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8992831745613195 | validation: 1.5154287845561305]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9804715002813171		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.9804715002813171 | validation: 1.1392217481271913]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735579183630468		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.0735579183630468 | validation: 1.5196393581725587]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896649536138934		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.0896649536138934 | validation: 1.3147593074969934]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048706215123519		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.048706215123519 | validation: 1.134377970392488]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9523936190527245		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.9523936190527245 | validation: 1.1416054712436972]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030974788313404		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.030974788313404 | validation: 0.9100643135198354]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.89762705258234		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.89762705258234 | validation: 1.059871722523182]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9370302751107156		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.9370302751107156 | validation: 4.419501136116259]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.939391161722586		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.939391161722586 | validation: 1.0647332386385522]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829426129466134		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.8829426129466134 | validation: 1.1667974462108242]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0505223093631935		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.0505223093631935 | validation: 0.9666705085538637]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8850643414407167		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.8850643414407167 | validation: 1.0240722422188346]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840293731254144		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.840293731254144 | validation: 1.2481859822735804]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0409682155982396		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.0409682155982396 | validation: 3.0153203582469654]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7714319134688163		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.7714319134688163 | validation: 1.1852104843626787]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642997560526062		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.0642997560526062 | validation: 0.966127058328282]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9170278618167544		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.9170278618167544 | validation: 1.2181732109077226]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019560501556408		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.019560501556408 | validation: 1.1987389145081337]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9752439248755642		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.9752439248755642 | validation: 1.2147833048776553]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250283270012304		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.0250283270012304 | validation: 1.1562019872302824]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.982572264306556		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.982572264306556 | validation: 0.787049411121433]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701275694353646		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.7701275694353646 | validation: 1.0668916447026644]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8799674911734985		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.8799674911734985 | validation: 0.8333581412238491]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7527414752622398		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7527414752622398 | validation: 1.1822624133702633]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0060069514887269		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.0060069514887269 | validation: 0.941827999807257]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439332128784369		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.8439332128784369 | validation: 0.8893459468111914]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0215688654619361		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.0215688654619361 | validation: 1.0951809889020194]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5745076881954994		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.5745076881954994 | validation: 1.3275056869751678]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1946356364142483		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.1946356364142483 | validation: 0.8840759593710895]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223839378250437		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.0223839378250437 | validation: 1.2024658060001239]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9150245349260483		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.9150245349260483 | validation: 0.8875135761005936]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762938103088973		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.762938103088973 | validation: 0.9618125273575617]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9218057105005883		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.9218057105005883 | validation: 0.8712512697345173]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387699687468536		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7387699687468536 | validation: 0.9804878473408541]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8763287964503492		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.8763287964503492 | validation: 1.5685610822349514]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433460393930734		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.1433460393930734 | validation: 1.0822955879048193]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035714964458998		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.9035714964458998 | validation: 1.1372662879354911]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732927384592393		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.8732927384592393 | validation: 0.9692750420171777]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7799139116606489		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7799139116606489 | validation: 0.9783094497216734]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876816753763642		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.876816753763642 | validation: 1.0134512386978958]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374086200607891		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.9374086200607891 | validation: 1.0316432454327948]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.972217702431568		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.972217702431568 | validation: 1.103252175411848]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3185635144454897		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.3185635144454897 | validation: 0.852624139907665]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0897559009882059		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.0897559009882059 | validation: 1.2131091567997994]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9329635176569095		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.9329635176569095 | validation: 0.952388548240917]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8159424173065692		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.8159424173065692 | validation: 1.1850377547169808]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114722805645962		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8114722805645962 | validation: 0.9174693729426897]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3675566373548784		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.3675566373548784 | validation: 1.0736819800907969]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9596458195367678		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.9596458195367678 | validation: 0.9886451139001596]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8348153684396383		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.8348153684396383 | validation: 1.4648930155203954]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1982380226525744		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.1982380226525744 | validation: 1.2711121750713934]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8701142438149269		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.8701142438149269 | validation: 1.3784269243635316]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.882792785353856		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.882792785353856 | validation: 0.8932015643874687]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805651956283564		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.8805651956283564 | validation: 0.9419649739615409]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7499770925246034		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7499770925246034 | validation: 0.8717028043450283]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8207806407339415		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.8207806407339415 | validation: 1.0828620503823478]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826070318891307		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7826070318891307 | validation: 0.8838624504283515]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903004130376708		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.903004130376708 | validation: 0.7267494135824206]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071929817907353		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.8071929817907353 | validation: 0.8863671391050778]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.929144829195643		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.929144829195643 | validation: 1.7154947801041396]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628815570694676		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.0628815570694676 | validation: 0.7880320316673268]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8474329766419917		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8474329766419917 | validation: 0.8263492423200788]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7298018407615667		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7298018407615667 | validation: 1.16544448297669]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9356824094378765		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.9356824094378765 | validation: 1.291174040982964]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9675070243371028		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.9675070243371028 | validation: 0.8601386574318473]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7586138115768714		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7586138115768714 | validation: 0.8558289106002261]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336144126699616		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.9336144126699616 | validation: 0.7766845465583854]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8352752069861449		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.8352752069861449 | validation: 0.8324069670921379]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7945797448518049		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7945797448518049 | validation: 0.989372862725198]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075708525425501		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.9075708525425501 | validation: 0.7881285546158272]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752921019932836		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7752921019932836 | validation: 0.9630071732651071]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1589631417177853		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.1589631417177853 | validation: 1.4017188850510007]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020454765055621		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.020454765055621 | validation: 1.5160843191856597]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9537023684177819		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.9537023684177819 | validation: 1.2128160630438385]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876985007374058		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.876985007374058 | validation: 0.6845658485813817]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584329168125967		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7584329168125967 | validation: 1.0213152682750128]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881733116348325		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.8881733116348325 | validation: 1.1926994595669276]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8460140898932653		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.8460140898932653 | validation: 1.52312865980595]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528707193724212		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.0528707193724212 | validation: 0.7439561048099246]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307380934100052		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.7307380934100052 | validation: 1.4226706350702705]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0279503292341843		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.0279503292341843 | validation: 0.7536789257899646]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7541009389053579		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7541009389053579 | validation: 1.1161770512616773]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208508598841426		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.9208508598841426 | validation: 1.375763342543142]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9961078673606325		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.9961078673606325 | validation: 0.7572386821018096]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7666040601901486		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.7666040601901486 | validation: 0.7685263608488098]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188673761475407		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7188673761475407 | validation: 1.1106211538544342]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375246129153231		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.8375246129153231 | validation: 0.8551546170423865]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8928412850635858		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.8928412850635858 | validation: 0.7544705580357197]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7429379644668765		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.7429379644668765 | validation: 0.7904044163639589]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0095881840323615		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.0095881840323615 | validation: 0.9236785937230029]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181548350710619		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.8181548350710619 | validation: 0.8987302818566119]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9543872759132149		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.9543872759132149 | validation: 0.9954091850085754]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8870387273474596		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.8870387273474596 | validation: 0.9114354513756097]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376044063498437		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7376044063498437 | validation: 1.1377370886733347]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900378364520115		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7900378364520115 | validation: 0.7249133271228362]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120094534216215		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.8120094534216215 | validation: 1.1192976202100602]
	TIME [epoch: 24.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789348178062074		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.789348178062074 | validation: 0.9345005464759641]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8636416396077427		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.8636416396077427 | validation: 0.9958591019388628]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8101162166838257		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.8101162166838257 | validation: 1.042472198648214]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7727352950934858		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7727352950934858 | validation: 0.8076488754565998]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830579343520675		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6830579343520675 | validation: 0.8730511422298561]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8041950449845994		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.8041950449845994 | validation: 0.7441766635935886]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735385294288978		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.735385294288978 | validation: 0.8253548118749763]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9914407857861922		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.9914407857861922 | validation: 3.692698249119683]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.59117376859172		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.59117376859172 | validation: 2.7631624316296954]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2418540564408977		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.2418540564408977 | validation: 1.155335385496505]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9624743013444664		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.9624743013444664 | validation: 1.169968790164321]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8013273745192676		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.8013273745192676 | validation: 0.9514999365208118]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9988281588219483		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.9988281588219483 | validation: 1.5790149015889952]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086099104987494		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.086099104987494 | validation: 0.7976610127518134]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605987407741626		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7605987407741626 | validation: 0.8977455311948924]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648067806159993		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7648067806159993 | validation: 0.9745188454420307]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8515204274803649		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.8515204274803649 | validation: 1.2605036155050213]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8148889266384554		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8148889266384554 | validation: 1.1808497282728312]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9887252490511635		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.9887252490511635 | validation: 0.8162908626036565]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8634158349290918		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.8634158349290918 | validation: 0.8682255360834699]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162595924541135		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7162595924541135 | validation: 0.7568566343512707]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945715826752922		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.6945715826752922 | validation: 1.243730245230343]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9550696506272162		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.9550696506272162 | validation: 0.7093635967308436]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888463839779663		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.6888463839779663 | validation: 0.8658152924835707]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008460909897419		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7008460909897419 | validation: 0.8063139105518217]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805498302698346		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.805498302698346 | validation: 0.7924630061159106]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487870313046697		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.6487870313046697 | validation: 0.7443400424415936]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126603931012794		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7126603931012794 | validation: 1.036091696933128]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8257597176013356		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8257597176013356 | validation: 0.9633038435383046]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756196733763162		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.756196733763162 | validation: 0.6796990612798611]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6895339469624266		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6895339469624266 | validation: 1.071033503253702]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956309357342579		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6956309357342579 | validation: 0.9209582487196228]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432773199595587		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.7432773199595587 | validation: 0.7545011302478267]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6274894754098688		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6274894754098688 | validation: 0.6722079267321649]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360854798109493		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.7360854798109493 | validation: 0.7567620459822821]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140711526726722		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.7140711526726722 | validation: 0.9529103246030414]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956898597618821		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.6956898597618821 | validation: 0.8136858706594207]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813852265370198		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.6813852265370198 | validation: 0.7095756941926998]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6403624433704123		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6403624433704123 | validation: 0.7444880501563046]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818285195157254		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.818285195157254 | validation: 0.6835237832724905]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216995574720433		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6216995574720433 | validation: 0.8083007133180692]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9391481446284611		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.9391481446284611 | validation: 0.7825421524961711]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9204550277572937		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.9204550277572937 | validation: 0.8211387516854928]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432114230677462		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7432114230677462 | validation: 0.8807380771114431]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235681868551472		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7235681868551472 | validation: 0.7516737125408496]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929020576077052		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6929020576077052 | validation: 0.8425343248551661]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653141433458904		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.653141433458904 | validation: 0.7919230938788195]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734503175935931		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6734503175935931 | validation: 0.6132955517480437]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719559723620733		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.719559723620733 | validation: 0.7836029134655289]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7889558757006256		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.7889558757006256 | validation: 0.7979284846963222]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172403173501292		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7172403173501292 | validation: 0.7521657286672698]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282985806659643		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.7282985806659643 | validation: 0.7340304055097946]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300401162961408		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6300401162961408 | validation: 1.069619022635528]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160862188367172		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7160862188367172 | validation: 0.7952126726707495]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616337610356099		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.616337610356099 | validation: 0.7891111512558172]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545068398198909		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7545068398198909 | validation: 0.8328874477122872]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6766522074937497		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6766522074937497 | validation: 0.8860672422410579]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479112702120666		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6479112702120666 | validation: 0.6572736907925395]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.978726704267671		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.978726704267671 | validation: 0.8075860993718152]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8302992382796379		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.8302992382796379 | validation: 0.7141640560889385]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755694362876304		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7755694362876304 | validation: 0.7393946517631023]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361374288247185		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.6361374288247185 | validation: 0.6222795940230913]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128121925345921		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6128121925345921 | validation: 0.7727431665088283]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734277105985341		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.6734277105985341 | validation: 0.8102133958549865]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684108318215829		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6684108318215829 | validation: 0.6369952408734452]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090928636908615		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.6090928636908615 | validation: 0.6878071153356623]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283138196724939		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6283138196724939 | validation: 0.7016661984685711]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760467133495344		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5760467133495344 | validation: 0.841976693019353]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922929050437456		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6922929050437456 | validation: 0.5728209071005219]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6488472759627806		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6488472759627806 | validation: 0.8014124413590926]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879676099083515		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5879676099083515 | validation: 0.8494983905992207]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907043490685286		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7907043490685286 | validation: 1.1361674591373163]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7830511542601771		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7830511542601771 | validation: 0.7196360289783297]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162760803171248		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6162760803171248 | validation: 0.8179681779869047]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806296097719112		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.806296097719112 | validation: 1.1726321125740915]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921131978596738		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7921131978596738 | validation: 0.6899378690958641]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436220990522793		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.6436220990522793 | validation: 0.6520970236794148]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432450104118079		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6432450104118079 | validation: 0.6875027582659823]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940912308017353		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.5940912308017353 | validation: 0.6321631430871019]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048975461353059		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6048975461353059 | validation: 0.8205874755453345]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6412833806139094		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6412833806139094 | validation: 0.7222408355679043]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6395588113856041		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6395588113856041 | validation: 0.650243611584171]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876832010868772		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5876832010868772 | validation: 0.7623568243990172]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5557615430042774		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5557615430042774 | validation: 0.6897144179588482]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620277609528798		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.620277609528798 | validation: 0.6450567928867581]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1063576925588174		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.1063576925588174 | validation: 0.9324401038475569]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806407306242222		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.806407306242222 | validation: 0.7712419682366877]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461265606694449		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5461265606694449 | validation: 0.7167906338943244]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7579522932065653		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.7579522932065653 | validation: 1.149508380911704]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879488033394972		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.8879488033394972 | validation: 0.6646131217064957]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799096101421497		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5799096101421497 | validation: 0.6036108975609734]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155960079368553		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5155960079368553 | validation: 0.6438431786407928]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5594328239100638		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.5594328239100638 | validation: 0.8420609714858627]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8926293836522426		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.8926293836522426 | validation: 0.8107048044487888]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7035304820068982		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.7035304820068982 | validation: 1.050292148009654]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590038783392231		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.7590038783392231 | validation: 0.8658858230543653]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678386934912102		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6678386934912102 | validation: 0.8330141780389059]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788571300829015		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.6788571300829015 | validation: 0.7562911852254982]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6022557047777755		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6022557047777755 | validation: 0.6316499938333123]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5805384673011776		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5805384673011776 | validation: 0.6351223974275403]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7573417719397352		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.7573417719397352 | validation: 0.7556044393504536]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007534890916152		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.7007534890916152 | validation: 0.5911244402123622]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634369197144898		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.634369197144898 | validation: 0.6172092072996529]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958132804838403		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.5958132804838403 | validation: 0.6370174244762032]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211226511556786		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5211226511556786 | validation: 1.0799849035025406]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8164850249850344		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.8164850249850344 | validation: 0.7669555202764984]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717808481380226		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.717808481380226 | validation: 0.7377358236308055]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7604891468382283		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7604891468382283 | validation: 0.6912966138867713]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677548710100244		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.7677548710100244 | validation: 1.2341738994668023]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.085752009308009		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.085752009308009 | validation: 1.1780864105327242]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589887512117456		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.7589887512117456 | validation: 0.780785000638777]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342425918985206		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.6342425918985206 | validation: 0.6984177887479123]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493559572343737		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.5493559572343737 | validation: 0.595780066042883]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662449786871014		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5662449786871014 | validation: 0.6143965343860439]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533243464375633		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.533243464375633 | validation: 0.5831831624510723]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6067768308091804		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6067768308091804 | validation: 0.6090530943520102]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5709352025501024		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5709352025501024 | validation: 0.6190526462596119]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621013074761124		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.621013074761124 | validation: 0.7668788372992245]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436110911652156		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6436110911652156 | validation: 0.6817187320876431]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797563952640363		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6797563952640363 | validation: 0.8431127789630616]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769738997272067		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.6769738997272067 | validation: 1.6288018116016638]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045310672813966		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.045310672813966 | validation: 0.9858692220160526]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057157068168618		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.7057157068168618 | validation: 0.7631138776715056]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843169419344723		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5843169419344723 | validation: 0.6067092792672483]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225515341445572		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5225515341445572 | validation: 0.5814600481375745]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.521182814068751		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.521182814068751 | validation: 0.6069215430999644]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5766655425000782		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5766655425000782 | validation: 0.7455017006387334]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423756358796975		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5423756358796975 | validation: 0.5286689355170855]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5813440566142646		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5813440566142646 | validation: 0.555953579311046]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254574968484274		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.6254574968484274 | validation: 0.7273906002871007]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279737844101443		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.6279737844101443 | validation: 0.764148730501521]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759310084880093		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5759310084880093 | validation: 0.6706940721195811]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931794786398066		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5931794786398066 | validation: 0.5601855166003583]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6209356200662011		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.6209356200662011 | validation: 0.5746933769219037]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5530633748617344		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5530633748617344 | validation: 0.6692495906216257]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5610814835752742		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5610814835752742 | validation: 0.5574074243297651]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527593428294976		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.527593428294976 | validation: 0.6956583678893908]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638366696129962		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.638366696129962 | validation: 0.6941885046337063]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5767287978158007		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.5767287978158007 | validation: 0.5702521126586121]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48471464113751583		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.48471464113751583 | validation: 0.7294794720273281]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.64620526796179		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.64620526796179 | validation: 0.6430023464246725]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199298233103673		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5199298233103673 | validation: 0.5389452013336821]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231363911801908		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5231363911801908 | validation: 0.6400725235801514]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461820534609936		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5461820534609936 | validation: 0.567810837475294]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430474776404384		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5430474776404384 | validation: 0.5339979863084164]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381507286118108		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5381507286118108 | validation: 0.9236552589788781]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.600593394916475		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.600593394916475 | validation: 0.490931491154917]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092230666223929		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.6092230666223929 | validation: 0.7808812138615556]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576338204070279		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.6576338204070279 | validation: 0.5683942038784927]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482704440732619		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5482704440732619 | validation: 0.5783465103163041]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832739868471353		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5832739868471353 | validation: 0.7671518856290501]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195043099970792		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5195043099970792 | validation: 0.6551413890044916]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279844512193227		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5279844512193227 | validation: 0.6875055613416194]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092123859517097		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.6092123859517097 | validation: 0.6152548352467172]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4947192418114927		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.4947192418114927 | validation: 0.5636712312406624]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937007354814184		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.4937007354814184 | validation: 0.7393853937951176]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066088741531306		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6066088741531306 | validation: 0.7207967658986906]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5681918458668681		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5681918458668681 | validation: 0.5969297391975313]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222370623089045		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5222370623089045 | validation: 0.5564763605005058]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062716124908785		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5062716124908785 | validation: 0.557455906321801]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232338112788358		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.5232338112788358 | validation: 0.6072778768533862]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49492281526510074		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.49492281526510074 | validation: 0.7099384428868197]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809112155401469		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.5809112155401469 | validation: 0.6783251813711499]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927286169527878		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.6927286169527878 | validation: 0.7880117147008229]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564153099687963		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5564153099687963 | validation: 0.564582673145286]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314284090938599		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5314284090938599 | validation: 0.7697312189045047]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773362329424391		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5773362329424391 | validation: 0.7229520351737108]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736261473411399		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5736261473411399 | validation: 0.6797476780592158]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182335942021976		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5182335942021976 | validation: 0.6693981822157027]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835076778099737		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5835076778099737 | validation: 0.6753359606490901]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561053323393937		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5561053323393937 | validation: 0.5443878399668232]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199913386588766		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5199913386588766 | validation: 0.5441361206308012]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47155027827573		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.47155027827573 | validation: 0.6387722281266448]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150425664611028		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5150425664611028 | validation: 0.5953103661840665]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128693413272882		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5128693413272882 | validation: 0.5237062213920978]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254763449760392		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.6254763449760392 | validation: 0.7089234935017109]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54937658860182		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.54937658860182 | validation: 0.6580817780290107]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336347404686612		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5336347404686612 | validation: 0.552486492375702]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49547542225547664		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.49547542225547664 | validation: 0.49786363562766756]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5531025584468519		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.5531025584468519 | validation: 0.7039486454779056]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090220975356699		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.6090220975356699 | validation: 0.7240087511709438]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183331954180431		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.6183331954180431 | validation: 0.5932986481965121]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158893739187143		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5158893739187143 | validation: 0.5278901283591168]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4951579464397925		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.4951579464397925 | validation: 0.6468176122765188]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280278033711632		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5280278033711632 | validation: 0.6547260298800118]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068420691073623		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5068420691073623 | validation: 0.6292556141473135]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011948631021332		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5011948631021332 | validation: 0.6760346108742761]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4420183790935608		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.4420183790935608 | validation: 0.5581159566678894]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45823136211551596		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.45823136211551596 | validation: 0.4921927394692378]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199747883616431		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.4199747883616431 | validation: 0.4650853686354354]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676072825137766		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.4676072825137766 | validation: 0.5522628084211775]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5583359849896233		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5583359849896233 | validation: 0.6011325734209325]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205728894858308		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6205728894858308 | validation: 0.8218262810164069]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203221842690599		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5203221842690599 | validation: 0.4858130170257654]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4369475529731298		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.4369475529731298 | validation: 0.5139609732342982]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702962762722772		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.4702962762722772 | validation: 0.7864507582931048]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5930652838321143		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5930652838321143 | validation: 0.823552460407837]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699244848769542		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.6699244848769542 | validation: 1.8672832628548424]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301040842045201		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.301040842045201 | validation: 0.7661184152354651]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463796665730883		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5463796665730883 | validation: 0.551476503175601]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4611551198307236		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.4611551198307236 | validation: 0.6900625623524081]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4944542337799285		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.4944542337799285 | validation: 0.5660123081481954]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242203027045488		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5242203027045488 | validation: 0.5431916468932403]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395669929312743		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.4395669929312743 | validation: 0.6515941893644848]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5658200213247195		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5658200213247195 | validation: 0.5064667420173067]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45363569528999864		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.45363569528999864 | validation: 0.5847616398968984]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125628661534638		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.5125628661534638 | validation: 0.6904172428854278]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5495355709163976		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5495355709163976 | validation: 0.5358383180129402]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45363052435102275		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.45363052435102275 | validation: 0.5640903310431277]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47223397451711024		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.47223397451711024 | validation: 0.6502900699251773]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165868087049434		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5165868087049434 | validation: 0.5905287895571258]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202741910812037		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5202741910812037 | validation: 0.7316516028692701]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5421257025282658		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5421257025282658 | validation: 0.5794142107723038]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967415761588088		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.4967415761588088 | validation: 0.5519997094280499]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45841011745895643		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.45841011745895643 | validation: 0.6782105859486615]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414948927379509		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5414948927379509 | validation: 0.5841134856042214]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48046098177117147		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.48046098177117147 | validation: 0.6290189226960241]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193347229536813		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5193347229536813 | validation: 0.5046855363131197]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47440858777317657		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.47440858777317657 | validation: 0.5187426675933418]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654459958988193		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.654459958988193 | validation: 0.6928903808510859]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272921297320441		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5272921297320441 | validation: 0.7356524341937609]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665606326633786		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5665606326633786 | validation: 0.6083970109643386]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45357292157232904		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.45357292157232904 | validation: 0.5412809247353643]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883223966560837		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.4883223966560837 | validation: 0.6067056811893917]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915342838594119		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5915342838594119 | validation: 0.6471037393347456]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410433738318532		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5410433738318532 | validation: 0.5548610169587975]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43105347265606775		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.43105347265606775 | validation: 0.5587802078209896]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938982191859604		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5938982191859604 | validation: 0.6588809874275608]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45832778234325006		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.45832778234325006 | validation: 0.5002688076362146]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42163581581087173		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.42163581581087173 | validation: 0.5502311629628608]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.435704809358368		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.435704809358368 | validation: 0.5350825494933839]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45188480226681216		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.45188480226681216 | validation: 0.504935122424376]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4344290866065662		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.4344290866065662 | validation: 0.5098365381298359]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435777924053801		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.4435777924053801 | validation: 0.483342449476839]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4559760310172948		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4559760310172948 | validation: 0.523940311209766]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179709335061358		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.8179709335061358 | validation: 1.1474781724943304]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990139451831853		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6990139451831853 | validation: 0.6047346969641535]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382727831346501		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5382727831346501 | validation: 0.721866087080989]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467738065987922		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.5467738065987922 | validation: 0.7136016608988776]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014660820256039		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5014660820256039 | validation: 0.5692760006920626]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445496739701274		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5445496739701274 | validation: 0.4870540194716443]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39330642820359346		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.39330642820359346 | validation: 0.49447940473235946]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44341506556140525		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.44341506556140525 | validation: 0.6844107989081863]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045584585655657		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5045584585655657 | validation: 0.6167524718360294]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43480308640053295		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.43480308640053295 | validation: 0.4733670224239785]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651105840316664		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4651105840316664 | validation: 0.7686317119021874]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340919319700217		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5340919319700217 | validation: 0.6342028095362744]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6612728708707309		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.6612728708707309 | validation: 0.48470698928449707]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40952554068793223		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.40952554068793223 | validation: 0.7350380185483707]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745192875910323		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.6745192875910323 | validation: 0.5698959255371695]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218249546503032		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.4218249546503032 | validation: 0.4950630028318431]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49824149068804324		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.49824149068804324 | validation: 0.5536454760960284]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606266117647824		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.606266117647824 | validation: 0.5147693941856353]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013554491957231		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5013554491957231 | validation: 0.9215544390417059]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658261641861866		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.658261641861866 | validation: 0.5887523728359078]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561311763007865		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5561311763007865 | validation: 0.49190285853851373]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45165547817766505		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.45165547817766505 | validation: 0.5792628175761031]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913461345948189		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.5913461345948189 | validation: 0.8189631227554923]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955475407852169		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.5955475407852169 | validation: 0.5579593983841925]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588527626316892		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.4588527626316892 | validation: 0.455323664099532]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42584733921309337		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.42584733921309337 | validation: 0.6124480400133812]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582576397832664		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5582576397832664 | validation: 0.6529412624846552]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48106308881744997		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.48106308881744997 | validation: 0.4796638257960298]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37636574844908455		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.37636574844908455 | validation: 0.4935212431860912]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4167176163490682		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4167176163490682 | validation: 0.5985929021788994]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4965153694791243		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4965153694791243 | validation: 0.6916255061040033]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43793126756822354		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.43793126756822354 | validation: 0.5075147842075106]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43338470904328447		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.43338470904328447 | validation: 0.47118534717005506]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980068017902876		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3980068017902876 | validation: 0.5838957287127654]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366898510155512		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5366898510155512 | validation: 0.5808639672287212]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035989728058091		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5035989728058091 | validation: 0.6848509898872164]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003907094722658		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.5003907094722658 | validation: 0.5377618346069416]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44945777485491156		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.44945777485491156 | validation: 0.475904537196416]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42663228401247366		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.42663228401247366 | validation: 0.46573207263739586]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4212923855079377		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.4212923855079377 | validation: 0.48819971917634747]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454166473184807		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.454166473184807 | validation: 0.5628330533672389]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4381195772526675		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4381195772526675 | validation: 0.5716673032904245]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232228178053788		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.6232228178053788 | validation: 0.5278009849730602]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42067798624477704		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.42067798624477704 | validation: 0.5509853026106634]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340765820601575		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.4340765820601575 | validation: 0.5621380989763433]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135811586818122		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5135811586818122 | validation: 0.5727940804797806]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174047349898865		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4174047349898865 | validation: 0.49052556133045194]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094668694988616		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4094668694988616 | validation: 0.5030438081334743]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46556609637175894		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.46556609637175894 | validation: 0.5154252310760817]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688832982330532		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4688832982330532 | validation: 0.5847731246928188]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676317006899654		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.5676317006899654 | validation: 0.4653183789573708]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.392277337017511		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.392277337017511 | validation: 0.5385720120122919]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346504676476722		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5346504676476722 | validation: 0.6292424838807748]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230665930153934		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.5230665930153934 | validation: 0.5594467589843196]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4250297306398857		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4250297306398857 | validation: 0.467357273978796]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41979153968168537		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.41979153968168537 | validation: 0.48131747869378144]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4933973369007063		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4933973369007063 | validation: 0.566922343538404]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42212385038421973		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.42212385038421973 | validation: 0.5645983128641889]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4613643111405329		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.4613643111405329 | validation: 0.4871213697134751]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48800736333185335		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.48800736333185335 | validation: 0.6749270316985226]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716914390366193		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5716914390366193 | validation: 0.5042098415538752]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426496019849815		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.5426496019849815 | validation: 0.7689691608655691]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350038098857861		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.5350038098857861 | validation: 0.5048166324975536]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.400225174922603		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.400225174922603 | validation: 0.5330945605400301]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46869911769608114		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.46869911769608114 | validation: 0.5115871991944565]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46278609063191617		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.46278609063191617 | validation: 0.49156645896613854]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977016656931168		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.4977016656931168 | validation: 0.45966408986738216]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47231012518068166		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.47231012518068166 | validation: 0.6239762159099926]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48316749702840506		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.48316749702840506 | validation: 0.5413141678047152]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351406794354322		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4351406794354322 | validation: 0.5396890975245314]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089543712192077		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.5089543712192077 | validation: 0.5052100680113678]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888749870874819		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4888749870874819 | validation: 0.5854970113820521]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40127090327986437		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.40127090327986437 | validation: 0.5171271899269249]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741419849127796		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4741419849127796 | validation: 0.4651777788964151]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878364642232998		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.3878364642232998 | validation: 0.4846746105747321]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3912345793818772		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3912345793818772 | validation: 0.48910975244302635]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4306429252735712		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.4306429252735712 | validation: 0.5572283106214875]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935319748274392		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4935319748274392 | validation: 0.6166761346052655]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46619811809956146		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.46619811809956146 | validation: 0.6003383043013995]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40187834451637755		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.40187834451637755 | validation: 0.5009948732411243]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46506071799909027		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.46506071799909027 | validation: 0.5580546181321118]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43969445275165076		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.43969445275165076 | validation: 0.5350677609404109]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39525587845625987		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.39525587845625987 | validation: 0.5646964039180666]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4315094662898707		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4315094662898707 | validation: 0.820527276231636]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.617542226691709		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.617542226691709 | validation: 0.6114612416509645]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49162439618858983		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.49162439618858983 | validation: 0.4651045069902395]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42713397111914		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.42713397111914 | validation: 0.553303519171128]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149894723253744		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.5149894723253744 | validation: 0.5797035727382995]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49342906724391966		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.49342906724391966 | validation: 0.5427662202246389]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38908257061285023		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.38908257061285023 | validation: 0.5000879438404661]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832253656647546		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3832253656647546 | validation: 0.5893941478747915]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040570474641179		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.7040570474641179 | validation: 0.7279891209725062]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228630106061734		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5228630106061734 | validation: 0.7597061579314891]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5672122070963053		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.5672122070963053 | validation: 0.552290615673382]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689988289498772		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4689988289498772 | validation: 0.5601972577196529]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779936719668586		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4779936719668586 | validation: 0.6453437647844228]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4521092852010554		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4521092852010554 | validation: 0.5464901549493965]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40649169927931084		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.40649169927931084 | validation: 0.538160974167767]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533261680090364		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.4533261680090364 | validation: 0.49388770179443625]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928638321704339		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.4928638321704339 | validation: 0.5112913931453811]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4140332595027613		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4140332595027613 | validation: 0.5657226841051508]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43641543459758675		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.43641543459758675 | validation: 0.5061559194927009]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38912596991404896		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.38912596991404896 | validation: 0.4823926579715275]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395548573473958		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4395548573473958 | validation: 0.5874364763797671]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288405104978448		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4288405104978448 | validation: 0.6313378401375449]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45774014776860705		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.45774014776860705 | validation: 0.5248705154072713]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38732866827043516		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.38732866827043516 | validation: 0.5080902340440016]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868727425746208		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4868727425746208 | validation: 0.48510658631055464]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509518304122637		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.509518304122637 | validation: 0.7319649558973944]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5063454413283284		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.5063454413283284 | validation: 0.5466164695265242]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4274429201106438		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.4274429201106438 | validation: 0.5380773931238954]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358240015410477		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4358240015410477 | validation: 0.6166563176109604]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47786469068865955		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.47786469068865955 | validation: 0.5103956160761816]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386406943812845		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.386406943812845 | validation: 0.4992461808766105]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46962886017664845		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.46962886017664845 | validation: 0.6594594978966071]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47372377686508926		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.47372377686508926 | validation: 0.5512559414807777]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47995929269452803		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.47995929269452803 | validation: 0.7163310871956197]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48359353949221245		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.48359353949221245 | validation: 0.5444190817714419]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155997549776337		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4155997549776337 | validation: 0.5182847358696623]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49979588629512206		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.49979588629512206 | validation: 0.5646354528322413]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40521316465088114		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.40521316465088114 | validation: 0.5404521165953599]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528941005411346		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.528941005411346 | validation: 0.6884574385132197]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321240638775793		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.5321240638775793 | validation: 0.5097835625297049]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3839370122726637		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3839370122726637 | validation: 0.4902612455782618]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798692271334453		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.3798692271334453 | validation: 0.5293644437144949]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41835896769902686		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.41835896769902686 | validation: 0.46933793918314914]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40768361253263896		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.40768361253263896 | validation: 0.7371644073112958]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5086014524719005		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.5086014524719005 | validation: 0.5581123724072813]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44546370493712284		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.44546370493712284 | validation: 0.519841373123705]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42732284960473954		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.42732284960473954 | validation: 0.5364397467564167]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804553615322613		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.3804553615322613 | validation: 0.4719023023029301]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38906672158852507		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.38906672158852507 | validation: 0.5227893798939482]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404466174558733		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.4404466174558733 | validation: 0.48294406893466907]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42122646383658		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.42122646383658 | validation: 0.5434329137031694]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44127225389415825		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.44127225389415825 | validation: 0.46252886166757157]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614662392230593		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.3614662392230593 | validation: 0.4774200658671664]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399461269915286		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3399461269915286 | validation: 0.4449194921933809]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38453640180618504		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.38453640180618504 | validation: 0.5639120155524492]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41422310528002837		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.41422310528002837 | validation: 0.5352737626757407]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939704721672343		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.4939704721672343 | validation: 0.5397263035266541]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4320205874768275		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.4320205874768275 | validation: 0.44593711048092816]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563600156100167		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.3563600156100167 | validation: 0.4459478664125054]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38458211747559096		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.38458211747559096 | validation: 0.5082490546745155]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36420331227838904		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.36420331227838904 | validation: 0.4196994733480938]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_866.pth
	Model improved!!!
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32166036054174907		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.32166036054174907 | validation: 0.4621800936950619]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36471620258702675		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.36471620258702675 | validation: 0.4640783276438127]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258579512645375		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3258579512645375 | validation: 0.4402139251967324]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4427625614237568		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.4427625614237568 | validation: 0.4475464569301986]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36434138796644816		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.36434138796644816 | validation: 0.43118941319047566]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37321391107625856		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.37321391107625856 | validation: 0.49755189909600495]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43032121901600107		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.43032121901600107 | validation: 0.5676158407255422]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46408119862904984		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.46408119862904984 | validation: 0.47953406179937774]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4769787550172578		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4769787550172578 | validation: 0.4844817653074532]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843582395477003		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.3843582395477003 | validation: 0.6031470858841236]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946169454407292		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3946169454407292 | validation: 0.43604318527896097]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38800302124501657		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.38800302124501657 | validation: 0.5427861037727731]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340741193358924		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4340741193358924 | validation: 0.5534969522419513]
	TIME [epoch: 24.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45245447822059254		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.45245447822059254 | validation: 0.4278958714316988]
	TIME [epoch: 24.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607365873107435		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3607365873107435 | validation: 0.46010609338057606]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822389661163441		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.3822389661163441 | validation: 0.4727069249981386]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35119941619235906		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.35119941619235906 | validation: 0.5989392564105736]
	TIME [epoch: 24.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46574741735107666		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.46574741735107666 | validation: 0.4757729802457209]
	TIME [epoch: 24.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642205550723889		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.3642205550723889 | validation: 0.49240672219349796]
	TIME [epoch: 24.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39734205891798		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.39734205891798 | validation: 0.617444138691291]
	TIME [epoch: 24.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46584430722605485		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.46584430722605485 | validation: 0.5886611356226724]
	TIME [epoch: 24.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664511654241238		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.4664511654241238 | validation: 0.49253311415499035]
	TIME [epoch: 24.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40740487051556157		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.40740487051556157 | validation: 0.4971256498278829]
	TIME [epoch: 24.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36805828695430204		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.36805828695430204 | validation: 0.4202383128055403]
	TIME [epoch: 24.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42645858203812426		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.42645858203812426 | validation: 0.4667540992033059]
	TIME [epoch: 24.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4884949312251641		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.4884949312251641 | validation: 0.49764506067248704]
	TIME [epoch: 24.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745321448539857		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3745321448539857 | validation: 0.5290198004702864]
	TIME [epoch: 24.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3947349409447282		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.3947349409447282 | validation: 0.4790321614382983]
	TIME [epoch: 24.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476254869552994		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.3476254869552994 | validation: 0.4521271302801597]
	TIME [epoch: 24.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35784976406069496		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.35784976406069496 | validation: 0.5851412351328567]
	TIME [epoch: 24.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46268238348664514		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.46268238348664514 | validation: 0.5180472902826507]
	TIME [epoch: 24.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756252173919813		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3756252173919813 | validation: 0.4248137266152729]
	TIME [epoch: 24.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574076511109868		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.3574076511109868 | validation: 0.4968454311921811]
	TIME [epoch: 24.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757691727886303		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3757691727886303 | validation: 0.5188526527723818]
	TIME [epoch: 24.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36799127981397		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.36799127981397 | validation: 0.5195637222760365]
	TIME [epoch: 24.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703058125089549		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3703058125089549 | validation: 0.4315197673583066]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36506246218959587		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.36506246218959587 | validation: 0.459321180987742]
	TIME [epoch: 24.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673325544571129		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.3673325544571129 | validation: 0.4360923670240065]
	TIME [epoch: 24.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476054450398951		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.3476054450398951 | validation: 0.5049774109153602]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082557757364042		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.4082557757364042 | validation: 0.49485090964240713]
	TIME [epoch: 24.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33356231443934725		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.33356231443934725 | validation: 0.5151785410215521]
	TIME [epoch: 24.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35718357638918596		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.35718357638918596 | validation: 0.44075570601661457]
	TIME [epoch: 24.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34539938162485795		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.34539938162485795 | validation: 0.4486830784689218]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44188178949999835		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.44188178949999835 | validation: 0.45562097106311783]
	TIME [epoch: 24.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215971585420289		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4215971585420289 | validation: 0.4582774075566491]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.367597566092817		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.367597566092817 | validation: 0.42678203017240657]
	TIME [epoch: 24.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34826844719047667		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.34826844719047667 | validation: 0.4324898402917397]
	TIME [epoch: 24.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38773536419327487		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.38773536419327487 | validation: 0.49080409935380404]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39968885973133367		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.39968885973133367 | validation: 0.4263696914298938]
	TIME [epoch: 24.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3829208850044075		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.3829208850044075 | validation: 0.4546502158053681]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38451049692732303		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.38451049692732303 | validation: 0.4587362290840959]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204655290076873		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4204655290076873 | validation: 0.4858434882444601]
	TIME [epoch: 24.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42391951128808086		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.42391951128808086 | validation: 0.5279384649670986]
	TIME [epoch: 24.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364062420639411		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.364062420639411 | validation: 0.42858492048784613]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35383170015293397		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.35383170015293397 | validation: 0.4907657059430058]
	TIME [epoch: 24.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620373371197845		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.3620373371197845 | validation: 0.4060318609035858]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34125749069281575		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.34125749069281575 | validation: 0.4419624601350051]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388861390499639		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.3388861390499639 | validation: 0.4327024509204956]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33110593410082123		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.33110593410082123 | validation: 0.4132086514249494]
	TIME [epoch: 24.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276052134229059		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3276052134229059 | validation: 0.40845252925378106]
	TIME [epoch: 24.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3265382200653736		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.3265382200653736 | validation: 0.4446964084332754]
	TIME [epoch: 24.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4434682053218354		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.4434682053218354 | validation: 0.6605049794050509]
	TIME [epoch: 24.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843285024965086		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.4843285024965086 | validation: 0.5508363261900996]
	TIME [epoch: 24.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39857086402275105		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.39857086402275105 | validation: 0.4356611529976141]
	TIME [epoch: 24.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529726703914938		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.3529726703914938 | validation: 0.4247805501118057]
	TIME [epoch: 24.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334610530919579		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.334610530919579 | validation: 0.42000093136729305]
	TIME [epoch: 24.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33055001838845477		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.33055001838845477 | validation: 0.43853523969410185]
	TIME [epoch: 24.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334423102183483		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.334423102183483 | validation: 0.429866769872811]
	TIME [epoch: 24.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32264065926349905		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.32264065926349905 | validation: 0.48867132494896043]
	TIME [epoch: 24.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36823304765343057		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.36823304765343057 | validation: 0.45278658435199914]
	TIME [epoch: 24.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40008380979374736		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.40008380979374736 | validation: 0.4180150382561266]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352019834449862		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3352019834449862 | validation: 0.47846575681295805]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35005631403500775		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.35005631403500775 | validation: 0.4265300874845417]
	TIME [epoch: 24.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39540055776002914		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.39540055776002914 | validation: 0.7061651510816906]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4889568024103658		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.4889568024103658 | validation: 0.4626682773058245]
	TIME [epoch: 24.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37436888111604305		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.37436888111604305 | validation: 0.42844528011060584]
	TIME [epoch: 24.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36110399427407364		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.36110399427407364 | validation: 0.4607987804093358]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33695843889263677		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.33695843889263677 | validation: 0.44086563146356567]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41892239780622886		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.41892239780622886 | validation: 0.5478120535145498]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061055785295331		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.4061055785295331 | validation: 0.44207960338306995]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536172922247177		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.3536172922247177 | validation: 0.3827109466598632]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32450553046969066		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.32450553046969066 | validation: 0.4273151273873416]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.346215689309282		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.346215689309282 | validation: 0.5016413659474894]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38737469016133624		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.38737469016133624 | validation: 0.4025357292022062]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321465043235824		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.3321465043235824 | validation: 0.40506507537410835]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32302220952631894		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.32302220952631894 | validation: 0.4640035388396874]
	TIME [epoch: 24.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048247383037922		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.4048247383037922 | validation: 0.4983964348494541]
	TIME [epoch: 24.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38021510239490647		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.38021510239490647 | validation: 0.45569520327237717]
	TIME [epoch: 24.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32691206894229463		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.32691206894229463 | validation: 0.39950582630052134]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529255642059439		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.3529255642059439 | validation: 0.48750047091408805]
	TIME [epoch: 24.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642122807769337		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3642122807769337 | validation: 0.4001671389132936]
	TIME [epoch: 24.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31448343475962504		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.31448343475962504 | validation: 0.39504584927786496]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3277478030314827		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.3277478030314827 | validation: 0.4303484098103661]
	TIME [epoch: 24.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37777433981194986		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.37777433981194986 | validation: 0.4550849153018446]
	TIME [epoch: 24.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34961452674614885		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.34961452674614885 | validation: 0.42642601359484955]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32470810544355755		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.32470810544355755 | validation: 0.3800748889277359]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33124827606794877		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.33124827606794877 | validation: 0.48664063112531836]
	TIME [epoch: 24.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346437370233248		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.3346437370233248 | validation: 0.3816323696126399]
	TIME [epoch: 24.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064801233999567		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.3064801233999567 | validation: 0.4229685495875636]
	TIME [epoch: 24.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35538193458638845		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.35538193458638845 | validation: 0.4183549624682678]
	TIME [epoch: 24.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30790389810193175		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.30790389810193175 | validation: 0.3688020639487135]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_967.pth
	Model improved!!!
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805425053476288		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.3805425053476288 | validation: 0.40482902854305397]
	TIME [epoch: 24.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479472271874491		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.3479472271874491 | validation: 0.7474284632919722]
	TIME [epoch: 24.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060695364294597		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.5060695364294597 | validation: 0.3988392489358454]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32369359995593594		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.32369359995593594 | validation: 0.413684796374873]
	TIME [epoch: 24.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33464730058917674		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.33464730058917674 | validation: 0.3880495589265294]
	TIME [epoch: 24.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30829843922035327		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.30829843922035327 | validation: 0.3931721345857787]
	TIME [epoch: 24.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259028082923312		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.3259028082923312 | validation: 0.423089038348395]
	TIME [epoch: 24.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496375792060069		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3496375792060069 | validation: 0.400242541930845]
	TIME [epoch: 24.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983517858065416		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.3983517858065416 | validation: 0.591583823359151]
	TIME [epoch: 24.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816880768834849		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.3816880768834849 | validation: 0.39630228402299916]
	TIME [epoch: 24.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33775964682272286		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.33775964682272286 | validation: 0.3734843617879675]
	TIME [epoch: 24.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32113990932750985		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.32113990932750985 | validation: 0.37683211303843533]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32598219839596015		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.32598219839596015 | validation: 0.45896582954008075]
	TIME [epoch: 24.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.406142274987199		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.406142274987199 | validation: 0.4492663447468077]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163195538308017		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4163195538308017 | validation: 0.40631036923272207]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37632645657204156		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.37632645657204156 | validation: 0.4941176194008175]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602325575418178		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.3602325575418178 | validation: 0.42406345302728854]
	TIME [epoch: 24.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592062855294831		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3592062855294831 | validation: 0.42817900406516823]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267013204055792		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.3267013204055792 | validation: 0.453296976873273]
	TIME [epoch: 24.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34263506789243753		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.34263506789243753 | validation: 0.4658081644356387]
	TIME [epoch: 24.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33219568573880237		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.33219568573880237 | validation: 0.400443449397046]
	TIME [epoch: 24.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250127972430875		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.3250127972430875 | validation: 0.44259022349999]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224154509426834		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.3224154509426834 | validation: 0.46434501760104263]
	TIME [epoch: 24.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36361169398157395		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.36361169398157395 | validation: 0.429800582584451]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092874548264083		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.3092874548264083 | validation: 0.3832854759373314]
	TIME [epoch: 24.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304563093516562		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.304563093516562 | validation: 0.37064530840427506]
	TIME [epoch: 24.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115546086915947		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.3115546086915947 | validation: 0.41905844208847604]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36101904669326945		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.36101904669326945 | validation: 0.4391966150410833]
	TIME [epoch: 24.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34918204143872433		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.34918204143872433 | validation: 0.4984014495229383]
	TIME [epoch: 24.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661253523818324		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.3661253523818324 | validation: 0.4184713150175179]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225561845290445		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.3225561845290445 | validation: 0.3722926884876068]
	TIME [epoch: 24.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309310592464703		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.309310592464703 | validation: 0.40094395137833017]
	TIME [epoch: 24.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39553063982819375		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.39553063982819375 | validation: 0.4446323281422403]
	TIME [epoch: 24.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38383750884845946		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.38383750884845946 | validation: 0.4483543891212686]
	TIME [epoch: 24.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38409757171425146		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.38409757171425146 | validation: 0.4777800477531956]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4223400676050794		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.4223400676050794 | validation: 0.43774341967931096]
	TIME [epoch: 24.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3780719781392937		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.3780719781392937 | validation: 0.4054887707323765]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30809770534971864		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.30809770534971864 | validation: 0.39462138445480394]
	TIME [epoch: 24.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33856926718021096		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.33856926718021096 | validation: 0.4105947132439542]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648417927963026		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.3648417927963026 | validation: 0.4878076617329052]
	TIME [epoch: 24.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851549150033309		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3851549150033309 | validation: 0.40549999570658996]
	TIME [epoch: 24.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41602829521382634		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.41602829521382634 | validation: 0.4500227966689732]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3966373938623413		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.3966373938623413 | validation: 0.6645064031272804]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102093139612403		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.6102093139612403 | validation: 0.5371099891678276]
	TIME [epoch: 24.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793669374488325		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3793669374488325 | validation: 0.415394302614911]
	TIME [epoch: 24.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454406072708003		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.3454406072708003 | validation: 0.4197197664324201]
	TIME [epoch: 24.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321568033147372		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3321568033147372 | validation: 0.38227416415515725]
	TIME [epoch: 24.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383119317759795		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.3383119317759795 | validation: 0.4938070993089537]
	TIME [epoch: 24.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37605107446882186		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.37605107446882186 | validation: 0.4280961505722277]
	TIME [epoch: 24.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32386198573360475		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.32386198573360475 | validation: 0.38308098281882225]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966695821629798		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.2966695821629798 | validation: 0.38772352736148014]
	TIME [epoch: 24.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182059881088811		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3182059881088811 | validation: 0.4204934795489068]
	TIME [epoch: 24.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37613170054013356		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.37613170054013356 | validation: 0.4248277659731077]
	TIME [epoch: 24.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4593209858210881		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.4593209858210881 | validation: 0.5532445295821906]
	TIME [epoch: 24.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42523724013391695		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.42523724013391695 | validation: 0.4038240856106388]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556924632890768		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3556924632890768 | validation: 0.4299505097739993]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511956640591962		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.3511956640591962 | validation: 0.39245827843008685]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31818525480614646		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.31818525480614646 | validation: 0.38642036308765354]
	TIME [epoch: 24.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32114356359117213		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.32114356359117213 | validation: 0.40937280022133166]
	TIME [epoch: 24.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388117723320226		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3388117723320226 | validation: 0.4006419273793709]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3197809031406927		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3197809031406927 | validation: 0.423548888045866]
	TIME [epoch: 24.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515850979512068		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3515850979512068 | validation: 0.48230020165148013]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407801998187196		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.3407801998187196 | validation: 0.37409337085653965]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32751777786127617		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.32751777786127617 | validation: 0.3990086794068229]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147860015240701		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.3147860015240701 | validation: 0.3766748852075445]
	TIME [epoch: 24.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243930445961811		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3243930445961811 | validation: 0.37701462613385944]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34807699675977266		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.34807699675977266 | validation: 0.42307957495828574]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35694970133211557		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.35694970133211557 | validation: 0.41625632231301724]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718437370049714		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.3718437370049714 | validation: 0.42139976220045017]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32517963027914243		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.32517963027914243 | validation: 0.38622145813618985]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128676337429981		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.3128676337429981 | validation: 0.43615337366354084]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33472968455965996		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.33472968455965996 | validation: 0.3890886424276783]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32285420046498486		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.32285420046498486 | validation: 0.3850696985254386]
	TIME [epoch: 24.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196460225292658		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.3196460225292658 | validation: 0.36817484005771195]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1041.pth
	Model improved!!!
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959270704361589		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.2959270704361589 | validation: 0.35345276440692613]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438445787047122		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.3438445787047122 | validation: 0.4320379040296548]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811914009080667		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.3811914009080667 | validation: 0.38330581868437547]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269416917942894		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3269416917942894 | validation: 0.39962211303152473]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35279459404642993		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.35279459404642993 | validation: 0.4260834258116267]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333117815144126		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.333117815144126 | validation: 0.4397587634562353]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206240551195929		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.4206240551195929 | validation: 0.397066329128953]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35861945606619094		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.35861945606619094 | validation: 0.42373152875587794]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34556854562447725		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.34556854562447725 | validation: 0.39757040090256296]
	TIME [epoch: 24.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30776162966736104		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.30776162966736104 | validation: 0.4119547229335964]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32687379633801883		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.32687379633801883 | validation: 0.41596768893651886]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430182684923695		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.3430182684923695 | validation: 0.4350910431144618]
	TIME [epoch: 24.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319799734106354		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.319799734106354 | validation: 0.3668388138252841]
	TIME [epoch: 24.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299903909599159		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.299903909599159 | validation: 0.36933728818808675]
	TIME [epoch: 24.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983295307170733		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.2983295307170733 | validation: 0.36745253797545774]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32395524852085394		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.32395524852085394 | validation: 0.36349055975770483]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33204936347888825		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.33204936347888825 | validation: 0.45025249560280856]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35001630108299725		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.35001630108299725 | validation: 0.4148865845013265]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457882936647727		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.3457882936647727 | validation: 0.40797343291929195]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34128522452357973		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.34128522452357973 | validation: 0.37818133755260164]
	TIME [epoch: 24.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404309894877407		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3404309894877407 | validation: 0.41790626596334607]
	TIME [epoch: 24.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457977361512855		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3457977361512855 | validation: 0.4783134157881044]
	TIME [epoch: 24.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32964809588867755		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.32964809588867755 | validation: 0.3846012658998968]
	TIME [epoch: 24.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304245887529817		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.304245887529817 | validation: 0.3682823895569476]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29090245839950923		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.29090245839950923 | validation: 0.3612233288676243]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29462097206027876		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.29462097206027876 | validation: 0.3581218895099626]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135285686286867		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3135285686286867 | validation: 0.47278583899401855]
	TIME [epoch: 24.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41615111054161513		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.41615111054161513 | validation: 0.4484662218259169]
	TIME [epoch: 24.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33735961208235654		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.33735961208235654 | validation: 0.40024143960464925]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30743877838407563		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.30743877838407563 | validation: 0.3835867042331597]
	TIME [epoch: 24.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972834848539523		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.2972834848539523 | validation: 0.360761265379266]
	TIME [epoch: 24.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30004432984148405		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.30004432984148405 | validation: 0.40319407254837253]
	TIME [epoch: 24.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299086020984071		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3299086020984071 | validation: 0.4289414974412382]
	TIME [epoch: 24.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35223079416000924		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.35223079416000924 | validation: 0.3888898877176071]
	TIME [epoch: 24.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31363467742455414		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.31363467742455414 | validation: 0.3628468985041233]
	TIME [epoch: 24.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016341357117208		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.3016341357117208 | validation: 0.36033539405922993]
	TIME [epoch: 24.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960972762289476		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.2960972762289476 | validation: 0.3819821643313327]
	TIME [epoch: 24.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30370956822012746		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.30370956822012746 | validation: 0.3795864849880398]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30064415352097223		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.30064415352097223 | validation: 0.3559228231691013]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055393589229754		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3055393589229754 | validation: 0.3942283055944495]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33993049558469624		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.33993049558469624 | validation: 0.3536652470590832]
	TIME [epoch: 24.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950573499566272		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.2950573499566272 | validation: 0.450485287450641]
	TIME [epoch: 24.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744089824800901		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.3744089824800901 | validation: 0.5553701432379805]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40134916991336034		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.40134916991336034 | validation: 0.42484209350279983]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31302220340550796		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.31302220340550796 | validation: 0.41067402481589654]
	TIME [epoch: 24.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30559541646837063		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.30559541646837063 | validation: 0.41672505056260634]
	TIME [epoch: 24.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139261547037594		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.3139261547037594 | validation: 0.42027466405153746]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353436864454708		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.3353436864454708 | validation: 0.38639554699977824]
	TIME [epoch: 24.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34480953050666246		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.34480953050666246 | validation: 0.4534076779745286]
	TIME [epoch: 24.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3857866885519993		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.3857866885519993 | validation: 0.46696605518156037]
	TIME [epoch: 24.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869955930989837		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.3869955930989837 | validation: 0.45452126369629475]
	TIME [epoch: 24.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523908660046161		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3523908660046161 | validation: 0.3681256064439235]
	TIME [epoch: 24.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856493558399178		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.2856493558399178 | validation: 0.38184673521395807]
	TIME [epoch: 24.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31918234158260606		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.31918234158260606 | validation: 0.3601939208488127]
	TIME [epoch: 24.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306185884243013		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.306185884243013 | validation: 0.36583542843730604]
	TIME [epoch: 24.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30633163351875503		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.30633163351875503 | validation: 0.4103543672096585]
	TIME [epoch: 24.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374051885203918		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.3374051885203918 | validation: 0.38069979296038425]
	TIME [epoch: 24.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28855681557538826		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.28855681557538826 | validation: 0.3463620021574754]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1099.pth
	Model improved!!!
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28783080977403874		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.28783080977403874 | validation: 0.35425770496487174]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28974934629548077		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.28974934629548077 | validation: 0.3664512225765892]
	TIME [epoch: 24.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28957803189305215		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.28957803189305215 | validation: 0.356459373110777]
	TIME [epoch: 24.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29755679080817393		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.29755679080817393 | validation: 0.41579933937597235]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166442705931361		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3166442705931361 | validation: 0.36228897404930144]
	TIME [epoch: 24.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800343318593914		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.2800343318593914 | validation: 0.3571232201344377]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136632066886106		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.3136632066886106 | validation: 0.44531463543282784]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800654686267902		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.3800654686267902 | validation: 0.4035756899202505]
	TIME [epoch: 24.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31845825661564275		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.31845825661564275 | validation: 0.36478956468457524]
	TIME [epoch: 24.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028325458973098		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.3028325458973098 | validation: 0.3683530604465763]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31459755410697765		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.31459755410697765 | validation: 0.3645367544960007]
	TIME [epoch: 24.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923086030646598		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.2923086030646598 | validation: 0.3778670268539961]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27581089841888307		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.27581089841888307 | validation: 0.35485018158347814]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29310344861375826		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.29310344861375826 | validation: 0.35833205058765827]
	TIME [epoch: 24.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27824747108004483		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.27824747108004483 | validation: 0.3488275878966288]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847099597916181		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2847099597916181 | validation: 0.3958465727129959]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3298965657320237		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3298965657320237 | validation: 0.3695139720099331]
	TIME [epoch: 24.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28854401875962377		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.28854401875962377 | validation: 0.3901948484644738]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33010469993256686		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.33010469993256686 | validation: 0.4062550863085188]
	TIME [epoch: 24.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31606262470088814		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.31606262470088814 | validation: 0.35894951828913507]
	TIME [epoch: 24.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898203945274888		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2898203945274888 | validation: 0.36891328529218675]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823023094053103		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2823023094053103 | validation: 0.3516758958070195]
	TIME [epoch: 24.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29203282418537935		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.29203282418537935 | validation: 0.40801292332022276]
	TIME [epoch: 24.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230812676130816		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.3230812676130816 | validation: 0.3998927844673635]
	TIME [epoch: 24.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31405338655437554		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.31405338655437554 | validation: 0.44672126181641986]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31284229224584437		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.31284229224584437 | validation: 0.38055045492643025]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3208339229189981		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.3208339229189981 | validation: 0.38194967870137464]
	TIME [epoch: 24.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28957839875907404		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.28957839875907404 | validation: 0.3565639783573326]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802966650242029		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2802966650242029 | validation: 0.38214771330515773]
	TIME [epoch: 24.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29446980348627727		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.29446980348627727 | validation: 0.38901508251373396]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31912844290882203		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.31912844290882203 | validation: 0.44042454886518545]
	TIME [epoch: 24.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31928375638802764		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.31928375638802764 | validation: 0.35219349494872965]
	TIME [epoch: 24.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386438206403465		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3386438206403465 | validation: 0.4121027409693363]
	TIME [epoch: 24.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369218299025135		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.3369218299025135 | validation: 0.3528925234545268]
	TIME [epoch: 24.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973989130844644		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2973989130844644 | validation: 0.37497457088140673]
	TIME [epoch: 24.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204552152992265		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3204552152992265 | validation: 0.36394163413076913]
	TIME [epoch: 24.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029465520131366		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3029465520131366 | validation: 0.45925564797660423]
	TIME [epoch: 24.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108742756212602		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.3108742756212602 | validation: 0.3605305969797404]
	TIME [epoch: 24.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30223748122956173		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.30223748122956173 | validation: 0.43590328668977846]
	TIME [epoch: 24.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30819574867409294		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.30819574867409294 | validation: 0.35854861176709113]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28254307574481674		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.28254307574481674 | validation: 0.36522128838225015]
	TIME [epoch: 24.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29356876456148895		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.29356876456148895 | validation: 0.3537725677487809]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891222899011649		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.2891222899011649 | validation: 0.38893517552932394]
	TIME [epoch: 24.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453447847200237		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3453447847200237 | validation: 0.4132799823967636]
	TIME [epoch: 24.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436185645754722		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3436185645754722 | validation: 0.37986658001750756]
	TIME [epoch: 24.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31088632110696457		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.31088632110696457 | validation: 0.3565015488363544]
	TIME [epoch: 24.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316438763713666		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.316438763713666 | validation: 0.3676164304449685]
	TIME [epoch: 24.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828591642267686		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.2828591642267686 | validation: 0.35423307697208034]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27989690250410937		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.27989690250410937 | validation: 0.37545514768696275]
	TIME [epoch: 24.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28971422891140763		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.28971422891140763 | validation: 0.3611060455058631]
	TIME [epoch: 24.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881958220934216		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.2881958220934216 | validation: 0.36040943199331393]
	TIME [epoch: 24.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052574309499827		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.3052574309499827 | validation: 0.3834981428966551]
	TIME [epoch: 24.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960127954770138		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2960127954770138 | validation: 0.37059938508382045]
	TIME [epoch: 24.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30598327690497773		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.30598327690497773 | validation: 0.4243450660917813]
	TIME [epoch: 24.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056299337568326		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3056299337568326 | validation: 0.3740472725371855]
	TIME [epoch: 24.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966690851044351		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2966690851044351 | validation: 0.3636059699681723]
	TIME [epoch: 24.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27912597847046955		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.27912597847046955 | validation: 0.36975931544080765]
	TIME [epoch: 24.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30695273712003673		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.30695273712003673 | validation: 0.46495358612940524]
	TIME [epoch: 24.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316662947739506		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.3316662947739506 | validation: 0.39934925466012594]
	TIME [epoch: 24.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949489617196303		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.2949489617196303 | validation: 0.37182896659898795]
	TIME [epoch: 24.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28011839207917444		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.28011839207917444 | validation: 0.3561172152786229]
	TIME [epoch: 24.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110555039975363		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.3110555039975363 | validation: 0.40189768310757584]
	TIME [epoch: 24.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33486562240188633		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.33486562240188633 | validation: 0.41774918169441677]
	TIME [epoch: 24.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957423624531493		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.2957423624531493 | validation: 0.35333321119136246]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875354705007972		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.2875354705007972 | validation: 0.3847977368545058]
	TIME [epoch: 24.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31417408553881127		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.31417408553881127 | validation: 0.40952897922769216]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32290088994414085		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.32290088994414085 | validation: 0.39665747919383193]
	TIME [epoch: 24.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857786469532157		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.2857786469532157 | validation: 0.3892367475837878]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300956429960387		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.300956429960387 | validation: 0.391670739970437]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143871090443887		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3143871090443887 | validation: 0.402315860312446]
	TIME [epoch: 24.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29834700244486995		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.29834700244486995 | validation: 0.3585853127390945]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27621209635770716		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.27621209635770716 | validation: 0.34568915273288964]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1171.pth
	Model improved!!!
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28197110667238395		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.28197110667238395 | validation: 0.351156397093415]
	TIME [epoch: 24.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790760733950547		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.2790760733950547 | validation: 0.38744843054080863]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32968123449617137		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.32968123449617137 | validation: 0.3929530787803462]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953254204892787		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.2953254204892787 | validation: 0.36908544350143346]
	TIME [epoch: 24.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832053308753945		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.2832053308753945 | validation: 0.3600803043304293]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28638348782412687		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.28638348782412687 | validation: 0.35577687540052366]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28254464129924667		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.28254464129924667 | validation: 0.3702038972474579]
	TIME [epoch: 24.8 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886082135780952		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.2886082135780952 | validation: 0.3960192021185852]
	TIME [epoch: 24.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33069160209035076		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.33069160209035076 | validation: 0.35465719819361113]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785545831270409		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.2785545831270409 | validation: 0.3454338376571687]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27157843646645863		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.27157843646645863 | validation: 0.34928287949116127]
	TIME [epoch: 24.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686595052511157		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.2686595052511157 | validation: 0.3371808518369911]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1183.pth
	Model improved!!!
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27101777356266693		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.27101777356266693 | validation: 0.350955324198995]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27003431632476776		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.27003431632476776 | validation: 0.33905179232061095]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842001509374582		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.2842001509374582 | validation: 0.3510592292656343]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27381128443035263		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.27381128443035263 | validation: 0.34147790712630227]
	TIME [epoch: 24.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689907766689812		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.2689907766689812 | validation: 0.3376133329820844]
	TIME [epoch: 24.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27002353110694033		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.27002353110694033 | validation: 0.347817167314976]
	TIME [epoch: 24.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799389111149594		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.2799389111149594 | validation: 0.3557146809565028]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883425441257941		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.2883425441257941 | validation: 0.3965989082644083]
	TIME [epoch: 24.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32506679412372075		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.32506679412372075 | validation: 0.354398053400308]
	TIME [epoch: 24.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2717230948708064		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.2717230948708064 | validation: 0.33834164725897153]
	TIME [epoch: 24.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27976546538987923		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.27976546538987923 | validation: 0.38520730182031854]
	TIME [epoch: 24.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29441473224950565		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.29441473224950565 | validation: 0.36161009026974017]
	TIME [epoch: 24.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792144472257777		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.2792144472257777 | validation: 0.35290937976900183]
	TIME [epoch: 24.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752116893619456		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2752116893619456 | validation: 0.34991494499175246]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28157602372781043		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.28157602372781043 | validation: 0.34251861962518093]
	TIME [epoch: 24.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29330452560495257		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.29330452560495257 | validation: 0.34017968561678463]
	TIME [epoch: 24.8 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29019736992032197		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.29019736992032197 | validation: 0.37703076479693776]
	TIME [epoch: 24.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228841658513003		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.3228841658513003 | validation: 0.3690723644094032]
	TIME [epoch: 24.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29608408996363966		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.29608408996363966 | validation: 0.3593751785884572]
	TIME [epoch: 24.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823940477466458		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.2823940477466458 | validation: 0.3398672929260595]
	TIME [epoch: 24.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705743943313787		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.2705743943313787 | validation: 0.3489931944872609]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28201633676443505		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.28201633676443505 | validation: 0.3480637652211391]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827599085202136		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.2827599085202136 | validation: 0.34235271497027553]
	TIME [epoch: 24.8 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27640008566675245		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.27640008566675245 | validation: 0.3451049039801829]
	TIME [epoch: 24.8 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27795743313197596		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.27795743313197596 | validation: 0.34196845913963464]
	TIME [epoch: 24.8 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31109952751977477		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.31109952751977477 | validation: 0.3330963048947397]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278712744000974		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.278712744000974 | validation: 0.3477799102936192]
	TIME [epoch: 24.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34271633805323354		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.34271633805323354 | validation: 0.37714750922523854]
	TIME [epoch: 24.8 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985148798250204		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.2985148798250204 | validation: 0.34522826163655185]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952416936682688		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.2952416936682688 | validation: 0.33997536180332605]
	TIME [epoch: 24.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27883787515144687		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.27883787515144687 | validation: 0.345177978619941]
	TIME [epoch: 24.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26889930590885336		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.26889930590885336 | validation: 0.3419663613150363]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878501354531478		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.2878501354531478 | validation: 0.39100039776744183]
	TIME [epoch: 24.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28690004589200857		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.28690004589200857 | validation: 0.35418581451263587]
	TIME [epoch: 24.8 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28107794774797173		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.28107794774797173 | validation: 0.3447114608124352]
	TIME [epoch: 24.8 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867494879714262		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.2867494879714262 | validation: 0.35725402638326587]
	TIME [epoch: 24.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29975198176390994		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.29975198176390994 | validation: 0.34866209511137486]
	TIME [epoch: 24.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829364791525289		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.2829364791525289 | validation: 0.3379523013440281]
	TIME [epoch: 24.8 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832661754709043		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.2832661754709043 | validation: 0.3236753759192375]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1222.pth
	Model improved!!!
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877337911749763		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.2877337911749763 | validation: 0.35969132867512643]
	TIME [epoch: 24.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845206874840217		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.2845206874840217 | validation: 0.36095057938241115]
	TIME [epoch: 24.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931746821921001		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.2931746821921001 | validation: 0.35164001070312395]
	TIME [epoch: 24.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27731648457371677		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.27731648457371677 | validation: 0.33252367376432573]
	TIME [epoch: 24.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957014912303587		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.2957014912303587 | validation: 0.3422560035000019]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751215065158257		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.2751215065158257 | validation: 0.3443896416321775]
	TIME [epoch: 24.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696762191168938		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.2696762191168938 | validation: 0.35045638946957297]
	TIME [epoch: 24.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27653922647227636		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.27653922647227636 | validation: 0.34374745881918123]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28255115520787916		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.28255115520787916 | validation: 0.37938854718315557]
	TIME [epoch: 24.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882690993139836		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.2882690993139836 | validation: 0.35678506564454154]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30218570328161126		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.30218570328161126 | validation: 0.40046110491959624]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302789905978365		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.3302789905978365 | validation: 0.3762352228244938]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3111743937389869		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.3111743937389869 | validation: 0.3628246344887127]
	TIME [epoch: 24.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29330518769339076		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.29330518769339076 | validation: 0.3419154282729099]
	TIME [epoch: 24.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29329768454642635		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.29329768454642635 | validation: 0.37428975917457474]
	TIME [epoch: 24.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35178552554747483		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.35178552554747483 | validation: 0.37658709216584496]
	TIME [epoch: 24.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324476062330111		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.3324476062330111 | validation: 0.3430112398146423]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075872811697469		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.3075872811697469 | validation: 0.35147165938903785]
	TIME [epoch: 24.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30583762912335277		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.30583762912335277 | validation: 0.36400103243786797]
	TIME [epoch: 24.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29588726906399637		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.29588726906399637 | validation: 0.3544840260201679]
	TIME [epoch: 24.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316151291879156		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.316151291879156 | validation: 0.3732626842985596]
	TIME [epoch: 24.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30349975043747884		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.30349975043747884 | validation: 0.38067504431655297]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983992381587217		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.2983992381587217 | validation: 0.3347968903914108]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734899445100032		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.2734899445100032 | validation: 0.3210842046101031]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1246.pth
	Model improved!!!
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701657602898786		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.2701657602898786 | validation: 0.3601206607472957]
	TIME [epoch: 24.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30493802923809893		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.30493802923809893 | validation: 0.32475799987548726]
	TIME [epoch: 24.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26995297751659364		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.26995297751659364 | validation: 0.33668789575867836]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835092393882478		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.2835092393882478 | validation: 0.3654572311125915]
	TIME [epoch: 24.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28659271807268966		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.28659271807268966 | validation: 0.32370980069404576]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655599969711859		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.2655599969711859 | validation: 0.3312827056316611]
	TIME [epoch: 24.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28279409732058297		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.28279409732058297 | validation: 0.34297778062686846]
	TIME [epoch: 24.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27897984393231556		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.27897984393231556 | validation: 0.3372054370936117]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949707268508587		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.2949707268508587 | validation: 0.32551708589246203]
	TIME [epoch: 24.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27323956925861775		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.27323956925861775 | validation: 0.3393558474893028]
	TIME [epoch: 24.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27462721500880816		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.27462721500880816 | validation: 0.33066460428145455]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274103405554534		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.274103405554534 | validation: 0.3244997718633988]
	TIME [epoch: 24.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26872920659518207		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.26872920659518207 | validation: 0.3338504393768186]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739907533571726		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.2739907533571726 | validation: 0.3286691867055125]
	TIME [epoch: 24.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723212644335202		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.2723212644335202 | validation: 0.3299848148366254]
	TIME [epoch: 24.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27168836975165855		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.27168836975165855 | validation: 0.33731117830242097]
	TIME [epoch: 24.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860203961185955		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.2860203961185955 | validation: 0.347684299753206]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270530761145708		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.270530761145708 | validation: 0.36094846523134033]
	TIME [epoch: 24.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968662969499908		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.2968662969499908 | validation: 0.36771006643266513]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199742868574404		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.3199742868574404 | validation: 0.3485239549911657]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950461024375259		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.2950461024375259 | validation: 0.32758922559206916]
	TIME [epoch: 24.8 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829346669800719		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.2829346669800719 | validation: 0.3257387686083867]
	TIME [epoch: 24.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852093909109929		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.2852093909109929 | validation: 0.34491916776033604]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040563894265137		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.3040563894265137 | validation: 0.3446104664008274]
	TIME [epoch: 24.8 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304084462265504		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.304084462265504 | validation: 0.33811345949451105]
	TIME [epoch: 24.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28687369517677375		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.28687369517677375 | validation: 0.3172130157326234]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240310_003029/states/model_tr_study5_1272.pth
	Model improved!!!
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26631850424249803		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.26631850424249803 | validation: 0.33797333981449157]
	TIME [epoch: 24.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28929426552139875		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.28929426552139875 | validation: 0.3814003617017053]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023601947325239		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.3023601947325239 | validation: 0.36908670960462175]
	TIME [epoch: 24.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878278156992365		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2878278156992365 | validation: 0.3353815678844562]
	TIME [epoch: 24.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631614141240917		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.2631614141240917 | validation: 0.32203618272350143]
	TIME [epoch: 24.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741454728615926		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.2741454728615926 | validation: 0.3235158022460013]
	TIME [epoch: 24.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758488463959181		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.2758488463959181 | validation: 0.3187095668701251]
	TIME [epoch: 24.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686477642796484		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.2686477642796484 | validation: 0.3392590555627232]
	TIME [epoch: 24.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27049944649091734		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.27049944649091734 | validation: 0.35188184553513124]
	TIME [epoch: 24.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740261887811273		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.2740261887811273 | validation: 0.3646443543251607]
	TIME [epoch: 24.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885757676381498		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.2885757676381498 | validation: 0.3862788798135726]
	TIME [epoch: 24.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29116976516243404		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.29116976516243404 | validation: 0.3747628456773353]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696635711524924		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.2696635711524924 | validation: 0.3348154910519318]
	TIME [epoch: 24.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26044076069783334		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.26044076069783334 | validation: 0.3281107420657159]
	TIME [epoch: 24.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27613248811393604		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.27613248811393604 | validation: 0.38936254370309636]
	TIME [epoch: 24.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29753171483170215		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.29753171483170215 | validation: 0.3509458459984649]
	TIME [epoch: 24.8 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768874384598449		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.2768874384598449 | validation: 0.35548092878973664]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29366292995567905		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.29366292995567905 | validation: 0.36892883082811667]
	TIME [epoch: 24.8 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773302075251457		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.2773302075251457 | validation: 0.349268914161051]
	TIME [epoch: 24.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034143327429289		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.3034143327429289 | validation: 0.3969842288813476]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130539865322255		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.3130539865322255 | validation: 0.3972450756145959]
	TIME [epoch: 24.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31526661162705266		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.31526661162705266 | validation: 0.41575535507454503]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584607676916705		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.3584607676916705 | validation: 0.4777096896832799]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39345510174767856		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.39345510174767856 | validation: 0.4564170132912183]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34044858348515517		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.34044858348515517 | validation: 0.39857558128556286]
	TIME [epoch: 24.8 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29751945529137824		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.29751945529137824 | validation: 0.3531036579117931]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27694859845451514		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.27694859845451514 | validation: 0.3795608449290412]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28776971256740497		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.28776971256740497 | validation: 0.4071559436774143]
	TIME [epoch: 24.8 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35333710758390396		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.35333710758390396 | validation: 0.47291963478226107]
	TIME [epoch: 24.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560436410253133		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.3560436410253133 | validation: 0.4401220587843659]
	TIME [epoch: 24.8 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.314704885909021		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.314704885909021 | validation: 0.39645727581586643]
	TIME [epoch: 24.8 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29627163788389066		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.29627163788389066 | validation: 0.3858640827412529]
	TIME [epoch: 24.8 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967058331198763		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.2967058331198763 | validation: 0.37857813729967865]
	TIME [epoch: 24.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28482480858577625		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.28482480858577625 | validation: 0.35157670847641315]
	TIME [epoch: 24.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26686596840565524		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.26686596840565524 | validation: 0.33462861508519326]
	TIME [epoch: 24.8 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27151800758259353		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.27151800758259353 | validation: 0.34339796860734345]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27013696621643213		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.27013696621643213 | validation: 0.3422303784916592]
	TIME [epoch: 24.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26691844716913915		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.26691844716913915 | validation: 0.3402855946799882]
	TIME [epoch: 24.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665950551418359		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.2665950551418359 | validation: 0.3479934252063721]
	TIME [epoch: 24.8 sec]
EPOCH 1312/2000:
	Training over batches...
