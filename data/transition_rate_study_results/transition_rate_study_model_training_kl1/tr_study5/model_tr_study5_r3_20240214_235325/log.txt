Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3047795554

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 11.024488339653013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.024488339653013 | validation: 10.936333490692537]
	TIME [epoch: 49.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 10.38240749074543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.38240749074543 | validation: 10.0210229110377]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 9.042299632158393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.042299632158393 | validation: 9.751501630525889]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 9.606939710606081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.606939710606081 | validation: 8.871695617061311]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 8.702666890815069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.702666890815069 | validation: 8.972160486510207]
	TIME [epoch: 10.3 sec]
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 8.828636075078546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.828636075078546 | validation: 8.47430364334682]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 8.291108202900912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.291108202900912 | validation: 8.12777441373663]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 7.8437270729407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8437270729407 | validation: 8.102281315987245]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 7.68232263913489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.68232263913489 | validation: 7.957407801844746]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 7.73039020115076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.73039020115076 | validation: 8.242537820537276]
	TIME [epoch: 10.4 sec]
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 7.899797599761811		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 7.899797599761811 | validation: 8.32361782841421]
	TIME [epoch: 10.3 sec]
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 7.223429190772945		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 7.223429190772945 | validation: 8.210419492195433]
	TIME [epoch: 10.3 sec]
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 7.300217740032835		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 7.300217740032835 | validation: 7.459348622904121]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 7.391015831440187		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 7.391015831440187 | validation: 7.826938408276947]
	TIME [epoch: 10.3 sec]
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 7.244518882442327		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 7.244518882442327 | validation: 7.776004132296565]
	TIME [epoch: 10.3 sec]
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 7.028500998086463		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 7.028500998086463 | validation: 7.44181820607635]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 6.668681882987097		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 6.668681882987097 | validation: 7.37770768227358]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 6.65924999882842		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 6.65924999882842 | validation: 7.215186591354977]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 6.936967194539697		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 6.936967194539697 | validation: 7.268899078011508]
	TIME [epoch: 10.3 sec]
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 6.974041076643374		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 6.974041076643374 | validation: 7.7233250640776445]
	TIME [epoch: 10.3 sec]
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 9.952639204378537		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 9.952639204378537 | validation: 11.228751618683306]
	TIME [epoch: 10.3 sec]
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 8.071343137409023		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 8.071343137409023 | validation: 7.188629308834927]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 6.6773334580171895		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 6.6773334580171895 | validation: 6.875403712498262]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 6.372872686597676		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 6.372872686597676 | validation: 7.559076131895256]
	TIME [epoch: 10.3 sec]
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 6.545260862776702		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 6.545260862776702 | validation: 6.507365648734359]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 6.260063377962489		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 6.260063377962489 | validation: 6.4582074569196735]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 6.180897911518212		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 6.180897911518212 | validation: 6.375627038418943]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 6.050854098609145		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 6.050854098609145 | validation: 7.1467533919478665]
	TIME [epoch: 10.3 sec]
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 6.1392033484785955		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 6.1392033484785955 | validation: 6.044009715769051]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 6.060639532466927		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 6.060639532466927 | validation: 6.121493595960981]
	TIME [epoch: 10.3 sec]
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 6.038614140736706		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 6.038614140736706 | validation: 6.3503641099563914]
	TIME [epoch: 10.4 sec]
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 6.602601459799521		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 6.602601459799521 | validation: 6.926066233221189]
	TIME [epoch: 10.3 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 6.3074932658757765		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 6.3074932658757765 | validation: 6.3781932261736]
	TIME [epoch: 10.3 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 6.069126522865581		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 6.069126522865581 | validation: 5.970846296560238]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 6.037415997071647		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 6.037415997071647 | validation: 5.950057669345243]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 6.038821618508049		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 6.038821618508049 | validation: 5.8635333761239945]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 6.169841670009091		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 6.169841670009091 | validation: 6.253395755827196]
	TIME [epoch: 10.4 sec]
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 6.2038681149413275		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 6.2038681149413275 | validation: 5.871378693428603]
	TIME [epoch: 10.3 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 6.18289879718272		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 6.18289879718272 | validation: 6.540546638484044]
	TIME [epoch: 10.3 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 6.107736017052529		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 6.107736017052529 | validation: 6.173435793081165]
	TIME [epoch: 10.3 sec]
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 6.114951486536831		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 6.114951486536831 | validation: 6.0861879305335655]
	TIME [epoch: 10.3 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 5.977956820467801		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 5.977956820467801 | validation: 5.719017705536788]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 5.8841359013488495		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 5.8841359013488495 | validation: 5.896083037992617]
	TIME [epoch: 10.3 sec]
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 6.010946264753855		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 6.010946264753855 | validation: 5.7724000499139265]
	TIME [epoch: 10.3 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 5.8579645961313584		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 5.8579645961313584 | validation: 5.941348783393596]
	TIME [epoch: 10.4 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 6.3038326515408025		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 6.3038326515408025 | validation: 8.36131633995921]
	TIME [epoch: 10.3 sec]
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 6.822369069423615		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 6.822369069423615 | validation: 5.790630679908547]
	TIME [epoch: 10.3 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 5.889176227528952		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 5.889176227528952 | validation: 5.711305448110275]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 6.09363605211225		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 6.09363605211225 | validation: 5.922669822203786]
	TIME [epoch: 10.3 sec]
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 6.014085933368394		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 6.014085933368394 | validation: 6.158218584207972]
	TIME [epoch: 10.4 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 5.966444299218721		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 5.966444299218721 | validation: 6.076761747980855]
	TIME [epoch: 10.3 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 5.866328140536957		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 5.866328140536957 | validation: 5.841355067127173]
	TIME [epoch: 10.3 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 5.810014850934259		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 5.810014850934259 | validation: 5.67701415979777]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 5.674338013210013		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 5.674338013210013 | validation: 5.606559977274507]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 6.2011113414347365		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 6.2011113414347365 | validation: 7.39911580154498]
	TIME [epoch: 10.4 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 6.466742770808336		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 6.466742770808336 | validation: 5.894551726256127]
	TIME [epoch: 10.3 sec]
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 5.809155339215304		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 5.809155339215304 | validation: 5.7071565978254934]
	TIME [epoch: 10.4 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 5.74470342489883		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 5.74470342489883 | validation: 5.702030447961049]
	TIME [epoch: 10.3 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 5.684457370367298		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 5.684457370367298 | validation: 5.6961408497728545]
	TIME [epoch: 10.4 sec]
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 5.669102174018997		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 5.669102174018997 | validation: 5.751126531278285]
	TIME [epoch: 10.4 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 5.833537066754332		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 5.833537066754332 | validation: 5.832588167317465]
	TIME [epoch: 10.4 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 5.890845651667374		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 5.890845651667374 | validation: 6.303625151570534]
	TIME [epoch: 10.4 sec]
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 6.386508309889263		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 6.386508309889263 | validation: 5.82643442232313]
	TIME [epoch: 10.4 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 6.037886476854606		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 6.037886476854606 | validation: 6.160337894671795]
	TIME [epoch: 10.4 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 6.179949959552054		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 6.179949959552054 | validation: 6.321718737097747]
	TIME [epoch: 10.4 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 6.7610167907441605		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 6.7610167907441605 | validation: 7.248511052237118]
	TIME [epoch: 10.4 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 7.168782569279935		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 7.168782569279935 | validation: 6.252678546496656]
	TIME [epoch: 10.3 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9140722376104335		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 5.9140722376104335 | validation: 5.808931381706905]
	TIME [epoch: 10.3 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 5.738065311562673		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 5.738065311562673 | validation: 5.603802388726404]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 5.674026350996493		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 5.674026350996493 | validation: 5.652443245122752]
	TIME [epoch: 10.3 sec]
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 5.56399872280012		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 5.56399872280012 | validation: 5.159585860451833]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 5.519906359847207		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 5.519906359847207 | validation: 6.037941369300141]
	TIME [epoch: 10.3 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 5.926736014162553		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 5.926736014162553 | validation: 5.99285394596965]
	TIME [epoch: 10.3 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 6.781381398602096		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 6.781381398602096 | validation: 6.02612707934916]
	TIME [epoch: 10.4 sec]
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 5.575558927810436		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 5.575558927810436 | validation: 5.364560585339292]
	TIME [epoch: 10.4 sec]
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 5.925631076014033		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 5.925631076014033 | validation: 5.745141917566996]
	TIME [epoch: 10.4 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 6.584572762750895		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 6.584572762750895 | validation: 6.367187658954217]
	TIME [epoch: 10.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 5.846993796979424		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 5.846993796979424 | validation: 5.589402291516939]
	TIME [epoch: 10.4 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 5.468514183605249		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 5.468514183605249 | validation: 5.519646274986748]
	TIME [epoch: 10.4 sec]
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 5.395190125464002		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 5.395190125464002 | validation: 5.228308961376053]
	TIME [epoch: 10.4 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 5.204551852217383		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 5.204551852217383 | validation: 4.881235667375189]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 5.29084421348525		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 5.29084421348525 | validation: 5.8113120866227055]
	TIME [epoch: 10.3 sec]
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 5.282374463170084		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 5.282374463170084 | validation: 5.357471336327251]
	TIME [epoch: 10.3 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 5.976341045953835		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 5.976341045953835 | validation: 6.68269747846893]
	TIME [epoch: 10.3 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 6.977903301490111		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 6.977903301490111 | validation: 7.000578998229121]
	TIME [epoch: 10.3 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9782401433618455		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 5.9782401433618455 | validation: 5.05811995387053]
	TIME [epoch: 10.3 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 4.983028691761012		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 4.983028691761012 | validation: 4.90515917688315]
	TIME [epoch: 10.3 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 4.903579321892307		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 4.903579321892307 | validation: 4.809854297778809]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 5.83915891356539		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 5.83915891356539 | validation: 7.419175969062273]
	TIME [epoch: 10.4 sec]
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 6.71991275086243		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 6.71991275086243 | validation: 5.458300494278224]
	TIME [epoch: 10.4 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 5.468027658814212		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 5.468027658814212 | validation: 5.380181222048101]
	TIME [epoch: 10.4 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 5.2878393947494295		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 5.2878393947494295 | validation: 5.3889640604018485]
	TIME [epoch: 10.4 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 5.332897689476532		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 5.332897689476532 | validation: 5.0516760017323]
	TIME [epoch: 10.4 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 5.04439075999278		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 5.04439075999278 | validation: 5.0759450092487075]
	TIME [epoch: 10.4 sec]
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 5.183608639482372		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 5.183608639482372 | validation: 5.2025754407484035]
	TIME [epoch: 10.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 5.4360765423467985		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 5.4360765423467985 | validation: 5.136663681193109]
	TIME [epoch: 10.4 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 5.093008289198809		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 5.093008289198809 | validation: 5.039663687528578]
	TIME [epoch: 10.4 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 4.983503008401074		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 4.983503008401074 | validation: 4.98298025236047]
	TIME [epoch: 10.4 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 5.525687425533145		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 5.525687425533145 | validation: 5.830032323127448]
	TIME [epoch: 10.4 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 5.236155731292536		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 5.236155731292536 | validation: 5.071384620002951]
	TIME [epoch: 10.4 sec]
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 4.873920461043054		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 4.873920461043054 | validation: 4.778519652234962]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 4.861609149425876		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 4.861609149425876 | validation: 5.2526441297497195]
	TIME [epoch: 10.4 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 4.964532269030734		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 4.964532269030734 | validation: 4.997022735607003]
	TIME [epoch: 10.4 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 4.968022241089157		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 4.968022241089157 | validation: 5.830385510183821]
	TIME [epoch: 10.4 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 6.307045182158771		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 6.307045182158771 | validation: 6.195066677273083]
	TIME [epoch: 10.4 sec]
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 5.35416340048435		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 5.35416340048435 | validation: 4.802390740364743]
	TIME [epoch: 10.5 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 4.904366886601233		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 4.904366886601233 | validation: 4.763448926794856]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 4.81567968076232		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 4.81567968076232 | validation: 4.715596074550368]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 4.774481673214017		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 4.774481673214017 | validation: 4.664635363586711]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 4.621415389831875		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 4.621415389831875 | validation: 4.280181980893758]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 4.502699919738893		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 4.502699919738893 | validation: 5.960719540747404]
	TIME [epoch: 10.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 6.161941504029531		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 6.161941504029531 | validation: 6.47957690552038]
	TIME [epoch: 10.3 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 5.780341239777529		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 5.780341239777529 | validation: 5.878994040984387]
	TIME [epoch: 10.3 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 6.056806347399723		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 6.056806347399723 | validation: 6.953645209375461]
	TIME [epoch: 10.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 6.394240430647273		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 6.394240430647273 | validation: 5.849028137065374]
	TIME [epoch: 10.3 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 5.888881909121631		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 5.888881909121631 | validation: 6.321505084148278]
	TIME [epoch: 10.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 6.332557245959376		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 6.332557245959376 | validation: 5.903446446993623]
	TIME [epoch: 10.3 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 5.277278168085145		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 5.277278168085145 | validation: 4.622770347426279]
	TIME [epoch: 10.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 4.755867670747528		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 4.755867670747528 | validation: 4.612451615486371]
	TIME [epoch: 10.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 4.411690786997862		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 4.411690786997862 | validation: 4.100687779427579]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_120.pth
	Model improved!!!
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 4.244321731712841		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 4.244321731712841 | validation: 4.895656552502477]
	TIME [epoch: 10.3 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 4.163079474869209		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 4.163079474869209 | validation: 3.777811136943062]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 4.0142492641627925		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 4.0142492641627925 | validation: 4.759573111858872]
	TIME [epoch: 10.3 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 4.07458781915142		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 4.07458781915142 | validation: 3.541834646349172]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 3.657668845964237		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 3.657668845964237 | validation: 4.455439757782298]
	TIME [epoch: 10.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 3.774143855036461		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 3.774143855036461 | validation: 3.6868938459922402]
	TIME [epoch: 10.3 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 4.365344521960867		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 4.365344521960867 | validation: 3.5400245320568287]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 3.38738056499096		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 3.38738056499096 | validation: 3.2084055538802807]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_128.pth
	Model improved!!!
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 3.151745788907791		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 3.151745788907791 | validation: 3.224454169370613]
	TIME [epoch: 10.4 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4960376997798503		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 3.4960376997798503 | validation: 2.964762443646837]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9424986660817867		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 2.9424986660817867 | validation: 2.861919040008223]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 3.135808718182294		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 3.135808718182294 | validation: 3.636303178178944]
	TIME [epoch: 10.3 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 4.558455257813462		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 4.558455257813462 | validation: 2.8105558906026737]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_133.pth
	Model improved!!!
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8513799618867046		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 2.8513799618867046 | validation: 3.8706689544240986]
	TIME [epoch: 10.4 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6891913156339404		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 3.6891913156339404 | validation: 2.607205109763251]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7086524953919295		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 2.7086524953919295 | validation: 2.7895862216174625]
	TIME [epoch: 10.3 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8630492471068254		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 2.8630492471068254 | validation: 2.3661090837180634]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_137.pth
	Model improved!!!
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4776476573008646		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 2.4776476573008646 | validation: 5.331372548298743]
	TIME [epoch: 10.4 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 3.500534634376385		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 3.500534634376385 | validation: 2.3447960114390547]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4154780039774537		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 2.4154780039774537 | validation: 2.2701456094957324]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 2.639610363632893		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 2.639610363632893 | validation: 2.8541561028615408]
	TIME [epoch: 10.4 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6127604971574963		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 2.6127604971574963 | validation: 2.1929825694584713]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_142.pth
	Model improved!!!
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 2.212749920203954		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 2.212749920203954 | validation: 2.1938153737690897]
	TIME [epoch: 10.4 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6625814177162006		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 2.6625814177162006 | validation: 2.5734095824772125]
	TIME [epoch: 10.3 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2681705347125365		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 2.2681705347125365 | validation: 2.815265512128193]
	TIME [epoch: 10.4 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5851250997672985		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 2.5851250997672985 | validation: 2.079037869686642]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3375278469816956		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 2.3375278469816956 | validation: 2.0703923001879416]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_147.pth
	Model improved!!!
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3528503969541674		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 2.3528503969541674 | validation: 2.1928849479498673]
	TIME [epoch: 10.4 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1977883234638993		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 2.1977883234638993 | validation: 2.558254499584075]
	TIME [epoch: 10.4 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4008853185801042		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 2.4008853185801042 | validation: 1.805311855728942]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_150.pth
	Model improved!!!
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0365995185691816		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 2.0365995185691816 | validation: 1.9414361501641926]
	TIME [epoch: 10.3 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0455653956399535		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 2.0455653956399535 | validation: 1.6284764435423291]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 2.143518114503071		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 2.143518114503071 | validation: 1.9254086688652223]
	TIME [epoch: 10.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9314901085562113		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 1.9314901085562113 | validation: 1.7483222066040736]
	TIME [epoch: 10.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9448902639410082		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 1.9448902639410082 | validation: 1.8007360272646231]
	TIME [epoch: 10.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 2.09117072009708		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 2.09117072009708 | validation: 1.49118500293112]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 1.676107878567874		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 1.676107878567874 | validation: 2.431505819973775]
	TIME [epoch: 10.3 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7661796716466103		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 1.7661796716466103 | validation: 1.8034042923070848]
	TIME [epoch: 10.3 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 2.925023462969261		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 2.925023462969261 | validation: 1.7416690052749542]
	TIME [epoch: 10.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5063504360210302		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 2.5063504360210302 | validation: 3.0282608405429086]
	TIME [epoch: 10.3 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2487775066795592		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 3.2487775066795592 | validation: 2.8464817062328858]
	TIME [epoch: 10.3 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 2.614392750273687		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 2.614392750273687 | validation: 2.6523512180046684]
	TIME [epoch: 10.3 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1478388302027547		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 2.1478388302027547 | validation: 1.614846908146643]
	TIME [epoch: 10.3 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6412468051024358		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 1.6412468051024358 | validation: 1.8144548835117036]
	TIME [epoch: 10.3 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 1.667282631840786		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 1.667282631840786 | validation: 1.2675648869098757]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6517477035874564		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 1.6517477035874564 | validation: 1.9182449390184122]
	TIME [epoch: 10.3 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9774854747376505		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 1.9774854747376505 | validation: 2.018621842910451]
	TIME [epoch: 10.3 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 2.624130852292547		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 2.624130852292547 | validation: 1.4725024183144553]
	TIME [epoch: 10.3 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5720282000676788		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 1.5720282000676788 | validation: 1.4765471543514803]
	TIME [epoch: 10.3 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 1.68561545753394		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 1.68561545753394 | validation: 1.422409801608423]
	TIME [epoch: 10.3 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6457648077230005		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 1.6457648077230005 | validation: 1.520612176380153]
	TIME [epoch: 10.3 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 1.465189817113918		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 1.465189817113918 | validation: 2.21166065059638]
	TIME [epoch: 10.3 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7734718786986037		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 1.7734718786986037 | validation: 1.5741084769628089]
	TIME [epoch: 10.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5305047344719984		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 1.5305047344719984 | validation: 1.3066071981684206]
	TIME [epoch: 10.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7833320192613222		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 1.7833320192613222 | validation: 1.5821960478990535]
	TIME [epoch: 10.3 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5690483389272343		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 1.5690483389272343 | validation: 1.566983029577772]
	TIME [epoch: 10.3 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8192652543215702		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 1.8192652543215702 | validation: 1.4474631235974786]
	TIME [epoch: 10.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 1.560371963286422		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 1.560371963286422 | validation: 1.4066012075287129]
	TIME [epoch: 10.3 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 1.804007079952779		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 1.804007079952779 | validation: 2.621654315613933]
	TIME [epoch: 10.3 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 2.033733746958661		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 2.033733746958661 | validation: 1.5016393165095878]
	TIME [epoch: 10.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7104181120741757		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 1.7104181120741757 | validation: 1.8564419903682403]
	TIME [epoch: 10.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4264499227289367		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 2.4264499227289367 | validation: 1.318125517152726]
	TIME [epoch: 10.3 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 1.655161466225676		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 1.655161466225676 | validation: 1.7804629492520634]
	TIME [epoch: 10.3 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7312050562878742		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 1.7312050562878742 | validation: 3.445056557623599]
	TIME [epoch: 10.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 1.951728864607595		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 1.951728864607595 | validation: 1.8681440589702294]
	TIME [epoch: 10.3 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7497135316330037		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 1.7497135316330037 | validation: 1.5330078340746598]
	TIME [epoch: 10.3 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6472714771606192		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 1.6472714771606192 | validation: 1.5139991404533408]
	TIME [epoch: 10.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5450645337120832		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 1.5450645337120832 | validation: 1.2540787338531088]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_188.pth
	Model improved!!!
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7442034825333146		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 1.7442034825333146 | validation: 1.3165659400000644]
	TIME [epoch: 10.3 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5975136923074758		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 1.5975136923074758 | validation: 1.4633290127486895]
	TIME [epoch: 10.4 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8683145030347235		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 1.8683145030347235 | validation: 1.4423795265039974]
	TIME [epoch: 10.3 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8763510353883945		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 1.8763510353883945 | validation: 1.67701875548347]
	TIME [epoch: 10.3 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5577560738818017		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 1.5577560738818017 | validation: 1.7554369111941737]
	TIME [epoch: 10.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5092390644820257		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 1.5092390644820257 | validation: 1.1767950270178325]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_194.pth
	Model improved!!!
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3754230446089686		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 1.3754230446089686 | validation: 1.7340019134965508]
	TIME [epoch: 10.3 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 1.488446129194712		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 1.488446129194712 | validation: 1.9835021703308302]
	TIME [epoch: 10.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7221640370302107		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 1.7221640370302107 | validation: 2.4545533636449357]
	TIME [epoch: 10.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 2.455563127009122		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 2.455563127009122 | validation: 1.417691829800974]
	TIME [epoch: 10.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6545851624729173		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 1.6545851624729173 | validation: 1.7752805469177322]
	TIME [epoch: 10.4 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5855765055867086		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 1.5855765055867086 | validation: 2.2797937678983433]
	TIME [epoch: 10.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 2.309856056251532		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 2.309856056251532 | validation: 1.9561170642740178]
	TIME [epoch: 10.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7971474810954569		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 1.7971474810954569 | validation: 2.041139031378848]
	TIME [epoch: 10.3 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0967021367768166		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 3.0967021367768166 | validation: 2.094859722657626]
	TIME [epoch: 10.3 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6259467011818036		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 1.6259467011818036 | validation: 1.9456601298566183]
	TIME [epoch: 10.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 2.133780128622793		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 2.133780128622793 | validation: 1.508103955651231]
	TIME [epoch: 10.3 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 1.555729387158688		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 1.555729387158688 | validation: 1.3364294146434055]
	TIME [epoch: 10.4 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 1.576576488311365		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 1.576576488311365 | validation: 1.1437181496200883]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_207.pth
	Model improved!!!
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 1.475926693247076		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 1.475926693247076 | validation: 1.602425409742251]
	TIME [epoch: 10.3 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 1.660003255188904		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 1.660003255188904 | validation: 6.334343715873522]
	TIME [epoch: 10.3 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 5.057219284947932		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 5.057219284947932 | validation: 1.48794760087481]
	TIME [epoch: 10.3 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7154002573814053		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 1.7154002573814053 | validation: 1.8593982084201874]
	TIME [epoch: 10.3 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6483355260125467		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 1.6483355260125467 | validation: 1.6090437927487922]
	TIME [epoch: 10.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6545230505366426		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 1.6545230505366426 | validation: 1.8720002030799745]
	TIME [epoch: 10.4 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7312496955979682		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 1.7312496955979682 | validation: 1.2171653573817929]
	TIME [epoch: 10.4 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7034143699968525		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 1.7034143699968525 | validation: 1.278986828673026]
	TIME [epoch: 10.3 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3199907328340132		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 1.3199907328340132 | validation: 1.160369736117697]
	TIME [epoch: 10.3 sec]
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 1.49208747441244		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 1.49208747441244 | validation: 1.5192186252487476]
	TIME [epoch: 10.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9751107454764694		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 1.9751107454764694 | validation: 2.716414918524023]
	TIME [epoch: 10.4 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9869654036320057		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 1.9869654036320057 | validation: 1.188062967262094]
	TIME [epoch: 10.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7391383004440855		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 1.7391383004440855 | validation: 1.205335659993482]
	TIME [epoch: 10.3 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3713051020710711		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 1.3713051020710711 | validation: 1.1447332689209995]
	TIME [epoch: 10.4 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6989115660867682		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 1.6989115660867682 | validation: 2.575541158361521]
	TIME [epoch: 10.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8812009641949554		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 1.8812009641949554 | validation: 1.5328923104224603]
	TIME [epoch: 10.3 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7195848854180227		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 1.7195848854180227 | validation: 1.2751218951940313]
	TIME [epoch: 10.3 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3425817882243312		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 1.3425817882243312 | validation: 1.2226251139579902]
	TIME [epoch: 10.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3706019720883553		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 1.3706019720883553 | validation: 1.3741347192286748]
	TIME [epoch: 10.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 1.581666801871437		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 1.581666801871437 | validation: 1.3720690780846025]
	TIME [epoch: 10.4 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6154480084058924		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 1.6154480084058924 | validation: 1.229171146547888]
	TIME [epoch: 10.4 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 1.414384401117368		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 1.414384401117368 | validation: 1.1454381807288108]
	TIME [epoch: 10.4 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4155020978351565		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 1.4155020978351565 | validation: 1.3290692710251182]
	TIME [epoch: 10.4 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3891070142952053		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 1.3891070142952053 | validation: 1.216962290169137]
	TIME [epoch: 10.3 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8295313757701155		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 1.8295313757701155 | validation: 1.768079223377777]
	TIME [epoch: 10.4 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4815104061602875		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 1.4815104061602875 | validation: 1.9309754152858931]
	TIME [epoch: 10.4 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5911759948409168		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 1.5911759948409168 | validation: 1.6754688209624409]
	TIME [epoch: 10.5 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8906555275437857		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 1.8906555275437857 | validation: 1.689084571544246]
	TIME [epoch: 10.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4611352524165078		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 1.4611352524165078 | validation: 1.357884361087851]
	TIME [epoch: 10.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4783497702732675		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 1.4783497702732675 | validation: 1.3250238180923584]
	TIME [epoch: 10.4 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2501565480663444		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 1.2501565480663444 | validation: 1.5485083067748837]
	TIME [epoch: 10.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4673788407273953		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 1.4673788407273953 | validation: 1.2584918993076313]
	TIME [epoch: 10.4 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2986355902271538		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 1.2986355902271538 | validation: 1.3884626738409964]
	TIME [epoch: 10.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8527811084898425		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 1.8527811084898425 | validation: 1.2964175585969515]
	TIME [epoch: 10.4 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3946397528659822		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 1.3946397528659822 | validation: 1.3524743147997607]
	TIME [epoch: 10.4 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 1.51511234108982		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 1.51511234108982 | validation: 1.1879730351722675]
	TIME [epoch: 10.4 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 1.582084408092508		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 1.582084408092508 | validation: 1.0942443524264014]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_244.pth
	Model improved!!!
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3035737862136167		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 1.3035737862136167 | validation: 1.4813217928002334]
	TIME [epoch: 10.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3550505179656305		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 1.3550505179656305 | validation: 1.2081809102702867]
	TIME [epoch: 10.4 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4422508810248176		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 1.4422508810248176 | validation: 1.1278336376267926]
	TIME [epoch: 10.4 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1612719643161244		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 1.1612719643161244 | validation: 2.131503845605966]
	TIME [epoch: 10.4 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 1.622227442575993		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 1.622227442575993 | validation: 1.199906765634606]
	TIME [epoch: 10.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2035622027750659		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 1.2035622027750659 | validation: 1.682713836876427]
	TIME [epoch: 10.4 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6125164804988543		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 1.6125164804988543 | validation: 1.0005207500176652]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_251.pth
	Model improved!!!
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2031741985658568		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 1.2031741985658568 | validation: 1.6969143975472605]
	TIME [epoch: 10.4 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4223018627070823		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 1.4223018627070823 | validation: 1.2467905049187866]
	TIME [epoch: 10.4 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1810546210666861		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 1.1810546210666861 | validation: 1.2124799382260054]
	TIME [epoch: 10.4 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1624309263098636		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 1.1624309263098636 | validation: 1.5912686559778884]
	TIME [epoch: 10.4 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 1.420757930224159		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 1.420757930224159 | validation: 1.5011375059242713]
	TIME [epoch: 10.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4241952742843786		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 1.4241952742843786 | validation: 1.1803566901555258]
	TIME [epoch: 10.4 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2337763915562179		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 1.2337763915562179 | validation: 1.144918279737186]
	TIME [epoch: 10.4 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3732205929705956		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 1.3732205929705956 | validation: 1.3583701523136658]
	TIME [epoch: 10.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2127591520038024		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 1.2127591520038024 | validation: 1.0719692517804627]
	TIME [epoch: 10.4 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5173290264316184		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 1.5173290264316184 | validation: 1.2044597606535765]
	TIME [epoch: 10.4 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2323244034494536		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 1.2323244034494536 | validation: 1.5317599873704837]
	TIME [epoch: 10.4 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4968101157442675		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 1.4968101157442675 | validation: 1.3631452357132587]
	TIME [epoch: 10.4 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 1.153772298321508		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 1.153772298321508 | validation: 1.64312507645791]
	TIME [epoch: 10.4 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 1.311700060199573		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 1.311700060199573 | validation: 1.2637108088790552]
	TIME [epoch: 10.4 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2259050111847425		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 1.2259050111847425 | validation: 1.3871163128120705]
	TIME [epoch: 10.4 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 1.41168385946483		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 1.41168385946483 | validation: 2.090253218604916]
	TIME [epoch: 10.4 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3932783955392933		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 1.3932783955392933 | validation: 1.645801365875995]
	TIME [epoch: 10.4 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 1.434222727104099		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 1.434222727104099 | validation: 1.576501765579643]
	TIME [epoch: 10.3 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3901544557403058		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 1.3901544557403058 | validation: 1.2039568694414398]
	TIME [epoch: 10.4 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2471076063516222		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 1.2471076063516222 | validation: 1.1549067437768212]
	TIME [epoch: 10.4 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1773371720575379		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 1.1773371720575379 | validation: 1.1391660063500793]
	TIME [epoch: 10.4 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1593688372043196		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 1.1593688372043196 | validation: 1.02817106510072]
	TIME [epoch: 10.4 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2754934845259647		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 1.2754934845259647 | validation: 1.541132249070304]
	TIME [epoch: 10.4 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6460967410400964		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 1.6460967410400964 | validation: 1.286064484657845]
	TIME [epoch: 10.4 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1759244612517983		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 1.1759244612517983 | validation: 1.0477661441085206]
	TIME [epoch: 10.4 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4268128063132213		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 1.4268128063132213 | validation: 1.3932128462935396]
	TIME [epoch: 10.4 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2149413265452513		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 1.2149413265452513 | validation: 1.2081456980670815]
	TIME [epoch: 10.4 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 1.282323403461102		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 1.282323403461102 | validation: 2.7001859675020268]
	TIME [epoch: 10.4 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7219207497628723		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 1.7219207497628723 | validation: 1.2626815991803075]
	TIME [epoch: 10.4 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3285560639611096		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 1.3285560639611096 | validation: 1.362173617374448]
	TIME [epoch: 10.4 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6716069644419296		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 1.6716069644419296 | validation: 1.8884410517021775]
	TIME [epoch: 10.4 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3876754571619252		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 1.3876754571619252 | validation: 1.2518847276180638]
	TIME [epoch: 10.3 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1267086462584586		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 1.1267086462584586 | validation: 1.3744206885484942]
	TIME [epoch: 10.4 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2419420726239152		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 1.2419420726239152 | validation: 1.2013183625527835]
	TIME [epoch: 10.4 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4170008182354665		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 1.4170008182354665 | validation: 1.2575868413291849]
	TIME [epoch: 10.4 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1168602567848651		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 1.1168602567848651 | validation: 0.9245095939852739]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_287.pth
	Model improved!!!
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0911928142344258		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 1.0911928142344258 | validation: 0.9805266914936621]
	TIME [epoch: 10.4 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3589319109416818		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 1.3589319109416818 | validation: 0.9484783369950976]
	TIME [epoch: 10.4 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4886716733100536		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 1.4886716733100536 | validation: 1.100885716275139]
	TIME [epoch: 10.4 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2087483113393303		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 1.2087483113393303 | validation: 0.953813654141128]
	TIME [epoch: 10.4 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1172244149397903		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 1.1172244149397903 | validation: 1.3189007193475784]
	TIME [epoch: 10.4 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1319084811121116		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 1.1319084811121116 | validation: 1.2095019922966834]
	TIME [epoch: 10.4 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1649006055348456		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 1.1649006055348456 | validation: 1.0475610590471534]
	TIME [epoch: 10.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1505092946356577		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 1.1505092946356577 | validation: 1.2786992743616516]
	TIME [epoch: 10.4 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 1.051141723536476		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 1.051141723536476 | validation: 1.352817350655879]
	TIME [epoch: 10.4 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2019341733636397		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 1.2019341733636397 | validation: 1.0148019366457168]
	TIME [epoch: 10.4 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2859750929179643		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 1.2859750929179643 | validation: 1.602555134149136]
	TIME [epoch: 10.4 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2014910845799727		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 1.2014910845799727 | validation: 1.2751540004569686]
	TIME [epoch: 10.4 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2854273129894085		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 1.2854273129894085 | validation: 1.0581975694012702]
	TIME [epoch: 10.4 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 1.517740643664443		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 1.517740643664443 | validation: 1.1684062995478897]
	TIME [epoch: 10.4 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0927081016441533		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 1.0927081016441533 | validation: 1.2664102809909275]
	TIME [epoch: 10.4 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2031385170160886		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 1.2031385170160886 | validation: 1.2836134510907198]
	TIME [epoch: 10.4 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0781240534490601		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 1.0781240534490601 | validation: 1.1006618959306047]
	TIME [epoch: 10.4 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2072794685794013		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 1.2072794685794013 | validation: 1.7104250977521631]
	TIME [epoch: 10.4 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3062715155954425		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 1.3062715155954425 | validation: 1.2054379091089518]
	TIME [epoch: 10.4 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0430723544571512		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 1.0430723544571512 | validation: 1.022702437710717]
	TIME [epoch: 10.4 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3977047716693611		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 1.3977047716693611 | validation: 1.2967139746158836]
	TIME [epoch: 10.4 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1909984335048538		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 1.1909984335048538 | validation: 1.1051936737279504]
	TIME [epoch: 10.4 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0744088064157749		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 1.0744088064157749 | validation: 1.5788243796934387]
	TIME [epoch: 10.4 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3598501721188234		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 1.3598501721188234 | validation: 1.5349907513723604]
	TIME [epoch: 10.4 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 1.26944818886856		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 1.26944818886856 | validation: 1.1244114327726777]
	TIME [epoch: 10.4 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1351675238004721		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 1.1351675238004721 | validation: 1.1177161701303973]
	TIME [epoch: 10.4 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2371783246752182		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 1.2371783246752182 | validation: 1.1958685404081046]
	TIME [epoch: 10.4 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0830681361848609		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 1.0830681361848609 | validation: 1.1353942933193968]
	TIME [epoch: 10.4 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2297619434020821		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 1.2297619434020821 | validation: 1.4333681044882565]
	TIME [epoch: 10.4 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1456946317506973		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 2.1456946317506973 | validation: 1.3186182623618317]
	TIME [epoch: 10.4 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 1.119182204998154		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 1.119182204998154 | validation: 1.6990933691546155]
	TIME [epoch: 10.4 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3093729694529301		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 1.3093729694529301 | validation: 1.1306057011868167]
	TIME [epoch: 10.4 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1005536503094673		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 1.1005536503094673 | validation: 1.4597723337091975]
	TIME [epoch: 10.4 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1421854178695727		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 1.1421854178695727 | validation: 1.2020141058821048]
	TIME [epoch: 10.4 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 1.042565852255897		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 1.042565852255897 | validation: 1.0431745706942477]
	TIME [epoch: 10.4 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0395950430560288		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 1.0395950430560288 | validation: 1.109331843443]
	TIME [epoch: 10.4 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 1.019019596679402		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 1.019019596679402 | validation: 1.100271165509035]
	TIME [epoch: 10.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4015751010349489		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 1.4015751010349489 | validation: 1.2591180295291324]
	TIME [epoch: 10.4 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0331178721800651		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 1.0331178721800651 | validation: 1.0481818259485638]
	TIME [epoch: 10.4 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0048396790785854		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 1.0048396790785854 | validation: 0.9712466830197661]
	TIME [epoch: 10.4 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1094880641063964		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 1.1094880641063964 | validation: 1.3551820522802742]
	TIME [epoch: 10.4 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0595372254200432		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 1.0595372254200432 | validation: 1.3951884819632374]
	TIME [epoch: 10.4 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 1.119270096950321		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 1.119270096950321 | validation: 1.078727862258801]
	TIME [epoch: 10.4 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 1.195152456523342		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 1.195152456523342 | validation: 1.536554960435978]
	TIME [epoch: 10.4 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1739420084410792		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 1.1739420084410792 | validation: 1.1561445313669878]
	TIME [epoch: 10.4 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4449560813204634		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 1.4449560813204634 | validation: 1.1778780847444057]
	TIME [epoch: 10.4 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2508077953172445		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 1.2508077953172445 | validation: 1.072875507031142]
	TIME [epoch: 10.4 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1828860096876903		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 1.1828860096876903 | validation: 0.9560658877826548]
	TIME [epoch: 10.4 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0954172018625372		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 1.0954172018625372 | validation: 1.1153711921629121]
	TIME [epoch: 10.4 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 1.087929685596602		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 1.087929685596602 | validation: 0.8550768653281946]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_337.pth
	Model improved!!!
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3532631263384185		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 1.3532631263384185 | validation: 1.5184471139130424]
	TIME [epoch: 10.4 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0823227289898338		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 1.0823227289898338 | validation: 0.9878512965874352]
	TIME [epoch: 10.4 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 1.092287658788625		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 1.092287658788625 | validation: 1.0802310563218744]
	TIME [epoch: 10.4 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0126016346524478		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 1.0126016346524478 | validation: 1.0180336659043827]
	TIME [epoch: 10.4 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0765883087341528		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 1.0765883087341528 | validation: 1.0451016958586015]
	TIME [epoch: 10.4 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 1.009242531276977		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 1.009242531276977 | validation: 0.8897369602464129]
	TIME [epoch: 10.4 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9606552809903798		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.9606552809903798 | validation: 0.9955037312648409]
	TIME [epoch: 10.4 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 1.217764135993988		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 1.217764135993988 | validation: 1.0469555387579366]
	TIME [epoch: 10.4 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9505578407267589		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.9505578407267589 | validation: 0.909219404349981]
	TIME [epoch: 10.4 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0022161526782272		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 1.0022161526782272 | validation: 1.3262403471640318]
	TIME [epoch: 10.4 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1387448605627737		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 1.1387448605627737 | validation: 0.9815412243786296]
	TIME [epoch: 10.4 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9778643878186115		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.9778643878186115 | validation: 0.8928981726227718]
	TIME [epoch: 10.4 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1880158381025239		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 1.1880158381025239 | validation: 1.2307237357163903]
	TIME [epoch: 10.4 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 1.05273346341811		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 1.05273346341811 | validation: 1.321444264658304]
	TIME [epoch: 10.4 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3557251386262987		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 1.3557251386262987 | validation: 1.8240988623377252]
	TIME [epoch: 10.4 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5074590795154788		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 1.5074590795154788 | validation: 1.0297016394837233]
	TIME [epoch: 10.4 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9007636388861201		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.9007636388861201 | validation: 0.9780330608331071]
	TIME [epoch: 10.4 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0259545487912378		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 1.0259545487912378 | validation: 0.8860480079691445]
	TIME [epoch: 10.4 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9529054222291362		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.9529054222291362 | validation: 0.992998490709748]
	TIME [epoch: 10.4 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9301747307386542		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.9301747307386542 | validation: 1.1151909544455727]
	TIME [epoch: 10.4 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5401012530432996		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 1.5401012530432996 | validation: 0.9561252023795496]
	TIME [epoch: 10.4 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9886289344652479		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.9886289344652479 | validation: 1.0950064469224772]
	TIME [epoch: 10.4 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0990109306153317		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 1.0990109306153317 | validation: 0.840939215756614]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_360.pth
	Model improved!!!
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0386185070716594		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 1.0386185070716594 | validation: 1.095730857906453]
	TIME [epoch: 10.4 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0084527899704814		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 1.0084527899704814 | validation: 1.237700147992001]
	TIME [epoch: 10.5 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1031832258256966		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 1.1031832258256966 | validation: 1.1054152240006656]
	TIME [epoch: 10.4 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 1.019295798565074		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 1.019295798565074 | validation: 1.1240852061192488]
	TIME [epoch: 10.4 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9235156766775781		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.9235156766775781 | validation: 1.9570233651734823]
	TIME [epoch: 10.4 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 1.487427680139948		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 1.487427680139948 | validation: 1.1415344834153094]
	TIME [epoch: 10.4 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0665404523858268		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 1.0665404523858268 | validation: 1.1249845161528933]
	TIME [epoch: 10.4 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1136896153754727		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 1.1136896153754727 | validation: 1.0953161586298794]
	TIME [epoch: 10.4 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1650310924733707		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 1.1650310924733707 | validation: 1.303800916437375]
	TIME [epoch: 10.4 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 1.057124684883554		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 1.057124684883554 | validation: 1.1268470835824034]
	TIME [epoch: 10.4 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0130928612528118		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 1.0130928612528118 | validation: 1.0782832631060737]
	TIME [epoch: 10.4 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2871346112886044		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 1.2871346112886044 | validation: 1.449840823496453]
	TIME [epoch: 10.4 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3862704640699963		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 1.3862704640699963 | validation: 0.9578262405402492]
	TIME [epoch: 10.4 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9165849679553919		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.9165849679553919 | validation: 1.169988056963268]
	TIME [epoch: 10.4 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0144601225389893		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 1.0144601225389893 | validation: 1.2129139572257277]
	TIME [epoch: 10.4 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9694635127806468		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.9694635127806468 | validation: 1.1206139261180543]
	TIME [epoch: 10.4 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8977362394468786		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.8977362394468786 | validation: 1.1599023149292966]
	TIME [epoch: 10.4 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9946694608680096		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.9946694608680096 | validation: 1.0122888443928684]
	TIME [epoch: 10.4 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9298276409468654		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.9298276409468654 | validation: 1.6132134163933094]
	TIME [epoch: 10.4 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3701794727437628		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 1.3701794727437628 | validation: 1.425080282672943]
	TIME [epoch: 10.4 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 1.012923476926088		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 1.012923476926088 | validation: 1.2080730289336616]
	TIME [epoch: 10.4 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9022500125392632		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.9022500125392632 | validation: 1.0290662181959964]
	TIME [epoch: 10.4 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.925184544724296		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.925184544724296 | validation: 1.243583877703371]
	TIME [epoch: 10.4 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9925343399712544		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.9925343399712544 | validation: 1.0688646836414446]
	TIME [epoch: 10.4 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0205258903238754		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 1.0205258903238754 | validation: 1.206223926593098]
	TIME [epoch: 10.4 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9797603120973797		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.9797603120973797 | validation: 1.0772227842190443]
	TIME [epoch: 10.5 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1078790863780044		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 1.1078790863780044 | validation: 0.9689318730473991]
	TIME [epoch: 10.4 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 1.042775854278194		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 1.042775854278194 | validation: 1.1427388729366756]
	TIME [epoch: 10.4 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0745102512979656		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 1.0745102512979656 | validation: 1.2508679143376302]
	TIME [epoch: 10.4 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1366049176797837		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 1.1366049176797837 | validation: 1.0311004397556973]
	TIME [epoch: 10.4 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0148511197193923		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 1.0148511197193923 | validation: 1.360802093783916]
	TIME [epoch: 10.4 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 1.026422449522762		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 1.026422449522762 | validation: 1.0691540822304892]
	TIME [epoch: 10.4 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9816534998422263		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.9816534998422263 | validation: 0.8111271031583506]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_393.pth
	Model improved!!!
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8756936651431714		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.8756936651431714 | validation: 1.0181204713907388]
	TIME [epoch: 10.4 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9470398465407056		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.9470398465407056 | validation: 1.4647839996912995]
	TIME [epoch: 10.4 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0369369649650133		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 1.0369369649650133 | validation: 1.0385348191515253]
	TIME [epoch: 10.4 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8970740990171784		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.8970740990171784 | validation: 1.1704827530100435]
	TIME [epoch: 10.4 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0000519390233022		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 1.0000519390233022 | validation: 0.8579974261964884]
	TIME [epoch: 10.5 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9812910164854314		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.9812910164854314 | validation: 1.5435067455359348]
	TIME [epoch: 10.4 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2098387048498291		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 1.2098387048498291 | validation: 1.170135423737594]
	TIME [epoch: 10.4 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9315412446326393		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.9315412446326393 | validation: 0.9768154763446218]
	TIME [epoch: 10.4 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0932408122480797		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 1.0932408122480797 | validation: 1.8626971752824153]
	TIME [epoch: 10.5 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1182001119460945		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 1.1182001119460945 | validation: 1.2949771977891982]
	TIME [epoch: 10.4 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0252154781093468		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 1.0252154781093468 | validation: 0.8784406820086759]
	TIME [epoch: 10.4 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9215148520077567		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.9215148520077567 | validation: 0.9222589073454561]
	TIME [epoch: 10.4 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9501873664582556		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.9501873664582556 | validation: 0.9816049532758484]
	TIME [epoch: 10.5 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.927964544085867		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.927964544085867 | validation: 0.8773071754281281]
	TIME [epoch: 10.4 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8203455567749721		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.8203455567749721 | validation: 0.8967520367666335]
	TIME [epoch: 10.4 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8526486068060389		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.8526486068060389 | validation: 0.7886630510450897]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_409.pth
	Model improved!!!
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9986088804965247		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.9986088804965247 | validation: 0.8464943596352623]
	TIME [epoch: 10.4 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8823177135637238		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.8823177135637238 | validation: 0.7664992605926872]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_411.pth
	Model improved!!!
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8209117074379753		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.8209117074379753 | validation: 1.0895989526565497]
	TIME [epoch: 10.4 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8410043757622511		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.8410043757622511 | validation: 1.1712201707347947]
	TIME [epoch: 10.4 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0113562672880063		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 1.0113562672880063 | validation: 1.0293980408429515]
	TIME [epoch: 10.4 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9734475543208669		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.9734475543208669 | validation: 1.0860133406862094]
	TIME [epoch: 10.4 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2370441325980575		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 1.2370441325980575 | validation: 1.9698900909039372]
	TIME [epoch: 10.4 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0851043769056983		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 1.0851043769056983 | validation: 1.1526952308428935]
	TIME [epoch: 10.4 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8314473755329445		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.8314473755329445 | validation: 1.00309766026466]
	TIME [epoch: 10.4 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8620958049867335		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.8620958049867335 | validation: 0.840688207266041]
	TIME [epoch: 10.4 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8681723739950273		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.8681723739950273 | validation: 0.8452286852535364]
	TIME [epoch: 10.4 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.86968364445113		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.86968364445113 | validation: 0.7803855949368023]
	TIME [epoch: 10.4 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8453523140694074		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.8453523140694074 | validation: 0.8601846788675366]
	TIME [epoch: 10.4 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8952291125329707		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.8952291125329707 | validation: 0.9102534069848583]
	TIME [epoch: 10.4 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0714071252250528		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 1.0714071252250528 | validation: 1.1752274143745474]
	TIME [epoch: 10.4 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9666474312015451		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.9666474312015451 | validation: 0.8990829568904386]
	TIME [epoch: 10.4 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9023823425485394		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.9023823425485394 | validation: 0.9749696069282522]
	TIME [epoch: 10.4 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8659441201090358		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.8659441201090358 | validation: 1.1107730630896238]
	TIME [epoch: 10.4 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8799956848272471		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.8799956848272471 | validation: 0.8356725604993724]
	TIME [epoch: 10.4 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8042567620779983		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.8042567620779983 | validation: 0.9626060967535678]
	TIME [epoch: 10.4 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8901144668294251		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.8901144668294251 | validation: 0.9176954645455472]
	TIME [epoch: 10.4 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8583226161983462		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.8583226161983462 | validation: 1.0855206599627318]
	TIME [epoch: 10.4 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9382837492054719		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.9382837492054719 | validation: 1.4060936831941584]
	TIME [epoch: 10.4 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0267590435933929		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 1.0267590435933929 | validation: 0.9314520221709662]
	TIME [epoch: 10.4 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9183572743079701		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.9183572743079701 | validation: 1.6455419718581124]
	TIME [epoch: 10.4 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9419031957923327		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 1.9419031957923327 | validation: 0.8763629880065075]
	TIME [epoch: 10.4 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9314690137470055		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.9314690137470055 | validation: 0.8201004875814458]
	TIME [epoch: 10.4 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9028754365815137		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.9028754365815137 | validation: 1.1026820471290666]
	TIME [epoch: 10.4 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9598575455052746		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.9598575455052746 | validation: 0.7463273869313403]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240214_235325/states/model_tr_study5_438.pth
	Model improved!!!
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0330604584056238		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 1.0330604584056238 | validation: 1.007759408653472]
	TIME [epoch: 10.4 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9582218180347557		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.9582218180347557 | validation: 0.8669744259621069]
	TIME [epoch: 10.4 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7656432215520559		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.7656432215520559 | validation: 0.8705976132573846]
	TIME [epoch: 10.4 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8737702818430014		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.8737702818430014 | validation: 1.0629995769498364]
	TIME [epoch: 10.5 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8857226174014776		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.8857226174014776 | validation: 0.8323902116945164]
	TIME [epoch: 10.4 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8372223067795377		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.8372223067795377 | validation: 0.8271002173849672]
	TIME [epoch: 10.4 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7558143007837229		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.7558143007837229 | validation: 1.2968557299356513]
	TIME [epoch: 10.4 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8663833702233775		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.8663833702233775 | validation: 0.8515948754323744]
	TIME [epoch: 10.5 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9106282224151503		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.9106282224151503 | validation: 1.0713540130699204]
	TIME [epoch: 10.4 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.825616497550522		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.825616497550522 | validation: 1.4417084101902906]
	TIME [epoch: 10.4 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8738698892843768		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.8738698892843768 | validation: 0.818370434095637]
	TIME [epoch: 10.4 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7766557849611551		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.7766557849611551 | validation: 0.9075895601764608]
	TIME [epoch: 10.4 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8579327782316426		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.8579327782316426 | validation: 0.9013100176586107]
	TIME [epoch: 10.4 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9426277791680491		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.9426277791680491 | validation: 1.7545092119820433]
	TIME [epoch: 10.4 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2746056749930221		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 1.2746056749930221 | validation: 0.9707053160050275]
	TIME [epoch: 10.4 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8862037960819084		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.8862037960819084 | validation: 1.0038408990662524]
	TIME [epoch: 10.4 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9115312273128836		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.9115312273128836 | validation: 1.070850273150839]
	TIME [epoch: 10.4 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8980811010544034		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.8980811010544034 | validation: 0.8911667406815248]
	TIME [epoch: 10.4 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7984162902198315		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.7984162902198315 | validation: 1.317250731287691]
	TIME [epoch: 10.5 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0897175339623746		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 1.0897175339623746 | validation: 1.0721716626955147]
	TIME [epoch: 10.5 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8072096272065743		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.8072096272065743 | validation: 0.838708546483611]
	TIME [epoch: 10.4 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.831317293686932		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.831317293686932 | validation: 1.5559635870176933]
	TIME [epoch: 10.4 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0100374535004302		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 1.0100374535004302 | validation: 0.8235852226728336]
	TIME [epoch: 10.4 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8372575196735186		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.8372575196735186 | validation: 1.3871376222599936]
	TIME [epoch: 10.4 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0530824075451917		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 1.0530824075451917 | validation: 0.8260285977226665]
	TIME [epoch: 10.5 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8138475826981125		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.8138475826981125 | validation: 0.799208221858629]
	TIME [epoch: 10.4 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7692112762949932		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.7692112762949932 | validation: 0.800402948443068]
	TIME [epoch: 10.4 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8066290726463918		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.8066290726463918 | validation: 0.7788819136489675]
	TIME [epoch: 10.4 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8354727947178049		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.8354727947178049 | validation: 1.604662228717489]
	TIME [epoch: 10.4 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1381829273012554		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 1.1381829273012554 | validation: 0.8525997938364585]
	TIME [epoch: 10.4 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 1.097970939411924		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 1.097970939411924 | validation: 0.9027429612593534]
	TIME [epoch: 10.5 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8501749376014136		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.8501749376014136 | validation: 0.8560669760069131]
	TIME [epoch: 10.5 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7981708773752809		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.7981708773752809 | validation: 0.7515484026099611]
	TIME [epoch: 10.5 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2709718865702997		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 1.2709718865702997 | validation: 0.9800584554842116]
	TIME [epoch: 10.4 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7936685402660261		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.7936685402660261 | validation: 0.9330739326658958]
	TIME [epoch: 10.5 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.802514189167416		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.802514189167416 | validation: 0.9902615692967627]
	TIME [epoch: 10.5 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1445810015556455		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 1.1445810015556455 | validation: 1.1515156270206253]
	TIME [epoch: 10.5 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8209802803907283		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.8209802803907283 | validation: 0.9532987851871831]
	TIME [epoch: 10.5 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8587735419173868		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.8587735419173868 | validation: 0.9082589744025963]
	TIME [epoch: 10.5 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7361905716967505		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.7361905716967505 | validation: 0.9488494865536751]
	TIME [epoch: 10.5 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7788514034574027		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.7788514034574027 | validation: 1.26571938753965]
	TIME [epoch: 10.5 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.910787733416037		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.910787733416037 | validation: 1.3254962294264858]
	TIME [epoch: 10.5 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9144208660551161		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.9144208660551161 | validation: 1.3276387168873915]
	TIME [epoch: 10.5 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9566851493570218		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.9566851493570218 | validation: 0.9217293906799224]
	TIME [epoch: 10.5 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7811820964025284		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.7811820964025284 | validation: 1.2189566242816912]
	TIME [epoch: 10.5 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9772499695779155		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.9772499695779155 | validation: 0.9245351374785648]
	TIME [epoch: 10.5 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8606427293975536		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.8606427293975536 | validation: 1.590933721833098]
	TIME [epoch: 10.5 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0243081102383624		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 1.0243081102383624 | validation: 0.8272293890292193]
	TIME [epoch: 10.5 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8087741190856068		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.8087741190856068 | validation: 1.2523147507982768]
	TIME [epoch: 10.5 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9207570696268439		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.9207570696268439 | validation: 1.0181497477399235]
	TIME [epoch: 10.5 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7647814636073681		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.7647814636073681 | validation: 0.8269729605156999]
	TIME [epoch: 10.5 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7833134687912701		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.7833134687912701 | validation: 0.9301343298071016]
	TIME [epoch: 10.5 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8203563827447002		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.8203563827447002 | validation: 0.783102216760695]
	TIME [epoch: 10.5 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9006219336357753		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.9006219336357753 | validation: 1.000214161966235]
	TIME [epoch: 10.5 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8874311367093117		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.8874311367093117 | validation: 0.8877912024635064]
	TIME [epoch: 10.5 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7011298274420223		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.7011298274420223 | validation: 0.7471613707505023]
	TIME [epoch: 10.5 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8282548125171422		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.8282548125171422 | validation: 1.0554034030510664]
	TIME [epoch: 10.5 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8563820910429684		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.8563820910429684 | validation: 0.984642311225088]
	TIME [epoch: 10.5 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7521080391852499		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.7521080391852499 | validation: 0.9144188259898599]
	TIME [epoch: 10.5 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7372752580717918		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.7372752580717918 | validation: 1.0123825263411366]
	TIME [epoch: 10.5 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8493307753899799		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.8493307753899799 | validation: 1.2355544203289595]
	TIME [epoch: 10.5 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 1.003629045150082		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 1.003629045150082 | validation: 0.8267783823306255]
	TIME [epoch: 10.5 sec]
Finished training in 5257.435 seconds.
