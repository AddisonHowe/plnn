Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r2', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1681722900

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.820903763417196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.820903763417196 | validation: 12.22590832500325]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.021672900375018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.021672900375018 | validation: 9.057751483698782]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.397571619909574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.397571619909574 | validation: 8.686730870824613]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.158243596656462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.158243596656462 | validation: 8.02943707808198]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.303246697788772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.303246697788772 | validation: 7.575218908159257]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.112319499436856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.112319499436856 | validation: 7.239256029337578]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.651808510432335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.651808510432335 | validation: 6.965708964816742]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.412564634296299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.412564634296299 | validation: 6.626014283695127]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.034953408168558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.034953408168558 | validation: 6.53231412759771]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.746080675086092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.746080675086092 | validation: 6.3134183860959086]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.264307697823404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.264307697823404 | validation: 5.881459927999347]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.04593327336546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.04593327336546 | validation: 6.355930898076687]
	TIME [epoch: 24.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.193059127456586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.193059127456586 | validation: 5.73796492240645]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.925240749650918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.925240749650918 | validation: 5.504504946099578]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735404927859321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.735404927859321 | validation: 6.5668180483678125]
	TIME [epoch: 24.7 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830283202771024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.830283202771024 | validation: 5.6011069623727465]
	TIME [epoch: 24.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.615400876016862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.615400876016862 | validation: 5.345362121079624]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.553243726158313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.553243726158313 | validation: 5.131614503159823]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.370756013362072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.370756013362072 | validation: 5.210322732880264]
	TIME [epoch: 24.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.489193971767733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.489193971767733 | validation: 4.893405162766487]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.500824411131841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.500824411131841 | validation: 6.061668091815847]
	TIME [epoch: 24.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.358097619709625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.358097619709625 | validation: 4.847583107256224]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.01256074917247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.01256074917247 | validation: 5.6773373982000725]
	TIME [epoch: 24.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3610093411585025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3610093411585025 | validation: 4.740937819802885]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2538071918236176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2538071918236176 | validation: 5.750468558806412]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.465034103502111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.465034103502111 | validation: 4.940585201116952]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1514727508841505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1514727508841505 | validation: 4.30596374422111]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101757000262593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.101757000262593 | validation: 4.586857994694522]
	TIME [epoch: 24.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.050167461288649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.050167461288649 | validation: 4.9131045817144035]
	TIME [epoch: 24.7 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.316758400717578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.316758400717578 | validation: 5.3110995352241845]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.755308128876596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.755308128876596 | validation: 4.203895960855017]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4633066044229714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4633066044229714 | validation: 4.34461195997362]
	TIME [epoch: 24.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.416747011783259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.416747011783259 | validation: 4.215727299510146]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.647361327708125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.647361327708125 | validation: 4.522818236414122]
	TIME [epoch: 24.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513964738810443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.513964738810443 | validation: 4.6873989252488855]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.825324262175237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.825324262175237 | validation: 4.8657815940629945]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85928874518074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.85928874518074 | validation: 4.430858779058642]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.797304723016823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.797304723016823 | validation: 4.552341464148915]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.571755167678748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.571755167678748 | validation: 5.303254456804268]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.908213230290416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.908213230290416 | validation: 4.590281263670781]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.586807552431543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.586807552431543 | validation: 4.451475254762326]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4437196918016655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4437196918016655 | validation: 5.616801355939656]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7048961460408085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7048961460408085 | validation: 4.3170448430306045]
	TIME [epoch: 24.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.709998984815529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.709998984815529 | validation: 7.571905659148861]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.850053893655615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.850053893655615 | validation: 5.2526603297391]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3556733239388095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3556733239388095 | validation: 4.7370331994469534]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.905484806885309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.905484806885309 | validation: 4.415812236241074]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531301086863145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.531301086863145 | validation: 4.1439999980849045]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497705220207274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.497705220207274 | validation: 3.9778690304784727]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.727335742034985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.727335742034985 | validation: 5.996514694509645]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578082368851106		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.578082368851106 | validation: 6.155726587402162]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.536136390489632		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.536136390489632 | validation: 4.440093984658821]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545643844235295		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.545643844235295 | validation: 4.272215481606379]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.95557793869755		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.95557793869755 | validation: 4.792060677766204]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981644294999208		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.981644294999208 | validation: 4.097068903966649]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496296235991391		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.496296235991391 | validation: 4.6168466606160665]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.846962048814581		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.846962048814581 | validation: 4.718038784265821]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8291638452495915		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.8291638452495915 | validation: 4.209514233699647]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243819640473582		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.243819640473582 | validation: 3.9586500146123367]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.208722602488014		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.208722602488014 | validation: 3.844048696577502]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510071721673389		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.510071721673389 | validation: 3.9658278844193826]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.528758922068116		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.528758922068116 | validation: 4.520115011405976]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.589333087835517		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.589333087835517 | validation: 4.206315970642524]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.04866866885717		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.04866866885717 | validation: 4.0598414128276135]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1197809421969875		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.1197809421969875 | validation: 3.8914715421545862]
	TIME [epoch: 24.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.274221485974401		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.274221485974401 | validation: 4.6355042412284995]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.154144721916392		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.154144721916392 | validation: 5.807466740277379]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.373920671887941		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.373920671887941 | validation: 4.502787761059061]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.979092986791242		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.979092986791242 | validation: 7.743963815339029]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8732955317245095		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.8732955317245095 | validation: 4.879671646816745]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.361224672039586		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.361224672039586 | validation: 3.924446804167772]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.001341726037282		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.001341726037282 | validation: 3.7474788057424413]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.773567957559939		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.773567957559939 | validation: 3.5804482827320165]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6611298090387665		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.6611298090387665 | validation: 4.222021842032903]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9983149793914556		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.9983149793914556 | validation: 3.695692118209054]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.805275697065047		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.805275697065047 | validation: 4.8097238277381145]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.324080204587762		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.324080204587762 | validation: 3.958729080179735]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.839907489384948		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.839907489384948 | validation: 3.712870513218908]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.703138743974251		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.703138743974251 | validation: 3.735086834355942]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.159168787800571		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.159168787800571 | validation: 4.075276389502746]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.112875042184551		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.112875042184551 | validation: 5.79136631394485]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8858126749708415		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.8858126749708415 | validation: 3.6000888506700064]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.149190962704919		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.149190962704919 | validation: 3.9100605998442295]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.707131935871908		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.707131935871908 | validation: 3.9454976790100558]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.889827591983545		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.889827591983545 | validation: 3.583633856714006]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1646044856388125		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.1646044856388125 | validation: 4.571067263175074]
	TIME [epoch: 24.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.051712291439332		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.051712291439332 | validation: 4.058638497720211]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.689525408170136		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.689525408170136 | validation: 3.5066045096226426]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.883890378148852		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.883890378148852 | validation: 3.454232605713796]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648343999482522		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.648343999482522 | validation: 3.839131204305855]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.197701476754857		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.197701476754857 | validation: 3.9624507885859703]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.338050874523148		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.338050874523148 | validation: 3.9377728867699457]
	TIME [epoch: 24.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068509854506986		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.068509854506986 | validation: 3.617153679476695]
	TIME [epoch: 24.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0579859081682645		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.0579859081682645 | validation: 4.275668856719354]
	TIME [epoch: 24.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.145492658559435		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.145492658559435 | validation: 5.127083917456641]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.444181064338567		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.444181064338567 | validation: 3.9719166901110614]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9338920940257163		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.9338920940257163 | validation: 4.3534962276533]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.043647678913305		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.043647678913305 | validation: 4.753029376603506]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.946228481633819		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 6.946228481633819 | validation: 5.652681859350817]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.938125085601188		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.938125085601188 | validation: 4.975430561653288]
	TIME [epoch: 24.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.307311475690485		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.307311475690485 | validation: 5.303677330623803]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8908258834635125		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.8908258834635125 | validation: 4.538311733652109]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.414026260901934		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.414026260901934 | validation: 4.384324055005573]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.388903769687243		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.388903769687243 | validation: 7.395833939887752]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.119595299312958		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 6.119595299312958 | validation: 4.474019798349684]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.277556598853094		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.277556598853094 | validation: 4.209941665107532]
	TIME [epoch: 24.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.475086406107671		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 5.475086406107671 | validation: 4.506908116090677]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.384240561213428		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.384240561213428 | validation: 3.7817227581635953]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2179740038006415		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.2179740038006415 | validation: 6.177382471947794]
	TIME [epoch: 24.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.249549684437421		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 7.249549684437421 | validation: 8.798815795194946]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5999646576186635		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 6.5999646576186635 | validation: 4.382408093057369]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.153783968095513		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.153783968095513 | validation: 3.736190846424819]
	TIME [epoch: 24.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9286260120168235		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.9286260120168235 | validation: 3.4933600407887866]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.658047130108933		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.658047130108933 | validation: 3.6172555740270878]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0246171203919445		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.0246171203919445 | validation: 3.6304806259117663]
	TIME [epoch: 24.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.055946202932518		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.055946202932518 | validation: 3.598343353148248]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.750125054235332		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.750125054235332 | validation: 3.679774350786464]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.574340630632503		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.574340630632503 | validation: 3.497615365049388]
	TIME [epoch: 24.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9471594245992554		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.9471594245992554 | validation: 4.32256637087351]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.151036798620337		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.151036798620337 | validation: 3.4425933124389854]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.608000042302685		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.608000042302685 | validation: 3.8200601953194995]
	TIME [epoch: 24.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.867872014882656		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.867872014882656 | validation: 3.382158322570761]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4894578762423443		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.4894578762423443 | validation: 3.7799934460425924]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.634703391227607		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.634703391227607 | validation: 4.448517538203332]
	TIME [epoch: 24.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.337835015305769		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 5.337835015305769 | validation: 6.05567454523801]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.244282717057037		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 7.244282717057037 | validation: 8.264808832109779]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.861928526561279		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 6.861928526561279 | validation: 4.784155293917654]
	TIME [epoch: 24.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525350889090381		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.525350889090381 | validation: 3.951184768477065]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.045067238464205		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.045067238464205 | validation: 3.7445429784337425]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.336050881725541		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.336050881725541 | validation: 5.10406994561956]
	TIME [epoch: 24.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.225647567511252		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.225647567511252 | validation: 3.4378405779136427]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.846604231161483		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.846604231161483 | validation: 3.523989246133725]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7224157457805624		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.7224157457805624 | validation: 4.505423008580721]
	TIME [epoch: 24.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.191805715804393		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.191805715804393 | validation: 3.1913171219260916]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.43910304694254		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.43910304694254 | validation: 3.5289066059813115]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.111375256713851		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.111375256713851 | validation: 5.454882908260654]
	TIME [epoch: 24.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044924065728679		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.044924065728679 | validation: 3.2964748194536004]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.526288559684412		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.526288559684412 | validation: 3.178239792952691]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.115084936121339		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.115084936121339 | validation: 3.6511530050461722]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.466571243486629		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.466571243486629 | validation: 4.586752373330405]
	TIME [epoch: 24.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53868257897572		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.53868257897572 | validation: 3.6124863715636866]
	TIME [epoch: 24.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.69568203088988		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.69568203088988 | validation: 3.480266077478698]
	TIME [epoch: 24.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.624443255833533		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.624443255833533 | validation: 7.067654900739505]
	TIME [epoch: 24.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.356267968740337		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 5.356267968740337 | validation: 3.6968525580779104]
	TIME [epoch: 24.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.139087986419778		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 4.139087986419778 | validation: 3.6321531660075728]
	TIME [epoch: 24.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.856885937570492		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.856885937570492 | validation: 3.672668531728379]
	TIME [epoch: 24.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6983447200273343		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.6983447200273343 | validation: 4.104465682514314]
	TIME [epoch: 24.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5700276072301995		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.5700276072301995 | validation: 3.6177875288755343]
	TIME [epoch: 24.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283303046075399		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 4.283303046075399 | validation: 3.805600745985862]
	TIME [epoch: 24.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.957891700167076		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.957891700167076 | validation: 3.7690000162544055]
	TIME [epoch: 24.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4943366269835314		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.4943366269835314 | validation: 3.2412616774597316]
	TIME [epoch: 24.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4225488512200037		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.4225488512200037 | validation: 3.4308849596392044]
	TIME [epoch: 24.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.541102527018283		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.541102527018283 | validation: 3.8222431675952704]
	TIME [epoch: 24.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8407125407592275		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.8407125407592275 | validation: 3.063175207457965]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270704689956856		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.270704689956856 | validation: 3.861240620851751]
	TIME [epoch: 24.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.209431841238817		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 5.209431841238817 | validation: 5.064148863841159]
	TIME [epoch: 24.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.904466204561972		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.904466204561972 | validation: 3.0819055014205095]
	TIME [epoch: 24.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5892392298768288		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.5892392298768288 | validation: 2.9446377738593994]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4345150508027293		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.4345150508027293 | validation: 3.78174380504635]
	TIME [epoch: 24.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2970988719359724		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.2970988719359724 | validation: 3.240631931549137]
	TIME [epoch: 24.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.553311205948112		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.553311205948112 | validation: 3.246160485684129]
	TIME [epoch: 24.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3173309910816884		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.3173309910816884 | validation: 4.202586189479836]
	TIME [epoch: 24.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.060598193374999		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.060598193374999 | validation: 3.5622831094486105]
	TIME [epoch: 24.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1454069100150743		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.1454069100150743 | validation: 3.0698018617421567]
	TIME [epoch: 24.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270625172731742		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.270625172731742 | validation: 3.091914467740228]
	TIME [epoch: 24.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.313233294980162		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.313233294980162 | validation: 3.980663327926434]
	TIME [epoch: 24.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.189764111676061		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.189764111676061 | validation: 4.190489750721252]
	TIME [epoch: 24.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6203268843453267		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.6203268843453267 | validation: 3.005308972477952]
	TIME [epoch: 24.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0600014082067784		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.0600014082067784 | validation: 3.4561885123506624]
	TIME [epoch: 24.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9512561766281955		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.9512561766281955 | validation: 2.511503772463363]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7211570134751284		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.7211570134751284 | validation: 2.4577031787572365]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985224077248537		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.985224077248537 | validation: 2.8168420099448657]
	TIME [epoch: 24.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9616412936380945		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.9616412936380945 | validation: 4.250310091529515]
	TIME [epoch: 24.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.571660050582979		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.571660050582979 | validation: 4.23590867235896]
	TIME [epoch: 24.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.40493379107524		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.40493379107524 | validation: 3.607497861467548]
	TIME [epoch: 24.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1863666273127906		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.1863666273127906 | validation: 2.4167016868909843]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858576144871007		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.858576144871007 | validation: 2.38988826416186]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435782927833227		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.435782927833227 | validation: 4.589103679585333]
	TIME [epoch: 24.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389277622837665		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.389277622837665 | validation: 2.611994675243239]
	TIME [epoch: 24.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5981997765210982		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.5981997765210982 | validation: 2.2871500053393574]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.528862130920304		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.528862130920304 | validation: 2.2423918527075917]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0530051566873455		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.0530051566873455 | validation: 3.243094669689878]
	TIME [epoch: 24.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808111491930004		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.808111491930004 | validation: 2.4534075722265123]
	TIME [epoch: 24.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.751984708072887		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.751984708072887 | validation: 2.4785918378567833]
	TIME [epoch: 24.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9141631261490386		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.9141631261490386 | validation: 2.431698207808504]
	TIME [epoch: 24.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5693427188569635		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.5693427188569635 | validation: 2.475284110780884]
	TIME [epoch: 24.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.697555585057132		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.697555585057132 | validation: 2.9909477208225894]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.564250412865534		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.564250412865534 | validation: 2.2660541451259224]
	TIME [epoch: 24.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3904916742093674		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.3904916742093674 | validation: 2.5988513461351603]
	TIME [epoch: 24.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3737068358009243		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.3737068358009243 | validation: 2.862041378849582]
	TIME [epoch: 24.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8063107802720357		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.8063107802720357 | validation: 2.482102686500286]
	TIME [epoch: 24.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7918390531588373		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.7918390531588373 | validation: 3.256873108642208]
	TIME [epoch: 24.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87614279993865		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.87614279993865 | validation: 2.555382268065279]
	TIME [epoch: 24.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.727430135675262		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.727430135675262 | validation: 2.5343010132072514]
	TIME [epoch: 24.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5897006582124784		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.5897006582124784 | validation: 2.4217883841629453]
	TIME [epoch: 24.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5243903311772895		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.5243903311772895 | validation: 2.3062112932444596]
	TIME [epoch: 24.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.199773457552149		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.199773457552149 | validation: 2.8289788084398424]
	TIME [epoch: 24.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5658648617562276		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.5658648617562276 | validation: 2.2447222059707093]
	TIME [epoch: 24.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5949028357722375		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.5949028357722375 | validation: 2.653166737697077]
	TIME [epoch: 24.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8705710886186884		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.8705710886186884 | validation: 2.3480335796352927]
	TIME [epoch: 24.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6091955222734584		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.6091955222734584 | validation: 2.862885307368439]
	TIME [epoch: 24.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.567003804792175		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.567003804792175 | validation: 2.041234937363824]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6817490738316843		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.6817490738316843 | validation: 2.436049508937841]
	TIME [epoch: 24.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.401825705840989		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.401825705840989 | validation: 1.9607074558108628]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.483340734784784		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.483340734784784 | validation: 2.2823169899036837]
	TIME [epoch: 24.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1436632902420576		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.1436632902420576 | validation: 2.3536509799584593]
	TIME [epoch: 24.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3301188262455494		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.3301188262455494 | validation: 1.9582275135316192]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.71663801685044		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.71663801685044 | validation: 2.962329099408249]
	TIME [epoch: 24.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7728787748778485		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.7728787748778485 | validation: 2.428156832323844]
	TIME [epoch: 24.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.772004236679076		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.772004236679076 | validation: 2.4697094255772574]
	TIME [epoch: 24.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.571427129622175		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.571427129622175 | validation: 2.9500793752107772]
	TIME [epoch: 24.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8039796448240764		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.8039796448240764 | validation: 2.4273945032635202]
	TIME [epoch: 24.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.581155790737607		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.581155790737607 | validation: 3.151528163926404]
	TIME [epoch: 24.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6240176513230726		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.6240176513230726 | validation: 2.0824360536316515]
	TIME [epoch: 24.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415777679270678		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.415777679270678 | validation: 2.5577317880656425]
	TIME [epoch: 24.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5419396492445125		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.5419396492445125 | validation: 2.756387378181401]
	TIME [epoch: 24.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31448346628507		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.31448346628507 | validation: 2.8483343826334893]
	TIME [epoch: 24.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4488900662295143		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.4488900662295143 | validation: 2.611377458815894]
	TIME [epoch: 24.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4578420107326107		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.4578420107326107 | validation: 3.5197374957552756]
	TIME [epoch: 24.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5937785951272665		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.5937785951272665 | validation: 2.521568612408392]
	TIME [epoch: 24.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4230037416883596		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.4230037416883596 | validation: 2.6679721753235444]
	TIME [epoch: 24.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4038292913017507		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.4038292913017507 | validation: 2.1584941212482485]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335468659474312		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.335468659474312 | validation: 2.0460485409897906]
	TIME [epoch: 24.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.353416941193549		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.353416941193549 | validation: 2.0340442632365496]
	TIME [epoch: 24.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284536214466499		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.284536214466499 | validation: 1.8502441649950414]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381691655176075		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.381691655176075 | validation: 2.594905670817503]
	TIME [epoch: 24.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.753961978385722		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.753961978385722 | validation: 1.8611882645850182]
	TIME [epoch: 24.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0072283123226153		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.0072283123226153 | validation: 2.2428523358944314]
	TIME [epoch: 24.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3113330093973143		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.3113330093973143 | validation: 1.9964156902716133]
	TIME [epoch: 24.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1150003640569635		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.1150003640569635 | validation: 1.9793009265925445]
	TIME [epoch: 24.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0527847262807772		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.0527847262807772 | validation: 2.0149443136149596]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9379722890601598		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.9379722890601598 | validation: 2.0004476516802736]
	TIME [epoch: 24.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.522743153662699		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.522743153662699 | validation: 2.716906330415485]
	TIME [epoch: 24.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2730967713697883		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.2730967713697883 | validation: 2.4672024495149487]
	TIME [epoch: 24.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1512907343484065		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.1512907343484065 | validation: 1.990243514652626]
	TIME [epoch: 24.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056456648521764		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.056456648521764 | validation: 2.3761206903209824]
	TIME [epoch: 24.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2031533822218465		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.2031533822218465 | validation: 2.1913045492605865]
	TIME [epoch: 24.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9327245439653993		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.9327245439653993 | validation: 3.520632746306199]
	TIME [epoch: 24.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239007995173534		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.239007995173534 | validation: 1.6637147829686627]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180563927054539		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.180563927054539 | validation: 2.1978077795481816]
	TIME [epoch: 24.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085015525959304		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.085015525959304 | validation: 2.109015712198155]
	TIME [epoch: 24.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.887747519807319		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.887747519807319 | validation: 1.786894450016668]
	TIME [epoch: 24.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7954873531013735		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.7954873531013735 | validation: 1.890142023427295]
	TIME [epoch: 24.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045171773468392		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.045171773468392 | validation: 1.6943060523380096]
	TIME [epoch: 24.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8706711781895669		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.8706711781895669 | validation: 1.9089267962153755]
	TIME [epoch: 24.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.944096322924703		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.944096322924703 | validation: 2.5085659070759405]
	TIME [epoch: 24.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0496755528575195		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.0496755528575195 | validation: 1.6195165830233673]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2655008863840838		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.2655008863840838 | validation: 1.8044307039019276]
	TIME [epoch: 24.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.929245409402405		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.929245409402405 | validation: 1.8706785705349678]
	TIME [epoch: 24.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7591938110760592		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.7591938110760592 | validation: 1.5011970046752425]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.638620878569086		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.638620878569086 | validation: 1.6969478931761126]
	TIME [epoch: 24.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6502155024026857		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.6502155024026857 | validation: 1.6149158112195392]
	TIME [epoch: 24.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7349875290230727		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.7349875290230727 | validation: 2.280107475862782]
	TIME [epoch: 24.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8653371433270638		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.8653371433270638 | validation: 1.483977423840724]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9521051260307893		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.9521051260307893 | validation: 2.0902069869795294]
	TIME [epoch: 24.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1801909185284702		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.1801909185284702 | validation: 1.8855120422416278]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8359956544010685		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.8359956544010685 | validation: 1.7649770557373636]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7860572643392283		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.7860572643392283 | validation: 1.8876517036443436]
	TIME [epoch: 24.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1381205809290864		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.1381205809290864 | validation: 1.9276667865501425]
	TIME [epoch: 24.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169181018336939		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.169181018336939 | validation: 3.0500281665921207]
	TIME [epoch: 24.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2256817927059167		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.2256817927059167 | validation: 4.74935174075363]
	TIME [epoch: 24.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2758024814126028		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.2758024814126028 | validation: 2.7004950522813176]
	TIME [epoch: 24.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1559693324369906		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.1559693324369906 | validation: 2.622535644058088]
	TIME [epoch: 24.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9430343363576041		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.9430343363576041 | validation: 1.806335905565582]
	TIME [epoch: 24.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0957310393681143		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.0957310393681143 | validation: 1.8799375653585324]
	TIME [epoch: 24.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.980877696001917		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.980877696001917 | validation: 1.694749804274885]
	TIME [epoch: 24.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2340611279166644		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 4.2340611279166644 | validation: 3.5497551283397257]
	TIME [epoch: 24.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2732250750090772		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.2732250750090772 | validation: 2.007095949273185]
	TIME [epoch: 24.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.968302377799691		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.968302377799691 | validation: 1.7447359515386012]
	TIME [epoch: 24.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9174243669297262		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.9174243669297262 | validation: 2.6300954803699894]
	TIME [epoch: 24.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1218801695061478		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.1218801695061478 | validation: 1.700063623767693]
	TIME [epoch: 24.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1085481218953284		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.1085481218953284 | validation: 2.639120089936355]
	TIME [epoch: 24.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.939303707167563		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.939303707167563 | validation: 1.6120293706828768]
	TIME [epoch: 24.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321369773976582		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.321369773976582 | validation: 1.591819254195396]
	TIME [epoch: 24.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6452025023691323		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.6452025023691323 | validation: 1.7444368579732148]
	TIME [epoch: 24.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.712008804720925		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.712008804720925 | validation: 2.0923546485138638]
	TIME [epoch: 24.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3022408260974347		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.3022408260974347 | validation: 1.4802163473342045]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6267425958234734		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.6267425958234734 | validation: 2.1367050615682244]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7561999201996596		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.7561999201996596 | validation: 1.479661073238099]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7098146170312907		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.7098146170312907 | validation: 1.3029106550693408]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7598001149326663		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.7598001149326663 | validation: 1.4380918361246773]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4398427569017147		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.4398427569017147 | validation: 1.2919889347115163]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4860007395641213		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.4860007395641213 | validation: 2.650120382202019]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290674211458177		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.290674211458177 | validation: 1.7193855140494798]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5983546027086015		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.5983546027086015 | validation: 3.233055169757569]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1504397305669887		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.1504397305669887 | validation: 2.1527266669684026]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7765932958294999		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.7765932958294999 | validation: 3.788605608188323]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4975456817776793		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.4975456817776793 | validation: 1.6809089265557287]
	TIME [epoch: 24.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7634469191591107		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.7634469191591107 | validation: 1.5417314248002891]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1533706144573928		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.1533706144573928 | validation: 1.544415968138415]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.632906482093853		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.632906482093853 | validation: 1.4356364674791888]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5656600019371547		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.5656600019371547 | validation: 1.854816604833362]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7431166865309586		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.7431166865309586 | validation: 1.667575047890586]
	TIME [epoch: 24.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6641518457177746		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.6641518457177746 | validation: 1.366951314698651]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.990190126367244		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.990190126367244 | validation: 1.62302292358323]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5493174337805458		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.5493174337805458 | validation: 2.6261559683402753]
	TIME [epoch: 24.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0479089326606568		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.0479089326606568 | validation: 1.834508946054873]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7610991852854891		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.7610991852854891 | validation: 1.6962574510935955]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5495304969080566		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.5495304969080566 | validation: 1.8379659786206037]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5935362661681598		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.5935362661681598 | validation: 1.724457835876345]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289067645364576		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.289067645364576 | validation: 1.7291014044801596]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7790727173123932		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.7790727173123932 | validation: 1.3094815558113653]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.432488218740259		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.432488218740259 | validation: 1.6755024545001214]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5835504815599055		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.5835504815599055 | validation: 1.3176903737194323]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4872841678504742		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.4872841678504742 | validation: 1.5897233581876402]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5765474349647897		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.5765474349647897 | validation: 1.413342719071786]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.847766671683225		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.847766671683225 | validation: 1.5648363617772396]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7016536836088052		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.7016536836088052 | validation: 1.4056738158217525]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5142177828049783		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.5142177828049783 | validation: 2.2232414287170164]
	TIME [epoch: 24.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6193175311975045		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.6193175311975045 | validation: 1.368636528806585]
	TIME [epoch: 24.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4444499279711542		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.4444499279711542 | validation: 1.4573721753815745]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252955914726513		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.252955914726513 | validation: 1.27732229237578]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5213158195703638		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.5213158195703638 | validation: 1.9464785788609478]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7014363002565425		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.7014363002565425 | validation: 1.1453175651018692]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6086193861744613		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.6086193861744613 | validation: 1.4534928034236196]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7058060490305498		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.7058060490305498 | validation: 1.3201839920249288]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5276553789706986		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.5276553789706986 | validation: 1.47048189456201]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4975427595071178		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.4975427595071178 | validation: 1.4348341480732694]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4337618105744419		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.4337618105744419 | validation: 1.6766083400480756]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.383920862225906		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.383920862225906 | validation: 2.184198549594285]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.156295576978289		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.156295576978289 | validation: 1.2463071557913985]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5296300915226677		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.5296300915226677 | validation: 2.0199504060535496]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4947808571882466		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.4947808571882466 | validation: 1.2958428138183775]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.77678839340289		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.77678839340289 | validation: 1.3882795710099403]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8290947689643677		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.8290947689643677 | validation: 1.976258739092611]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5012212953604684		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.5012212953604684 | validation: 1.735838053040907]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7283940218703944		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.7283940218703944 | validation: 1.6154583600812493]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2792104648797897		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.2792104648797897 | validation: 4.009967809302975]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8495182384077453		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.8495182384077453 | validation: 2.123393457636289]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5256385099581737		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.5256385099581737 | validation: 1.6020550085082115]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.566264759670712		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.566264759670712 | validation: 1.440378608130803]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311030029977983		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.311030029977983 | validation: 1.2765983361611066]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4323937908365565		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.4323937908365565 | validation: 2.1668777671062576]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7511691838512757		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.7511691838512757 | validation: 1.4597375525375134]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.451982134126584		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.451982134126584 | validation: 3.6974020682606454]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3085673328352994		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.3085673328352994 | validation: 1.3533004157011363]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8986628477470398		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.8986628477470398 | validation: 1.3309337313299738]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3706926038902485		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.3706926038902485 | validation: 1.27330544436809]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3498135535477385		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.3498135535477385 | validation: 1.2135922712032101]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3936637132539795		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.3936637132539795 | validation: 1.3354971576157362]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4833607983576198		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.4833607983576198 | validation: 1.3369635450999366]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3072747161689708		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.3072747161689708 | validation: 1.2572217821235785]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4482361182870918		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.4482361182870918 | validation: 1.2673483494339493]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292368811016558		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.292368811016558 | validation: 1.2865038723303515]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2457062303452724		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.2457062303452724 | validation: 1.074178230432762]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5663998856941141		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.5663998856941141 | validation: 1.5643521039826285]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6508566006649357		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.6508566006649357 | validation: 1.7670334057926178]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5977920958290155		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.5977920958290155 | validation: 1.3136154836730969]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2493282944355655		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.2493282944355655 | validation: 1.9023585559428136]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6533585921610947		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.6533585921610947 | validation: 1.287056668025926]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6644217167195117		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.6644217167195117 | validation: 4.299495372619303]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4488692728872827		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.4488692728872827 | validation: 1.5311264047474873]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6646448737058146		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.6646448737058146 | validation: 1.276067520118874]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5677637058700875		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.5677637058700875 | validation: 1.3634302432098993]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6694423890646206		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.6694423890646206 | validation: 1.3324843254522734]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.604801866721074		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.604801866721074 | validation: 2.67007008841376]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.802112884766538		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.802112884766538 | validation: 1.2884020056758567]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7366609046685197		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.7366609046685197 | validation: 1.9549797686993577]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.003747410554561		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.003747410554561 | validation: 1.403199839947075]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3705953259194672		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.3705953259194672 | validation: 1.2667824739861901]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2977397192126534		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.2977397192126534 | validation: 1.2319420584758733]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4684894311398395		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4684894311398395 | validation: 1.5737695184660678]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5127905018608032		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.5127905018608032 | validation: 2.508036701686232]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1427571744404856		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.1427571744404856 | validation: 1.3625793126993477]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4379719216834304		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.4379719216834304 | validation: 1.1850969948329315]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4080802856726227		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.4080802856726227 | validation: 1.2837876956500858]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1860087009563818		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.1860087009563818 | validation: 1.0859898498038987]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220242531682717		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.220242531682717 | validation: 1.0356778082279592]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598955846342615		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.0598955846342615 | validation: 0.9368271839691454]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2462737113561249		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.2462737113561249 | validation: 0.93911272020711]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2638764703729573		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.2638764703729573 | validation: 1.3230750390866772]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3732481233904743		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.3732481233904743 | validation: 1.2400722117193888]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737858621559058		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0737858621559058 | validation: 1.1790420648259314]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1727773805061026		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.1727773805061026 | validation: 1.1893927948562482]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.535349959838191		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.535349959838191 | validation: 1.3195467093618276]
	TIME [epoch: 24.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2617655014613525		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.2617655014613525 | validation: 1.3800098216409327]
	TIME [epoch: 24.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262199167681926		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.262199167681926 | validation: 1.5681380040317834]
	TIME [epoch: 24.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3288796555721845		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.3288796555721845 | validation: 0.9430317723381806]
	TIME [epoch: 24.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982396874730296		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.0982396874730296 | validation: 0.9336652246777802]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0937764520107995		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.0937764520107995 | validation: 1.2288090769245192]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2759793439461111		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.2759793439461111 | validation: 1.2777722608809332]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2893593554203577		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.2893593554203577 | validation: 1.526429394613283]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3853376694251607		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.3853376694251607 | validation: 1.0626218320570229]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5667412935103129		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.5667412935103129 | validation: 2.3266143760439766]
	TIME [epoch: 24.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7297467238652195		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.7297467238652195 | validation: 2.164653574992073]
	TIME [epoch: 24.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337944890449548		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.337944890449548 | validation: 1.6813645020819519]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.906755115543299		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.906755115543299 | validation: 1.4054145918103094]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4773843499542778		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.4773843499542778 | validation: 1.7903797213804946]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8214589077909302		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.8214589077909302 | validation: 1.407546351014665]
	TIME [epoch: 24.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.373316493500599		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.373316493500599 | validation: 1.115523286674897]
	TIME [epoch: 24.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262891905103043		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.262891905103043 | validation: 2.544920037027352]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8863713115448788		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.8863713115448788 | validation: 1.1900599213186618]
	TIME [epoch: 24.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491182987405883		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.491182987405883 | validation: 1.3976783897701102]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4487497555529076		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.4487497555529076 | validation: 1.3058519672224966]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.210865117883916		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.210865117883916 | validation: 1.2379973929035353]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823980306089819		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.1823980306089819 | validation: 0.9469378217357545]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.413797580141218		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.413797580141218 | validation: 3.821764556151127]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.453106539687661		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.453106539687661 | validation: 2.2691659285204966]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4433920055328708		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.4433920055328708 | validation: 1.2777001623523732]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1841195222277632		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.1841195222277632 | validation: 1.1129775999382334]
	TIME [epoch: 24.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381882860612976		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.2381882860612976 | validation: 2.070274910227928]
	TIME [epoch: 24.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3195218292120918		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.3195218292120918 | validation: 1.0161685750654008]
	TIME [epoch: 24.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5329084095375665		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.5329084095375665 | validation: 0.9676609580717042]
	TIME [epoch: 24.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3672251681391425		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.3672251681391425 | validation: 3.572419922847976]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070428914497951		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.070428914497951 | validation: 1.0478969415140076]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0865806602775696		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.0865806602775696 | validation: 1.3810737557311663]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4674289418802984		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.4674289418802984 | validation: 0.891979506134609]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668092351148222		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.0668092351148222 | validation: 1.0016083467116585]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.546563283082408		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.546563283082408 | validation: 1.3395799500539054]
	TIME [epoch: 24.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2735802849125775		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.2735802849125775 | validation: 2.143514533054096]
	TIME [epoch: 24.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6591158367207155		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.6591158367207155 | validation: 1.3450358015596964]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3369972476645264		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3369972476645264 | validation: 1.6402855765793578]
	TIME [epoch: 24.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.47822992341319		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.47822992341319 | validation: 1.3303244114264317]
	TIME [epoch: 24.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180657609093952		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.180657609093952 | validation: 1.2203556535398423]
	TIME [epoch: 24.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8473820718024854		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.8473820718024854 | validation: 1.1944969287491285]
	TIME [epoch: 24.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2770414596031103		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.2770414596031103 | validation: 1.1748300380897794]
	TIME [epoch: 24.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6924751605171025		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.6924751605171025 | validation: 1.2792616461227824]
	TIME [epoch: 24.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2791495847617433		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.2791495847617433 | validation: 1.2058802667171264]
	TIME [epoch: 24.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1957708903476227		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.1957708903476227 | validation: 1.619162962058421]
	TIME [epoch: 24.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5236066874305103		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.5236066874305103 | validation: 1.126896035452965]
	TIME [epoch: 24.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9749487552560165		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.9749487552560165 | validation: 1.6190400718118019]
	TIME [epoch: 24.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8336181347736367		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.8336181347736367 | validation: 1.5042633128339986]
	TIME [epoch: 24.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494734171125067		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.1494734171125067 | validation: 1.3177564737902616]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5333840074144924		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.5333840074144924 | validation: 1.0740521809390464]
	TIME [epoch: 24.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0387185840712068		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.0387185840712068 | validation: 1.0156498869330834]
	TIME [epoch: 24.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0071488418422314		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.0071488418422314 | validation: 0.8688972293488437]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036485433073346		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.036485433073346 | validation: 0.9350375910933607]
	TIME [epoch: 24.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9504582395774701		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.9504582395774701 | validation: 1.1890937025528063]
	TIME [epoch: 24.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0890749379004543		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.0890749379004543 | validation: 0.8923977161580731]
	TIME [epoch: 24.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310105626687602		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.0310105626687602 | validation: 2.070216708247001]
	TIME [epoch: 24.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3835457588399125		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.3835457588399125 | validation: 1.1670732171589842]
	TIME [epoch: 24.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0160649759047375		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.0160649759047375 | validation: 0.8589064322475468]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0558206157807604		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.0558206157807604 | validation: 1.1982028192854228]
	TIME [epoch: 24.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0860161330727973		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.0860161330727973 | validation: 0.8490669137798258]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9596191447386331		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.9596191447386331 | validation: 0.7587253859199922]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8850406252191367		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.8850406252191367 | validation: 0.8228378454224735]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985765606338131		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.0985765606338131 | validation: 1.8049506966906859]
	TIME [epoch: 24.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2805592519933324		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.2805592519933324 | validation: 1.1337983571359678]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235718374033897		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.235718374033897 | validation: 2.0438072794392026]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6103381524802722		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.6103381524802722 | validation: 1.1371456244978515]
	TIME [epoch: 24.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0186323915158233		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.0186323915158233 | validation: 1.0759166694556606]
	TIME [epoch: 24.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9464460807102486		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.9464460807102486 | validation: 0.8542144348314018]
	TIME [epoch: 24.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0446300551565546		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.0446300551565546 | validation: 1.6934297884947438]
	TIME [epoch: 24.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1874329114918523		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.1874329114918523 | validation: 0.8105829813198531]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9771954730854984		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.9771954730854984 | validation: 0.8182393650666944]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9599135879709682		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.9599135879709682 | validation: 1.0010824905714528]
	TIME [epoch: 24.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0055411689401197		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.0055411689401197 | validation: 1.242934289642998]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203589934318912		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.203589934318912 | validation: 1.2018449386649306]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0566532513326123		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.0566532513326123 | validation: 1.0313184062976442]
	TIME [epoch: 24.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1608743568326059		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.1608743568326059 | validation: 1.1395162598914832]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1882475914131645		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.1882475914131645 | validation: 1.2196560771636054]
	TIME [epoch: 24.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1909017744827608		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.1909017744827608 | validation: 0.932460207772202]
	TIME [epoch: 24.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0550114666703356		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.0550114666703356 | validation: 0.8135127846018597]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8898273432033701		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.8898273432033701 | validation: 0.8702696358925246]
	TIME [epoch: 24.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.452283231895315		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.452283231895315 | validation: 1.2744389203569293]
	TIME [epoch: 24.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1756069318875548		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.1756069318875548 | validation: 1.2428043734385705]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234465542194413		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.234465542194413 | validation: 1.0970032136984857]
	TIME [epoch: 24.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554168949117058		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.1554168949117058 | validation: 1.030404310122636]
	TIME [epoch: 24.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.017743537593674		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.017743537593674 | validation: 1.0288684977762188]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0856279410972063		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.0856279410972063 | validation: 0.871212261335728]
	TIME [epoch: 24.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9125058637148471		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.9125058637148471 | validation: 0.9683370553872968]
	TIME [epoch: 24.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9507853224720552		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.9507853224720552 | validation: 0.83378916783493]
	TIME [epoch: 24.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4463501070431892		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.4463501070431892 | validation: 1.307984709906467]
	TIME [epoch: 24.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032926568188137		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.032926568188137 | validation: 1.0210965459737193]
	TIME [epoch: 24.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249163174517506		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.0249163174517506 | validation: 0.7746384356065573]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9143927786149938		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.9143927786149938 | validation: 2.412664499502178]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.387327778931524		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.387327778931524 | validation: 1.341794801564943]
	TIME [epoch: 24.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9903719758901803		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.9903719758901803 | validation: 1.3393420958133546]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703519582982493		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.1703519582982493 | validation: 0.842560148795362]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9354431456172181		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.9354431456172181 | validation: 0.8769354680966277]
	TIME [epoch: 24.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.896609790319421		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.896609790319421 | validation: 0.9771311724065939]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9431629672177961		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.9431629672177961 | validation: 1.0497136815682768]
	TIME [epoch: 24.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8682736892812778		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.8682736892812778 | validation: 1.6582725033979215]
	TIME [epoch: 24.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1781753877662207		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.1781753877662207 | validation: 1.0265248698852512]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0412292155981242		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.0412292155981242 | validation: 1.7423990986834195]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1380900315897846		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.1380900315897846 | validation: 0.890521995928259]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9311726438831692		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.9311726438831692 | validation: 1.227756573807614]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9620657706380726		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.9620657706380726 | validation: 0.8605636804204775]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8050328461132987		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.8050328461132987 | validation: 0.8559431931755492]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9987266848040639		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.9987266848040639 | validation: 0.9582550511909901]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9465979627709024		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.9465979627709024 | validation: 0.7771801824895601]
	TIME [epoch: 24.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764713788702439		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7764713788702439 | validation: 0.7783654855291513]
	TIME [epoch: 24.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0400169171517801		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.0400169171517801 | validation: 0.8284457053159746]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1591387995096685		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.1591387995096685 | validation: 1.1735121317606438]
	TIME [epoch: 24.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0948743817932203		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.0948743817932203 | validation: 0.9660129007530597]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1926020194336777		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.1926020194336777 | validation: 1.1504741276133685]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077756611415798		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.0077756611415798 | validation: 1.1287020762497109]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212961873464782		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.8212961873464782 | validation: 0.708955011520665]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696807946229267		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.8696807946229267 | validation: 0.8815149469520149]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0301702659165912		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.0301702659165912 | validation: 1.3633133202677328]
	TIME [epoch: 24.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9864709901299755		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.9864709901299755 | validation: 0.6948473417754353]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862677024528893		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.862677024528893 | validation: 1.2125170416719746]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5877213301948627		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.5877213301948627 | validation: 0.7815208379264326]
	TIME [epoch: 24.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874048085773863		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.874048085773863 | validation: 0.805168463144266]
	TIME [epoch: 24.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2073655205392484		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.2073655205392484 | validation: 1.3837786926191709]
	TIME [epoch: 24.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0201705621282329		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.0201705621282329 | validation: 1.3527775704590972]
	TIME [epoch: 24.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.997860039716537		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.997860039716537 | validation: 0.709134157129096]
	TIME [epoch: 24.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862328180119925		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.7862328180119925 | validation: 0.7498404373977497]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8196317273362996		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.8196317273362996 | validation: 0.86404483938195]
	TIME [epoch: 24.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752171839373368		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.8752171839373368 | validation: 0.746812192225811]
	TIME [epoch: 24.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8477659797970272		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.8477659797970272 | validation: 0.8439795673967249]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9297197087580106		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.9297197087580106 | validation: 1.3411148651874794]
	TIME [epoch: 24.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4438925203766102		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.4438925203766102 | validation: 1.182569965165911]
	TIME [epoch: 24.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9526831944861078		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.9526831944861078 | validation: 0.7046050066225782]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8330192672978705		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8330192672978705 | validation: 0.738725952216748]
	TIME [epoch: 24.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085715070784318		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.8085715070784318 | validation: 0.8322062397564995]
	TIME [epoch: 24.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7515080826298428		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.7515080826298428 | validation: 0.8783759528620402]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750837451786288		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.750837451786288 | validation: 0.7219070920687409]
	TIME [epoch: 24.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7995082108104707		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.7995082108104707 | validation: 0.6610628577083796]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9255529840357495		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.9255529840357495 | validation: 1.3777952208082838]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1562648674309104		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1562648674309104 | validation: 0.8160853946489165]
	TIME [epoch: 24.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8163015266925536		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.8163015266925536 | validation: 1.6701310303711654]
	TIME [epoch: 24.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4490121610098936		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.4490121610098936 | validation: 2.04479074851284]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1756102075434214		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.1756102075434214 | validation: 0.6950125127160809]
	TIME [epoch: 24.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316259908457101		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7316259908457101 | validation: 0.9703201812970431]
	TIME [epoch: 24.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8592004389387502		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8592004389387502 | validation: 0.9764869031103195]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0475128180218096		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.0475128180218096 | validation: 1.2631134034309057]
	TIME [epoch: 24.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9311334590297782		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.9311334590297782 | validation: 0.7404376417722369]
	TIME [epoch: 24.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7516092324415505		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.7516092324415505 | validation: 0.6915969222617379]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77851786441257		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.77851786441257 | validation: 1.0508355209629745]
	TIME [epoch: 24.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005986035864078		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.8005986035864078 | validation: 0.8128590278472442]
	TIME [epoch: 24.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244802162944233		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.0244802162944233 | validation: 0.8393980030887513]
	TIME [epoch: 24.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771062850736666		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.7771062850736666 | validation: 1.0480126392525384]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1770298529614673		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.1770298529614673 | validation: 0.7834192266520927]
	TIME [epoch: 24.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0047820686050124		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.0047820686050124 | validation: 1.0216607763736751]
	TIME [epoch: 24.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9880659213422888		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.9880659213422888 | validation: 1.1335228399116921]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9319965684325524		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.9319965684325524 | validation: 1.4554367095833476]
	TIME [epoch: 24.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9823241601464875		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.9823241601464875 | validation: 0.8571659565352873]
	TIME [epoch: 24.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093147925475322		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.093147925475322 | validation: 1.3140473458436344]
	TIME [epoch: 24.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9038749809391		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.9038749809391 | validation: 0.7123675273844119]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555017787141739		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.8555017787141739 | validation: 1.4106913397883727]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573788500248184		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.9573788500248184 | validation: 0.7169491254934351]
	TIME [epoch: 24.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0001720886229575		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.0001720886229575 | validation: 0.884496720921905]
	TIME [epoch: 24.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0177532837907257		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.0177532837907257 | validation: 0.9873271548814845]
	TIME [epoch: 24.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275331112430433		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.275331112430433 | validation: 0.8520454914555652]
	TIME [epoch: 24.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.959927583990209		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.959927583990209 | validation: 0.6626895267244781]
	TIME [epoch: 24.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169968724844406		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8169968724844406 | validation: 1.041606338266996]
	TIME [epoch: 24.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721292666021813		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.8721292666021813 | validation: 0.643104260650696]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601559057071092		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.7601559057071092 | validation: 0.7887791759167717]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7965834179793808		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.7965834179793808 | validation: 0.8200721737176839]
	TIME [epoch: 24.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1021213538519339		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.1021213538519339 | validation: 0.923415209648137]
	TIME [epoch: 24.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.807255001408551		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.807255001408551 | validation: 0.9949284760936433]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9324318881167143		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.9324318881167143 | validation: 1.0621796204324547]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440794853738071		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.8440794853738071 | validation: 0.8700508059879062]
	TIME [epoch: 24.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243975537384191		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.7243975537384191 | validation: 1.223716901078546]
	TIME [epoch: 24.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9895723379008088		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.9895723379008088 | validation: 0.8416080165961376]
	TIME [epoch: 24.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657550712729893		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7657550712729893 | validation: 0.7806724550776708]
	TIME [epoch: 24.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1575114961561748		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.1575114961561748 | validation: 1.3035719311682794]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217645631531465		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.0217645631531465 | validation: 0.9099764132332238]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818448583228361		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.818448583228361 | validation: 0.7964220461752199]
	TIME [epoch: 24.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8156243476001697		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.8156243476001697 | validation: 0.7179356418372934]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9683526863355845		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.9683526863355845 | validation: 0.8180253416012788]
	TIME [epoch: 24.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8951139455516126		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.8951139455516126 | validation: 0.6975204980403686]
	TIME [epoch: 24.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673372565244462		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.8673372565244462 | validation: 0.6999296668469779]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677094677584039		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7677094677584039 | validation: 1.0437269793018673]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075652854924318		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.9075652854924318 | validation: 0.9196784188580057]
	TIME [epoch: 24.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234842138080651		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.234842138080651 | validation: 1.0170666024218735]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1155272526971984		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.1155272526971984 | validation: 0.8801891891166403]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160081758014416		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.160081758014416 | validation: 0.8395381929486604]
	TIME [epoch: 24.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7535877726186065		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7535877726186065 | validation: 0.9072863966618883]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461522615601631		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.7461522615601631 | validation: 0.8340723030787024]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718449155861545		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.718449155861545 | validation: 0.6301784967708831]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204258150539917		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7204258150539917 | validation: 1.0379664661735315]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679209493395773		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.7679209493395773 | validation: 0.7142453093706951]
	TIME [epoch: 24.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525947172000307		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6525947172000307 | validation: 0.7600527863155887]
	TIME [epoch: 24.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536200971315057		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6536200971315057 | validation: 0.7375978696986004]
	TIME [epoch: 24.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218677369407196		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.7218677369407196 | validation: 0.8849751975529918]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952903602044067		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6952903602044067 | validation: 1.091328423209133]
	TIME [epoch: 24.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544605788331028		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.7544605788331028 | validation: 0.6491851719627016]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8224048176646639		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.8224048176646639 | validation: 0.5542789499008861]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097551878797445		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.6097551878797445 | validation: 0.8423891686557111]
	TIME [epoch: 24.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721470607034687		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.721470607034687 | validation: 0.5389728808464697]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.770994488203184		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.770994488203184 | validation: 0.8214393508057777]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8818351797559955		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.8818351797559955 | validation: 0.9653171673027209]
	TIME [epoch: 24.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8197946670297949		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.8197946670297949 | validation: 0.817112320643219]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6380829219047954		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6380829219047954 | validation: 0.5742434601653179]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846420326724475		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.7846420326724475 | validation: 0.9475730025234422]
	TIME [epoch: 24.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877045814906015		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6877045814906015 | validation: 0.5946187335165075]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188280056379471		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.7188280056379471 | validation: 0.5662631021423529]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08558091271475		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.08558091271475 | validation: 0.6317115659432995]
	TIME [epoch: 24.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753932523240175		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6753932523240175 | validation: 0.8038248260962658]
	TIME [epoch: 24.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8293383637462761		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.8293383637462761 | validation: 0.7226608802930642]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635343686639594		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6635343686639594 | validation: 0.8144634323285647]
	TIME [epoch: 24.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7368993380108614		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.7368993380108614 | validation: 0.7003119373653133]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181386599428386		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.8181386599428386 | validation: 0.6888524088510135]
	TIME [epoch: 24.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.678551488026552		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.678551488026552 | validation: 0.5517252692800172]
	TIME [epoch: 24.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818022362112359		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.6818022362112359 | validation: 0.6453695761758327]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680301891303139		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6680301891303139 | validation: 0.8821005505662751]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189432175177908		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.7189432175177908 | validation: 0.8067687929867404]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313404443534915		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.7313404443534915 | validation: 0.7388503882036922]
	TIME [epoch: 24.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102279933675193		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.7102279933675193 | validation: 0.7996558008961232]
	TIME [epoch: 24.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0450405612208784		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.0450405612208784 | validation: 1.6689648859242658]
	TIME [epoch: 24.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8844057049190479		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.8844057049190479 | validation: 0.7449784852435059]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043379767101927		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.7043379767101927 | validation: 0.9694002750445432]
	TIME [epoch: 24.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779376990486762		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.6779376990486762 | validation: 0.7052927763820843]
	TIME [epoch: 24.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769264900319392		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6769264900319392 | validation: 0.6385629476249836]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645684228330339		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5645684228330339 | validation: 0.6147840564626896]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593590181981768		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6593590181981768 | validation: 0.8290739292778608]
	TIME [epoch: 24.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930365821955886		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.6930365821955886 | validation: 0.7748190770596588]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7096139909443699		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.7096139909443699 | validation: 0.6691191053302481]
	TIME [epoch: 24.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996381263577558		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6996381263577558 | validation: 1.4184063916679042]
	TIME [epoch: 24.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9409545294671142		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.9409545294671142 | validation: 0.5396665406752582]
	TIME [epoch: 24.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744076569229498		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7744076569229498 | validation: 0.7172158755409496]
	TIME [epoch: 24.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021929759812248		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6021929759812248 | validation: 0.6191780241457747]
	TIME [epoch: 24.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026343800844566		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6026343800844566 | validation: 0.5818779240980504]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908234286055227		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.5908234286055227 | validation: 0.6283028479647504]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335853151054271		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6335853151054271 | validation: 0.6447729831440714]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846960249183479		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.5846960249183479 | validation: 0.5802138038577168]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6572310096270723		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.6572310096270723 | validation: 0.6067397577232948]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554042630307427		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6554042630307427 | validation: 0.6737889027635785]
	TIME [epoch: 24.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931510197497945		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6931510197497945 | validation: 0.7019631177839223]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451474184890135		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.6451474184890135 | validation: 0.6171157196034402]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690147333503992		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5690147333503992 | validation: 1.0215222083303406]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8045097630530843		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.8045097630530843 | validation: 0.5775948728052158]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559397816023866		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5559397816023866 | validation: 0.6909656729325891]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780050481410154		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5780050481410154 | validation: 0.8834087044463528]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0887210248586698		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.0887210248586698 | validation: 0.9348338248159017]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095411213061922		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.7095411213061922 | validation: 0.5878528864853914]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7017099362984587		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.7017099362984587 | validation: 0.8214973196885944]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8498416559569475		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.8498416559569475 | validation: 0.7995130577196568]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0650749338716303		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.0650749338716303 | validation: 0.8410994299433364]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8769351849020762		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.8769351849020762 | validation: 0.7735874760868263]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9414184286990135		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.9414184286990135 | validation: 0.6698891826560986]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8784321784464486		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.8784321784464486 | validation: 1.8123180482918633]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9475469733400447		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.9475469733400447 | validation: 0.6828983635075129]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091599357012642		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.7091599357012642 | validation: 0.5719203452370856]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6233762374134568		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.6233762374134568 | validation: 0.5997706141128426]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609670579593404		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5609670579593404 | validation: 0.5134935406105869]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5784261238401935		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5784261238401935 | validation: 0.7400118461532053]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532455139826283		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.7532455139826283 | validation: 0.6323365960839977]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034365913603953		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.7034365913603953 | validation: 1.0005061701075375]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6531511473691576		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.6531511473691576 | validation: 0.6241238761980136]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936705088314177		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5936705088314177 | validation: 1.0289673646162032]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369172826281704		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.7369172826281704 | validation: 0.5151479051343338]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667333774582481		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5667333774582481 | validation: 0.6020480846535624]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757165767423317		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5757165767423317 | validation: 1.1684275060769413]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130160888369392		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.7130160888369392 | validation: 0.5743874910996819]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422280921852483		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.6422280921852483 | validation: 0.5867157701178786]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965676572789536		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5965676572789536 | validation: 0.5726399395401826]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976293100956032		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5976293100956032 | validation: 0.6421641710559414]
	TIME [epoch: 24.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164273115944154		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.7164273115944154 | validation: 1.4809424685027164]
	TIME [epoch: 24.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8775397538938978		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.8775397538938978 | validation: 0.7578163698896923]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697713255155364		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.697713255155364 | validation: 0.6034859102088534]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256767033758941		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6256767033758941 | validation: 0.6792042306722726]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916107952582143		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.6916107952582143 | validation: 0.682322911685394]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5783129907165178		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5783129907165178 | validation: 0.7823622655768769]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588405299527273		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6588405299527273 | validation: 0.6036799975248863]
	TIME [epoch: 24.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369276309366231		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.6369276309366231 | validation: 0.827013965325233]
	TIME [epoch: 24.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194741154748518		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.7194741154748518 | validation: 0.8369427972631354]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65539778331688		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.65539778331688 | validation: 0.8630378203590553]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163657401856077		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.6163657401856077 | validation: 0.8296685210060467]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9309567444010385		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.9309567444010385 | validation: 0.8401865854088104]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775518059977149		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.6775518059977149 | validation: 0.6218631120064724]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200783563460339		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.6200783563460339 | validation: 1.9428808887165054]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1678730890445974		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.1678730890445974 | validation: 0.6220138058580856]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.593287143427266		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.593287143427266 | validation: 0.532198086030275]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314170730979746		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5314170730979746 | validation: 0.5620641110979123]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5670630926785585		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5670630926785585 | validation: 0.573577077861331]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6521044820817306		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.6521044820817306 | validation: 0.7693786254545734]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220855238882566		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.7220855238882566 | validation: 0.9329115248207924]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171120026971214		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7171120026971214 | validation: 0.584754125820571]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010704757747379		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.6010704757747379 | validation: 0.5324665555378784]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682302570981829		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5682302570981829 | validation: 0.5815790085465481]
	TIME [epoch: 24.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949993960011298		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5949993960011298 | validation: 0.5936793576908153]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396530467300798		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.6396530467300798 | validation: 0.5342629666303199]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369759379855961		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5369759379855961 | validation: 0.5693511437712208]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5861115249276613		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.5861115249276613 | validation: 0.5920483170844237]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295834179385249		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.6295834179385249 | validation: 1.3135087725556733]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9223067537776934		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.9223067537776934 | validation: 0.8801434848057715]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528895045014716		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.7528895045014716 | validation: 0.5707345019564136]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5765800056106737		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5765800056106737 | validation: 0.6295286532818731]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054621341066527		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6054621341066527 | validation: 0.5705513019584498]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.628560136537604		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.628560136537604 | validation: 0.5569596733269166]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524119945293853		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.6524119945293853 | validation: 0.6714073713311115]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616940430877783		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.616940430877783 | validation: 0.9476886110681537]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107710154844254		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.8107710154844254 | validation: 0.5204521737893159]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402596744536222		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5402596744536222 | validation: 0.6221721433154045]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204624183948598		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6204624183948598 | validation: 0.5692088117910342]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6050740191776669		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.6050740191776669 | validation: 0.7821431235408559]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893441856117393		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6893441856117393 | validation: 0.5391874095958745]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543713456065712		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.6543713456065712 | validation: 0.8195462023270025]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107548270901759		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6107548270901759 | validation: 0.5786391147499307]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49117738076229384		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.49117738076229384 | validation: 0.6232654631367526]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576503298874758		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.576503298874758 | validation: 0.5478735589421748]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.618838788821459		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.618838788821459 | validation: 0.5434181095059699]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480789029921265		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5480789029921265 | validation: 0.6227220283631288]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196625588118073		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.7196625588118073 | validation: 0.5970462996948014]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619699783292474		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5619699783292474 | validation: 0.5606409465894749]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378910252232818		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5378910252232818 | validation: 0.6823340735290334]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862304692590883		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5862304692590883 | validation: 0.6072786361593463]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279419500296063		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5279419500296063 | validation: 0.5707615715526724]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316935508615787		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.7316935508615787 | validation: 0.6476294474389414]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038962937527226		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6038962937527226 | validation: 0.6353615527121668]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9137560048752573		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.9137560048752573 | validation: 0.6698839599099623]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6143023897780615		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6143023897780615 | validation: 0.6145455892864596]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126517047891447		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.6126517047891447 | validation: 0.6065731202769764]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173631564290408		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.8173631564290408 | validation: 0.7710255614719391]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722144941085625		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5722144941085625 | validation: 0.6166358689694466]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758560679302003		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5758560679302003 | validation: 0.592828567306694]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159110949877941		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5159110949877941 | validation: 0.5020651795987147]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47419978653298295		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.47419978653298295 | validation: 0.5007237258524133]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47544862334726323		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.47544862334726323 | validation: 0.6573362842191982]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685776016541879		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.6685776016541879 | validation: 0.6832776346584832]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964200949269596		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5964200949269596 | validation: 0.7519799752432877]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912040199151459		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5912040199151459 | validation: 0.6312501437807617]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548443462175234		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.6548443462175234 | validation: 0.5214307286258603]
	TIME [epoch: 25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525752880034949		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.525752880034949 | validation: 0.556545065400079]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268031208417707		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5268031208417707 | validation: 0.8897808750136804]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6703251661655748		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.6703251661655748 | validation: 0.8223512181339482]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6386102018120633		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.6386102018120633 | validation: 0.5866333175651705]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126802442210865		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.5126802442210865 | validation: 0.5811295603631836]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347919632770367		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5347919632770367 | validation: 0.500248424023724]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5679427015063462		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5679427015063462 | validation: 0.5253396645595666]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234448479305931		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5234448479305931 | validation: 0.5207748692422716]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435336384627787		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5435336384627787 | validation: 0.5706480773652672]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826713819444631		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.6826713819444631 | validation: 0.560286310548186]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531602949756574		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.531602949756574 | validation: 0.633170333682638]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5500934908253087		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.5500934908253087 | validation: 0.5444175893782904]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100310904775498		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.6100310904775498 | validation: 0.5741008445445659]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559850914157433		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5559850914157433 | validation: 1.0209916891458242]
	TIME [epoch: 24.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7864501754423903		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.7864501754423903 | validation: 0.6549396253708025]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5634453944629088		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.5634453944629088 | validation: 0.5013234404290939]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075679157688035		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.6075679157688035 | validation: 0.5596255475503756]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069380355642231		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5069380355642231 | validation: 0.6173761070112457]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260257369119316		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6260257369119316 | validation: 0.7497731838174317]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6434672109761151		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.6434672109761151 | validation: 0.5528480616040327]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724956368752191		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5724956368752191 | validation: 0.7589756070580647]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653483949681704		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.653483949681704 | validation: 0.5140583273311629]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390081298836721		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6390081298836721 | validation: 0.47751181707113305]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_729.pth
	Model improved!!!
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5719831347243967		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5719831347243967 | validation: 0.7751461717787905]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8783951084725656		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.8783951084725656 | validation: 0.7397004480334902]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582841059624998		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.6582841059624998 | validation: 0.5542119344494081]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.646406004182372		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.646406004182372 | validation: 0.7797159367687831]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829078033069675		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.6829078033069675 | validation: 1.031341402542546]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8278720703916289		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.8278720703916289 | validation: 0.6010441197846653]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917249526131033		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5917249526131033 | validation: 0.5607561537723441]
	TIME [epoch: 24.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49105704080715795		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.49105704080715795 | validation: 0.4695223678444496]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6288729062258098		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.6288729062258098 | validation: 0.585436845470695]
	TIME [epoch: 24.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928382227974017		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5928382227974017 | validation: 0.6482344573888357]
	TIME [epoch: 24.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130709277102815		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5130709277102815 | validation: 0.5380195200181279]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6343769447797155		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.6343769447797155 | validation: 0.6438997860073855]
	TIME [epoch: 24.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.837224823567002		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.837224823567002 | validation: 0.7606721258832666]
	TIME [epoch: 24.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246062983244369		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.7246062983244369 | validation: 0.6969164183775806]
	TIME [epoch: 24.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694633262782308		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.694633262782308 | validation: 0.5349238398120127]
	TIME [epoch: 24.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7308267409879622		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.7308267409879622 | validation: 0.5581633862667922]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542511356043297		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.5542511356043297 | validation: 0.4952912712587493]
	TIME [epoch: 24.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503004114067703		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.503004114067703 | validation: 0.7109197099224422]
	TIME [epoch: 24.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6247458947750003		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.6247458947750003 | validation: 0.6940726006123066]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956585974773963		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.6956585974773963 | validation: 0.8420097954423075]
	TIME [epoch: 24.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7379720001324159		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.7379720001324159 | validation: 0.8385273378976829]
	TIME [epoch: 24.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548303522299929		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.548303522299929 | validation: 0.6434984514655174]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632535583841005		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5632535583841005 | validation: 0.5213881877134602]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876976226574953		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4876976226574953 | validation: 0.7162596022131977]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7122442367757018		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.7122442367757018 | validation: 0.5932360200142074]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563646626676872		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.563646626676872 | validation: 0.6237335836057113]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032972565636695		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5032972565636695 | validation: 0.5293476811020176]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260179652348978		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6260179652348978 | validation: 0.6055436071681223]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035462771052326		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5035462771052326 | validation: 0.5710774244987552]
	TIME [epoch: 24.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49711444871274646		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.49711444871274646 | validation: 0.7268753221580282]
	TIME [epoch: 24.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520656647122106		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5520656647122106 | validation: 0.4909065272934284]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542887426918159		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.542887426918159 | validation: 0.5724090755034971]
	TIME [epoch: 24.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205777295316686		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5205777295316686 | validation: 0.5163049340324369]
	TIME [epoch: 24.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030066294483455		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5030066294483455 | validation: 0.5724511703986641]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49354751537596064		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.49354751537596064 | validation: 0.5878156373401615]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5233595080099882		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5233595080099882 | validation: 0.52023667714146]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948474343584307		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5948474343584307 | validation: 0.672584968895915]
	TIME [epoch: 24.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5745903332674829		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.5745903332674829 | validation: 0.7868995363684542]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815276272460709		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5815276272460709 | validation: 0.5798552120495922]
	TIME [epoch: 24.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565683571605472		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.565683571605472 | validation: 0.46166845396082096]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554997929553919		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.554997929553919 | validation: 0.5259113641496194]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204309555104908		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.5204309555104908 | validation: 0.48452869239635477]
	TIME [epoch: 24.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4601094400239021		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4601094400239021 | validation: 0.4766948168664359]
	TIME [epoch: 24.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47522695741353677		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.47522695741353677 | validation: 0.7078401696535989]
	TIME [epoch: 24.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874256604080904		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.6874256604080904 | validation: 0.6536012208069523]
	TIME [epoch: 24.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208315879508723		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5208315879508723 | validation: 0.5717255415147849]
	TIME [epoch: 24.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516123669100894		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.516123669100894 | validation: 0.5911172051448266]
	TIME [epoch: 24.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48041203969278834		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.48041203969278834 | validation: 0.5762379249710387]
	TIME [epoch: 24.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180293792630328		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5180293792630328 | validation: 0.704717046190524]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330613932882209		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.5330613932882209 | validation: 0.5422258510574985]
	TIME [epoch: 24.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900814787754199		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4900814787754199 | validation: 0.5173864126440018]
	TIME [epoch: 24.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45837358284482643		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.45837358284482643 | validation: 0.5176237661658218]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072780933095415		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5072780933095415 | validation: 0.48326130859152644]
	TIME [epoch: 24.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48168180956144563		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.48168180956144563 | validation: 0.5271952581055714]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4858819564264143		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.4858819564264143 | validation: 0.49483314762647385]
	TIME [epoch: 24.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883177671926249		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4883177671926249 | validation: 0.7605748512730945]
	TIME [epoch: 24.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835810062884819		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.5835810062884819 | validation: 0.4848826456123353]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5717072233296705		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5717072233296705 | validation: 0.5205437499602382]
	TIME [epoch: 24.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5988159667537704		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5988159667537704 | validation: 0.8373855966327776]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497323393557758		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5497323393557758 | validation: 0.540928422800818]
	TIME [epoch: 24.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378042231735068		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.5378042231735068 | validation: 0.5605514812886907]
	TIME [epoch: 24.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351455289707272		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.5351455289707272 | validation: 0.5678880469639858]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181360574859581		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.5181360574859581 | validation: 0.49188362492827004]
	TIME [epoch: 24.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865197487582544		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4865197487582544 | validation: 0.5011580515157386]
	TIME [epoch: 24.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045431762411424		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5045431762411424 | validation: 0.49301103346454556]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45996351905592014		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.45996351905592014 | validation: 0.9585461570294718]
	TIME [epoch: 24.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924588856729179		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.6924588856729179 | validation: 0.542725575818922]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45218317533125696		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.45218317533125696 | validation: 0.46236966855863143]
	TIME [epoch: 24.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025613152448265		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.5025613152448265 | validation: 0.466351330150139]
	TIME [epoch: 24.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49751960174615856		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.49751960174615856 | validation: 0.9428783933427711]
	TIME [epoch: 24.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612549797293831		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.612549797293831 | validation: 0.9184077244344485]
	TIME [epoch: 24.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.64101658455528		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.64101658455528 | validation: 0.6116046607780808]
	TIME [epoch: 24.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5706392567369563		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5706392567369563 | validation: 0.5792436256205737]
	TIME [epoch: 24.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5671887554054137		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.5671887554054137 | validation: 0.5467557834956172]
	TIME [epoch: 24.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324623888075004		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.5324623888075004 | validation: 0.5811319854911862]
	TIME [epoch: 24.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076896340817133		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.5076896340817133 | validation: 0.5310177312626972]
	TIME [epoch: 24.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526453354007933		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4526453354007933 | validation: 0.6531447923194935]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052623044285773		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5052623044285773 | validation: 0.6135905813671932]
	TIME [epoch: 24.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627142239572312		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.627142239572312 | validation: 0.6034267596984166]
	TIME [epoch: 24.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594510566109173		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.6594510566109173 | validation: 0.6994370802796608]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6698412713868884		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.6698412713868884 | validation: 0.6937391765168605]
	TIME [epoch: 24.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672427261507663		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.672427261507663 | validation: 0.7506867812447177]
	TIME [epoch: 24.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115169262052429		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6115169262052429 | validation: 0.5969606635263303]
	TIME [epoch: 24.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168545697448979		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.5168545697448979 | validation: 1.1600653523474185]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290797877203626		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.7290797877203626 | validation: 0.45096193541034235]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44494780711571247		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.44494780711571247 | validation: 0.47097322255098506]
	TIME [epoch: 24.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750856298595138		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.4750856298595138 | validation: 0.5055269128845464]
	TIME [epoch: 24.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4579361244170752		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4579361244170752 | validation: 0.47073971734646114]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375783543041858		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4375783543041858 | validation: 0.4848324698865015]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4854317224472944		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4854317224472944 | validation: 0.5706874631847364]
	TIME [epoch: 24.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007717955915328		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.5007717955915328 | validation: 0.5420108640792257]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429439586369642		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5429439586369642 | validation: 0.5977903632665976]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5601342494092975		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.5601342494092975 | validation: 0.5493756917180671]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567706241134592		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.567706241134592 | validation: 1.1190833815552677]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9958527703330661		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.9958527703330661 | validation: 0.5943082760885181]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5535673379327773		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.5535673379327773 | validation: 0.5511609151322808]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641234626700173		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.5641234626700173 | validation: 0.5748704020173199]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5362483347390199		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.5362483347390199 | validation: 0.5428707749570745]
	TIME [epoch: 24.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4755672771139942		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.4755672771139942 | validation: 0.5449465452779466]
	TIME [epoch: 24.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629830656002214		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.4629830656002214 | validation: 0.4757341649498807]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499088256530712		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.5499088256530712 | validation: 0.6077518049126163]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5701028047715643		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.5701028047715643 | validation: 0.885986085100701]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295654795413533		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.6295654795413533 | validation: 0.49479039597147]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034839216849869		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5034839216849869 | validation: 0.4757087186943336]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.477723097162325		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.477723097162325 | validation: 0.5226322609044322]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44839472475259295		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.44839472475259295 | validation: 0.5045933292223574]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415412035290902		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4415412035290902 | validation: 0.6677761939394966]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116570190247287		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.5116570190247287 | validation: 0.4957385785344628]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454433516018689		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.454433516018689 | validation: 0.4670004271310282]
	TIME [epoch: 24.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178875839261825		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.5178875839261825 | validation: 0.4969732115599635]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992792130618275		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.4992792130618275 | validation: 0.5634357021154535]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318322258606836		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.5318322258606836 | validation: 0.5158800443625299]
	TIME [epoch: 24.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4714555831969557		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.4714555831969557 | validation: 0.49055644481102945]
	TIME [epoch: 24.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4725996278202829		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4725996278202829 | validation: 0.4942528416034722]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104896513912366		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.5104896513912366 | validation: 0.602303336679077]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49134076077970246		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.49134076077970246 | validation: 0.5444638216927815]
	TIME [epoch: 24.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676996180297753		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.5676996180297753 | validation: 0.7770976438157624]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739372584250403		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.5739372584250403 | validation: 0.49580978622131733]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44701724952870386		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.44701724952870386 | validation: 0.48519573557286894]
	TIME [epoch: 24.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068830739856487		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.5068830739856487 | validation: 0.4644994094238797]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46068430203575383		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.46068430203575383 | validation: 0.4464105678674077]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240309_135650/states/model_tr_study5_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4784667775025989		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4784667775025989 | validation: 0.46261769416874843]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49308406494387574		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.49308406494387574 | validation: 0.6594891854751863]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155588100255082		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.5155588100255082 | validation: 0.49109136466891634]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4192759863753647		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4192759863753647 | validation: 0.46852840701710846]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43165285804515874		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.43165285804515874 | validation: 0.5677165116136025]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4801566636038014		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.4801566636038014 | validation: 0.5507466488542433]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.581087514669216		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.581087514669216 | validation: 0.5710080710317278]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108516477039212		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.5108516477039212 | validation: 0.5899050062689223]
	TIME [epoch: 24.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5727441989398764		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5727441989398764 | validation: 0.8279771062076925]
	TIME [epoch: 24.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661829862211723		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.6661829862211723 | validation: 0.7933094125127335]
	TIME [epoch: 24.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6511977049634549		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.6511977049634549 | validation: 0.600274884042237]
	TIME [epoch: 24.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638558478668443		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.5638558478668443 | validation: 0.6054573783622679]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796694151167753		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.5796694151167753 | validation: 0.4935204683915887]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48630713308088275		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.48630713308088275 | validation: 0.5360394653723981]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47141299159532557		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.47141299159532557 | validation: 0.4531242141817757]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45389438967163975		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.45389438967163975 | validation: 0.741958056830201]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273062694242026		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.5273062694242026 | validation: 0.46685063035225793]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4463521423234423		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4463521423234423 | validation: 0.5378469492660127]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48336386972591494		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.48336386972591494 | validation: 0.5961564264270348]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449860219461321		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.5449860219461321 | validation: 0.5885181719879332]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772859660025775		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4772859660025775 | validation: 0.5861871743875291]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955611792233112		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.4955611792233112 | validation: 0.6250946409108922]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5498232668351302		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.5498232668351302 | validation: 0.5962838520912911]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397024367863308		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.6397024367863308 | validation: 0.8677375906471372]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.670175992940798		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.670175992940798 | validation: 0.6591638877483307]
	TIME [epoch: 24.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5073036601727048		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.5073036601727048 | validation: 0.6921970376628173]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230324239472154		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.5230324239472154 | validation: 0.601459330671977]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
