Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3490986526

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 11.2818614651938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.2818614651938 | validation: 10.728006017333197]
	TIME [epoch: 49.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 10.772523094602144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.772523094602144 | validation: 10.514614520885253]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 10.36689233138484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.36689233138484 | validation: 10.03213181559289]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 9.708897818746678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.708897818746678 | validation: 10.544741441003016]
	TIME [epoch: 10.4 sec]
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 9.297090081200079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.297090081200079 | validation: 9.285186962413958]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 8.691823899452565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.691823899452565 | validation: 9.353935441060386]
	TIME [epoch: 10.4 sec]
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 8.482089634663962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.482089634663962 | validation: 8.751081628293512]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 7.9135559123151795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.9135559123151795 | validation: 8.454818461884383]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 7.64524537884688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.64524537884688 | validation: 8.446267758266108]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 7.677246874844324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.677246874844324 | validation: 8.085857115751548]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 7.372236933126049		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 7.372236933126049 | validation: 7.784948691746872]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 7.804496976458319		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 7.804496976458319 | validation: 7.838850586052703]
	TIME [epoch: 10.4 sec]
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 7.355789300188034		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 7.355789300188034 | validation: 7.538322091795985]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 6.887668003100835		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 6.887668003100835 | validation: 7.012003752948581]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 6.840555295194636		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 6.840555295194636 | validation: 7.363004677946009]
	TIME [epoch: 10.4 sec]
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 6.7710814460482		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 6.7710814460482 | validation: 6.499997242211134]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 6.778300745511919		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 6.778300745511919 | validation: 10.340431440075445]
	TIME [epoch: 10.4 sec]
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 9.153762860753563		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 9.153762860753563 | validation: 7.026297767984454]
	TIME [epoch: 10.4 sec]
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 6.618518115415722		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 6.618518115415722 | validation: 6.581504056533096]
	TIME [epoch: 10.4 sec]
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 6.439240800033535		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 6.439240800033535 | validation: 6.465203358983367]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 6.358482844449441		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 6.358482844449441 | validation: 6.269890539222252]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 6.308421410524911		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 6.308421410524911 | validation: 6.412032024104669]
	TIME [epoch: 10.4 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 6.178571711128159		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 6.178571711128159 | validation: 6.661473372896603]
	TIME [epoch: 10.4 sec]
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 6.938137462511676		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 6.938137462511676 | validation: 6.83095119539209]
	TIME [epoch: 10.4 sec]
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 6.541501706302976		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 6.541501706302976 | validation: 6.245792668408439]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 6.116065861492662		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 6.116065861492662 | validation: 6.359058189951837]
	TIME [epoch: 10.4 sec]
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 6.115351516651782		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 6.115351516651782 | validation: 6.199225602151783]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 5.995950073243479		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 5.995950073243479 | validation: 6.12859884683997]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 5.888275241120115		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 5.888275241120115 | validation: 6.027523351823982]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 5.887236855167204		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 5.887236855167204 | validation: 6.015507686104536]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 5.8190103872234165		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 5.8190103872234165 | validation: 5.936058364134899]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 5.8205220574812175		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 5.8205220574812175 | validation: 6.063516480053611]
	TIME [epoch: 10.4 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 6.006007290015402		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 6.006007290015402 | validation: 6.036927970434983]
	TIME [epoch: 10.4 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 5.830948589248406		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 5.830948589248406 | validation: 5.831872906486035]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 5.825424848461897		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 5.825424848461897 | validation: 5.956302651029187]
	TIME [epoch: 10.4 sec]
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 5.848277051467425		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 5.848277051467425 | validation: 5.979250950638527]
	TIME [epoch: 10.4 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9542721438325925		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 5.9542721438325925 | validation: 5.7666337529649745]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 6.281633457795438		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 6.281633457795438 | validation: 5.78844732612961]
	TIME [epoch: 10.4 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 5.682707130478671		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 5.682707130478671 | validation: 5.807272007002705]
	TIME [epoch: 10.4 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 5.6517091511552335		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 5.6517091511552335 | validation: 5.828366191381947]
	TIME [epoch: 10.4 sec]
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 5.625548598422431		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 5.625548598422431 | validation: 6.4032292260866575]
	TIME [epoch: 10.4 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 8.526825483238312		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 8.526825483238312 | validation: 8.797382376004933]
	TIME [epoch: 10.4 sec]
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 6.535940615520292		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 6.535940615520292 | validation: 6.0001318586564985]
	TIME [epoch: 10.4 sec]
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 6.0765068109069365		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 6.0765068109069365 | validation: 6.0128354421127845]
	TIME [epoch: 10.4 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 5.928122844632854		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 5.928122844632854 | validation: 6.099832368148022]
	TIME [epoch: 10.4 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 5.757635912403434		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 5.757635912403434 | validation: 5.760197527698489]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 5.756526773399569		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 5.756526773399569 | validation: 5.729649085665805]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 5.784736899717996		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 5.784736899717996 | validation: 6.131016509434268]
	TIME [epoch: 10.4 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 5.843299588629527		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 5.843299588629527 | validation: 5.927773176056]
	TIME [epoch: 10.4 sec]
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 5.922405339943434		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 5.922405339943434 | validation: 5.806532290564734]
	TIME [epoch: 10.4 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 5.75433750231023		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 5.75433750231023 | validation: 5.515451701944337]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 5.72331413313124		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 5.72331413313124 | validation: 6.171881926762239]
	TIME [epoch: 10.4 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 6.179633186821532		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 6.179633186821532 | validation: 5.756363630053238]
	TIME [epoch: 10.4 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 5.581956237609935		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 5.581956237609935 | validation: 5.994028260037424]
	TIME [epoch: 10.4 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 5.612997409332687		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 5.612997409332687 | validation: 6.000821301568644]
	TIME [epoch: 10.4 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 5.583720971747569		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 5.583720971747569 | validation: 5.621947534796362]
	TIME [epoch: 10.4 sec]
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 5.33825846115134		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 5.33825846115134 | validation: 5.61107512487438]
	TIME [epoch: 10.4 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 6.912903576272408		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 6.912903576272408 | validation: 7.3827609668899346]
	TIME [epoch: 10.4 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 5.91166897781868		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 5.91166897781868 | validation: 5.504470290937173]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 5.506480035941758		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 5.506480035941758 | validation: 5.610706829615626]
	TIME [epoch: 10.4 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 5.62377871416311		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 5.62377871416311 | validation: 6.17132366394388]
	TIME [epoch: 10.4 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 5.514836596414802		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 5.514836596414802 | validation: 5.328869111061404]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 5.334997551096263		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 5.334997551096263 | validation: 5.278921801611477]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 5.031970617234356		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 5.031970617234356 | validation: 4.919299451074789]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 5.321410546256826		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 5.321410546256826 | validation: 4.733807563048339]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 4.666379249975127		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 4.666379249975127 | validation: 4.6711398059177025]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 5.103716921605408		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 5.103716921605408 | validation: 4.635888030728404]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 5.038952571821276		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 5.038952571821276 | validation: 5.5021386213570755]
	TIME [epoch: 10.4 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 5.43076309975318		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 5.43076309975318 | validation: 5.308125079725058]
	TIME [epoch: 10.4 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 4.929348521403379		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 4.929348521403379 | validation: 4.606791238031681]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 4.581731217273122		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 4.581731217273122 | validation: 4.7446139037465045]
	TIME [epoch: 10.4 sec]
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 5.427292761601204		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 5.427292761601204 | validation: 5.219164047464587]
	TIME [epoch: 10.4 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 5.108334173763981		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 5.108334173763981 | validation: 6.108452089584414]
	TIME [epoch: 10.4 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 4.890844074788609		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 4.890844074788609 | validation: 4.381200443957921]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 4.2273257685796795		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 4.2273257685796795 | validation: 4.913961855310958]
	TIME [epoch: 10.4 sec]
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 4.323662539283916		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 4.323662539283916 | validation: 4.516091242795847]
	TIME [epoch: 10.4 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 4.965294550401758		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 4.965294550401758 | validation: 6.259006385059681]
	TIME [epoch: 10.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 6.186345623076404		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 6.186345623076404 | validation: 7.323885487443419]
	TIME [epoch: 10.4 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 5.985477934369932		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 5.985477934369932 | validation: 4.541310749053591]
	TIME [epoch: 10.4 sec]
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 6.7225084250444755		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 6.7225084250444755 | validation: 6.7519671782205455]
	TIME [epoch: 10.4 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 5.405201156031788		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 5.405201156031788 | validation: 4.440304842731959]
	TIME [epoch: 10.4 sec]
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 4.350881373099191		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 4.350881373099191 | validation: 4.506697212320433]
	TIME [epoch: 10.4 sec]
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 4.372375965018188		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 4.372375965018188 | validation: 4.246188919846978]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 4.157730158367756		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 4.157730158367756 | validation: 4.102567836032669]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 5.052708110374694		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 5.052708110374694 | validation: 7.486919583045884]
	TIME [epoch: 10.4 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 6.0046975297286185		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 6.0046975297286185 | validation: 4.388752152789964]
	TIME [epoch: 10.4 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 4.2762439962527665		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 4.2762439962527665 | validation: 4.146320319470806]
	TIME [epoch: 10.4 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 4.7783796604412085		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 4.7783796604412085 | validation: 5.17017463818356]
	TIME [epoch: 10.4 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 4.5538131072155865		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 4.5538131072155865 | validation: 3.9999353598801486]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 4.075499141791452		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 4.075499141791452 | validation: 3.878357327210597]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 3.921426453760676		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 3.921426453760676 | validation: 3.8049516876979306]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8666825391069524		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 3.8666825391069524 | validation: 4.518624984073291]
	TIME [epoch: 10.4 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8142653011329792		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 3.8142653011329792 | validation: 3.5751164952752252]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6849564915645723		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 3.6849564915645723 | validation: 4.771449273591828]
	TIME [epoch: 10.4 sec]
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 3.945469864018908		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 3.945469864018908 | validation: 3.783396230072709]
	TIME [epoch: 10.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7595338159031675		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 3.7595338159031675 | validation: 4.020707597546109]
	TIME [epoch: 10.4 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 4.871585198045214		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 4.871585198045214 | validation: 4.180016240764035]
	TIME [epoch: 10.4 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6325230894709457		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 3.6325230894709457 | validation: 4.44364972124267]
	TIME [epoch: 10.4 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 4.220864302972228		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 4.220864302972228 | validation: 4.116054486679493]
	TIME [epoch: 10.4 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 3.748170561333133		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 3.748170561333133 | validation: 3.5870342950623137]
	TIME [epoch: 10.4 sec]
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8545080771885383		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 3.8545080771885383 | validation: 4.111320952907074]
	TIME [epoch: 10.4 sec]
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5964584901406327		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 3.5964584901406327 | validation: 3.775383043007463]
	TIME [epoch: 10.4 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4012672589093866		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 3.4012672589093866 | validation: 3.72260470329113]
	TIME [epoch: 10.4 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5735872698264792		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 3.5735872698264792 | validation: 3.4967864310580694]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 3.334026399377233		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 3.334026399377233 | validation: 3.2143129441294116]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3243259629818276		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 3.3243259629818276 | validation: 3.5399499284926437]
	TIME [epoch: 10.4 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 3.329652592797172		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 3.329652592797172 | validation: 3.367877685085917]
	TIME [epoch: 10.4 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 3.024749081019711		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 3.024749081019711 | validation: 3.1506093599583482]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 3.747506113583765		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 3.747506113583765 | validation: 4.002848303577883]
	TIME [epoch: 10.4 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 3.919704557441785		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 3.919704557441785 | validation: 2.9671190815706137]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0959087607682796		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 3.0959087607682796 | validation: 3.0365393557911156]
	TIME [epoch: 10.4 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1613880732913997		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 3.1613880732913997 | validation: 3.396159444774298]
	TIME [epoch: 10.4 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 3.155313421285148		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 3.155313421285148 | validation: 2.78959133069299]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 2.939339105435908		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 2.939339105435908 | validation: 2.861819878555215]
	TIME [epoch: 10.4 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 2.778427441339743		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 2.778427441339743 | validation: 2.996659919067629]
	TIME [epoch: 10.4 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 2.736797727561243		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 2.736797727561243 | validation: 2.789608090524218]
	TIME [epoch: 10.4 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7920000332234785		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 2.7920000332234785 | validation: 2.881296594616174]
	TIME [epoch: 10.4 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6263379324608547		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 2.6263379324608547 | validation: 3.125902167170951]
	TIME [epoch: 10.4 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 2.880858440222864		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 2.880858440222864 | validation: 2.735899357662481]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6636098290854155		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 2.6636098290854155 | validation: 2.468652753403919]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_120.pth
	Model improved!!!
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4811054054542008		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 2.4811054054542008 | validation: 2.465501935343063]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6068758798166023		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 2.6068758798166023 | validation: 2.512972604853912]
	TIME [epoch: 10.4 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4534102681202032		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 2.4534102681202032 | validation: 2.251122209711338]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_123.pth
	Model improved!!!
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 2.412788346977885		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 2.412788346977885 | validation: 2.4045111743099343]
	TIME [epoch: 10.4 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6359827503535995		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 2.6359827503535995 | validation: 2.947144333122355]
	TIME [epoch: 10.4 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 2.552951124508115		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 2.552951124508115 | validation: 2.300986632630088]
	TIME [epoch: 10.4 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2514751375394764		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 2.2514751375394764 | validation: 2.1677330653212326]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7259160995086567		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 2.7259160995086567 | validation: 2.5850503812612455]
	TIME [epoch: 10.4 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2615798602830304		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 2.2615798602830304 | validation: 2.275047616371015]
	TIME [epoch: 10.4 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 2.181032277225743		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 2.181032277225743 | validation: 2.661061851090551]
	TIME [epoch: 10.4 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7075865347721573		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 2.7075865347721573 | validation: 2.315736764931033]
	TIME [epoch: 10.4 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 2.175523633433084		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 2.175523633433084 | validation: 2.5316535083082603]
	TIME [epoch: 10.4 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3803246515460534		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 2.3803246515460534 | validation: 2.1952163708197556]
	TIME [epoch: 10.4 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 2.061907663724186		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 2.061907663724186 | validation: 2.045800812677247]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 2.144238294978156		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 2.144238294978156 | validation: 2.08128583922352]
	TIME [epoch: 10.4 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 2.360157753144824		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 2.360157753144824 | validation: 2.3059414482445186]
	TIME [epoch: 10.4 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1588393962992094		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 2.1588393962992094 | validation: 2.517605760745321]
	TIME [epoch: 10.4 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 2.161085374559084		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 2.161085374559084 | validation: 2.2004380791928067]
	TIME [epoch: 10.4 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 3.056794416004807		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 3.056794416004807 | validation: 2.6335581368114345]
	TIME [epoch: 10.4 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 2.238538616527131		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 2.238538616527131 | validation: 1.9347781715850092]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9875804821949348		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 1.9875804821949348 | validation: 2.1181168604116265]
	TIME [epoch: 10.4 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2150720887798068		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 2.2150720887798068 | validation: 2.2767778390160736]
	TIME [epoch: 10.4 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0229798995815074		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 2.0229798995815074 | validation: 2.5058793001831368]
	TIME [epoch: 10.4 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0552339543912987		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 2.0552339543912987 | validation: 2.02618619292179]
	TIME [epoch: 10.4 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1884437255384626		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 2.1884437255384626 | validation: 1.895375002748565]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 1.97442670708663		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 1.97442670708663 | validation: 2.13583523811312]
	TIME [epoch: 10.4 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2804367005727775		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 2.2804367005727775 | validation: 2.2311981480604284]
	TIME [epoch: 10.4 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 2.011365924627671		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 2.011365924627671 | validation: 2.195203955044021]
	TIME [epoch: 10.4 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 1.949618619342779		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 1.949618619342779 | validation: 2.0955105547332575]
	TIME [epoch: 10.4 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0392293687908287		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 2.0392293687908287 | validation: 2.0651703143049343]
	TIME [epoch: 10.4 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8887076564764507		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 1.8887076564764507 | validation: 1.9963899366223874]
	TIME [epoch: 10.4 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8436369693175199		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 1.8436369693175199 | validation: 2.054825135888815]
	TIME [epoch: 10.4 sec]
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8315031809233275		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 1.8315031809233275 | validation: 2.0778503776104786]
	TIME [epoch: 10.4 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9147319495625048		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 1.9147319495625048 | validation: 1.8164310336437504]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 1.676436414647957		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 1.676436414647957 | validation: 1.6863035051716286]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_155.pth
	Model improved!!!
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6501220067197173		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 1.6501220067197173 | validation: 2.0916326211185305]
	TIME [epoch: 10.4 sec]
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6038718600417696		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 1.6038718600417696 | validation: 2.7549362637868144]
	TIME [epoch: 10.4 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9950262008590713		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 1.9950262008590713 | validation: 1.8907911221493705]
	TIME [epoch: 10.4 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7789420224535868		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 1.7789420224535868 | validation: 1.7706010990517782]
	TIME [epoch: 10.4 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 1.684734787363458		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 1.684734787363458 | validation: 1.9497613102467306]
	TIME [epoch: 10.4 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7823767004415934		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 1.7823767004415934 | validation: 1.7433697367596563]
	TIME [epoch: 10.4 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 1.619632609594531		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 1.619632609594531 | validation: 1.7683389511738703]
	TIME [epoch: 10.4 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6429111739212359		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 1.6429111739212359 | validation: 1.8642951828264172]
	TIME [epoch: 10.4 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6330359281383842		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 1.6330359281383842 | validation: 1.4089931383511332]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_164.pth
	Model improved!!!
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 1.811936332388618		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 1.811936332388618 | validation: 1.7442141517780925]
	TIME [epoch: 10.4 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6454462417990203		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 1.6454462417990203 | validation: 2.0246101938326593]
	TIME [epoch: 10.4 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6338426243613047		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 1.6338426243613047 | validation: 1.4394804615807042]
	TIME [epoch: 10.4 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5912330883925252		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 1.5912330883925252 | validation: 1.6866557957460344]
	TIME [epoch: 10.4 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 1.54640985396089		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 1.54640985396089 | validation: 1.4703196314899947]
	TIME [epoch: 10.4 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4884218977445856		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 1.4884218977445856 | validation: 1.9513890403350889]
	TIME [epoch: 10.4 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5136629769891292		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 1.5136629769891292 | validation: 1.4526736101909365]
	TIME [epoch: 10.4 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 1.526461212617963		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 1.526461212617963 | validation: 1.9616531812734344]
	TIME [epoch: 10.4 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4685385519034426		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 1.4685385519034426 | validation: 1.7422064236454904]
	TIME [epoch: 10.4 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7160457452454352		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 1.7160457452454352 | validation: 1.8931097089482154]
	TIME [epoch: 10.4 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6772449741105464		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 1.6772449741105464 | validation: 1.9697643735414982]
	TIME [epoch: 10.4 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5773498188226966		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 1.5773498188226966 | validation: 1.7919438760145394]
	TIME [epoch: 10.4 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 1.408295935241848		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 1.408295935241848 | validation: 2.0354308685763702]
	TIME [epoch: 10.4 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9242326615305028		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 1.9242326615305028 | validation: 1.4494860288750224]
	TIME [epoch: 10.4 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3952311788751701		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 1.3952311788751701 | validation: 2.0802510273755868]
	TIME [epoch: 10.4 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5525902008255026		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 1.5525902008255026 | validation: 1.3500797366800075]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_180.pth
	Model improved!!!
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 1.418480407164417		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 1.418480407164417 | validation: 1.546140403456653]
	TIME [epoch: 10.4 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4914056103439841		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 1.4914056103439841 | validation: 1.9264997127552475]
	TIME [epoch: 10.4 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 1.645924719938422		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 1.645924719938422 | validation: 1.4710216547946988]
	TIME [epoch: 10.4 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3516750368761277		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 1.3516750368761277 | validation: 1.5460652580867873]
	TIME [epoch: 10.4 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 1.303372409489794		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 1.303372409489794 | validation: 1.3337069484390314]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_185.pth
	Model improved!!!
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2951709604521033		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 1.2951709604521033 | validation: 1.76614363658835]
	TIME [epoch: 10.4 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4287809849731605		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 1.4287809849731605 | validation: 1.7262417526539604]
	TIME [epoch: 10.4 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4488161150765655		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 1.4488161150765655 | validation: 1.5157885463303862]
	TIME [epoch: 10.4 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4514388016986466		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 1.4514388016986466 | validation: 1.6645175421327723]
	TIME [epoch: 10.4 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4555971366427516		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 1.4555971366427516 | validation: 1.2250667995489186]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_190.pth
	Model improved!!!
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2465321908809472		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 1.2465321908809472 | validation: 1.3862309266101562]
	TIME [epoch: 10.4 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 1.269168888366943		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 1.269168888366943 | validation: 1.3180429046111448]
	TIME [epoch: 10.4 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2339481235440697		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 1.2339481235440697 | validation: 1.891998212323713]
	TIME [epoch: 10.4 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4070450189272676		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 1.4070450189272676 | validation: 1.6281443896062027]
	TIME [epoch: 10.4 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3151384700736979		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 1.3151384700736979 | validation: 1.2103465608467625]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_195.pth
	Model improved!!!
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2731450141412763		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 1.2731450141412763 | validation: 1.4670365376294752]
	TIME [epoch: 10.4 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3578041066695499		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 1.3578041066695499 | validation: 2.391288303084634]
	TIME [epoch: 10.4 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 1.540233548112113		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 1.540233548112113 | validation: 1.5781433493713193]
	TIME [epoch: 10.4 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5511520852636882		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 1.5511520852636882 | validation: 1.5068466028317111]
	TIME [epoch: 10.4 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2028042242175356		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 1.2028042242175356 | validation: 1.4779316686920296]
	TIME [epoch: 10.4 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2500419345684814		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 1.2500419345684814 | validation: 1.2668656384434893]
	TIME [epoch: 10.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 1.215461159706209		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 1.215461159706209 | validation: 1.2879556680876045]
	TIME [epoch: 10.4 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2800014658625627		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 1.2800014658625627 | validation: 1.3202207727545976]
	TIME [epoch: 10.4 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6424725037744103		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 1.6424725037744103 | validation: 1.4573586669056107]
	TIME [epoch: 10.4 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2422579166258214		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 1.2422579166258214 | validation: 1.5974456599750557]
	TIME [epoch: 10.4 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5551455786910218		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 1.5551455786910218 | validation: 1.4443738955307583]
	TIME [epoch: 10.4 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3022016023188585		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 1.3022016023188585 | validation: 1.1650956998347508]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_207.pth
	Model improved!!!
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 1.159101439392307		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 1.159101439392307 | validation: 1.2655524626403176]
	TIME [epoch: 10.4 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2859856101246043		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 1.2859856101246043 | validation: 1.1901088994822655]
	TIME [epoch: 10.4 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 1.300494050998394		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 1.300494050998394 | validation: 1.788528129547292]
	TIME [epoch: 10.4 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2984550312099867		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 1.2984550312099867 | validation: 1.9771135933942254]
	TIME [epoch: 10.4 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3791954682907126		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 1.3791954682907126 | validation: 1.5464278049878266]
	TIME [epoch: 10.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4026290910949644		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 1.4026290910949644 | validation: 1.723892923784102]
	TIME [epoch: 10.4 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 1.326303517788523		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 1.326303517788523 | validation: 1.087643972173644]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_214.pth
	Model improved!!!
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0915139875341007		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 1.0915139875341007 | validation: 1.1765905431435109]
	TIME [epoch: 10.4 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 1.077738580626369		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 1.077738580626369 | validation: 1.9846590333697984]
	TIME [epoch: 10.4 sec]
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3372188332422528		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 1.3372188332422528 | validation: 1.2174635042141302]
	TIME [epoch: 10.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1114122050330377		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 1.1114122050330377 | validation: 1.1927121545694892]
	TIME [epoch: 10.4 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3177495432018413		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 1.3177495432018413 | validation: 1.1820468665149304]
	TIME [epoch: 10.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1880506591728686		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 1.1880506591728686 | validation: 1.4316837414458599]
	TIME [epoch: 10.4 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4805389601979937		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 1.4805389601979937 | validation: 1.4195957309862177]
	TIME [epoch: 10.4 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3959845694470205		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 1.3959845694470205 | validation: 1.5504862488215394]
	TIME [epoch: 10.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2913616821631828		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 1.2913616821631828 | validation: 1.3549673545547563]
	TIME [epoch: 10.4 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2416993321963037		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 1.2416993321963037 | validation: 1.3346721264633346]
	TIME [epoch: 10.4 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0770094328856041		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 1.0770094328856041 | validation: 1.2860685087673158]
	TIME [epoch: 10.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1480562825514824		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 1.1480562825514824 | validation: 1.2027582309165132]
	TIME [epoch: 10.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0907742377065568		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 1.0907742377065568 | validation: 1.2771730779841923]
	TIME [epoch: 10.4 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1014108660984108		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 1.1014108660984108 | validation: 1.121872524428571]
	TIME [epoch: 10.4 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1457224966127553		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 1.1457224966127553 | validation: 1.38467151817772]
	TIME [epoch: 10.4 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 1.268726484161086		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 1.268726484161086 | validation: 2.170244743465973]
	TIME [epoch: 10.4 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2731585650094814		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 1.2731585650094814 | validation: 1.0551105263823952]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_231.pth
	Model improved!!!
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2087218471588703		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 1.2087218471588703 | validation: 1.0992425867721227]
	TIME [epoch: 10.4 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0619265792526487		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 1.0619265792526487 | validation: 1.1548166678513736]
	TIME [epoch: 10.4 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0376974457418648		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 1.0376974457418648 | validation: 1.413598990930276]
	TIME [epoch: 10.4 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1009979775482592		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 1.1009979775482592 | validation: 1.0789175022279516]
	TIME [epoch: 10.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1733244007760917		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 1.1733244007760917 | validation: 1.8784172959058116]
	TIME [epoch: 10.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 1.26521485190791		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 1.26521485190791 | validation: 1.1959998848714866]
	TIME [epoch: 10.4 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1670197803850906		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 1.1670197803850906 | validation: 1.3443459917640743]
	TIME [epoch: 10.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3878928573565377		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 1.3878928573565377 | validation: 1.4512606385555358]
	TIME [epoch: 10.4 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3123342779305465		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 1.3123342779305465 | validation: 1.0596856911224528]
	TIME [epoch: 10.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9554963255808472		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 0.9554963255808472 | validation: 1.362828995413243]
	TIME [epoch: 10.4 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 1.150837964770259		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 1.150837964770259 | validation: 1.171919303063106]
	TIME [epoch: 10.4 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1307291903104562		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 1.1307291903104562 | validation: 1.4724867831310264]
	TIME [epoch: 10.4 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0632135021646758		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 1.0632135021646758 | validation: 1.010710572239641]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_244.pth
	Model improved!!!
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 1.135553820361531		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 1.135553820361531 | validation: 1.0822859209961966]
	TIME [epoch: 10.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1108899543548398		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 1.1108899543548398 | validation: 0.9565938924045263]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_246.pth
	Model improved!!!
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0839015821702447		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 1.0839015821702447 | validation: 1.112497296264563]
	TIME [epoch: 10.4 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 1.258701270716847		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 1.258701270716847 | validation: 1.1038087872438853]
	TIME [epoch: 10.4 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 1.119668736223504		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 1.119668736223504 | validation: 1.216703368342038]
	TIME [epoch: 10.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1459482616346792		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 1.1459482616346792 | validation: 1.7889411361103746]
	TIME [epoch: 10.4 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4293630637476418		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 1.4293630637476418 | validation: 1.5933503655538384]
	TIME [epoch: 10.4 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5085245309810291		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 1.5085245309810291 | validation: 1.1539894826608932]
	TIME [epoch: 10.4 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 1.170820860045602		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 1.170820860045602 | validation: 1.61252649043435]
	TIME [epoch: 10.4 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4408013627642746		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 1.4408013627642746 | validation: 1.0813912169128488]
	TIME [epoch: 10.4 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1104301637371534		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 1.1104301637371534 | validation: 1.355911308685271]
	TIME [epoch: 10.4 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0908533251966959		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 1.0908533251966959 | validation: 1.3009284168617632]
	TIME [epoch: 10.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1341548405944881		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 1.1341548405944881 | validation: 0.9138014263470073]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_257.pth
	Model improved!!!
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 1.257598685521163		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 1.257598685521163 | validation: 1.4747525694862413]
	TIME [epoch: 10.4 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4162607921508874		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 1.4162607921508874 | validation: 1.156292810440289]
	TIME [epoch: 10.4 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0218539053452953		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 1.0218539053452953 | validation: 0.9232484244052163]
	TIME [epoch: 10.4 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0904456915249758		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 1.0904456915249758 | validation: 1.0632379776554182]
	TIME [epoch: 10.4 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9951206762962375		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 0.9951206762962375 | validation: 1.0822644434223556]
	TIME [epoch: 10.4 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2884190365776118		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 1.2884190365776118 | validation: 1.1675467581716326]
	TIME [epoch: 10.4 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0114885082452019		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 1.0114885082452019 | validation: 1.2690318316684204]
	TIME [epoch: 10.4 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 1.083077011744603		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 1.083077011744603 | validation: 1.0552393813751626]
	TIME [epoch: 10.4 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0749919805310673		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 1.0749919805310673 | validation: 1.0308469461772782]
	TIME [epoch: 10.4 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0678898114534365		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 1.0678898114534365 | validation: 1.2827114479889157]
	TIME [epoch: 10.4 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0707601230121115		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 1.0707601230121115 | validation: 1.0791085539495924]
	TIME [epoch: 10.4 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 1.203273849000588		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 1.203273849000588 | validation: 0.8658318712651072]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_269.pth
	Model improved!!!
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1224036951006178		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 1.1224036951006178 | validation: 0.9611258589019411]
	TIME [epoch: 10.4 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4275124877974612		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 1.4275124877974612 | validation: 1.2130094171979442]
	TIME [epoch: 10.4 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 1.242020729035272		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 1.242020729035272 | validation: 1.9839198996715168]
	TIME [epoch: 10.4 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 1.396593532705176		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 1.396593532705176 | validation: 1.029010414123076]
	TIME [epoch: 10.4 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 1.017835510135017		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 1.017835510135017 | validation: 1.0338231461348881]
	TIME [epoch: 10.4 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0221694400809906		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 1.0221694400809906 | validation: 1.1648781879484396]
	TIME [epoch: 10.4 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1147360044591466		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 1.1147360044591466 | validation: 1.2231011782479262]
	TIME [epoch: 10.4 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0133215759128704		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 1.0133215759128704 | validation: 1.1367220750890754]
	TIME [epoch: 10.4 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 1.083542489478657		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 1.083542489478657 | validation: 1.1286342734628634]
	TIME [epoch: 10.4 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 1.313854108977432		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 1.313854108977432 | validation: 1.0705037089647607]
	TIME [epoch: 10.4 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0696112669003945		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 1.0696112669003945 | validation: 1.069332119374032]
	TIME [epoch: 10.4 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9756343377126623		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 0.9756343377126623 | validation: 1.0219495084238868]
	TIME [epoch: 10.4 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0547726487137454		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 1.0547726487137454 | validation: 1.0775617503005581]
	TIME [epoch: 10.4 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 1.593835711174631		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 1.593835711174631 | validation: 1.1367411620685655]
	TIME [epoch: 10.4 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 1.035654130402412		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 1.035654130402412 | validation: 1.0298875914156977]
	TIME [epoch: 10.4 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9054428437357945		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 0.9054428437357945 | validation: 1.1649466632791754]
	TIME [epoch: 10.4 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0203136009983167		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 1.0203136009983167 | validation: 1.0128972022788247]
	TIME [epoch: 10.4 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2053979045650238		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 1.2053979045650238 | validation: 0.9543563664652477]
	TIME [epoch: 10.4 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 0.979891260947743		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 0.979891260947743 | validation: 1.2474745426135652]
	TIME [epoch: 10.4 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0787456111572742		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 1.0787456111572742 | validation: 0.9459890931112019]
	TIME [epoch: 10.4 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9690280356235949		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 0.9690280356235949 | validation: 1.052993688532223]
	TIME [epoch: 10.4 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8716495955010922		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 0.8716495955010922 | validation: 1.0055102999223988]
	TIME [epoch: 10.4 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0338655306370916		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 1.0338655306370916 | validation: 1.1681562256625067]
	TIME [epoch: 10.4 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9834819607990131		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 0.9834819607990131 | validation: 0.9353983409461992]
	TIME [epoch: 10.4 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0483391436119227		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 1.0483391436119227 | validation: 1.345514883382333]
	TIME [epoch: 10.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1610371388307965		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 1.1610371388307965 | validation: 1.434845336194324]
	TIME [epoch: 10.4 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0806580452862797		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 1.0806580452862797 | validation: 1.0551084732198115]
	TIME [epoch: 10.4 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1097515646820293		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 1.1097515646820293 | validation: 1.3594019712696224]
	TIME [epoch: 10.4 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0751611841095512		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 1.0751611841095512 | validation: 0.9542113464279082]
	TIME [epoch: 10.4 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9834820787916836		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.9834820787916836 | validation: 0.9319099874704712]
	TIME [epoch: 10.4 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0022301059864198		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 1.0022301059864198 | validation: 0.8351729264822155]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_300.pth
	Model improved!!!
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9473359898436039		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 0.9473359898436039 | validation: 0.976514680608004]
	TIME [epoch: 10.4 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 0.881400674528142		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 0.881400674528142 | validation: 0.9552935924005831]
	TIME [epoch: 10.4 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9082610020026699		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.9082610020026699 | validation: 1.0034341936066846]
	TIME [epoch: 10.4 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9614999017209419		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 0.9614999017209419 | validation: 0.9577957343518992]
	TIME [epoch: 10.4 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9522292696596809		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 0.9522292696596809 | validation: 0.9337371465023163]
	TIME [epoch: 10.4 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1195570584232075		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 1.1195570584232075 | validation: 0.9186093035315626]
	TIME [epoch: 10.4 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9880810699200376		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 0.9880810699200376 | validation: 1.2008378613812003]
	TIME [epoch: 10.4 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0680105300635514		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 1.0680105300635514 | validation: 0.9839864984481236]
	TIME [epoch: 10.4 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0341359893318198		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 1.0341359893318198 | validation: 1.005514639418509]
	TIME [epoch: 10.4 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 1.241756993117096		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 1.241756993117096 | validation: 0.9686235055291402]
	TIME [epoch: 10.4 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9273780947392739		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 0.9273780947392739 | validation: 0.9910666674980214]
	TIME [epoch: 10.4 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8652120692338737		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 0.8652120692338737 | validation: 1.0412780348462751]
	TIME [epoch: 10.4 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 0.958810245817227		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 0.958810245817227 | validation: 1.5826899106897707]
	TIME [epoch: 10.4 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1371434086692656		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 1.1371434086692656 | validation: 1.0194543302247348]
	TIME [epoch: 10.4 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8937706676935768		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 0.8937706676935768 | validation: 1.1090670413152122]
	TIME [epoch: 10.4 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9399976802514072		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 0.9399976802514072 | validation: 1.182203403520601]
	TIME [epoch: 10.4 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2061134943003768		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 1.2061134943003768 | validation: 0.970031134795947]
	TIME [epoch: 10.4 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 0.854790631857165		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 0.854790631857165 | validation: 0.9024582347557256]
	TIME [epoch: 10.4 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9707474821446584		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 0.9707474821446584 | validation: 1.3815598370440614]
	TIME [epoch: 10.4 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1785955799965744		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 1.1785955799965744 | validation: 0.9137128823839971]
	TIME [epoch: 10.4 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8887080934704288		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 0.8887080934704288 | validation: 1.003747173899342]
	TIME [epoch: 10.4 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9715335616706348		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.9715335616706348 | validation: 1.1394164784730394]
	TIME [epoch: 10.4 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0537855342198788		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 1.0537855342198788 | validation: 1.5473604670055412]
	TIME [epoch: 10.4 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 1.209084220002333		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 1.209084220002333 | validation: 1.3665863378503156]
	TIME [epoch: 10.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0301810969059617		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 1.0301810969059617 | validation: 1.2474402810452638]
	TIME [epoch: 10.4 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.93271193128564		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.93271193128564 | validation: 1.2055678297639885]
	TIME [epoch: 10.4 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9210870891740839		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.9210870891740839 | validation: 1.1114733369633032]
	TIME [epoch: 10.4 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9243449150396674		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.9243449150396674 | validation: 1.254487585195799]
	TIME [epoch: 10.4 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 1.037369098477152		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 1.037369098477152 | validation: 1.0962150410929064]
	TIME [epoch: 10.4 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9197483651953879		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.9197483651953879 | validation: 1.022308823465331]
	TIME [epoch: 10.4 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9461903301107956		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.9461903301107956 | validation: 1.1005619072220663]
	TIME [epoch: 10.4 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2080662028610831		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 1.2080662028610831 | validation: 1.1186961818283565]
	TIME [epoch: 10.4 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9296525194600429		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.9296525194600429 | validation: 0.8848220005054184]
	TIME [epoch: 10.4 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8335483817723762		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.8335483817723762 | validation: 1.0437993954984444]
	TIME [epoch: 10.4 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8714342391878155		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.8714342391878155 | validation: 0.9890412365407074]
	TIME [epoch: 10.4 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9155302845577493		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.9155302845577493 | validation: 1.912130073646644]
	TIME [epoch: 10.4 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3160935068230668		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 1.3160935068230668 | validation: 1.0687062124520352]
	TIME [epoch: 10.4 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 1.010389775133867		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 1.010389775133867 | validation: 1.187727840514244]
	TIME [epoch: 10.4 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 1.090994300608446		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 1.090994300608446 | validation: 1.1023236278478676]
	TIME [epoch: 10.4 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0263845321166363		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 1.0263845321166363 | validation: 1.1205327724437524]
	TIME [epoch: 10.4 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9641885654226108		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.9641885654226108 | validation: 0.912133321060767]
	TIME [epoch: 10.4 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9692360206077588		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.9692360206077588 | validation: 1.4949653393480742]
	TIME [epoch: 10.4 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0293233420588572		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 1.0293233420588572 | validation: 1.3810656230444567]
	TIME [epoch: 10.4 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9592926732687348		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.9592926732687348 | validation: 0.8777502063184249]
	TIME [epoch: 10.4 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8351677804874086		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.8351677804874086 | validation: 0.8385080304278553]
	TIME [epoch: 10.4 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.775017869446943		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.775017869446943 | validation: 1.0401694272129316]
	TIME [epoch: 10.4 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9520181515087527		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.9520181515087527 | validation: 1.4203593610161698]
	TIME [epoch: 10.4 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 1.132290115126626		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 1.132290115126626 | validation: 1.217276037333507]
	TIME [epoch: 10.4 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0241803872507629		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 1.0241803872507629 | validation: 1.3198824893882266]
	TIME [epoch: 10.4 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9701123175798226		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.9701123175798226 | validation: 1.1295206110078464]
	TIME [epoch: 10.4 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2194070517837108		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 1.2194070517837108 | validation: 0.9686181931006901]
	TIME [epoch: 10.4 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9785575223702668		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.9785575223702668 | validation: 0.8058505044762231]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_352.pth
	Model improved!!!
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8533690936709337		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.8533690936709337 | validation: 0.862154115186511]
	TIME [epoch: 10.4 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9373019342643752		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.9373019342643752 | validation: 1.0013544830557712]
	TIME [epoch: 10.4 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9859190120780408		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.9859190120780408 | validation: 1.0189843195018267]
	TIME [epoch: 10.4 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0448214096796478		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 1.0448214096796478 | validation: 1.0482724175361977]
	TIME [epoch: 10.4 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9511934056471848		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.9511934056471848 | validation: 0.8777175344951164]
	TIME [epoch: 10.4 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1711206407239518		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 1.1711206407239518 | validation: 0.9320942430323826]
	TIME [epoch: 10.4 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8896680416190511		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.8896680416190511 | validation: 0.8345938601165245]
	TIME [epoch: 10.4 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8321523323023445		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.8321523323023445 | validation: 0.8989952357023222]
	TIME [epoch: 10.4 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7767507281073108		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.7767507281073108 | validation: 1.0552402998649588]
	TIME [epoch: 10.4 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8497251061626688		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.8497251061626688 | validation: 1.0831011733522011]
	TIME [epoch: 10.4 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9476591044523452		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.9476591044523452 | validation: 1.042390106071274]
	TIME [epoch: 10.7 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.96379106052504		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.96379106052504 | validation: 1.065939128367644]
	TIME [epoch: 10.4 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9597451685242502		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.9597451685242502 | validation: 1.2419662682567865]
	TIME [epoch: 10.4 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9452217268535807		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.9452217268535807 | validation: 1.0096237023492722]
	TIME [epoch: 10.4 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8964904464835325		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.8964904464835325 | validation: 0.9000346907897009]
	TIME [epoch: 10.4 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8584704473299747		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.8584704473299747 | validation: 0.9276589215840662]
	TIME [epoch: 10.4 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8723468060917579		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.8723468060917579 | validation: 0.9483454894248476]
	TIME [epoch: 10.4 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.85923515851492		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.85923515851492 | validation: 0.9774494676646268]
	TIME [epoch: 10.4 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.915446986634816		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.915446986634816 | validation: 0.8086919239205406]
	TIME [epoch: 10.4 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8652462935489911		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.8652462935489911 | validation: 0.8822892943815884]
	TIME [epoch: 10.4 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8267914035408092		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.8267914035408092 | validation: 1.1076932915541604]
	TIME [epoch: 10.4 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9045802946533559		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.9045802946533559 | validation: 1.027727336822035]
	TIME [epoch: 10.4 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8919601721399424		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.8919601721399424 | validation: 0.914890527280594]
	TIME [epoch: 10.4 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8806674752127875		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.8806674752127875 | validation: 0.9119234959508696]
	TIME [epoch: 10.4 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8818892115711797		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.8818892115711797 | validation: 0.9625386865378097]
	TIME [epoch: 10.4 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8176495958036523		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.8176495958036523 | validation: 0.894065837870343]
	TIME [epoch: 10.4 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8060201833651993		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.8060201833651993 | validation: 1.028879008104353]
	TIME [epoch: 10.4 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8660259726435265		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.8660259726435265 | validation: 1.0914084153157972]
	TIME [epoch: 10.4 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8289002249951694		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.8289002249951694 | validation: 0.8244627619698008]
	TIME [epoch: 10.4 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8307528747518094		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.8307528747518094 | validation: 0.899027892969996]
	TIME [epoch: 10.4 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8660271008147233		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.8660271008147233 | validation: 0.8038908507031719]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_383.pth
	Model improved!!!
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7976688340669416		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.7976688340669416 | validation: 0.9213052256847872]
	TIME [epoch: 10.4 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8424011012575982		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.8424011012575982 | validation: 1.0166954182894432]
	TIME [epoch: 10.4 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9050963159790972		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.9050963159790972 | validation: 0.893646778155659]
	TIME [epoch: 10.4 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7938076823352933		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.7938076823352933 | validation: 0.9060268199388096]
	TIME [epoch: 10.4 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2709012568635447		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 1.2709012568635447 | validation: 0.933557893839338]
	TIME [epoch: 10.4 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9308746495994548		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.9308746495994548 | validation: 1.0218217915126702]
	TIME [epoch: 10.4 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8319224225433276		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.8319224225433276 | validation: 0.9609686652720728]
	TIME [epoch: 10.4 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9998800917655821		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.9998800917655821 | validation: 0.8148867876582588]
	TIME [epoch: 10.4 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9278473470022648		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.9278473470022648 | validation: 0.8528528092862316]
	TIME [epoch: 10.4 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8072672734232065		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.8072672734232065 | validation: 0.963503928628366]
	TIME [epoch: 10.4 sec]
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8099106184514542		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.8099106184514542 | validation: 0.8562171843850113]
	TIME [epoch: 10.4 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7885310839994751		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.7885310839994751 | validation: 0.7843716867472817]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_395.pth
	Model improved!!!
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7333385718344065		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.7333385718344065 | validation: 0.9072211562596106]
	TIME [epoch: 10.4 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.912043022154814		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.912043022154814 | validation: 0.9535529871183671]
	TIME [epoch: 10.4 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8094158160265981		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.8094158160265981 | validation: 0.8980639348537091]
	TIME [epoch: 10.4 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7848353164211177		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.7848353164211177 | validation: 0.9345991475896811]
	TIME [epoch: 10.4 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8126117940055348		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.8126117940055348 | validation: 0.8036616775664317]
	TIME [epoch: 10.4 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8536673144030825		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.8536673144030825 | validation: 0.9667245303700788]
	TIME [epoch: 10.3 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9770901342249505		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.9770901342249505 | validation: 0.8780849134531944]
	TIME [epoch: 10.4 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9363815407572365		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.9363815407572365 | validation: 1.623979921323695]
	TIME [epoch: 10.4 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0489815787858425		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 1.0489815787858425 | validation: 1.0412374289782846]
	TIME [epoch: 10.4 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7944665246013307		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.7944665246013307 | validation: 0.9127949380764813]
	TIME [epoch: 10.4 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8054419477338358		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.8054419477338358 | validation: 1.0179098455263706]
	TIME [epoch: 10.4 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8795583200868778		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.8795583200868778 | validation: 0.9037406679781839]
	TIME [epoch: 10.4 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7995996533954506		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.7995996533954506 | validation: 1.0086952142818582]
	TIME [epoch: 10.3 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.82429683749043		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.82429683749043 | validation: 1.2560396350056857]
	TIME [epoch: 10.4 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8754589045644048		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.8754589045644048 | validation: 0.8692314688087689]
	TIME [epoch: 10.4 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7598808185854528		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.7598808185854528 | validation: 0.9332703691451095]
	TIME [epoch: 10.4 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8397108650094479		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.8397108650094479 | validation: 0.9438320769630942]
	TIME [epoch: 10.3 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.914626954954237		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.914626954954237 | validation: 0.9624793077763354]
	TIME [epoch: 10.3 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8921538155697153		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.8921538155697153 | validation: 1.0180066012978304]
	TIME [epoch: 10.4 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7919132911216535		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.7919132911216535 | validation: 0.8279673146108293]
	TIME [epoch: 10.3 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8807400036946562		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.8807400036946562 | validation: 1.0829318203101876]
	TIME [epoch: 10.3 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.80882051251156		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.80882051251156 | validation: 0.9020699168008934]
	TIME [epoch: 10.3 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7823794728496261		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.7823794728496261 | validation: 0.7513464583702534]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_418.pth
	Model improved!!!
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8934773370613638		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.8934773370613638 | validation: 0.9711066297624155]
	TIME [epoch: 10.3 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.837129277408596		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.837129277408596 | validation: 0.810043386325788]
	TIME [epoch: 10.3 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7384162059258744		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.7384162059258744 | validation: 1.4024519338167603]
	TIME [epoch: 10.4 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9962422786933669		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.9962422786933669 | validation: 0.8613825993598004]
	TIME [epoch: 10.4 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7468846973913594		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.7468846973913594 | validation: 0.9555257377542398]
	TIME [epoch: 10.3 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8004794911119706		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.8004794911119706 | validation: 0.7510545727967319]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_424.pth
	Model improved!!!
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7870151919951989		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.7870151919951989 | validation: 0.8162441681207014]
	TIME [epoch: 10.4 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7767353694550229		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.7767353694550229 | validation: 0.8428804403960615]
	TIME [epoch: 10.3 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.808181041807724		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.808181041807724 | validation: 0.9673776893847784]
	TIME [epoch: 10.3 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8888555416868791		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.8888555416868791 | validation: 0.8308202808887818]
	TIME [epoch: 10.3 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8027147273071696		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.8027147273071696 | validation: 0.7808393048597293]
	TIME [epoch: 10.3 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7665008299156698		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.7665008299156698 | validation: 0.9468123539344661]
	TIME [epoch: 10.3 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7592051080056097		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.7592051080056097 | validation: 0.897880200403648]
	TIME [epoch: 10.3 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8092526429360536		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.8092526429360536 | validation: 1.1286575510273003]
	TIME [epoch: 10.3 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8458674154471828		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.8458674154471828 | validation: 0.8264765656860854]
	TIME [epoch: 10.3 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.874824712653808		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.874824712653808 | validation: 0.8296739646637685]
	TIME [epoch: 10.3 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7714528625448944		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.7714528625448944 | validation: 0.8382143535508161]
	TIME [epoch: 10.3 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7263125809214406		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.7263125809214406 | validation: 0.8826601988288953]
	TIME [epoch: 10.3 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8854095856219377		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.8854095856219377 | validation: 0.819220573135625]
	TIME [epoch: 10.3 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7389312200989064		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.7389312200989064 | validation: 1.4621638544081754]
	TIME [epoch: 10.3 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0316675135181703		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 1.0316675135181703 | validation: 0.908566115337544]
	TIME [epoch: 10.3 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0293663964831836		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 1.0293663964831836 | validation: 0.9755815449486827]
	TIME [epoch: 10.3 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8991318661275581		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.8991318661275581 | validation: 0.8228310379878405]
	TIME [epoch: 10.3 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7424080960067243		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.7424080960067243 | validation: 0.7952011865351304]
	TIME [epoch: 10.3 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7959216694710883		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.7959216694710883 | validation: 0.8333668639310549]
	TIME [epoch: 10.3 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7198996810079079		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.7198996810079079 | validation: 1.0448787400784982]
	TIME [epoch: 10.3 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7701190779021386		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.7701190779021386 | validation: 0.8359567599850667]
	TIME [epoch: 10.3 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.777025034025089		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.777025034025089 | validation: 0.8034087590615695]
	TIME [epoch: 10.3 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7816103601919828		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.7816103601919828 | validation: 0.8734618845589825]
	TIME [epoch: 10.3 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7472927250847217		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.7472927250847217 | validation: 0.9372744031246069]
	TIME [epoch: 10.3 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8152658762780451		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.8152658762780451 | validation: 0.9762325313455071]
	TIME [epoch: 10.3 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9420537571094225		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.9420537571094225 | validation: 0.9087115819533085]
	TIME [epoch: 10.3 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8048664128256331		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.8048664128256331 | validation: 0.9178251024054267]
	TIME [epoch: 10.3 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.764407251572768		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.764407251572768 | validation: 1.0144503960890052]
	TIME [epoch: 10.3 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9825784442048917		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.9825784442048917 | validation: 0.8035105076003305]
	TIME [epoch: 10.3 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6913398420500453		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.6913398420500453 | validation: 0.7425551262521551]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_454.pth
	Model improved!!!
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.72432596230581		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.72432596230581 | validation: 0.8037099490970403]
	TIME [epoch: 10.3 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6754758203361505		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.6754758203361505 | validation: 0.8965226799522129]
	TIME [epoch: 10.3 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7670916419180424		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.7670916419180424 | validation: 0.715765205040142]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240215_000555/states/model_tr_study5_457.pth
	Model improved!!!
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8962940741333203		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.8962940741333203 | validation: 0.9309287699538418]
	TIME [epoch: 10.3 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8196097035697463		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.8196097035697463 | validation: 1.1685616861754147]
	TIME [epoch: 10.3 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8281677441858044		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.8281677441858044 | validation: 0.8290593015175414]
	TIME [epoch: 10.3 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7204069023088817		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.7204069023088817 | validation: 0.8106571641028631]
	TIME [epoch: 10.3 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8799323710281197		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.8799323710281197 | validation: 0.7533360598212694]
	TIME [epoch: 10.3 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6725922749148423		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.6725922749148423 | validation: 0.8570253388797423]
	TIME [epoch: 10.3 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7528768835770014		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.7528768835770014 | validation: 0.7973759552313883]
	TIME [epoch: 10.3 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7058526343856221		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.7058526343856221 | validation: 0.874652699860701]
	TIME [epoch: 10.3 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7794513339058934		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.7794513339058934 | validation: 0.997209864460788]
	TIME [epoch: 10.3 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7250495103532621		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.7250495103532621 | validation: 0.8214745947463343]
	TIME [epoch: 10.3 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6792721904873303		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.6792721904873303 | validation: 0.8002854591804459]
	TIME [epoch: 10.3 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7660822776614443		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.7660822776614443 | validation: 0.7831922341220263]
	TIME [epoch: 10.3 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7138482673043268		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.7138482673043268 | validation: 0.7581363280559985]
	TIME [epoch: 10.3 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7251615467731568		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.7251615467731568 | validation: 0.9751116605789162]
	TIME [epoch: 10.3 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8050518756190298		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.8050518756190298 | validation: 1.096496458345618]
	TIME [epoch: 10.3 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.830211409926401		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.830211409926401 | validation: 0.9015791360843403]
	TIME [epoch: 10.3 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6952692095659488		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.6952692095659488 | validation: 0.9516159420139593]
	TIME [epoch: 10.3 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7587992113632633		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.7587992113632633 | validation: 0.8975485450469863]
	TIME [epoch: 10.3 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9891901156948497		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.9891901156948497 | validation: 0.7767037775268182]
	TIME [epoch: 10.3 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6917280120252786		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.6917280120252786 | validation: 0.7286368691293439]
	TIME [epoch: 10.3 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6940212913675399		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.6940212913675399 | validation: 0.7524403762841869]
	TIME [epoch: 10.3 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6889428088154244		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.6889428088154244 | validation: 0.894260976233372]
	TIME [epoch: 10.3 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7973010601498638		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.7973010601498638 | validation: 0.9933858547963919]
	TIME [epoch: 10.3 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7713306190095583		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.7713306190095583 | validation: 0.8512420912926263]
	TIME [epoch: 10.3 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6958776342963646		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.6958776342963646 | validation: 0.8285824396423743]
	TIME [epoch: 10.3 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7496515358352879		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.7496515358352879 | validation: 0.8303497528726362]
	TIME [epoch: 10.3 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7059224653096566		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.7059224653096566 | validation: 0.7878524648523145]
	TIME [epoch: 10.3 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.675911327884872		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.675911327884872 | validation: 0.8694548876538702]
	TIME [epoch: 10.3 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7914627467396365		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.7914627467396365 | validation: 1.0149639805974702]
	TIME [epoch: 10.3 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7835246931762014		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.7835246931762014 | validation: 1.1046136997573301]
	TIME [epoch: 10.3 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9496392028933922		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.9496392028933922 | validation: 1.1690061022493874]
	TIME [epoch: 10.3 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8442364858099424		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.8442364858099424 | validation: 0.9119289061857342]
	TIME [epoch: 10.3 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7200937853244586		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.7200937853244586 | validation: 1.0200401099437975]
	TIME [epoch: 10.3 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9436214295434902		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.9436214295434902 | validation: 1.007647223235514]
	TIME [epoch: 10.3 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.775469184962586		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.775469184962586 | validation: 0.787805694817807]
	TIME [epoch: 10.3 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6880538367994413		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.6880538367994413 | validation: 0.8331154289979001]
	TIME [epoch: 10.3 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7900612884923335		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.7900612884923335 | validation: 0.7967271044966517]
	TIME [epoch: 10.3 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7148340532338733		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.7148340532338733 | validation: 0.7477429669798348]
	TIME [epoch: 10.3 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7180717109946124		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.7180717109946124 | validation: 0.7383385097325129]
	TIME [epoch: 10.3 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.642194410874837		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.642194410874837 | validation: 0.7318916724829001]
	TIME [epoch: 10.3 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6565854124431795		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.6565854124431795 | validation: 0.8955642886281039]
	TIME [epoch: 10.3 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.681368530286611		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.681368530286611 | validation: 0.7940394546178995]
	TIME [epoch: 10.3 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6457819870593651		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.6457819870593651 | validation: 0.8736356353377389]
	TIME [epoch: 10.3 sec]
Finished training in 5256.926 seconds.
