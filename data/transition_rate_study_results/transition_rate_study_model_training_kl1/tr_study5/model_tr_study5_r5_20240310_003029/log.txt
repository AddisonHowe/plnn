Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 377426523

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.208772477298373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.208772477298373 | validation: 12.202032590776207]
	TIME [epoch: 106 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.487608912912936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.487608912912936 | validation: 10.55988841177385]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.628564711891201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.628564711891201 | validation: 9.943151460383156]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.066861571160334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.066861571160334 | validation: 8.813165978149641]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.503724044130443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.503724044130443 | validation: 8.5929432362247]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.10783475391575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.10783475391575 | validation: 7.948965053075941]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.565004563383958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.565004563383958 | validation: 7.341061424102869]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.870967179912228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.870967179912228 | validation: 6.960802252453629]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.941608584794961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.941608584794961 | validation: 7.491429626224613]
	TIME [epoch: 27.5 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.022673714280938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.022673714280938 | validation: 7.04793574280174]
	TIME [epoch: 27.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.681547096983438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.681547096983438 | validation: 6.354103405850674]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.240404561737803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.240404561737803 | validation: 6.267569456783071]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.128542965703709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.128542965703709 | validation: 6.172567084002801]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0331936286206735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0331936286206735 | validation: 6.277228672885524]
	TIME [epoch: 27.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.049238481543443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.049238481543443 | validation: 6.150883216377113]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.081029415508421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.081029415508421 | validation: 6.294687320642768]
	TIME [epoch: 27.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2413849212646655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2413849212646655 | validation: 6.186281888841627]
	TIME [epoch: 27.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.139789701774846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.139789701774846 | validation: 6.132660102754333]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.141092958595502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.141092958595502 | validation: 6.096000022434664]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.986427366956269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.986427366956269 | validation: 6.046881139176556]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.972159532993602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.972159532993602 | validation: 6.013730641049364]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.920795344132511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.920795344132511 | validation: 5.829611720990704]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.876190699095737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.876190699095737 | validation: 5.799648731883912]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.23863354019395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.23863354019395 | validation: 6.229005512177528]
	TIME [epoch: 27.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158895447760728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.158895447760728 | validation: 6.062463190457504]
	TIME [epoch: 27.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.889251045522574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.889251045522574 | validation: 6.002894698602115]
	TIME [epoch: 27.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9155437537580955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9155437537580955 | validation: 5.883635224009394]
	TIME [epoch: 27.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.889742037209668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.889742037209668 | validation: 6.150618966004761]
	TIME [epoch: 27.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.633980834530297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.633980834530297 | validation: 6.253707399262671]
	TIME [epoch: 27.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.193034474458217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.193034474458217 | validation: 6.705939547027267]
	TIME [epoch: 27.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.759400614974874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.759400614974874 | validation: 5.782704784134]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.924901018414833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.924901018414833 | validation: 5.976776578245428]
	TIME [epoch: 27.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852072586833899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852072586833899 | validation: 5.799243946976248]
	TIME [epoch: 27.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.798331594756073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.798331594756073 | validation: 5.983150704571415]
	TIME [epoch: 27.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962938846293639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.962938846293639 | validation: 6.011877550746109]
	TIME [epoch: 27.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.895511405977344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.895511405977344 | validation: 5.853540231497837]
	TIME [epoch: 27.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733899761390301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.733899761390301 | validation: 5.792738106447419]
	TIME [epoch: 27.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.774862652388729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.774862652388729 | validation: 5.725620884589293]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753225011479515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.753225011479515 | validation: 5.678109186890871]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.708179195683158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.708179195683158 | validation: 5.6144273088204955]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.688038549082059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.688038549082059 | validation: 5.925027610075993]
	TIME [epoch: 27.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8110121878035255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8110121878035255 | validation: 5.623576143168744]
	TIME [epoch: 27.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3149571468829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3149571468829 | validation: 6.164481231929804]
	TIME [epoch: 27.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822869441596641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.822869441596641 | validation: 5.583707098717739]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.304595594965992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.304595594965992 | validation: 9.267403135440127]
	TIME [epoch: 27.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.974671222262235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.974671222262235 | validation: 5.977035830504097]
	TIME [epoch: 27.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.797374527850334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.797374527850334 | validation: 6.429588554069802]
	TIME [epoch: 27.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.993262330060697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.993262330060697 | validation: 6.101739486750574]
	TIME [epoch: 27.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.647383885130864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.647383885130864 | validation: 6.053839448353131]
	TIME [epoch: 27.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.544910617867071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.544910617867071 | validation: 5.413515585295263]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.00357692202566		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 6.00357692202566 | validation: 7.450967676353547]
	TIME [epoch: 27.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.621845040057117		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 6.621845040057117 | validation: 7.78308425990738]
	TIME [epoch: 27.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.253077865670775		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 8.253077865670775 | validation: 7.926607235534525]
	TIME [epoch: 27.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.052630795781288		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 7.052630795781288 | validation: 6.405493897938202]
	TIME [epoch: 27.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772356750972005		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.772356750972005 | validation: 5.48830671293072]
	TIME [epoch: 27.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.460697719177749		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.460697719177749 | validation: 5.344490171720393]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.421951901825905		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.421951901825905 | validation: 5.399826280451427]
	TIME [epoch: 27.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.282592831191014		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 6.282592831191014 | validation: 6.583261231798331]
	TIME [epoch: 27.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.607875534741088		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.607875534741088 | validation: 5.465705145346495]
	TIME [epoch: 27.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.251252180767499		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.251252180767499 | validation: 5.249575033620895]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.188486251162659		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.188486251162659 | validation: 5.668433636706616]
	TIME [epoch: 27.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.490128502066564		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.490128502066564 | validation: 5.125584595181713]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.333989377747606		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.333989377747606 | validation: 4.97619314693808]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.055357485545908		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.055357485545908 | validation: 5.087865371125024]
	TIME [epoch: 27.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297030278157618		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.297030278157618 | validation: 5.016827468388984]
	TIME [epoch: 27.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.486453210965142		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.486453210965142 | validation: 6.480422986626948]
	TIME [epoch: 27.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3304706538125		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.3304706538125 | validation: 5.518470237765938]
	TIME [epoch: 27.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.672734397282624		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.672734397282624 | validation: 5.0333774741177635]
	TIME [epoch: 27.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.944001534869847		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.944001534869847 | validation: 5.500483225483188]
	TIME [epoch: 27.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.958500361730309		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.958500361730309 | validation: 6.383197294298542]
	TIME [epoch: 27.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57549739348263		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.57549739348263 | validation: 4.818440247243646]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.998424052661326		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.998424052661326 | validation: 5.243770337602216]
	TIME [epoch: 27.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.037173392278404		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 5.037173392278404 | validation: 4.894375520365382]
	TIME [epoch: 27.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7472325134851765		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.7472325134851765 | validation: 4.9145002795374895]
	TIME [epoch: 27.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7665592870979		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.7665592870979 | validation: 4.709285258351787]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.731804138320525		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.731804138320525 | validation: 4.663567717827405]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.678281041026318		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.678281041026318 | validation: 4.5654283912889335]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.739910248904294		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.739910248904294 | validation: 4.861051206265488]
	TIME [epoch: 27.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.667065794549782		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.667065794549782 | validation: 4.715688792217007]
	TIME [epoch: 27.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.589495142325582		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.589495142325582 | validation: 4.452370210318885]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077544147366314		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 6.077544147366314 | validation: 9.88373474599013]
	TIME [epoch: 27.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.500270019208585		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 8.500270019208585 | validation: 5.618373284048175]
	TIME [epoch: 27.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.139763092960106		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.139763092960106 | validation: 4.683035151305253]
	TIME [epoch: 27.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9477896627938485		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.9477896627938485 | validation: 5.312476497648718]
	TIME [epoch: 27.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.179525477934122		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.179525477934122 | validation: 5.351389180468053]
	TIME [epoch: 27.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.967476228756833		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 6.967476228756833 | validation: 8.132262366252666]
	TIME [epoch: 27.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.293805392413075		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 7.293805392413075 | validation: 5.826578502978252]
	TIME [epoch: 27.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840403780038756		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 5.840403780038756 | validation: 6.122993453071981]
	TIME [epoch: 27.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.250195589639319		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 6.250195589639319 | validation: 5.756113588168627]
	TIME [epoch: 27.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.434826535636136		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 5.434826535636136 | validation: 4.813315211230464]
	TIME [epoch: 27.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.700027216400088		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.700027216400088 | validation: 4.850671641429134]
	TIME [epoch: 27.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.469943376114273		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 5.469943376114273 | validation: 8.36570555007497]
	TIME [epoch: 27.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.941455222609152		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 8.941455222609152 | validation: 7.847168041938182]
	TIME [epoch: 27.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.471401970582032		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 6.471401970582032 | validation: 5.195661560898154]
	TIME [epoch: 27.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.108411350625648		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 5.108411350625648 | validation: 5.3388302071566525]
	TIME [epoch: 27.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.711205345779073		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 5.711205345779073 | validation: 5.392701276071419]
	TIME [epoch: 27.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.071749998977873		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 5.071749998977873 | validation: 5.086583691190399]
	TIME [epoch: 27.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.249017987420171		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 5.249017987420171 | validation: 4.943918351420644]
	TIME [epoch: 27.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.043329177463255		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 5.043329177463255 | validation: 5.11807971034415]
	TIME [epoch: 27.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.88209201376336		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.88209201376336 | validation: 5.4344598850488435]
	TIME [epoch: 27.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724024994180386		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.724024994180386 | validation: 5.818120221063208]
	TIME [epoch: 27.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.409640574050985		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 5.409640574050985 | validation: 4.938773726671444]
	TIME [epoch: 27.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.717927649240044		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.717927649240044 | validation: 5.05243921102638]
	TIME [epoch: 27.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779688454358784		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.779688454358784 | validation: 4.555138592690078]
	TIME [epoch: 27.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.578057819104102		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.578057819104102 | validation: 4.619907045954505]
	TIME [epoch: 27.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.652673633853219		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.652673633853219 | validation: 4.7328579337923955]
	TIME [epoch: 27.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3415453113378195		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.3415453113378195 | validation: 4.6169507813326645]
	TIME [epoch: 27.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498609995264692		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.498609995264692 | validation: 4.2232078988303785]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.121367874105179		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.121367874105179 | validation: 3.8979254809187114]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.83619272882093		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.83619272882093 | validation: 3.5851670637257578]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.553833012056523		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.553833012056523 | validation: 3.4327403427468557]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239627414169072		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.239627414169072 | validation: 3.9544427374973896]
	TIME [epoch: 27.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1032802794140775		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.1032802794140775 | validation: 3.972030068796779]
	TIME [epoch: 27.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5808588307859615		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.5808588307859615 | validation: 3.48500597275735]
	TIME [epoch: 27.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.404860182745422		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.404860182745422 | validation: 3.255159461743647]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.082468566781586		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.082468566781586 | validation: 4.104746701394296]
	TIME [epoch: 27.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4736283102985808		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.4736283102985808 | validation: 3.517217474545426]
	TIME [epoch: 27.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.328300748620363		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.328300748620363 | validation: 3.4290965210690514]
	TIME [epoch: 27.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0762859691104225		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.0762859691104225 | validation: 2.732451293299088]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7445412814417405		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.7445412814417405 | validation: 3.3219010816938654]
	TIME [epoch: 27.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9541560403388147		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.9541560403388147 | validation: 3.3310182337051377]
	TIME [epoch: 27.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4964119740476436		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.4964119740476436 | validation: 3.3209223885451764]
	TIME [epoch: 27.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.71525074508729		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.71525074508729 | validation: 2.7091948580820895]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8061345447444537		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.8061345447444537 | validation: 2.402525084724397]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246921193430027		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.246921193430027 | validation: 3.7242494285495766]
	TIME [epoch: 27.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4361878102750496		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.4361878102750496 | validation: 2.5637073387631313]
	TIME [epoch: 27.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.648683305124349		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.648683305124349 | validation: 3.877213265333866]
	TIME [epoch: 27.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.883318128653577		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.883318128653577 | validation: 3.338690352304659]
	TIME [epoch: 27.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1315953701196095		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.1315953701196095 | validation: 2.450213865822208]
	TIME [epoch: 27.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842749882838302		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.842749882838302 | validation: 2.877945942357239]
	TIME [epoch: 27.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820111662701729		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.820111662701729 | validation: 2.2077446683096866]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3744141583954423		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.3744141583954423 | validation: 2.9193734047717532]
	TIME [epoch: 27.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.599000427488654		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.599000427488654 | validation: 6.178701712220779]
	TIME [epoch: 27.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.400415270230014		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.400415270230014 | validation: 3.2066326574775004]
	TIME [epoch: 27.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9274264012428115		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.9274264012428115 | validation: 2.570922489915395]
	TIME [epoch: 27.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478151617980232		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.478151617980232 | validation: 2.590038489099433]
	TIME [epoch: 27.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4867339683108263		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.4867339683108263 | validation: 3.491984517214884]
	TIME [epoch: 27.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3482895366442156		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.3482895366442156 | validation: 2.5525887220106607]
	TIME [epoch: 27.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.958859648844949		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.958859648844949 | validation: 2.824003798593184]
	TIME [epoch: 27.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.122138359861019		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.122138359861019 | validation: 2.6062157618888273]
	TIME [epoch: 27.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6013734942038846		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.6013734942038846 | validation: 2.3942605033904414]
	TIME [epoch: 27.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335769537550375		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.335769537550375 | validation: 2.3877362500736568]
	TIME [epoch: 27.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2293765560380745		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.2293765560380745 | validation: 2.440170692675782]
	TIME [epoch: 27.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164108117243896		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.164108117243896 | validation: 2.139256421708774]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9556700956359034		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.9556700956359034 | validation: 2.534203917013664]
	TIME [epoch: 27.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.859594362760953		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.859594362760953 | validation: 2.342813015099364]
	TIME [epoch: 27.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.517571092605947		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.517571092605947 | validation: 4.770501280648397]
	TIME [epoch: 27.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213073440789907		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.213073440789907 | validation: 2.1483576476538655]
	TIME [epoch: 27.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3061321252919074		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.3061321252919074 | validation: 2.3103162514583055]
	TIME [epoch: 27.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07468303011506		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.07468303011506 | validation: 1.9503919270830417]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051199163604483		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.051199163604483 | validation: 1.8857449645998956]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1902210389683407		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.1902210389683407 | validation: 1.8881145585038746]
	TIME [epoch: 27.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9030719483271494		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.9030719483271494 | validation: 1.9962515144735498]
	TIME [epoch: 27.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8709632428217746		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.8709632428217746 | validation: 2.6952115359196824]
	TIME [epoch: 27.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.157483360345444		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.157483360345444 | validation: 2.0338198664279394]
	TIME [epoch: 27.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8334452812433684		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.8334452812433684 | validation: 1.9284951256334335]
	TIME [epoch: 27.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.174156564153995		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.174156564153995 | validation: 2.402455527041656]
	TIME [epoch: 27.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0553401496494486		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.0553401496494486 | validation: 2.007673944734023]
	TIME [epoch: 27.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8335946298094212		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.8335946298094212 | validation: 2.6365225018459864]
	TIME [epoch: 27.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.186843247749723		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.186843247749723 | validation: 2.398456015805893]
	TIME [epoch: 27.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473249060223808		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.473249060223808 | validation: 2.8496408875606187]
	TIME [epoch: 27.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6299678198055796		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.6299678198055796 | validation: 3.690028398255273]
	TIME [epoch: 27.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8823626593964438		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.8823626593964438 | validation: 2.378668718484751]
	TIME [epoch: 27.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4182006099376134		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.4182006099376134 | validation: 1.9300290335217636]
	TIME [epoch: 27.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0602197111872353		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.0602197111872353 | validation: 7.678291809940811]
	TIME [epoch: 27.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.924613144559828		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 4.924613144559828 | validation: 2.595419857105576]
	TIME [epoch: 27.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4803684767075085		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.4803684767075085 | validation: 2.099133412602462]
	TIME [epoch: 27.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9158576869654018		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.9158576869654018 | validation: 2.299884193791626]
	TIME [epoch: 27.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0417524823448456		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.0417524823448456 | validation: 1.9608459280005295]
	TIME [epoch: 27.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3163167541509493		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.3163167541509493 | validation: 2.1654214785703405]
	TIME [epoch: 27.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9101735668101814		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.9101735668101814 | validation: 1.6697647712795702]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7947490312388523		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.7947490312388523 | validation: 2.8330011688418466]
	TIME [epoch: 27.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3165152466220422		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.3165152466220422 | validation: 3.402790524855313]
	TIME [epoch: 27.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.880173898432977		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.880173898432977 | validation: 4.482945872610128]
	TIME [epoch: 27.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1809345573914976		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.1809345573914976 | validation: 1.9782905181605148]
	TIME [epoch: 27.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9153079802467246		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.9153079802467246 | validation: 1.9932503359283293]
	TIME [epoch: 27.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.215990510674982		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.215990510674982 | validation: 2.6328280477856243]
	TIME [epoch: 27.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3779449753144957		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.3779449753144957 | validation: 2.8285906495280995]
	TIME [epoch: 27.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1613440191074496		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.1613440191074496 | validation: 2.1826136311098727]
	TIME [epoch: 27.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.114390259998401		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.114390259998401 | validation: 1.8928187404516783]
	TIME [epoch: 27.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9766607653022716		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.9766607653022716 | validation: 2.1307882325270584]
	TIME [epoch: 27.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1296276744096443		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.1296276744096443 | validation: 2.809762619191198]
	TIME [epoch: 27.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365668364389622		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.365668364389622 | validation: 2.3151383627080895]
	TIME [epoch: 27.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1215403715282455		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.1215403715282455 | validation: 2.4513440450724335]
	TIME [epoch: 27.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9048707029405643		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.9048707029405643 | validation: 3.8522898785245476]
	TIME [epoch: 27.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6532159295825295		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 5.6532159295825295 | validation: 6.724778398044285]
	TIME [epoch: 27.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.251121027083736		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 6.251121027083736 | validation: 6.615818919973516]
	TIME [epoch: 27.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.178108888934368		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 6.178108888934368 | validation: 6.603122326098864]
	TIME [epoch: 27.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.314449512793683		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 6.314449512793683 | validation: 6.626229803214824]
	TIME [epoch: 27.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.287593337358435		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 6.287593337358435 | validation: 6.541166354379714]
	TIME [epoch: 27.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3447598004182435		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 6.3447598004182435 | validation: 6.543905923787256]
	TIME [epoch: 27.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.331129781718999		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 6.331129781718999 | validation: 6.312230197029809]
	TIME [epoch: 27.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.333175438470613		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.333175438470613 | validation: 3.1100241405545788]
	TIME [epoch: 27.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2959675591384743		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.2959675591384743 | validation: 1.8516599996081868]
	TIME [epoch: 27.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8371573481002437		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.8371573481002437 | validation: 3.188455305285552]
	TIME [epoch: 27.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.419232003470593		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.419232003470593 | validation: 1.850609909765495]
	TIME [epoch: 27.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9511037980529076		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.9511037980529076 | validation: 1.8369925423657154]
	TIME [epoch: 27.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6451957410843276		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.6451957410843276 | validation: 1.4449835444478256]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0031033226667367		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.0031033226667367 | validation: 2.112320195380551]
	TIME [epoch: 27.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8703030311357782		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.8703030311357782 | validation: 1.9349239130751088]
	TIME [epoch: 27.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7028766231118673		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.7028766231118673 | validation: 1.6790385093646947]
	TIME [epoch: 27.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0681937328406135		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.0681937328406135 | validation: 2.766684374460334]
	TIME [epoch: 27.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061289021302278		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.061289021302278 | validation: 2.88722875660474]
	TIME [epoch: 27.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0660950049246454		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.0660950049246454 | validation: 2.151072982702558]
	TIME [epoch: 27.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9486195563139332		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.9486195563139332 | validation: 1.70226939007871]
	TIME [epoch: 27.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7725516452458518		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.7725516452458518 | validation: 1.7309153676358944]
	TIME [epoch: 27.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7744858957441922		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.7744858957441922 | validation: 1.559358064065107]
	TIME [epoch: 27.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3841409543388528		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.3841409543388528 | validation: 3.265442637736736]
	TIME [epoch: 27.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1533269726137183		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.1533269726137183 | validation: 2.7723975603655804]
	TIME [epoch: 27.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897674072502503		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.897674072502503 | validation: 2.567529014963388]
	TIME [epoch: 27.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0119888182148458		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.0119888182148458 | validation: 2.1863905209941974]
	TIME [epoch: 27.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7267305746094164		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.7267305746094164 | validation: 2.6900429563934574]
	TIME [epoch: 27.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.026143272872311		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.026143272872311 | validation: 2.1180922576342356]
	TIME [epoch: 27.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0008848709252445		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.0008848709252445 | validation: 1.9163760231194114]
	TIME [epoch: 27.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7953575077528374		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.7953575077528374 | validation: 2.1241545052450705]
	TIME [epoch: 27.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118734085148184		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.118734085148184 | validation: 1.953119215942927]
	TIME [epoch: 27.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8213743036364654		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.8213743036364654 | validation: 1.6971319465553387]
	TIME [epoch: 27.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.57851733321748		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.57851733321748 | validation: 1.4722970968284643]
	TIME [epoch: 27.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3897847929155964		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.3897847929155964 | validation: 1.6107218322971089]
	TIME [epoch: 27.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6366983567843851		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.6366983567843851 | validation: 1.8238133817414255]
	TIME [epoch: 27.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.598748247222557		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.598748247222557 | validation: 1.4325350665365084]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1236733937851024		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.1236733937851024 | validation: 2.2461142460420587]
	TIME [epoch: 27.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7706154527855797		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.7706154527855797 | validation: 2.1598858242956886]
	TIME [epoch: 27.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8589930831385288		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.8589930831385288 | validation: 2.079629075372281]
	TIME [epoch: 27.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6434856997320533		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.6434856997320533 | validation: 2.439903776533812]
	TIME [epoch: 27.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7683430685199513		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.7683430685199513 | validation: 1.5570478976169089]
	TIME [epoch: 27.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6874546368517205		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.6874546368517205 | validation: 1.7999398169754433]
	TIME [epoch: 27.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8768007965091806		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.8768007965091806 | validation: 1.8112109908679197]
	TIME [epoch: 27.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.941881086281004		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.941881086281004 | validation: 1.40824861180072]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5180413672805337		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.5180413672805337 | validation: 2.6216721649920847]
	TIME [epoch: 27.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854962963105363		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.854962963105363 | validation: 2.8976085474537068]
	TIME [epoch: 27.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.20157099297292		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.20157099297292 | validation: 2.1371329256691105]
	TIME [epoch: 27.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8495081735935932		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.8495081735935932 | validation: 1.5542296643611775]
	TIME [epoch: 27.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6440600937694494		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.6440600937694494 | validation: 1.648407528945144]
	TIME [epoch: 27.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6481886388465457		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6481886388465457 | validation: 1.5610513104273693]
	TIME [epoch: 27.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6494378676032126		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.6494378676032126 | validation: 1.8472318077133403]
	TIME [epoch: 27.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728279913519888		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.728279913519888 | validation: 1.6394015590321667]
	TIME [epoch: 27.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312393780617083		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.312393780617083 | validation: 1.8490147620858017]
	TIME [epoch: 27.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8036650021946634		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.8036650021946634 | validation: 1.6763552691320387]
	TIME [epoch: 27.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.669141589145719		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.669141589145719 | validation: 1.9755779842588959]
	TIME [epoch: 27.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6205951476824423		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.6205951476824423 | validation: 1.9085739074942374]
	TIME [epoch: 27.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7155313021515195		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.7155313021515195 | validation: 1.5836132446971705]
	TIME [epoch: 27.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4825177171187947		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.4825177171187947 | validation: 1.4835648154074494]
	TIME [epoch: 27.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2589006779269245		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.2589006779269245 | validation: 1.9759499237988065]
	TIME [epoch: 27.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.615198968443776		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.615198968443776 | validation: 1.8611036845955722]
	TIME [epoch: 27.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049689708132946		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.049689708132946 | validation: 1.8995048968445667]
	TIME [epoch: 27.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5680154357230034		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.5680154357230034 | validation: 1.3914179255963297]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3623663134296327		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.3623663134296327 | validation: 1.406344049718948]
	TIME [epoch: 27.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3374678601900567		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.3374678601900567 | validation: 1.3555872320856468]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2825232088297163		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.2825232088297163 | validation: 1.186336894851439]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8403360444070802		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.8403360444070802 | validation: 3.979823329374808]
	TIME [epoch: 27.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1671961568658045		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.1671961568658045 | validation: 1.6497493319124892]
	TIME [epoch: 27.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.700555922758601		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.700555922758601 | validation: 2.0844036553630474]
	TIME [epoch: 27.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.611030009154113		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.611030009154113 | validation: 1.9749210271163982]
	TIME [epoch: 27.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8615628240893676		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.8615628240893676 | validation: 3.6139554894704147]
	TIME [epoch: 27.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2742834212896272		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.2742834212896272 | validation: 1.4793080122957998]
	TIME [epoch: 27.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6075789997181644		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.6075789997181644 | validation: 1.4296163569741596]
	TIME [epoch: 27.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.425450828174109		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.425450828174109 | validation: 1.4189959561689791]
	TIME [epoch: 27.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4873991843546066		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.4873991843546066 | validation: 1.3063366646897112]
	TIME [epoch: 27.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3458922758645635		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.3458922758645635 | validation: 1.4478932342383493]
	TIME [epoch: 27.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.408212704031166		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.408212704031166 | validation: 1.7265165801192988]
	TIME [epoch: 27.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8396439439874435		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.8396439439874435 | validation: 1.9312729640622595]
	TIME [epoch: 27.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.581274283577554		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.581274283577554 | validation: 1.760626431957713]
	TIME [epoch: 27.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4422830244338487		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.4422830244338487 | validation: 1.854891237679325]
	TIME [epoch: 27.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3624874220131198		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.3624874220131198 | validation: 1.642516178598043]
	TIME [epoch: 27.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7633824223592423		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.7633824223592423 | validation: 2.275389969550353]
	TIME [epoch: 27.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4649088392727176		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.4649088392727176 | validation: 1.660858253304321]
	TIME [epoch: 27.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4171659927512708		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.4171659927512708 | validation: 1.8015042199791689]
	TIME [epoch: 27.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8433755415371325		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.8433755415371325 | validation: 1.7542885877088297]
	TIME [epoch: 27.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7019591844355002		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.7019591844355002 | validation: 1.5237927072644055]
	TIME [epoch: 27.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3941111175667122		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.3941111175667122 | validation: 1.9905372045807788]
	TIME [epoch: 27.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5294969274430699		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.5294969274430699 | validation: 1.7571738403501929]
	TIME [epoch: 27.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.548729412180971		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.548729412180971 | validation: 5.554111006778063]
	TIME [epoch: 27.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1287216776334157		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.1287216776334157 | validation: 1.5012140125787181]
	TIME [epoch: 27.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3415105374630578		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.3415105374630578 | validation: 1.3553404001135316]
	TIME [epoch: 27.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8091085569646914		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.8091085569646914 | validation: 1.4488397518852492]
	TIME [epoch: 27.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398060396615885		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.398060396615885 | validation: 4.1733830299255334]
	TIME [epoch: 27.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.493924037088349		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.493924037088349 | validation: 1.6927583144112242]
	TIME [epoch: 27.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.407095281910596		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.407095281910596 | validation: 1.8751034486661982]
	TIME [epoch: 27.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.582180168544621		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.582180168544621 | validation: 1.2972427851766841]
	TIME [epoch: 27.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4609666434252717		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.4609666434252717 | validation: 1.3982359125933728]
	TIME [epoch: 27.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3378605243828128		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.3378605243828128 | validation: 1.596454290074081]
	TIME [epoch: 27.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5908305039595385		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.5908305039595385 | validation: 1.2313948954521499]
	TIME [epoch: 27.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491411779522078		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.491411779522078 | validation: 1.4558202261378812]
	TIME [epoch: 27.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2582757589910436		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.2582757589910436 | validation: 1.2922678439111082]
	TIME [epoch: 27.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241277459201941		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.241277459201941 | validation: 1.5766612104130178]
	TIME [epoch: 27.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3234432087204222		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.3234432087204222 | validation: 1.767432805903975]
	TIME [epoch: 27.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4210097381062305		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.4210097381062305 | validation: 1.2554408234730772]
	TIME [epoch: 27.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1512835520472615		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1512835520472615 | validation: 1.966956512999304]
	TIME [epoch: 27.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4368203948972424		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.4368203948972424 | validation: 1.7481908794620722]
	TIME [epoch: 27.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6914096333791722		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.6914096333791722 | validation: 1.3758550369220328]
	TIME [epoch: 27.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3172050710983654		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.3172050710983654 | validation: 1.2287433357443203]
	TIME [epoch: 27.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6600269262934442		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.6600269262934442 | validation: 1.2719432113623528]
	TIME [epoch: 27.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6139318765210662		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.6139318765210662 | validation: 1.7112412973011217]
	TIME [epoch: 27.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6698817486682072		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.6698817486682072 | validation: 1.127602050668294]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1585365937589063		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.1585365937589063 | validation: 1.2559336883943073]
	TIME [epoch: 27.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1286176980146319		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.1286176980146319 | validation: 1.3572050156778446]
	TIME [epoch: 27.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4765010748605112		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.4765010748605112 | validation: 1.2874362551334735]
	TIME [epoch: 27.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438305391214877		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.438305391214877 | validation: 1.7141375564567813]
	TIME [epoch: 27.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371514684466702		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.371514684466702 | validation: 1.6595938106223738]
	TIME [epoch: 27.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4621553475723275		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.4621553475723275 | validation: 1.3186398607443397]
	TIME [epoch: 27.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301225284127533		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.2301225284127533 | validation: 1.1228493672884736]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262059156523059		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.262059156523059 | validation: 1.9711643480082912]
	TIME [epoch: 27.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5312401275542642		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.5312401275542642 | validation: 1.4330037550932395]
	TIME [epoch: 27.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.327118128293921		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.327118128293921 | validation: 1.5365119342139988]
	TIME [epoch: 27.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4468723189544352		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.4468723189544352 | validation: 1.7629942363340976]
	TIME [epoch: 27.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.603803224501629		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.603803224501629 | validation: 1.3327722762153777]
	TIME [epoch: 27.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4231153736008082		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.4231153736008082 | validation: 1.1836841201014516]
	TIME [epoch: 27.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082693608898222		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.082693608898222 | validation: 1.129056515978535]
	TIME [epoch: 27.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1881712012750274		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.1881712012750274 | validation: 1.150704418512228]
	TIME [epoch: 27.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519548014175591		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.1519548014175591 | validation: 1.256528972388331]
	TIME [epoch: 27.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460890464794489		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.460890464794489 | validation: 2.3932319223659744]
	TIME [epoch: 27.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4927938784092112		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.4927938784092112 | validation: 1.8341048981593622]
	TIME [epoch: 27.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3972509386616		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.3972509386616 | validation: 1.599932310209015]
	TIME [epoch: 27.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5349810405964663		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.5349810405964663 | validation: 1.5463069171526156]
	TIME [epoch: 27.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4341187705352838		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.4341187705352838 | validation: 2.0546720605829645]
	TIME [epoch: 27.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.448611472281929		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.448611472281929 | validation: 1.2508963999383844]
	TIME [epoch: 27.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4046926040340708		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.4046926040340708 | validation: 1.1848204456685887]
	TIME [epoch: 27.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5269352983227162		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.5269352983227162 | validation: 2.5780251042267786]
	TIME [epoch: 27.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8162118468151403		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.8162118468151403 | validation: 1.6730915051337492]
	TIME [epoch: 27.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5093636840990696		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.5093636840990696 | validation: 1.8006187303979124]
	TIME [epoch: 27.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3773045490638745		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.3773045490638745 | validation: 1.817702255374162]
	TIME [epoch: 27.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7597771393096557		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.7597771393096557 | validation: 1.8320710702138865]
	TIME [epoch: 27.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6196432146829536		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.6196432146829536 | validation: 1.4853668187365168]
	TIME [epoch: 27.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6297948483704183		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.6297948483704183 | validation: 2.0304309235040647]
	TIME [epoch: 27.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9655533806484211		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.9655533806484211 | validation: 1.5071170985842421]
	TIME [epoch: 27.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4844051791420885		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.4844051791420885 | validation: 1.857562016216524]
	TIME [epoch: 27.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6922287634426647		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.6922287634426647 | validation: 1.9085575165517688]
	TIME [epoch: 27.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3265097894464042		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.3265097894464042 | validation: 2.9494737495806995]
	TIME [epoch: 27.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7803423473184605		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.7803423473184605 | validation: 1.1550064494876546]
	TIME [epoch: 27.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3006674122424737		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.3006674122424737 | validation: 1.0961497444105763]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0166154655473258		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0166154655473258 | validation: 1.7989443577173843]
	TIME [epoch: 27.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262869520760015		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.262869520760015 | validation: 1.8699397272818863]
	TIME [epoch: 27.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6037747819704775		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.6037747819704775 | validation: 1.9850696085908706]
	TIME [epoch: 27.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3357896208908075		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.3357896208908075 | validation: 1.202428833257279]
	TIME [epoch: 27.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1820371371807625		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.1820371371807625 | validation: 1.4548129930558704]
	TIME [epoch: 27.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288327786760491		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.7288327786760491 | validation: 2.2885800581404316]
	TIME [epoch: 27.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5367333376234897		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.5367333376234897 | validation: 1.5439356665042234]
	TIME [epoch: 27.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1192932734056185		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.1192932734056185 | validation: 2.2900174241339157]
	TIME [epoch: 27.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6405676104866909		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.6405676104866909 | validation: 1.3013772019834868]
	TIME [epoch: 27.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1648962167635126		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.1648962167635126 | validation: 1.2825970968963112]
	TIME [epoch: 27.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2531158225252073		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.2531158225252073 | validation: 1.6004439521315812]
	TIME [epoch: 27.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806969792956087		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.2806969792956087 | validation: 1.4141754994074653]
	TIME [epoch: 27.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093082923648895		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.093082923648895 | validation: 1.1022139199786054]
	TIME [epoch: 27.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0712648975004209		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.0712648975004209 | validation: 1.712811680158319]
	TIME [epoch: 27.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2949303902895752		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.2949303902895752 | validation: 2.0702025664846118]
	TIME [epoch: 27.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4874934936945807		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.4874934936945807 | validation: 2.1784884708004864]
	TIME [epoch: 27.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4000669764560953		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.4000669764560953 | validation: 1.106067051410352]
	TIME [epoch: 27.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388247803382912		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.1388247803382912 | validation: 1.2280937545616963]
	TIME [epoch: 27.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.087419478545526		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.087419478545526 | validation: 0.9882079049315706]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0712277544797169		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.0712277544797169 | validation: 1.221774879664481]
	TIME [epoch: 27.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5171585648391372		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.5171585648391372 | validation: 1.4570580187268354]
	TIME [epoch: 27.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.295458294019248		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.295458294019248 | validation: 1.1893152515451173]
	TIME [epoch: 27.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1491883298652597		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.1491883298652597 | validation: 1.0283660866719284]
	TIME [epoch: 27.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9824657171941322		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.9824657171941322 | validation: 1.59200964500521]
	TIME [epoch: 27.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463889016652349		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.463889016652349 | validation: 1.1100491673172468]
	TIME [epoch: 27.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073245007614303		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.073245007614303 | validation: 1.2394016031820536]
	TIME [epoch: 27.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0905209902592885		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.0905209902592885 | validation: 1.32141498667696]
	TIME [epoch: 27.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8066858517318323		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.8066858517318323 | validation: 2.4210061342376337]
	TIME [epoch: 27.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1067140610461355		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 3.1067140610461355 | validation: 1.7506383582257439]
	TIME [epoch: 27.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.554272725454996		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.554272725454996 | validation: 1.1822178072887735]
	TIME [epoch: 27.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1470247813115348		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.1470247813115348 | validation: 1.2098426551202655]
	TIME [epoch: 27.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116901347855645		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.116901347855645 | validation: 1.032371269285326]
	TIME [epoch: 27.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376795677604152		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.1376795677604152 | validation: 1.6824932611803647]
	TIME [epoch: 27.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1412487835946228		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.1412487835946228 | validation: 0.9182148349917794]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8722453550873462		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8722453550873462 | validation: 1.061265945327955]
	TIME [epoch: 27.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0664315892625829		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.0664315892625829 | validation: 1.6596655431596736]
	TIME [epoch: 27.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2767808273588779		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.2767808273588779 | validation: 2.4530909651756536]
	TIME [epoch: 27.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491121037566931		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.491121037566931 | validation: 1.3763906660395155]
	TIME [epoch: 27.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650024568043214		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.2650024568043214 | validation: 1.0776064184819358]
	TIME [epoch: 27.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6891890613459277		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.6891890613459277 | validation: 0.9812806666690103]
	TIME [epoch: 27.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1745897865366683		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.1745897865366683 | validation: 1.563497376852622]
	TIME [epoch: 27.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5185606786339356		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.5185606786339356 | validation: 1.8597931001205226]
	TIME [epoch: 27.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2638592357870282		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.2638592357870282 | validation: 0.8876716198147884]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169508488358578		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.169508488358578 | validation: 1.1551345138784346]
	TIME [epoch: 27.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.011311823730199		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.011311823730199 | validation: 1.2121289432840243]
	TIME [epoch: 27.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228912515452013		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.228912515452013 | validation: 1.105704586174392]
	TIME [epoch: 27.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0904765091130226		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.0904765091130226 | validation: 1.2899875243644496]
	TIME [epoch: 27.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303806351233274		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.303806351233274 | validation: 1.4579373950133407]
	TIME [epoch: 27.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620106891566738		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.0620106891566738 | validation: 1.120588713797532]
	TIME [epoch: 27.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.316050452665341		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.316050452665341 | validation: 1.4672150065299672]
	TIME [epoch: 27.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1659337502060299		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.1659337502060299 | validation: 1.5513423300097333]
	TIME [epoch: 27.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9700839497054611		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.9700839497054611 | validation: 2.127311794991858]
	TIME [epoch: 27.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2642416919009718		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.2642416919009718 | validation: 1.1581896178085902]
	TIME [epoch: 27.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520387649736836		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.1520387649736836 | validation: 1.1876146312367357]
	TIME [epoch: 27.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384801316434785		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.1384801316434785 | validation: 1.3331962381492712]
	TIME [epoch: 27.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0875332589859343		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.0875332589859343 | validation: 0.9462433932189283]
	TIME [epoch: 27.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0396263621087622		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.0396263621087622 | validation: 1.071522857405343]
	TIME [epoch: 27.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7817530479551125		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.7817530479551125 | validation: 1.568424569739336]
	TIME [epoch: 27.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.279027303550993		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.279027303550993 | validation: 1.1222249309505896]
	TIME [epoch: 27.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277898902201154		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.277898902201154 | validation: 1.399281580876252]
	TIME [epoch: 27.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0649758110823124		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.0649758110823124 | validation: 0.9514514339400546]
	TIME [epoch: 27.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9613594573613363		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9613594573613363 | validation: 1.000964460309771]
	TIME [epoch: 27.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9833662801661546		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.9833662801661546 | validation: 1.002366334988773]
	TIME [epoch: 27.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048011807233071		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.048011807233071 | validation: 1.3159236604905786]
	TIME [epoch: 27.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269130061765232		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.269130061765232 | validation: 1.9183823675352145]
	TIME [epoch: 27.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3851316675680616		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.3851316675680616 | validation: 1.6762073734146319]
	TIME [epoch: 27.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4891399465554487		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.4891399465554487 | validation: 1.4266880641292887]
	TIME [epoch: 27.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0545687340863013		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.0545687340863013 | validation: 0.998331205870125]
	TIME [epoch: 27.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159986387401152		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.159986387401152 | validation: 1.13027022150761]
	TIME [epoch: 27.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9963593508562231		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.9963593508562231 | validation: 1.1467045350860847]
	TIME [epoch: 27.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288066467108329		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.288066467108329 | validation: 1.789987431743894]
	TIME [epoch: 27.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2063796641019988		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.2063796641019988 | validation: 1.121699877914047]
	TIME [epoch: 27.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233092268670914		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.0233092268670914 | validation: 1.1617398470640945]
	TIME [epoch: 27.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339763173442657		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.339763173442657 | validation: 1.1912614398933559]
	TIME [epoch: 27.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4249626700134825		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.4249626700134825 | validation: 1.2959119000513522]
	TIME [epoch: 27.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0059476229286641		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.0059476229286641 | validation: 1.037836172823696]
	TIME [epoch: 27.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0799496811022489		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.0799496811022489 | validation: 1.6840128688161817]
	TIME [epoch: 27.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286352670589409		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.2286352670589409 | validation: 1.1035958138629494]
	TIME [epoch: 27.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608191825886644		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.0608191825886644 | validation: 1.0901952922433158]
	TIME [epoch: 27.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2993593165687205		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.2993593165687205 | validation: 0.9096254372401572]
	TIME [epoch: 27.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553335994284191		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.9553335994284191 | validation: 1.1287160010617898]
	TIME [epoch: 27.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9899555341161335		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.9899555341161335 | validation: 1.1166360852543642]
	TIME [epoch: 27.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9424505406558964		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.9424505406558964 | validation: 0.9129072751763068]
	TIME [epoch: 27.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8584258425914435		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.8584258425914435 | validation: 1.005705407127485]
	TIME [epoch: 27.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542105439055605		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.9542105439055605 | validation: 0.8467665239085682]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418027346916523		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.0418027346916523 | validation: 1.0286425829696009]
	TIME [epoch: 27.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050122908715721		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.050122908715721 | validation: 0.9925234463311589]
	TIME [epoch: 27.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8601425551742892		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.8601425551742892 | validation: 1.8663938925503152]
	TIME [epoch: 27.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2737323780753174		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.2737323780753174 | validation: 0.9399797033245265]
	TIME [epoch: 27.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476990631133046		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.8476990631133046 | validation: 0.9318317244041232]
	TIME [epoch: 27.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8238544085379065		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8238544085379065 | validation: 0.8204016904021774]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878139325356179		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.9878139325356179 | validation: 0.7916093601487242]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8958418372441573		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.8958418372441573 | validation: 1.053661010773511]
	TIME [epoch: 27.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629087395424661		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.0629087395424661 | validation: 1.9046635804081076]
	TIME [epoch: 27.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3278823260803405		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.3278823260803405 | validation: 1.1412760491734875]
	TIME [epoch: 27.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1017960552102453		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.1017960552102453 | validation: 0.9250210833743242]
	TIME [epoch: 27.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8020665628731685		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.8020665628731685 | validation: 0.7112517124048919]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6518936451512822		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.6518936451512822 | validation: 0.9677143318245022]
	TIME [epoch: 27.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031978127852058		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.031978127852058 | validation: 1.1479281249957831]
	TIME [epoch: 27.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0028342998240192		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.0028342998240192 | validation: 0.962217530514549]
	TIME [epoch: 27.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003928705558604		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.003928705558604 | validation: 1.6360246643745655]
	TIME [epoch: 27.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133498277331936		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.133498277331936 | validation: 0.6907446183717073]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.132866157055441		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.132866157055441 | validation: 0.9616401950894452]
	TIME [epoch: 27.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167281897372848		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.9167281897372848 | validation: 0.8378908057480504]
	TIME [epoch: 27.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9620893143018041		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.9620893143018041 | validation: 0.8131323909131948]
	TIME [epoch: 27.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773463786094799		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7773463786094799 | validation: 0.9404762437946761]
	TIME [epoch: 27.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8007911116781645		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8007911116781645 | validation: 0.7013623463646879]
	TIME [epoch: 27.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822264583143583		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.9822264583143583 | validation: 0.8197644360313621]
	TIME [epoch: 27.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9415830874350399		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.9415830874350399 | validation: 0.896149345426432]
	TIME [epoch: 27.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9998845680256669		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.9998845680256669 | validation: 0.8166456604928035]
	TIME [epoch: 27.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1538854859249352		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.1538854859249352 | validation: 1.3067886816657241]
	TIME [epoch: 27.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0935595072466149		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.0935595072466149 | validation: 0.9179924706535161]
	TIME [epoch: 27.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9228296728173673		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.9228296728173673 | validation: 1.3530390708866429]
	TIME [epoch: 27.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.017100448240997		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.017100448240997 | validation: 0.9045742198659278]
	TIME [epoch: 27.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8884208153808784		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.8884208153808784 | validation: 1.2311751010510559]
	TIME [epoch: 27.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9355214728893285		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.9355214728893285 | validation: 1.1197031276883869]
	TIME [epoch: 27.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3137380318869374		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.3137380318869374 | validation: 1.0546401790044866]
	TIME [epoch: 27.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8358356249027459		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.8358356249027459 | validation: 0.8799513491901806]
	TIME [epoch: 27.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8915347629733179		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.8915347629733179 | validation: 0.7529941883903076]
	TIME [epoch: 27.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8705925091719015		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8705925091719015 | validation: 0.8630096029443212]
	TIME [epoch: 27.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9099545223066151		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.9099545223066151 | validation: 0.8591539763977426]
	TIME [epoch: 27.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042384279699768		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.1042384279699768 | validation: 1.4294099192245293]
	TIME [epoch: 27.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053693604386201		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.053693604386201 | validation: 1.7584195309382822]
	TIME [epoch: 27.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2100337696849752		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.2100337696849752 | validation: 1.1242354377742054]
	TIME [epoch: 27.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065827056688387		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.065827056688387 | validation: 1.0128308686453642]
	TIME [epoch: 27.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2005835600332142		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.2005835600332142 | validation: 1.0413744151099376]
	TIME [epoch: 27.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8610036010274886		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.8610036010274886 | validation: 0.7053885277693553]
	TIME [epoch: 27.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8130002218296906		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.8130002218296906 | validation: 0.9866044779769249]
	TIME [epoch: 27.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8242442130539198		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.8242442130539198 | validation: 0.8237336723184686]
	TIME [epoch: 27.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8298861646766589		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.8298861646766589 | validation: 0.8730610548688241]
	TIME [epoch: 27.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0862891332812756		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.0862891332812756 | validation: 1.9447181937852105]
	TIME [epoch: 27.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9963297150117694		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.9963297150117694 | validation: 1.0468132331295477]
	TIME [epoch: 27.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8207823001476559		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8207823001476559 | validation: 0.9895901401904628]
	TIME [epoch: 27.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351022172578697		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.8351022172578697 | validation: 1.0627346788943237]
	TIME [epoch: 27.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8947747541501069		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8947747541501069 | validation: 0.8253417552447715]
	TIME [epoch: 27.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1429897758629184		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.1429897758629184 | validation: 1.2943195673143544]
	TIME [epoch: 27.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2563974508246893		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.2563974508246893 | validation: 0.844970462877163]
	TIME [epoch: 27.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8636837959266094		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.8636837959266094 | validation: 0.9672844847017481]
	TIME [epoch: 27.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9477047686531885		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.9477047686531885 | validation: 0.8273379300491979]
	TIME [epoch: 27.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982510703253645		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.0982510703253645 | validation: 1.2832940684142915]
	TIME [epoch: 27.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0730337924963163		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.0730337924963163 | validation: 1.3778484558895716]
	TIME [epoch: 27.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5294375861023901		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.5294375861023901 | validation: 0.9599407799818951]
	TIME [epoch: 27.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8941434212125545		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.8941434212125545 | validation: 0.6635396954894168]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431832438751057		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.8431832438751057 | validation: 0.8638361029799131]
	TIME [epoch: 27.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8226512817465756		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.8226512817465756 | validation: 0.9117914288009535]
	TIME [epoch: 27.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.778836908530529		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.778836908530529 | validation: 0.7220297391951066]
	TIME [epoch: 27.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8210575262482944		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.8210575262482944 | validation: 0.7382232837467072]
	TIME [epoch: 27.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833556154473986		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7833556154473986 | validation: 1.2675146467088227]
	TIME [epoch: 27.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794529198145574		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.9794529198145574 | validation: 0.6321188230011524]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9289387651833296		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.9289387651833296 | validation: 0.7843975858977343]
	TIME [epoch: 27.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.858217018531722		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.858217018531722 | validation: 0.6353561048649182]
	TIME [epoch: 27.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6250504897008579		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.6250504897008579 | validation: 0.695012894713462]
	TIME [epoch: 27.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7570483201964222		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.7570483201964222 | validation: 0.8848568057287335]
	TIME [epoch: 27.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1968671518086034		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.1968671518086034 | validation: 1.7329691050983145]
	TIME [epoch: 27.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003712496908178		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.003712496908178 | validation: 0.6294398054482785]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672942002852889		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.672942002852889 | validation: 0.6837957475695693]
	TIME [epoch: 27.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7505476224683316		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7505476224683316 | validation: 0.9254700304637428]
	TIME [epoch: 27.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8517476354430211		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.8517476354430211 | validation: 0.9076697125179969]
	TIME [epoch: 27.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036670425608767		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.8036670425608767 | validation: 0.832453531690795]
	TIME [epoch: 27.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990537798852078		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7990537798852078 | validation: 0.8182074500294181]
	TIME [epoch: 27.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773194736803715		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7773194736803715 | validation: 1.4324137501965117]
	TIME [epoch: 27.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9524807592902662		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.9524807592902662 | validation: 1.01425403067838]
	TIME [epoch: 27.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8413178025355045		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.8413178025355045 | validation: 0.7748843592682048]
	TIME [epoch: 27.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813513462555887		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6813513462555887 | validation: 0.8459386512592652]
	TIME [epoch: 27.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8580021972195593		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.8580021972195593 | validation: 1.2141224342159158]
	TIME [epoch: 27.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189426601809504		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.9189426601809504 | validation: 0.8469785362648699]
	TIME [epoch: 27.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9309969089979762		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.9309969089979762 | validation: 1.8498025540727419]
	TIME [epoch: 27.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2649036328384549		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.2649036328384549 | validation: 2.3199380485237806]
	TIME [epoch: 27.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3372277048825785		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.3372277048825785 | validation: 0.8217241037413365]
	TIME [epoch: 27.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198713884497794		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.7198713884497794 | validation: 0.660158802606696]
	TIME [epoch: 27.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891868455991618		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6891868455991618 | validation: 0.5907393730816092]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8927297730372954		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.8927297730372954 | validation: 0.6828911616414195]
	TIME [epoch: 27.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254355821159899		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7254355821159899 | validation: 0.9294782907394662]
	TIME [epoch: 27.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7820559319957854		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.7820559319957854 | validation: 0.6238003036645097]
	TIME [epoch: 27.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914035970922996		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.6914035970922996 | validation: 0.651012794600762]
	TIME [epoch: 27.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6686971281370343		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6686971281370343 | validation: 1.4236887757321985]
	TIME [epoch: 27.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9464462154408211		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.9464462154408211 | validation: 0.8062301260689129]
	TIME [epoch: 27.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9575819634445089		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.9575819634445089 | validation: 0.8181285958380817]
	TIME [epoch: 27.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697519332701618		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.697519332701618 | validation: 0.7901171879897416]
	TIME [epoch: 27.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415472125876954		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.7415472125876954 | validation: 0.8446191003487337]
	TIME [epoch: 27.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228769286798373		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7228769286798373 | validation: 0.6305903018131279]
	TIME [epoch: 27.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8053054645446347		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.8053054645446347 | validation: 0.6973844953918799]
	TIME [epoch: 27.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584200939502062		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.0584200939502062 | validation: 1.9239839009603907]
	TIME [epoch: 27.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9970707949733508		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.9970707949733508 | validation: 0.7062585865317509]
	TIME [epoch: 27.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229737214123078		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7229737214123078 | validation: 0.8303850611892719]
	TIME [epoch: 27.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911251187478725		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7911251187478725 | validation: 0.7288327849420257]
	TIME [epoch: 27.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.75233855992812		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.75233855992812 | validation: 0.8374893004442481]
	TIME [epoch: 27.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834394757652846		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6834394757652846 | validation: 1.0362947097897552]
	TIME [epoch: 27.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1366245105702384		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.1366245105702384 | validation: 0.793194880858567]
	TIME [epoch: 27.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325288878972299		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6325288878972299 | validation: 1.6896286320584906]
	TIME [epoch: 27.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2991168091873426		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.2991168091873426 | validation: 0.9555526089062164]
	TIME [epoch: 27.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7609264825350485		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.7609264825350485 | validation: 0.6842023295450418]
	TIME [epoch: 27.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7763147647568192		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7763147647568192 | validation: 0.8131691913234244]
	TIME [epoch: 27.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825086318446958		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.7825086318446958 | validation: 2.2339361165787897]
	TIME [epoch: 27.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.514617652748258		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.514617652748258 | validation: 0.8277663041571276]
	TIME [epoch: 27.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1469548690428581		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.1469548690428581 | validation: 1.0170138768535002]
	TIME [epoch: 27.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7735035106110659		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.7735035106110659 | validation: 0.6981570760047544]
	TIME [epoch: 27.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8060193723993739		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.8060193723993739 | validation: 1.1394526084887286]
	TIME [epoch: 27.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9262401208681279		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.9262401208681279 | validation: 0.6885085846530353]
	TIME [epoch: 27.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479285932277686		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6479285932277686 | validation: 0.8507609296992312]
	TIME [epoch: 27.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176009030258472		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.9176009030258472 | validation: 0.9679087744129069]
	TIME [epoch: 27.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7610837289400486		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.7610837289400486 | validation: 1.160796814587103]
	TIME [epoch: 27.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1695144539936053		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.1695144539936053 | validation: 0.8915679176316436]
	TIME [epoch: 27.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676960012112147		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.7676960012112147 | validation: 1.0363392711768746]
	TIME [epoch: 27.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8757233476827946		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.8757233476827946 | validation: 1.0160214403414403]
	TIME [epoch: 27.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8626060067173893		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8626060067173893 | validation: 0.644074171398133]
	TIME [epoch: 27.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967206727638673		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6967206727638673 | validation: 0.7449942582565723]
	TIME [epoch: 27.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6413833966273339		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6413833966273339 | validation: 0.7456304483780279]
	TIME [epoch: 27.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346831540128755		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6346831540128755 | validation: 1.9643360646270143]
	TIME [epoch: 27.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4434336665233287		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.4434336665233287 | validation: 0.6953362210397478]
	TIME [epoch: 27.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6541657286693842		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.6541657286693842 | validation: 1.0031380401429526]
	TIME [epoch: 27.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226082991941343		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7226082991941343 | validation: 0.6084480283182088]
	TIME [epoch: 27.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301860541686147		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6301860541686147 | validation: 0.6592472733449434]
	TIME [epoch: 27.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685686499266993		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.7685686499266993 | validation: 0.8968532338274744]
	TIME [epoch: 27.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394939720202766		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.7394939720202766 | validation: 0.865013016225431]
	TIME [epoch: 27.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7841191691138643		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7841191691138643 | validation: 0.9061912366280747]
	TIME [epoch: 27.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559906822312622		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7559906822312622 | validation: 0.5262264094092689]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5985585167418744		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5985585167418744 | validation: 1.3101604658044468]
	TIME [epoch: 27.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1987648015090309		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.1987648015090309 | validation: 0.8445545575440713]
	TIME [epoch: 27.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064076827215995		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7064076827215995 | validation: 0.9813640836570647]
	TIME [epoch: 27.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088983687981044		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8088983687981044 | validation: 0.8803119121316791]
	TIME [epoch: 27.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0152998239695672		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.0152998239695672 | validation: 1.3410898081813298]
	TIME [epoch: 27.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590215675067538		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7590215675067538 | validation: 1.8472614946323753]
	TIME [epoch: 27.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3193107977166574		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.3193107977166574 | validation: 0.6439716456464977]
	TIME [epoch: 27.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9751544119932185		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.9751544119932185 | validation: 1.0483775916340337]
	TIME [epoch: 27.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750269206657749		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.750269206657749 | validation: 0.9108262960844147]
	TIME [epoch: 27.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778684643386877		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.6778684643386877 | validation: 0.6280035606414545]
	TIME [epoch: 27.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7124668604820756		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7124668604820756 | validation: 0.9391759831838854]
	TIME [epoch: 27.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214067867983766		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7214067867983766 | validation: 0.6087951681487556]
	TIME [epoch: 27.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689449736815825		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6689449736815825 | validation: 0.771050985639612]
	TIME [epoch: 27.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261266461444156		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7261266461444156 | validation: 0.6830915259635515]
	TIME [epoch: 27.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8642930315949096		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.8642930315949096 | validation: 0.6910356959245131]
	TIME [epoch: 27.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285485638896897		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.7285485638896897 | validation: 0.9707937024234753]
	TIME [epoch: 27.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796711437060224		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.7796711437060224 | validation: 0.7596346322728005]
	TIME [epoch: 27.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1285667330891753		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.1285667330891753 | validation: 0.7056081603643583]
	TIME [epoch: 27.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7467360257193459		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.7467360257193459 | validation: 0.650424489828385]
	TIME [epoch: 27.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7997779577439166		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.7997779577439166 | validation: 0.6991686323044727]
	TIME [epoch: 27.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393262391485655		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6393262391485655 | validation: 0.6146842875605032]
	TIME [epoch: 27.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579405067754646		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5579405067754646 | validation: 0.5584220053376354]
	TIME [epoch: 27.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206517421200461		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7206517421200461 | validation: 0.5454696527922617]
	TIME [epoch: 27.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983561180203845		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5983561180203845 | validation: 0.8031742437458317]
	TIME [epoch: 27.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656683857319201		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.656683857319201 | validation: 0.6442387309525178]
	TIME [epoch: 27.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155032089940567		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6155032089940567 | validation: 0.5741127356087911]
	TIME [epoch: 27.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649825215720162		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5649825215720162 | validation: 0.5441146405345044]
	TIME [epoch: 27.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364846089021349		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.7364846089021349 | validation: 0.6809520910261102]
	TIME [epoch: 27.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328804155444322		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.6328804155444322 | validation: 1.0731102330922326]
	TIME [epoch: 27.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8872974531961081		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.8872974531961081 | validation: 0.6970814006870903]
	TIME [epoch: 27.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6027087304747953		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6027087304747953 | validation: 0.9089714149908592]
	TIME [epoch: 27.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775555588394039		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.775555588394039 | validation: 0.6533504543098998]
	TIME [epoch: 27.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161146263649876		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6161146263649876 | validation: 0.6406781458102568]
	TIME [epoch: 27.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973863740190437		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5973863740190437 | validation: 0.7118745080842479]
	TIME [epoch: 27.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585549459109039		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5585549459109039 | validation: 0.979475316012637]
	TIME [epoch: 27.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7518623967023977		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.7518623967023977 | validation: 0.6296586902046869]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219326172986333		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.7219326172986333 | validation: 0.6153593603393753]
	TIME [epoch: 27.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704127422042492		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6704127422042492 | validation: 0.5620582883496527]
	TIME [epoch: 27.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.661298423429771		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.661298423429771 | validation: 1.0716501051573752]
	TIME [epoch: 27.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6377663192276398		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6377663192276398 | validation: 1.2553797580750692]
	TIME [epoch: 27.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0556714779863796		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.0556714779863796 | validation: 1.0277723970970916]
	TIME [epoch: 27.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7614537357936031		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.7614537357936031 | validation: 0.6422885723418764]
	TIME [epoch: 27.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050608452318509		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.050608452318509 | validation: 1.111536792407648]
	TIME [epoch: 27.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332351031744885		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7332351031744885 | validation: 0.6723908858049308]
	TIME [epoch: 27.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319819841246946		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6319819841246946 | validation: 0.6638907143034396]
	TIME [epoch: 27.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5919952801780523		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5919952801780523 | validation: 0.6411360630443208]
	TIME [epoch: 27.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589355581342754		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.6589355581342754 | validation: 0.5555427419080466]
	TIME [epoch: 27.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4925065640330698		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.4925065640330698 | validation: 0.822312737899672]
	TIME [epoch: 27.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433353632852999		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.6433353632852999 | validation: 1.089222085053057]
	TIME [epoch: 27.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787110399448506		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.7787110399448506 | validation: 0.7864482038472502]
	TIME [epoch: 27.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492342621488971		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.7492342621488971 | validation: 0.908898629738639]
	TIME [epoch: 27.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476999754995612		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6476999754995612 | validation: 0.7362522833544799]
	TIME [epoch: 27.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8112157996682208		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.8112157996682208 | validation: 0.8495571810862561]
	TIME [epoch: 27.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782845031340859		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.782845031340859 | validation: 0.8117060793445552]
	TIME [epoch: 27.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6523527400225708		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6523527400225708 | validation: 0.8446950535857313]
	TIME [epoch: 27.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102433820846522		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6102433820846522 | validation: 0.8088726160651212]
	TIME [epoch: 27.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8045400441016247		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.8045400441016247 | validation: 1.3354583756855047]
	TIME [epoch: 27.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7388227024938228		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.7388227024938228 | validation: 0.638846716011098]
	TIME [epoch: 27.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006651722051874		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6006651722051874 | validation: 0.7814366860898164]
	TIME [epoch: 27.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8937070902665418		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.8937070902665418 | validation: 0.8946695162643005]
	TIME [epoch: 27.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6450489005295827		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.6450489005295827 | validation: 0.8673462672321497]
	TIME [epoch: 27.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508351933111041		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6508351933111041 | validation: 0.490283581233074]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_610.pth
	Model improved!!!
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5156002248726054		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5156002248726054 | validation: 0.500870595688863]
	TIME [epoch: 27.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6546775026267364		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.6546775026267364 | validation: 0.5831310959978315]
	TIME [epoch: 27.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802988421346964		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5802988421346964 | validation: 0.5010788859612998]
	TIME [epoch: 27.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690824027414698		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5690824027414698 | validation: 0.6131721939441119]
	TIME [epoch: 27.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797905529937319		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6797905529937319 | validation: 0.54914195926716]
	TIME [epoch: 27.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161271543143344		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5161271543143344 | validation: 0.6993333602972611]
	TIME [epoch: 27.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131594449409143		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.6131594449409143 | validation: 0.7249696317329591]
	TIME [epoch: 27.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9091224769381574		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.9091224769381574 | validation: 0.8918887774508312]
	TIME [epoch: 27.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071129870869562		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.8071129870869562 | validation: 0.783424507288562]
	TIME [epoch: 27.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418344290850931		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.7418344290850931 | validation: 0.7667053957151054]
	TIME [epoch: 27.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5437516181644557		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5437516181644557 | validation: 0.6010583675008114]
	TIME [epoch: 27.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075110355234555		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6075110355234555 | validation: 0.6318645174534158]
	TIME [epoch: 27.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6175884897216128		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.6175884897216128 | validation: 0.6309755990697873]
	TIME [epoch: 27.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272096818245793		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5272096818245793 | validation: 0.6251434117125089]
	TIME [epoch: 27.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609662046751773		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.609662046751773 | validation: 0.8397017037311728]
	TIME [epoch: 27.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6018948608504895		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.6018948608504895 | validation: 0.6513035067316344]
	TIME [epoch: 27.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991001585084093		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5991001585084093 | validation: 0.5753199510940248]
	TIME [epoch: 27.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052240395158783		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6052240395158783 | validation: 0.5818471017980656]
	TIME [epoch: 27.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068994976488393		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6068994976488393 | validation: 0.46192394059175346]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677137969230774		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.677137969230774 | validation: 0.7424721528813308]
	TIME [epoch: 27.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5954130687820829		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5954130687820829 | validation: 0.6341160434528754]
	TIME [epoch: 27.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260089225184053		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5260089225184053 | validation: 0.5777882359932328]
	TIME [epoch: 27.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446132752068608		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5446132752068608 | validation: 0.4224892281267002]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_633.pth
	Model improved!!!
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552013923460429		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5552013923460429 | validation: 0.5074392368010346]
	TIME [epoch: 27.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746993460428438		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5746993460428438 | validation: 0.7296898897180668]
	TIME [epoch: 27.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9195921294417706		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.9195921294417706 | validation: 0.6947110702853391]
	TIME [epoch: 27.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507717110766418		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.507717110766418 | validation: 0.5459844702481241]
	TIME [epoch: 27.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021826373200956		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.6021826373200956 | validation: 0.5078887053001696]
	TIME [epoch: 27.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599692023235791		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.599692023235791 | validation: 0.48923451130312007]
	TIME [epoch: 27.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254926627729475		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5254926627729475 | validation: 0.6262649409203198]
	TIME [epoch: 27.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8365340892277141		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.8365340892277141 | validation: 1.0138530424826109]
	TIME [epoch: 27.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324165384426275		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5324165384426275 | validation: 0.5792257000857104]
	TIME [epoch: 27.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6209106679072643		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.6209106679072643 | validation: 0.7055196644240229]
	TIME [epoch: 27.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066568944401478		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6066568944401478 | validation: 0.9590813227192322]
	TIME [epoch: 27.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428669051289628		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.6428669051289628 | validation: 0.5223949283270949]
	TIME [epoch: 27.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127012821457961		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.7127012821457961 | validation: 1.2634070665643604]
	TIME [epoch: 27.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159583312979132		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.7159583312979132 | validation: 0.4872577808107876]
	TIME [epoch: 27.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390117508675938		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.6390117508675938 | validation: 0.6564701672236666]
	TIME [epoch: 27.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677680601329278		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.5677680601329278 | validation: 0.610569635151082]
	TIME [epoch: 27.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025755534637185		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.6025755534637185 | validation: 0.4960483517118564]
	TIME [epoch: 27.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504197570850003		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.504197570850003 | validation: 0.6408581812366255]
	TIME [epoch: 27.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377462826493338		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5377462826493338 | validation: 0.5517653938821455]
	TIME [epoch: 27.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067208570048404		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5067208570048404 | validation: 0.4284383371243048]
	TIME [epoch: 27.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5622512899414994		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5622512899414994 | validation: 0.5855960173867204]
	TIME [epoch: 27.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611298444837058		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5611298444837058 | validation: 0.6113051594113635]
	TIME [epoch: 27.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871013775276759		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5871013775276759 | validation: 0.6369102183749782]
	TIME [epoch: 27.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483333933894876		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.6483333933894876 | validation: 0.45763435250269524]
	TIME [epoch: 27.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422270993794767		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5422270993794767 | validation: 0.6665205444585971]
	TIME [epoch: 27.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768197059326031		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5768197059326031 | validation: 0.5613454841345276]
	TIME [epoch: 27.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437199555556752		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.4437199555556752 | validation: 0.5572803545628532]
	TIME [epoch: 27.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158376049194936		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.6158376049194936 | validation: 0.672628056709168]
	TIME [epoch: 27.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202905657349057		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5202905657349057 | validation: 0.4906652477656971]
	TIME [epoch: 27.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5485770444211222		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5485770444211222 | validation: 0.7986706649300169]
	TIME [epoch: 27.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218290251942846		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5218290251942846 | validation: 0.6183012377230523]
	TIME [epoch: 27.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49013438217263067		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.49013438217263067 | validation: 0.7845490622974456]
	TIME [epoch: 27.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343168938644308		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5343168938644308 | validation: 0.5149759647806994]
	TIME [epoch: 27.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839016027489949		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4839016027489949 | validation: 0.4756299808596798]
	TIME [epoch: 27.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678138337810811		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.7678138337810811 | validation: 0.9045112259062799]
	TIME [epoch: 27.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6194731473995646		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.6194731473995646 | validation: 0.6489339626551822]
	TIME [epoch: 27.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596889603980677		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5596889603980677 | validation: 0.5340015411527724]
	TIME [epoch: 27.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4591008441526707		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.4591008441526707 | validation: 0.6043284706253317]
	TIME [epoch: 27.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788469595047761		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6788469595047761 | validation: 0.5275929289916186]
	TIME [epoch: 27.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775620251310657		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5775620251310657 | validation: 0.743663012088263]
	TIME [epoch: 27.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973695157686271		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5973695157686271 | validation: 0.8672006583534665]
	TIME [epoch: 27.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7898919594725455		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.7898919594725455 | validation: 0.8754237205964177]
	TIME [epoch: 27.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712384868276904		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.712384868276904 | validation: 0.6977031654234125]
	TIME [epoch: 27.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641445708362431		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5641445708362431 | validation: 0.5377660627528686]
	TIME [epoch: 27.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185693706700689		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5185693706700689 | validation: 0.6016867786406332]
	TIME [epoch: 27.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8856600105298904		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.8856600105298904 | validation: 0.7057476313668124]
	TIME [epoch: 27.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059258071058578		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5059258071058578 | validation: 0.6580409596180588]
	TIME [epoch: 27.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179334809731374		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5179334809731374 | validation: 0.4591624131327237]
	TIME [epoch: 27.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107390636403958		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5107390636403958 | validation: 0.46708308311642854]
	TIME [epoch: 27.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40360592323807565		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.40360592323807565 | validation: 0.4164003372561224]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646262539611711		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.6646262539611711 | validation: 0.6192762209082744]
	TIME [epoch: 27.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8598078196973924		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.8598078196973924 | validation: 0.6036900321324398]
	TIME [epoch: 27.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929987752076591		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5929987752076591 | validation: 0.7391090960650953]
	TIME [epoch: 27.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5591988511944734		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5591988511944734 | validation: 0.8119384398703753]
	TIME [epoch: 27.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118140509041426		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.8118140509041426 | validation: 0.7916983000783845]
	TIME [epoch: 27.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908606294405641		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.4908606294405641 | validation: 0.6266725970882715]
	TIME [epoch: 27.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237113863013367		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5237113863013367 | validation: 0.5494438537302233]
	TIME [epoch: 27.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025102908173066		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.6025102908173066 | validation: 0.5385326608312128]
	TIME [epoch: 27.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.490737225288501		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.490737225288501 | validation: 1.047751813309117]
	TIME [epoch: 27.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425859832016126		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.2425859832016126 | validation: 1.260111945839961]
	TIME [epoch: 27.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7729039091526155		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.7729039091526155 | validation: 0.47939712211689667]
	TIME [epoch: 27.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771475162334679		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5771475162334679 | validation: 0.44335975831255414]
	TIME [epoch: 27.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390869127283901		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.390869127283901 | validation: 0.44358222292558436]
	TIME [epoch: 27.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4940226244840919		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.4940226244840919 | validation: 0.5081502266605511]
	TIME [epoch: 27.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45229664080381904		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.45229664080381904 | validation: 0.6547302731634137]
	TIME [epoch: 27.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49319853966361493		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.49319853966361493 | validation: 0.46168773785421807]
	TIME [epoch: 27.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659006731937704		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.4659006731937704 | validation: 0.5504927817723408]
	TIME [epoch: 27.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103885873483506		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5103885873483506 | validation: 0.8305906223403569]
	TIME [epoch: 27.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411861605993862		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6411861605993862 | validation: 0.4805190593024648]
	TIME [epoch: 27.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47107778518242055		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.47107778518242055 | validation: 0.5692539301364024]
	TIME [epoch: 27.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47673664363207163		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.47673664363207163 | validation: 0.5449659967723491]
	TIME [epoch: 27.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4949313105264806		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.4949313105264806 | validation: 0.4281578185455597]
	TIME [epoch: 27.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459960614550734		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5459960614550734 | validation: 0.5294661541249321]
	TIME [epoch: 27.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037468794148572		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.5037468794148572 | validation: 0.697510064795527]
	TIME [epoch: 27.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.536720912930151		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.536720912930151 | validation: 0.5453811915966107]
	TIME [epoch: 27.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021806416971908		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5021806416971908 | validation: 0.5786502130605018]
	TIME [epoch: 27.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241283086172921		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5241283086172921 | validation: 0.4768552167704083]
	TIME [epoch: 27.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141112912203438		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6141112912203438 | validation: 1.348294699321463]
	TIME [epoch: 27.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8391998476588751		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.8391998476588751 | validation: 0.6947865352492125]
	TIME [epoch: 27.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5511220835337424		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5511220835337424 | validation: 0.6508076773764673]
	TIME [epoch: 27.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548804793827747		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5548804793827747 | validation: 0.7987075824274991]
	TIME [epoch: 27.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451742034984326		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5451742034984326 | validation: 0.7221134833943179]
	TIME [epoch: 27.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490014935016082		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5490014935016082 | validation: 0.5627625046282878]
	TIME [epoch: 27.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44464342467250273		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.44464342467250273 | validation: 0.5372812879096754]
	TIME [epoch: 27.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517276908670971		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.517276908670971 | validation: 0.52218505395448]
	TIME [epoch: 27.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216520707095976		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.7216520707095976 | validation: 0.9231918810532258]
	TIME [epoch: 27.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3113720086390137		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.3113720086390137 | validation: 0.6904771319149374]
	TIME [epoch: 27.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49528826050931696		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.49528826050931696 | validation: 0.4533758942763555]
	TIME [epoch: 27.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4615639559624941		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4615639559624941 | validation: 0.534174993023744]
	TIME [epoch: 27.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493159188003562		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.5493159188003562 | validation: 0.46438799710548806]
	TIME [epoch: 27.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46855401458415835		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.46855401458415835 | validation: 0.44135737769370376]
	TIME [epoch: 27.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575934246871143		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.575934246871143 | validation: 0.5944893002924213]
	TIME [epoch: 27.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880446091851217		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4880446091851217 | validation: 0.6904196157240674]
	TIME [epoch: 27.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542072033806796		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5542072033806796 | validation: 0.4704385315977502]
	TIME [epoch: 27.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41837990137084397		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.41837990137084397 | validation: 0.49595768618982866]
	TIME [epoch: 27.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4091262601852903		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.4091262601852903 | validation: 0.5104719770582404]
	TIME [epoch: 27.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48754518530760516		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.48754518530760516 | validation: 0.4333566863780798]
	TIME [epoch: 27.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44824109312405663		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.44824109312405663 | validation: 0.5495080806348994]
	TIME [epoch: 27.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338674169738089		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.7338674169738089 | validation: 0.5061531765737347]
	TIME [epoch: 27.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880434118019855		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4880434118019855 | validation: 0.6132422450969298]
	TIME [epoch: 27.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5504697820220373		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5504697820220373 | validation: 0.4697112577310136]
	TIME [epoch: 27.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47764473852844747		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.47764473852844747 | validation: 0.5388865094603523]
	TIME [epoch: 27.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356344020826764		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5356344020826764 | validation: 0.5109210339258128]
	TIME [epoch: 27.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4566385113665939		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4566385113665939 | validation: 0.4352077626485874]
	TIME [epoch: 27.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43240147832368614		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.43240147832368614 | validation: 0.5945297282611658]
	TIME [epoch: 27.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323911040702615		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.7323911040702615 | validation: 0.7037728559733029]
	TIME [epoch: 27.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179777657609601		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.6179777657609601 | validation: 0.8054237973331044]
	TIME [epoch: 27.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6070238724142393		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.6070238724142393 | validation: 0.5627053561793908]
	TIME [epoch: 27.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838305245930505		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.6838305245930505 | validation: 0.48974109824552514]
	TIME [epoch: 27.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703875892192434		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4703875892192434 | validation: 0.46210007578896284]
	TIME [epoch: 27.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658266129398212		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.4658266129398212 | validation: 0.46673299399149965]
	TIME [epoch: 27.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4627255204806474		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.4627255204806474 | validation: 0.49689092184484396]
	TIME [epoch: 27.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4941409187371305		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.4941409187371305 | validation: 0.4417360346587534]
	TIME [epoch: 27.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43713067199130884		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.43713067199130884 | validation: 0.6657609064016058]
	TIME [epoch: 27.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46618343573702975		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.46618343573702975 | validation: 0.7686195131419595]
	TIME [epoch: 27.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389470260804123		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5389470260804123 | validation: 0.6846746057745984]
	TIME [epoch: 27.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387655397202165		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.7387655397202165 | validation: 0.6867214294928473]
	TIME [epoch: 27.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770780087296965		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5770780087296965 | validation: 0.6239993547184399]
	TIME [epoch: 27.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378397146163866		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5378397146163866 | validation: 0.5775444059310884]
	TIME [epoch: 27.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641720989153581		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.641720989153581 | validation: 0.6798437722428397]
	TIME [epoch: 27.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723414560809277		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6723414560809277 | validation: 0.7036835148628796]
	TIME [epoch: 27.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940081418267069		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5940081418267069 | validation: 0.5012591097437108]
	TIME [epoch: 27.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44982015862228697		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.44982015862228697 | validation: 0.5303777145791047]
	TIME [epoch: 27.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4951661703150468		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.4951661703150468 | validation: 0.5790200745306378]
	TIME [epoch: 27.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743109683827665		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5743109683827665 | validation: 0.43498815373273225]
	TIME [epoch: 27.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49745619316741574		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.49745619316741574 | validation: 0.8234731202985128]
	TIME [epoch: 27.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691682448471553		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5691682448471553 | validation: 0.5930753100407679]
	TIME [epoch: 27.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658917319207554		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.4658917319207554 | validation: 0.48802253175570104]
	TIME [epoch: 27.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590742622565226		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.4590742622565226 | validation: 0.62765902446264]
	TIME [epoch: 27.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43203179233698635		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.43203179233698635 | validation: 0.4097516203951125]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_763.pth
	Model improved!!!
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808500995736025		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4808500995736025 | validation: 0.6294770521831282]
	TIME [epoch: 27.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49845488458777		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.49845488458777 | validation: 0.46206609597109344]
	TIME [epoch: 27.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37453055282325454		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.37453055282325454 | validation: 0.41055927061442166]
	TIME [epoch: 27.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934721210824469		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3934721210824469 | validation: 0.37862587610532616]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504728126641581		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.504728126641581 | validation: 0.39187356063064704]
	TIME [epoch: 27.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42861321822631726		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.42861321822631726 | validation: 0.4834789578520278]
	TIME [epoch: 27.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127491198540132		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.5127491198540132 | validation: 0.8161733580283084]
	TIME [epoch: 27.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245105720920587		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.6245105720920587 | validation: 0.5450454602988105]
	TIME [epoch: 27.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563592544473412		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.563592544473412 | validation: 0.42046947593009193]
	TIME [epoch: 27.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433605047137972		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.433605047137972 | validation: 0.4099522214745043]
	TIME [epoch: 27.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137907859319343		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4137907859319343 | validation: 0.7027836851013176]
	TIME [epoch: 27.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269607745863216		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5269607745863216 | validation: 0.41313723584314566]
	TIME [epoch: 27.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43520230282822114		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.43520230282822114 | validation: 0.46276950593806077]
	TIME [epoch: 27.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39156974861198823		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.39156974861198823 | validation: 0.4137508787414115]
	TIME [epoch: 27.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39565095677257833		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.39565095677257833 | validation: 0.4270841340164988]
	TIME [epoch: 27.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421950638658157		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.421950638658157 | validation: 0.4193295510499732]
	TIME [epoch: 27.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4655570575119429		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4655570575119429 | validation: 0.5713574111302046]
	TIME [epoch: 27.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491964605064585		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.6491964605064585 | validation: 0.5665173877584568]
	TIME [epoch: 27.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014177278536571		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5014177278536571 | validation: 0.8976240416833381]
	TIME [epoch: 27.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5867244459112125		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5867244459112125 | validation: 0.42886686329818885]
	TIME [epoch: 27.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139842470925481		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.4139842470925481 | validation: 0.46437435688333284]
	TIME [epoch: 27.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48838250761664626		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.48838250761664626 | validation: 0.5250918633834303]
	TIME [epoch: 27.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4418152709970462		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4418152709970462 | validation: 0.5381373332904587]
	TIME [epoch: 27.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137183317981196		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.7137183317981196 | validation: 0.5601628700756318]
	TIME [epoch: 27.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42124833612421386		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.42124833612421386 | validation: 0.573439918460915]
	TIME [epoch: 27.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4557682469745806		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.4557682469745806 | validation: 0.4416106908739316]
	TIME [epoch: 27.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39839398109349416		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.39839398109349416 | validation: 0.38146656589057537]
	TIME [epoch: 27.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4102289790988697		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4102289790988697 | validation: 0.4889008515866711]
	TIME [epoch: 27.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45124192996146906		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.45124192996146906 | validation: 0.4068009723217456]
	TIME [epoch: 27.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42487299239294496		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.42487299239294496 | validation: 0.4225939008476015]
	TIME [epoch: 27.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5629784908523677		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5629784908523677 | validation: 0.43194229480293383]
	TIME [epoch: 27.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386242599217583		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.386242599217583 | validation: 0.40891290673492764]
	TIME [epoch: 27.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612177734895557		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3612177734895557 | validation: 0.6539249046580006]
	TIME [epoch: 27.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740632974732982		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.5740632974732982 | validation: 0.4768462399244473]
	TIME [epoch: 27.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571502836666935		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.4571502836666935 | validation: 0.604862165566619]
	TIME [epoch: 27.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220613022401981		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.5220613022401981 | validation: 0.5958189448088786]
	TIME [epoch: 27.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.579503287016085		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.579503287016085 | validation: 0.6009489941900013]
	TIME [epoch: 27.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845300227725028		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.4845300227725028 | validation: 0.6256032515885831]
	TIME [epoch: 27.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656025466425639		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5656025466425639 | validation: 0.7377822681047778]
	TIME [epoch: 27.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361846871943648		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.6361846871943648 | validation: 0.6364814509165122]
	TIME [epoch: 27.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5996802897396528		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.5996802897396528 | validation: 0.6415794956890755]
	TIME [epoch: 27.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074161584964929		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.5074161584964929 | validation: 0.5926516575374047]
	TIME [epoch: 27.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45374021231521316		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.45374021231521316 | validation: 0.49555026218172005]
	TIME [epoch: 27.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568329197087799		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.568329197087799 | validation: 0.6506876033042563]
	TIME [epoch: 27.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531225866895547		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.531225866895547 | validation: 0.5276902361217767]
	TIME [epoch: 27.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210183269221889		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5210183269221889 | validation: 0.5202798910787404]
	TIME [epoch: 27.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48589528523719383		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.48589528523719383 | validation: 0.6413658832237599]
	TIME [epoch: 27.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5209039055134103		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.5209039055134103 | validation: 0.4526284918969003]
	TIME [epoch: 27.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862725537719358		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.3862725537719358 | validation: 0.5069197593895831]
	TIME [epoch: 27.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357150909617132		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.5357150909617132 | validation: 0.36942040894929984]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_813.pth
	Model improved!!!
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37801143251305597		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.37801143251305597 | validation: 0.547102366751901]
	TIME [epoch: 27.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.489444665768488		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.489444665768488 | validation: 0.5158219465837123]
	TIME [epoch: 27.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563406408127722		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.563406408127722 | validation: 0.4011548991263014]
	TIME [epoch: 27.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48071630285564426		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.48071630285564426 | validation: 0.4546928423733671]
	TIME [epoch: 27.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607957549662338		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4607957549662338 | validation: 0.384584221249506]
	TIME [epoch: 27.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983134226080831		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3983134226080831 | validation: 0.3579305805484691]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_819.pth
	Model improved!!!
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259197907024895		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.4259197907024895 | validation: 0.4347604381953154]
	TIME [epoch: 27.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39562397096093205		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.39562397096093205 | validation: 0.40889940328513247]
	TIME [epoch: 27.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40463357320750054		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.40463357320750054 | validation: 0.482414821064513]
	TIME [epoch: 27.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41203631511678845		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.41203631511678845 | validation: 0.8813297759758478]
	TIME [epoch: 27.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006564510986106		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.7006564510986106 | validation: 0.4287706768616931]
	TIME [epoch: 27.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36420627177163356		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.36420627177163356 | validation: 0.3777898887147963]
	TIME [epoch: 27.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472270240301153		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3472270240301153 | validation: 0.3245614974593042]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597733370792825		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3597733370792825 | validation: 0.3914060482145622]
	TIME [epoch: 27.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5073079891433661		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.5073079891433661 | validation: 0.5896508784342247]
	TIME [epoch: 27.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47350524678737993		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.47350524678737993 | validation: 0.3496345491033489]
	TIME [epoch: 27.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694766588992999		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.3694766588992999 | validation: 0.4262378748808506]
	TIME [epoch: 27.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39774213010945025		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.39774213010945025 | validation: 0.5188049854068544]
	TIME [epoch: 27.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39348646157067707		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.39348646157067707 | validation: 0.6707017139268868]
	TIME [epoch: 27.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548076800305858		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.4548076800305858 | validation: 0.36975887849536115]
	TIME [epoch: 27.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3967056893162844		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3967056893162844 | validation: 0.34819266594143355]
	TIME [epoch: 27.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31327991102042674		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.31327991102042674 | validation: 0.3509075125510989]
	TIME [epoch: 27.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074365165321817		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4074365165321817 | validation: 0.3531522284571536]
	TIME [epoch: 27.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007158922904534		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.4007158922904534 | validation: 0.43423678382703074]
	TIME [epoch: 27.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443234113231572		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.3443234113231572 | validation: 0.6723659114085289]
	TIME [epoch: 27.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46433339727645795		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.46433339727645795 | validation: 0.5458565036247341]
	TIME [epoch: 27.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453498526806178		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.4453498526806178 | validation: 0.5436036424837103]
	TIME [epoch: 27.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47933668494363246		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.47933668494363246 | validation: 0.4048345926192083]
	TIME [epoch: 27.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840440098227177		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.3840440098227177 | validation: 0.3663749189357602]
	TIME [epoch: 27.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3797346875518383		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3797346875518383 | validation: 0.43925624009793296]
	TIME [epoch: 27.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692124331656216		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.3692124331656216 | validation: 0.3555994375553672]
	TIME [epoch: 27.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.372303840436706		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.372303840436706 | validation: 0.33156254524226614]
	TIME [epoch: 27.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908104141047576		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3908104141047576 | validation: 0.3520210533077352]
	TIME [epoch: 27.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37555817597278		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.37555817597278 | validation: 0.38821349648870523]
	TIME [epoch: 27.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40826756656710866		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.40826756656710866 | validation: 0.43889364952412757]
	TIME [epoch: 27.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4192922593479881		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4192922593479881 | validation: 0.5769302288620182]
	TIME [epoch: 27.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6196553281233826		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.6196553281233826 | validation: 0.4104227289489398]
	TIME [epoch: 27.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42254128030858223		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.42254128030858223 | validation: 0.4849336537131936]
	TIME [epoch: 27.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772942167527783		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.3772942167527783 | validation: 0.3633961553276967]
	TIME [epoch: 27.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4381468241047768		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4381468241047768 | validation: 0.5057097177115316]
	TIME [epoch: 27.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296054035667326		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4296054035667326 | validation: 0.7374744060389834]
	TIME [epoch: 27.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46959232931186096		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.46959232931186096 | validation: 0.4582087399678855]
	TIME [epoch: 27.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547139667451944		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.3547139667451944 | validation: 0.4228241030687206]
	TIME [epoch: 27.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44059195769168547		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.44059195769168547 | validation: 0.4169399462992792]
	TIME [epoch: 27.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781523979151426		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.3781523979151426 | validation: 0.452117684631278]
	TIME [epoch: 27.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5276515064034354		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5276515064034354 | validation: 0.3788664474043084]
	TIME [epoch: 27.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37090601680500174		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.37090601680500174 | validation: 0.35089876000360976]
	TIME [epoch: 27.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40258060877166585		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.40258060877166585 | validation: 0.4886189615192963]
	TIME [epoch: 27.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045739001151889		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.4045739001151889 | validation: 0.44827503739156593]
	TIME [epoch: 27.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408449616321219		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.408449616321219 | validation: 0.46171280442093676]
	TIME [epoch: 27.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38498584461747476		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.38498584461747476 | validation: 0.385219890484019]
	TIME [epoch: 27.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657922627912325		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.3657922627912325 | validation: 0.49358706533677776]
	TIME [epoch: 27.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131290651674083		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4131290651674083 | validation: 0.6432283207170252]
	TIME [epoch: 27.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43798560952302423		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.43798560952302423 | validation: 0.3892164511699857]
	TIME [epoch: 27.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453780132127506		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4453780132127506 | validation: 0.4445357651552985]
	TIME [epoch: 27.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41989451410965656		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.41989451410965656 | validation: 0.427237731416092]
	TIME [epoch: 27.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39931535485590264		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.39931535485590264 | validation: 0.348991492115924]
	TIME [epoch: 27.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233500805631046		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.3233500805631046 | validation: 0.3780382499010231]
	TIME [epoch: 27.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33568790031660706		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.33568790031660706 | validation: 0.40403458452952934]
	TIME [epoch: 27.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721179893642925		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.3721179893642925 | validation: 0.33041182017592957]
	TIME [epoch: 27.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36911386119703765		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.36911386119703765 | validation: 0.44806237346428146]
	TIME [epoch: 27.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675260835121447		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4675260835121447 | validation: 0.5057100217202727]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528098837655227		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4528098837655227 | validation: 0.36140874593981537]
	TIME [epoch: 27.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034093104590975		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4034093104590975 | validation: 0.5000615679558738]
	TIME [epoch: 27.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40074835720102797		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.40074835720102797 | validation: 0.45521483107550753]
	TIME [epoch: 27.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061323275925974		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4061323275925974 | validation: 0.40541144210439883]
	TIME [epoch: 27.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.372308043308864		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.372308043308864 | validation: 0.34046629761042824]
	TIME [epoch: 27.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349739532049528		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3349739532049528 | validation: 0.42363451602193664]
	TIME [epoch: 27.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35456527706042057		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.35456527706042057 | validation: 0.41233196759688506]
	TIME [epoch: 27.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39878711395802785		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.39878711395802785 | validation: 0.40373063131670167]
	TIME [epoch: 27.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40346666206552106		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.40346666206552106 | validation: 0.8154604389455342]
	TIME [epoch: 27.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517524972335659		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.5517524972335659 | validation: 0.4352819567381848]
	TIME [epoch: 27.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3265249192550853		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3265249192550853 | validation: 0.3650892065779696]
	TIME [epoch: 27.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33151961874900393		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.33151961874900393 | validation: 0.37002584676438594]
	TIME [epoch: 27.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761782965304475		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.4761782965304475 | validation: 0.623219276499424]
	TIME [epoch: 27.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613413892616593		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.5613413892616593 | validation: 0.321617384233966]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37836680474068785		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.37836680474068785 | validation: 0.3814486230585252]
	TIME [epoch: 27.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366895620904957		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.366895620904957 | validation: 0.4229050097352577]
	TIME [epoch: 27.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190038560137578		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.4190038560137578 | validation: 0.6047274261230975]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335523600685187		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.6335523600685187 | validation: 0.9533883857212717]
	TIME [epoch: 27.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343546082740913		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.7343546082740913 | validation: 0.7913837037268399]
	TIME [epoch: 27.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47530191818239964		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.47530191818239964 | validation: 0.4364060409266651]
	TIME [epoch: 27.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31812529705141623		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.31812529705141623 | validation: 0.3979854862866034]
	TIME [epoch: 27.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256466411783271		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.3256466411783271 | validation: 0.47791723714553563]
	TIME [epoch: 27.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34422133633414426		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.34422133633414426 | validation: 0.5035338194230196]
	TIME [epoch: 27.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376911140269864		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.3376911140269864 | validation: 0.45090349062237023]
	TIME [epoch: 27.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32240984351806656		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.32240984351806656 | validation: 0.4160162992836922]
	TIME [epoch: 27.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246014192803765		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3246014192803765 | validation: 0.36839967972752746]
	TIME [epoch: 27.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939514026498649		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2939514026498649 | validation: 0.42932940484995585]
	TIME [epoch: 27.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32568919543908265		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.32568919543908265 | validation: 0.40348880513143437]
	TIME [epoch: 27.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.369217166962977		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.369217166962977 | validation: 0.4313335817574574]
	TIME [epoch: 27.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45927163702584306		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.45927163702584306 | validation: 0.6583183516516999]
	TIME [epoch: 27.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4960237542926131		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.4960237542926131 | validation: 0.4391115402715958]
	TIME [epoch: 27.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36864800673844117		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.36864800673844117 | validation: 0.40621024860236776]
	TIME [epoch: 27.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547863697991895		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.3547863697991895 | validation: 0.4326703356809358]
	TIME [epoch: 27.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586267046397634		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3586267046397634 | validation: 0.5184780657812157]
	TIME [epoch: 27.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435183902294345		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.4435183902294345 | validation: 0.4525285781516192]
	TIME [epoch: 27.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40757184216845677		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.40757184216845677 | validation: 0.39731631418636587]
	TIME [epoch: 27.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36066766466448824		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.36066766466448824 | validation: 0.43775420823764144]
	TIME [epoch: 27.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44707584058964456		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.44707584058964456 | validation: 0.5392707484163988]
	TIME [epoch: 27.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551026190097293		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.3551026190097293 | validation: 0.3821323492402013]
	TIME [epoch: 27.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36440180556519564		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.36440180556519564 | validation: 0.44205243819279316]
	TIME [epoch: 27.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413492135740726		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.3413492135740726 | validation: 0.4433538036668047]
	TIME [epoch: 27.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676907783259811		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.3676907783259811 | validation: 0.35453420164683225]
	TIME [epoch: 27.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338316381447526		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3338316381447526 | validation: 0.3696279010095539]
	TIME [epoch: 27.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39425867689302024		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.39425867689302024 | validation: 0.441079041788506]
	TIME [epoch: 27.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3898665454911649		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.3898665454911649 | validation: 0.48871305195983555]
	TIME [epoch: 27.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41013472762988634		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.41013472762988634 | validation: 0.4231387215006656]
	TIME [epoch: 27.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31331285976133716		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.31331285976133716 | validation: 0.43050173421503757]
	TIME [epoch: 27.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39488678613468486		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.39488678613468486 | validation: 0.45195680185975123]
	TIME [epoch: 27.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33247709334866177		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.33247709334866177 | validation: 0.425088484955206]
	TIME [epoch: 27.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100700158505215		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3100700158505215 | validation: 0.35623867458196273]
	TIME [epoch: 27.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687675320631188		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3687675320631188 | validation: 0.4610922910003253]
	TIME [epoch: 27.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4311907677649462		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4311907677649462 | validation: 0.34315629129247854]
	TIME [epoch: 27.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29841649011532134		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.29841649011532134 | validation: 0.38495766376663026]
	TIME [epoch: 27.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335618244736198		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.4335618244736198 | validation: 0.5265155783916764]
	TIME [epoch: 27.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38151652833406474		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.38151652833406474 | validation: 0.44621555722493816]
	TIME [epoch: 27.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33025250776847076		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.33025250776847076 | validation: 0.3865000392383067]
	TIME [epoch: 27.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032369323141174		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3032369323141174 | validation: 0.37594347565175784]
	TIME [epoch: 27.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32404721319479957		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.32404721319479957 | validation: 0.3785794060975567]
	TIME [epoch: 27.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846729921743104		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2846729921743104 | validation: 0.40406928288067107]
	TIME [epoch: 27.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368569644100482		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.3368569644100482 | validation: 0.408725342146186]
	TIME [epoch: 27.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779354465035439		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3779354465035439 | validation: 0.39427298963962976]
	TIME [epoch: 27.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401519248936152		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.3401519248936152 | validation: 0.40522633598222485]
	TIME [epoch: 27.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30825115790398994		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.30825115790398994 | validation: 0.34776781178004845]
	TIME [epoch: 27.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100991042350505		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3100991042350505 | validation: 0.42641857448012443]
	TIME [epoch: 27.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086468351788205		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.3086468351788205 | validation: 0.414210165620231]
	TIME [epoch: 27.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40575716000299544		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.40575716000299544 | validation: 0.38541750893108573]
	TIME [epoch: 27.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3821864045809417		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.3821864045809417 | validation: 0.3640759537765111]
	TIME [epoch: 27.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30091269816339167		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.30091269816339167 | validation: 0.37589220391714423]
	TIME [epoch: 27.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3610911171743188		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.3610911171743188 | validation: 0.37480076332698503]
	TIME [epoch: 27.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031336228658288		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3031336228658288 | validation: 0.35532781850791906]
	TIME [epoch: 27.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168524218904908		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.3168524218904908 | validation: 0.5066645164196912]
	TIME [epoch: 27.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351627372591904		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.351627372591904 | validation: 0.38733976868432735]
	TIME [epoch: 27.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31611444787925924		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.31611444787925924 | validation: 0.37958379067780357]
	TIME [epoch: 27.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558730125422603		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.3558730125422603 | validation: 0.3745480209304384]
	TIME [epoch: 27.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228720859449802		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3228720859449802 | validation: 0.2992637662290913]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_950.pth
	Model improved!!!
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28614953099827944		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.28614953099827944 | validation: 0.46533475956545445]
	TIME [epoch: 27.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34714886766300185		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.34714886766300185 | validation: 0.38838483678556673]
	TIME [epoch: 27.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33814311523349094		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.33814311523349094 | validation: 0.3853816464705491]
	TIME [epoch: 27.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100614740727019		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.4100614740727019 | validation: 0.4818210444989514]
	TIME [epoch: 27.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419736821036865		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.4419736821036865 | validation: 0.5634978436083137]
	TIME [epoch: 27.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171449517305143		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.5171449517305143 | validation: 0.4700612111918155]
	TIME [epoch: 27.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907244171640581		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3907244171640581 | validation: 0.4299457123868347]
	TIME [epoch: 27.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691634637036977		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.3691634637036977 | validation: 0.3971404178663089]
	TIME [epoch: 27.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337441228451414		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.337441228451414 | validation: 0.2939159864474548]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_959.pth
	Model improved!!!
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961782998929896		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2961782998929896 | validation: 0.3399591143311641]
	TIME [epoch: 27.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639334148605413		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.3639334148605413 | validation: 0.4539136089428598]
	TIME [epoch: 27.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611885064231797		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.3611885064231797 | validation: 0.3804808048021242]
	TIME [epoch: 27.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31424377956376043		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.31424377956376043 | validation: 0.4043534700320759]
	TIME [epoch: 27.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42091811483129465		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.42091811483129465 | validation: 0.5876281246965541]
	TIME [epoch: 27.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490179502694542		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4490179502694542 | validation: 0.46552739949007127]
	TIME [epoch: 27.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3097836503588704		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.3097836503588704 | validation: 0.43720823041634654]
	TIME [epoch: 27.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36664593969777415		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.36664593969777415 | validation: 0.4128735513363413]
	TIME [epoch: 27.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35693682754339234		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.35693682754339234 | validation: 0.3428439589098055]
	TIME [epoch: 27.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036284519165201		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.3036284519165201 | validation: 0.2906269799820215]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_969.pth
	Model improved!!!
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32102830416960937		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.32102830416960937 | validation: 0.34848207579325385]
	TIME [epoch: 27.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31866359127776245		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.31866359127776245 | validation: 0.2941797747698986]
	TIME [epoch: 27.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3059021962795816		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3059021962795816 | validation: 0.3251305016067659]
	TIME [epoch: 27.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37440964431926677		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.37440964431926677 | validation: 0.3966636923567161]
	TIME [epoch: 27.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43458313464532805		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.43458313464532805 | validation: 0.3781292557575141]
	TIME [epoch: 27.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325502659675181		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3325502659675181 | validation: 0.3036673012667119]
	TIME [epoch: 27.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338061199583864		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.338061199583864 | validation: 0.43514832475317267]
	TIME [epoch: 27.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43906584214666666		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.43906584214666666 | validation: 0.36389170080786687]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34319468946705456		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.34319468946705456 | validation: 0.4451761924014744]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47454950832068904		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.47454950832068904 | validation: 0.5348911448132946]
	TIME [epoch: 27.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509137051246704		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.509137051246704 | validation: 0.5602220746485628]
	TIME [epoch: 27.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111494825059129		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.5111494825059129 | validation: 0.33648401446180193]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694268016448653		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3694268016448653 | validation: 0.3071589211671469]
	TIME [epoch: 27.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313510106241785		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3313510106241785 | validation: 0.32911397828910977]
	TIME [epoch: 27.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35480382188535897		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.35480382188535897 | validation: 0.34144729862647355]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3231665559817369		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3231665559817369 | validation: 0.33648794406968635]
	TIME [epoch: 27.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2936833392980459		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2936833392980459 | validation: 0.29238565334801275]
	TIME [epoch: 27.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26845098335349166		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.26845098335349166 | validation: 0.297605278997961]
	TIME [epoch: 27.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39496460912640396		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.39496460912640396 | validation: 0.393040743266065]
	TIME [epoch: 27.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31150646749473004		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.31150646749473004 | validation: 0.3162867404736031]
	TIME [epoch: 27.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290311430149992		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.290311430149992 | validation: 0.27634454211006976]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_990.pth
	Model improved!!!
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838806548342389		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.2838806548342389 | validation: 0.5353728992395884]
	TIME [epoch: 27.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5353403370955145		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.5353403370955145 | validation: 0.352731066535861]
	TIME [epoch: 27.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036255163407828		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.3036255163407828 | validation: 0.31192479158956393]
	TIME [epoch: 27.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757448685141185		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.2757448685141185 | validation: 0.33261172822923096]
	TIME [epoch: 27.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836976028908068		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2836976028908068 | validation: 0.35253370010641705]
	TIME [epoch: 27.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527430664828566		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.3527430664828566 | validation: 0.28225469191933356]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695212747894785		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.2695212747894785 | validation: 0.2995417543344472]
	TIME [epoch: 27.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859495801405857		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.2859495801405857 | validation: 0.30048111862299803]
	TIME [epoch: 27.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32858946246226717		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.32858946246226717 | validation: 0.370641800151417]
	TIME [epoch: 27.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3940073610565107		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.3940073610565107 | validation: 0.35345354238132426]
	TIME [epoch: 27.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440543469880071		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.3440543469880071 | validation: 0.2985893247095193]
	TIME [epoch: 27.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32708323380126014		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.32708323380126014 | validation: 0.325968032007868]
	TIME [epoch: 27.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32400191346511137		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.32400191346511137 | validation: 0.31112360955379736]
	TIME [epoch: 27.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134588129691136		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.3134588129691136 | validation: 0.3329942590686529]
	TIME [epoch: 27.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36632566688858137		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.36632566688858137 | validation: 0.4773433613092676]
	TIME [epoch: 27.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689988808887224		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3689988808887224 | validation: 0.4287414098780561]
	TIME [epoch: 27.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39175543774890115		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.39175543774890115 | validation: 0.40767211854494634]
	TIME [epoch: 27.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154782382181538		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.4154782382181538 | validation: 0.3228193038137129]
	TIME [epoch: 27.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573871329437339		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.3573871329437339 | validation: 0.27798507624885954]
	TIME [epoch: 27.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988167043714055		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.2988167043714055 | validation: 0.27290584847974986]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1010.pth
	Model improved!!!
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371914899364036		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.3371914899364036 | validation: 0.3236429911967985]
	TIME [epoch: 27.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30692081354176276		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.30692081354176276 | validation: 0.2699290779602299]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983546405672052		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2983546405672052 | validation: 0.3019566682472649]
	TIME [epoch: 27.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088998976601105		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3088998976601105 | validation: 0.2903632533861455]
	TIME [epoch: 27.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40618754092287435		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.40618754092287435 | validation: 0.41115193541337475]
	TIME [epoch: 27.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328178473133026		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.4328178473133026 | validation: 0.39324252443186114]
	TIME [epoch: 27.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34304451745907394		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.34304451745907394 | validation: 0.31227156151509283]
	TIME [epoch: 27.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840619633922276		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.2840619633922276 | validation: 0.310273912795228]
	TIME [epoch: 27.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40981982346927687		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.40981982346927687 | validation: 0.37027727911578195]
	TIME [epoch: 27.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339448589216511		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.3339448589216511 | validation: 0.3461438863481605]
	TIME [epoch: 27.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749540446895269		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.3749540446895269 | validation: 0.3179264650723414]
	TIME [epoch: 27.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328684554893634		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.328684554893634 | validation: 0.26654854152570595]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1022.pth
	Model improved!!!
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031460816677132		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3031460816677132 | validation: 0.3101749653333811]
	TIME [epoch: 27.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30436987577206454		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.30436987577206454 | validation: 0.26393547627827224]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1024.pth
	Model improved!!!
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28270792262666433		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.28270792262666433 | validation: 0.37930682970865437]
	TIME [epoch: 27.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38198002560615185		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.38198002560615185 | validation: 0.4840689785729599]
	TIME [epoch: 27.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37416760077777617		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.37416760077777617 | validation: 0.5883526471149968]
	TIME [epoch: 27.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6145511147400531		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.6145511147400531 | validation: 0.5415184650927861]
	TIME [epoch: 27.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655495198883156		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3655495198883156 | validation: 0.2974721067913265]
	TIME [epoch: 27.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816369651096151		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2816369651096151 | validation: 0.3516214208072527]
	TIME [epoch: 27.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37448060048539017		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.37448060048539017 | validation: 0.3441124379757436]
	TIME [epoch: 27.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843810781017777		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2843810781017777 | validation: 0.2834425240926452]
	TIME [epoch: 27.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26207593779425364		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.26207593779425364 | validation: 0.3232874320609422]
	TIME [epoch: 27.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26668760005648917		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.26668760005648917 | validation: 0.34753436299504875]
	TIME [epoch: 27.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948978966758903		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.2948978966758903 | validation: 0.3394599678310948]
	TIME [epoch: 27.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613159466466041		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.2613159466466041 | validation: 0.31429555501442674]
	TIME [epoch: 27.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27749365426945205		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.27749365426945205 | validation: 0.3292544091660317]
	TIME [epoch: 27.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725406928080084		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2725406928080084 | validation: 0.29612477953493677]
	TIME [epoch: 27.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892830643855535		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.2892830643855535 | validation: 0.2988410038357801]
	TIME [epoch: 27.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838504930327388		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.2838504930327388 | validation: 0.28333901190906446]
	TIME [epoch: 27.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28937107720151656		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.28937107720151656 | validation: 0.309706836173684]
	TIME [epoch: 27.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25740570494961307		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.25740570494961307 | validation: 0.3252643384570652]
	TIME [epoch: 27.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625554361749235		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2625554361749235 | validation: 0.2793138019082365]
	TIME [epoch: 27.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27632184287169004		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.27632184287169004 | validation: 0.3187568229221831]
	TIME [epoch: 27.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33712481229883856		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.33712481229883856 | validation: 0.4557364881458447]
	TIME [epoch: 27.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416647492586144		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.4416647492586144 | validation: 0.2953593617801984]
	TIME [epoch: 27.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421063272898158		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.3421063272898158 | validation: 0.39871268456924525]
	TIME [epoch: 27.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34523716980364244		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.34523716980364244 | validation: 0.32548569067431304]
	TIME [epoch: 27.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31245179665512185		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.31245179665512185 | validation: 0.33192057578566375]
	TIME [epoch: 27.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310291770930438		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.310291770930438 | validation: 0.28240567557660734]
	TIME [epoch: 27.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32867244302002785		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.32867244302002785 | validation: 0.2677470173626307]
	TIME [epoch: 27.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34127009059428093		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.34127009059428093 | validation: 0.332667685009621]
	TIME [epoch: 27.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31132714490913616		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.31132714490913616 | validation: 0.3132076251433551]
	TIME [epoch: 27.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768044145574847		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.2768044145574847 | validation: 0.28539124781997677]
	TIME [epoch: 27.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30183007031027215		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.30183007031027215 | validation: 0.2932226240340855]
	TIME [epoch: 27.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753492126224188		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.2753492126224188 | validation: 0.2773829470776282]
	TIME [epoch: 27.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25076138571998907		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.25076138571998907 | validation: 0.2579917244263261]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1057.pth
	Model improved!!!
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790476868252162		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.2790476868252162 | validation: 0.2772404296936827]
	TIME [epoch: 27.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32913985298432685		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.32913985298432685 | validation: 0.43953597263209815]
	TIME [epoch: 27.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37375972514678507		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.37375972514678507 | validation: 0.3952886221167654]
	TIME [epoch: 27.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36652174185124775		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.36652174185124775 | validation: 0.3814794781344384]
	TIME [epoch: 27.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295733762280739		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3295733762280739 | validation: 0.33605844209651703]
	TIME [epoch: 27.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239969881334972		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3239969881334972 | validation: 0.3411962806745595]
	TIME [epoch: 27.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090615784747602		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3090615784747602 | validation: 0.31110128783957125]
	TIME [epoch: 27.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949342278132201		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.2949342278132201 | validation: 0.30492622535104774]
	TIME [epoch: 27.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29403888763865293		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.29403888763865293 | validation: 0.31306507799873173]
	TIME [epoch: 27.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978197746333226		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.2978197746333226 | validation: 0.2998324256313247]
	TIME [epoch: 27.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774884471418437		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.2774884471418437 | validation: 0.29558019961078574]
	TIME [epoch: 27.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28343039846174867		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.28343039846174867 | validation: 0.28735337968786795]
	TIME [epoch: 27.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102553198395236		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.3102553198395236 | validation: 0.35631737498949856]
	TIME [epoch: 27.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803880484578817		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2803880484578817 | validation: 0.31713663342380444]
	TIME [epoch: 27.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253782126902216		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.253782126902216 | validation: 0.2856352240060044]
	TIME [epoch: 27.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077853782815538		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.3077853782815538 | validation: 0.35347746651857437]
	TIME [epoch: 27.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32312142605688193		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.32312142605688193 | validation: 0.34058540202908544]
	TIME [epoch: 27.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31059096426273397		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.31059096426273397 | validation: 0.27452801091512374]
	TIME [epoch: 27.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941018726036676		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.2941018726036676 | validation: 0.30695769480344687]
	TIME [epoch: 27.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641311234703822		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.2641311234703822 | validation: 0.2532541768194442]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1077.pth
	Model improved!!!
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27546400800064297		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.27546400800064297 | validation: 0.2855814503613927]
	TIME [epoch: 27.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28435876850853303		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.28435876850853303 | validation: 0.25685965823694834]
	TIME [epoch: 27.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25851311060544946		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.25851311060544946 | validation: 0.27103060166370463]
	TIME [epoch: 27.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855750375777128		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.2855750375777128 | validation: 0.4023967397071712]
	TIME [epoch: 27.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985369431543702		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2985369431543702 | validation: 0.34190514169311664]
	TIME [epoch: 27.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28431244540727224		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.28431244540727224 | validation: 0.26363407087025237]
	TIME [epoch: 27.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24811537319258542		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.24811537319258542 | validation: 0.30296752151521217]
	TIME [epoch: 27.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23238740479067752		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.23238740479067752 | validation: 0.2530657264298675]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893016280941934		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.2893016280941934 | validation: 0.33138267639137736]
	TIME [epoch: 27.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27006076772316		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.27006076772316 | validation: 0.2508413508100961]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240310_003029/states/model_tr_study5_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25779039223048		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.25779039223048 | validation: 0.28388045172714726]
	TIME [epoch: 27.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774413527918814		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2774413527918814 | validation: 0.2616483925417943]
	TIME [epoch: 27.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030059709227282		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3030059709227282 | validation: 0.28856256916205697]
	TIME [epoch: 27.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33749548848452565		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.33749548848452565 | validation: 0.3220292136209703]
	TIME [epoch: 27.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355911572080915		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.355911572080915 | validation: 0.37512197463338126]
	TIME [epoch: 27.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3025069768327633		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3025069768327633 | validation: 0.28694970678980763]
	TIME [epoch: 27.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521215244063706		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.2521215244063706 | validation: 0.2760764615912911]
	TIME [epoch: 27.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26101518706598426		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.26101518706598426 | validation: 0.27778804887954184]
	TIME [epoch: 27.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693475474031093		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2693475474031093 | validation: 0.3042744215202815]
	TIME [epoch: 27.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27881712650715645		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.27881712650715645 | validation: 0.3227793830859011]
	TIME [epoch: 27.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941232837536233		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2941232837536233 | validation: 0.3449337618689218]
	TIME [epoch: 27.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452265910473457		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.3452265910473457 | validation: 0.4269880383966873]
	TIME [epoch: 27.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309978166778548		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3309978166778548 | validation: 0.4103998002594644]
	TIME [epoch: 27.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3416949127639638		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3416949127639638 | validation: 0.3719556196906571]
	TIME [epoch: 27.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27103164004804836		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.27103164004804836 | validation: 0.25933595673022475]
	TIME [epoch: 27.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23952246697191165		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.23952246697191165 | validation: 0.2713708241196333]
	TIME [epoch: 27.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24483292206669105		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.24483292206669105 | validation: 0.3262203879187511]
	TIME [epoch: 27.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280425087933391		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.280425087933391 | validation: 0.39386081270741885]
	TIME [epoch: 27.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37237010639940227		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.37237010639940227 | validation: 0.3730112620593603]
	TIME [epoch: 27.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3165462979952938		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.3165462979952938 | validation: 0.28895918880744104]
	TIME [epoch: 27.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573795792486615		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.2573795792486615 | validation: 0.2997634024111233]
	TIME [epoch: 27.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701913900041325		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.2701913900041325 | validation: 0.3304801159967684]
	TIME [epoch: 27.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31278264562632463		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.31278264562632463 | validation: 0.35233491780936077]
	TIME [epoch: 27.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37919657923438327		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.37919657923438327 | validation: 0.34162260693367336]
	TIME [epoch: 27.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30626014266520596		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.30626014266520596 | validation: 0.28508182858635367]
	TIME [epoch: 27.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28803304794122564		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.28803304794122564 | validation: 0.35543470299766233]
	TIME [epoch: 27.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31937840062961015		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.31937840062961015 | validation: 0.3576725499139555]
	TIME [epoch: 27.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906474188994795		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3906474188994795 | validation: 0.4867233025743417]
	TIME [epoch: 27.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39784383498568987		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.39784383498568987 | validation: 0.3329961316831102]
	TIME [epoch: 27.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30985100774738483		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.30985100774738483 | validation: 0.3632740477332848]
	TIME [epoch: 27.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33812134766236057		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.33812134766236057 | validation: 0.48062137126643395]
	TIME [epoch: 27.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.396807889661136		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.396807889661136 | validation: 0.45350310394963816]
	TIME [epoch: 27.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289615938400097		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.3289615938400097 | validation: 0.33191438828753567]
	TIME [epoch: 27.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782508824828952		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2782508824828952 | validation: 0.31831848081967073]
	TIME [epoch: 27.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038633596809019		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3038633596809019 | validation: 0.3475828430353414]
	TIME [epoch: 27.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3262527179427157		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.3262527179427157 | validation: 0.2988117500670099]
	TIME [epoch: 27.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331680569750882		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.3331680569750882 | validation: 0.3624185547008196]
	TIME [epoch: 27.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523336309554612		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.3523336309554612 | validation: 0.4498853772683911]
	TIME [epoch: 27.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37318439634175804		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.37318439634175804 | validation: 0.31584994779836073]
	TIME [epoch: 27.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28114057520802505		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.28114057520802505 | validation: 0.286997099019861]
	TIME [epoch: 27.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559087879756399		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2559087879756399 | validation: 0.2893951827204773]
	TIME [epoch: 27.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26707441120916847		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.26707441120916847 | validation: 0.29543435706557]
	TIME [epoch: 27.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635662838393573		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.2635662838393573 | validation: 0.2887178133703669]
	TIME [epoch: 27.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535226076479985		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2535226076479985 | validation: 0.2760696058743513]
	TIME [epoch: 27.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518097996639723		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.2518097996639723 | validation: 0.31767379854637173]
	TIME [epoch: 27.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842240108738947		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2842240108738947 | validation: 0.3256245719791262]
	TIME [epoch: 27.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677390107213695		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2677390107213695 | validation: 0.33266290037954804]
	TIME [epoch: 27.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820098501895018		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.2820098501895018 | validation: 0.29903215495344504]
	TIME [epoch: 27.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28634896514341135		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.28634896514341135 | validation: 0.3540275253212949]
	TIME [epoch: 27.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293276358933822		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.293276358933822 | validation: 0.34575724955015885]
	TIME [epoch: 27.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30974767677137605		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.30974767677137605 | validation: 0.3783165433910247]
	TIME [epoch: 27.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26924805935428614		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.26924805935428614 | validation: 0.3186116433335554]
	TIME [epoch: 27.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509955540926084		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2509955540926084 | validation: 0.30723080995640245]
	TIME [epoch: 27.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252818856302385		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.252818856302385 | validation: 0.32199787326733303]
	TIME [epoch: 27.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641161690433044		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.2641161690433044 | validation: 0.4123293460178917]
	TIME [epoch: 27.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756682934270649		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.2756682934270649 | validation: 0.260557321347493]
	TIME [epoch: 27.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534519574728401		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.2534519574728401 | validation: 0.37531106790097896]
	TIME [epoch: 27.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37405044284702094		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.37405044284702094 | validation: 0.2972938466832199]
	TIME [epoch: 27.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890051773922486		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.2890051773922486 | validation: 0.30689922913324447]
	TIME [epoch: 27.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786846281835459		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.2786846281835459 | validation: 0.3082810751881812]
	TIME [epoch: 27.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27872521509537207		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.27872521509537207 | validation: 0.3378802325342675]
	TIME [epoch: 27.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744839746765583		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.2744839746765583 | validation: 0.34406589652123504]
	TIME [epoch: 27.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28425237847671786		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.28425237847671786 | validation: 0.3251540527308129]
	TIME [epoch: 27.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26482199954880714		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.26482199954880714 | validation: 0.3191623551184726]
	TIME [epoch: 27.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2440482925160533		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2440482925160533 | validation: 0.3145106935541396]
	TIME [epoch: 27.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25389178404624196		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.25389178404624196 | validation: 0.33824035372963474]
	TIME [epoch: 27.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703927841659459		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2703927841659459 | validation: 0.3013518563098948]
	TIME [epoch: 27.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2443340010536707		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2443340010536707 | validation: 0.28025941646943675]
	TIME [epoch: 27.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2385540606049746		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.2385540606049746 | validation: 0.288617888897623]
	TIME [epoch: 27.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.229552849719167		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.229552849719167 | validation: 0.26185049246077335]
	TIME [epoch: 27.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23289986862005063		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.23289986862005063 | validation: 0.3024704064649606]
	TIME [epoch: 27.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23819444733577338		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.23819444733577338 | validation: 0.27749161856585025]
	TIME [epoch: 27.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423245096098729		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2423245096098729 | validation: 0.3108718011177174]
	TIME [epoch: 27.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309383375753171		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.2309383375753171 | validation: 0.2645140463706926]
	TIME [epoch: 27.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.240305759802789		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.240305759802789 | validation: 0.31511092615803843]
	TIME [epoch: 27.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23809488640027035		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.23809488640027035 | validation: 0.27899032539763885]
	TIME [epoch: 27.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.246503517182807		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.246503517182807 | validation: 0.30894333237940785]
	TIME [epoch: 27.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24612618028397218		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.24612618028397218 | validation: 0.2841044701913321]
	TIME [epoch: 27.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26272299728770526		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.26272299728770526 | validation: 0.26524421780279417]
	TIME [epoch: 27.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24805807713162775		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.24805807713162775 | validation: 0.2810425552355191]
	TIME [epoch: 27.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24448486689981253		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.24448486689981253 | validation: 0.26934052609437525]
	TIME [epoch: 27.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616492310392875		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.2616492310392875 | validation: 0.34508031978988557]
	TIME [epoch: 27.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014716208910492		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.3014716208910492 | validation: 0.4367241883065877]
	TIME [epoch: 27.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352884399335024		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.3352884399335024 | validation: 0.3807493923413789]
	TIME [epoch: 27.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26245876655231143		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.26245876655231143 | validation: 0.3034875207671229]
	TIME [epoch: 27.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2284088958570209		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.2284088958570209 | validation: 0.27518568352879874]
	TIME [epoch: 27.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253626734381226		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.253626734381226 | validation: 0.3441306494408093]
	TIME [epoch: 27.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26121467478158067		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.26121467478158067 | validation: 0.33204855437293407]
	TIME [epoch: 27.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584256845055539		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.2584256845055539 | validation: 0.3008389759999781]
	TIME [epoch: 27.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22148806589562053		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.22148806589562053 | validation: 0.29416568079080535]
	TIME [epoch: 27.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840430908989099		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.3840430908989099 | validation: 0.44566141871556836]
	TIME [epoch: 27.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691529047551354		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.3691529047551354 | validation: 0.3359904245070882]
	TIME [epoch: 27.5 sec]
EPOCH 1180/2000:
	Training over batches...
