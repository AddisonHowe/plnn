Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1087222368

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.960875845011923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.960875845011923 | validation: 11.203478900193558]
	TIME [epoch: 49.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.466685881763292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.466685881763292 | validation: 10.410370121606034]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.838008128907132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.838008128907132 | validation: 10.017623202281309]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.46870601216649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.46870601216649 | validation: 9.486750523117426]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.928003011745634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.928003011745634 | validation: 10.135022773333041]
	TIME [epoch: 10.4 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.968965959303492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.968965959303492 | validation: 8.865411990883253]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.270630549947418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.270630549947418 | validation: 8.050943665874302]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.635419045712473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.635419045712473 | validation: 7.517221115922807]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.4703592241605605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4703592241605605 | validation: 7.2631680366537035]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.976509841434414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.976509841434414 | validation: 7.256567870749093]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.85046334795184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.85046334795184 | validation: 7.13549878090728]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.835092132224304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.835092132224304 | validation: 7.1296640516778735]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.855650799216855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.855650799216855 | validation: 7.09524549951647]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.714772217180716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.714772217180716 | validation: 7.01684235773837]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.680902820229109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.680902820229109 | validation: 6.975358003779923]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.583946260752116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.583946260752116 | validation: 7.086842330296638]
	TIME [epoch: 10.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.548067979946902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.548067979946902 | validation: 6.833944646431758]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.186183937357699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.186183937357699 | validation: 6.900404395490181]
	TIME [epoch: 10.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.08241204650156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.08241204650156 | validation: 6.535215283488377]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.081207035145186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.081207035145186 | validation: 6.462218644730292]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.751759851445998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.751759851445998 | validation: 6.348140256029169]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5434095341925795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5434095341925795 | validation: 6.267568214792544]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.480905282105246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.480905282105246 | validation: 6.130299055970994]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.622103772438161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.622103772438161 | validation: 6.035380029904777]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.522153432815996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.522153432815996 | validation: 6.201574746811196]
	TIME [epoch: 10.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.529424881112389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529424881112389 | validation: 6.11870839647667]
	TIME [epoch: 10.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.425784183268144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.425784183268144 | validation: 6.18510938870367]
	TIME [epoch: 10.4 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.485298283085372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.485298283085372 | validation: 6.181482207145386]
	TIME [epoch: 10.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.300450363542338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.300450363542338 | validation: 5.934630559152493]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.382032195562931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.382032195562931 | validation: 5.91917452008448]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2718558828014945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2718558828014945 | validation: 5.990407254217598]
	TIME [epoch: 10.4 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.366101162629383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.366101162629383 | validation: 5.960494247543527]
	TIME [epoch: 10.4 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.24394108964912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.24394108964912 | validation: 5.706606348670164]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.171041086293175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.171041086293175 | validation: 5.8779745785921635]
	TIME [epoch: 10.4 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.196879115899982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.196879115899982 | validation: 6.087238473518205]
	TIME [epoch: 10.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.301809490841288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.301809490841288 | validation: 5.918513960798651]
	TIME [epoch: 10.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.137507863402147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.137507863402147 | validation: 5.824939690348031]
	TIME [epoch: 10.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0635580006534955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0635580006534955 | validation: 5.527494014179131]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.140684130063484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.140684130063484 | validation: 5.504290614359609]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.067628198480195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.067628198480195 | validation: 5.7998060988798725]
	TIME [epoch: 10.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7143190516876725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7143190516876725 | validation: 5.023356731974925]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6678154811966435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6678154811966435 | validation: 4.741746143418729]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.978244640608613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.978244640608613 | validation: 4.773249223112315]
	TIME [epoch: 10.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.533188929275473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.533188929275473 | validation: 4.738650625127025]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.174637465820516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.174637465820516 | validation: 4.740319039906301]
	TIME [epoch: 10.4 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.514463064193843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.514463064193843 | validation: 5.048491099086347]
	TIME [epoch: 10.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.474497568839866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.474497568839866 | validation: 4.4861188039111095]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.251296222891538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.251296222891538 | validation: 4.9795609144169655]
	TIME [epoch: 10.4 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.449089187300878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.449089187300878 | validation: 4.65286371853168]
	TIME [epoch: 10.4 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.219034958493314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.219034958493314 | validation: 4.996061302022175]
	TIME [epoch: 10.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4018149046132935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4018149046132935 | validation: 5.130655018992726]
	TIME [epoch: 10.4 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.407712550209865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407712550209865 | validation: 4.741270962240101]
	TIME [epoch: 10.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.289085734355504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.289085734355504 | validation: 4.462624694483771]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.407121406735143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407121406735143 | validation: 4.383494515617302]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.040870610781409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.040870610781409 | validation: 4.357157524192831]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.267427912411686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.267427912411686 | validation: 4.395586900772788]
	TIME [epoch: 10.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.124707045635256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.124707045635256 | validation: 4.138700066608201]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.716328913498219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.716328913498219 | validation: 5.101356548040993]
	TIME [epoch: 10.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.277593080670387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.277593080670387 | validation: 4.972654746982981]
	TIME [epoch: 10.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.400605131170858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.400605131170858 | validation: 4.4646047791226335]
	TIME [epoch: 10.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.195475843739372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.195475843739372 | validation: 4.107530328383123]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.639041860621672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.639041860621672 | validation: 4.703360769696413]
	TIME [epoch: 10.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.848495033108938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.848495033108938 | validation: 4.4209114285742945]
	TIME [epoch: 10.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.596049930279368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596049930279368 | validation: 5.448580917843003]
	TIME [epoch: 10.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.781562834783513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.781562834783513 | validation: 4.19064826129032]
	TIME [epoch: 10.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.225490256847627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.225490256847627 | validation: 3.9348976653908334]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.095193719025458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.095193719025458 | validation: 3.59127436730598]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5187517883756163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5187517883756163 | validation: 4.705907821698018]
	TIME [epoch: 10.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3549985724951625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3549985724951625 | validation: 5.161942397044067]
	TIME [epoch: 10.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.460037925385263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.460037925385263 | validation: 4.1597739314975595]
	TIME [epoch: 10.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8795368970007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8795368970007 | validation: 7.095962855985569]
	TIME [epoch: 10.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.623719610435847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.623719610435847 | validation: 5.017255661008199]
	TIME [epoch: 10.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.194320949938115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.194320949938115 | validation: 3.9924704955724946]
	TIME [epoch: 10.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.117385837464911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.117385837464911 | validation: 4.248968859605627]
	TIME [epoch: 10.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.991138398478835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.991138398478835 | validation: 4.059217044815248]
	TIME [epoch: 10.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.681478549479106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.681478549479106 | validation: 3.7972581526849853]
	TIME [epoch: 10.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.109173305740561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.109173305740561 | validation: 4.093077007336344]
	TIME [epoch: 10.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5475643613550822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5475643613550822 | validation: 3.253931721652687]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2975583692963317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2975583692963317 | validation: 3.7898510286032674]
	TIME [epoch: 10.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.594457417018215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.594457417018215 | validation: 4.756561205848439]
	TIME [epoch: 10.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.230744869812849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.230744869812849 | validation: 4.011715967720182]
	TIME [epoch: 10.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7960854222531424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7960854222531424 | validation: 4.4176044728700745]
	TIME [epoch: 10.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.494828375603047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.494828375603047 | validation: 4.042432537203195]
	TIME [epoch: 10.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8278163434988834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8278163434988834 | validation: 3.4520115184507905]
	TIME [epoch: 10.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7069632469528058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7069632469528058 | validation: 3.8639522403381426]
	TIME [epoch: 10.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.30241893325798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.30241893325798 | validation: 3.079347088465742]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.250306276866046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.250306276866046 | validation: 3.459046605789911]
	TIME [epoch: 10.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9657928665867472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9657928665867472 | validation: 7.052860407408947]
	TIME [epoch: 10.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.392954795025674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.392954795025674 | validation: 5.062846925840562]
	TIME [epoch: 10.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.118797137333874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.118797137333874 | validation: 3.4367375195614263]
	TIME [epoch: 10.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2498915572000415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2498915572000415 | validation: 3.060223726572176]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.158402920067978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.158402920067978 | validation: 3.865735064165284]
	TIME [epoch: 10.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4312815038658586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4312815038658586 | validation: 3.3500470919653367]
	TIME [epoch: 10.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.615312938441943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.615312938441943 | validation: 3.4250881506247493]
	TIME [epoch: 10.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.038664560813888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.038664560813888 | validation: 3.946151861883826]
	TIME [epoch: 10.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4756037365767396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4756037365767396 | validation: 3.0092519161441853]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.892805932167968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.892805932167968 | validation: 7.410425241383008]
	TIME [epoch: 10.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.146293125995841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.146293125995841 | validation: 5.2712714188961876]
	TIME [epoch: 10.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.743527287025927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.743527287025927 | validation: 3.7224311345187546]
	TIME [epoch: 10.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9135005540872925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9135005540872925 | validation: 3.168857532248446]
	TIME [epoch: 10.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.87377999752238		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 2.87377999752238 | validation: 2.9085723338310197]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5018386196607363		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 2.5018386196607363 | validation: 2.5040126390010364]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5247263064616434		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 2.5247263064616434 | validation: 2.50982497414618]
	TIME [epoch: 10.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3679707510548416		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.3679707510548416 | validation: 3.2634245453680024]
	TIME [epoch: 10.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8034428066522095		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 2.8034428066522095 | validation: 2.581595361665769]
	TIME [epoch: 10.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4797484055181664		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.4797484055181664 | validation: 2.7819472935231646]
	TIME [epoch: 10.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5037251170654224		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 2.5037251170654224 | validation: 2.715151633093601]
	TIME [epoch: 10.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.65443180075305		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.65443180075305 | validation: 2.8443386481404183]
	TIME [epoch: 10.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7705148703428053		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 2.7705148703428053 | validation: 3.4196133227100036]
	TIME [epoch: 10.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4308320972683197		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.4308320972683197 | validation: 2.2305291915632224]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.294766058007604		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 2.294766058007604 | validation: 3.0264172169189822]
	TIME [epoch: 10.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9701286469215136		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.9701286469215136 | validation: 3.324934247631818]
	TIME [epoch: 10.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9921574054209086		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 2.9921574054209086 | validation: 3.081288671515565]
	TIME [epoch: 10.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2190345958067024		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.2190345958067024 | validation: 2.3746539083639187]
	TIME [epoch: 10.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3453909938330293		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 2.3453909938330293 | validation: 2.955679491164151]
	TIME [epoch: 10.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4505384281892857		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 2.4505384281892857 | validation: 2.087868106153628]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.128932892257535		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 2.128932892257535 | validation: 2.0912695573414215]
	TIME [epoch: 10.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1680743509980984		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 2.1680743509980984 | validation: 2.268586067480635]
	TIME [epoch: 10.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0238919433934166		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 2.0238919433934166 | validation: 3.2257522102001577]
	TIME [epoch: 10.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9214511622687205		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 2.9214511622687205 | validation: 4.122795748433732]
	TIME [epoch: 10.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.432934930302416		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 2.432934930302416 | validation: 2.3707372820285113]
	TIME [epoch: 10.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1000978545375353		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.1000978545375353 | validation: 2.0363909994023563]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.264586288651384		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 2.264586288651384 | validation: 2.4499098564560473]
	TIME [epoch: 10.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.176294889339115		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.176294889339115 | validation: 3.735091970571425]
	TIME [epoch: 10.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.204669942084263		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 2.204669942084263 | validation: 2.1813314927507634]
	TIME [epoch: 10.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8944438131430954		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.8944438131430954 | validation: 2.898307498662181]
	TIME [epoch: 10.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1764757971300215		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 2.1764757971300215 | validation: 2.3141485495270473]
	TIME [epoch: 10.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.82507723063705		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.82507723063705 | validation: 2.5869922275310824]
	TIME [epoch: 10.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.157781688314034		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 2.157781688314034 | validation: 2.144831246071046]
	TIME [epoch: 10.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8502016284303966		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.8502016284303966 | validation: 2.3156822583277323]
	TIME [epoch: 10.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8343186043030735		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 1.8343186043030735 | validation: 2.1204797442704324]
	TIME [epoch: 10.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7792011421829812		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.7792011421829812 | validation: 2.0078470626152263]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6035096887560811		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 1.6035096887560811 | validation: 1.7558354126792954]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2456223902551935		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 2.2456223902551935 | validation: 2.2673389864226823]
	TIME [epoch: 10.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7490271520983498		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 1.7490271520983498 | validation: 2.289024386684805]
	TIME [epoch: 10.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8369401402522947		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.8369401402522947 | validation: 2.140763480409166]
	TIME [epoch: 10.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0401870679336866		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 2.0401870679336866 | validation: 2.1596919386299023]
	TIME [epoch: 10.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0456699096933524		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 2.0456699096933524 | validation: 2.0508532300278546]
	TIME [epoch: 10.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7771848523256526		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 1.7771848523256526 | validation: 2.2346551281805573]
	TIME [epoch: 10.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7115361280934962		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.7115361280934962 | validation: 1.915067904525364]
	TIME [epoch: 10.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.583776911143253		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 1.583776911143253 | validation: 1.890115953660762]
	TIME [epoch: 10.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9802368900261662		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.9802368900261662 | validation: 1.8080015364563014]
	TIME [epoch: 10.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6752310655765499		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 1.6752310655765499 | validation: 2.7071706328775407]
	TIME [epoch: 10.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9244275140071074		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.9244275140071074 | validation: 2.451105822171936]
	TIME [epoch: 10.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.018284408490536		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 2.018284408490536 | validation: 2.0098685839432293]
	TIME [epoch: 10.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5358058070583438		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.5358058070583438 | validation: 1.8836510728721587]
	TIME [epoch: 10.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6117897974567774		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 1.6117897974567774 | validation: 1.9330445485858523]
	TIME [epoch: 10.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.396788635559456		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.396788635559456 | validation: 1.8100820183170305]
	TIME [epoch: 10.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4680997269260136		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 1.4680997269260136 | validation: 3.251212833072488]
	TIME [epoch: 10.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7849059104162923		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.7849059104162923 | validation: 1.627516854827349]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6914838939364842		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 1.6914838939364842 | validation: 1.9866295491965655]
	TIME [epoch: 10.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6493415881917493		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.6493415881917493 | validation: 1.9165192756859535]
	TIME [epoch: 10.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9612862741858201		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 1.9612862741858201 | validation: 2.980813594303421]
	TIME [epoch: 10.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2347680223089736		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 2.2347680223089736 | validation: 2.3457544717513983]
	TIME [epoch: 10.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6978335294648175		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 1.6978335294648175 | validation: 2.3910103992712823]
	TIME [epoch: 10.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.57758147236393		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.57758147236393 | validation: 2.7702132446452072]
	TIME [epoch: 10.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5964468548462558		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 1.5964468548462558 | validation: 2.45230569983078]
	TIME [epoch: 10.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9188216435649568		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.9188216435649568 | validation: 2.290486409555771]
	TIME [epoch: 10.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7206644310846682		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 1.7206644310846682 | validation: 1.7603360139526054]
	TIME [epoch: 10.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.440877509282832		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.440877509282832 | validation: 2.0912008557564623]
	TIME [epoch: 10.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8522408840006108		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 1.8522408840006108 | validation: 2.116451199329833]
	TIME [epoch: 10.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.994398276503497		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.994398276503497 | validation: 2.2781306725154535]
	TIME [epoch: 10.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.790028715170211		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 1.790028715170211 | validation: 2.058468108528035]
	TIME [epoch: 10.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4970501594835748		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.4970501594835748 | validation: 1.6038972210856037]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4516123131902166		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 1.4516123131902166 | validation: 2.6850885629451966]
	TIME [epoch: 10.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5483938224709481		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.5483938224709481 | validation: 2.210436939424733]
	TIME [epoch: 10.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7683116876109632		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 1.7683116876109632 | validation: 1.9352257503177692]
	TIME [epoch: 10.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5599096982897316		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.5599096982897316 | validation: 2.278878512754443]
	TIME [epoch: 10.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7945051881563079		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 1.7945051881563079 | validation: 1.766500950256944]
	TIME [epoch: 10.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7725429028302109		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.7725429028302109 | validation: 1.6606662038547968]
	TIME [epoch: 10.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9173693718036127		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 1.9173693718036127 | validation: 1.8423274254538882]
	TIME [epoch: 10.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8218164183811922		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.8218164183811922 | validation: 2.6099834912236286]
	TIME [epoch: 10.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8096256532295274		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 1.8096256532295274 | validation: 2.270995481883873]
	TIME [epoch: 10.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5466856600958712		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.5466856600958712 | validation: 1.9566430098636047]
	TIME [epoch: 10.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5772628116105998		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 1.5772628116105998 | validation: 1.4947024864785545]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7347750013665693		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.7347750013665693 | validation: 1.7821770953080849]
	TIME [epoch: 10.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6589937305284903		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.6589937305284903 | validation: 2.024859552684202]
	TIME [epoch: 10.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7781442980505773		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.7781442980505773 | validation: 1.8793206200466466]
	TIME [epoch: 10.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4331563892986234		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 1.4331563892986234 | validation: 2.0465970205764203]
	TIME [epoch: 10.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8893553511380472		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.8893553511380472 | validation: 1.7629596642761225]
	TIME [epoch: 10.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8688357753864377		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 1.8688357753864377 | validation: 2.09844223031853]
	TIME [epoch: 10.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5565953523798648		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.5565953523798648 | validation: 2.5574899504148614]
	TIME [epoch: 10.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7038522272815158		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 1.7038522272815158 | validation: 2.060801945875524]
	TIME [epoch: 10.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7881588112297897		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.7881588112297897 | validation: 1.9241351285990749]
	TIME [epoch: 10.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7347759755278367		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 1.7347759755278367 | validation: 1.87480033854232]
	TIME [epoch: 10.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3826263012008133		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.3826263012008133 | validation: 1.7915952864190932]
	TIME [epoch: 10.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.454364467245735		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.454364467245735 | validation: 1.5708642294930486]
	TIME [epoch: 10.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5491864054595748		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.5491864054595748 | validation: 1.6601949177198254]
	TIME [epoch: 10.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4149828206960837		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.4149828206960837 | validation: 1.3467433362956205]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2384135075853444		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.2384135075853444 | validation: 1.5792406425905083]
	TIME [epoch: 10.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3794888617502052		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 1.3794888617502052 | validation: 2.0037111489131174]
	TIME [epoch: 10.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4022390230021602		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.4022390230021602 | validation: 1.24117520646914]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.528493184006668		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 1.528493184006668 | validation: 1.876006927437541]
	TIME [epoch: 10.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7862559152352744		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.7862559152352744 | validation: 2.0284814704551812]
	TIME [epoch: 10.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.53149061357746		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 1.53149061357746 | validation: 1.32124141844878]
	TIME [epoch: 10.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.344823574097179		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.344823574097179 | validation: 1.2951344991548193]
	TIME [epoch: 10.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4026629588483404		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.4026629588483404 | validation: 1.7660081266122525]
	TIME [epoch: 10.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3090432443727424		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 2.3090432443727424 | validation: 1.5367324141548329]
	TIME [epoch: 10.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.222445809949874		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 1.222445809949874 | validation: 1.1825167100790137]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3760345050130471		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.3760345050130471 | validation: 1.4580426619191684]
	TIME [epoch: 10.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0637536421783054		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 1.0637536421783054 | validation: 1.3921687168012704]
	TIME [epoch: 10.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.385216116512961		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.385216116512961 | validation: 1.6833822857158582]
	TIME [epoch: 10.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5925480356991615		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 1.5925480356991615 | validation: 1.6285299661493293]
	TIME [epoch: 10.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.457074043151286		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.457074043151286 | validation: 1.9605012975798461]
	TIME [epoch: 10.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5342269372102777		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 1.5342269372102777 | validation: 0.9498958747542378]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3533461847442656		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.3533461847442656 | validation: 2.0146798132689026]
	TIME [epoch: 10.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5425288768343102		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.5425288768343102 | validation: 1.5991407767049937]
	TIME [epoch: 10.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3094080035968663		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.3094080035968663 | validation: 1.7366558016858307]
	TIME [epoch: 10.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.10326998906218		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 1.10326998906218 | validation: 1.1729691990135636]
	TIME [epoch: 10.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2427257159437861		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.2427257159437861 | validation: 1.7852492845237384]
	TIME [epoch: 10.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2690670581539416		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 1.2690670581539416 | validation: 1.3520015496847955]
	TIME [epoch: 10.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1940779097301513		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.1940779097301513 | validation: 2.059493549918311]
	TIME [epoch: 10.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2833699496035123		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 1.2833699496035123 | validation: 1.5124560180968223]
	TIME [epoch: 10.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4358606105541634		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.4358606105541634 | validation: 1.5571975997987266]
	TIME [epoch: 10.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2950534161093141		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 1.2950534161093141 | validation: 1.1894386409863162]
	TIME [epoch: 10.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0701828533285282		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.0701828533285282 | validation: 1.1147580742831478]
	TIME [epoch: 10.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.280316243800736		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 1.280316243800736 | validation: 1.203019685465017]
	TIME [epoch: 10.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2334815933339311		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.2334815933339311 | validation: 1.330962270175621]
	TIME [epoch: 10.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4009072956379327		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 1.4009072956379327 | validation: 1.1481493710609332]
	TIME [epoch: 10.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1916236409788896		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.1916236409788896 | validation: 1.8171893686934382]
	TIME [epoch: 10.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.403493746332873		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 1.403493746332873 | validation: 0.8255475881885823]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2244646150241651		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.2244646150241651 | validation: 1.6849589761837451]
	TIME [epoch: 10.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4288070425704875		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 1.4288070425704875 | validation: 2.4067960292587482]
	TIME [epoch: 10.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3108602354549799		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.3108602354549799 | validation: 0.8395653935407887]
	TIME [epoch: 10.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9968496955428534		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.9968496955428534 | validation: 1.2925604641708088]
	TIME [epoch: 10.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0468054333094647		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.0468054333094647 | validation: 1.9390108793282013]
	TIME [epoch: 10.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5919948587577637		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 1.5919948587577637 | validation: 1.4872186031436316]
	TIME [epoch: 10.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.021516189318847		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.021516189318847 | validation: 0.8973756229561213]
	TIME [epoch: 10.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0156290797348364		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 1.0156290797348364 | validation: 1.9869370207933594]
	TIME [epoch: 10.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0611999358211137		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.0611999358211137 | validation: 1.0705663972452053]
	TIME [epoch: 10.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.034525604417602		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 1.034525604417602 | validation: 1.6117877346683913]
	TIME [epoch: 10.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.229125738378895		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.229125738378895 | validation: 1.2159417916563928]
	TIME [epoch: 10.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3087082970954562		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 1.3087082970954562 | validation: 1.394897149695688]
	TIME [epoch: 10.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.974841739111081		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.974841739111081 | validation: 0.902855527073412]
	TIME [epoch: 10.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.196699340135091		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 1.196699340135091 | validation: 1.753136081773376]
	TIME [epoch: 10.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2176707049385058		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.2176707049385058 | validation: 1.5463389038856818]
	TIME [epoch: 10.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1637779914347046		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 1.1637779914347046 | validation: 0.7493147269800371]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.271598145059032		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.271598145059032 | validation: 1.041084586071385]
	TIME [epoch: 10.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4186117246650904		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 1.4186117246650904 | validation: 1.6652891536525902]
	TIME [epoch: 10.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1809238625838034		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.1809238625838034 | validation: 1.432077183923983]
	TIME [epoch: 10.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3146351981881372		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 1.3146351981881372 | validation: 1.029133551567823]
	TIME [epoch: 10.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.104368221900397		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.104368221900397 | validation: 0.8123973022075185]
	TIME [epoch: 10.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0023987707986421		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.0023987707986421 | validation: 0.8391894551567518]
	TIME [epoch: 10.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.042761747968775		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.042761747968775 | validation: 1.545369176155807]
	TIME [epoch: 10.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1512898357669787		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 1.1512898357669787 | validation: 0.8855725158284707]
	TIME [epoch: 10.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.076300310659694		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.076300310659694 | validation: 1.4860554254408862]
	TIME [epoch: 10.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0281530886903685		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 1.0281530886903685 | validation: 0.9416091605656328]
	TIME [epoch: 10.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0245989536859157		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.0245989536859157 | validation: 0.9226290930273717]
	TIME [epoch: 10.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1821549218593828		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 1.1821549218593828 | validation: 0.859590089248281]
	TIME [epoch: 10.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9784809904950903		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.9784809904950903 | validation: 1.7065236371185473]
	TIME [epoch: 10.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2420100035466206		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 1.2420100035466206 | validation: 0.8829774989502762]
	TIME [epoch: 10.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0575558182268097		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.0575558182268097 | validation: 1.076191616124648]
	TIME [epoch: 10.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9048303027630595		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.9048303027630595 | validation: 1.0242946774999238]
	TIME [epoch: 10.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1445165467049072		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.1445165467049072 | validation: 1.4140956350702714]
	TIME [epoch: 10.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2489037801603762		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 1.2489037801603762 | validation: 1.6895012832105494]
	TIME [epoch: 10.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2475776738873767		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.2475776738873767 | validation: 1.0034848365848164]
	TIME [epoch: 10.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1835047547345792		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 1.1835047547345792 | validation: 1.814542767731212]
	TIME [epoch: 10.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3649243835733986		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.3649243835733986 | validation: 1.1754732232111844]
	TIME [epoch: 10.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0314869401066893		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 1.0314869401066893 | validation: 1.0883902457302117]
	TIME [epoch: 10.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9580113724217061		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.9580113724217061 | validation: 0.9148755579950398]
	TIME [epoch: 10.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0615154250309344		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 1.0615154250309344 | validation: 1.6034664581409772]
	TIME [epoch: 10.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9131538050364472		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.9131538050364472 | validation: 1.792521794941419]
	TIME [epoch: 10.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.360666161072031		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 1.360666161072031 | validation: 1.5627423655240642]
	TIME [epoch: 10.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.204166234157435		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.204166234157435 | validation: 0.9399435101495275]
	TIME [epoch: 10.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.148012636018298		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 1.148012636018298 | validation: 1.1101507490485956]
	TIME [epoch: 10.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1709998281740126		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.1709998281740126 | validation: 1.228996281217448]
	TIME [epoch: 10.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0805311590599973		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 1.0805311590599973 | validation: 1.0875762628850647]
	TIME [epoch: 10.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1914331623321077		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1914331623321077 | validation: 1.5992093194054757]
	TIME [epoch: 10.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4530018889710041		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 1.4530018889710041 | validation: 1.4295313464420702]
	TIME [epoch: 10.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0442187440528674		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.0442187440528674 | validation: 1.0137185443919783]
	TIME [epoch: 10.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.566294705994111		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 1.566294705994111 | validation: 1.201006773434088]
	TIME [epoch: 10.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2653754091865705		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.2653754091865705 | validation: 1.6084369314546798]
	TIME [epoch: 10.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.214998399072808		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 1.214998399072808 | validation: 1.592753948781793]
	TIME [epoch: 10.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1151160672793918		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.1151160672793918 | validation: 1.201933419475665]
	TIME [epoch: 10.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0817428953125248		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 1.0817428953125248 | validation: 1.086060685628751]
	TIME [epoch: 10.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1711274201402606		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.1711274201402606 | validation: 1.6144998483243922]
	TIME [epoch: 10.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.061104432184305		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 1.061104432184305 | validation: 1.6553008997189849]
	TIME [epoch: 10.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2828784620771263		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.2828784620771263 | validation: 1.1790491351247194]
	TIME [epoch: 10.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1793112724453256		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 1.1793112724453256 | validation: 1.2146830559208923]
	TIME [epoch: 10.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1793822676991677		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.1793822676991677 | validation: 1.0346327607413697]
	TIME [epoch: 10.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0291760409032256		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 1.0291760409032256 | validation: 1.0353689434714362]
	TIME [epoch: 10.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0453899267584057		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.0453899267584057 | validation: 0.8289314781098395]
	TIME [epoch: 10.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.216757180087278		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 1.216757180087278 | validation: 0.9109919803585609]
	TIME [epoch: 10.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9815178598483816		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.9815178598483816 | validation: 2.553208308341137]
	TIME [epoch: 10.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3436273526813987		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 1.3436273526813987 | validation: 0.8755633953212065]
	TIME [epoch: 10.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1000351199330498		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.1000351199330498 | validation: 1.327742629975432]
	TIME [epoch: 10.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.120224872555247		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 1.120224872555247 | validation: 0.9866632257809408]
	TIME [epoch: 10.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9439332717074344		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.9439332717074344 | validation: 1.1401795815156137]
	TIME [epoch: 10.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9976790170583033		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.9976790170583033 | validation: 0.8476415978945044]
	TIME [epoch: 10.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9640449767261934		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.9640449767261934 | validation: 1.1509350414410282]
	TIME [epoch: 10.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0261297779640235		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 1.0261297779640235 | validation: 0.992023796599349]
	TIME [epoch: 10.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0783080537995384		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.0783080537995384 | validation: 0.9896039892586171]
	TIME [epoch: 10.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.703336981277386		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 1.703336981277386 | validation: 1.168383648664027]
	TIME [epoch: 10.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1936223616901163		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.1936223616901163 | validation: 1.5526954626940725]
	TIME [epoch: 10.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1321768707208173		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 1.1321768707208173 | validation: 1.180368709350624]
	TIME [epoch: 10.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9575766343490791		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.9575766343490791 | validation: 1.0012032309797965]
	TIME [epoch: 10.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3979993895444227		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 1.3979993895444227 | validation: 0.9408970939966641]
	TIME [epoch: 10.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.092950432966483		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.092950432966483 | validation: 0.9355559400259609]
	TIME [epoch: 10.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0291519861841052		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 1.0291519861841052 | validation: 1.0126185832031918]
	TIME [epoch: 10.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9619177797088962		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.9619177797088962 | validation: 0.8131229259298735]
	TIME [epoch: 10.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.02436845534664		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 1.02436845534664 | validation: 1.4365302485402065]
	TIME [epoch: 10.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4604491816413891		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.4604491816413891 | validation: 1.1461856510036463]
	TIME [epoch: 10.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9475818813254197		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.9475818813254197 | validation: 1.2600682029120365]
	TIME [epoch: 10.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8998059651599062		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.8998059651599062 | validation: 1.1384221956393301]
	TIME [epoch: 10.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2199407624951848		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 1.2199407624951848 | validation: 1.6250824219444426]
	TIME [epoch: 10.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0166600412756754		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.0166600412756754 | validation: 1.1254313228162982]
	TIME [epoch: 10.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8372891122694022		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.8372891122694022 | validation: 1.4215447007209616]
	TIME [epoch: 10.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.034928677192695		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.034928677192695 | validation: 1.3927500746279626]
	TIME [epoch: 10.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0054304492569872		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 1.0054304492569872 | validation: 0.8601234463448174]
	TIME [epoch: 10.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2063225361763426		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.2063225361763426 | validation: 1.04256198606771]
	TIME [epoch: 10.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9730539642625724		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 0.9730539642625724 | validation: 1.3262735865488822]
	TIME [epoch: 10.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.090559490021644		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.090559490021644 | validation: 1.1770411986426357]
	TIME [epoch: 10.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0070728821635986		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 1.0070728821635986 | validation: 1.6491090388743077]
	TIME [epoch: 10.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2192130211213144		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.2192130211213144 | validation: 1.0938321837477762]
	TIME [epoch: 10.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.103225262414289		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 1.103225262414289 | validation: 1.1826537694014834]
	TIME [epoch: 10.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0346324373292632		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.0346324373292632 | validation: 1.2738773388481865]
	TIME [epoch: 10.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3831889616259159		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 1.3831889616259159 | validation: 0.889533285534732]
	TIME [epoch: 10.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0355709719168218		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.0355709719168218 | validation: 0.9808797151238758]
	TIME [epoch: 10.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0296288018665656		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 1.0296288018665656 | validation: 1.3961456149263263]
	TIME [epoch: 10.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0983836557740116		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.0983836557740116 | validation: 1.160592268628533]
	TIME [epoch: 10.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.007648751247605		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 1.007648751247605 | validation: 1.7073873088607894]
	TIME [epoch: 10.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8750094564673496		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.8750094564673496 | validation: 1.5287717164541406]
	TIME [epoch: 10.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0418191602225337		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 1.0418191602225337 | validation: 0.8683326229525108]
	TIME [epoch: 10.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8957523779311997		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.8957523779311997 | validation: 0.8635390930290544]
	TIME [epoch: 10.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1822782067630373		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 1.1822782067630373 | validation: 1.0189559752458863]
	TIME [epoch: 10.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0221698968155182		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.0221698968155182 | validation: 0.8244125344503083]
	TIME [epoch: 10.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0361925171737305		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 1.0361925171737305 | validation: 1.3794043538781386]
	TIME [epoch: 10.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1588110998251155		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.1588110998251155 | validation: 1.2323447475443763]
	TIME [epoch: 10.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995685344903201		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.8995685344903201 | validation: 0.727281661304821]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7668877789580523		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.7668877789580523 | validation: 1.4941407109623124]
	TIME [epoch: 10.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.06573473795281		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 1.06573473795281 | validation: 1.308675467034663]
	TIME [epoch: 10.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.199620484353575		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.199620484353575 | validation: 1.284197846542361]
	TIME [epoch: 10.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.049855188582239		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 1.049855188582239 | validation: 1.0874669386562053]
	TIME [epoch: 10.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8928758367977538		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.8928758367977538 | validation: 1.5139076027887859]
	TIME [epoch: 10.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9801817534272926		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.9801817534272926 | validation: 1.3857270281799299]
	TIME [epoch: 10.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9769373079105991		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.9769373079105991 | validation: 1.0894033864777335]
	TIME [epoch: 10.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547803788753265		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.8547803788753265 | validation: 1.1509873210959451]
	TIME [epoch: 10.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0216211064159944		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.0216211064159944 | validation: 0.8261276007519293]
	TIME [epoch: 10.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8866611072301196		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 1.8866611072301196 | validation: 0.988634528364899]
	TIME [epoch: 10.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995550880482568		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.8995550880482568 | validation: 1.138918020540909]
	TIME [epoch: 10.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7907307463390021		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.7907307463390021 | validation: 0.8375148178447849]
	TIME [epoch: 10.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7236091057599654		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.7236091057599654 | validation: 0.8320742508587724]
	TIME [epoch: 10.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6920955603927234		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.6920955603927234 | validation: 0.9297186606317821]
	TIME [epoch: 10.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.818107851590252		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.818107851590252 | validation: 1.6601221360552]
	TIME [epoch: 10.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1363095440481104		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 1.1363095440481104 | validation: 0.9426264252466099]
	TIME [epoch: 10.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0459909010025965		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.0459909010025965 | validation: 0.9025376456613015]
	TIME [epoch: 10.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559245695547085		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.9559245695547085 | validation: 1.1493585727444973]
	TIME [epoch: 10.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8792102184740382		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.8792102184740382 | validation: 1.5962101977788854]
	TIME [epoch: 10.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1040994418164989		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 1.1040994418164989 | validation: 1.1703074503946997]
	TIME [epoch: 10.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2006168824691288		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.2006168824691288 | validation: 2.0412690566262]
	TIME [epoch: 10.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1497942132931227		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 1.1497942132931227 | validation: 0.7411359490903743]
	TIME [epoch: 10.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869663853261143		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.6869663853261143 | validation: 1.4340888350887042]
	TIME [epoch: 10.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9864986104825283		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.9864986104825283 | validation: 0.8147139482554607]
	TIME [epoch: 10.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9160524650267622		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.9160524650267622 | validation: 1.0312071123919682]
	TIME [epoch: 10.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7536567435276957		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.7536567435276957 | validation: 1.0944460433454812]
	TIME [epoch: 10.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0944871042497304		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.0944871042497304 | validation: 1.0251838036961263]
	TIME [epoch: 10.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8040296206342701		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.8040296206342701 | validation: 1.3672122699240459]
	TIME [epoch: 10.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8873951860193856		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.8873951860193856 | validation: 0.8378300782013335]
	TIME [epoch: 10.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7848518600354704		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.7848518600354704 | validation: 1.2574278510716999]
	TIME [epoch: 10.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0745779350640436		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.0745779350640436 | validation: 0.8606573474726055]
	TIME [epoch: 10.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9294060988410517		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 0.9294060988410517 | validation: 0.8996852392788576]
	TIME [epoch: 10.4 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8812334690150152		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.8812334690150152 | validation: 0.8926058799431585]
	TIME [epoch: 10.4 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9141458377627742		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.9141458377627742 | validation: 1.219823565006292]
	TIME [epoch: 10.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7443243785929035		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.7443243785929035 | validation: 1.2423772882436646]
	TIME [epoch: 10.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9351088730359545		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.9351088730359545 | validation: 0.9788498691210907]
	TIME [epoch: 10.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.792244959360569		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.792244959360569 | validation: 0.8231410737903551]
	TIME [epoch: 10.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9244881430115006		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.9244881430115006 | validation: 0.7149767747330261]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325774394525306		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.7325774394525306 | validation: 0.8817940670480602]
	TIME [epoch: 10.4 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7260605846529647		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.7260605846529647 | validation: 0.9238670916762293]
	TIME [epoch: 10.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6796538628232837		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.6796538628232837 | validation: 0.7512031772260869]
	TIME [epoch: 10.4 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8375872326511686		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.8375872326511686 | validation: 0.622949539750922]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6404031328616107		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.6404031328616107 | validation: 0.8897423360553316]
	TIME [epoch: 10.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6295373078853246		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.6295373078853246 | validation: 0.892286574456751]
	TIME [epoch: 10.4 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7202511678252215		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.7202511678252215 | validation: 1.4754711062827826]
	TIME [epoch: 10.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0456373562543697		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 1.0456373562543697 | validation: 0.6456023380192855]
	TIME [epoch: 10.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9362024625440302		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.9362024625440302 | validation: 1.344600055212458]
	TIME [epoch: 10.4 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7022610056470806		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.7022610056470806 | validation: 0.7285705228268801]
	TIME [epoch: 10.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8477286315502373		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.8477286315502373 | validation: 1.415024109728667]
	TIME [epoch: 10.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7320910977510956		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.7320910977510956 | validation: 0.9375977091881993]
	TIME [epoch: 10.4 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8788441574885193		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.8788441574885193 | validation: 1.245354551062554]
	TIME [epoch: 10.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8701276704057634		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 1.8701276704057634 | validation: 2.0116746714668206]
	TIME [epoch: 10.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3117691218762908		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.3117691218762908 | validation: 0.8298300169295175]
	TIME [epoch: 10.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7044107926713854		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.7044107926713854 | validation: 0.7762965351180665]
	TIME [epoch: 10.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6951204546561025		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.6951204546561025 | validation: 1.0230791490360003]
	TIME [epoch: 10.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7131858798094388		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.7131858798094388 | validation: 0.9024330016229241]
	TIME [epoch: 10.4 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366018196040244		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.6366018196040244 | validation: 0.9660513385579248]
	TIME [epoch: 10.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695885851711318		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.6695885851711318 | validation: 0.5769377674837685]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7298636544343206		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.7298636544343206 | validation: 2.128872278288709]
	TIME [epoch: 10.4 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5065627428776769		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 1.5065627428776769 | validation: 1.2244269182359124]
	TIME [epoch: 10.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9333309388204489		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.9333309388204489 | validation: 0.693248510836341]
	TIME [epoch: 10.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6143037495668716		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.6143037495668716 | validation: 0.5276125518393928]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5899097713045507		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.5899097713045507 | validation: 0.6223253473252917]
	TIME [epoch: 10.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.629683361667942		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.629683361667942 | validation: 0.9520041932294134]
	TIME [epoch: 10.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7305854859947647		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.7305854859947647 | validation: 0.8680729805909215]
	TIME [epoch: 10.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7291763236961674		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.7291763236961674 | validation: 1.1326568688375376]
	TIME [epoch: 10.4 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5618163363724695		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.5618163363724695 | validation: 1.0386367444621007]
	TIME [epoch: 10.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8868587785468949		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.8868587785468949 | validation: 0.5052667603508699]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.555380100667752		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.555380100667752 | validation: 0.6954239302147468]
	TIME [epoch: 10.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6648481761774395		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.6648481761774395 | validation: 0.8418944285547927]
	TIME [epoch: 10.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7275179760317053		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.7275179760317053 | validation: 0.7579674164506587]
	TIME [epoch: 10.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6726452251046683		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.6726452251046683 | validation: 0.9015450315978051]
	TIME [epoch: 10.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.732314710595216		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.732314710595216 | validation: 0.8408323030328899]
	TIME [epoch: 10.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4851633222927495		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.4851633222927495 | validation: 0.4371957480734577]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9526360829352696		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.9526360829352696 | validation: 1.2072784875989022]
	TIME [epoch: 10.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7531900404650305		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.7531900404650305 | validation: 0.938664997850305]
	TIME [epoch: 10.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.770673665110658		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.770673665110658 | validation: 0.7682007485837579]
	TIME [epoch: 10.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8647379497499432		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.8647379497499432 | validation: 1.0572619598751352]
	TIME [epoch: 10.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7879896604801464		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.7879896604801464 | validation: 0.5355657690965873]
	TIME [epoch: 10.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.704059101728594		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.704059101728594 | validation: 0.9427883732398614]
	TIME [epoch: 10.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7874968439303309		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.7874968439303309 | validation: 1.2290578843466944]
	TIME [epoch: 10.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9701368547237014		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.9701368547237014 | validation: 1.2906216243539745]
	TIME [epoch: 10.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.183811839828273		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.183811839828273 | validation: 1.1054495069745012]
	TIME [epoch: 10.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.928282219146956		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.928282219146956 | validation: 1.1669679409098646]
	TIME [epoch: 10.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9016792325561074		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.9016792325561074 | validation: 1.132290030139517]
	TIME [epoch: 10.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8892814793484402		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.8892814793484402 | validation: 0.6947126407959746]
	TIME [epoch: 10.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9084019462906634		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.9084019462906634 | validation: 0.7916946230230792]
	TIME [epoch: 10.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7523591461933441		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.7523591461933441 | validation: 1.3437435833674714]
	TIME [epoch: 10.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9012639927164502		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.9012639927164502 | validation: 0.726873311879163]
	TIME [epoch: 10.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8827374736192569		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.8827374736192569 | validation: 1.1188246754686655]
	TIME [epoch: 10.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7562151625205148		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.7562151625205148 | validation: 1.4205120267786644]
	TIME [epoch: 10.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.780987486610221		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.780987486610221 | validation: 0.8290368992284374]
	TIME [epoch: 10.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.052786652537074		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.052786652537074 | validation: 0.8116211801993387]
	TIME [epoch: 10.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8548120760165647		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.8548120760165647 | validation: 0.7549859112385707]
	TIME [epoch: 10.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7171042387009743		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.7171042387009743 | validation: 0.9745616077980139]
	TIME [epoch: 10.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8843770708319696		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.8843770708319696 | validation: 0.6249956400140786]
	TIME [epoch: 10.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6067145079585607		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.6067145079585607 | validation: 0.7366392261852001]
	TIME [epoch: 10.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6056361234035432		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.6056361234035432 | validation: 0.7751347643421096]
	TIME [epoch: 10.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7810790310266587		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.7810790310266587 | validation: 0.8244668574142235]
	TIME [epoch: 10.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.788845726262447		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.788845726262447 | validation: 0.8773733101751825]
	TIME [epoch: 10.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.109883338468661		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.109883338468661 | validation: 0.8762950502406837]
	TIME [epoch: 10.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6886804921354241		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.6886804921354241 | validation: 0.9137488998725347]
	TIME [epoch: 10.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7904194751360386		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.7904194751360386 | validation: 0.9349028279395808]
	TIME [epoch: 10.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6352695778399372		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.6352695778399372 | validation: 0.7942303141368803]
	TIME [epoch: 10.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6852346632081778		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.6852346632081778 | validation: 0.8155975125670881]
	TIME [epoch: 10.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298855182098345		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.6298855182098345 | validation: 0.7550202890801324]
	TIME [epoch: 10.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.71820301028101		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.71820301028101 | validation: 1.0537925999371527]
	TIME [epoch: 10.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3525726912167837		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 1.3525726912167837 | validation: 1.21951762308117]
	TIME [epoch: 10.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9259634019555106		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.9259634019555106 | validation: 0.7554416923232538]
	TIME [epoch: 10.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534046738912807		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.6534046738912807 | validation: 0.6008397818759361]
	TIME [epoch: 10.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.682276818599804		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.682276818599804 | validation: 0.8048738338972268]
	TIME [epoch: 10.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.793661551802943		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.793661551802943 | validation: 0.7075401192585582]
	TIME [epoch: 10.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9500991677004114		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.9500991677004114 | validation: 1.3461244326997468]
	TIME [epoch: 10.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0349485950729538		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 1.0349485950729538 | validation: 1.3046853732403378]
	TIME [epoch: 10.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8741314727316976		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.8741314727316976 | validation: 0.9547857980351026]
	TIME [epoch: 10.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8621234254757415		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 1.8621234254757415 | validation: 2.22077755218369]
	TIME [epoch: 10.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0690850465746813		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 1.0690850465746813 | validation: 0.8582221676537465]
	TIME [epoch: 10.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740865850916251		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.7740865850916251 | validation: 0.7179141717928529]
	TIME [epoch: 10.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6487041564877793		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.6487041564877793 | validation: 0.7267989669328128]
	TIME [epoch: 10.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7268942473446331		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.7268942473446331 | validation: 1.821264330513398]
	TIME [epoch: 10.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8756224672056125		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.8756224672056125 | validation: 0.8702784437885069]
	TIME [epoch: 10.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500824385503391		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.6500824385503391 | validation: 0.5740865613967272]
	TIME [epoch: 10.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5908618470147643		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.5908618470147643 | validation: 0.8250868059152001]
	TIME [epoch: 10.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6800627863732938		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.6800627863732938 | validation: 2.1378876068297594]
	TIME [epoch: 10.4 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0710864158050586		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 1.0710864158050586 | validation: 1.056451148333221]
	TIME [epoch: 10.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7092723818393202		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.7092723818393202 | validation: 0.5791548576781574]
	TIME [epoch: 10.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749803261286734		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.5749803261286734 | validation: 0.8831478806849237]
	TIME [epoch: 10.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6690674459483437		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.6690674459483437 | validation: 0.548842799937776]
	TIME [epoch: 10.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305094565942703		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.6305094565942703 | validation: 1.007458710609035]
	TIME [epoch: 10.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6893244415254576		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.6893244415254576 | validation: 0.7515748092460806]
	TIME [epoch: 10.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9309759215366065		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.9309759215366065 | validation: 0.944223416737776]
	TIME [epoch: 10.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8617364641547605		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.8617364641547605 | validation: 0.7977965325848652]
	TIME [epoch: 10.4 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197250682026201		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.5197250682026201 | validation: 0.5375166751700032]
	TIME [epoch: 10.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.540133232341642		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.540133232341642 | validation: 0.9291487440410433]
	TIME [epoch: 10.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7210763620575181		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.7210763620575181 | validation: 0.8295195994384806]
	TIME [epoch: 10.4 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6733748186212793		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.6733748186212793 | validation: 0.8878157387990956]
	TIME [epoch: 10.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8330959969359586		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.8330959969359586 | validation: 0.8003547285125613]
	TIME [epoch: 10.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7329028345757361		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.7329028345757361 | validation: 1.126390535956017]
	TIME [epoch: 10.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7582627751497318		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.7582627751497318 | validation: 0.5308180139240877]
	TIME [epoch: 10.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448070803803878		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.6448070803803878 | validation: 1.0053885543478887]
	TIME [epoch: 10.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415551089283157		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.5415551089283157 | validation: 1.0725336003092236]
	TIME [epoch: 10.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7085367602450197		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.7085367602450197 | validation: 0.6119402640778053]
	TIME [epoch: 10.4 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5852978581005697		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.5852978581005697 | validation: 0.9392633646742954]
	TIME [epoch: 10.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0192179751916883		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 1.0192179751916883 | validation: 0.7889468824093641]
	TIME [epoch: 10.4 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7510435831908708		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.7510435831908708 | validation: 0.619359063472638]
	TIME [epoch: 10.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351132093059821		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.6351132093059821 | validation: 0.5676885272359885]
	TIME [epoch: 10.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6892501406088585		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.6892501406088585 | validation: 0.7161405021840119]
	TIME [epoch: 10.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6531981708271005		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.6531981708271005 | validation: 0.4747337580648891]
	TIME [epoch: 10.4 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4254902309626215		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.4254902309626215 | validation: 0.5414865201619404]
	TIME [epoch: 10.4 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5868151030681532		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.5868151030681532 | validation: 0.509890580932539]
	TIME [epoch: 10.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139210199487925		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.5139210199487925 | validation: 1.303631400199654]
	TIME [epoch: 10.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7686347105398175		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.7686347105398175 | validation: 0.6097749089666048]
	TIME [epoch: 10.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159733364122731		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.6159733364122731 | validation: 0.7338475697357402]
	TIME [epoch: 10.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577801033289991		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.5577801033289991 | validation: 0.8757133500882021]
	TIME [epoch: 10.4 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5859434533905988		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.5859434533905988 | validation: 0.5350399517207007]
	TIME [epoch: 10.4 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.468722820255306		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.468722820255306 | validation: 0.6277919193250532]
	TIME [epoch: 10.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4858759764110186		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.4858759764110186 | validation: 0.99481403363038]
	TIME [epoch: 10.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49817687942867667		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.49817687942867667 | validation: 0.47973178494846436]
	TIME [epoch: 10.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6623562387024815		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.6623562387024815 | validation: 0.8312957211000606]
	TIME [epoch: 10.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6400743741544046		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.6400743741544046 | validation: 0.6870352653534602]
	TIME [epoch: 10.4 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44590909548874375		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.44590909548874375 | validation: 0.6428109182972845]
	TIME [epoch: 10.4 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42783829679555685		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.42783829679555685 | validation: 0.36535822204532964]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36926858225645676		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.36926858225645676 | validation: 0.8336608602238752]
	TIME [epoch: 10.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8744963592897104		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.8744963592897104 | validation: 0.9614271077744938]
	TIME [epoch: 10.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469575701707797		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.6469575701707797 | validation: 1.0743614100923369]
	TIME [epoch: 10.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7158121098785498		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.7158121098785498 | validation: 0.9336027809383909]
	TIME [epoch: 10.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5854499423646228		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.5854499423646228 | validation: 0.8974112206673905]
	TIME [epoch: 10.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6871806778034001		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.6871806778034001 | validation: 0.9235017636471602]
	TIME [epoch: 10.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7951352944768788		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.7951352944768788 | validation: 0.808981609837967]
	TIME [epoch: 10.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6262249083907792		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.6262249083907792 | validation: 0.7438865748116547]
	TIME [epoch: 10.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44727060596101137		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.44727060596101137 | validation: 0.5472567924358123]
	TIME [epoch: 10.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41661746229276336		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.41661746229276336 | validation: 0.48857452762614273]
	TIME [epoch: 10.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0018984514723377		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 1.0018984514723377 | validation: 1.4375414812053586]
	TIME [epoch: 10.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8146306456710389		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.8146306456710389 | validation: 0.5154446550247996]
	TIME [epoch: 10.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4364325181223605		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.4364325181223605 | validation: 0.32062780462517376]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.578464128813368		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.578464128813368 | validation: 0.7940145315015985]
	TIME [epoch: 10.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7264046457714721		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.7264046457714721 | validation: 0.5247450283438198]
	TIME [epoch: 10.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8100915272679906		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.8100915272679906 | validation: 0.5286144680268742]
	TIME [epoch: 10.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43702704736397247		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.43702704736397247 | validation: 0.34667105657126007]
	TIME [epoch: 10.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3706605388902727		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.3706605388902727 | validation: 0.921100903704313]
	TIME [epoch: 10.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9513968552867308		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.9513968552867308 | validation: 0.5662957070915517]
	TIME [epoch: 10.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38605741854514025		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.38605741854514025 | validation: 0.5369604583252774]
	TIME [epoch: 10.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5663157296582182		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.5663157296582182 | validation: 0.49733335316816724]
	TIME [epoch: 10.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.619616630921484		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.619616630921484 | validation: 0.8633753046061844]
	TIME [epoch: 10.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5663142135027144		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.5663142135027144 | validation: 0.8250459769926954]
	TIME [epoch: 10.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6510492830626776		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.6510492830626776 | validation: 0.8103868188704462]
	TIME [epoch: 10.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5097870787628034		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.5097870787628034 | validation: 0.5960636902643893]
	TIME [epoch: 10.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41011123575941577		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.41011123575941577 | validation: 0.4395756125813847]
	TIME [epoch: 10.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444384441192034		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.4444384441192034 | validation: 0.7580558085824879]
	TIME [epoch: 10.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6507597315687506		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.6507597315687506 | validation: 0.9756949451942234]
	TIME [epoch: 10.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6192727412306592		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.6192727412306592 | validation: 0.4588051768974604]
	TIME [epoch: 10.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4131501631889088		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.4131501631889088 | validation: 0.3353706799835578]
	TIME [epoch: 10.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4850098824026416		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4850098824026416 | validation: 0.9330686956890571]
	TIME [epoch: 10.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.654484678569566		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.654484678569566 | validation: 0.8515840842794932]
	TIME [epoch: 10.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252018350923184		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.5252018350923184 | validation: 1.1094385840316772]
	TIME [epoch: 10.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256236553062044		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.5256236553062044 | validation: 0.7247361708808941]
	TIME [epoch: 10.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6703496779432114		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.6703496779432114 | validation: 0.5596404619821861]
	TIME [epoch: 10.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42007199175219706		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.42007199175219706 | validation: 0.6426351585424942]
	TIME [epoch: 10.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5083815179474923		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.5083815179474923 | validation: 2.0435309053922364]
	TIME [epoch: 10.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9828575977747336		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.9828575977747336 | validation: 0.5424480323389587]
	TIME [epoch: 10.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350325579599041		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.6350325579599041 | validation: 0.5490833092289067]
	TIME [epoch: 10.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061590560186485		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.6061590560186485 | validation: 0.41619588010172487]
	TIME [epoch: 10.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.516327927167015		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.516327927167015 | validation: 0.7474853001216687]
	TIME [epoch: 10.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4917113320273353		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.4917113320273353 | validation: 0.6724757105478717]
	TIME [epoch: 10.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5240932291041472		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.5240932291041472 | validation: 1.0872304843861935]
	TIME [epoch: 10.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7290864255557784		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.7290864255557784 | validation: 0.42882697166519806]
	TIME [epoch: 10.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48283233204412246		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.48283233204412246 | validation: 0.7145782601285171]
	TIME [epoch: 10.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4399335274445744		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.4399335274445744 | validation: 0.3439752705479027]
	TIME [epoch: 10.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759188695609986		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5759188695609986 | validation: 0.43681291392003985]
	TIME [epoch: 10.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424624453593675		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.5424624453593675 | validation: 0.5853832757408592]
	TIME [epoch: 10.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4835244527318189		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.4835244527318189 | validation: 0.5991678631545693]
	TIME [epoch: 10.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5097922037511717		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.5097922037511717 | validation: 0.40658247676063697]
	TIME [epoch: 10.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5309558661467321		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.5309558661467321 | validation: 0.6475752399475545]
	TIME [epoch: 10.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237934760723568		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.5237934760723568 | validation: 1.1385045476564537]
	TIME [epoch: 10.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7951792105405106		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.7951792105405106 | validation: 0.6717865485658823]
	TIME [epoch: 10.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47908247538422943		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.47908247538422943 | validation: 0.4838495222142874]
	TIME [epoch: 10.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353567023506814		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.5353567023506814 | validation: 0.480180878736604]
	TIME [epoch: 10.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4871281857096551		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.4871281857096551 | validation: 0.5984238531285523]
	TIME [epoch: 10.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5609704995575303		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.5609704995575303 | validation: 0.5594439575972866]
	TIME [epoch: 10.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43940949764466125		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.43940949764466125 | validation: 0.5534772038943209]
	TIME [epoch: 10.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45213854745648385		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.45213854745648385 | validation: 0.5012928115627692]
	TIME [epoch: 10.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4332383960658988		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.4332383960658988 | validation: 0.8989402116648401]
	TIME [epoch: 10.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5406979235539899		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5406979235539899 | validation: 0.9109667785811066]
	TIME [epoch: 10.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5578930109188619		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.5578930109188619 | validation: 0.5990953142193105]
	TIME [epoch: 10.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4990880893812273		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.4990880893812273 | validation: 0.7439203558835689]
	TIME [epoch: 10.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.534131940970507		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.534131940970507 | validation: 0.41971431933547443]
	TIME [epoch: 10.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4018507007553147		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4018507007553147 | validation: 0.5292280760744983]
	TIME [epoch: 10.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4854885632401319		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.4854885632401319 | validation: 0.3921063157020759]
	TIME [epoch: 10.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37683286122876203		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.37683286122876203 | validation: 0.3732649777849742]
	TIME [epoch: 10.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39651315123122477		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.39651315123122477 | validation: 0.5390623434396874]
	TIME [epoch: 10.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326294125106998		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.5326294125106998 | validation: 0.43264246541377377]
	TIME [epoch: 10.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149368176229242		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.5149368176229242 | validation: 0.515019720224784]
	TIME [epoch: 10.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439414012309883		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.4439414012309883 | validation: 0.5362007955332955]
	TIME [epoch: 10.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.608582486470631		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.608582486470631 | validation: 1.0638180025910189]
	TIME [epoch: 10.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4374401063718582		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.4374401063718582 | validation: 0.5196411146847726]
	TIME [epoch: 10.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6830256047563743		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.6830256047563743 | validation: 0.6791382460433303]
	TIME [epoch: 10.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5619380775424739		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.5619380775424739 | validation: 0.4321317761753783]
	TIME [epoch: 10.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.700232674228112		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.700232674228112 | validation: 1.2452609357700024]
	TIME [epoch: 10.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273946717101664		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.5273946717101664 | validation: 0.7644527233533804]
	TIME [epoch: 10.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49063227260753184		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.49063227260753184 | validation: 0.45881883555618486]
	TIME [epoch: 10.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553097551936574		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.5553097551936574 | validation: 0.9514115297595026]
	TIME [epoch: 10.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7176692531729196		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.7176692531729196 | validation: 1.0072524824692888]
	TIME [epoch: 10.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7771668368054081		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.7771668368054081 | validation: 0.9102386463197023]
	TIME [epoch: 10.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.942432321032828		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.942432321032828 | validation: 1.0425016298976162]
	TIME [epoch: 10.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0020468276677932		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 1.0020468276677932 | validation: 0.9653828407575291]
	TIME [epoch: 10.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876495238065883		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.7876495238065883 | validation: 1.555048897095129]
	TIME [epoch: 10.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0325179612255146		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 1.0325179612255146 | validation: 0.4853025497775383]
	TIME [epoch: 10.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162814654390609		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.4162814654390609 | validation: 0.42958401180628364]
	TIME [epoch: 10.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.524212688385228		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.524212688385228 | validation: 0.7777772350618588]
	TIME [epoch: 10.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518394214610523		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.518394214610523 | validation: 0.6208433348164878]
	TIME [epoch: 10.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4206400701874971		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.4206400701874971 | validation: 0.6928361566600348]
	TIME [epoch: 10.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45963244114776297		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.45963244114776297 | validation: 0.4562672112205162]
	TIME [epoch: 10.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46839016263371713		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.46839016263371713 | validation: 0.57229269821775]
	TIME [epoch: 10.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7334864311740242		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.7334864311740242 | validation: 0.6923625604579493]
	TIME [epoch: 10.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4839178364384237		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.4839178364384237 | validation: 0.5843259717093191]
	TIME [epoch: 10.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3940645756362304		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.3940645756362304 | validation: 0.4796069265900987]
	TIME [epoch: 10.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5362493900044544		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.5362493900044544 | validation: 0.33799789292286603]
	TIME [epoch: 10.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523709370958534		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.523709370958534 | validation: 1.6376530117754093]
	TIME [epoch: 10.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.949863827134285		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.949863827134285 | validation: 0.6959982560520587]
	TIME [epoch: 10.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245887611120799		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.5245887611120799 | validation: 0.6049740842715651]
	TIME [epoch: 10.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5578026860759809		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.5578026860759809 | validation: 0.44259212979303886]
	TIME [epoch: 10.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43921067363028043		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.43921067363028043 | validation: 0.44012111633539874]
	TIME [epoch: 10.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43885622641189814		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.43885622641189814 | validation: 0.4796181564683265]
	TIME [epoch: 10.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333656813914704		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.6333656813914704 | validation: 0.8034071299302429]
	TIME [epoch: 10.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7640621175180121		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.7640621175180121 | validation: 0.5467075723322611]
	TIME [epoch: 10.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46210867860543053		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.46210867860543053 | validation: 0.612336894536504]
	TIME [epoch: 10.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7363213552519076		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.7363213552519076 | validation: 0.7425019824076649]
	TIME [epoch: 10.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164993870976728		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.5164993870976728 | validation: 0.4796342137780107]
	TIME [epoch: 10.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37287665479954085		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.37287665479954085 | validation: 0.5694329503881983]
	TIME [epoch: 10.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443811129184871		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.5443811129184871 | validation: 0.6592105363934851]
	TIME [epoch: 10.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795755677264106		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.3795755677264106 | validation: 0.5148855619071965]
	TIME [epoch: 10.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4665205056555782		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.4665205056555782 | validation: 0.5699510845065572]
	TIME [epoch: 10.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39353985771868577		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.39353985771868577 | validation: 0.70299636818927]
	TIME [epoch: 10.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38194195733285		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.38194195733285 | validation: 0.6779357456952347]
	TIME [epoch: 10.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4777503052016089		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.4777503052016089 | validation: 0.5799495746905372]
	TIME [epoch: 10.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4923460221520776		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.4923460221520776 | validation: 0.5011268323079487]
	TIME [epoch: 10.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6021126572558355		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.6021126572558355 | validation: 0.6801518826077205]
	TIME [epoch: 10.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4394834581732187		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.4394834581732187 | validation: 0.6621785070985188]
	TIME [epoch: 10.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4141604355401717		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.4141604355401717 | validation: 1.5468701913709675]
	TIME [epoch: 10.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8433420413059999		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.8433420413059999 | validation: 0.5934261879624414]
	TIME [epoch: 10.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5554789420405435		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.5554789420405435 | validation: 0.5072742270092155]
	TIME [epoch: 10.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4542478330729341		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.4542478330729341 | validation: 0.6075522384052601]
	TIME [epoch: 10.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5147504059926948		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.5147504059926948 | validation: 0.4698707711889161]
	TIME [epoch: 10.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270514055109523		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.5270514055109523 | validation: 0.973728824468288]
	TIME [epoch: 10.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250895929032226		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.6250895929032226 | validation: 0.4506793172145713]
	TIME [epoch: 10.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4172011973219439		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.4172011973219439 | validation: 0.694565934167897]
	TIME [epoch: 10.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39808531024442634		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.39808531024442634 | validation: 0.6347028104110599]
	TIME [epoch: 10.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440216529439968		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.5440216529439968 | validation: 0.3970117806795249]
	TIME [epoch: 10.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4705688761890241		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.4705688761890241 | validation: 0.5741363938645703]
	TIME [epoch: 10.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.408813131490078		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.408813131490078 | validation: 0.6921310266001858]
	TIME [epoch: 10.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4749057589503852		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.4749057589503852 | validation: 0.36662332673150455]
	TIME [epoch: 10.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.462760144222481		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.462760144222481 | validation: 1.4511234665351143]
	TIME [epoch: 10.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8673000032179022		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.8673000032179022 | validation: 0.4498281632626329]
	TIME [epoch: 10.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4335635224686353		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.4335635224686353 | validation: 0.49976793468295494]
	TIME [epoch: 10.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4722249015375903		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.4722249015375903 | validation: 0.8205505110288225]
	TIME [epoch: 10.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.450217284008391		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.450217284008391 | validation: 0.803569109889009]
	TIME [epoch: 10.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.557721558633639		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.557721558633639 | validation: 0.45966251269849495]
	TIME [epoch: 10.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3884582197378087		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.3884582197378087 | validation: 1.0530787168620865]
	TIME [epoch: 10.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251522186549027		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.5251522186549027 | validation: 0.4832106613203876]
	TIME [epoch: 10.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200173040044982		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.4200173040044982 | validation: 0.33370076296094037]
	TIME [epoch: 10.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3783878963231241		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.3783878963231241 | validation: 0.46453297737630345]
	TIME [epoch: 10.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36809013764195203		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.36809013764195203 | validation: 0.5423720554134943]
	TIME [epoch: 10.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36725443748229203		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.36725443748229203 | validation: 0.46076473707697446]
	TIME [epoch: 10.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3987228954432993		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.3987228954432993 | validation: 0.46248379431236686]
	TIME [epoch: 10.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3978055482332256		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.3978055482332256 | validation: 0.4993890620493502]
	TIME [epoch: 10.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38057621428132415		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.38057621428132415 | validation: 0.4044802902896133]
	TIME [epoch: 10.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30991736829230476		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.30991736829230476 | validation: 0.6123805528731311]
	TIME [epoch: 10.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5984671078642702		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.5984671078642702 | validation: 0.9378672569188361]
	TIME [epoch: 10.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091660069832018		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.5091660069832018 | validation: 0.5900792283642599]
	TIME [epoch: 10.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31091618956414424		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.31091618956414424 | validation: 0.6741638797070684]
	TIME [epoch: 10.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3796185577279217		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.3796185577279217 | validation: 0.30001475228723534]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3182217874039172		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.3182217874039172 | validation: 0.7250557265475367]
	TIME [epoch: 10.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3235299730617782		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.3235299730617782 | validation: 0.4105101140963132]
	TIME [epoch: 10.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31680516722378815		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.31680516722378815 | validation: 0.41605576237704844]
	TIME [epoch: 10.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233152643322617		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.3233152643322617 | validation: 0.32389203080452456]
	TIME [epoch: 10.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.353926802188237		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.353926802188237 | validation: 0.4214871319088583]
	TIME [epoch: 10.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40898321247644487		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.40898321247644487 | validation: 0.3556683045897719]
	TIME [epoch: 10.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31653579039436563		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.31653579039436563 | validation: 0.689450571136367]
	TIME [epoch: 10.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233697272223401		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.5233697272223401 | validation: 0.6361594313947672]
	TIME [epoch: 10.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012973000120702		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.4012973000120702 | validation: 0.4756932601186214]
	TIME [epoch: 10.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3220713919031935		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.3220713919031935 | validation: 0.3690802253571191]
	TIME [epoch: 10.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3634068387980772		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.3634068387980772 | validation: 0.486143409498181]
	TIME [epoch: 10.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36455836586799756		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.36455836586799756 | validation: 0.6140357916411064]
	TIME [epoch: 10.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4070425239469656		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.4070425239469656 | validation: 0.3423878816081725]
	TIME [epoch: 10.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2863238921238387		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.2863238921238387 | validation: 0.40823345452296567]
	TIME [epoch: 10.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013016586933914		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.3013016586933914 | validation: 0.5003977329137519]
	TIME [epoch: 10.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28608167479881075		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.28608167479881075 | validation: 0.43075094898521954]
	TIME [epoch: 10.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3473501579904355		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.3473501579904355 | validation: 0.4347566083851687]
	TIME [epoch: 10.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34753255282243484		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.34753255282243484 | validation: 0.4963560828100411]
	TIME [epoch: 10.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4029339805389903		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.4029339805389903 | validation: 0.2849318261637975]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27492453648990656		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.27492453648990656 | validation: 0.4968382680709664]
	TIME [epoch: 10.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38981121778507444		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.38981121778507444 | validation: 0.36399101087054647]
	TIME [epoch: 10.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4740644452431043		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.4740644452431043 | validation: 0.471795262055017]
	TIME [epoch: 10.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34967664848915725		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.34967664848915725 | validation: 0.7775711444359468]
	TIME [epoch: 10.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28852198901133636		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.28852198901133636 | validation: 0.2753501539888743]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124086455700766		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.3124086455700766 | validation: 0.5391631908601674]
	TIME [epoch: 10.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4911423130918404		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.4911423130918404 | validation: 0.44314823649175117]
	TIME [epoch: 10.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44766604744510535		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.44766604744510535 | validation: 0.4718775825185274]
	TIME [epoch: 10.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4254475882046984		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.4254475882046984 | validation: 0.6322504973357163]
	TIME [epoch: 10.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217445755561674		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.5217445755561674 | validation: 0.5339624542706133]
	TIME [epoch: 10.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4929986901072055		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.4929986901072055 | validation: 0.6292228944192537]
	TIME [epoch: 10.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38874991448926927		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.38874991448926927 | validation: 0.8408674234868534]
	TIME [epoch: 10.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4760001062204592		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.4760001062204592 | validation: 0.3638177471187663]
	TIME [epoch: 10.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3686763369644394		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.3686763369644394 | validation: 0.35269895577681387]
	TIME [epoch: 10.4 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34029263562016804		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.34029263562016804 | validation: 0.34355796959299084]
	TIME [epoch: 10.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3306509943606011		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.3306509943606011 | validation: 0.45215171754349637]
	TIME [epoch: 10.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43839158880457935		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.43839158880457935 | validation: 0.2558645655632251]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32747689825622583		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.32747689825622583 | validation: 0.36763285513018834]
	TIME [epoch: 10.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230291121259839		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.3230291121259839 | validation: 0.7137396663208909]
	TIME [epoch: 10.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45027369294981734		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.45027369294981734 | validation: 0.47061280872365047]
	TIME [epoch: 10.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28663309407565685		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.28663309407565685 | validation: 0.4489823079126075]
	TIME [epoch: 10.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32394699555694617		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.32394699555694617 | validation: 0.5297703734502275]
	TIME [epoch: 10.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33941869808861397		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.33941869808861397 | validation: 0.5538791263757301]
	TIME [epoch: 10.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27923563706074106		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.27923563706074106 | validation: 0.2921818867535771]
	TIME [epoch: 10.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28653597471176057		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.28653597471176057 | validation: 0.4257556846081613]
	TIME [epoch: 10.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3067827625314723		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.3067827625314723 | validation: 0.49060336744346444]
	TIME [epoch: 10.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3452755001164315		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.3452755001164315 | validation: 0.2969410769621451]
	TIME [epoch: 10.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25215643422942063		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.25215643422942063 | validation: 0.23108947500881466]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3799513657297386		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.3799513657297386 | validation: 0.43592449242958764]
	TIME [epoch: 10.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35136155085598253		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.35136155085598253 | validation: 0.5334142973004182]
	TIME [epoch: 10.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3571409535714942		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.3571409535714942 | validation: 0.37521250813336327]
	TIME [epoch: 10.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2754509289636323		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.2754509289636323 | validation: 0.3634332132067634]
	TIME [epoch: 10.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182638941538152		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.4182638941538152 | validation: 0.32490034285102815]
	TIME [epoch: 10.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2601925347470456		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.2601925347470456 | validation: 0.4839061796656573]
	TIME [epoch: 10.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3761473098463529		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.3761473098463529 | validation: 0.5522248535735002]
	TIME [epoch: 10.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3378475439666831		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.3378475439666831 | validation: 0.3822077522795955]
	TIME [epoch: 10.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075045983767404		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.3075045983767404 | validation: 0.2801607592064202]
	TIME [epoch: 10.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25724005212693307		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.25724005212693307 | validation: 0.24061611223578908]
	TIME [epoch: 10.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30618548667677753		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.30618548667677753 | validation: 0.4961788006519735]
	TIME [epoch: 10.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256051357458954		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.256051357458954 | validation: 0.2196748408851142]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2853503275986988		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.2853503275986988 | validation: 0.4650691264979565]
	TIME [epoch: 10.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33050614902844216		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.33050614902844216 | validation: 0.27797141403300113]
	TIME [epoch: 10.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2810061987300771		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.2810061987300771 | validation: 0.30315552910692817]
	TIME [epoch: 10.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28676514226522976		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.28676514226522976 | validation: 0.42552962561928104]
	TIME [epoch: 10.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2844377973841732		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.2844377973841732 | validation: 0.5537485830344112]
	TIME [epoch: 10.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32200388266667457		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.32200388266667457 | validation: 0.2267234524556963]
	TIME [epoch: 10.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278134555583827		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.2278134555583827 | validation: 0.45730658227532717]
	TIME [epoch: 10.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059082769506863		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.3059082769506863 | validation: 0.4484775224528623]
	TIME [epoch: 10.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30466161588114593		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.30466161588114593 | validation: 0.45540364577742914]
	TIME [epoch: 10.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21399487121256003		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.21399487121256003 | validation: 0.25428485008925383]
	TIME [epoch: 10.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922410256564112		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2922410256564112 | validation: 0.31603962939583996]
	TIME [epoch: 10.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35653023986169785		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.35653023986169785 | validation: 0.2560524969489046]
	TIME [epoch: 10.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29406383898908056		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.29406383898908056 | validation: 0.3842456279253431]
	TIME [epoch: 10.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4617164039026706		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.4617164039026706 | validation: 0.35142787876927684]
	TIME [epoch: 10.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36328116480422806		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.36328116480422806 | validation: 0.31215460316059473]
	TIME [epoch: 10.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2905548718145171		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.2905548718145171 | validation: 0.308716171988319]
	TIME [epoch: 10.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32739345497550254		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.32739345497550254 | validation: 0.4213343223071493]
	TIME [epoch: 10.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3501621286076624		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.3501621286076624 | validation: 0.579831388091658]
	TIME [epoch: 10.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3303244847430216		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.3303244847430216 | validation: 0.5697650836343747]
	TIME [epoch: 10.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30763448460984244		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.30763448460984244 | validation: 0.3648028886819833]
	TIME [epoch: 10.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.360826507917801		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.360826507917801 | validation: 0.5178726677084486]
	TIME [epoch: 10.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3583272231149358		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.3583272231149358 | validation: 0.3039561026734021]
	TIME [epoch: 10.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2891411629317894		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.2891411629317894 | validation: 0.32779778744452986]
	TIME [epoch: 10.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922239102645836		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.2922239102645836 | validation: 0.2902275432562516]
	TIME [epoch: 10.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3578478991034463		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.3578478991034463 | validation: 0.35207574346044096]
	TIME [epoch: 10.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27871847659927534		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.27871847659927534 | validation: 0.23163985932418946]
	TIME [epoch: 10.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3189262284183637		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.3189262284183637 | validation: 0.199269453039974]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29392616932886345		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.29392616932886345 | validation: 0.33500218354053496]
	TIME [epoch: 10.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33448926134023765		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.33448926134023765 | validation: 0.6293953555943201]
	TIME [epoch: 10.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33554893288318705		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.33554893288318705 | validation: 0.3106604720546519]
	TIME [epoch: 10.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2393009917470011		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.2393009917470011 | validation: 0.2233303856483382]
	TIME [epoch: 10.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21357715072017874		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.21357715072017874 | validation: 0.48525623033893567]
	TIME [epoch: 10.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3337532499176079		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.3337532499176079 | validation: 0.4037227076765711]
	TIME [epoch: 10.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588748437976767		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.2588748437976767 | validation: 0.2383182802105231]
	TIME [epoch: 10.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21181351681318752		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.21181351681318752 | validation: 0.3171230412064889]
	TIME [epoch: 10.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.283849275354656		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.283849275354656 | validation: 0.43828936736774654]
	TIME [epoch: 10.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3596831659170559		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3596831659170559 | validation: 0.2999645693066425]
	TIME [epoch: 10.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24786944697777624		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.24786944697777624 | validation: 0.31786983582471073]
	TIME [epoch: 10.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42996128226789204		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.42996128226789204 | validation: 0.602660481254592]
	TIME [epoch: 10.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47904744307400493		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.47904744307400493 | validation: 0.30518321352266176]
	TIME [epoch: 10.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26645401854125905		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.26645401854125905 | validation: 0.28094220229752126]
	TIME [epoch: 10.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26336900823428167		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.26336900823428167 | validation: 0.28872231038226054]
	TIME [epoch: 10.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20840879138239377		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.20840879138239377 | validation: 0.32151430059360975]
	TIME [epoch: 10.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34832623879816926		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.34832623879816926 | validation: 0.9434002149793148]
	TIME [epoch: 10.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5478477284993293		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.5478477284993293 | validation: 0.37316194599905955]
	TIME [epoch: 10.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2284986322204121		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.2284986322204121 | validation: 0.19659551030865552]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20302026736954099		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.20302026736954099 | validation: 0.397945554544409]
	TIME [epoch: 10.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2826165799201935		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.2826165799201935 | validation: 0.31628796666677145]
	TIME [epoch: 10.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2125948675482651		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.2125948675482651 | validation: 0.41294972651977946]
	TIME [epoch: 10.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18048793821676123		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.18048793821676123 | validation: 0.4194687876287526]
	TIME [epoch: 10.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920784971268602		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.2920784971268602 | validation: 0.22592707135936912]
	TIME [epoch: 10.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2556018061886912		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.2556018061886912 | validation: 0.26912144961050727]
	TIME [epoch: 10.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35213581193565063		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.35213581193565063 | validation: 0.6592520054398425]
	TIME [epoch: 10.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4290437759976469		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.4290437759976469 | validation: 0.5329994046163898]
	TIME [epoch: 10.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31660708042498176		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.31660708042498176 | validation: 0.42702884733340296]
	TIME [epoch: 10.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3450025175247231		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.3450025175247231 | validation: 0.44069560478940745]
	TIME [epoch: 10.4 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33850008792420627		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.33850008792420627 | validation: 0.4096942146326707]
	TIME [epoch: 10.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3133044440309173		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.3133044440309173 | validation: 0.3351797207735012]
	TIME [epoch: 10.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2360919841903089		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.2360919841903089 | validation: 0.24205624246053206]
	TIME [epoch: 10.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21286585072379008		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.21286585072379008 | validation: 0.28903831186348905]
	TIME [epoch: 10.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35223309586061485		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.35223309586061485 | validation: 0.5826900419494403]
	TIME [epoch: 10.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26853980493367113		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.26853980493367113 | validation: 0.35278134108720594]
	TIME [epoch: 10.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4571562101640506		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.4571562101640506 | validation: 1.5099717167658693]
	TIME [epoch: 10.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7624854341158508		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.7624854341158508 | validation: 0.8627420409640605]
	TIME [epoch: 10.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3629133630058773		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.3629133630058773 | validation: 0.26792404435768136]
	TIME [epoch: 10.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29649600235422874		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.29649600235422874 | validation: 0.39324995879106556]
	TIME [epoch: 10.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3896403085143608		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.3896403085143608 | validation: 0.47246950897840206]
	TIME [epoch: 10.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3293706197048367		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.3293706197048367 | validation: 0.41551265449479735]
	TIME [epoch: 10.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26155899671713634		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.26155899671713634 | validation: 0.3029209870792747]
	TIME [epoch: 10.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21321385390463296		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.21321385390463296 | validation: 0.3665446873349118]
	TIME [epoch: 10.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2150936029271456		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.2150936029271456 | validation: 0.502521504273601]
	TIME [epoch: 10.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32283951292649243		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.32283951292649243 | validation: 0.35047308351776546]
	TIME [epoch: 10.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4418031952515462		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.4418031952515462 | validation: 0.4009025918596807]
	TIME [epoch: 10.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23184657113857615		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.23184657113857615 | validation: 0.44054264584411906]
	TIME [epoch: 10.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28092797116529356		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.28092797116529356 | validation: 0.7156076274085333]
	TIME [epoch: 10.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2984270750495047		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.2984270750495047 | validation: 0.34661047377168475]
	TIME [epoch: 10.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076048238771903		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.3076048238771903 | validation: 0.49523939216861396]
	TIME [epoch: 10.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34641024464712344		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.34641024464712344 | validation: 0.5283395046779401]
	TIME [epoch: 10.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2926718981600941		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.2926718981600941 | validation: 0.38126299148802106]
	TIME [epoch: 10.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3473271367121565		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.3473271367121565 | validation: 0.6154137096076567]
	TIME [epoch: 10.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44887994522940466		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.44887994522940466 | validation: 0.5063808550584691]
	TIME [epoch: 10.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060859749641718		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.4060859749641718 | validation: 0.6321732926071354]
	TIME [epoch: 10.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4293174708318891		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.4293174708318891 | validation: 0.8380227549898532]
	TIME [epoch: 10.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4450154339757956		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.4450154339757956 | validation: 0.44689109921825704]
	TIME [epoch: 10.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.317220102392391		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.317220102392391 | validation: 0.3853422601936047]
	TIME [epoch: 10.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399958632518948		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.3399958632518948 | validation: 0.7162169016782169]
	TIME [epoch: 10.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4395403070792159		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.4395403070792159 | validation: 0.5363297185798515]
	TIME [epoch: 10.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47274527486043966		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.47274527486043966 | validation: 0.8655654759460933]
	TIME [epoch: 10.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32418341014103136		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.32418341014103136 | validation: 0.31215492651476395]
	TIME [epoch: 10.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23533308492271376		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.23533308492271376 | validation: 0.5911424326587289]
	TIME [epoch: 10.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33845358346674936		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.33845358346674936 | validation: 0.3816390786487638]
	TIME [epoch: 10.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380607905578846		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.3380607905578846 | validation: 0.9691043522672635]
	TIME [epoch: 10.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47580057077149907		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.47580057077149907 | validation: 0.1929527283458492]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20042457407580377		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.20042457407580377 | validation: 0.22159178212646197]
	TIME [epoch: 10.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20010382965788476		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.20010382965788476 | validation: 0.24549619964541108]
	TIME [epoch: 10.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882798695976252		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.1882798695976252 | validation: 0.20140067120611232]
	TIME [epoch: 10.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2203717564644873		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.2203717564644873 | validation: 0.23999412326685737]
	TIME [epoch: 10.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2213243177198177		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.2213243177198177 | validation: 0.2788065871221152]
	TIME [epoch: 10.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31320660010780277		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.31320660010780277 | validation: 0.39286541227351846]
	TIME [epoch: 10.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28354655966483544		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.28354655966483544 | validation: 0.3036315444696192]
	TIME [epoch: 10.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2467205856213494		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.2467205856213494 | validation: 0.21800371264142407]
	TIME [epoch: 10.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22520722325401418		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.22520722325401418 | validation: 0.2898433273942695]
	TIME [epoch: 10.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27813863587256327		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.27813863587256327 | validation: 0.30394540724201724]
	TIME [epoch: 10.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20567633201135185		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.20567633201135185 | validation: 0.2684739921273242]
	TIME [epoch: 10.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5423641210936795		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.5423641210936795 | validation: 0.6163058715682803]
	TIME [epoch: 10.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233437381362843		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.3233437381362843 | validation: 0.2786391921368575]
	TIME [epoch: 10.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20508843843847285		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.20508843843847285 | validation: 0.3428554140247199]
	TIME [epoch: 10.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19315846244881518		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.19315846244881518 | validation: 0.26039591985302774]
	TIME [epoch: 10.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45306066591734345		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.45306066591734345 | validation: 0.33447188948078493]
	TIME [epoch: 10.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3763842822191297		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.3763842822191297 | validation: 0.4639974910219453]
	TIME [epoch: 10.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27955904817979915		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.27955904817979915 | validation: 0.2343362698247023]
	TIME [epoch: 10.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2762868911580562		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.2762868911580562 | validation: 0.24156831596570408]
	TIME [epoch: 10.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19804854295265445		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.19804854295265445 | validation: 0.21205216081412467]
	TIME [epoch: 10.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642431732809664		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.1642431732809664 | validation: 0.40065497443721]
	TIME [epoch: 10.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19668813024730683		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.19668813024730683 | validation: 0.28114874765602743]
	TIME [epoch: 10.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2543101392975444		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.2543101392975444 | validation: 0.4007902482212276]
	TIME [epoch: 10.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24231714655276893		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.24231714655276893 | validation: 0.24672253840543357]
	TIME [epoch: 10.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19320931751719173		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.19320931751719173 | validation: 0.3806322469917336]
	TIME [epoch: 10.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17754422963408636		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.17754422963408636 | validation: 0.21771109779337877]
	TIME [epoch: 10.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27244215982459113		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.27244215982459113 | validation: 0.37216512153540865]
	TIME [epoch: 10.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21221885159504145		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.21221885159504145 | validation: 0.2772748484705879]
	TIME [epoch: 10.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2910743609212947		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.2910743609212947 | validation: 0.5322790359283739]
	TIME [epoch: 10.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31133222613977		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.31133222613977 | validation: 0.1873603386622121]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_822.pth
	Model improved!!!
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19855638978669957		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.19855638978669957 | validation: 0.2525669509952734]
	TIME [epoch: 10.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549008111177948		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.15549008111177948 | validation: 0.247607248024065]
	TIME [epoch: 10.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.257455248309017		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.257455248309017 | validation: 0.2729610098742768]
	TIME [epoch: 10.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2139947124673088		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2139947124673088 | validation: 0.2437927977890314]
	TIME [epoch: 10.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2905841994470933		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.2905841994470933 | validation: 0.3750654200944913]
	TIME [epoch: 10.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21312141989983896		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.21312141989983896 | validation: 0.2048250304085754]
	TIME [epoch: 10.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027090844941964		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.17027090844941964 | validation: 0.20434388738645642]
	TIME [epoch: 10.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15941769967627223		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.15941769967627223 | validation: 0.4648022838804154]
	TIME [epoch: 10.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19068762395319744		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.19068762395319744 | validation: 0.19124730117007688]
	TIME [epoch: 10.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788386980526767		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.15788386980526767 | validation: 0.3269543602288987]
	TIME [epoch: 10.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2030096968821758		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.2030096968821758 | validation: 0.3586689559205992]
	TIME [epoch: 10.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2184738249359887		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.2184738249359887 | validation: 0.210374132411397]
	TIME [epoch: 10.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18735632887329737		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.18735632887329737 | validation: 0.1966670521107136]
	TIME [epoch: 10.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199518044669255		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.3199518044669255 | validation: 0.9205852058585186]
	TIME [epoch: 10.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49994526411242124		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.49994526411242124 | validation: 0.3237721555196526]
	TIME [epoch: 10.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22958548182590874		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.22958548182590874 | validation: 0.295952765476044]
	TIME [epoch: 10.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20764096290555867		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.20764096290555867 | validation: 0.19014494170515572]
	TIME [epoch: 10.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2322550360324811		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.2322550360324811 | validation: 0.31090614407695677]
	TIME [epoch: 10.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20588528445185822		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.20588528445185822 | validation: 0.23256883434933287]
	TIME [epoch: 10.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15097378701189862		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.15097378701189862 | validation: 0.25858705158086415]
	TIME [epoch: 10.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16721555820273168		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.16721555820273168 | validation: 0.30264586036346625]
	TIME [epoch: 10.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381083904571506		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.2381083904571506 | validation: 0.24753624529137078]
	TIME [epoch: 10.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20288198168430577		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.20288198168430577 | validation: 0.3256277134537378]
	TIME [epoch: 10.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845694887087689		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.2845694887087689 | validation: 0.3494225866199098]
	TIME [epoch: 10.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23994311376605526		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.23994311376605526 | validation: 0.24258179344456374]
	TIME [epoch: 10.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532257877290476		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.18532257877290476 | validation: 0.6500536707973704]
	TIME [epoch: 10.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2951532454441806		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.2951532454441806 | validation: 0.31205186033725124]
	TIME [epoch: 10.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3351561971292919		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.3351561971292919 | validation: 0.32156233890946234]
	TIME [epoch: 10.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22053798141408146		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.22053798141408146 | validation: 0.48227351267245155]
	TIME [epoch: 10.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28448550516327		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.28448550516327 | validation: 0.41608015191270203]
	TIME [epoch: 10.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40587220087238923		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.40587220087238923 | validation: 0.2468598291917113]
	TIME [epoch: 10.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18408816792772906		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.18408816792772906 | validation: 0.16637659749413902]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_854.pth
	Model improved!!!
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1944721734232174		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.1944721734232174 | validation: 0.3954073226365617]
	TIME [epoch: 10.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2185046850493312		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.2185046850493312 | validation: 0.2391057656565235]
	TIME [epoch: 10.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19057728791652387		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.19057728791652387 | validation: 0.3710308832734556]
	TIME [epoch: 10.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27026090485337734		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.27026090485337734 | validation: 0.359522581422648]
	TIME [epoch: 10.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2282789962271731		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.2282789962271731 | validation: 0.44392413196665576]
	TIME [epoch: 10.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26517531918642817		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.26517531918642817 | validation: 0.3785386477002247]
	TIME [epoch: 10.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957811899471762		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.2957811899471762 | validation: 0.23196089626358032]
	TIME [epoch: 10.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20309756130907863		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.20309756130907863 | validation: 0.14761875912718483]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_862.pth
	Model improved!!!
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21483915089345618		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.21483915089345618 | validation: 0.2855218876465334]
	TIME [epoch: 10.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21769431426778726		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.21769431426778726 | validation: 0.24356274457897364]
	TIME [epoch: 10.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16814118852630458		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.16814118852630458 | validation: 0.356630955326182]
	TIME [epoch: 10.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2414214309558572		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.2414214309558572 | validation: 0.32086473704699275]
	TIME [epoch: 10.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2167835566375372		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.2167835566375372 | validation: 0.19034379212541855]
	TIME [epoch: 10.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18339726923583283		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.18339726923583283 | validation: 0.20127345639172958]
	TIME [epoch: 10.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20186956462418176		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.20186956462418176 | validation: 0.47122302865544013]
	TIME [epoch: 10.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27503608241568334		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.27503608241568334 | validation: 0.2813591049586114]
	TIME [epoch: 10.4 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2560869129480621		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.2560869129480621 | validation: 0.35711597917701154]
	TIME [epoch: 10.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2611781142743089		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.2611781142743089 | validation: 0.2861952409950668]
	TIME [epoch: 10.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2012541402158893		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.2012541402158893 | validation: 0.17762710467110288]
	TIME [epoch: 10.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18454781618885718		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.18454781618885718 | validation: 0.2171494054839692]
	TIME [epoch: 10.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17984502787694184		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.17984502787694184 | validation: 0.1559622549829482]
	TIME [epoch: 10.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1336557424441527		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.1336557424441527 | validation: 0.20154784922587143]
	TIME [epoch: 10.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12536440818674705		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.12536440818674705 | validation: 0.1946999036368924]
	TIME [epoch: 10.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21498035522377804		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.21498035522377804 | validation: 0.29146662367846293]
	TIME [epoch: 10.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19144820233279317		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.19144820233279317 | validation: 0.18712394041834116]
	TIME [epoch: 10.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19788620635740392		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.19788620635740392 | validation: 0.2563913065496917]
	TIME [epoch: 10.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22777521001139042		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.22777521001139042 | validation: 0.27718754256966016]
	TIME [epoch: 10.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2578191977671754		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.2578191977671754 | validation: 0.4153595412400094]
	TIME [epoch: 10.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25077670722062745		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.25077670722062745 | validation: 0.26004490019007764]
	TIME [epoch: 10.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21776807261235737		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.21776807261235737 | validation: 0.23057084562274427]
	TIME [epoch: 10.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24289132285780254		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.24289132285780254 | validation: 0.25560031947390754]
	TIME [epoch: 10.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24795011818267615		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.24795011818267615 | validation: 0.22698619307138956]
	TIME [epoch: 10.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19772399769031074		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.19772399769031074 | validation: 0.15372189794232288]
	TIME [epoch: 10.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17658468027823146		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.17658468027823146 | validation: 0.2109296936631373]
	TIME [epoch: 10.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15839607857342108		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.15839607857342108 | validation: 0.18459108434716243]
	TIME [epoch: 10.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19082258165952554		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.19082258165952554 | validation: 0.49662070178261225]
	TIME [epoch: 10.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24512827073508636		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.24512827073508636 | validation: 0.37771213281668015]
	TIME [epoch: 10.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2526922564158852		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.2526922564158852 | validation: 0.23708272817873471]
	TIME [epoch: 10.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721034674761804		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.1721034674761804 | validation: 0.21753152596449796]
	TIME [epoch: 10.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20834135369892565		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.20834135369892565 | validation: 0.2961274324061601]
	TIME [epoch: 10.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19479671883728492		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.19479671883728492 | validation: 0.24067387618154418]
	TIME [epoch: 10.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13641026159538244		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.13641026159538244 | validation: 0.1580134775964374]
	TIME [epoch: 10.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16346799772079507		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.16346799772079507 | validation: 0.2700847983914664]
	TIME [epoch: 10.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20877769328758117		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.20877769328758117 | validation: 0.283387254967322]
	TIME [epoch: 10.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20470156730776004		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.20470156730776004 | validation: 0.2893028997101041]
	TIME [epoch: 10.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19761334423383853		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.19761334423383853 | validation: 0.23205369480198562]
	TIME [epoch: 10.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18992154804136469		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.18992154804136469 | validation: 0.2142293501646531]
	TIME [epoch: 10.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239994245318286		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.15239994245318286 | validation: 0.2311812794976671]
	TIME [epoch: 10.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2085175297322707		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.2085175297322707 | validation: 0.370314853541517]
	TIME [epoch: 10.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21326391412664006		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.21326391412664006 | validation: 0.22807107074578994]
	TIME [epoch: 10.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14470714603262438		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.14470714603262438 | validation: 0.194984893192689]
	TIME [epoch: 10.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16446539356825676		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.16446539356825676 | validation: 0.27047649789058015]
	TIME [epoch: 10.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2286591704035572		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.2286591704035572 | validation: 0.2188482976542971]
	TIME [epoch: 10.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945939282073421		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.2945939282073421 | validation: 0.3335228445099942]
	TIME [epoch: 10.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2491975551179073		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.2491975551179073 | validation: 0.22012922246029049]
	TIME [epoch: 10.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20633866542134913		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.20633866542134913 | validation: 0.19879222781695385]
	TIME [epoch: 10.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14439526400444186		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.14439526400444186 | validation: 0.19066536004781853]
	TIME [epoch: 10.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14752347528846677		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.14752347528846677 | validation: 0.3671429331428096]
	TIME [epoch: 10.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25717938048232075		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.25717938048232075 | validation: 0.2404562665502933]
	TIME [epoch: 10.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21278449452741968		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.21278449452741968 | validation: 0.23742395740495145]
	TIME [epoch: 10.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2696854397367092		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.2696854397367092 | validation: 0.1502005443418746]
	TIME [epoch: 10.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19389131281778296		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.19389131281778296 | validation: 0.2483275321563664]
	TIME [epoch: 10.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14502278978200311		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.14502278978200311 | validation: 0.20486654823459763]
	TIME [epoch: 10.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15751424584030146		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.15751424584030146 | validation: 0.32562278312086707]
	TIME [epoch: 10.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105517323077872		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.3105517323077872 | validation: 0.4367916888542922]
	TIME [epoch: 10.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672960904688114		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.2672960904688114 | validation: 0.18227767164776404]
	TIME [epoch: 10.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805488495600777		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.1805488495600777 | validation: 0.45845032973119104]
	TIME [epoch: 10.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3468488184244458		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.3468488184244458 | validation: 0.18025665459484555]
	TIME [epoch: 10.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19534399194094237		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.19534399194094237 | validation: 0.2166112910486593]
	TIME [epoch: 10.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2519478243825216		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.2519478243825216 | validation: 0.23552363415699773]
	TIME [epoch: 10.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17360365722749982		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.17360365722749982 | validation: 0.33369350238918116]
	TIME [epoch: 10.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15673474563186168		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.15673474563186168 | validation: 0.13009870091978235]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.146411600439628		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.146411600439628 | validation: 0.1639772473898748]
	TIME [epoch: 10.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15251483849060235		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.15251483849060235 | validation: 0.20278919735240714]
	TIME [epoch: 10.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16658390368405487		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.16658390368405487 | validation: 0.20634952606014456]
	TIME [epoch: 10.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36482847645457384		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.36482847645457384 | validation: 0.355745875144219]
	TIME [epoch: 10.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2168514878421846		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.2168514878421846 | validation: 0.24743371566508113]
	TIME [epoch: 10.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2214956808096308		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.2214956808096308 | validation: 0.19669643609717355]
	TIME [epoch: 10.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18112112173806474		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.18112112173806474 | validation: 0.17134854842271435]
	TIME [epoch: 10.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16468891919906672		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.16468891919906672 | validation: 0.1781313581647928]
	TIME [epoch: 10.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872876551223243		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.1872876551223243 | validation: 0.31719504975186474]
	TIME [epoch: 10.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18622032226460045		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.18622032226460045 | validation: 0.20885438999015407]
	TIME [epoch: 10.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18104929862763333		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.18104929862763333 | validation: 0.19959614396882208]
	TIME [epoch: 10.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3979254190653633		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.3979254190653633 | validation: 0.5134579934130489]
	TIME [epoch: 10.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2181553558322844		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.2181553558322844 | validation: 0.28298183515347275]
	TIME [epoch: 10.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16496992604646604		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.16496992604646604 | validation: 0.16903950701431916]
	TIME [epoch: 10.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16311531459649997		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.16311531459649997 | validation: 0.18729647289015766]
	TIME [epoch: 10.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11121006548106897		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.11121006548106897 | validation: 0.21167795712791168]
	TIME [epoch: 10.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168621782559027		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.15168621782559027 | validation: 0.21658519635549545]
	TIME [epoch: 10.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39126723629177534		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.39126723629177534 | validation: 0.3093155314160274]
	TIME [epoch: 10.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19552907072325038		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.19552907072325038 | validation: 0.2806920019039203]
	TIME [epoch: 10.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17157252516940075		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.17157252516940075 | validation: 0.2125294637447916]
	TIME [epoch: 10.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13879374958025345		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.13879374958025345 | validation: 0.35227196206377026]
	TIME [epoch: 10.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19948001589023953		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.19948001589023953 | validation: 0.24046076289454973]
	TIME [epoch: 10.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846691468212853		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.2846691468212853 | validation: 0.36092758494277627]
	TIME [epoch: 10.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20621951335092342		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.20621951335092342 | validation: 0.27397794256987845]
	TIME [epoch: 10.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291856966075292		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.2291856966075292 | validation: 0.17953241155448388]
	TIME [epoch: 10.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18201295371019		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.18201295371019 | validation: 0.45550356429800654]
	TIME [epoch: 10.4 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28887677913406995		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.28887677913406995 | validation: 0.49453136649804974]
	TIME [epoch: 10.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2362653672735441		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.2362653672735441 | validation: 0.2741958856124832]
	TIME [epoch: 10.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.191198572574609		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.191198572574609 | validation: 0.20118280561664265]
	TIME [epoch: 10.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657437134240775		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.1657437134240775 | validation: 0.34811191396627605]
	TIME [epoch: 10.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24386755415099232		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.24386755415099232 | validation: 0.29170566699316036]
	TIME [epoch: 10.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16219880166324213		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.16219880166324213 | validation: 0.26214115830495166]
	TIME [epoch: 10.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13917006952847		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.13917006952847 | validation: 0.16196146674675554]
	TIME [epoch: 10.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14809552896694275		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.14809552896694275 | validation: 0.18446865194468892]
	TIME [epoch: 10.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21713402481168015		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.21713402481168015 | validation: 0.32915968734404777]
	TIME [epoch: 10.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18343204262825183		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.18343204262825183 | validation: 0.17419701008907054]
	TIME [epoch: 10.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.148395750675906		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.148395750675906 | validation: 0.16918286369678393]
	TIME [epoch: 10.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15866760294092494		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.15866760294092494 | validation: 0.25900591538474166]
	TIME [epoch: 10.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1795046813324267		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.1795046813324267 | validation: 0.24166957837130207]
	TIME [epoch: 10.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12705721921950253		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.12705721921950253 | validation: 0.1934380644778915]
	TIME [epoch: 10.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161851216538549		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.161851216538549 | validation: 0.17047252609496027]
	TIME [epoch: 10.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17815947599093188		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.17815947599093188 | validation: 0.25331086691247817]
	TIME [epoch: 10.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13884629641002133		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.13884629641002133 | validation: 0.2134710864025405]
	TIME [epoch: 10.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1701124019447025		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.1701124019447025 | validation: 0.3185761357529228]
	TIME [epoch: 10.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18992899451421308		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.18992899451421308 | validation: 0.11563640240370973]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_971.pth
	Model improved!!!
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12222642456562811		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.12222642456562811 | validation: 0.1907691443467648]
	TIME [epoch: 10.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1352608679232711		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.1352608679232711 | validation: 0.16798151688679638]
	TIME [epoch: 10.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15115416459863548		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.15115416459863548 | validation: 0.15173538330202435]
	TIME [epoch: 10.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12366084495679996		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.12366084495679996 | validation: 0.19094834487603676]
	TIME [epoch: 10.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19002920794225822		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.19002920794225822 | validation: 0.2582056593752596]
	TIME [epoch: 10.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19026569775569663		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.19026569775569663 | validation: 0.23525990988638104]
	TIME [epoch: 10.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2001399976375345		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2001399976375345 | validation: 0.26260402488511936]
	TIME [epoch: 10.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366337245670384		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.2366337245670384 | validation: 0.22524274222767787]
	TIME [epoch: 10.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15210181529489736		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.15210181529489736 | validation: 0.22356781757294564]
	TIME [epoch: 10.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12660321645428058		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.12660321645428058 | validation: 0.2881337210656249]
	TIME [epoch: 10.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19806150324522648		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.19806150324522648 | validation: 0.12447622597124931]
	TIME [epoch: 10.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12536504569252757		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.12536504569252757 | validation: 0.2616746278095136]
	TIME [epoch: 10.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14704857770054913		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.14704857770054913 | validation: 0.15733956083543663]
	TIME [epoch: 10.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10831227441775573		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.10831227441775573 | validation: 0.10785819785806869]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_985.pth
	Model improved!!!
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10551869687617055		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.10551869687617055 | validation: 0.22741418553347292]
	TIME [epoch: 10.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13155907167347136		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.13155907167347136 | validation: 0.1593094718386716]
	TIME [epoch: 10.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21804488316725132		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.21804488316725132 | validation: 0.18221699693580562]
	TIME [epoch: 10.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609630628676432		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.1609630628676432 | validation: 0.1691236423777149]
	TIME [epoch: 10.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17223821957849977		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.17223821957849977 | validation: 0.2756342730815425]
	TIME [epoch: 10.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16185651981065247		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.16185651981065247 | validation: 0.16681310303546468]
	TIME [epoch: 10.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13647638947972643		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.13647638947972643 | validation: 0.11614403876408892]
	TIME [epoch: 10.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14290084404041142		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.14290084404041142 | validation: 0.22287061545502782]
	TIME [epoch: 10.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1714732977271842		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.1714732977271842 | validation: 0.18445518953114184]
	TIME [epoch: 10.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14661336180598203		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.14661336180598203 | validation: 0.1468587745815721]
	TIME [epoch: 10.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17960161001650893		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.17960161001650893 | validation: 0.1857785888764299]
	TIME [epoch: 10.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15161623277635794		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.15161623277635794 | validation: 0.20488885137276172]
	TIME [epoch: 10.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16820126269548516		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.16820126269548516 | validation: 0.1880498235356442]
	TIME [epoch: 10.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14428040452694896		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.14428040452694896 | validation: 0.18068851971928723]
	TIME [epoch: 10.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19309164692495545		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.19309164692495545 | validation: 0.23058664900199044]
	TIME [epoch: 10.4 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16730345042497957		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.16730345042497957 | validation: 0.14775855841110805]
	TIME [epoch: 10.4 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14771829977285417		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.14771829977285417 | validation: 0.19205104115619465]
	TIME [epoch: 10.4 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612066681428878		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.1612066681428878 | validation: 0.29091933423846433]
	TIME [epoch: 10.4 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22445938612041522		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.22445938612041522 | validation: 0.18221713397194025]
	TIME [epoch: 10.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23460373836175313		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.23460373836175313 | validation: 0.2646025317218888]
	TIME [epoch: 10.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20303474982239017		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.20303474982239017 | validation: 0.2006059723897748]
	TIME [epoch: 10.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21370655250210832		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.21370655250210832 | validation: 0.15034522403383552]
	TIME [epoch: 10.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696136718025505		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.1696136718025505 | validation: 0.2465725841412804]
	TIME [epoch: 10.4 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18103646549017313		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.18103646549017313 | validation: 0.17325032855660083]
	TIME [epoch: 10.4 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1386240688357107		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.1386240688357107 | validation: 0.13478974084633497]
	TIME [epoch: 10.4 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16925920257113614		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.16925920257113614 | validation: 0.1844554735090249]
	TIME [epoch: 10.4 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13910384035474696		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.13910384035474696 | validation: 0.17215515738459863]
	TIME [epoch: 10.4 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16148198468773511		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.16148198468773511 | validation: 0.22668950004660965]
	TIME [epoch: 10.4 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18575032168676514		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.18575032168676514 | validation: 0.20682825477908967]
	TIME [epoch: 10.4 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16198694875319175		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.16198694875319175 | validation: 0.22998691595158594]
	TIME [epoch: 10.4 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13484813601396886		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.13484813601396886 | validation: 0.17091820021274878]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637239353098056		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.1637239353098056 | validation: 0.17908731107844447]
	TIME [epoch: 10.4 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18848332701076562		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.18848332701076562 | validation: 0.17588805768586163]
	TIME [epoch: 10.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15500135726043293		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.15500135726043293 | validation: 0.20606874746904325]
	TIME [epoch: 10.4 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16715867510561364		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.16715867510561364 | validation: 0.17452734947820914]
	TIME [epoch: 10.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11841251472755947		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.11841251472755947 | validation: 0.18464314065367363]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20628401514005112		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.20628401514005112 | validation: 0.3257786743633946]
	TIME [epoch: 10.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626002959711123		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.2626002959711123 | validation: 0.26134095804530344]
	TIME [epoch: 10.4 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205141048053187		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.205141048053187 | validation: 0.20848420027075854]
	TIME [epoch: 10.4 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13663674311783716		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.13663674311783716 | validation: 0.23678108537034767]
	TIME [epoch: 10.4 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184518352682084		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.184518352682084 | validation: 0.16037871950914412]
	TIME [epoch: 10.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14420486970375984		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.14420486970375984 | validation: 0.22463373391734714]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520337916923515		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.1520337916923515 | validation: 0.2520946643856602]
	TIME [epoch: 10.4 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17241044131415087		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.17241044131415087 | validation: 0.2003803872036003]
	TIME [epoch: 10.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17001437875345465		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.17001437875345465 | validation: 0.1944675826617834]
	TIME [epoch: 10.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15859931334233063		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.15859931334233063 | validation: 0.18102320829232108]
	TIME [epoch: 10.4 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2305038957820739		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.2305038957820739 | validation: 0.20644766045328922]
	TIME [epoch: 10.4 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18965416218417083		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.18965416218417083 | validation: 0.21213019127424557]
	TIME [epoch: 10.4 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17168950428570198		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.17168950428570198 | validation: 0.15027835155941305]
	TIME [epoch: 10.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14331793216696198		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.14331793216696198 | validation: 0.18007181472896683]
	TIME [epoch: 10.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1902636261710668		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.1902636261710668 | validation: 0.37670363022299025]
	TIME [epoch: 10.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26369404188505285		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.26369404188505285 | validation: 0.2218295902162256]
	TIME [epoch: 10.4 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19939583750442036		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.19939583750442036 | validation: 0.30370032206769376]
	TIME [epoch: 10.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18668822530308554		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.18668822530308554 | validation: 0.32777567525704243]
	TIME [epoch: 10.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22618803317587594		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.22618803317587594 | validation: 0.19680495012987473]
	TIME [epoch: 10.4 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1798169950757338		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.1798169950757338 | validation: 0.32396179264041025]
	TIME [epoch: 10.4 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.252807367274912		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.252807367274912 | validation: 0.22255263988609741]
	TIME [epoch: 10.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1821502772684135		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.1821502772684135 | validation: 0.1694370193062272]
	TIME [epoch: 10.4 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17437088768588693		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.17437088768588693 | validation: 0.3118194707361285]
	TIME [epoch: 10.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18250329668997375		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.18250329668997375 | validation: 0.3138558182460662]
	TIME [epoch: 10.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19187950984137758		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.19187950984137758 | validation: 0.3002413340484332]
	TIME [epoch: 10.4 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21210435824184365		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.21210435824184365 | validation: 0.1433836689432084]
	TIME [epoch: 10.4 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657417079321631		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.1657417079321631 | validation: 0.14370544152154371]
	TIME [epoch: 10.4 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11178881631926052		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.11178881631926052 | validation: 0.1158112287421731]
	TIME [epoch: 10.4 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10896511670913386		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.10896511670913386 | validation: 0.155253441018431]
	TIME [epoch: 10.4 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12862519184253127		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.12862519184253127 | validation: 0.24862222441994913]
	TIME [epoch: 10.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15039522184271809		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.15039522184271809 | validation: 0.1297786433974032]
	TIME [epoch: 10.4 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11733790468738851		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.11733790468738851 | validation: 0.31875434387124446]
	TIME [epoch: 10.4 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19070325400863028		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.19070325400863028 | validation: 0.1959941884129238]
	TIME [epoch: 10.4 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1839027879088428		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.1839027879088428 | validation: 0.12338070545275207]
	TIME [epoch: 10.4 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11800508997035244		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.11800508997035244 | validation: 0.2401259737511807]
	TIME [epoch: 10.4 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583315079380628		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.1583315079380628 | validation: 0.21097569509509384]
	TIME [epoch: 10.4 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16777487860224113		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.16777487860224113 | validation: 0.18380961906665352]
	TIME [epoch: 10.4 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13074416384132118		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.13074416384132118 | validation: 0.18871235248209772]
	TIME [epoch: 10.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11143006301949361		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.11143006301949361 | validation: 0.14910489955536668]
	TIME [epoch: 10.4 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11813075866973088		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.11813075866973088 | validation: 0.2258081588990256]
	TIME [epoch: 10.4 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11118788946777938		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.11118788946777938 | validation: 0.10965338133251479]
	TIME [epoch: 10.4 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09981897759308649		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.09981897759308649 | validation: 0.12956251532575777]
	TIME [epoch: 10.4 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09344933737868286		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.09344933737868286 | validation: 0.13468208038995716]
	TIME [epoch: 10.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11726196515396654		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.11726196515396654 | validation: 0.09375667982849625]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1065.pth
	Model improved!!!
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10006069107638649		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.10006069107638649 | validation: 0.13124356482467625]
	TIME [epoch: 10.4 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11485132538707869		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.11485132538707869 | validation: 0.25309770846211893]
	TIME [epoch: 10.4 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12026238001527623		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.12026238001527623 | validation: 0.12891582715679323]
	TIME [epoch: 10.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14512245040385321		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.14512245040385321 | validation: 0.24856062308731605]
	TIME [epoch: 10.4 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614202667712107		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.1614202667712107 | validation: 0.1813275380444417]
	TIME [epoch: 10.4 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16539653373816385		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.16539653373816385 | validation: 0.16442392505410838]
	TIME [epoch: 10.4 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11163427101355128		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.11163427101355128 | validation: 0.1759908182237761]
	TIME [epoch: 10.4 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1195659959818756		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.1195659959818756 | validation: 0.2290110185321788]
	TIME [epoch: 10.4 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11232250195210096		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.11232250195210096 | validation: 0.25905897425113894]
	TIME [epoch: 10.4 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16526660293229073		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.16526660293229073 | validation: 0.23310813896522534]
	TIME [epoch: 10.4 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12400877439664511		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.12400877439664511 | validation: 0.1662379191841921]
	TIME [epoch: 10.4 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16060554247480324		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.16060554247480324 | validation: 0.19735295567984446]
	TIME [epoch: 10.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16909145703331782		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.16909145703331782 | validation: 0.22270075050280963]
	TIME [epoch: 10.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1946171496784818		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.1946171496784818 | validation: 0.17033994573525568]
	TIME [epoch: 10.4 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15887673122876894		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.15887673122876894 | validation: 0.2452024067857635]
	TIME [epoch: 10.4 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12902842897592323		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.12902842897592323 | validation: 0.15495964553430067]
	TIME [epoch: 10.4 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13684229081788513		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.13684229081788513 | validation: 0.18026701815617813]
	TIME [epoch: 10.4 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457101220745747		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.1457101220745747 | validation: 0.23083009341154445]
	TIME [epoch: 10.4 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11546240491678776		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.11546240491678776 | validation: 0.19024568064564168]
	TIME [epoch: 10.4 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12230131835476535		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.12230131835476535 | validation: 0.15903517754826613]
	TIME [epoch: 10.4 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14875199920274876		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.14875199920274876 | validation: 0.4033995029159105]
	TIME [epoch: 10.4 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651087444641743		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.2651087444641743 | validation: 0.567312750416158]
	TIME [epoch: 10.4 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29507191499789154		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.29507191499789154 | validation: 0.4506294861139914]
	TIME [epoch: 10.4 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21429183059808285		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.21429183059808285 | validation: 0.2635875106931258]
	TIME [epoch: 10.4 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14859839604822303		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.14859839604822303 | validation: 0.22863627918629156]
	TIME [epoch: 10.4 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12004726026101364		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.12004726026101364 | validation: 0.16085422448451234]
	TIME [epoch: 10.4 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18985086085031283		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.18985086085031283 | validation: 0.16569604519335523]
	TIME [epoch: 10.4 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1096015579348271		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.1096015579348271 | validation: 0.19659285254693132]
	TIME [epoch: 10.4 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10890109825877943		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.10890109825877943 | validation: 0.1696516516414939]
	TIME [epoch: 10.4 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13136535932259535		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.13136535932259535 | validation: 0.29636700960413676]
	TIME [epoch: 10.4 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2387519154877203		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.2387519154877203 | validation: 0.19332842754564594]
	TIME [epoch: 10.4 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1339740722940413		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.1339740722940413 | validation: 0.24539405694186692]
	TIME [epoch: 10.4 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13460616209987242		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.13460616209987242 | validation: 0.16008647482951205]
	TIME [epoch: 10.4 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1567838396231712		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.1567838396231712 | validation: 0.16174302939616655]
	TIME [epoch: 10.4 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18930784727823874		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.18930784727823874 | validation: 0.535756572802572]
	TIME [epoch: 10.4 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502309974642146		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.2502309974642146 | validation: 0.28315828346459543]
	TIME [epoch: 10.4 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16639210344575522		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.16639210344575522 | validation: 0.24633319522034675]
	TIME [epoch: 10.4 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20012692535027474		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.20012692535027474 | validation: 0.14689842119725413]
	TIME [epoch: 10.4 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13327596355049523		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.13327596355049523 | validation: 0.17873633321960364]
	TIME [epoch: 10.4 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10859466458574903		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.10859466458574903 | validation: 0.1886717966343897]
	TIME [epoch: 10.4 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20234739552475012		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.20234739552475012 | validation: 0.20502186771740433]
	TIME [epoch: 10.4 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11585623104369443		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.11585623104369443 | validation: 0.13967891233645582]
	TIME [epoch: 10.4 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0887429678363459		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.0887429678363459 | validation: 0.31064462494064926]
	TIME [epoch: 10.4 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1327436273181523		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.1327436273181523 | validation: 0.221990995054937]
	TIME [epoch: 10.4 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518188425653098		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.1518188425653098 | validation: 0.1595154352362097]
	TIME [epoch: 10.4 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10797993752105102		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.10797993752105102 | validation: 0.1335607515575577]
	TIME [epoch: 10.4 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11919352269184487		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.11919352269184487 | validation: 0.19422052367861284]
	TIME [epoch: 10.4 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15226606949813404		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.15226606949813404 | validation: 0.1917796388119359]
	TIME [epoch: 10.4 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10440600251095962		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.10440600251095962 | validation: 0.17476477304911128]
	TIME [epoch: 10.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14666368541508923		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.14666368541508923 | validation: 0.14526989007270627]
	TIME [epoch: 10.4 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09346679017113498		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.09346679017113498 | validation: 0.1902462210815932]
	TIME [epoch: 10.4 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13317791892283587		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.13317791892283587 | validation: 0.17493946574746158]
	TIME [epoch: 10.4 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10133707651901269		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.10133707651901269 | validation: 0.22385853699607086]
	TIME [epoch: 10.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1174094758158464		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.1174094758158464 | validation: 0.1648626457690996]
	TIME [epoch: 10.4 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11264744801651902		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.11264744801651902 | validation: 0.152980144626823]
	TIME [epoch: 10.4 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14398598659659662		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.14398598659659662 | validation: 0.17091411527001577]
	TIME [epoch: 10.4 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10968544690881869		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.10968544690881869 | validation: 0.1580338584514952]
	TIME [epoch: 10.4 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1245945645470427		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.1245945645470427 | validation: 0.12172199897400125]
	TIME [epoch: 10.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11172411872930685		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.11172411872930685 | validation: 0.1780777072936772]
	TIME [epoch: 10.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10246338291272528		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.10246338291272528 | validation: 0.2253767961519897]
	TIME [epoch: 10.4 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12961851055959367		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.12961851055959367 | validation: 0.152714293838575]
	TIME [epoch: 10.4 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09550994240265995		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.09550994240265995 | validation: 0.26436238073579893]
	TIME [epoch: 10.4 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147290728663562		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.147290728663562 | validation: 0.2176622503137832]
	TIME [epoch: 10.4 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15459705663855589		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.15459705663855589 | validation: 0.21525513028997878]
	TIME [epoch: 10.4 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12115082457441759		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.12115082457441759 | validation: 0.2142515242949987]
	TIME [epoch: 10.4 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14244689635592145		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.14244689635592145 | validation: 0.3653581666596154]
	TIME [epoch: 10.4 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518834541568948		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.1518834541568948 | validation: 0.14637684445548785]
	TIME [epoch: 10.4 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16811438826739686		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.16811438826739686 | validation: 0.4471036081613532]
	TIME [epoch: 10.4 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2882753439586415		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.2882753439586415 | validation: 0.23648597195077373]
	TIME [epoch: 10.4 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21984665826914815		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.21984665826914815 | validation: 0.30575237916535775]
	TIME [epoch: 10.4 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17129962735217844		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.17129962735217844 | validation: 0.28095013052088186]
	TIME [epoch: 10.4 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1928361229102557		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.1928361229102557 | validation: 0.19347304269734292]
	TIME [epoch: 10.4 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1250932572344292		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.1250932572344292 | validation: 0.21374794494425453]
	TIME [epoch: 10.4 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09345455313410041		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.09345455313410041 | validation: 0.12695785139645854]
	TIME [epoch: 10.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08626510488036924		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.08626510488036924 | validation: 0.16270018742720396]
	TIME [epoch: 10.4 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1101872303211943		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.1101872303211943 | validation: 0.11307332816927174]
	TIME [epoch: 10.4 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07362644289257728		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.07362644289257728 | validation: 0.12980162211945173]
	TIME [epoch: 10.4 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09336972736029685		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.09336972736029685 | validation: 0.14387916121155686]
	TIME [epoch: 10.4 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11170807324194905		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.11170807324194905 | validation: 0.16367325504705946]
	TIME [epoch: 10.4 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580245706006567		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.09580245706006567 | validation: 0.1807603967598552]
	TIME [epoch: 10.4 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12939742199961596		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.12939742199961596 | validation: 0.1677819536701334]
	TIME [epoch: 10.4 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12180485692835293		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.12180485692835293 | validation: 0.13293958633653247]
	TIME [epoch: 10.4 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780166730617087		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.08780166730617087 | validation: 0.15702873284559968]
	TIME [epoch: 10.4 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12056142554334418		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.12056142554334418 | validation: 0.1613041347840335]
	TIME [epoch: 10.4 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.136857883859355		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.136857883859355 | validation: 0.2197358278915636]
	TIME [epoch: 10.4 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11238200276358304		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.11238200276358304 | validation: 0.25102340416955526]
	TIME [epoch: 10.4 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1315988813544216		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.1315988813544216 | validation: 0.18403725877204338]
	TIME [epoch: 10.4 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12453789551562769		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.12453789551562769 | validation: 0.140203429408228]
	TIME [epoch: 10.4 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1398715382346644		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.1398715382346644 | validation: 0.2797342333021786]
	TIME [epoch: 10.4 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18194059269377896		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.18194059269377896 | validation: 0.19833178056915998]
	TIME [epoch: 10.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11813455188497238		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.11813455188497238 | validation: 0.18018342384486158]
	TIME [epoch: 10.4 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13834741613746054		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.13834741613746054 | validation: 0.1795564467062566]
	TIME [epoch: 10.4 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599339714231721		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.08599339714231721 | validation: 0.21265056719472605]
	TIME [epoch: 10.4 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09399083026400885		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.09399083026400885 | validation: 0.1355680580429625]
	TIME [epoch: 10.4 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09961290678571201		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.09961290678571201 | validation: 0.09036786340708015]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1160.pth
	Model improved!!!
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910637910109166		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.0910637910109166 | validation: 0.11282313537050218]
	TIME [epoch: 10.4 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09116317088366925		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.09116317088366925 | validation: 0.12349814751271104]
	TIME [epoch: 10.4 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10126063705852437		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.10126063705852437 | validation: 0.13819851832734842]
	TIME [epoch: 10.4 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11871687584695116		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.11871687584695116 | validation: 0.17489826495369282]
	TIME [epoch: 10.4 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10512156052515038		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.10512156052515038 | validation: 0.12161705853307708]
	TIME [epoch: 10.4 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08502102953816335		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.08502102953816335 | validation: 0.13727763177878663]
	TIME [epoch: 10.4 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11952320243286459		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.11952320243286459 | validation: 0.16277920938440396]
	TIME [epoch: 10.4 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12588162671778985		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.12588162671778985 | validation: 0.1335888536040349]
	TIME [epoch: 10.4 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11569556644358259		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.11569556644358259 | validation: 0.13100858912836752]
	TIME [epoch: 10.4 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09463098884163824		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.09463098884163824 | validation: 0.19165744011760388]
	TIME [epoch: 10.4 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07074579646995988		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.07074579646995988 | validation: 0.2115808772340334]
	TIME [epoch: 10.4 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11993571952551152		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.11993571952551152 | validation: 0.2807022645660022]
	TIME [epoch: 10.4 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34185598426053987		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.34185598426053987 | validation: 0.22730955013981796]
	TIME [epoch: 10.4 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18957622808741836		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.18957622808741836 | validation: 0.20377706961373146]
	TIME [epoch: 10.4 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17476469557182955		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.17476469557182955 | validation: 0.3705318853681302]
	TIME [epoch: 10.4 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15440406737088228		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.15440406737088228 | validation: 0.15556815575995372]
	TIME [epoch: 10.4 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11609346853505782		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.11609346853505782 | validation: 0.1665300813305467]
	TIME [epoch: 10.4 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11448644927864655		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.11448644927864655 | validation: 0.18793803419101565]
	TIME [epoch: 10.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08506417485202271		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.08506417485202271 | validation: 0.11814443736634221]
	TIME [epoch: 10.4 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09127387378914018		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.09127387378914018 | validation: 0.2409759093507288]
	TIME [epoch: 10.4 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11447848884399478		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.11447848884399478 | validation: 0.16077663164605263]
	TIME [epoch: 10.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08895962050878198		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.08895962050878198 | validation: 0.13089288787621545]
	TIME [epoch: 10.4 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831208127275866		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.09831208127275866 | validation: 0.2706699857435648]
	TIME [epoch: 10.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14750017289747533		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.14750017289747533 | validation: 0.1863933618749851]
	TIME [epoch: 10.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11058292770188365		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.11058292770188365 | validation: 0.14817438545913342]
	TIME [epoch: 10.4 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11767173757511888		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.11767173757511888 | validation: 0.12893253211321734]
	TIME [epoch: 10.4 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23335504508026944		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.23335504508026944 | validation: 0.16896763217804125]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11053278487051647		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.11053278487051647 | validation: 0.12016037984447728]
	TIME [epoch: 10.4 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935626810348998		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.0935626810348998 | validation: 0.13826907407364528]
	TIME [epoch: 10.4 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09757292645380929		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.09757292645380929 | validation: 0.11003051702297263]
	TIME [epoch: 10.4 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0998457901188555		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.0998457901188555 | validation: 0.18037335963100484]
	TIME [epoch: 10.4 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14288074499990483		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.14288074499990483 | validation: 0.16729787123412698]
	TIME [epoch: 10.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14121605164860512		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.14121605164860512 | validation: 0.18518183094624782]
	TIME [epoch: 10.4 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11153839014816883		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.11153839014816883 | validation: 0.11513507077343484]
	TIME [epoch: 10.4 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144411988162946		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.1144411988162946 | validation: 0.2972570468482531]
	TIME [epoch: 10.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18250326487044158		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.18250326487044158 | validation: 0.1731235678339388]
	TIME [epoch: 10.4 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11846428699938383		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.11846428699938383 | validation: 0.22734727110566205]
	TIME [epoch: 10.4 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17188680146308338		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.17188680146308338 | validation: 0.2204985817260742]
	TIME [epoch: 10.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14787133652401022		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.14787133652401022 | validation: 0.14958049655250366]
	TIME [epoch: 10.4 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08933199369001969		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.08933199369001969 | validation: 0.14546813875415968]
	TIME [epoch: 10.4 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08512022414696048		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.08512022414696048 | validation: 0.15341568952372966]
	TIME [epoch: 10.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08957665964416997		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.08957665964416997 | validation: 0.11214403192918823]
	TIME [epoch: 10.4 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07752584297184847		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.07752584297184847 | validation: 0.12454828320016688]
	TIME [epoch: 10.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09383101032558112		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.09383101032558112 | validation: 0.14380223889146312]
	TIME [epoch: 10.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08465194549646675		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.08465194549646675 | validation: 0.1225711448933905]
	TIME [epoch: 10.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10378396973730626		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.10378396973730626 | validation: 0.12092852643141232]
	TIME [epoch: 10.4 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08012193556382345		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.08012193556382345 | validation: 0.1401131141858539]
	TIME [epoch: 10.4 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12236346632308662		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.12236346632308662 | validation: 0.19130589330490685]
	TIME [epoch: 10.4 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12312690986365946		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.12312690986365946 | validation: 0.18559230751969807]
	TIME [epoch: 10.4 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12579158501030868		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.12579158501030868 | validation: 0.15355434032726897]
	TIME [epoch: 10.4 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342059355205322		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.1342059355205322 | validation: 0.30187487920275735]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837182873982402		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.1837182873982402 | validation: 0.25210943997734964]
	TIME [epoch: 10.4 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14238325861763096		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.14238325861763096 | validation: 0.13888541122130302]
	TIME [epoch: 10.4 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12027365396388923		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.12027365396388923 | validation: 0.11177707236899088]
	TIME [epoch: 10.4 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09783910789575949		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.09783910789575949 | validation: 0.14590622446086132]
	TIME [epoch: 10.4 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11466580261443737		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.11466580261443737 | validation: 0.17700777447010269]
	TIME [epoch: 10.4 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11486188366662811		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.11486188366662811 | validation: 0.15264010583648557]
	TIME [epoch: 10.4 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11174031579567727		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.11174031579567727 | validation: 0.14393183348061286]
	TIME [epoch: 10.4 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10430999595265486		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.10430999595265486 | validation: 0.1343051050030498]
	TIME [epoch: 10.4 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144552821297585		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.1144552821297585 | validation: 0.24666662890764468]
	TIME [epoch: 10.4 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15226487325004223		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.15226487325004223 | validation: 0.20623557126642642]
	TIME [epoch: 10.4 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1394712930475101		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.1394712930475101 | validation: 0.21860008552118218]
	TIME [epoch: 10.4 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953663556150072		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.1953663556150072 | validation: 0.15650639705932523]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10503687061738262		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.10503687061738262 | validation: 0.24342809718277983]
	TIME [epoch: 10.4 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2254165082678239		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.2254165082678239 | validation: 0.18094809784945606]
	TIME [epoch: 10.4 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11894859439075278		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.11894859439075278 | validation: 0.20157061949642155]
	TIME [epoch: 10.4 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1080366457111801		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.1080366457111801 | validation: 0.12667719365837254]
	TIME [epoch: 10.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09847345373658091		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.09847345373658091 | validation: 0.13652962681200845]
	TIME [epoch: 10.4 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1362348521134961		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.1362348521134961 | validation: 0.12414446564477633]
	TIME [epoch: 10.4 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074072212666366		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.1074072212666366 | validation: 0.11485802785759551]
	TIME [epoch: 10.4 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11735138212083154		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.11735138212083154 | validation: 0.1295596276323177]
	TIME [epoch: 10.4 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08600906132757603		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.08600906132757603 | validation: 0.09342256651397415]
	TIME [epoch: 10.4 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09378744278999777		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.09378744278999777 | validation: 0.1177561825819652]
	TIME [epoch: 10.4 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10443850599490374		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.10443850599490374 | validation: 0.12508101189010248]
	TIME [epoch: 10.4 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07668006886443132		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.07668006886443132 | validation: 0.15659472134021388]
	TIME [epoch: 10.4 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1207435327841467		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.1207435327841467 | validation: 0.12577330444086346]
	TIME [epoch: 10.4 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09528600784322186		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.09528600784322186 | validation: 0.10156278678808066]
	TIME [epoch: 10.4 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07016316961887498		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.07016316961887498 | validation: 0.11173683353905851]
	TIME [epoch: 10.4 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11997911096845297		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.11997911096845297 | validation: 0.13869252791086417]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09927778104418512		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.09927778104418512 | validation: 0.10974985943305128]
	TIME [epoch: 10.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09995761764910008		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.09995761764910008 | validation: 0.10798624105373762]
	TIME [epoch: 10.4 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384035871637488		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.08384035871637488 | validation: 0.08781224153043729]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1242.pth
	Model improved!!!
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0994577039991411		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.0994577039991411 | validation: 0.12130728736029006]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11431877747903166		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.11431877747903166 | validation: 0.18797554942495034]
	TIME [epoch: 10.4 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11771036691853173		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.11771036691853173 | validation: 0.19279621700776572]
	TIME [epoch: 10.4 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14263950200837547		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.14263950200837547 | validation: 0.1770330182017303]
	TIME [epoch: 10.4 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09061307362612267		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.09061307362612267 | validation: 0.11444126913425003]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0849375498596906		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.0849375498596906 | validation: 0.13165381620180344]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09587338857592391		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.09587338857592391 | validation: 0.11715825247010363]
	TIME [epoch: 10.4 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08581916002801504		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.08581916002801504 | validation: 0.0864854202059661]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1250.pth
	Model improved!!!
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07472037465537609		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.07472037465537609 | validation: 0.10033412901746344]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932926765698809		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.08932926765698809 | validation: 0.1355409058662659]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09644208083096234		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.09644208083096234 | validation: 0.09632894103368188]
	TIME [epoch: 10.4 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10190278589149589		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.10190278589149589 | validation: 0.11122753537185359]
	TIME [epoch: 10.4 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07595771264826214		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.07595771264826214 | validation: 0.21124692113364787]
	TIME [epoch: 10.4 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09817010221124639		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.09817010221124639 | validation: 0.1375733623497625]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08789617803401456		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.08789617803401456 | validation: 0.18215027770479922]
	TIME [epoch: 10.4 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10002355156231571		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.10002355156231571 | validation: 0.11599498115491899]
	TIME [epoch: 10.4 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10168509629807054		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.10168509629807054 | validation: 0.09889204337075352]
	TIME [epoch: 10.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09065017227797903		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.09065017227797903 | validation: 0.18458593592576925]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14205659813547378		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.14205659813547378 | validation: 0.1368700190249044]
	TIME [epoch: 10.4 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08546176925305209		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.08546176925305209 | validation: 0.1017224592382955]
	TIME [epoch: 10.4 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06996448009389891		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.06996448009389891 | validation: 0.1347882719729472]
	TIME [epoch: 10.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0969896714513982		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.0969896714513982 | validation: 0.07690105902507341]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1264.pth
	Model improved!!!
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607747400373775		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.08607747400373775 | validation: 0.09395413578709264]
	TIME [epoch: 10.4 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08913030678372481		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.08913030678372481 | validation: 0.12346162900681121]
	TIME [epoch: 10.4 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11411964137579111		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.11411964137579111 | validation: 0.14744423529468326]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09273370869501284		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.09273370869501284 | validation: 0.08664878447010853]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06598544565175388		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.06598544565175388 | validation: 0.13409720397695957]
	TIME [epoch: 10.4 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08068896762078664		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.08068896762078664 | validation: 0.10598512834836842]
	TIME [epoch: 10.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09946142889733663		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.09946142889733663 | validation: 0.09654764065336031]
	TIME [epoch: 10.4 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10117153916945323		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.10117153916945323 | validation: 0.10514086553386222]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07632040019656976		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.07632040019656976 | validation: 0.07087377656932012]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1273.pth
	Model improved!!!
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08003404519074625		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.08003404519074625 | validation: 0.13406864868643925]
	TIME [epoch: 10.4 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08855814435753656		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.08855814435753656 | validation: 0.11320283327001883]
	TIME [epoch: 10.4 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07656229476140455		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.07656229476140455 | validation: 0.07680548448400912]
	TIME [epoch: 10.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07302126195721147		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.07302126195721147 | validation: 0.12747718055771562]
	TIME [epoch: 10.4 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09234228125743071		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.09234228125743071 | validation: 0.12694982776557]
	TIME [epoch: 10.4 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09961667859474861		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.09961667859474861 | validation: 0.14708208485928945]
	TIME [epoch: 10.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285190096258222		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.15285190096258222 | validation: 0.11973189214685594]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.087315932389316		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.087315932389316 | validation: 0.2194414218619626]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12530377483174432		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.12530377483174432 | validation: 0.16762140101627815]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12271186724589507		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.12271186724589507 | validation: 0.15753372349933914]
	TIME [epoch: 10.3 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09712217043657255		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.09712217043657255 | validation: 0.11676301531377044]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08975297204146342		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.08975297204146342 | validation: 0.12226475892137209]
	TIME [epoch: 10.4 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.080683234952081		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.080683234952081 | validation: 0.1279908462787502]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11379384480112678		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.11379384480112678 | validation: 0.1382657338885966]
	TIME [epoch: 10.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07953062598459983		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.07953062598459983 | validation: 0.06312918489561006]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1288.pth
	Model improved!!!
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07566282005157059		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.07566282005157059 | validation: 0.09221096725397274]
	TIME [epoch: 10.4 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07092406295364935		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.07092406295364935 | validation: 0.07438659781856669]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09389883550680808		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.09389883550680808 | validation: 0.16921216751280244]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09462045037179694		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.09462045037179694 | validation: 0.09376761944411759]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07549472195929009		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.07549472195929009 | validation: 0.12616972114724248]
	TIME [epoch: 10.4 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07433340180630395		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.07433340180630395 | validation: 0.16304751067639336]
	TIME [epoch: 10.4 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09877980170405727		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.09877980170405727 | validation: 0.11530229701701047]
	TIME [epoch: 10.3 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09462627495126634		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.09462627495126634 | validation: 0.10860952322584883]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06518862239359272		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.06518862239359272 | validation: 0.11514527098357621]
	TIME [epoch: 10.4 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0715691042704408		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.0715691042704408 | validation: 0.08721854775973363]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06501614641275681		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.06501614641275681 | validation: 0.07536554404952912]
	TIME [epoch: 10.4 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05876527623916672		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.05876527623916672 | validation: 0.10467309410656174]
	TIME [epoch: 10.4 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0808223939418107		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.0808223939418107 | validation: 0.26821958829321524]
	TIME [epoch: 10.4 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291731926378809		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.2291731926378809 | validation: 0.24408554080505632]
	TIME [epoch: 10.4 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11328018208751581		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.11328018208751581 | validation: 0.11674642532125104]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08316629624950413		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.08316629624950413 | validation: 0.09486592957761214]
	TIME [epoch: 10.4 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06204637505371241		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.06204637505371241 | validation: 0.12196658080387315]
	TIME [epoch: 10.4 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07505235696453941		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.07505235696453941 | validation: 0.12551143891784905]
	TIME [epoch: 10.4 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07908568244932841		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.07908568244932841 | validation: 0.2316670428529507]
	TIME [epoch: 10.4 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13265748462384347		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.13265748462384347 | validation: 0.10018559003462524]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10211155701113765		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.10211155701113765 | validation: 0.11419446462247165]
	TIME [epoch: 10.4 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413536569621364		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.09413536569621364 | validation: 0.1563457746534914]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11358250063233546		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.11358250063233546 | validation: 0.0961497728886582]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07690167553536491		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.07690167553536491 | validation: 0.12485690840007227]
	TIME [epoch: 10.4 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06401904273711641		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.06401904273711641 | validation: 0.08142069581911768]
	TIME [epoch: 10.4 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08522717588506985		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.08522717588506985 | validation: 0.14502165978508533]
	TIME [epoch: 10.3 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09788592403079051		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.09788592403079051 | validation: 0.10838189472726827]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08248435381047234		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.08248435381047234 | validation: 0.1431298197752322]
	TIME [epoch: 10.4 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0715078947054443		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.0715078947054443 | validation: 0.14315471126610932]
	TIME [epoch: 10.4 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08649599376561978		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.08649599376561978 | validation: 0.20022186239064038]
	TIME [epoch: 10.4 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11244167035969055		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.11244167035969055 | validation: 0.14399740969924485]
	TIME [epoch: 10.4 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666135225211027		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.08666135225211027 | validation: 0.09819134127213079]
	TIME [epoch: 10.4 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08314055892068153		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.08314055892068153 | validation: 0.13225361017234313]
	TIME [epoch: 10.4 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0768740263606487		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.0768740263606487 | validation: 0.0939160362278992]
	TIME [epoch: 10.4 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07239106595986049		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.07239106595986049 | validation: 0.10969162175276335]
	TIME [epoch: 10.4 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09858206688183194		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.09858206688183194 | validation: 0.0721472934505342]
	TIME [epoch: 10.4 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07337413309473986		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.07337413309473986 | validation: 0.10078665543953727]
	TIME [epoch: 10.4 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08067510235446555		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.08067510235446555 | validation: 0.12398563403079468]
	TIME [epoch: 10.4 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0767545084098841		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.0767545084098841 | validation: 0.10193963824842506]
	TIME [epoch: 10.4 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0909389372745902		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.0909389372745902 | validation: 0.09952312969813623]
	TIME [epoch: 10.4 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0818412609850623		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.0818412609850623 | validation: 0.1242731202415309]
	TIME [epoch: 10.4 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10454997031141203		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.10454997031141203 | validation: 0.12558814540906504]
	TIME [epoch: 10.4 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08079448081650797		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.08079448081650797 | validation: 0.07956989919452859]
	TIME [epoch: 10.4 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06585736030202755		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.06585736030202755 | validation: 0.08448229610991109]
	TIME [epoch: 10.4 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06532927940204693		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.06532927940204693 | validation: 0.12709860893197747]
	TIME [epoch: 10.4 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11080520125691651		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.11080520125691651 | validation: 0.16691084658674604]
	TIME [epoch: 10.4 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18211435526278044		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.18211435526278044 | validation: 0.25153808958937945]
	TIME [epoch: 10.4 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12898157249439174		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.12898157249439174 | validation: 0.07619828986141085]
	TIME [epoch: 10.4 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07012827288163663		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.07012827288163663 | validation: 0.1493054653054945]
	TIME [epoch: 10.4 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06585109308980612		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.06585109308980612 | validation: 0.08657257674244344]
	TIME [epoch: 10.4 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08909651773036625		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.08909651773036625 | validation: 0.07301434804735042]
	TIME [epoch: 10.4 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06170963013234966		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.06170963013234966 | validation: 0.10585908709810099]
	TIME [epoch: 10.4 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06833520403539817		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.06833520403539817 | validation: 0.07726915683224227]
	TIME [epoch: 10.4 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06337692985690566		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.06337692985690566 | validation: 0.09800855113522426]
	TIME [epoch: 10.4 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06728780516208765		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.06728780516208765 | validation: 0.12020790977523692]
	TIME [epoch: 10.4 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10900638939668092		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.10900638939668092 | validation: 0.09141142038535299]
	TIME [epoch: 10.4 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07059420360171402		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.07059420360171402 | validation: 0.13222800314463923]
	TIME [epoch: 10.4 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07721088876605124		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.07721088876605124 | validation: 0.07738124414661626]
	TIME [epoch: 10.4 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059908306116669106		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.059908306116669106 | validation: 0.07371784116185558]
	TIME [epoch: 10.4 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06000955914150531		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.06000955914150531 | validation: 0.09859218339924851]
	TIME [epoch: 10.4 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062146689242400174		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.062146689242400174 | validation: 0.12943701503826355]
	TIME [epoch: 10.4 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05911464875977612		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.05911464875977612 | validation: 0.08663598140597673]
	TIME [epoch: 10.4 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0648353296719069		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.0648353296719069 | validation: 0.13670356667594796]
	TIME [epoch: 10.4 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07662219468077353		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.07662219468077353 | validation: 0.10278805748860627]
	TIME [epoch: 10.4 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06593685254709174		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.06593685254709174 | validation: 0.12236367693995792]
	TIME [epoch: 10.4 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08217973021924138		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.08217973021924138 | validation: 0.08728747423580697]
	TIME [epoch: 10.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0676313164495804		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.0676313164495804 | validation: 0.12747057784908375]
	TIME [epoch: 10.4 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12270147255895243		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.12270147255895243 | validation: 0.17101952049535235]
	TIME [epoch: 10.4 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11531107794495336		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.11531107794495336 | validation: 0.14426501705582676]
	TIME [epoch: 10.4 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07430744707497755		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.07430744707497755 | validation: 0.12288718456795238]
	TIME [epoch: 10.4 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07144862513240384		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.07144862513240384 | validation: 0.10319068627873247]
	TIME [epoch: 10.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11343674393664693		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.11343674393664693 | validation: 0.15848310565877158]
	TIME [epoch: 10.4 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11611511416775475		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.11611511416775475 | validation: 0.08609139902596574]
	TIME [epoch: 10.4 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07700457488314062		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.07700457488314062 | validation: 0.12014775804981011]
	TIME [epoch: 10.4 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07930503991442692		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.07930503991442692 | validation: 0.1364833684388139]
	TIME [epoch: 10.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07806004216901287		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.07806004216901287 | validation: 0.09693756122186621]
	TIME [epoch: 10.4 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06727218810764449		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.06727218810764449 | validation: 0.13612178381511808]
	TIME [epoch: 10.4 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08536386613369107		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.08536386613369107 | validation: 0.1997897335162345]
	TIME [epoch: 10.4 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10632568261866178		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.10632568261866178 | validation: 0.18838028621891723]
	TIME [epoch: 10.4 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1246782440250686		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.1246782440250686 | validation: 0.11153320338980778]
	TIME [epoch: 10.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09549688744023714		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.09549688744023714 | validation: 0.11918051340701936]
	TIME [epoch: 10.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07134468101125624		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.07134468101125624 | validation: 0.11879652208804341]
	TIME [epoch: 10.4 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06068883778686531		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.06068883778686531 | validation: 0.10887256467311143]
	TIME [epoch: 10.4 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07640264318088089		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.07640264318088089 | validation: 0.11441254206963689]
	TIME [epoch: 10.4 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07118368150398943		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.07118368150398943 | validation: 0.10902683049846168]
	TIME [epoch: 10.4 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06330224248496413		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.06330224248496413 | validation: 0.09126733755405302]
	TIME [epoch: 10.4 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06613870780378037		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.06613870780378037 | validation: 0.14856228560925175]
	TIME [epoch: 10.4 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813109962499063		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.0813109962499063 | validation: 0.12593062589623094]
	TIME [epoch: 10.4 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07066366347875179		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.07066366347875179 | validation: 0.127240056515693]
	TIME [epoch: 10.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09175702884458249		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.09175702884458249 | validation: 0.15638976041733474]
	TIME [epoch: 10.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0961050615105832		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.0961050615105832 | validation: 0.11354998797546023]
	TIME [epoch: 10.4 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07473401456083115		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.07473401456083115 | validation: 0.2132911683644262]
	TIME [epoch: 10.4 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15129705881944022		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.15129705881944022 | validation: 0.14587364453132864]
	TIME [epoch: 10.4 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09942460753693086		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.09942460753693086 | validation: 0.08700769258155147]
	TIME [epoch: 10.4 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06747382021142076		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.06747382021142076 | validation: 0.08124788194911582]
	TIME [epoch: 10.4 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0702030553275969		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.0702030553275969 | validation: 0.12847243293353788]
	TIME [epoch: 10.4 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08494245205904793		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.08494245205904793 | validation: 0.12106611066648938]
	TIME [epoch: 10.4 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07652261931451583		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.07652261931451583 | validation: 0.11505213079656929]
	TIME [epoch: 10.4 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08508337359081053		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.08508337359081053 | validation: 0.1847596183021338]
	TIME [epoch: 10.4 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1132311403258462		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.1132311403258462 | validation: 0.13872808064274392]
	TIME [epoch: 10.4 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10163243238906236		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.10163243238906236 | validation: 0.20129629791965184]
	TIME [epoch: 10.4 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10414177070415102		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.10414177070415102 | validation: 0.14500044789867209]
	TIME [epoch: 10.4 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07629162845271102		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.07629162845271102 | validation: 0.09361421743756361]
	TIME [epoch: 10.4 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07623645104957967		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.07623645104957967 | validation: 0.0885380257761488]
	TIME [epoch: 10.4 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10490413178649782		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.10490413178649782 | validation: 0.06915187522146278]
	TIME [epoch: 10.4 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07613995372307972		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.07613995372307972 | validation: 0.11273519475369455]
	TIME [epoch: 10.4 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07452468774794767		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.07452468774794767 | validation: 0.15592325446201144]
	TIME [epoch: 10.4 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08296625705933124		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.08296625705933124 | validation: 0.09242486757516542]
	TIME [epoch: 10.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08911635523977299		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.08911635523977299 | validation: 0.162844487990231]
	TIME [epoch: 10.4 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1178916167655409		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.1178916167655409 | validation: 0.11983683767933972]
	TIME [epoch: 10.4 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08187266795692269		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.08187266795692269 | validation: 0.10068139188159307]
	TIME [epoch: 10.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07183175814349888		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.07183175814349888 | validation: 0.07719205201354612]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06625459705430799		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.06625459705430799 | validation: 0.1955693501314368]
	TIME [epoch: 10.4 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947349038737006		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.09947349038737006 | validation: 0.1123005743573023]
	TIME [epoch: 10.4 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07422901224631974		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.07422901224631974 | validation: 0.11570840501826499]
	TIME [epoch: 10.4 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11229815762618534		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.11229815762618534 | validation: 0.32305101160371263]
	TIME [epoch: 10.4 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14095861895670306		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.14095861895670306 | validation: 0.1813062337208876]
	TIME [epoch: 10.4 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09474779807115663		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.09474779807115663 | validation: 0.11851910901069461]
	TIME [epoch: 10.4 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07599066505798038		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.07599066505798038 | validation: 0.1165089416228493]
	TIME [epoch: 10.4 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06311099943499915		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.06311099943499915 | validation: 0.11757197566950162]
	TIME [epoch: 10.4 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09995704355538142		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.09995704355538142 | validation: 0.1473209667359519]
	TIME [epoch: 10.4 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10683902419465863		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.10683902419465863 | validation: 0.130182894189194]
	TIME [epoch: 10.4 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102076298534105		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.102076298534105 | validation: 0.15028522627840082]
	TIME [epoch: 10.4 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11493586018467308		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.11493586018467308 | validation: 0.167892676188309]
	TIME [epoch: 10.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10687067203666016		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.10687067203666016 | validation: 0.13647146726883366]
	TIME [epoch: 10.4 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608336069387136		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.10608336069387136 | validation: 0.1684386577593527]
	TIME [epoch: 10.4 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09872905964707467		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.09872905964707467 | validation: 0.12015128572469536]
	TIME [epoch: 10.4 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10057250194088925		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.10057250194088925 | validation: 0.12684311752248825]
	TIME [epoch: 10.4 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08939448123341986		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.08939448123341986 | validation: 0.14545519969863913]
	TIME [epoch: 10.4 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09239200301985356		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.09239200301985356 | validation: 0.14269424920091212]
	TIME [epoch: 10.4 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12852662089034542		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.12852662089034542 | validation: 0.25198630423122304]
	TIME [epoch: 10.4 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19893734139200717		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.19893734139200717 | validation: 0.3108287988106921]
	TIME [epoch: 10.4 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.190154856795342		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.190154856795342 | validation: 0.18193693135236583]
	TIME [epoch: 10.4 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12495885633048234		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.12495885633048234 | validation: 0.18830716744554196]
	TIME [epoch: 10.4 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11885208566104288		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.11885208566104288 | validation: 0.12440024299832632]
	TIME [epoch: 10.4 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09543515358209967		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.09543515358209967 | validation: 0.15746531603046868]
	TIME [epoch: 10.4 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851572079344775		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.09851572079344775 | validation: 0.10694546659497149]
	TIME [epoch: 10.4 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07694493520851046		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.07694493520851046 | validation: 0.14688670511464053]
	TIME [epoch: 10.4 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10115401323970608		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.10115401323970608 | validation: 0.0965097560914689]
	TIME [epoch: 10.4 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07933059907612088		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.07933059907612088 | validation: 0.09796039455727573]
	TIME [epoch: 10.4 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07477362766524638		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.07477362766524638 | validation: 0.10293158239595024]
	TIME [epoch: 10.4 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07186030142256648		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.07186030142256648 | validation: 0.08970833969558609]
	TIME [epoch: 10.4 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07759450957499694		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.07759450957499694 | validation: 0.09225937508864882]
	TIME [epoch: 10.4 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06512994746315656		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.06512994746315656 | validation: 0.08566209341493157]
	TIME [epoch: 10.4 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08847583552640774		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.08847583552640774 | validation: 0.07800811642527704]
	TIME [epoch: 10.4 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059080041569636886		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.059080041569636886 | validation: 0.09018700891904906]
	TIME [epoch: 10.4 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06614617022873177		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.06614617022873177 | validation: 0.0666283665105232]
	TIME [epoch: 10.4 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051834572065680706		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.051834572065680706 | validation: 0.06947785921011268]
	TIME [epoch: 10.4 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052866182642227845		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.052866182642227845 | validation: 0.09685981772889307]
	TIME [epoch: 10.4 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0720815245127077		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.0720815245127077 | validation: 0.10088298601637678]
	TIME [epoch: 10.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06255782168511256		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.06255782168511256 | validation: 0.06664744732956096]
	TIME [epoch: 10.4 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05642094169857768		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.05642094169857768 | validation: 0.084929961886583]
	TIME [epoch: 10.4 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06896919501593907		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.06896919501593907 | validation: 0.1249639414704419]
	TIME [epoch: 10.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09281542927143552		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.09281542927143552 | validation: 0.08999699811375228]
	TIME [epoch: 10.4 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0625943395484461		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.0625943395484461 | validation: 0.08274125765489379]
	TIME [epoch: 10.4 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06586111302416216		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.06586111302416216 | validation: 0.07652075648569727]
	TIME [epoch: 10.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06810871923758419		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.06810871923758419 | validation: 0.13139296555399874]
	TIME [epoch: 10.4 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06039465934749129		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.06039465934749129 | validation: 0.07145423851071431]
	TIME [epoch: 10.4 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05224255736386094		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.05224255736386094 | validation: 0.08945270717151665]
	TIME [epoch: 10.4 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05578569991748696		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.05578569991748696 | validation: 0.07137328277459343]
	TIME [epoch: 10.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07501318810627926		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.07501318810627926 | validation: 0.06930920327191917]
	TIME [epoch: 10.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0655896628202403		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.0655896628202403 | validation: 0.08269453782034765]
	TIME [epoch: 10.4 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07141950934389096		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.07141950934389096 | validation: 0.0875273285282136]
	TIME [epoch: 10.4 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06451754024680065		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.06451754024680065 | validation: 0.07637820008368525]
	TIME [epoch: 10.4 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07679139380633065		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.07679139380633065 | validation: 0.14334454527697005]
	TIME [epoch: 10.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07880835533859851		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.07880835533859851 | validation: 0.08491551314156427]
	TIME [epoch: 10.4 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08862040811021435		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.08862040811021435 | validation: 0.1118302729973526]
	TIME [epoch: 10.4 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07939400842123852		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.07939400842123852 | validation: 0.07736040180463549]
	TIME [epoch: 10.4 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06416598530446925		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.06416598530446925 | validation: 0.08476848309710004]
	TIME [epoch: 10.4 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06769598943723039		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.06769598943723039 | validation: 0.06150799845752234]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1458.pth
	Model improved!!!
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06446561394872347		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.06446561394872347 | validation: 0.08577356411996818]
	TIME [epoch: 10.4 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05764138580921091		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.05764138580921091 | validation: 0.0688615750271289]
	TIME [epoch: 10.4 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04811176239531956		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.04811176239531956 | validation: 0.051771202599659935]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1461.pth
	Model improved!!!
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05435332433695911		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.05435332433695911 | validation: 0.06598365531027658]
	TIME [epoch: 10.4 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04387506406351995		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.04387506406351995 | validation: 0.08536897059930042]
	TIME [epoch: 10.4 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06167425391302613		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.06167425391302613 | validation: 0.09962353716151377]
	TIME [epoch: 10.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05909810280452867		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.05909810280452867 | validation: 0.06924841010912787]
	TIME [epoch: 10.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06101685761204475		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.06101685761204475 | validation: 0.08124972217844796]
	TIME [epoch: 10.4 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06117002254700443		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.06117002254700443 | validation: 0.11312549682250016]
	TIME [epoch: 10.4 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04832241502181548		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.04832241502181548 | validation: 0.08036435470522386]
	TIME [epoch: 10.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06703816009267333		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.06703816009267333 | validation: 0.07180661845648682]
	TIME [epoch: 10.4 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09638501407400776		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.09638501407400776 | validation: 0.16379480327228482]
	TIME [epoch: 10.4 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12843849335251684		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.12843849335251684 | validation: 0.17056325136916997]
	TIME [epoch: 10.4 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08409439502782493		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.08409439502782493 | validation: 0.1170993172678355]
	TIME [epoch: 10.4 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751779827773438		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.08751779827773438 | validation: 0.18389895149461924]
	TIME [epoch: 10.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1224530929517231		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.1224530929517231 | validation: 0.10653240872437504]
	TIME [epoch: 10.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07206675113697322		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.07206675113697322 | validation: 0.07749229647775147]
	TIME [epoch: 10.4 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06377672226785407		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.06377672226785407 | validation: 0.09511392411879227]
	TIME [epoch: 10.4 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05156763048378086		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.05156763048378086 | validation: 0.0924656699965181]
	TIME [epoch: 10.4 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058313978765546934		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.058313978765546934 | validation: 0.0883641345282295]
	TIME [epoch: 10.4 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900713488914373		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.08900713488914373 | validation: 0.21731522822667337]
	TIME [epoch: 10.4 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11058963448797313		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.11058963448797313 | validation: 0.12282591017095451]
	TIME [epoch: 10.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08436356726414637		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.08436356726414637 | validation: 0.18687530870049293]
	TIME [epoch: 10.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13189562824028975		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.13189562824028975 | validation: 0.16070061259247984]
	TIME [epoch: 10.4 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10904396763184124		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.10904396763184124 | validation: 0.08714362083087697]
	TIME [epoch: 10.4 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09396880890552232		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.09396880890552232 | validation: 0.056975302827776936]
	TIME [epoch: 10.4 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05144386885729315		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.05144386885729315 | validation: 0.10943934903713562]
	TIME [epoch: 10.4 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06577852881053536		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.06577852881053536 | validation: 0.11731415909571016]
	TIME [epoch: 10.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06252300240184915		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.06252300240184915 | validation: 0.12336841344350864]
	TIME [epoch: 10.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0710458101665086		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.0710458101665086 | validation: 0.08240943250759758]
	TIME [epoch: 10.4 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0660562986768555		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.0660562986768555 | validation: 0.08539940854597872]
	TIME [epoch: 10.4 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06298647667498156		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.06298647667498156 | validation: 0.11956118523383694]
	TIME [epoch: 10.4 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12695668183321		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.12695668183321 | validation: 0.15851524475298756]
	TIME [epoch: 10.4 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07535325523570771		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.07535325523570771 | validation: 0.088862741109073]
	TIME [epoch: 10.4 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08425949242761728		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.08425949242761728 | validation: 0.11389799688096666]
	TIME [epoch: 10.4 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09335766315695732		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.09335766315695732 | validation: 0.07904966385212253]
	TIME [epoch: 10.4 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057265770274300944		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.057265770274300944 | validation: 0.09479091595657486]
	TIME [epoch: 10.4 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07204654339213719		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.07204654339213719 | validation: 0.08909918659646814]
	TIME [epoch: 10.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10243980202465683		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.10243980202465683 | validation: 0.1137533445581273]
	TIME [epoch: 10.4 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08088466574071076		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.08088466574071076 | validation: 0.1022142103560331]
	TIME [epoch: 10.4 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09036678585556841		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.09036678585556841 | validation: 0.0785410251673077]
	TIME [epoch: 10.4 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06507745251980729		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.06507745251980729 | validation: 0.09599638949374653]
	TIME [epoch: 10.4 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07464122117623637		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.07464122117623637 | validation: 0.09640441025480341]
	TIME [epoch: 10.4 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07570107432226345		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.07570107432226345 | validation: 0.07371716016966089]
	TIME [epoch: 10.4 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05465946184508186		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.05465946184508186 | validation: 0.09006843917426047]
	TIME [epoch: 10.4 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06435555278582045		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.06435555278582045 | validation: 0.09385073577912977]
	TIME [epoch: 10.4 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0498783517757148		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.0498783517757148 | validation: 0.06173212318708159]
	TIME [epoch: 10.4 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0454957637393793		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.0454957637393793 | validation: 0.06464083456915583]
	TIME [epoch: 10.4 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048493083405982955		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.048493083405982955 | validation: 0.07275520982182986]
	TIME [epoch: 10.4 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05349349610871264		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.05349349610871264 | validation: 0.055176080185200316]
	TIME [epoch: 10.4 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06345762139184762		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.06345762139184762 | validation: 0.07024977214046058]
	TIME [epoch: 10.4 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0617784880811789		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.0617784880811789 | validation: 0.13277369834439628]
	TIME [epoch: 10.4 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07810324570474371		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.07810324570474371 | validation: 0.1047390198462487]
	TIME [epoch: 10.4 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0647091563815552		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.0647091563815552 | validation: 0.13671560833155472]
	TIME [epoch: 10.4 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08889161482785442		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.08889161482785442 | validation: 0.1359395666386374]
	TIME [epoch: 10.4 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0890323903397094		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.0890323903397094 | validation: 0.10941178995940021]
	TIME [epoch: 10.4 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0876724670116474		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.0876724670116474 | validation: 0.09412168963760874]
	TIME [epoch: 10.4 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11068900754968954		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.11068900754968954 | validation: 0.13885559374560943]
	TIME [epoch: 10.4 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10293558128727313		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.10293558128727313 | validation: 0.11216864422993218]
	TIME [epoch: 10.4 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09344015839660483		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.09344015839660483 | validation: 0.1558905659116434]
	TIME [epoch: 10.4 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09084267513823077		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.09084267513823077 | validation: 0.09274597903587176]
	TIME [epoch: 10.4 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05766600723250156		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.05766600723250156 | validation: 0.08452654717785879]
	TIME [epoch: 10.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07507564519795454		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.07507564519795454 | validation: 0.12178926596832235]
	TIME [epoch: 10.4 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08952202754234431		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.08952202754234431 | validation: 0.11368265158695025]
	TIME [epoch: 10.4 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07793966493502727		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.07793966493502727 | validation: 0.067323844671851]
	TIME [epoch: 10.4 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06299659192159243		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.06299659192159243 | validation: 0.0758919995603884]
	TIME [epoch: 10.4 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0653957320693787		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.0653957320693787 | validation: 0.11672373865073997]
	TIME [epoch: 10.4 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06885241386921455		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.06885241386921455 | validation: 0.08366433753928336]
	TIME [epoch: 10.4 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058554254521815195		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.058554254521815195 | validation: 0.081706920854158]
	TIME [epoch: 10.4 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05242123171586616		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.05242123171586616 | validation: 0.08883166436874419]
	TIME [epoch: 10.4 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053241938290009394		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.053241938290009394 | validation: 0.06414110024625948]
	TIME [epoch: 10.4 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06658814437230118		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.06658814437230118 | validation: 0.12591321307171305]
	TIME [epoch: 10.4 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10831089936026814		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.10831089936026814 | validation: 0.10293854996735884]
	TIME [epoch: 10.4 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07896822188089044		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.07896822188089044 | validation: 0.10758673512168007]
	TIME [epoch: 10.4 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884223236537654		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.08884223236537654 | validation: 0.1235154793514987]
	TIME [epoch: 10.4 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07677224390897161		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.07677224390897161 | validation: 0.13594548313268162]
	TIME [epoch: 10.4 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05622693981886785		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.05622693981886785 | validation: 0.08016433317401278]
	TIME [epoch: 10.4 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04293537074423864		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.04293537074423864 | validation: 0.10836302177801851]
	TIME [epoch: 10.4 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059016400778416925		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.059016400778416925 | validation: 0.08845587270238393]
	TIME [epoch: 10.4 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06715308033713341		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.06715308033713341 | validation: 0.09374580196340099]
	TIME [epoch: 10.4 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057973807524058216		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.057973807524058216 | validation: 0.09495035398586232]
	TIME [epoch: 10.4 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06273915393103568		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.06273915393103568 | validation: 0.10635523100513641]
	TIME [epoch: 10.4 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07198250676475211		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.07198250676475211 | validation: 0.13174347804586092]
	TIME [epoch: 10.4 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07298207210916888		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.07298207210916888 | validation: 0.07057772239400749]
	TIME [epoch: 10.4 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649963643140005		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.0649963643140005 | validation: 0.10392777082821204]
	TIME [epoch: 10.4 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08054766880408934		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.08054766880408934 | validation: 0.1655953978985369]
	TIME [epoch: 10.4 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07860091485153732		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.07860091485153732 | validation: 0.1058622620081719]
	TIME [epoch: 10.4 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061983569007019255		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.061983569007019255 | validation: 0.07500202005310007]
	TIME [epoch: 10.4 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055668447688285216		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.055668447688285216 | validation: 0.12732859177431555]
	TIME [epoch: 10.4 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05722878717178483		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.05722878717178483 | validation: 0.08081975805724977]
	TIME [epoch: 10.4 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054107124573392375		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.054107124573392375 | validation: 0.07925496052667942]
	TIME [epoch: 10.4 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0627416910915317		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.0627416910915317 | validation: 0.13880116753131375]
	TIME [epoch: 10.4 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09011305704173433		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.09011305704173433 | validation: 0.10945506024965151]
	TIME [epoch: 10.4 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07227818555165724		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.07227818555165724 | validation: 0.12448849643537724]
	TIME [epoch: 10.4 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10144957531714112		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.10144957531714112 | validation: 0.16556375707734863]
	TIME [epoch: 10.4 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0981469296151081		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.0981469296151081 | validation: 0.10632539334959264]
	TIME [epoch: 10.4 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08065646961318203		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.08065646961318203 | validation: 0.09796858672171471]
	TIME [epoch: 10.4 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06898031121329351		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.06898031121329351 | validation: 0.10763120257076438]
	TIME [epoch: 10.4 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07433961462572444		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.07433961462572444 | validation: 0.10746693313097139]
	TIME [epoch: 10.4 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0640418513232352		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.0640418513232352 | validation: 0.11516242543464386]
	TIME [epoch: 10.4 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05364207144456361		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.05364207144456361 | validation: 0.08182887250858341]
	TIME [epoch: 10.4 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06908629752699853		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.06908629752699853 | validation: 0.06350521338303476]
	TIME [epoch: 10.4 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05346133087133388		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.05346133087133388 | validation: 0.09287026032858721]
	TIME [epoch: 10.4 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04573051122225349		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.04573051122225349 | validation: 0.13258557326231574]
	TIME [epoch: 10.4 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10241014274300135		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.10241014274300135 | validation: 0.1154360451490866]
	TIME [epoch: 10.4 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07700363249461672		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.07700363249461672 | validation: 0.12629449258164066]
	TIME [epoch: 10.4 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08145091792226526		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.08145091792226526 | validation: 0.12881877385662857]
	TIME [epoch: 10.4 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07228449118624913		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.07228449118624913 | validation: 0.09254265914308665]
	TIME [epoch: 10.4 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06070217785348207		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.06070217785348207 | validation: 0.099839910010706]
	TIME [epoch: 10.4 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052823945470074816		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.052823945470074816 | validation: 0.07272045922731799]
	TIME [epoch: 10.4 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056867244415214804		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.056867244415214804 | validation: 0.11762166515772425]
	TIME [epoch: 10.4 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06811214328345747		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.06811214328345747 | validation: 0.1175289830815099]
	TIME [epoch: 10.4 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07680776638064804		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.07680776638064804 | validation: 0.09816835683765686]
	TIME [epoch: 10.4 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06296306677219517		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.06296306677219517 | validation: 0.09246575721398888]
	TIME [epoch: 10.4 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05926496644441215		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.05926496644441215 | validation: 0.10269874175763379]
	TIME [epoch: 10.4 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08045098650185348		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.08045098650185348 | validation: 0.1691784830309935]
	TIME [epoch: 10.4 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0675036700044688		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.0675036700044688 | validation: 0.08195615412647861]
	TIME [epoch: 10.4 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06668437782472182		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.06668437782472182 | validation: 0.10261741496913626]
	TIME [epoch: 10.4 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07240948009734609		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.07240948009734609 | validation: 0.12618293556844773]
	TIME [epoch: 10.4 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06721759106164042		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.06721759106164042 | validation: 0.08189190016147777]
	TIME [epoch: 10.4 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0715172380091749		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.0715172380091749 | validation: 0.08780647003743448]
	TIME [epoch: 10.4 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059750075066972795		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.059750075066972795 | validation: 0.08294275458254634]
	TIME [epoch: 10.4 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05989069335125764		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.05989069335125764 | validation: 0.08429795739520879]
	TIME [epoch: 10.4 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054303156798401975		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.054303156798401975 | validation: 0.05954787363403814]
	TIME [epoch: 10.4 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04689944912162032		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.04689944912162032 | validation: 0.10574351373580985]
	TIME [epoch: 10.4 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06540755555500659		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.06540755555500659 | validation: 0.08823812983243762]
	TIME [epoch: 10.4 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060243454185056965		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.060243454185056965 | validation: 0.10127008067849115]
	TIME [epoch: 10.4 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05565962878068886		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.05565962878068886 | validation: 0.11124616872752142]
	TIME [epoch: 10.4 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255581670980995		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.09255581670980995 | validation: 0.16988469245455246]
	TIME [epoch: 10.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08462004656967115		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.08462004656967115 | validation: 0.10037767094116067]
	TIME [epoch: 10.4 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06864317165424877		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.06864317165424877 | validation: 0.12549216277744518]
	TIME [epoch: 10.4 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058220451140412875		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.058220451140412875 | validation: 0.10359767079333781]
	TIME [epoch: 10.4 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049006288158843746		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.049006288158843746 | validation: 0.08149025070108526]
	TIME [epoch: 10.4 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05178235755859291		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.05178235755859291 | validation: 0.07140210639432544]
	TIME [epoch: 10.4 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05511063308794426		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.05511063308794426 | validation: 0.09683333739062848]
	TIME [epoch: 10.4 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05838643851149271		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.05838643851149271 | validation: 0.08015744634718551]
	TIME [epoch: 10.4 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0528414236637456		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.0528414236637456 | validation: 0.07731919030784166]
	TIME [epoch: 10.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743623625367023		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.06743623625367023 | validation: 0.0986919499634023]
	TIME [epoch: 10.4 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197477953604526		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.08197477953604526 | validation: 0.08299517836430587]
	TIME [epoch: 10.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06006612808356301		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.06006612808356301 | validation: 0.05208729934617956]
	TIME [epoch: 10.4 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049494374010546474		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.049494374010546474 | validation: 0.06695079125739435]
	TIME [epoch: 10.4 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056172908706268454		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.056172908706268454 | validation: 0.10516846151034508]
	TIME [epoch: 10.4 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06650446302930837		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.06650446302930837 | validation: 0.08836664334971954]
	TIME [epoch: 10.4 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050033872989239114		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.050033872989239114 | validation: 0.07288622723562717]
	TIME [epoch: 10.4 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0664499697394928		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.0664499697394928 | validation: 0.07462119270651119]
	TIME [epoch: 10.4 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053470216023716835		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.053470216023716835 | validation: 0.07403020177432955]
	TIME [epoch: 10.4 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06902667712318747		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.06902667712318747 | validation: 0.08537952659299718]
	TIME [epoch: 10.4 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04937147330290624		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.04937147330290624 | validation: 0.07216889284619643]
	TIME [epoch: 10.4 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06350585845768107		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.06350585845768107 | validation: 0.10560752967229417]
	TIME [epoch: 10.4 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06500524183287246		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.06500524183287246 | validation: 0.07806687007651533]
	TIME [epoch: 10.4 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05242135959459139		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.05242135959459139 | validation: 0.06089925910920419]
	TIME [epoch: 10.4 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0460942209801146		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.0460942209801146 | validation: 0.07404250519613474]
	TIME [epoch: 10.4 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0445991810449427		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.0445991810449427 | validation: 0.054318687945732205]
	TIME [epoch: 10.4 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041033659326791636		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.041033659326791636 | validation: 0.07592392215398508]
	TIME [epoch: 10.4 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040375995714134964		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.040375995714134964 | validation: 0.06708045222298634]
	TIME [epoch: 10.4 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060894369806185		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.060894369806185 | validation: 0.07070759068563842]
	TIME [epoch: 10.4 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06700267266672526		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.06700267266672526 | validation: 0.08495144238835123]
	TIME [epoch: 10.4 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049361914815782		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.049361914815782 | validation: 0.06976343041985843]
	TIME [epoch: 10.4 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05800349482138062		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.05800349482138062 | validation: 0.10543468574717882]
	TIME [epoch: 10.4 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04708889000818685		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.04708889000818685 | validation: 0.05791993628494474]
	TIME [epoch: 10.4 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04489587589067626		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.04489587589067626 | validation: 0.043405295496680596]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1619.pth
	Model improved!!!
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06019179430032977		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.06019179430032977 | validation: 0.06600738703423512]
	TIME [epoch: 10.4 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047983934219159335		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.047983934219159335 | validation: 0.07321777925916094]
	TIME [epoch: 10.4 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0484951882452335		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.0484951882452335 | validation: 0.11689327717380918]
	TIME [epoch: 10.4 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05585998041188471		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.05585998041188471 | validation: 0.0740898694546731]
	TIME [epoch: 10.4 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04901936579174259		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.04901936579174259 | validation: 0.07828464352648866]
	TIME [epoch: 10.4 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051575678023648805		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.051575678023648805 | validation: 0.05787780793474614]
	TIME [epoch: 10.4 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057391908337412714		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.057391908337412714 | validation: 0.08644229282334152]
	TIME [epoch: 10.4 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05848247440306799		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.05848247440306799 | validation: 0.05650101328435118]
	TIME [epoch: 10.4 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05019813895126789		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.05019813895126789 | validation: 0.0647553922295673]
	TIME [epoch: 10.4 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04368999056328279		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.04368999056328279 | validation: 0.07874962428052282]
	TIME [epoch: 10.4 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05998146961588755		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.05998146961588755 | validation: 0.1296016373414752]
	TIME [epoch: 10.4 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07349249196341809		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.07349249196341809 | validation: 0.1021055829873173]
	TIME [epoch: 10.4 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06780034569262752		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.06780034569262752 | validation: 0.10787286788417486]
	TIME [epoch: 10.4 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07354376768406652		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.07354376768406652 | validation: 0.08501781944090443]
	TIME [epoch: 10.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07181183529485657		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.07181183529485657 | validation: 0.1058654259525462]
	TIME [epoch: 10.4 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05642048231634143		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.05642048231634143 | validation: 0.06617470223251956]
	TIME [epoch: 10.4 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06300986395791028		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.06300986395791028 | validation: 0.13004351710843404]
	TIME [epoch: 10.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0973619685792596		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.0973619685792596 | validation: 0.1331254547833822]
	TIME [epoch: 10.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08854396820610151		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.08854396820610151 | validation: 0.19620045224038918]
	TIME [epoch: 10.4 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1324185272129077		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.1324185272129077 | validation: 0.1790572514570458]
	TIME [epoch: 10.4 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1229001362438568		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.1229001362438568 | validation: 0.20351457762179856]
	TIME [epoch: 10.4 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10110956820555209		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.10110956820555209 | validation: 0.12478384108193769]
	TIME [epoch: 10.4 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886583948498133		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.08886583948498133 | validation: 0.10859999976013146]
	TIME [epoch: 10.4 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07530389726555606		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.07530389726555606 | validation: 0.09408083136335631]
	TIME [epoch: 10.4 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05803281255553226		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.05803281255553226 | validation: 0.08039559679830713]
	TIME [epoch: 10.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07478891882105716		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.07478891882105716 | validation: 0.07360764667189282]
	TIME [epoch: 10.4 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05178564334390891		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.05178564334390891 | validation: 0.09587062137774498]
	TIME [epoch: 10.4 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05752623196549953		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.05752623196549953 | validation: 0.0772410359432983]
	TIME [epoch: 10.4 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06719822894799624		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.06719822894799624 | validation: 0.07151315911574761]
	TIME [epoch: 10.4 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06276675945682605		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.06276675945682605 | validation: 0.06094469181531351]
	TIME [epoch: 10.4 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401926755237679		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.08401926755237679 | validation: 0.0743230873709057]
	TIME [epoch: 10.4 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06668102803126155		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.06668102803126155 | validation: 0.06266833779478785]
	TIME [epoch: 10.4 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06098318743741817		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.06098318743741817 | validation: 0.049188689847344536]
	TIME [epoch: 10.4 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05427999986222668		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.05427999986222668 | validation: 0.06396356655743364]
	TIME [epoch: 10.4 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056925701012854615		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.056925701012854615 | validation: 0.06100609108385899]
	TIME [epoch: 10.4 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05038889650027867		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.05038889650027867 | validation: 0.07464257261775364]
	TIME [epoch: 10.4 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054247209970030144		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.054247209970030144 | validation: 0.10088428761397725]
	TIME [epoch: 10.4 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051113428662395245		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.051113428662395245 | validation: 0.06097150458101086]
	TIME [epoch: 10.4 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0474528214099402		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.0474528214099402 | validation: 0.12415830682478905]
	TIME [epoch: 10.4 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475133098306609		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.08475133098306609 | validation: 0.09308152488637887]
	TIME [epoch: 10.4 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07489172894134914		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.07489172894134914 | validation: 0.08791130724577104]
	TIME [epoch: 10.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0646371574756533		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.0646371574756533 | validation: 0.08737363555268676]
	TIME [epoch: 10.4 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04529446395350613		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.04529446395350613 | validation: 0.07685183546886197]
	TIME [epoch: 10.4 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047917390416041414		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.047917390416041414 | validation: 0.06337245381210348]
	TIME [epoch: 10.4 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04530018754673274		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.04530018754673274 | validation: 0.05816586531254084]
	TIME [epoch: 10.4 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052550201878443524		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.052550201878443524 | validation: 0.08918616494325089]
	TIME [epoch: 10.4 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04226809720809593		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.04226809720809593 | validation: 0.09112230889671294]
	TIME [epoch: 10.4 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05004211512138693		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.05004211512138693 | validation: 0.0785784981157305]
	TIME [epoch: 10.4 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045248521367381375		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.045248521367381375 | validation: 0.07822248002130476]
	TIME [epoch: 10.4 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05524929311706508		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.05524929311706508 | validation: 0.08728671956363833]
	TIME [epoch: 10.4 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053855408969913574		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.053855408969913574 | validation: 0.09724953742916363]
	TIME [epoch: 10.4 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05020447844006223		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.05020447844006223 | validation: 0.07742321233302073]
	TIME [epoch: 10.4 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04506133308135897		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.04506133308135897 | validation: 0.08634482572907082]
	TIME [epoch: 10.4 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05784375956481254		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.05784375956481254 | validation: 0.09711067015612464]
	TIME [epoch: 10.4 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05172013420348341		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.05172013420348341 | validation: 0.05936974010014667]
	TIME [epoch: 10.4 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04006518801725618		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.04006518801725618 | validation: 0.05759872146542367]
	TIME [epoch: 10.4 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055054304295623344		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.055054304295623344 | validation: 0.10356774192702375]
	TIME [epoch: 10.4 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0594209675554835		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.0594209675554835 | validation: 0.10524460895711829]
	TIME [epoch: 10.4 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05452164554529848		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.05452164554529848 | validation: 0.10954299940175317]
	TIME [epoch: 10.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054987791549834006		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.054987791549834006 | validation: 0.08822153982344634]
	TIME [epoch: 10.4 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04487301075172204		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.04487301075172204 | validation: 0.056003765572828657]
	TIME [epoch: 10.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05112530273891368		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.05112530273891368 | validation: 0.07704519476924399]
	TIME [epoch: 10.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05139553213738951		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.05139553213738951 | validation: 0.07658068426500711]
	TIME [epoch: 10.4 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03921995966224155		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.03921995966224155 | validation: 0.05077748613526179]
	TIME [epoch: 10.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04677504810609815		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.04677504810609815 | validation: 0.06677645558422694]
	TIME [epoch: 10.4 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04133631312710257		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.04133631312710257 | validation: 0.06530804782841446]
	TIME [epoch: 10.4 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04157879154793733		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.04157879154793733 | validation: 0.06465370389712626]
	TIME [epoch: 10.4 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05540061427902356		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.05540061427902356 | validation: 0.062020474421274376]
	TIME [epoch: 10.4 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03859455254801377		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.03859455254801377 | validation: 0.05299541477636103]
	TIME [epoch: 10.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04126254103883246		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.04126254103883246 | validation: 0.07650857372274737]
	TIME [epoch: 10.4 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049321054266928246		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.049321054266928246 | validation: 0.06835787026366912]
	TIME [epoch: 10.4 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041313580356088786		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.041313580356088786 | validation: 0.06018027407453481]
	TIME [epoch: 10.4 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04639277213998509		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.04639277213998509 | validation: 0.04451138205724498]
	TIME [epoch: 10.4 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036826808946011536		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.036826808946011536 | validation: 0.052736461933847865]
	TIME [epoch: 10.4 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03532436299531909		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.03532436299531909 | validation: 0.059274328303257455]
	TIME [epoch: 10.4 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047995030077003606		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.047995030077003606 | validation: 0.0721263131450474]
	TIME [epoch: 10.4 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06992825908055947		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.06992825908055947 | validation: 0.08333371859551171]
	TIME [epoch: 10.4 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05600065387981641		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.05600065387981641 | validation: 0.0629669237688186]
	TIME [epoch: 10.4 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050949085384927414		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.050949085384927414 | validation: 0.06891388415495814]
	TIME [epoch: 10.4 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0557207363562008		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.0557207363562008 | validation: 0.055014574730176465]
	TIME [epoch: 10.4 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050167661237093195		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.050167661237093195 | validation: 0.06835622119621873]
	TIME [epoch: 10.4 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05140604514624466		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.05140604514624466 | validation: 0.07935826879260527]
	TIME [epoch: 10.4 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05475402433075671		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.05475402433075671 | validation: 0.07058869160170478]
	TIME [epoch: 10.4 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053685883033834106		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.053685883033834106 | validation: 0.0601268068402251]
	TIME [epoch: 10.4 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04989748580550214		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.04989748580550214 | validation: 0.06879376537141353]
	TIME [epoch: 10.4 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05615218169682752		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.05615218169682752 | validation: 0.08905468232176937]
	TIME [epoch: 10.4 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06274535096349107		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.06274535096349107 | validation: 0.07376650844887506]
	TIME [epoch: 10.4 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05635022143795624		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.05635022143795624 | validation: 0.05992748858347068]
	TIME [epoch: 10.4 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06941342970019332		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.06941342970019332 | validation: 0.07117581129626196]
	TIME [epoch: 10.4 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0640154273088321		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.0640154273088321 | validation: 0.060205687857428594]
	TIME [epoch: 10.4 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0753177075042939		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.0753177075042939 | validation: 0.09078177337237268]
	TIME [epoch: 10.4 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06419309444207835		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.06419309444207835 | validation: 0.11468484414296697]
	TIME [epoch: 10.4 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06172837547920157		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.06172837547920157 | validation: 0.0959077903027002]
	TIME [epoch: 10.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05291089509546559		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.05291089509546559 | validation: 0.09011852851693053]
	TIME [epoch: 10.4 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04966242063366983		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.04966242063366983 | validation: 0.07886459868524798]
	TIME [epoch: 10.4 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04909190384449803		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.04909190384449803 | validation: 0.09141397742310055]
	TIME [epoch: 10.4 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05437801241442536		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.05437801241442536 | validation: 0.08554294281782303]
	TIME [epoch: 10.4 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04810723298130798		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.04810723298130798 | validation: 0.08881240714439292]
	TIME [epoch: 10.4 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062033506018607375		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.062033506018607375 | validation: 0.12492568446487119]
	TIME [epoch: 10.4 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06894227534630544		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.06894227534630544 | validation: 0.0913049503584894]
	TIME [epoch: 10.4 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051832413396621056		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.051832413396621056 | validation: 0.08439976246576823]
	TIME [epoch: 10.4 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04178313120676038		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.04178313120676038 | validation: 0.06418145906818269]
	TIME [epoch: 10.4 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03869626894856463		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.03869626894856463 | validation: 0.06079199159983374]
	TIME [epoch: 10.4 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03993391338967739		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.03993391338967739 | validation: 0.0730518836973858]
	TIME [epoch: 10.4 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04575810097603692		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.04575810097603692 | validation: 0.06341633145409699]
	TIME [epoch: 10.4 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05357431914515197		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.05357431914515197 | validation: 0.05371974722512841]
	TIME [epoch: 10.4 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04997758183956184		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.04997758183956184 | validation: 0.06088078172070741]
	TIME [epoch: 10.4 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05603432430403712		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.05603432430403712 | validation: 0.06700127332417863]
	TIME [epoch: 10.4 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0435065820038542		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.0435065820038542 | validation: 0.05298422108794368]
	TIME [epoch: 10.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0510302131433615		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.0510302131433615 | validation: 0.056845565730392955]
	TIME [epoch: 10.4 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05117601644301073		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.05117601644301073 | validation: 0.07068907247526049]
	TIME [epoch: 10.4 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05415048432068287		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.05415048432068287 | validation: 0.08175007926474641]
	TIME [epoch: 10.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08305278590538903		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.08305278590538903 | validation: 0.11523698235259772]
	TIME [epoch: 10.4 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07772034276957722		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.07772034276957722 | validation: 0.08325550500345891]
	TIME [epoch: 10.4 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06664428845599263		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.06664428845599263 | validation: 0.07302249596361478]
	TIME [epoch: 10.4 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0680542510400249		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.0680542510400249 | validation: 0.09447574814584732]
	TIME [epoch: 10.4 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07479882813147813		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.07479882813147813 | validation: 0.08352075248895278]
	TIME [epoch: 10.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05048883502153303		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.05048883502153303 | validation: 0.0834278690291039]
	TIME [epoch: 10.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04073889925480483		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.04073889925480483 | validation: 0.09686323503202349]
	TIME [epoch: 10.4 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03701287230609592		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.03701287230609592 | validation: 0.06848457364742892]
	TIME [epoch: 10.4 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04449706189170347		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.04449706189170347 | validation: 0.07908834019748395]
	TIME [epoch: 10.4 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04854655959446159		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.04854655959446159 | validation: 0.08379298864456032]
	TIME [epoch: 10.4 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04511705846191372		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.04511705846191372 | validation: 0.08618168073402384]
	TIME [epoch: 10.4 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04606670754145412		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.04606670754145412 | validation: 0.05376857542755458]
	TIME [epoch: 10.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04765138313345123		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.04765138313345123 | validation: 0.06855147404464591]
	TIME [epoch: 10.4 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04436354882052458		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.04436354882052458 | validation: 0.07308822807353604]
	TIME [epoch: 10.4 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0523929248611522		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.0523929248611522 | validation: 0.07352155236306171]
	TIME [epoch: 10.4 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043913387026749275		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.043913387026749275 | validation: 0.06967477918844919]
	TIME [epoch: 10.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05205800363557876		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.05205800363557876 | validation: 0.0697814982968477]
	TIME [epoch: 10.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04076707789252384		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.04076707789252384 | validation: 0.05853294537970902]
	TIME [epoch: 10.4 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048238127797896754		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.048238127797896754 | validation: 0.0709299061959702]
	TIME [epoch: 10.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0641968267820967		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.0641968267820967 | validation: 0.07419658540658765]
	TIME [epoch: 10.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06859411639592913		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.06859411639592913 | validation: 0.09445267855182934]
	TIME [epoch: 10.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05860199889316166		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.05860199889316166 | validation: 0.07917869307529526]
	TIME [epoch: 10.4 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0596058247186871		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.0596058247186871 | validation: 0.10930904858515206]
	TIME [epoch: 10.4 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04928270864877572		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.04928270864877572 | validation: 0.08885222185304043]
	TIME [epoch: 10.4 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058166713421412754		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.058166713421412754 | validation: 0.13291872284537867]
	TIME [epoch: 10.4 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05491119023715405		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.05491119023715405 | validation: 0.08500917515095992]
	TIME [epoch: 10.4 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050923028496121715		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.050923028496121715 | validation: 0.06957436932992778]
	TIME [epoch: 10.4 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04431802690924319		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.04431802690924319 | validation: 0.07485859368294408]
	TIME [epoch: 10.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05399416820867309		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.05399416820867309 | validation: 0.09263032112123827]
	TIME [epoch: 10.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06056758843103329		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.06056758843103329 | validation: 0.10155927650227158]
	TIME [epoch: 10.4 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07003270468029842		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.07003270468029842 | validation: 0.10637301071478376]
	TIME [epoch: 10.4 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06098488488471571		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.06098488488471571 | validation: 0.07156034274625109]
	TIME [epoch: 10.4 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044054799361892924		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.044054799361892924 | validation: 0.06372647080042075]
	TIME [epoch: 10.4 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050675633711281455		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.050675633711281455 | validation: 0.09805532018122934]
	TIME [epoch: 10.4 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06131926129147212		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.06131926129147212 | validation: 0.07181532951631146]
	TIME [epoch: 10.4 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06386828420542887		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.06386828420542887 | validation: 0.11385188399221058]
	TIME [epoch: 10.4 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05084029718228765		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.05084029718228765 | validation: 0.06773337780818273]
	TIME [epoch: 10.4 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055855851697976897		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.055855851697976897 | validation: 0.0964992334883792]
	TIME [epoch: 10.4 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07567729155122352		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.07567729155122352 | validation: 0.08629420239856969]
	TIME [epoch: 10.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06184143886499712		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.06184143886499712 | validation: 0.08148069545614967]
	TIME [epoch: 10.4 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057366811337347334		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.057366811337347334 | validation: 0.07499532760788846]
	TIME [epoch: 10.4 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038115121518335925		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.038115121518335925 | validation: 0.0640823999686656]
	TIME [epoch: 10.4 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04389755233721254		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.04389755233721254 | validation: 0.08724932444812239]
	TIME [epoch: 10.4 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042733062950213486		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.042733062950213486 | validation: 0.07242278384177109]
	TIME [epoch: 10.4 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042499138580199894		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.042499138580199894 | validation: 0.05003174383809331]
	TIME [epoch: 10.4 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03912364460470312		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.03912364460470312 | validation: 0.05390734972430532]
	TIME [epoch: 10.4 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048910637349862396		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.048910637349862396 | validation: 0.06606431467422126]
	TIME [epoch: 10.4 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05018181460430682		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.05018181460430682 | validation: 0.0521308119472711]
	TIME [epoch: 10.4 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04135111735558664		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.04135111735558664 | validation: 0.07028379934069096]
	TIME [epoch: 10.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04541735351481664		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.04541735351481664 | validation: 0.06573606585164442]
	TIME [epoch: 10.4 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043456311199617854		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.043456311199617854 | validation: 0.04058919762783608]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1782.pth
	Model improved!!!
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041949500775250566		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.041949500775250566 | validation: 0.04452892229971414]
	TIME [epoch: 10.4 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04340304758995679		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.04340304758995679 | validation: 0.0644072331844495]
	TIME [epoch: 10.4 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05753482266426687		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.05753482266426687 | validation: 0.067820666088912]
	TIME [epoch: 10.4 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04543186529018007		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.04543186529018007 | validation: 0.056181457578827775]
	TIME [epoch: 10.4 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03884936642691389		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.03884936642691389 | validation: 0.06071382773150186]
	TIME [epoch: 10.4 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04076033579776205		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.04076033579776205 | validation: 0.06367456027028986]
	TIME [epoch: 10.4 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042966791629003284		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.042966791629003284 | validation: 0.06771638408806915]
	TIME [epoch: 10.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03741009749726756		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.03741009749726756 | validation: 0.059655919965530484]
	TIME [epoch: 10.4 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04553433609692152		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.04553433609692152 | validation: 0.09195803822538996]
	TIME [epoch: 10.4 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04391427459971742		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.04391427459971742 | validation: 0.06579659440408755]
	TIME [epoch: 10.4 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04624743314287433		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.04624743314287433 | validation: 0.05278685774307437]
	TIME [epoch: 10.4 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040002986208979394		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.040002986208979394 | validation: 0.0515608493355774]
	TIME [epoch: 10.4 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05217665539658223		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.05217665539658223 | validation: 0.057257567934324925]
	TIME [epoch: 10.4 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045877255770715955		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.045877255770715955 | validation: 0.0540077663044692]
	TIME [epoch: 10.4 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04606847292960276		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.04606847292960276 | validation: 0.05983815382915848]
	TIME [epoch: 10.4 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04966495139604498		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.04966495139604498 | validation: 0.07720389879939028]
	TIME [epoch: 10.4 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058783676147664866		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.058783676147664866 | validation: 0.06867802388113672]
	TIME [epoch: 10.4 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04808630958040328		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.04808630958040328 | validation: 0.054858386883040455]
	TIME [epoch: 10.4 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04190815571674616		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.04190815571674616 | validation: 0.058451843731051965]
	TIME [epoch: 10.4 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036712989314096854		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.036712989314096854 | validation: 0.05266326105477793]
	TIME [epoch: 10.4 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04875840461653022		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.04875840461653022 | validation: 0.06441032728276433]
	TIME [epoch: 10.4 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04038762144244212		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.04038762144244212 | validation: 0.06616586720772649]
	TIME [epoch: 10.4 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040487851086029356		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.040487851086029356 | validation: 0.04175537061319842]
	TIME [epoch: 10.4 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05237417445599868		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.05237417445599868 | validation: 0.07767736603936427]
	TIME [epoch: 10.4 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05037520359767972		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.05037520359767972 | validation: 0.07199581977621548]
	TIME [epoch: 10.4 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050015184474251184		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.050015184474251184 | validation: 0.06512524071511136]
	TIME [epoch: 10.4 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04511860775996361		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.04511860775996361 | validation: 0.06986154159211036]
	TIME [epoch: 10.4 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04825889761352234		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.04825889761352234 | validation: 0.07242696673138886]
	TIME [epoch: 10.4 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0452599107797581		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.0452599107797581 | validation: 0.07269898647458167]
	TIME [epoch: 10.4 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043010064253135735		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.043010064253135735 | validation: 0.05232859004393447]
	TIME [epoch: 10.4 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046072626830927964		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.046072626830927964 | validation: 0.06360387877330577]
	TIME [epoch: 10.4 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05322414001517258		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.05322414001517258 | validation: 0.064589657596432]
	TIME [epoch: 10.4 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03501318723527334		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.03501318723527334 | validation: 0.0617495951807254]
	TIME [epoch: 10.4 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04922327310783821		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.04922327310783821 | validation: 0.07943651824096046]
	TIME [epoch: 10.4 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04856997765286943		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.04856997765286943 | validation: 0.07946929780184316]
	TIME [epoch: 10.4 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0394334186158535		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.0394334186158535 | validation: 0.07095722371340753]
	TIME [epoch: 10.4 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040496869739691035		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.040496869739691035 | validation: 0.05575950105311511]
	TIME [epoch: 10.4 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04643041253078449		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.04643041253078449 | validation: 0.07600074735537563]
	TIME [epoch: 10.4 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04784103762382942		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.04784103762382942 | validation: 0.08426469966131059]
	TIME [epoch: 10.4 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04777957948160816		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.04777957948160816 | validation: 0.07467965178609409]
	TIME [epoch: 10.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04521902303713725		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.04521902303713725 | validation: 0.0694100145296518]
	TIME [epoch: 10.4 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039697288636926474		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.039697288636926474 | validation: 0.0684396435342608]
	TIME [epoch: 10.4 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049535125182981754		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.049535125182981754 | validation: 0.06589905325522384]
	TIME [epoch: 10.4 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041699355948887434		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.041699355948887434 | validation: 0.06381947798644502]
	TIME [epoch: 10.4 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044570683919158784		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.044570683919158784 | validation: 0.06201047054587098]
	TIME [epoch: 10.4 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046660999030359765		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.046660999030359765 | validation: 0.06858497628561684]
	TIME [epoch: 10.4 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05174765176105989		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.05174765176105989 | validation: 0.04688019735332472]
	TIME [epoch: 10.4 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044139234178220514		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.044139234178220514 | validation: 0.07615548978014264]
	TIME [epoch: 10.4 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04973485212673641		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.04973485212673641 | validation: 0.05933312541494137]
	TIME [epoch: 10.4 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037028648253340984		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.037028648253340984 | validation: 0.06377279651758444]
	TIME [epoch: 10.4 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05177454791690901		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.05177454791690901 | validation: 0.05585366893375847]
	TIME [epoch: 10.4 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04093471902001301		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.04093471902001301 | validation: 0.05023006392579022]
	TIME [epoch: 10.4 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04818401264524029		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.04818401264524029 | validation: 0.06945101762596194]
	TIME [epoch: 10.4 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04516189441073647		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.04516189441073647 | validation: 0.06776930199060431]
	TIME [epoch: 10.4 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06703208768463229		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.06703208768463229 | validation: 0.07403384199598646]
	TIME [epoch: 10.4 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05900247484477694		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.05900247484477694 | validation: 0.05603191077401135]
	TIME [epoch: 10.4 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05581607977726749		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.05581607977726749 | validation: 0.08467976104709711]
	TIME [epoch: 10.4 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054929521470541164		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.054929521470541164 | validation: 0.0632829983811416]
	TIME [epoch: 10.4 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05649990294113225		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.05649990294113225 | validation: 0.06487519963154713]
	TIME [epoch: 10.4 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061509610512032985		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.061509610512032985 | validation: 0.08475018947108957]
	TIME [epoch: 10.4 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07383691770890231		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.07383691770890231 | validation: 0.07761560310624187]
	TIME [epoch: 10.4 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0661919542717175		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.0661919542717175 | validation: 0.08790074397913662]
	TIME [epoch: 10.4 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06322396877920727		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.06322396877920727 | validation: 0.04888345881699079]
	TIME [epoch: 10.4 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05339577776782749		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.05339577776782749 | validation: 0.06617161597279017]
	TIME [epoch: 10.4 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05799778381754996		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.05799778381754996 | validation: 0.07934369388484401]
	TIME [epoch: 10.4 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050899555361448925		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.050899555361448925 | validation: 0.06876905388877935]
	TIME [epoch: 10.4 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04735330091284546		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.04735330091284546 | validation: 0.07478713672915037]
	TIME [epoch: 10.4 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04226778235519173		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.04226778235519173 | validation: 0.07060681846441343]
	TIME [epoch: 10.4 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053630926598737895		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.053630926598737895 | validation: 0.07251930689177838]
	TIME [epoch: 10.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062149320414393264		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.062149320414393264 | validation: 0.08263492970798204]
	TIME [epoch: 10.4 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05012594213373743		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.05012594213373743 | validation: 0.048573189383551194]
	TIME [epoch: 10.4 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048656283950049777		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.048656283950049777 | validation: 0.10684475884803106]
	TIME [epoch: 10.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05221712608228225		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.05221712608228225 | validation: 0.05119476624762665]
	TIME [epoch: 10.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040897336716447345		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.040897336716447345 | validation: 0.0446360401814861]
	TIME [epoch: 10.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044159528086965195		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.044159528086965195 | validation: 0.07882251761304049]
	TIME [epoch: 10.4 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047784058398522906		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.047784058398522906 | validation: 0.06325047105503254]
	TIME [epoch: 10.4 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053109528034393526		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.053109528034393526 | validation: 0.07227209435598277]
	TIME [epoch: 10.4 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047088666347449695		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.047088666347449695 | validation: 0.05261650143999205]
	TIME [epoch: 10.4 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03916041183890274		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.03916041183890274 | validation: 0.041136914853260736]
	TIME [epoch: 10.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04149800350882525		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.04149800350882525 | validation: 0.05295597757895128]
	TIME [epoch: 10.4 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03793917836017473		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.03793917836017473 | validation: 0.04476225688179637]
	TIME [epoch: 10.4 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04038092051742945		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.04038092051742945 | validation: 0.05080187151980915]
	TIME [epoch: 10.4 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047814454632537015		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.047814454632537015 | validation: 0.055333443351740196]
	TIME [epoch: 10.4 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041044066771764275		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.041044066771764275 | validation: 0.05926415293250281]
	TIME [epoch: 10.4 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04431627533757794		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.04431627533757794 | validation: 0.05058174451172347]
	TIME [epoch: 10.4 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04047007444866539		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.04047007444866539 | validation: 0.05401597004774553]
	TIME [epoch: 10.4 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0428644948243808		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.0428644948243808 | validation: 0.05359863009896163]
	TIME [epoch: 10.4 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034901993446897706		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.034901993446897706 | validation: 0.059939133270439524]
	TIME [epoch: 10.3 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04253463234265877		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.04253463234265877 | validation: 0.06509459743301067]
	TIME [epoch: 10.4 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05016973720862167		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.05016973720862167 | validation: 0.08387845716281107]
	TIME [epoch: 10.4 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0431860367797962		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.0431860367797962 | validation: 0.05723360076508801]
	TIME [epoch: 10.4 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04403047806212059		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.04403047806212059 | validation: 0.0594295681935586]
	TIME [epoch: 10.4 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03507863257211204		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.03507863257211204 | validation: 0.044991426178814464]
	TIME [epoch: 10.4 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035186787858290845		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.035186787858290845 | validation: 0.06655334884804107]
	TIME [epoch: 10.4 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042374585981732445		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.042374585981732445 | validation: 0.07684089351902978]
	TIME [epoch: 10.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048464815115313795		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.048464815115313795 | validation: 0.08135012690407646]
	TIME [epoch: 10.4 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045319618464919706		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.045319618464919706 | validation: 0.0679834603175695]
	TIME [epoch: 10.4 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04056207587090944		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.04056207587090944 | validation: 0.06534067580997341]
	TIME [epoch: 10.4 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05470663760961094		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.05470663760961094 | validation: 0.07098758478641555]
	TIME [epoch: 10.4 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045345082782986185		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.045345082782986185 | validation: 0.05367862509044924]
	TIME [epoch: 10.4 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04765260145785098		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.04765260145785098 | validation: 0.0539060903563184]
	TIME [epoch: 10.4 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040652212297469056		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.040652212297469056 | validation: 0.06467212509219562]
	TIME [epoch: 10.4 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054131340060582234		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.054131340060582234 | validation: 0.0657325363571633]
	TIME [epoch: 10.4 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06062355396254907		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.06062355396254907 | validation: 0.07052419765904604]
	TIME [epoch: 10.4 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06307132627609706		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.06307132627609706 | validation: 0.08672420520926286]
	TIME [epoch: 10.4 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062376436555613646		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.062376436555613646 | validation: 0.07872959100946839]
	TIME [epoch: 10.4 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05774526422921696		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.05774526422921696 | validation: 0.09679259562748606]
	TIME [epoch: 10.4 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07486541502424501		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.07486541502424501 | validation: 0.12817296280319718]
	TIME [epoch: 10.4 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07505439868393735		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.07505439868393735 | validation: 0.09608041122414164]
	TIME [epoch: 10.4 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04832900753525741		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.04832900753525741 | validation: 0.06425951033656534]
	TIME [epoch: 10.4 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054171891791801305		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.054171891791801305 | validation: 0.06972222607103624]
	TIME [epoch: 10.4 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07054758011700482		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.07054758011700482 | validation: 0.058979983134716835]
	TIME [epoch: 10.4 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05579421005166259		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.05579421005166259 | validation: 0.03899193454770895]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1895.pth
	Model improved!!!
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04508227808504423		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.04508227808504423 | validation: 0.05417975229583959]
	TIME [epoch: 10.4 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04636645905120364		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.04636645905120364 | validation: 0.04272612645669213]
	TIME [epoch: 10.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03957890898029036		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.03957890898029036 | validation: 0.0575178943686778]
	TIME [epoch: 10.4 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04981628779557652		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.04981628779557652 | validation: 0.0621392680410002]
	TIME [epoch: 10.4 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04078883600020981		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.04078883600020981 | validation: 0.0476392353356596]
	TIME [epoch: 10.4 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050124574646972696		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.050124574646972696 | validation: 0.06603675291851124]
	TIME [epoch: 10.4 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04742809284733708		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.04742809284733708 | validation: 0.05633485959872994]
	TIME [epoch: 10.4 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04124443893216505		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.04124443893216505 | validation: 0.05473006374155534]
	TIME [epoch: 10.4 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055636232513322524		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.055636232513322524 | validation: 0.06733806953644958]
	TIME [epoch: 10.4 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05500300240208726		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.05500300240208726 | validation: 0.05556488058971799]
	TIME [epoch: 10.4 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04959339990561174		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.04959339990561174 | validation: 0.05835263722581119]
	TIME [epoch: 10.4 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04479058188482741		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.04479058188482741 | validation: 0.058242527302555226]
	TIME [epoch: 10.3 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044012295591253435		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.044012295591253435 | validation: 0.07590304098402383]
	TIME [epoch: 10.4 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040777896592688		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.040777896592688 | validation: 0.05854150300637516]
	TIME [epoch: 10.4 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04072854425702556		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.04072854425702556 | validation: 0.055106715239769156]
	TIME [epoch: 10.4 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03605049782722758		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.03605049782722758 | validation: 0.03709741715856406]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1911.pth
	Model improved!!!
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03760847407133874		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.03760847407133874 | validation: 0.06213174898596623]
	TIME [epoch: 10.4 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04048775750800833		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.04048775750800833 | validation: 0.05596901550407712]
	TIME [epoch: 10.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034042769193521207		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.034042769193521207 | validation: 0.06556711392455399]
	TIME [epoch: 10.4 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03962027877639279		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.03962027877639279 | validation: 0.06759253472906127]
	TIME [epoch: 10.4 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0389131171252296		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.0389131171252296 | validation: 0.060032764647259665]
	TIME [epoch: 10.4 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041427881196333165		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.041427881196333165 | validation: 0.05373947448308502]
	TIME [epoch: 10.4 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04311996277973572		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.04311996277973572 | validation: 0.049555824287282245]
	TIME [epoch: 10.4 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046217905051929756		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.046217905051929756 | validation: 0.05607289002059311]
	TIME [epoch: 10.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05317524662894548		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.05317524662894548 | validation: 0.07671372030646689]
	TIME [epoch: 10.4 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05068652917251944		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.05068652917251944 | validation: 0.06059031365539393]
	TIME [epoch: 10.4 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04662671036979861		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.04662671036979861 | validation: 0.07788932169765621]
	TIME [epoch: 10.4 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04768925094498264		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.04768925094498264 | validation: 0.10725105897117314]
	TIME [epoch: 10.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04175585402649945		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.04175585402649945 | validation: 0.06520504734594351]
	TIME [epoch: 10.4 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03804452456815052		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.03804452456815052 | validation: 0.06338079274061928]
	TIME [epoch: 10.4 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039474264874217214		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.039474264874217214 | validation: 0.05749197543770457]
	TIME [epoch: 10.4 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04503147436565931		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.04503147436565931 | validation: 0.07085456636912088]
	TIME [epoch: 10.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05183347817244488		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.05183347817244488 | validation: 0.068403345722399]
	TIME [epoch: 10.4 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05140642736898351		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.05140642736898351 | validation: 0.05544802618533986]
	TIME [epoch: 10.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0441585073422299		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.0441585073422299 | validation: 0.05147331731184235]
	TIME [epoch: 10.4 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040134460321418305		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.040134460321418305 | validation: 0.059317698947532964]
	TIME [epoch: 10.4 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037653130948007964		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.037653130948007964 | validation: 0.05649178758307072]
	TIME [epoch: 10.4 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04153984152090926		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.04153984152090926 | validation: 0.056165862210223544]
	TIME [epoch: 10.4 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036578795116755276		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.036578795116755276 | validation: 0.05445070820509068]
	TIME [epoch: 10.4 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04457911454610839		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.04457911454610839 | validation: 0.0586934840730167]
	TIME [epoch: 10.4 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045880118069464966		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.045880118069464966 | validation: 0.0679051803238359]
	TIME [epoch: 10.4 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038372388531192125		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.038372388531192125 | validation: 0.059281166747230496]
	TIME [epoch: 10.4 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04021311531287709		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.04021311531287709 | validation: 0.07393542383947642]
	TIME [epoch: 10.4 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04422480943952741		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.04422480943952741 | validation: 0.07811806666635518]
	TIME [epoch: 10.4 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04171905559478374		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.04171905559478374 | validation: 0.05848760781293459]
	TIME [epoch: 10.4 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0424343626720408		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.0424343626720408 | validation: 0.04699641213828141]
	TIME [epoch: 10.4 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03611451528037152		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.03611451528037152 | validation: 0.07838764065943633]
	TIME [epoch: 10.4 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04481747734151017		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.04481747734151017 | validation: 0.058712914437533056]
	TIME [epoch: 10.4 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03207908298785776		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.03207908298785776 | validation: 0.06326093701061994]
	TIME [epoch: 10.4 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029285332801360853		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.029285332801360853 | validation: 0.07299897732949041]
	TIME [epoch: 10.4 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03993837146468587		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.03993837146468587 | validation: 0.07797423570233543]
	TIME [epoch: 10.4 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0408243064739812		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.0408243064739812 | validation: 0.10109111609415365]
	TIME [epoch: 10.4 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044317247644078336		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.044317247644078336 | validation: 0.09146603063114128]
	TIME [epoch: 10.4 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045396504183912056		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.045396504183912056 | validation: 0.07058898270552204]
	TIME [epoch: 10.4 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032353045709771336		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.032353045709771336 | validation: 0.053423571722402086]
	TIME [epoch: 10.4 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042792753826085106		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.042792753826085106 | validation: 0.04554507084221461]
	TIME [epoch: 10.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04141451061973857		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.04141451061973857 | validation: 0.06708263844273256]
	TIME [epoch: 10.4 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04981526549968988		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.04981526549968988 | validation: 0.06843280648042513]
	TIME [epoch: 10.4 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04548233956736695		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.04548233956736695 | validation: 0.06833700146543448]
	TIME [epoch: 10.4 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04170994546344052		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.04170994546344052 | validation: 0.04268331983962446]
	TIME [epoch: 10.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03608651489752436		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.03608651489752436 | validation: 0.06737135137185052]
	TIME [epoch: 10.4 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043215520812113675		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.043215520812113675 | validation: 0.06423345984748544]
	TIME [epoch: 10.4 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034474227254332225		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.034474227254332225 | validation: 0.05129936483333882]
	TIME [epoch: 10.4 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0354667965483484		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.0354667965483484 | validation: 0.06981145037571823]
	TIME [epoch: 10.4 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04312899662743367		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.04312899662743367 | validation: 0.07468218351644643]
	TIME [epoch: 10.4 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04584900908603482		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.04584900908603482 | validation: 0.06644748501837602]
	TIME [epoch: 10.4 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05162015416323682		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.05162015416323682 | validation: 0.07952423934916766]
	TIME [epoch: 10.4 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047507993276626394		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.047507993276626394 | validation: 0.09436961809891076]
	TIME [epoch: 10.4 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041801012084624764		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.041801012084624764 | validation: 0.06044848039976785]
	TIME [epoch: 10.4 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05175197153613649		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.05175197153613649 | validation: 0.051833347738957]
	TIME [epoch: 10.4 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05291511005326353		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.05291511005326353 | validation: 0.07803066483298243]
	TIME [epoch: 10.4 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05452746983853909		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.05452746983853909 | validation: 0.06276223678121742]
	TIME [epoch: 10.4 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0417696130273135		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.0417696130273135 | validation: 0.05974096698946623]
	TIME [epoch: 10.4 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0422904112294554		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.0422904112294554 | validation: 0.07634356586412858]
	TIME [epoch: 10.4 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0462693909915056		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.0462693909915056 | validation: 0.04972687286456992]
	TIME [epoch: 10.4 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04368902552895707		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.04368902552895707 | validation: 0.06179284526589679]
	TIME [epoch: 10.3 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04045919784398179		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.04045919784398179 | validation: 0.06492747232792415]
	TIME [epoch: 10.4 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044866633371166476		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.044866633371166476 | validation: 0.06913456992173453]
	TIME [epoch: 10.4 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041952868481601895		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.041952868481601895 | validation: 0.03535541400509109]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1974.pth
	Model improved!!!
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04491387270015909		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.04491387270015909 | validation: 0.05253115904922661]
	TIME [epoch: 10.3 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05175949789252019		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.05175949789252019 | validation: 0.05811498071388599]
	TIME [epoch: 10.4 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04929567395749572		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.04929567395749572 | validation: 0.06566002147980705]
	TIME [epoch: 10.4 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0519984848863691		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.0519984848863691 | validation: 0.07180036773534365]
	TIME [epoch: 10.4 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04554707454546175		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.04554707454546175 | validation: 0.06410004769182921]
	TIME [epoch: 10.4 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039823935220670195		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.039823935220670195 | validation: 0.03192875452025862]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240219_183143/states/model_tr_study5_1980.pth
	Model improved!!!
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0467863302671934		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.0467863302671934 | validation: 0.07145853284224815]
	TIME [epoch: 10.4 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04465187652461722		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.04465187652461722 | validation: 0.052339346443716864]
	TIME [epoch: 10.4 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03567743553327585		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.03567743553327585 | validation: 0.06948372915473405]
	TIME [epoch: 10.4 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042009170964628535		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.042009170964628535 | validation: 0.04918127466325774]
	TIME [epoch: 10.4 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039644150249166454		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.039644150249166454 | validation: 0.0523699024212185]
	TIME [epoch: 10.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04075935280616554		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.04075935280616554 | validation: 0.07870633019220966]
	TIME [epoch: 10.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042041574379206366		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.042041574379206366 | validation: 0.06654218316168996]
	TIME [epoch: 10.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0353685375476422		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.0353685375476422 | validation: 0.06205672286921425]
	TIME [epoch: 10.3 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04064377960352185		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.04064377960352185 | validation: 0.0801165327723329]
	TIME [epoch: 10.3 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04515700410363242		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.04515700410363242 | validation: 0.08117920274339036]
	TIME [epoch: 10.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05059150616769349		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.05059150616769349 | validation: 0.12193381067445301]
	TIME [epoch: 10.3 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05591944821604437		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.05591944821604437 | validation: 0.08690680195388296]
	TIME [epoch: 10.3 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041572692287468974		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.041572692287468974 | validation: 0.07256588902719668]
	TIME [epoch: 10.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037380403354969303		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.037380403354969303 | validation: 0.07118723586702475]
	TIME [epoch: 10.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0415588267573397		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.0415588267573397 | validation: 0.06533840092885919]
	TIME [epoch: 10.3 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0429044884213167		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.0429044884213167 | validation: 0.08875228037985489]
	TIME [epoch: 10.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05141171991430447		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.05141171991430447 | validation: 0.08121470152715347]
	TIME [epoch: 10.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04590426157335224		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.04590426157335224 | validation: 0.05511863757208601]
	TIME [epoch: 10.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041292467796606794		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.041292467796606794 | validation: 0.06452005234034448]
	TIME [epoch: 10.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04603775213757488		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.04603775213757488 | validation: 0.06372290774870616]
	TIME [epoch: 10.3 sec]
Finished training in 20876.077 seconds.
