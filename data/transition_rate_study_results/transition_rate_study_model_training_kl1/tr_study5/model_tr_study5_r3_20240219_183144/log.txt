Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3189395899

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.799549722124047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.799549722124047 | validation: 12.385609671169545]
	TIME [epoch: 54.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.69596981975084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.69596981975084 | validation: 12.03338918913851]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.030878926893443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.030878926893443 | validation: 11.244367561862935]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.739925954025717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.739925954025717 | validation: 11.074933897653478]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.37487650884102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.37487650884102 | validation: 10.75967784448649]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.865343921831677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.865343921831677 | validation: 10.416008787870833]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.534057437613923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.534057437613923 | validation: 10.299407208961771]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.418094371474314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.418094371474314 | validation: 10.295596894437688]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.304660594596939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.304660594596939 | validation: 10.088641904898422]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.071339966071829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.071339966071829 | validation: 9.926931296970908]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.86633218778244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.86633218778244 | validation: 9.777927405685592]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.683847645767743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.683847645767743 | validation: 9.301232814473662]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.241934920008074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.241934920008074 | validation: 9.056005884985128]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.547852290894493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.547852290894493 | validation: 9.7498398475211]
	TIME [epoch: 9.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.897455989517292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.897455989517292 | validation: 7.730030234734973]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.924763423360457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.924763423360457 | validation: 7.638905173628678]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.092078337064028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.092078337064028 | validation: 7.46163998637905]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.836979348020797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.836979348020797 | validation: 7.711067198017873]
	TIME [epoch: 9.52 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.8828045814534375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8828045814534375 | validation: 8.135861671577025]
	TIME [epoch: 9.52 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.952596441408521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.952596441408521 | validation: 7.209970588623182]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.706979469092717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706979469092717 | validation: 7.110643761687169]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6529834645098775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6529834645098775 | validation: 7.2858984359488845]
	TIME [epoch: 9.52 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.667799835102462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.667799835102462 | validation: 7.164795216128027]
	TIME [epoch: 9.54 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.62444297219875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.62444297219875 | validation: 7.525098025758]
	TIME [epoch: 9.52 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.887788903771882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.887788903771882 | validation: 7.111489288753643]
	TIME [epoch: 9.52 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.698298166104385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.698298166104385 | validation: 7.160679808476061]
	TIME [epoch: 9.52 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.591873358496199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.591873358496199 | validation: 7.176614440854134]
	TIME [epoch: 9.54 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.894883510146748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.894883510146748 | validation: 7.387914520629583]
	TIME [epoch: 9.52 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.945671853021151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.945671853021151 | validation: 7.191770472298282]
	TIME [epoch: 9.52 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.746353543072904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.746353543072904 | validation: 7.760042882665284]
	TIME [epoch: 9.54 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.799572123760038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.799572123760038 | validation: 7.215830900492928]
	TIME [epoch: 9.52 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.651243227872731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.651243227872731 | validation: 7.105071048712228]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.605449335970282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.605449335970282 | validation: 7.20259888360396]
	TIME [epoch: 9.52 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.807376159982999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.807376159982999 | validation: 7.134504041100314]
	TIME [epoch: 9.54 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.643363979451675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.643363979451675 | validation: 7.046137364409251]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.571494836352931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.571494836352931 | validation: 7.067646863633816]
	TIME [epoch: 9.51 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.1430605091488175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1430605091488175 | validation: 7.046344113948276]
	TIME [epoch: 9.53 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.68538774680186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.68538774680186 | validation: 7.107064612055549]
	TIME [epoch: 9.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.523542272551007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.523542272551007 | validation: 6.96707464880671]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6351080198893255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6351080198893255 | validation: 7.143568815160078]
	TIME [epoch: 9.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5468334724637245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5468334724637245 | validation: 7.149706904448936]
	TIME [epoch: 9.53 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.529541970158673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.529541970158673 | validation: 6.974806856393879]
	TIME [epoch: 9.51 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.663352526082167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.663352526082167 | validation: 7.141205082790312]
	TIME [epoch: 9.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.577978203274867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.577978203274867 | validation: 6.996875354339372]
	TIME [epoch: 9.51 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4965526834191225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4965526834191225 | validation: 7.278796123397624]
	TIME [epoch: 9.53 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.503054964769616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.503054964769616 | validation: 7.047630550895531]
	TIME [epoch: 9.51 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4217659003393806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4217659003393806 | validation: 7.217859712192213]
	TIME [epoch: 9.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.636993327256238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.636993327256238 | validation: 7.21464521674347]
	TIME [epoch: 9.52 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.446012224327563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.446012224327563 | validation: 6.942094978481565]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.352741638098548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.352741638098548 | validation: 6.987818480016704]
	TIME [epoch: 9.51 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.337712021323128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.337712021323128 | validation: 7.151980492463141]
	TIME [epoch: 9.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.591606973508759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.591606973508759 | validation: 6.883637108677881]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.318402416939832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.318402416939832 | validation: 6.841689101290731]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.220204704769241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220204704769241 | validation: 6.797091651908325]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.257600502252717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.257600502252717 | validation: 6.807553308225058]
	TIME [epoch: 9.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.298474574709038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.298474574709038 | validation: 6.903073801238438]
	TIME [epoch: 9.52 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.176997663653357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.176997663653357 | validation: 6.7130286177325935]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.156414275964914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.156414275964914 | validation: 7.041443189524134]
	TIME [epoch: 9.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.320260098894881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.320260098894881 | validation: 6.744246160756278]
	TIME [epoch: 9.52 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.247359047002797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.247359047002797 | validation: 6.667460808300839]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.114713974829792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.114713974829792 | validation: 6.924785093098558]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.099092234499704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.099092234499704 | validation: 6.712471117787523]
	TIME [epoch: 9.52 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.094860648411999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.094860648411999 | validation: 6.596378198075546]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.153524205702381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153524205702381 | validation: 6.743341942505428]
	TIME [epoch: 9.52 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.051520205919985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.051520205919985 | validation: 6.882710831878782]
	TIME [epoch: 9.52 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.011884602521688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.011884602521688 | validation: 6.547149687518104]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.115106881623371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.115106881623371 | validation: 6.471983336270407]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.957072148060615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.957072148060615 | validation: 6.561372717031918]
	TIME [epoch: 9.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.907828608631148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.907828608631148 | validation: 6.755535159131541]
	TIME [epoch: 9.51 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9743918032558945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9743918032558945 | validation: 6.725952067773221]
	TIME [epoch: 9.53 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.082634953663449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.082634953663449 | validation: 6.968290160745125]
	TIME [epoch: 9.51 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.107399932419483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.107399932419483 | validation: 6.579362249434521]
	TIME [epoch: 9.51 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.028332770463618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.028332770463618 | validation: 6.484038628634616]
	TIME [epoch: 9.51 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.891120893298909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.891120893298909 | validation: 6.801584904264005]
	TIME [epoch: 9.53 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.85949646392009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.85949646392009 | validation: 6.500359287109441]
	TIME [epoch: 9.51 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.839577102150533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.839577102150533 | validation: 6.383519783957791]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.875652175508476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.875652175508476 | validation: 6.515153561699779]
	TIME [epoch: 9.53 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.837362247366298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.837362247366298 | validation: 6.493194699364481]
	TIME [epoch: 9.51 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.316667184254457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.316667184254457 | validation: 6.534852114146438]
	TIME [epoch: 9.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.904132952093483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.904132952093483 | validation: 6.454476948854449]
	TIME [epoch: 9.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.836448161512649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.836448161512649 | validation: 6.679606091571973]
	TIME [epoch: 9.53 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.982100251398233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.982100251398233 | validation: 6.55189220135708]
	TIME [epoch: 9.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.798715323306231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.798715323306231 | validation: 6.884776347698754]
	TIME [epoch: 9.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.088620618447612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.088620618447612 | validation: 6.375426590541007]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.807771635727856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.807771635727856 | validation: 6.486938893519106]
	TIME [epoch: 9.52 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.937789394863026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.937789394863026 | validation: 6.41677711788187]
	TIME [epoch: 9.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.844720303650819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.844720303650819 | validation: 6.4671291316125545]
	TIME [epoch: 9.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.855933140891001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.855933140891001 | validation: 6.8232418860399955]
	TIME [epoch: 9.52 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.939900687149143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.939900687149143 | validation: 6.459298718901937]
	TIME [epoch: 9.51 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.834639898232824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834639898232824 | validation: 6.308759911803739]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.811820376507453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.811820376507453 | validation: 6.420444531733424]
	TIME [epoch: 9.51 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7920091148453015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7920091148453015 | validation: 6.355581733777276]
	TIME [epoch: 9.52 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.854067275606784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.854067275606784 | validation: 6.825793223945465]
	TIME [epoch: 9.49 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.010215800567963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.010215800567963 | validation: 6.348236895660612]
	TIME [epoch: 9.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.869898327823142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.869898327823142 | validation: 6.468748600619599]
	TIME [epoch: 9.51 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.760844754047477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.760844754047477 | validation: 6.322254048215864]
	TIME [epoch: 9.51 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.785000254910149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.785000254910149 | validation: 6.481277899263893]
	TIME [epoch: 9.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.877885573523755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.877885573523755 | validation: 6.394421255336652]
	TIME [epoch: 9.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.71766687104628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.71766687104628 | validation: 6.454776091057219]
	TIME [epoch: 9.53 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8387777577314095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8387777577314095 | validation: 6.302035009659797]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.698997464166187		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 5.698997464166187 | validation: 6.478892560602348]
	TIME [epoch: 9.51 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.798976720921038		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 5.798976720921038 | validation: 6.361461792500326]
	TIME [epoch: 9.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.743660714872539		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 5.743660714872539 | validation: 6.390362745450853]
	TIME [epoch: 9.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.921173117033193		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 5.921173117033193 | validation: 6.419224426710207]
	TIME [epoch: 9.51 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.811528082208637		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 5.811528082208637 | validation: 6.397739624011957]
	TIME [epoch: 9.49 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.779235081616814		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 5.779235081616814 | validation: 6.561399920093841]
	TIME [epoch: 9.51 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.885753558047734		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 5.885753558047734 | validation: 6.42669119897557]
	TIME [epoch: 9.51 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.71901714184767		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 5.71901714184767 | validation: 7.218951844824667]
	TIME [epoch: 9.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.160432068502029		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 6.160432068502029 | validation: 6.396201339149739]
	TIME [epoch: 9.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7542403301286384		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 5.7542403301286384 | validation: 6.398468097076035]
	TIME [epoch: 9.53 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7683097006545285		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 5.7683097006545285 | validation: 6.246691855019383]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.657313354726364		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 5.657313354726364 | validation: 6.574816459046917]
	TIME [epoch: 9.51 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7537799392787194		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 5.7537799392787194 | validation: 6.488147458724345]
	TIME [epoch: 9.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.821218937140316		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 5.821218937140316 | validation: 6.332415573589456]
	TIME [epoch: 9.52 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.665855617256893		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 5.665855617256893 | validation: 7.133200617439363]
	TIME [epoch: 9.51 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.993348251179488		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 5.993348251179488 | validation: 6.293987058995439]
	TIME [epoch: 9.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.683962549226735		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 5.683962549226735 | validation: 6.278792076142895]
	TIME [epoch: 9.51 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.654531316958883		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 5.654531316958883 | validation: 6.494908311947856]
	TIME [epoch: 9.51 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.735965556700223		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 5.735965556700223 | validation: 6.33611872202938]
	TIME [epoch: 9.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.773675993902964		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 5.773675993902964 | validation: 6.3979854443142745]
	TIME [epoch: 9.49 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.719606027033713		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 5.719606027033713 | validation: 6.284717566752798]
	TIME [epoch: 9.52 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.621226040434038		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 5.621226040434038 | validation: 6.143157288368489]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.568931255362519		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 5.568931255362519 | validation: 6.248573394865322]
	TIME [epoch: 9.51 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.599958738994475		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 5.599958738994475 | validation: 6.899670022639618]
	TIME [epoch: 9.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.824455654330056		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 5.824455654330056 | validation: 6.427684455483793]
	TIME [epoch: 9.52 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7795149171456135		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 5.7795149171456135 | validation: 6.789536382562301]
	TIME [epoch: 9.51 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.757953672871912		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 5.757953672871912 | validation: 6.1950611676192455]
	TIME [epoch: 9.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5909549642026946		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 5.5909549642026946 | validation: 6.1453282547761425]
	TIME [epoch: 9.52 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.437074893267948		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 5.437074893267948 | validation: 6.100409077508657]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.175291305599244		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 5.175291305599244 | validation: 5.615954108453008]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.654479208264686		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 4.654479208264686 | validation: 4.189262115360552]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3394705001171525		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 4.3394705001171525 | validation: 4.582479026372917]
	TIME [epoch: 9.53 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.127968427739237		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 4.127968427739237 | validation: 4.535494011278561]
	TIME [epoch: 9.51 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7690605309673324		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 3.7690605309673324 | validation: 3.653156712438524]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.262357665023926		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 3.262357665023926 | validation: 3.44910436875596]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8940766237913054		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 3.8940766237913054 | validation: 3.752224876846434]
	TIME [epoch: 9.51 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4034550270077255		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 3.4034550270077255 | validation: 3.5846800185914187]
	TIME [epoch: 9.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.333124294445672		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 3.333124294445672 | validation: 3.545672252732153]
	TIME [epoch: 9.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2687984171526194		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 3.2687984171526194 | validation: 3.830378637829449]
	TIME [epoch: 9.52 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2218898524133026		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 3.2218898524133026 | validation: 3.3370123355494212]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3170709229997835		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 3.3170709229997835 | validation: 3.314957082830931]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0571868928451993		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 3.0571868928451993 | validation: 3.35930601426589]
	TIME [epoch: 9.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.110249951311951		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 3.110249951311951 | validation: 3.2304359219019183]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.819292400454473		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 2.819292400454473 | validation: 3.3952490422739787]
	TIME [epoch: 9.49 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.919037433246487		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 2.919037433246487 | validation: 3.1233577772315617]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.462788987777246		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 3.462788987777246 | validation: 2.9684821323848958]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6718300317366954		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 2.6718300317366954 | validation: 4.736893576823588]
	TIME [epoch: 9.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.235162088845043		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 5.235162088845043 | validation: 5.720206156217097]
	TIME [epoch: 9.49 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9244042318450525		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 4.9244042318450525 | validation: 5.655956291429906]
	TIME [epoch: 9.49 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.833809846296893		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 4.833809846296893 | validation: 3.6196428373220364]
	TIME [epoch: 9.51 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6636812477589293		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 3.6636812477589293 | validation: 2.8163239843717243]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.888706976419216		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 2.888706976419216 | validation: 2.79278627095807]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.489541861461736		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 2.489541861461736 | validation: 2.2545587733901935]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.19245165290605		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 4.19245165290605 | validation: 7.856572857356148]
	TIME [epoch: 9.52 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.430865005950229		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 7.430865005950229 | validation: 6.648201492583257]
	TIME [epoch: 9.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.426468302749061		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 5.426468302749061 | validation: 3.9457808576922737]
	TIME [epoch: 9.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2674130278466196		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 3.2674130278466196 | validation: 2.3317754380754936]
	TIME [epoch: 9.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.314608642931727		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 2.314608642931727 | validation: 2.421143802866833]
	TIME [epoch: 9.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3163279829189785		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 2.3163279829189785 | validation: 2.6512828134527546]
	TIME [epoch: 9.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3464345122444725		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 2.3464345122444725 | validation: 1.86616805642174]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.215050684104315		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 2.215050684104315 | validation: 2.1046014567798625]
	TIME [epoch: 9.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1031316675959104		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 2.1031316675959104 | validation: 1.760110364281814]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.132090894750765		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 2.132090894750765 | validation: 4.3640950117119575]
	TIME [epoch: 9.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.772084400376863		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 2.772084400376863 | validation: 1.942426177363372]
	TIME [epoch: 9.51 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7802676648758364		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 1.7802676648758364 | validation: 1.6107037201092151]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0368624982392327		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 2.0368624982392327 | validation: 1.425602597479983]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1047630137178324		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 2.1047630137178324 | validation: 1.786308431680298]
	TIME [epoch: 9.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1919553713673174		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 2.1919553713673174 | validation: 2.991878902230268]
	TIME [epoch: 9.51 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9471303862720497		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 1.9471303862720497 | validation: 3.1055292618086994]
	TIME [epoch: 9.49 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3206391861557405		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 2.3206391861557405 | validation: 1.609464913103713]
	TIME [epoch: 9.49 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.054837233185235		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 2.054837233185235 | validation: 1.8756583199616572]
	TIME [epoch: 9.51 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5869786291957797		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.5869786291957797 | validation: 1.4995552010606372]
	TIME [epoch: 9.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.326212231335386		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 2.326212231335386 | validation: 1.765712454862502]
	TIME [epoch: 9.49 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6536839607344767		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.6536839607344767 | validation: 1.2212559874293027]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.335300650730882		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 1.335300650730882 | validation: 1.699565687565604]
	TIME [epoch: 9.51 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8909334648034135		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.8909334648034135 | validation: 1.734221844303761]
	TIME [epoch: 9.49 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3752746523593888		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.3752746523593888 | validation: 1.1865147108904723]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5236078941879194		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.5236078941879194 | validation: 1.7059566669809323]
	TIME [epoch: 9.49 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7359130640712594		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 2.7359130640712594 | validation: 2.5994855958608163]
	TIME [epoch: 9.52 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9876939422907582		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.9876939422907582 | validation: 1.1988533124460607]
	TIME [epoch: 9.49 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2261601996246787		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 2.2261601996246787 | validation: 1.2638714825924273]
	TIME [epoch: 9.49 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8763642545609547		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.8763642545609547 | validation: 2.7054888681695717]
	TIME [epoch: 9.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.638772493632446		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 1.638772493632446 | validation: 1.0491639875945067]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2402709663991904		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.2402709663991904 | validation: 1.0327164338522499]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2008115422804444		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 1.2008115422804444 | validation: 1.0810280348062176]
	TIME [epoch: 9.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8132087568387827		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.8132087568387827 | validation: 1.791580622258604]
	TIME [epoch: 9.52 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5194654343318637		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.5194654343318637 | validation: 1.0810773772613766]
	TIME [epoch: 9.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3432821327289968		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.3432821327289968 | validation: 1.786146310415765]
	TIME [epoch: 9.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4559268044290659		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.4559268044290659 | validation: 0.8911724843548985]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.142675178496591		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.142675178496591 | validation: 1.1778532783377391]
	TIME [epoch: 9.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2623668184588126		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 1.2623668184588126 | validation: 1.2497388341309474]
	TIME [epoch: 9.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8223933523101288		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.8223933523101288 | validation: 1.8009356149565081]
	TIME [epoch: 9.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7155773849478781		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 1.7155773849478781 | validation: 0.7847735197070332]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1197345228344537		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.1197345228344537 | validation: 1.2964847890950466]
	TIME [epoch: 9.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0761544842410842		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 1.0761544842410842 | validation: 0.6688471415344343]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1378278121501317		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.1378278121501317 | validation: 0.7899072576084784]
	TIME [epoch: 9.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1972122180968643		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.1972122180968643 | validation: 1.0819138326687852]
	TIME [epoch: 9.51 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1777074798079892		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.1777074798079892 | validation: 0.8249792176923306]
	TIME [epoch: 9.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0230152707025704		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 1.0230152707025704 | validation: 1.2750921512879498]
	TIME [epoch: 9.49 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9216279597082885		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.9216279597082885 | validation: 1.0041685535838796]
	TIME [epoch: 9.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0802595773711725		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 1.0802595773711725 | validation: 0.8213049964773768]
	TIME [epoch: 9.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5183664707731956		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.5183664707731956 | validation: 1.646268703251019]
	TIME [epoch: 9.49 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7735553093725067		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 1.7735553093725067 | validation: 1.574954731239464]
	TIME [epoch: 9.49 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6882364301061372		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.6882364301061372 | validation: 1.1928397555868395]
	TIME [epoch: 9.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3249240140578524		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 1.3249240140578524 | validation: 1.0692385546346803]
	TIME [epoch: 9.49 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.026086637300836		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.026086637300836 | validation: 0.7096945844215222]
	TIME [epoch: 9.49 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3315953745972544		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.3315953745972544 | validation: 0.8733115209487824]
	TIME [epoch: 9.49 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9765962018948325		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.9765962018948325 | validation: 1.533779236272573]
	TIME [epoch: 9.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3545789780211361		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 1.3545789780211361 | validation: 0.8880412777810915]
	TIME [epoch: 9.49 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9560133545255709		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.9560133545255709 | validation: 0.5317140924651435]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8502866446468426		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 0.8502866446468426 | validation: 0.6786454776559094]
	TIME [epoch: 9.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9897399822473787		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.9897399822473787 | validation: 1.65848236839646]
	TIME [epoch: 9.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9744558539222808		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 0.9744558539222808 | validation: 1.0132993126873004]
	TIME [epoch: 9.49 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8205264149232484		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.8205264149232484 | validation: 0.881791369465329]
	TIME [epoch: 9.48 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9659101524639526		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 0.9659101524639526 | validation: 1.3128453743515656]
	TIME [epoch: 9.51 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3861463122008313		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.3861463122008313 | validation: 1.2562080619933718]
	TIME [epoch: 9.49 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.232582881894569		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 1.232582881894569 | validation: 0.8907498716982059]
	TIME [epoch: 9.48 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9973226808318516		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.9973226808318516 | validation: 0.9290424522852624]
	TIME [epoch: 9.49 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8190825387776167		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 0.8190825387776167 | validation: 0.6503208654758441]
	TIME [epoch: 9.51 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9003876788268134		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.9003876788268134 | validation: 1.909619009379345]
	TIME [epoch: 9.49 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2672587835968392		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 1.2672587835968392 | validation: 0.7347892722262732]
	TIME [epoch: 9.48 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1021125073305211		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.1021125073305211 | validation: 1.2667308888517306]
	TIME [epoch: 9.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0205445831158129		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 1.0205445831158129 | validation: 0.7896343781334122]
	TIME [epoch: 9.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8131458082422374		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.8131458082422374 | validation: 1.3995068454425863]
	TIME [epoch: 9.49 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8248325679840948		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.8248325679840948 | validation: 0.9580225185464333]
	TIME [epoch: 9.48 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9713217148871685		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.9713217148871685 | validation: 1.055680203681686]
	TIME [epoch: 9.51 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.010058352332758		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 1.010058352332758 | validation: 0.780887058698749]
	TIME [epoch: 9.49 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521962366204679		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.7521962366204679 | validation: 1.2132673735598958]
	TIME [epoch: 9.48 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9899349351032631		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.9899349351032631 | validation: 0.7868588453733137]
	TIME [epoch: 9.48 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.797355082391477		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.797355082391477 | validation: 0.8690523834291193]
	TIME [epoch: 9.51 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8478099940768378		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.8478099940768378 | validation: 1.289818986065773]
	TIME [epoch: 9.48 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0006026474996945		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.0006026474996945 | validation: 0.5953101705678205]
	TIME [epoch: 9.49 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4056926584813294		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 1.4056926584813294 | validation: 2.297372665207917]
	TIME [epoch: 9.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.538532367769212		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.538532367769212 | validation: 0.945062316052435]
	TIME [epoch: 9.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2353988925633461		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 1.2353988925633461 | validation: 1.218166959478462]
	TIME [epoch: 9.48 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3702121714375266		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.3702121714375266 | validation: 1.0507164884298985]
	TIME [epoch: 9.49 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8804513696342081		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 0.8804513696342081 | validation: 0.7927701588391872]
	TIME [epoch: 9.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8745168225615452		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.8745168225615452 | validation: 0.8672471400688572]
	TIME [epoch: 9.49 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8450215846310506		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 0.8450215846310506 | validation: 1.1106471245872376]
	TIME [epoch: 9.49 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0069246219637624		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.0069246219637624 | validation: 0.6973593537589937]
	TIME [epoch: 9.49 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.895009122172436		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 0.895009122172436 | validation: 0.9604590148885325]
	TIME [epoch: 9.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8073843934539287		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.8073843934539287 | validation: 0.522005084983111]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8800517441890212		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 0.8800517441890212 | validation: 0.9846410631242756]
	TIME [epoch: 9.49 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7571808068830392		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.7571808068830392 | validation: 0.9172352901788883]
	TIME [epoch: 9.49 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521385985064496		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.7521385985064496 | validation: 1.1387404425482235]
	TIME [epoch: 9.49 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7627715664495153		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.7627715664495153 | validation: 1.2483293669523021]
	TIME [epoch: 9.48 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.877985754161387		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 0.877985754161387 | validation: 1.1754306650148156]
	TIME [epoch: 9.48 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.616299197801856		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.616299197801856 | validation: 1.0516862122972872]
	TIME [epoch: 9.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1939899495347954		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 1.1939899495347954 | validation: 1.2077276037734528]
	TIME [epoch: 9.49 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8325823093383711		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.8325823093383711 | validation: 1.2156942842374443]
	TIME [epoch: 9.48 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9474026383121936		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.9474026383121936 | validation: 0.9523642939517845]
	TIME [epoch: 9.48 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8515496715657672		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.8515496715657672 | validation: 0.43646909549453283]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3308739711511741		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 1.3308739711511741 | validation: 0.8129010400490944]
	TIME [epoch: 9.49 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9844845448955708		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.9844845448955708 | validation: 0.8923933087769385]
	TIME [epoch: 9.49 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1421006096196846		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 2.1421006096196846 | validation: 1.3129792199202825]
	TIME [epoch: 9.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6867828157578817		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 2.6867828157578817 | validation: 1.2768395213145483]
	TIME [epoch: 9.49 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2139798276430624		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 1.2139798276430624 | validation: 0.8700472676180558]
	TIME [epoch: 9.49 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024820936042213		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.9024820936042213 | validation: 1.34622648839678]
	TIME [epoch: 9.49 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1717829474067007		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 1.1717829474067007 | validation: 2.180047556146771]
	TIME [epoch: 9.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9204870958747449		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.9204870958747449 | validation: 0.8189608007791722]
	TIME [epoch: 9.49 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8605247096266428		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 0.8605247096266428 | validation: 0.833727833924029]
	TIME [epoch: 9.49 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8536052788168726		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.8536052788168726 | validation: 0.7484661986401696]
	TIME [epoch: 9.49 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8021060840562402		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 0.8021060840562402 | validation: 1.283111483107448]
	TIME [epoch: 9.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9594806995105067		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.9594806995105067 | validation: 1.3992765927207498]
	TIME [epoch: 9.48 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0910120503999294		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 1.0910120503999294 | validation: 0.9343371645569022]
	TIME [epoch: 9.49 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8427705151035836		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.8427705151035836 | validation: 1.159220087150297]
	TIME [epoch: 9.49 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2347918269665665		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 1.2347918269665665 | validation: 0.9682256203386408]
	TIME [epoch: 9.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1438612796169836		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1438612796169836 | validation: 0.48026106797738066]
	TIME [epoch: 9.49 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0878011161890886		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 1.0878011161890886 | validation: 0.6530734225229907]
	TIME [epoch: 9.48 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8827373387681929		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.8827373387681929 | validation: 1.0246679562522787]
	TIME [epoch: 9.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0753015702556739		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 1.0753015702556739 | validation: 0.6141999161566639]
	TIME [epoch: 9.49 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9242927236441447		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.9242927236441447 | validation: 1.190418835132953]
	TIME [epoch: 9.48 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2702803195932006		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 1.2702803195932006 | validation: 1.2930764848595726]
	TIME [epoch: 9.49 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.21152027651997		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.21152027651997 | validation: 0.8757206427925823]
	TIME [epoch: 9.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0219151996333302		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 1.0219151996333302 | validation: 1.2109671850177262]
	TIME [epoch: 9.48 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8786499019398176		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.8786499019398176 | validation: 0.6742429203642211]
	TIME [epoch: 9.48 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8093466134030116		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.8093466134030116 | validation: 0.8726324462653184]
	TIME [epoch: 9.49 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7499135847816952		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.7499135847816952 | validation: 0.811398525120787]
	TIME [epoch: 9.49 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8738751521069155		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.8738751521069155 | validation: 0.9019288209491131]
	TIME [epoch: 9.49 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9313760695298704		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.9313760695298704 | validation: 0.8212539969857897]
	TIME [epoch: 9.49 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9302757871944174		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 0.9302757871944174 | validation: 0.7212198661328023]
	TIME [epoch: 9.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7491950274070116		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.7491950274070116 | validation: 0.4754512905138104]
	TIME [epoch: 9.48 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7785924801856035		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.7785924801856035 | validation: 0.7816683705763333]
	TIME [epoch: 9.49 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1690701895009603		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.1690701895009603 | validation: 0.7952099115681693]
	TIME [epoch: 9.48 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9579002471983256		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.9579002471983256 | validation: 0.7356577338146955]
	TIME [epoch: 9.51 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8954905115330811		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.8954905115330811 | validation: 0.5514476211145637]
	TIME [epoch: 9.48 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8630630185463527		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 0.8630630185463527 | validation: 1.117446157968116]
	TIME [epoch: 9.48 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7432822206521359		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.7432822206521359 | validation: 0.6428320812145745]
	TIME [epoch: 9.49 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7765680873932478		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.7765680873932478 | validation: 1.7684374249926407]
	TIME [epoch: 9.49 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0807423197028374		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.0807423197028374 | validation: 0.48073176604944323]
	TIME [epoch: 9.48 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8749315092277605		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.8749315092277605 | validation: 1.1979296664491583]
	TIME [epoch: 9.48 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9167255543972688		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.9167255543972688 | validation: 0.8271650926511848]
	TIME [epoch: 9.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.85068135977722		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.85068135977722 | validation: 1.2084568948045111]
	TIME [epoch: 9.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4816104227897626		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.4816104227897626 | validation: 0.6049383060817413]
	TIME [epoch: 9.49 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8646222771238697		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.8646222771238697 | validation: 1.139420373406588]
	TIME [epoch: 9.49 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.039726064770767		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.039726064770767 | validation: 0.4745426601151179]
	TIME [epoch: 9.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9401510048113954		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.9401510048113954 | validation: 0.9420307809846176]
	TIME [epoch: 9.49 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7370265655507074		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.7370265655507074 | validation: 0.9129961430963883]
	TIME [epoch: 9.49 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3205975894270892		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 1.3205975894270892 | validation: 1.5678701676024713]
	TIME [epoch: 9.49 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0234064016195283		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.0234064016195283 | validation: 0.8836264915571189]
	TIME [epoch: 9.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7491091587374668		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.7491091587374668 | validation: 0.8124843065364652]
	TIME [epoch: 9.49 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9580813859428996		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.9580813859428996 | validation: 1.3010372236375582]
	TIME [epoch: 9.48 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2024468497392795		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 1.2024468497392795 | validation: 1.7317794627020962]
	TIME [epoch: 9.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0723799252759205		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.0723799252759205 | validation: 0.6309204475098266]
	TIME [epoch: 9.49 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7229625939326689		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 0.7229625939326689 | validation: 0.8067783252676148]
	TIME [epoch: 9.49 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7439450607593946		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.7439450607593946 | validation: 0.6653622932298783]
	TIME [epoch: 9.48 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9465517566413986		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.9465517566413986 | validation: 1.3980509950845852]
	TIME [epoch: 9.51 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9917291926179083		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.9917291926179083 | validation: 0.6616856900844772]
	TIME [epoch: 9.49 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6990101068344268		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.6990101068344268 | validation: 1.2110312086104724]
	TIME [epoch: 9.48 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1453326681401532		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.1453326681401532 | validation: 1.0187455207014988]
	TIME [epoch: 9.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2529610520859085		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 1.2529610520859085 | validation: 1.405803742855519]
	TIME [epoch: 9.49 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.25096530807179		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.25096530807179 | validation: 0.9565748540900998]
	TIME [epoch: 9.49 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2539573799148116		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 1.2539573799148116 | validation: 0.7215535488778266]
	TIME [epoch: 9.49 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9422183464359962		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.9422183464359962 | validation: 0.723008967662252]
	TIME [epoch: 9.51 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524288274881455		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.9524288274881455 | validation: 0.9802067418643704]
	TIME [epoch: 9.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.00513841174735		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.00513841174735 | validation: 0.5457980014252282]
	TIME [epoch: 9.49 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8283957261837674		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 0.8283957261837674 | validation: 1.4861442138440912]
	TIME [epoch: 9.49 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2696210442342752		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.2696210442342752 | validation: 1.7493071719496323]
	TIME [epoch: 9.51 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.064609918672267		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 1.064609918672267 | validation: 0.8752555925762923]
	TIME [epoch: 9.49 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7754257010360806		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.7754257010360806 | validation: 0.7707106744703868]
	TIME [epoch: 9.49 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.198989838341309		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 1.198989838341309 | validation: 0.720281106875824]
	TIME [epoch: 9.49 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.14258527046156		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.14258527046156 | validation: 0.7649993908862698]
	TIME [epoch: 9.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.886699789327956		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.886699789327956 | validation: 0.9534316303835764]
	TIME [epoch: 9.48 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.05631448656479		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.05631448656479 | validation: 0.8520019114084102]
	TIME [epoch: 9.48 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8537651665953794		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.8537651665953794 | validation: 0.8805162382647336]
	TIME [epoch: 9.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.071304024817315		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.071304024817315 | validation: 0.8257845132063919]
	TIME [epoch: 9.48 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0777568340197066		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 1.0777568340197066 | validation: 0.929383681143631]
	TIME [epoch: 9.48 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9750853888374482		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.9750853888374482 | validation: 0.7642081833986595]
	TIME [epoch: 9.49 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.997999032870978		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.997999032870978 | validation: 0.7969011766158585]
	TIME [epoch: 9.51 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.13369631688375		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.13369631688375 | validation: 0.7547330015109812]
	TIME [epoch: 9.49 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9667403180893581		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.9667403180893581 | validation: 1.1342418790848963]
	TIME [epoch: 9.49 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1809454739743426		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.1809454739743426 | validation: 1.1190738908394124]
	TIME [epoch: 9.49 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0740376924254116		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 1.0740376924254116 | validation: 1.0202782580536636]
	TIME [epoch: 9.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.219842226255389		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.219842226255389 | validation: 0.6565506713795594]
	TIME [epoch: 9.49 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7865820515445096		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.7865820515445096 | validation: 1.0396505603742454]
	TIME [epoch: 9.49 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9093084713520245		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.9093084713520245 | validation: 0.6930288731725297]
	TIME [epoch: 9.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9491817740704007		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.9491817740704007 | validation: 1.2786742538674538]
	TIME [epoch: 9.49 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9890572216960779		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.9890572216960779 | validation: 0.7238663666589011]
	TIME [epoch: 9.49 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7803272448586182		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.7803272448586182 | validation: 1.1292808028470045]
	TIME [epoch: 9.49 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9271891421664484		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.9271891421664484 | validation: 0.5028308850350299]
	TIME [epoch: 9.51 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8365318094104449		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.8365318094104449 | validation: 0.7016954623803418]
	TIME [epoch: 9.49 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8429622494478075		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.8429622494478075 | validation: 0.8642739628611193]
	TIME [epoch: 9.49 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7111907696477457		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.7111907696477457 | validation: 1.6220287618427227]
	TIME [epoch: 9.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6158823136026015		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.6158823136026015 | validation: 0.7855648914005248]
	TIME [epoch: 9.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2297895558709313		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 1.2297895558709313 | validation: 2.354666641246165]
	TIME [epoch: 9.49 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6276056877346874		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.6276056877346874 | validation: 0.8332305637722297]
	TIME [epoch: 9.48 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2338152314834838		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 1.2338152314834838 | validation: 1.1763208100131919]
	TIME [epoch: 9.51 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5631409610321734		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.5631409610321734 | validation: 1.204339529851129]
	TIME [epoch: 9.49 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.983286042434214		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.983286042434214 | validation: 0.8639589151112442]
	TIME [epoch: 9.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1891206699820083		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.1891206699820083 | validation: 0.8731448492605662]
	TIME [epoch: 9.49 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8467311791186642		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.8467311791186642 | validation: 1.574380912753284]
	TIME [epoch: 9.51 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5528264073911817		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.5528264073911817 | validation: 0.8327012536060708]
	TIME [epoch: 9.49 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.441609197719572		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 1.441609197719572 | validation: 1.0523443468121938]
	TIME [epoch: 9.51 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0830087337305332		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.0830087337305332 | validation: 0.8214231983371238]
	TIME [epoch: 9.51 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.099815367770343		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 1.099815367770343 | validation: 1.8243896586067285]
	TIME [epoch: 9.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.174869955623083		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.174869955623083 | validation: 0.7455338098124459]
	TIME [epoch: 9.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8721051244017548		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 1.8721051244017548 | validation: 0.755951734950439]
	TIME [epoch: 9.51 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9798995581112742		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.9798995581112742 | validation: 0.7887558553105001]
	TIME [epoch: 9.52 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0656843797659756		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 1.0656843797659756 | validation: 1.54078477357034]
	TIME [epoch: 9.51 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7468219764813508		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.7468219764813508 | validation: 1.1703286614002846]
	TIME [epoch: 9.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.056794707830208		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 1.056794707830208 | validation: 1.4857377162160479]
	TIME [epoch: 9.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2054235609708468		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.2054235609708468 | validation: 1.059023114424568]
	TIME [epoch: 9.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9724323109147898		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.9724323109147898 | validation: 0.9150965787057388]
	TIME [epoch: 9.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.960100689061061		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.960100689061061 | validation: 0.9482215372926421]
	TIME [epoch: 9.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0626551155544215		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 1.0626551155544215 | validation: 0.8983981150649964]
	TIME [epoch: 9.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9511317014964996		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.9511317014964996 | validation: 1.047547014454194]
	TIME [epoch: 9.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0697881538401404		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 1.0697881538401404 | validation: 1.213927984991949]
	TIME [epoch: 9.51 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3474598467592702		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.3474598467592702 | validation: 0.7475091756605998]
	TIME [epoch: 9.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9235105429615917		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.9235105429615917 | validation: 0.6909852045926789]
	TIME [epoch: 9.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0829249193223185		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.0829249193223185 | validation: 0.8245583087832563]
	TIME [epoch: 9.51 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8437243849175966		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.8437243849175966 | validation: 0.8824564679434351]
	TIME [epoch: 9.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9045229038956404		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.9045229038956404 | validation: 0.9745428631052808]
	TIME [epoch: 9.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1564807930945986		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 1.1564807930945986 | validation: 0.6032804948931364]
	TIME [epoch: 9.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1864396211833395		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.1864396211833395 | validation: 1.6408560207848881]
	TIME [epoch: 9.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.121719180514447		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 1.121719180514447 | validation: 1.0791437606779815]
	TIME [epoch: 9.51 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1432032405850636		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.1432032405850636 | validation: 1.1427878834243221]
	TIME [epoch: 9.51 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9735400877539764		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.9735400877539764 | validation: 1.015338573803663]
	TIME [epoch: 9.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0607650061721199		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.0607650061721199 | validation: 1.0973608509642585]
	TIME [epoch: 9.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.049532050325702		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 1.049532050325702 | validation: 0.7748758841039941]
	TIME [epoch: 9.49 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8658516554484805		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.8658516554484805 | validation: 1.0615164456291886]
	TIME [epoch: 9.51 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8079494525676602		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.8079494525676602 | validation: 0.6599361412400963]
	TIME [epoch: 9.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7012384534188125		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.7012384534188125 | validation: 1.1011986808802097]
	TIME [epoch: 9.49 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8931936230804951		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.8931936230804951 | validation: 1.184732797853269]
	TIME [epoch: 9.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0414367611303765		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.0414367611303765 | validation: 0.643877515567435]
	TIME [epoch: 9.52 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8675687535807801		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.8675687535807801 | validation: 0.7471068497533909]
	TIME [epoch: 9.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0422429275578984		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.0422429275578984 | validation: 0.9187319384622894]
	TIME [epoch: 9.49 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1252635602249879		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 1.1252635602249879 | validation: 0.6337789149488304]
	TIME [epoch: 9.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9314544409369034		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.9314544409369034 | validation: 2.3082385171506052]
	TIME [epoch: 9.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7252574642722613		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 1.7252574642722613 | validation: 1.0747701138897834]
	TIME [epoch: 9.49 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9645247856151269		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.9645247856151269 | validation: 0.9279946032119082]
	TIME [epoch: 9.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7681857353730057		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.7681857353730057 | validation: 0.9762819906431487]
	TIME [epoch: 9.52 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9307062600846493		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.9307062600846493 | validation: 0.7627340886627803]
	TIME [epoch: 9.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6526237023665488		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.6526237023665488 | validation: 1.5347184787521906]
	TIME [epoch: 9.49 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.921432875943788		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.921432875943788 | validation: 0.4133969792502535]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_394.pth
	Model improved!!!
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.151653037663252		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 1.151653037663252 | validation: 1.4315921484684027]
	TIME [epoch: 9.52 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2110142171527891		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.2110142171527891 | validation: 0.6658397355057346]
	TIME [epoch: 9.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8358151240999389		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.8358151240999389 | validation: 0.894318099222605]
	TIME [epoch: 9.51 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7298081100758911		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.7298081100758911 | validation: 0.5074989542120215]
	TIME [epoch: 9.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799831800571855		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.5799831800571855 | validation: 0.6789684344168234]
	TIME [epoch: 9.53 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.676348285321904		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.676348285321904 | validation: 0.7005694629459174]
	TIME [epoch: 9.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7097498769363624		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.7097498769363624 | validation: 0.6211831837645051]
	TIME [epoch: 9.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.703176860784716		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.703176860784716 | validation: 0.7712159312637068]
	TIME [epoch: 9.53 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537044262385988		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.7537044262385988 | validation: 1.2753866069628905]
	TIME [epoch: 9.51 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9733044076800196		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.9733044076800196 | validation: 1.0898905976819024]
	TIME [epoch: 9.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.691721707559314		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 1.691721707559314 | validation: 1.5284909298088472]
	TIME [epoch: 9.49 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5383796920410964		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 2.5383796920410964 | validation: 3.484625375283089]
	TIME [epoch: 9.52 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.124145345359762		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 3.124145345359762 | validation: 1.8388403495705985]
	TIME [epoch: 9.52 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6206992859065714		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 1.6206992859065714 | validation: 2.5412544193562554]
	TIME [epoch: 9.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.371840498038638		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 1.371840498038638 | validation: 1.0203446277202153]
	TIME [epoch: 9.51 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8038140607760752		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.8038140607760752 | validation: 0.8896462384042687]
	TIME [epoch: 9.52 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8970066215462538		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.8970066215462538 | validation: 0.5685272718580983]
	TIME [epoch: 9.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0434202399760177		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.0434202399760177 | validation: 0.6254279911914773]
	TIME [epoch: 9.51 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6983999906062058		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.6983999906062058 | validation: 0.8381713474457155]
	TIME [epoch: 9.51 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7311929713276009		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.7311929713276009 | validation: 0.6214733628075347]
	TIME [epoch: 9.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7486101018144207		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.7486101018144207 | validation: 0.6533357512382654]
	TIME [epoch: 9.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7905501607835606		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.7905501607835606 | validation: 1.2507784617675737]
	TIME [epoch: 9.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1732385302892485		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 1.1732385302892485 | validation: 0.9310814721441173]
	TIME [epoch: 9.52 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9485828558115432		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.9485828558115432 | validation: 0.6607986809725194]
	TIME [epoch: 9.49 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9775508910192006		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.9775508910192006 | validation: 0.7589198613365337]
	TIME [epoch: 9.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7839575629140986		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.7839575629140986 | validation: 1.2461297820824189]
	TIME [epoch: 9.51 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.881019850754931		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.881019850754931 | validation: 1.276881583482383]
	TIME [epoch: 9.51 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.922017233186109		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.922017233186109 | validation: 1.0440106090521146]
	TIME [epoch: 9.51 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.636213111185993		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 1.636213111185993 | validation: 1.4766053358146602]
	TIME [epoch: 9.49 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3691202267783955		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.3691202267783955 | validation: 1.0682520009571201]
	TIME [epoch: 9.52 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8361808919123401		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.8361808919123401 | validation: 2.2820620527573974]
	TIME [epoch: 9.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4570638459586736		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 1.4570638459586736 | validation: 0.7298325690950234]
	TIME [epoch: 9.49 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8049760140396659		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.8049760140396659 | validation: 0.5505649595140409]
	TIME [epoch: 9.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7535265765883183		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.7535265765883183 | validation: 0.8975937137127992]
	TIME [epoch: 9.53 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2508442457145534		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 1.2508442457145534 | validation: 1.3164393987533702]
	TIME [epoch: 9.49 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.695650241787136		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.695650241787136 | validation: 1.0543076280359838]
	TIME [epoch: 9.51 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0365169955286782		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 1.0365169955286782 | validation: 0.5277914663445091]
	TIME [epoch: 9.51 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9555519132271941		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.9555519132271941 | validation: 0.8787409639931818]
	TIME [epoch: 9.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7759518676587014		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.7759518676587014 | validation: 0.8452480760875543]
	TIME [epoch: 9.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0578707581794222		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 1.0578707581794222 | validation: 2.2157389855305785]
	TIME [epoch: 9.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6985548891895017		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 1.6985548891895017 | validation: 0.7641532577362219]
	TIME [epoch: 9.52 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6963059511669201		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.6963059511669201 | validation: 0.6627105670040122]
	TIME [epoch: 9.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8905252931519391		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.8905252931519391 | validation: 0.4760689337061886]
	TIME [epoch: 9.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544011400624251		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.6544011400624251 | validation: 0.657114013675778]
	TIME [epoch: 9.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6909805876267339		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 1.6909805876267339 | validation: 4.912680249708428]
	TIME [epoch: 9.53 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7633682262652948		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 2.7633682262652948 | validation: 1.5497874505837501]
	TIME [epoch: 9.51 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2160767535152988		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 1.2160767535152988 | validation: 0.7820924194161415]
	TIME [epoch: 9.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7514328865432196		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.7514328865432196 | validation: 0.7904233273589811]
	TIME [epoch: 9.51 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8497363372391339		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.8497363372391339 | validation: 0.7447856123257942]
	TIME [epoch: 9.51 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.59775110320225		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 2.59775110320225 | validation: 2.793306445445412]
	TIME [epoch: 9.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5137854870090504		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 2.5137854870090504 | validation: 1.1854330059677591]
	TIME [epoch: 9.52 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3441166618010658		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 1.3441166618010658 | validation: 1.072655884518003]
	TIME [epoch: 9.53 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.534932435734548		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 4.534932435734548 | validation: 4.870164451701645]
	TIME [epoch: 9.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.563462373546607		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 4.563462373546607 | validation: 2.6844044011018013]
	TIME [epoch: 9.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0904187475765736		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 3.0904187475765736 | validation: 2.104994477512523]
	TIME [epoch: 9.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1038489832838647		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 2.1038489832838647 | validation: 2.803410628801176]
	TIME [epoch: 9.53 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.0907751656536755		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 6.0907751656536755 | validation: 6.402310066493688]
	TIME [epoch: 9.51 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.383151391121068		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 6.383151391121068 | validation: 4.606298497630188]
	TIME [epoch: 9.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.876041009570222		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 3.876041009570222 | validation: 2.6451305527231703]
	TIME [epoch: 9.52 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.765889964474605		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 2.765889964474605 | validation: 1.433232949467636]
	TIME [epoch: 9.51 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1906017707812084		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 1.1906017707812084 | validation: 1.5655468412294]
	TIME [epoch: 9.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.215981366663431		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 1.215981366663431 | validation: 1.0579610315580452]
	TIME [epoch: 9.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1489158087305913		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 1.1489158087305913 | validation: 1.1388754257376885]
	TIME [epoch: 9.53 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1216561550746493		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 1.1216561550746493 | validation: 0.9111566519225057]
	TIME [epoch: 9.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524017940367997		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.9524017940367997 | validation: 0.7559371562966786]
	TIME [epoch: 9.49 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9266481670357465		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.9266481670357465 | validation: 1.666465678547957]
	TIME [epoch: 9.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2624937278327502		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 1.2624937278327502 | validation: 0.9669499830864414]
	TIME [epoch: 9.53 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9438282631868791		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.9438282631868791 | validation: 1.091591298623155]
	TIME [epoch: 9.51 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2786316881228543		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 1.2786316881228543 | validation: 1.5618576691078443]
	TIME [epoch: 9.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0782211003540207		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 1.0782211003540207 | validation: 1.0227791053217428]
	TIME [epoch: 9.51 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1464823139100795		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 1.1464823139100795 | validation: 2.1576142593206225]
	TIME [epoch: 9.52 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1022459487173353		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 1.1022459487173353 | validation: 1.0403544908535411]
	TIME [epoch: 9.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1030382559949417		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 1.1030382559949417 | validation: 1.1243832771754985]
	TIME [epoch: 9.51 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0431269728342432		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 1.0431269728342432 | validation: 0.9253805745856064]
	TIME [epoch: 9.53 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8806222943916433		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.8806222943916433 | validation: 0.6569636188242544]
	TIME [epoch: 9.51 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8342270358078853		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.8342270358078853 | validation: 0.7721136676245441]
	TIME [epoch: 9.51 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3833853294992706		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 1.3833853294992706 | validation: 0.6047170005530149]
	TIME [epoch: 9.51 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8180783262969673		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.8180783262969673 | validation: 0.6397392842420007]
	TIME [epoch: 9.53 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9029591519330296		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.9029591519330296 | validation: 0.7016449530400157]
	TIME [epoch: 9.51 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1244350662198677		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 1.1244350662198677 | validation: 0.7665718994223384]
	TIME [epoch: 9.51 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8260067389416349		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.8260067389416349 | validation: 1.165049486768322]
	TIME [epoch: 9.52 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9017748053188124		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.9017748053188124 | validation: 0.5810454923121553]
	TIME [epoch: 9.52 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9270571775714039		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.9270571775714039 | validation: 0.8679525624358425]
	TIME [epoch: 9.51 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7353650088172351		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.7353650088172351 | validation: 0.6196130239330212]
	TIME [epoch: 9.51 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8675505031448922		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.8675505031448922 | validation: 0.980923155919537]
	TIME [epoch: 9.53 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8724327517437814		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.8724327517437814 | validation: 1.546124993267457]
	TIME [epoch: 9.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1922293944011455		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 1.1922293944011455 | validation: 0.8206869670876895]
	TIME [epoch: 9.51 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0769174431694024		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 1.0769174431694024 | validation: 0.9775477867297994]
	TIME [epoch: 9.51 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.117717374887711		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 1.117717374887711 | validation: 0.6292835756018172]
	TIME [epoch: 9.53 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8314602981234882		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.8314602981234882 | validation: 0.6758899287814942]
	TIME [epoch: 9.51 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0262139626508904		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 1.0262139626508904 | validation: 3.086899675628126]
	TIME [epoch: 9.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6634038065885672		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 1.6634038065885672 | validation: 0.8518259029127825]
	TIME [epoch: 9.53 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9788338113274812		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.9788338113274812 | validation: 1.4330359966358226]
	TIME [epoch: 9.51 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0653211256744588		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 1.0653211256744588 | validation: 0.6359400180708277]
	TIME [epoch: 9.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7264538752095253		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.7264538752095253 | validation: 0.7420256249135914]
	TIME [epoch: 9.51 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8309586581040278		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.8309586581040278 | validation: 0.6381113999591131]
	TIME [epoch: 9.51 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7585461650103622		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.7585461650103622 | validation: 0.5609501073669781]
	TIME [epoch: 9.51 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6633716268801774		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.6633716268801774 | validation: 0.8115248830140627]
	TIME [epoch: 9.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7583094209115497		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.7583094209115497 | validation: 0.9124958302800701]
	TIME [epoch: 9.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7157696789216803		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.7157696789216803 | validation: 0.5866986658248865]
	TIME [epoch: 9.52 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469119689968083		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.6469119689968083 | validation: 0.5689361824580436]
	TIME [epoch: 9.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8298114990442791		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.8298114990442791 | validation: 0.8713032266830445]
	TIME [epoch: 9.51 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8401401440402265		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.8401401440402265 | validation: 0.5734748302750967]
	TIME [epoch: 9.53 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6728832391044245		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.6728832391044245 | validation: 0.8428684604239055]
	TIME [epoch: 9.51 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7903981535215052		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.7903981535215052 | validation: 0.5743596065197734]
	TIME [epoch: 9.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7049513275285383		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.7049513275285383 | validation: 0.6763456714385009]
	TIME [epoch: 9.51 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6509839215825501		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.6509839215825501 | validation: 0.49705044471768267]
	TIME [epoch: 9.52 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7748900542003957		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.7748900542003957 | validation: 1.442098554697799]
	TIME [epoch: 9.51 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9545433648129278		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.9545433648129278 | validation: 0.6664697162389664]
	TIME [epoch: 9.51 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9272476221763535		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.9272476221763535 | validation: 0.8025959750968394]
	TIME [epoch: 9.51 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7147764430351619		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.7147764430351619 | validation: 0.69903187230899]
	TIME [epoch: 9.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.680646816134241		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.680646816134241 | validation: 0.6224472289177976]
	TIME [epoch: 9.51 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7419733198035532		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.7419733198035532 | validation: 1.0261034515957383]
	TIME [epoch: 9.51 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7815847964920879		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.7815847964920879 | validation: 1.1483551196540829]
	TIME [epoch: 9.53 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7741002601030089		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.7741002601030089 | validation: 0.7647339082090946]
	TIME [epoch: 9.51 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9846005087106654		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.9846005087106654 | validation: 0.7801415948574032]
	TIME [epoch: 9.51 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8220222719044378		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.8220222719044378 | validation: 1.3245314901590766]
	TIME [epoch: 9.51 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.854109561025516		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.854109561025516 | validation: 0.6639637866269864]
	TIME [epoch: 9.53 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6690183586363551		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.6690183586363551 | validation: 0.9352251693813216]
	TIME [epoch: 9.51 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.928131924594046		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.928131924594046 | validation: 1.0262868614510432]
	TIME [epoch: 9.51 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9207340332801304		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.9207340332801304 | validation: 0.6642348958395264]
	TIME [epoch: 9.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7241176589735581		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.7241176589735581 | validation: 0.6378799655485493]
	TIME [epoch: 9.52 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8959468359773645		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.8959468359773645 | validation: 0.8336755366187218]
	TIME [epoch: 9.51 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8368739296977983		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.8368739296977983 | validation: 0.8043974951892924]
	TIME [epoch: 9.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5957632590001671		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.5957632590001671 | validation: 0.724450185599226]
	TIME [epoch: 9.53 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6870469663972687		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.6870469663972687 | validation: 0.6381135307273363]
	TIME [epoch: 9.51 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8061265140393186		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.8061265140393186 | validation: 0.7431477524027839]
	TIME [epoch: 9.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007237467675848		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.7007237467675848 | validation: 0.6108186721719971]
	TIME [epoch: 9.51 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6568092036308151		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.6568092036308151 | validation: 0.7811806952145409]
	TIME [epoch: 9.52 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6968896267766225		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.6968896267766225 | validation: 0.44194375824020327]
	TIME [epoch: 9.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240763005598424		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.7240763005598424 | validation: 0.8696308634142824]
	TIME [epoch: 9.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7198336230316947		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.7198336230316947 | validation: 0.6236594752986556]
	TIME [epoch: 9.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6116136817004044		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.6116136817004044 | validation: 0.4630334778829125]
	TIME [epoch: 9.52 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6182410115925194		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.6182410115925194 | validation: 0.8602392324710373]
	TIME [epoch: 9.49 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.655254526109716		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.655254526109716 | validation: 0.8481996576691927]
	TIME [epoch: 9.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5527333810477242		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 1.5527333810477242 | validation: 0.6087485619679508]
	TIME [epoch: 9.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1994341480660353		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 1.1994341480660353 | validation: 0.6871952665349371]
	TIME [epoch: 9.51 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8475736751956895		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.8475736751956895 | validation: 1.3871783382550837]
	TIME [epoch: 9.51 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1639145154041792		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 1.1639145154041792 | validation: 0.496547100176296]
	TIME [epoch: 9.51 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975805703230004		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.5975805703230004 | validation: 0.4759813125242786]
	TIME [epoch: 9.53 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312290939649868		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.6312290939649868 | validation: 0.7529912925951732]
	TIME [epoch: 9.52 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7147688612145526		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.7147688612145526 | validation: 0.556382919835156]
	TIME [epoch: 9.51 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6287287971774046		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.6287287971774046 | validation: 1.0379454691382741]
	TIME [epoch: 9.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7940150364255197		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.7940150364255197 | validation: 0.48245187439397563]
	TIME [epoch: 9.52 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7050848357708318		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.7050848357708318 | validation: 0.8764655358318484]
	TIME [epoch: 9.49 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9354752605670363		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.9354752605670363 | validation: 0.814375469224973]
	TIME [epoch: 9.51 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.945584811802504		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.945584811802504 | validation: 0.5574253946430704]
	TIME [epoch: 9.52 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7100214340207858		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.7100214340207858 | validation: 0.5147147116410113]
	TIME [epoch: 9.51 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5575096965724783		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.5575096965724783 | validation: 0.5386976541154626]
	TIME [epoch: 9.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5892414409764155		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.5892414409764155 | validation: 0.47258389611385965]
	TIME [epoch: 9.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6530068030372409		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.6530068030372409 | validation: 0.7854508197629997]
	TIME [epoch: 9.52 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783249160152205		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.6783249160152205 | validation: 0.42759447411115203]
	TIME [epoch: 9.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5584266892170183		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.5584266892170183 | validation: 1.203926152171274]
	TIME [epoch: 9.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0464113123180898		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 1.0464113123180898 | validation: 0.487601014184355]
	TIME [epoch: 9.51 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6609624574701267		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.6609624574701267 | validation: 0.4874409115801464]
	TIME [epoch: 9.54 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7281055741914235		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.7281055741914235 | validation: 0.7834114940448916]
	TIME [epoch: 9.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395527000786066		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.7395527000786066 | validation: 0.5739404725781432]
	TIME [epoch: 9.49 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5763685678147686		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5763685678147686 | validation: 0.512566904390415]
	TIME [epoch: 9.52 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554822264874452		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.554822264874452 | validation: 0.5871317354386636]
	TIME [epoch: 9.51 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8172907862632599		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.8172907862632599 | validation: 0.7901078398519151]
	TIME [epoch: 9.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6255305236683033		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.6255305236683033 | validation: 0.6426108727346086]
	TIME [epoch: 9.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553931691682397		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.5553931691682397 | validation: 0.5442305092715402]
	TIME [epoch: 9.53 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.761396567920498		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.761396567920498 | validation: 0.4706459835744728]
	TIME [epoch: 9.49 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6528318668918411		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.6528318668918411 | validation: 0.6491748120092521]
	TIME [epoch: 9.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6086277596944762		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.6086277596944762 | validation: 0.48772860715140126]
	TIME [epoch: 9.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6255448377321015		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.6255448377321015 | validation: 0.7005394199850622]
	TIME [epoch: 9.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584424081927107		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.584424081927107 | validation: 0.6845264814725256]
	TIME [epoch: 9.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6212806137429273		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.6212806137429273 | validation: 0.400738370375312]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6026791513711246		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.6026791513711246 | validation: 0.9413116245643949]
	TIME [epoch: 9.52 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.699452407181802		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.699452407181802 | validation: 0.8989383447501791]
	TIME [epoch: 9.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8159648859489768		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.8159648859489768 | validation: 0.948769443289059]
	TIME [epoch: 9.49 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.412337142484856		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 1.412337142484856 | validation: 0.569718049335689]
	TIME [epoch: 9.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4383513266013496		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.4383513266013496 | validation: 0.4315754461942366]
	TIME [epoch: 9.52 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7748354218799219		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.7748354218799219 | validation: 0.5455694636469671]
	TIME [epoch: 9.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968646854421367		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.5968646854421367 | validation: 0.6728221767238007]
	TIME [epoch: 9.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6080084681992666		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.6080084681992666 | validation: 0.5593840608546828]
	TIME [epoch: 9.51 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7689279658727872		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.7689279658727872 | validation: 0.619794113025591]
	TIME [epoch: 9.51 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645109438836749		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.6645109438836749 | validation: 0.48015010923605034]
	TIME [epoch: 9.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208489431600898		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.5208489431600898 | validation: 0.434967769698425]
	TIME [epoch: 9.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779016494331499		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.5779016494331499 | validation: 0.6849584924654589]
	TIME [epoch: 9.52 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624020250469209		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.5624020250469209 | validation: 0.4875778011133531]
	TIME [epoch: 9.51 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7289848987472166		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.7289848987472166 | validation: 0.6030005407020803]
	TIME [epoch: 9.51 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057353782810903		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.5057353782810903 | validation: 0.49402400881220027]
	TIME [epoch: 9.49 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5325676165021285		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.5325676165021285 | validation: 0.5614946022610007]
	TIME [epoch: 9.52 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5983372566242814		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.5983372566242814 | validation: 0.6521874082315404]
	TIME [epoch: 9.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5816291924967737		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.5816291924967737 | validation: 0.4871089607835595]
	TIME [epoch: 9.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.751090380681293		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.751090380681293 | validation: 0.9141908881968052]
	TIME [epoch: 9.51 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7870143869989068		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.7870143869989068 | validation: 0.48921025383649025]
	TIME [epoch: 9.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6087624519601363		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.6087624519601363 | validation: 0.4829042775151326]
	TIME [epoch: 9.49 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352549400532356		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.5352549400532356 | validation: 0.6346021704192352]
	TIME [epoch: 9.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6036898601535574		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.6036898601535574 | validation: 0.38405313422943793]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517969629863549		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.517969629863549 | validation: 0.41967094905310265]
	TIME [epoch: 9.53 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5176620400695251		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.5176620400695251 | validation: 1.2961526101070637]
	TIME [epoch: 9.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7446512053131646		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.7446512053131646 | validation: 0.40272050315327934]
	TIME [epoch: 9.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5003385615143829		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.5003385615143829 | validation: 0.4509460317437304]
	TIME [epoch: 9.54 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.605817818576029		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.605817818576029 | validation: 0.4077393087362329]
	TIME [epoch: 9.52 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4837671284110397		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.4837671284110397 | validation: 0.6366671337725629]
	TIME [epoch: 9.51 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5575082525958294		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.5575082525958294 | validation: 0.4877943599267441]
	TIME [epoch: 9.53 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5069546918467911		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.5069546918467911 | validation: 0.5294091954497051]
	TIME [epoch: 9.52 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44922688645949443		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.44922688645949443 | validation: 0.37982146450782794]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49693239367328107		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.49693239367328107 | validation: 0.4323646319272041]
	TIME [epoch: 9.52 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5122784027861853		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.5122784027861853 | validation: 0.8706191592890438]
	TIME [epoch: 9.53 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0166776574474399		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 1.0166776574474399 | validation: 0.6066256227528678]
	TIME [epoch: 9.51 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5751317081999854		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.5751317081999854 | validation: 0.478105062271056]
	TIME [epoch: 9.52 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7093477891490821		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.7093477891490821 | validation: 0.47508373324868486]
	TIME [epoch: 9.51 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48953372884078983		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.48953372884078983 | validation: 0.5317791061244245]
	TIME [epoch: 9.53 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9201620037419195		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.9201620037419195 | validation: 0.9179583354727109]
	TIME [epoch: 9.51 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5761761585843024		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.5761761585843024 | validation: 0.382300944435349]
	TIME [epoch: 9.51 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43888516728512156		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.43888516728512156 | validation: 0.3755298260538337]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5568150542855124		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.5568150542855124 | validation: 0.45166107838856023]
	TIME [epoch: 9.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3976044006887097		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.3976044006887097 | validation: 0.32291756778988484]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4465635360243997		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.4465635360243997 | validation: 0.495645405836453]
	TIME [epoch: 9.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42595065873169063		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.42595065873169063 | validation: 0.38427276480371747]
	TIME [epoch: 9.53 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5210131745650995		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.5210131745650995 | validation: 0.3325908780453476]
	TIME [epoch: 9.51 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39746764890290015		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.39746764890290015 | validation: 0.27581644090546886]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_609.pth
	Model improved!!!
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5932925054263242		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.5932925054263242 | validation: 0.31300419686509534]
	TIME [epoch: 9.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6078693720307481		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.6078693720307481 | validation: 0.3335626435315327]
	TIME [epoch: 9.51 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4262173413133016		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.4262173413133016 | validation: 0.599798137694152]
	TIME [epoch: 9.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5387481730003651		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.5387481730003651 | validation: 0.4982531103736625]
	TIME [epoch: 9.51 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5734194659657991		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.5734194659657991 | validation: 0.9316902674317932]
	TIME [epoch: 9.52 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.865309930735512		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.865309930735512 | validation: 0.5357035834522139]
	TIME [epoch: 9.51 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0029548300444437		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 1.0029548300444437 | validation: 0.904377505700185]
	TIME [epoch: 9.49 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0840404779140775		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 1.0840404779140775 | validation: 0.8910578587743203]
	TIME [epoch: 9.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7487402001832415		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.7487402001832415 | validation: 0.8671454097513109]
	TIME [epoch: 9.53 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7795430733864638		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.7795430733864638 | validation: 0.5066301255728205]
	TIME [epoch: 9.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7570175911918211		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.7570175911918211 | validation: 0.42059203580006993]
	TIME [epoch: 9.51 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350092358237946		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.5350092358237946 | validation: 0.6178619854783238]
	TIME [epoch: 9.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5008373210987624		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.5008373210987624 | validation: 0.42262337426476493]
	TIME [epoch: 9.52 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8394907961786947		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.8394907961786947 | validation: 0.8060931437157259]
	TIME [epoch: 9.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232763467760838		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.7232763467760838 | validation: 0.6038361735199796]
	TIME [epoch: 9.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094409748828573		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.6094409748828573 | validation: 0.6081903819832126]
	TIME [epoch: 9.53 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5864425250503487		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.5864425250503487 | validation: 0.40394683481673865]
	TIME [epoch: 9.51 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5594451256400387		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.5594451256400387 | validation: 0.4328220739836139]
	TIME [epoch: 9.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4956339462415542		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.4956339462415542 | validation: 0.4254652184953328]
	TIME [epoch: 9.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5548297047480649		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.5548297047480649 | validation: 0.538651576794232]
	TIME [epoch: 9.52 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086502314182327		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.5086502314182327 | validation: 0.41989564694610904]
	TIME [epoch: 9.51 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45254372075708427		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.45254372075708427 | validation: 0.8878898390455331]
	TIME [epoch: 9.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6246281301414321		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.6246281301414321 | validation: 0.7238682575885457]
	TIME [epoch: 9.52 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5530731435774766		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.5530731435774766 | validation: 0.5791251092918441]
	TIME [epoch: 9.51 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546771780883165		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.5546771780883165 | validation: 0.42910164750561736]
	TIME [epoch: 9.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5136272739752292		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.5136272739752292 | validation: 0.7543391112943675]
	TIME [epoch: 9.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9075886174614374		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.9075886174614374 | validation: 0.42907295561255593]
	TIME [epoch: 9.52 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326054406300458		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.4326054406300458 | validation: 0.2999718487025529]
	TIME [epoch: 9.51 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4118505530496792		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.4118505530496792 | validation: 0.559515011979598]
	TIME [epoch: 9.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46154387046629414		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.46154387046629414 | validation: 0.4820149157446701]
	TIME [epoch: 9.49 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4786256449174536		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.4786256449174536 | validation: 0.46911588417061595]
	TIME [epoch: 9.52 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091124732777418		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.6091124732777418 | validation: 0.471449742363306]
	TIME [epoch: 9.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47867613193676073		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.47867613193676073 | validation: 0.6182338525823331]
	TIME [epoch: 9.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46593910761829954		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.46593910761829954 | validation: 0.32964750019592376]
	TIME [epoch: 9.51 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48638966399164935		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.48638966399164935 | validation: 0.4086874699905448]
	TIME [epoch: 9.52 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386482650356733		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.4386482650356733 | validation: 0.5259209651183778]
	TIME [epoch: 9.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4856520374187216		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.4856520374187216 | validation: 0.41527009951981003]
	TIME [epoch: 9.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44373794302575853		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.44373794302575853 | validation: 0.7459973492753915]
	TIME [epoch: 9.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5321031633997653		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.5321031633997653 | validation: 0.2554772011691952]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.438193045573655		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.438193045573655 | validation: 0.5869518438240954]
	TIME [epoch: 9.49 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5943175353055318		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.5943175353055318 | validation: 0.4393453234112989]
	TIME [epoch: 9.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212248533084691		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.5212248533084691 | validation: 0.47332917253695583]
	TIME [epoch: 9.52 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5720751017490366		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.5720751017490366 | validation: 0.5732603606966541]
	TIME [epoch: 9.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42166264900795636		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.42166264900795636 | validation: 0.819054242374001]
	TIME [epoch: 9.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5677971186196573		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.5677971186196573 | validation: 0.3425165791729718]
	TIME [epoch: 9.51 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6973496617350239		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.6973496617350239 | validation: 0.6127504108402625]
	TIME [epoch: 9.52 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6401781656153746		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.6401781656153746 | validation: 0.5297709677182054]
	TIME [epoch: 9.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5446407819474262		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.5446407819474262 | validation: 0.8560737990915552]
	TIME [epoch: 9.51 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5269770265700628		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.5269770265700628 | validation: 0.5588474211754739]
	TIME [epoch: 9.51 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4477069014272391		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.4477069014272391 | validation: 0.5486500895021813]
	TIME [epoch: 9.51 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5580351001249833		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.5580351001249833 | validation: 0.4312881427945012]
	TIME [epoch: 9.49 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38532294507369586		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.38532294507369586 | validation: 0.3478248212217426]
	TIME [epoch: 9.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3489333139223711		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.3489333139223711 | validation: 0.45506986388593035]
	TIME [epoch: 9.53 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5778040869573798		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.5778040869573798 | validation: 0.41573254386694014]
	TIME [epoch: 9.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4686594189328213		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.4686594189328213 | validation: 0.7156726496443838]
	TIME [epoch: 9.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234454973181858		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.5234454973181858 | validation: 0.32741086497232064]
	TIME [epoch: 9.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42402287411598527		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.42402287411598527 | validation: 0.3490872087576925]
	TIME [epoch: 9.51 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.391624416712312		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.391624416712312 | validation: 0.31032150156222477]
	TIME [epoch: 9.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41172274781447654		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.41172274781447654 | validation: 0.46492048903709476]
	TIME [epoch: 9.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41869189350516933		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.41869189350516933 | validation: 0.5774373301345628]
	TIME [epoch: 9.52 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47688878331574747		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.47688878331574747 | validation: 0.6305028023758845]
	TIME [epoch: 9.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950409512438896		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.3950409512438896 | validation: 0.5626738602118775]
	TIME [epoch: 9.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44421993689132744		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.44421993689132744 | validation: 0.40612381264744285]
	TIME [epoch: 9.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048149072069071		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.4048149072069071 | validation: 0.5743518653022581]
	TIME [epoch: 9.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5846304211888539		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.5846304211888539 | validation: 0.5391006418834688]
	TIME [epoch: 9.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4036876458030781		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.4036876458030781 | validation: 0.8652312603210426]
	TIME [epoch: 9.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7021405139210298		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.7021405139210298 | validation: 0.6287294831195627]
	TIME [epoch: 9.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44720756223062386		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.44720756223062386 | validation: 0.44812193628776537]
	TIME [epoch: 9.51 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4125316763515494		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.4125316763515494 | validation: 0.7707875895976725]
	TIME [epoch: 9.49 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7305630281718198		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.7305630281718198 | validation: 0.3222608731637616]
	TIME [epoch: 9.49 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3714517641681812		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.3714517641681812 | validation: 0.5794602451880364]
	TIME [epoch: 9.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.468331367349748		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.468331367349748 | validation: 0.3847033180879331]
	TIME [epoch: 9.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3959951533454615		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.3959951533454615 | validation: 0.3896777181797381]
	TIME [epoch: 9.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45750652578505796		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.45750652578505796 | validation: 0.270403694437515]
	TIME [epoch: 9.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520115099748483		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.520115099748483 | validation: 0.33184227967065566]
	TIME [epoch: 9.52 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3940132388676011		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.3940132388676011 | validation: 0.3333964525530052]
	TIME [epoch: 9.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3675449788499906		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.3675449788499906 | validation: 0.6870330599256588]
	TIME [epoch: 9.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6849189035974806		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.6849189035974806 | validation: 0.4301883684024905]
	TIME [epoch: 9.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4845450164766202		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.4845450164766202 | validation: 0.5393320336332851]
	TIME [epoch: 9.52 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5944880938091133		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.5944880938091133 | validation: 0.3055581910960653]
	TIME [epoch: 9.49 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4409768980289289		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.4409768980289289 | validation: 0.29874775436231277]
	TIME [epoch: 9.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.549941563556799		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.549941563556799 | validation: 0.9191658211067738]
	TIME [epoch: 9.51 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8002960094506534		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.8002960094506534 | validation: 0.6462693765723452]
	TIME [epoch: 9.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6089361864675189		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.6089361864675189 | validation: 0.36305000831842016]
	TIME [epoch: 9.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4999446696494423		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.4999446696494423 | validation: 0.44034114390539963]
	TIME [epoch: 9.49 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5608826006788412		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.5608826006788412 | validation: 0.5898262996531581]
	TIME [epoch: 9.52 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332015490033559		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.6332015490033559 | validation: 0.38440986961457624]
	TIME [epoch: 9.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42710755520628707		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.42710755520628707 | validation: 0.7136044537641729]
	TIME [epoch: 9.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4340408410267759		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.4340408410267759 | validation: 0.4002535623888308]
	TIME [epoch: 9.51 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5027530815926244		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.5027530815926244 | validation: 0.4429610873295451]
	TIME [epoch: 9.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43148289741256385		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.43148289741256385 | validation: 0.5078077925700576]
	TIME [epoch: 9.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552343974633445		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.5552343974633445 | validation: 0.3989093858694588]
	TIME [epoch: 9.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4606150484218466		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.4606150484218466 | validation: 0.45018292117096936]
	TIME [epoch: 9.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46922219919552316		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.46922219919552316 | validation: 0.9122165113775268]
	TIME [epoch: 9.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6465138738706278		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.6465138738706278 | validation: 0.3435435648901148]
	TIME [epoch: 9.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48944266385641527		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.48944266385641527 | validation: 0.8249583996808189]
	TIME [epoch: 9.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8745004060006277		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.8745004060006277 | validation: 0.9085399784165403]
	TIME [epoch: 9.52 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676814361090707		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.5676814361090707 | validation: 1.7215111540287331]
	TIME [epoch: 9.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0707899424480165		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 1.0707899424480165 | validation: 0.47898207883476235]
	TIME [epoch: 9.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.476015643083865		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.476015643083865 | validation: 0.5793591384750838]
	TIME [epoch: 9.52 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4645672116572581		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.4645672116572581 | validation: 0.7785756586986419]
	TIME [epoch: 9.51 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4959744254501667		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.4959744254501667 | validation: 0.7031901889640543]
	TIME [epoch: 9.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46910365296403905		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.46910365296403905 | validation: 0.7892806699048538]
	TIME [epoch: 9.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49838532241088884		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.49838532241088884 | validation: 0.4981971101180107]
	TIME [epoch: 9.51 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36613790478175423		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.36613790478175423 | validation: 0.533830317236947]
	TIME [epoch: 9.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39461077116748255		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.39461077116748255 | validation: 0.27613979392915505]
	TIME [epoch: 9.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41886182487409085		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.41886182487409085 | validation: 0.6915496934306845]
	TIME [epoch: 9.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5513002480810907		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.5513002480810907 | validation: 0.6692273792589817]
	TIME [epoch: 9.52 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.468819793498199		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.468819793498199 | validation: 0.5272952414030739]
	TIME [epoch: 9.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37510099656681095		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.37510099656681095 | validation: 0.472293101323816]
	TIME [epoch: 9.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326324325245608		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.4326324325245608 | validation: 0.6808977445267698]
	TIME [epoch: 9.52 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7484165278365594		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.7484165278365594 | validation: 0.36689622670526745]
	TIME [epoch: 9.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4315900030508376		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.4315900030508376 | validation: 0.38197832583234487]
	TIME [epoch: 9.51 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3994850916493407		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.3994850916493407 | validation: 0.6048390529050163]
	TIME [epoch: 9.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4940919290097533		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.4940919290097533 | validation: 0.4120929567361813]
	TIME [epoch: 9.52 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40606088115000843		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.40606088115000843 | validation: 0.4737372510591017]
	TIME [epoch: 9.51 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119644570268882		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.4119644570268882 | validation: 0.5468431940545955]
	TIME [epoch: 9.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001538846703838		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.6001538846703838 | validation: 0.3570858688987994]
	TIME [epoch: 9.51 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5521225199863449		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 1.5521225199863449 | validation: 2.9429440409964376]
	TIME [epoch: 9.52 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4717234245572945		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 3.4717234245572945 | validation: 1.1394019926771168]
	TIME [epoch: 9.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1974766863099728		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 1.1974766863099728 | validation: 0.5046686016536935]
	TIME [epoch: 9.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3654960752019451		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.3654960752019451 | validation: 0.4254854292216141]
	TIME [epoch: 9.53 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34333378345695054		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.34333378345695054 | validation: 1.1837349056790556]
	TIME [epoch: 9.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7126366659835		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.7126366659835 | validation: 0.3681053835742541]
	TIME [epoch: 9.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329635921680611		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.5329635921680611 | validation: 0.46946910344132053]
	TIME [epoch: 9.51 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3459891396048287		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.3459891396048287 | validation: 0.41095007439797526]
	TIME [epoch: 9.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39473532792666066		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.39473532792666066 | validation: 0.4410823893178519]
	TIME [epoch: 9.51 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5118873617439783		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.5118873617439783 | validation: 0.6626500112448604]
	TIME [epoch: 9.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6348172891071722		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.6348172891071722 | validation: 0.5140784687303769]
	TIME [epoch: 9.51 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39835371116961826		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.39835371116961826 | validation: 0.458386476770742]
	TIME [epoch: 9.52 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36852456768689557		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.36852456768689557 | validation: 0.8996377540561709]
	TIME [epoch: 9.49 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7713008758119237		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.7713008758119237 | validation: 0.5090574090473918]
	TIME [epoch: 9.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4823327970766525		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.4823327970766525 | validation: 0.4872481908422879]
	TIME [epoch: 9.52 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596988371088125		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.5596988371088125 | validation: 0.4516971025533038]
	TIME [epoch: 9.51 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43825595836357606		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.43825595836357606 | validation: 0.49374607253262554]
	TIME [epoch: 9.51 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40076423243797804		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.40076423243797804 | validation: 0.4530986207331207]
	TIME [epoch: 9.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.417424618839832		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.417424618839832 | validation: 0.3074786631392336]
	TIME [epoch: 9.52 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.563264473574578		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.563264473574578 | validation: 0.6371928542907507]
	TIME [epoch: 9.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48654162584849453		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.48654162584849453 | validation: 0.5066525987760817]
	TIME [epoch: 9.51 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329172402790519		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.4329172402790519 | validation: 0.8092139897705022]
	TIME [epoch: 9.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43416226022162957		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.43416226022162957 | validation: 0.3750655841831972]
	TIME [epoch: 9.51 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33858190436116964		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.33858190436116964 | validation: 0.23552744010820065]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37753750701785216		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.37753750701785216 | validation: 0.7681946388648803]
	TIME [epoch: 9.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4389994359840704		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.4389994359840704 | validation: 0.3556334169484837]
	TIME [epoch: 9.53 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47317798107368614		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.47317798107368614 | validation: 0.35094791514024337]
	TIME [epoch: 9.51 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3279094840994202		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.3279094840994202 | validation: 0.2732287823880349]
	TIME [epoch: 9.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3364969298783457		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.3364969298783457 | validation: 0.406527456843149]
	TIME [epoch: 9.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4045378274917125		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.4045378274917125 | validation: 0.4288874297239441]
	TIME [epoch: 9.52 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007556651361959		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.4007556651361959 | validation: 0.5576800991067136]
	TIME [epoch: 9.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41422051235040974		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.41422051235040974 | validation: 0.6301193941439162]
	TIME [epoch: 9.49 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9597254281224139		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.9597254281224139 | validation: 0.3454790867727972]
	TIME [epoch: 9.51 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42969199062740265		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.42969199062740265 | validation: 0.6167202216527573]
	TIME [epoch: 9.52 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5646262404721151		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.5646262404721151 | validation: 0.2967992279223666]
	TIME [epoch: 9.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49884600228703874		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.49884600228703874 | validation: 0.43688119334432296]
	TIME [epoch: 9.49 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162541373287597		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.4162541373287597 | validation: 0.26848601144050244]
	TIME [epoch: 9.52 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850279816330533		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.2850279816330533 | validation: 0.38908519052376606]
	TIME [epoch: 9.51 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33293068076322274		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.33293068076322274 | validation: 0.47072064541455777]
	TIME [epoch: 9.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44754409991152466		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.44754409991152466 | validation: 0.4421531137631354]
	TIME [epoch: 9.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31754425401689484		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.31754425401689484 | validation: 0.33181390382392617]
	TIME [epoch: 9.51 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36453746043709706		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.36453746043709706 | validation: 0.418244137956693]
	TIME [epoch: 9.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37711730428439083		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.37711730428439083 | validation: 0.3995063486152936]
	TIME [epoch: 9.49 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276986233820296		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.4276986233820296 | validation: 0.6319967911357525]
	TIME [epoch: 9.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5756093305975956		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.5756093305975956 | validation: 0.9897877668763411]
	TIME [epoch: 9.52 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5818352930755862		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.5818352930755862 | validation: 0.4128109515467363]
	TIME [epoch: 9.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4376968380002702		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.4376968380002702 | validation: 0.564986030322543]
	TIME [epoch: 9.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5449174302155664		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.5449174302155664 | validation: 0.6978036830508941]
	TIME [epoch: 9.51 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47378843485463606		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.47378843485463606 | validation: 1.6109747610371443]
	TIME [epoch: 9.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7851579839245268		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.7851579839245268 | validation: 0.6188336735380751]
	TIME [epoch: 9.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49017127156396934		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.49017127156396934 | validation: 1.071693079583033]
	TIME [epoch: 9.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.561145861144859		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.561145861144859 | validation: 0.5694096542231847]
	TIME [epoch: 9.51 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893588371814737		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.3893588371814737 | validation: 0.6311283355247541]
	TIME [epoch: 9.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5572585800178059		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.5572585800178059 | validation: 0.7339620785180133]
	TIME [epoch: 9.49 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6591896315403905		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.6591896315403905 | validation: 0.7800360009707562]
	TIME [epoch: 9.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5461267253404835		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.5461267253404835 | validation: 0.5300368012899912]
	TIME [epoch: 9.51 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.417214957708455		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.417214957708455 | validation: 0.913491993477425]
	TIME [epoch: 9.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5669185149356617		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.5669185149356617 | validation: 0.5436868235760226]
	TIME [epoch: 9.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42773076517171116		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.42773076517171116 | validation: 0.3350165420906624]
	TIME [epoch: 9.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108312400165385		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.3108312400165385 | validation: 0.3468688767992713]
	TIME [epoch: 9.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37466943506313566		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.37466943506313566 | validation: 0.34806450766222413]
	TIME [epoch: 9.49 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.382424531652049		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.382424531652049 | validation: 0.3828208550609536]
	TIME [epoch: 9.49 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4053998169392397		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.4053998169392397 | validation: 0.30978262327226325]
	TIME [epoch: 9.52 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2985778856506063		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.2985778856506063 | validation: 0.23277230643116284]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3093929158202414		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.3093929158202414 | validation: 0.3192202047994685]
	TIME [epoch: 9.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36505256985730705		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.36505256985730705 | validation: 0.3421745949681653]
	TIME [epoch: 9.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32846757386803044		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.32846757386803044 | validation: 0.28746635663442127]
	TIME [epoch: 9.51 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156219577896974		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.3156219577896974 | validation: 0.2826199915800025]
	TIME [epoch: 9.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32485319626427456		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.32485319626427456 | validation: 0.310674168503207]
	TIME [epoch: 9.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46444299169273506		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.46444299169273506 | validation: 0.29253581320622457]
	TIME [epoch: 9.53 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34446870025043885		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.34446870025043885 | validation: 0.33322962682633295]
	TIME [epoch: 9.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31612701903032703		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.31612701903032703 | validation: 0.3627756192735641]
	TIME [epoch: 9.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27452038087756236		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.27452038087756236 | validation: 0.27171137212804775]
	TIME [epoch: 9.49 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3586894609401653		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.3586894609401653 | validation: 0.30837002940491504]
	TIME [epoch: 9.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32159088544587794		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.32159088544587794 | validation: 0.3574459580731969]
	TIME [epoch: 9.49 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439328624564374		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.4439328624564374 | validation: 0.7292254576757552]
	TIME [epoch: 9.51 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44560839477912034		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.44560839477912034 | validation: 0.5300771884153321]
	TIME [epoch: 9.51 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3468275594566702		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.3468275594566702 | validation: 0.26676834227878643]
	TIME [epoch: 9.51 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26317742349731377		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.26317742349731377 | validation: 0.37051498034373737]
	TIME [epoch: 9.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3016333499692245		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.3016333499692245 | validation: 0.3720000509280689]
	TIME [epoch: 9.53 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38685795270586326		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.38685795270586326 | validation: 0.23846857596415344]
	TIME [epoch: 9.51 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3209626675305813		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.3209626675305813 | validation: 0.20706360663118126]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_809.pth
	Model improved!!!
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2553450629177413		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.2553450629177413 | validation: 0.16609459084225137]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.312047732712682		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.312047732712682 | validation: 0.2984365606042076]
	TIME [epoch: 9.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35865939978411354		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.35865939978411354 | validation: 0.4189867754501089]
	TIME [epoch: 9.51 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3465804933657263		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.3465804933657263 | validation: 0.3953338716440416]
	TIME [epoch: 9.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3160189398995065		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.3160189398995065 | validation: 0.21883440067702764]
	TIME [epoch: 9.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501095872188416		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.2501095872188416 | validation: 0.2872096886277794]
	TIME [epoch: 9.51 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34560656363272557		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.34560656363272557 | validation: 0.34474482641271836]
	TIME [epoch: 9.51 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34603974811782756		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.34603974811782756 | validation: 0.3910905415108259]
	TIME [epoch: 9.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3234470269476325		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.3234470269476325 | validation: 0.24063972293399827]
	TIME [epoch: 9.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2554157578082404		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.2554157578082404 | validation: 0.26652972562795735]
	TIME [epoch: 9.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22629021746790193		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.22629021746790193 | validation: 0.3101559027416724]
	TIME [epoch: 9.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925773826058651		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.2925773826058651 | validation: 0.47729705338624256]
	TIME [epoch: 9.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48238537937493		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.48238537937493 | validation: 0.5199250441956248]
	TIME [epoch: 9.51 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4067305306634765		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.4067305306634765 | validation: 0.3360453742339504]
	TIME [epoch: 9.51 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28729463411846584		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.28729463411846584 | validation: 0.35641511395015146]
	TIME [epoch: 9.51 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7171997085440742		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.7171997085440742 | validation: 0.26414607593266815]
	TIME [epoch: 9.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152377083636048		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.3152377083636048 | validation: 0.2702301903903084]
	TIME [epoch: 9.53 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.340200955881764		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.340200955881764 | validation: 0.3692006785974961]
	TIME [epoch: 9.51 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33911218408290655		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.33911218408290655 | validation: 0.2999314089847639]
	TIME [epoch: 9.51 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.300610893262659		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.300610893262659 | validation: 0.3906693342894906]
	TIME [epoch: 9.51 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3291839923300227		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.3291839923300227 | validation: 0.5246779657864061]
	TIME [epoch: 9.52 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33656904974517887		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.33656904974517887 | validation: 0.2500221310569303]
	TIME [epoch: 9.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3841441818057243		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.3841441818057243 | validation: 0.24710216591260004]
	TIME [epoch: 9.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2779155656160368		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.2779155656160368 | validation: 0.15262913588236932]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28191535649767147		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.28191535649767147 | validation: 0.34024826708958755]
	TIME [epoch: 9.51 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031337365661636		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.3031337365661636 | validation: 0.3458791960506929]
	TIME [epoch: 9.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28775178059147966		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.28775178059147966 | validation: 0.26913259711629334]
	TIME [epoch: 9.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955864736319922		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.2955864736319922 | validation: 0.26243824543932043]
	TIME [epoch: 9.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4430574105730692		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.4430574105730692 | validation: 0.6423961772181278]
	TIME [epoch: 9.51 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3896053142266855		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.3896053142266855 | validation: 0.6976043278559323]
	TIME [epoch: 9.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3665127123033052		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.3665127123033052 | validation: 0.13755332751212265]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_840.pth
	Model improved!!!
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3915730187460699		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.3915730187460699 | validation: 0.30740743595041375]
	TIME [epoch: 9.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734587465099366		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.2734587465099366 | validation: 0.19771251317546704]
	TIME [epoch: 9.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21622278353259775		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.21622278353259775 | validation: 0.4590671685359983]
	TIME [epoch: 9.51 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4148266889267262		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.4148266889267262 | validation: 0.4479179978955046]
	TIME [epoch: 9.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3697438566941239		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.3697438566941239 | validation: 0.3188682791217748]
	TIME [epoch: 9.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28711890790985917		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.28711890790985917 | validation: 0.590145785863666]
	TIME [epoch: 9.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3483978489128897		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.3483978489128897 | validation: 0.36513480247642177]
	TIME [epoch: 9.52 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3584559580083056		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.3584559580083056 | validation: 0.4560210996224501]
	TIME [epoch: 9.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164724280787501		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.6164724280787501 | validation: 0.631251751969972]
	TIME [epoch: 9.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41975263687766207		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.41975263687766207 | validation: 0.22819940563203026]
	TIME [epoch: 9.52 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23692341889642843		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.23692341889642843 | validation: 0.5588582399066645]
	TIME [epoch: 9.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41848618899430623		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.41848618899430623 | validation: 0.29154926704166395]
	TIME [epoch: 9.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23606233262504306		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.23606233262504306 | validation: 0.3213086150311705]
	TIME [epoch: 9.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2595866667265447		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.2595866667265447 | validation: 0.26421516547926494]
	TIME [epoch: 9.52 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24656109471858345		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.24656109471858345 | validation: 0.3509850716354213]
	TIME [epoch: 9.49 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199142401866494		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.3199142401866494 | validation: 0.451004859794432]
	TIME [epoch: 9.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3778665762166179		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.3778665762166179 | validation: 0.3117659918785456]
	TIME [epoch: 9.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30581465894397636		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.30581465894397636 | validation: 0.3511198549959748]
	TIME [epoch: 9.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29855626580999595		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.29855626580999595 | validation: 0.39854564363847045]
	TIME [epoch: 9.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909621022889441		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3909621022889441 | validation: 0.3824122677753206]
	TIME [epoch: 9.51 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33634183933630457		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.33634183933630457 | validation: 0.2707801235097212]
	TIME [epoch: 9.53 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186381638657312		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.3186381638657312 | validation: 0.4671634931164941]
	TIME [epoch: 9.51 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240864743454242		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.3240864743454242 | validation: 0.5724790511727397]
	TIME [epoch: 9.52 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4595031406841308		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.4595031406841308 | validation: 0.3335439388021996]
	TIME [epoch: 9.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.281076143792225		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.281076143792225 | validation: 0.41076485992947415]
	TIME [epoch: 9.52 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3674445071420842		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.3674445071420842 | validation: 0.2908526530513769]
	TIME [epoch: 9.51 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716017824158806		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.2716017824158806 | validation: 0.36228421151029944]
	TIME [epoch: 9.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33469794872778186		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.33469794872778186 | validation: 0.32445342208100314]
	TIME [epoch: 9.52 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29698094241996154		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.29698094241996154 | validation: 0.4989504585872423]
	TIME [epoch: 9.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740524250267375		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.3740524250267375 | validation: 0.3839217196835007]
	TIME [epoch: 9.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3711746651649278		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.3711746651649278 | validation: 0.26536825276012266]
	TIME [epoch: 9.54 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31681589245960406		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.31681589245960406 | validation: 0.580515594642654]
	TIME [epoch: 9.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4115553437576486		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.4115553437576486 | validation: 0.27168041582443075]
	TIME [epoch: 9.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29540995388498226		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.29540995388498226 | validation: 0.25482938866813387]
	TIME [epoch: 9.54 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33337156532344486		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.33337156532344486 | validation: 0.4397214890775322]
	TIME [epoch: 9.53 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020892454627332		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.3020892454627332 | validation: 0.21586596574928657]
	TIME [epoch: 9.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26926144411284164		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.26926144411284164 | validation: 0.28771170278290853]
	TIME [epoch: 9.52 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237416976007214		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.3237416976007214 | validation: 0.48420714818911575]
	TIME [epoch: 9.54 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492487889150367		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.4492487889150367 | validation: 0.3871931130422627]
	TIME [epoch: 9.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121237546300127		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.5121237546300127 | validation: 0.4224149521517487]
	TIME [epoch: 9.52 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.312817292070059		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.312817292070059 | validation: 0.3096063087556899]
	TIME [epoch: 9.53 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5874610229355112		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.5874610229355112 | validation: 0.3512678264520525]
	TIME [epoch: 9.53 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36684246760284295		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.36684246760284295 | validation: 0.34344367927103703]
	TIME [epoch: 9.53 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29532791743008835		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.29532791743008835 | validation: 0.368234793004579]
	TIME [epoch: 9.52 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576344522543592		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.2576344522543592 | validation: 0.22234956596979097]
	TIME [epoch: 9.53 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24049778849975695		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.24049778849975695 | validation: 0.24699261019624114]
	TIME [epoch: 9.52 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3251081660841747		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.3251081660841747 | validation: 0.245463118227039]
	TIME [epoch: 9.51 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230813359713752		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.3230813359713752 | validation: 0.6047723717874116]
	TIME [epoch: 9.53 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39098214167459966		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.39098214167459966 | validation: 0.34220665819407386]
	TIME [epoch: 9.53 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36564299601241373		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.36564299601241373 | validation: 0.5254484393453313]
	TIME [epoch: 9.52 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36795306911524844		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.36795306911524844 | validation: 0.3792277007833361]
	TIME [epoch: 9.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662246345488124		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.2662246345488124 | validation: 0.1928556146891095]
	TIME [epoch: 9.54 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836270620028572		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.2836270620028572 | validation: 0.45221724457188117]
	TIME [epoch: 9.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.409458191081802		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.409458191081802 | validation: 0.2513729674147948]
	TIME [epoch: 9.51 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135062340252027		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.3135062340252027 | validation: 0.43842233138407194]
	TIME [epoch: 9.53 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3745021015931618		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.3745021015931618 | validation: 0.220762051516462]
	TIME [epoch: 9.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3173684312537084		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.3173684312537084 | validation: 0.2794141883043326]
	TIME [epoch: 9.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31349883797132044		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.31349883797132044 | validation: 0.3175298084377873]
	TIME [epoch: 9.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3378655527307733		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.3378655527307733 | validation: 0.379693605195358]
	TIME [epoch: 9.54 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168893115367302		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.3168893115367302 | validation: 0.2248175807078869]
	TIME [epoch: 9.51 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22478827523829858		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.22478827523829858 | validation: 0.22880788506545352]
	TIME [epoch: 9.51 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999695065013615		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.2999695065013615 | validation: 0.3431822441270275]
	TIME [epoch: 9.54 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44405042447278176		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.44405042447278176 | validation: 0.48960106209732973]
	TIME [epoch: 9.51 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3684203144241927		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.3684203144241927 | validation: 0.20829599885980066]
	TIME [epoch: 9.53 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27630166873509243		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.27630166873509243 | validation: 0.3140963493409707]
	TIME [epoch: 9.52 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22949786978080677		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.22949786978080677 | validation: 0.421221300449522]
	TIME [epoch: 9.54 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38064725689227863		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.38064725689227863 | validation: 0.249732052749388]
	TIME [epoch: 9.52 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3375992000698138		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.3375992000698138 | validation: 0.37992449365795594]
	TIME [epoch: 9.51 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256223640673941		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.256223640673941 | validation: 0.22161325471803112]
	TIME [epoch: 9.53 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23895898543445676		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.23895898543445676 | validation: 0.2561422046293537]
	TIME [epoch: 9.51 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35570554862681913		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.35570554862681913 | validation: 0.4333162207201421]
	TIME [epoch: 9.51 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295823129417073		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.3295823129417073 | validation: 0.1930068544077031]
	TIME [epoch: 9.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2074489546441499		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.2074489546441499 | validation: 0.21026903694660903]
	TIME [epoch: 9.53 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2970556362224134		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.2970556362224134 | validation: 0.3430339403991732]
	TIME [epoch: 9.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531356329920881		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.2531356329920881 | validation: 0.2248388571130427]
	TIME [epoch: 9.51 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24817816921125138		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.24817816921125138 | validation: 0.28076362582881315]
	TIME [epoch: 9.53 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2379728584678502		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.2379728584678502 | validation: 0.19914299601498933]
	TIME [epoch: 9.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748849935472672		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2748849935472672 | validation: 0.3704019064956927]
	TIME [epoch: 9.51 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221824238575517		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.3221824238575517 | validation: 0.5032143404074289]
	TIME [epoch: 9.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3540490641427855		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.3540490641427855 | validation: 0.18848869595673734]
	TIME [epoch: 9.51 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28222932811785717		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.28222932811785717 | validation: 0.5447021543575911]
	TIME [epoch: 9.49 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3956814358305344		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.3956814358305344 | validation: 0.3341630340707372]
	TIME [epoch: 9.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131679936884442		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.3131679936884442 | validation: 0.6415067221520877]
	TIME [epoch: 9.51 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3726378011414712		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.3726378011414712 | validation: 0.26115783249385355]
	TIME [epoch: 9.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24813142054691228		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.24813142054691228 | validation: 0.17011856383820884]
	TIME [epoch: 9.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33906044769327615		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.33906044769327615 | validation: 0.3894153317869133]
	TIME [epoch: 9.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302736311694578		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.3302736311694578 | validation: 0.285674337870613]
	TIME [epoch: 9.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.282925632280982		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.282925632280982 | validation: 0.27455835659583244]
	TIME [epoch: 9.51 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26248338581412234		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.26248338581412234 | validation: 0.2638708329192395]
	TIME [epoch: 9.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2656519179320459		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.2656519179320459 | validation: 0.29923109913243934]
	TIME [epoch: 9.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2465218240799945		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.2465218240799945 | validation: 0.4053406410055201]
	TIME [epoch: 9.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3449262799577523		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.3449262799577523 | validation: 0.29610715346395006]
	TIME [epoch: 9.51 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920953530920497		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.2920953530920497 | validation: 0.26364707766474166]
	TIME [epoch: 9.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2854972642726204		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.2854972642726204 | validation: 0.3458581269849592]
	TIME [epoch: 9.51 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2837129357064048		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.2837129357064048 | validation: 0.21034619904799368]
	TIME [epoch: 9.51 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25086072671686754		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.25086072671686754 | validation: 0.4612934411915459]
	TIME [epoch: 9.51 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749161309006587		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.2749161309006587 | validation: 0.44011323851135786]
	TIME [epoch: 9.52 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24778064861519908		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.24778064861519908 | validation: 0.3614789931563248]
	TIME [epoch: 9.52 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28470352669612015		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.28470352669612015 | validation: 0.5635458790110399]
	TIME [epoch: 9.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3016696793210484		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.3016696793210484 | validation: 0.5515651056118313]
	TIME [epoch: 9.51 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32363975385678156		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.32363975385678156 | validation: 0.3106305166616626]
	TIME [epoch: 9.51 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22664381698035788		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.22664381698035788 | validation: 0.20014509137535663]
	TIME [epoch: 9.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20483842544815753		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.20483842544815753 | validation: 0.17256193375211737]
	TIME [epoch: 9.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20764019967597985		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.20764019967597985 | validation: 0.20064418673154194]
	TIME [epoch: 9.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21102003551361936		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.21102003551361936 | validation: 0.3191182012112439]
	TIME [epoch: 9.51 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3263202362927577		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.3263202362927577 | validation: 0.27203040283961233]
	TIME [epoch: 9.51 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34034662044696135		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.34034662044696135 | validation: 0.2691307898625035]
	TIME [epoch: 9.51 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2184129196977583		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.2184129196977583 | validation: 0.35143180357959447]
	TIME [epoch: 9.52 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2312495701710228		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.2312495701710228 | validation: 0.26371577112001404]
	TIME [epoch: 9.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21720070788348456		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.21720070788348456 | validation: 0.24736778604602372]
	TIME [epoch: 9.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736537608342379		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.2736537608342379 | validation: 0.17068178778278978]
	TIME [epoch: 9.53 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637017079536216		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.2637017079536216 | validation: 0.2510007531516126]
	TIME [epoch: 9.51 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22427857506918877		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.22427857506918877 | validation: 0.30390566978458206]
	TIME [epoch: 9.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237392980331304		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.2237392980331304 | validation: 0.2568806466027945]
	TIME [epoch: 9.51 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28645088728667917		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.28645088728667917 | validation: 0.35479145504359993]
	TIME [epoch: 9.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20076440625750558		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.20076440625750558 | validation: 0.25004794343428083]
	TIME [epoch: 9.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26785644933455555		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.26785644933455555 | validation: 0.18652921541187156]
	TIME [epoch: 9.51 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2632813401626967		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.2632813401626967 | validation: 0.19733671910524297]
	TIME [epoch: 9.53 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577730426829565		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.2577730426829565 | validation: 0.38135798657298525]
	TIME [epoch: 9.51 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2835087214651807		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.2835087214651807 | validation: 0.20405360508373832]
	TIME [epoch: 9.51 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21757255533333913		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.21757255533333913 | validation: 0.24507896754001732]
	TIME [epoch: 9.51 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23777172124754808		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.23777172124754808 | validation: 0.2222568930535657]
	TIME [epoch: 9.52 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2162001419191276		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.2162001419191276 | validation: 0.23033543315444582]
	TIME [epoch: 9.51 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26274730223933884		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.26274730223933884 | validation: 0.2590228003911251]
	TIME [epoch: 9.49 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25893168089778706		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.25893168089778706 | validation: 0.33558840649462474]
	TIME [epoch: 9.53 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28350206005561207		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.28350206005561207 | validation: 0.23795337443147457]
	TIME [epoch: 9.51 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22549847573576018		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.22549847573576018 | validation: 0.31867294165032184]
	TIME [epoch: 9.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2671129720518155		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.2671129720518155 | validation: 0.30094464283930517]
	TIME [epoch: 9.53 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21364838331436986		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.21364838331436986 | validation: 0.26791533695872854]
	TIME [epoch: 9.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23313122528404584		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.23313122528404584 | validation: 0.3552192156485786]
	TIME [epoch: 9.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036291338303947		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.3036291338303947 | validation: 0.3160235978522314]
	TIME [epoch: 9.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26395872167596857		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.26395872167596857 | validation: 0.17722447415103265]
	TIME [epoch: 9.52 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24251983823564688		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.24251983823564688 | validation: 0.24849310920632423]
	TIME [epoch: 9.51 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22784562683979975		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.22784562683979975 | validation: 0.22506130498133978]
	TIME [epoch: 9.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25107582124964256		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.25107582124964256 | validation: 0.3110978996283661]
	TIME [epoch: 9.52 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2843569353106153		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.2843569353106153 | validation: 0.7061979562676797]
	TIME [epoch: 9.51 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4375828753235627		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.4375828753235627 | validation: 0.3728457074823466]
	TIME [epoch: 9.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2021414503048114		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2021414503048114 | validation: 0.2635719094275279]
	TIME [epoch: 9.51 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2778169409606053		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.2778169409606053 | validation: 0.5051684970662503]
	TIME [epoch: 9.53 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3014932456063062		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.3014932456063062 | validation: 0.28612365470425605]
	TIME [epoch: 9.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2627306857984213		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.2627306857984213 | validation: 0.5568291913292169]
	TIME [epoch: 9.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33329558545866755		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.33329558545866755 | validation: 0.2728884065861805]
	TIME [epoch: 9.53 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.201055642479206		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.201055642479206 | validation: 0.18495925685983103]
	TIME [epoch: 9.51 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2093599538083757		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.2093599538083757 | validation: 0.2411913539404539]
	TIME [epoch: 9.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260484493630839		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.3260484493630839 | validation: 0.3827530443856822]
	TIME [epoch: 9.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27333594007126233		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.27333594007126233 | validation: 0.20629971966938676]
	TIME [epoch: 9.52 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24164296929510093		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.24164296929510093 | validation: 0.31532147410480527]
	TIME [epoch: 9.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2814196043164454		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.2814196043164454 | validation: 0.353203506629348]
	TIME [epoch: 9.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013402881545741		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.3013402881545741 | validation: 0.232636561670079]
	TIME [epoch: 9.52 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2714976866093408		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.2714976866093408 | validation: 0.2327529374523305]
	TIME [epoch: 9.51 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24987992385256397		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.24987992385256397 | validation: 0.22545743424901027]
	TIME [epoch: 9.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23433282068453654		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.23433282068453654 | validation: 0.2180474161928882]
	TIME [epoch: 9.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1916130662775451		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.1916130662775451 | validation: 0.25585541289814356]
	TIME [epoch: 9.53 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23156827004106978		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.23156827004106978 | validation: 0.18637312331279127]
	TIME [epoch: 9.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517659840137091		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.2517659840137091 | validation: 0.6225884747152369]
	TIME [epoch: 9.51 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4364431433350637		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.4364431433350637 | validation: 0.34720338724435496]
	TIME [epoch: 9.52 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29755887029924166		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.29755887029924166 | validation: 0.23106833356146886]
	TIME [epoch: 9.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27442003194742554		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.27442003194742554 | validation: 0.35085955358334076]
	TIME [epoch: 9.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24367180683161466		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.24367180683161466 | validation: 0.3629526059305234]
	TIME [epoch: 9.52 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27841642728214333		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.27841642728214333 | validation: 0.25753587188682187]
	TIME [epoch: 9.53 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24971009162770735		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.24971009162770735 | validation: 0.2918962560072987]
	TIME [epoch: 9.51 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22704115146641204		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.22704115146641204 | validation: 0.2675440842823837]
	TIME [epoch: 9.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243786241971199		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.243786241971199 | validation: 0.2894740202839089]
	TIME [epoch: 9.53 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660485118374991		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.2660485118374991 | validation: 0.29948161580537735]
	TIME [epoch: 9.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21448899460849308		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.21448899460849308 | validation: 0.22093659342655725]
	TIME [epoch: 9.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24217563231162104		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.24217563231162104 | validation: 0.4254070942377959]
	TIME [epoch: 9.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2170089904341507		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.2170089904341507 | validation: 0.20887481998557014]
	TIME [epoch: 9.52 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1899598240053741		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.1899598240053741 | validation: 0.21187413234976668]
	TIME [epoch: 9.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15976416192144108		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.15976416192144108 | validation: 0.2915419105021655]
	TIME [epoch: 9.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22370219240137845		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.22370219240137845 | validation: 0.42558695048754075]
	TIME [epoch: 9.53 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667744185935679		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.2667744185935679 | validation: 0.4349568849892464]
	TIME [epoch: 9.51 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24394180578871744		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.24394180578871744 | validation: 0.2587281584257095]
	TIME [epoch: 9.51 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23294292352735244		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.23294292352735244 | validation: 0.3343805217774009]
	TIME [epoch: 9.52 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651338964736434		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.2651338964736434 | validation: 0.25610747662024397]
	TIME [epoch: 9.52 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24485508023371388		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.24485508023371388 | validation: 0.1359804961719911]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1015.pth
	Model improved!!!
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16486352344748137		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.16486352344748137 | validation: 0.19466489310717086]
	TIME [epoch: 9.51 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16731579402583843		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.16731579402583843 | validation: 0.2172354867707234]
	TIME [epoch: 9.53 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2941853908784052		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.2941853908784052 | validation: 0.30833111463119695]
	TIME [epoch: 9.51 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24400876448115807		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.24400876448115807 | validation: 0.36552714004379283]
	TIME [epoch: 9.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2042205478721805		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.2042205478721805 | validation: 0.39557901997809325]
	TIME [epoch: 9.52 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1909030632194995		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.1909030632194995 | validation: 0.35479572067433374]
	TIME [epoch: 9.52 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2871156069309957		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.2871156069309957 | validation: 0.33973085823413485]
	TIME [epoch: 9.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3639141649831319		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.3639141649831319 | validation: 0.7845568233168373]
	TIME [epoch: 9.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39456331561403185		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.39456331561403185 | validation: 0.38342521670890833]
	TIME [epoch: 9.52 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3471206518781301		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.3471206518781301 | validation: 0.6972219424646585]
	TIME [epoch: 9.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4359801833238627		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.4359801833238627 | validation: 0.5704022354312506]
	TIME [epoch: 9.49 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882922052016874		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.3882922052016874 | validation: 0.3031281183529429]
	TIME [epoch: 9.51 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19583586362575972		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.19583586362575972 | validation: 0.37661818052756374]
	TIME [epoch: 9.52 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642781781242848		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.2642781781242848 | validation: 0.3896723861884809]
	TIME [epoch: 9.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24062455131284635		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.24062455131284635 | validation: 0.345042093693616]
	TIME [epoch: 9.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23468953934296283		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.23468953934296283 | validation: 0.3660833426618554]
	TIME [epoch: 9.53 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32395888335868617		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.32395888335868617 | validation: 0.30428647624438854]
	TIME [epoch: 9.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24384748066189688		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.24384748066189688 | validation: 0.316199574415616]
	TIME [epoch: 9.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2726906892705401		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.2726906892705401 | validation: 0.3625802258155841]
	TIME [epoch: 9.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24634910305833335		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.24634910305833335 | validation: 0.48583167134238353]
	TIME [epoch: 9.51 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30700766335258123		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.30700766335258123 | validation: 0.5159692182650899]
	TIME [epoch: 9.51 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2892013945105346		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.2892013945105346 | validation: 0.3860330494532479]
	TIME [epoch: 9.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041959984169765		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.3041959984169765 | validation: 0.28195386253659677]
	TIME [epoch: 9.53 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20036797057442501		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.20036797057442501 | validation: 0.39829289576146254]
	TIME [epoch: 9.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782637724007595		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.2782637724007595 | validation: 0.3370989430585584]
	TIME [epoch: 9.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.284039704527293		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.284039704527293 | validation: 0.35670028675037735]
	TIME [epoch: 9.52 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734996831164821		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2734996831164821 | validation: 0.3274374489956894]
	TIME [epoch: 9.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23028738427427914		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.23028738427427914 | validation: 0.2871136893756084]
	TIME [epoch: 9.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21625052558386176		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.21625052558386176 | validation: 0.2548777965540072]
	TIME [epoch: 9.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20191777688510631		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.20191777688510631 | validation: 0.2733990964637259]
	TIME [epoch: 9.53 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18591016477781017		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.18591016477781017 | validation: 0.2792597127700709]
	TIME [epoch: 9.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22301153801092316		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.22301153801092316 | validation: 0.19539928031963155]
	TIME [epoch: 9.51 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21050057676855088		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.21050057676855088 | validation: 0.18800096721147833]
	TIME [epoch: 9.52 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17994251961082602		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.17994251961082602 | validation: 0.1707171244896521]
	TIME [epoch: 9.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639196111265156		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.1639196111265156 | validation: 0.26559869079677156]
	TIME [epoch: 9.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20233256674331349		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.20233256674331349 | validation: 0.13265363686497803]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1051.pth
	Model improved!!!
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20820085863153737		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.20820085863153737 | validation: 0.17248937086032975]
	TIME [epoch: 9.54 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21478393999499418		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.21478393999499418 | validation: 0.17694906874862668]
	TIME [epoch: 9.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21527136960976345		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.21527136960976345 | validation: 0.24798725433139546]
	TIME [epoch: 9.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1779110515414092		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.1779110515414092 | validation: 0.16627895266298567]
	TIME [epoch: 9.53 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17304130475937907		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.17304130475937907 | validation: 0.21035805222681128]
	TIME [epoch: 9.51 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18534480014144475		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.18534480014144475 | validation: 0.14752042263279083]
	TIME [epoch: 9.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17447191971422332		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.17447191971422332 | validation: 0.22076033855138746]
	TIME [epoch: 9.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176024934391039		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.176024934391039 | validation: 0.2904441134647989]
	TIME [epoch: 9.53 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21007871841595632		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.21007871841595632 | validation: 0.13602245345708405]
	TIME [epoch: 9.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14613167881292913		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.14613167881292913 | validation: 0.12280479914708055]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276967086691913		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.1276967086691913 | validation: 0.12649620306437723]
	TIME [epoch: 9.52 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17269990807493335		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.17269990807493335 | validation: 0.23868680860754793]
	TIME [epoch: 9.51 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20579478652142572		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.20579478652142572 | validation: 0.16430707083029927]
	TIME [epoch: 9.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21424393695054503		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.21424393695054503 | validation: 0.33265313778389627]
	TIME [epoch: 9.51 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26860560080024515		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.26860560080024515 | validation: 0.37273344418522053]
	TIME [epoch: 9.52 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2482693755502563		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.2482693755502563 | validation: 0.21864143957716622]
	TIME [epoch: 9.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2279271482394653		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.2279271482394653 | validation: 0.28766888426152454]
	TIME [epoch: 9.49 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2371372057465851		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.2371372057465851 | validation: 0.18810865183497677]
	TIME [epoch: 9.51 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16774273555839952		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.16774273555839952 | validation: 0.273097448179886]
	TIME [epoch: 9.49 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29449706947665943		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.29449706947665943 | validation: 0.1783139152615128]
	TIME [epoch: 9.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797719825476535		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.1797719825476535 | validation: 0.20599307098340977]
	TIME [epoch: 9.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17907555078820264		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.17907555078820264 | validation: 0.19424686932312568]
	TIME [epoch: 9.52 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18008658915807088		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.18008658915807088 | validation: 0.20944063810899832]
	TIME [epoch: 9.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22761928805665482		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.22761928805665482 | validation: 0.3270273502304715]
	TIME [epoch: 9.49 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.265136067756042		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.265136067756042 | validation: 0.1672716865635023]
	TIME [epoch: 9.52 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18835206242470365		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.18835206242470365 | validation: 0.2877004178600943]
	TIME [epoch: 9.51 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20899896338944335		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.20899896338944335 | validation: 0.1945400127572961]
	TIME [epoch: 9.51 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613474881999119		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.1613474881999119 | validation: 0.1417597762024995]
	TIME [epoch: 9.51 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14924529326884967		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.14924529326884967 | validation: 0.22828607356314748]
	TIME [epoch: 9.51 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.220656364534147		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.220656364534147 | validation: 0.1394133128947915]
	TIME [epoch: 9.51 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19456681812724588		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.19456681812724588 | validation: 0.25310534587029077]
	TIME [epoch: 9.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21354775055923328		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.21354775055923328 | validation: 0.14726358526041405]
	TIME [epoch: 9.53 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18151438033080952		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.18151438033080952 | validation: 0.4343430784505346]
	TIME [epoch: 9.51 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19565664877584207		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.19565664877584207 | validation: 0.2315694402355532]
	TIME [epoch: 9.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16378451713684314		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.16378451713684314 | validation: 0.1390326927032025]
	TIME [epoch: 9.51 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16898278899805594		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.16898278899805594 | validation: 0.16417738584389568]
	TIME [epoch: 9.51 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20986500938605018		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.20986500938605018 | validation: 0.20343580346951812]
	TIME [epoch: 9.51 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2066199002399017		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.2066199002399017 | validation: 0.2733367658181548]
	TIME [epoch: 9.51 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20789813063089846		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.20789813063089846 | validation: 0.15051206097861464]
	TIME [epoch: 9.53 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770759330030902		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.1770759330030902 | validation: 0.21764069434357097]
	TIME [epoch: 9.52 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15755106088765009		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15755106088765009 | validation: 0.16324518764386559]
	TIME [epoch: 9.51 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13466676693291252		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.13466676693291252 | validation: 0.1313189958724116]
	TIME [epoch: 9.53 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2270748454645739		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.2270748454645739 | validation: 0.11747893908016256]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1094.pth
	Model improved!!!
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1976313778504975		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.1976313778504975 | validation: 0.2727461078952086]
	TIME [epoch: 9.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18298099067487478		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.18298099067487478 | validation: 0.13424788155723225]
	TIME [epoch: 9.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16711657572176603		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.16711657572176603 | validation: 0.13063584998231734]
	TIME [epoch: 9.52 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15591228286920086		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.15591228286920086 | validation: 0.17261164215247315]
	TIME [epoch: 9.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18318161648924258		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.18318161648924258 | validation: 0.1937025323722159]
	TIME [epoch: 9.51 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17956413344452807		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.17956413344452807 | validation: 0.2572545896323689]
	TIME [epoch: 9.52 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2266623217023859		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.2266623217023859 | validation: 0.21961328630824778]
	TIME [epoch: 9.51 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16952263022352956		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.16952263022352956 | validation: 0.14493046055881387]
	TIME [epoch: 9.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16321401736529317		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.16321401736529317 | validation: 0.2061734037158059]
	TIME [epoch: 9.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789195992184606		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.1789195992184606 | validation: 0.1488626675420595]
	TIME [epoch: 9.53 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14144330139365907		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.14144330139365907 | validation: 0.29786829643090423]
	TIME [epoch: 9.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25292930811946623		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.25292930811946623 | validation: 0.1750342036836021]
	TIME [epoch: 9.51 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17540927355285504		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.17540927355285504 | validation: 0.1413062731740157]
	TIME [epoch: 9.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16275005923887673		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.16275005923887673 | validation: 0.1439538950833191]
	TIME [epoch: 9.51 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13211268466092702		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.13211268466092702 | validation: 0.15196343800423354]
	TIME [epoch: 9.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1603103206816565		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.1603103206816565 | validation: 0.18192153079033196]
	TIME [epoch: 9.52 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18642634110809292		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.18642634110809292 | validation: 0.20689417197763008]
	TIME [epoch: 9.52 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14154152635570624		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.14154152635570624 | validation: 0.14769481730376824]
	TIME [epoch: 9.51 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18108602911230184		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.18108602911230184 | validation: 0.1960995890475008]
	TIME [epoch: 9.51 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18799500450607484		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.18799500450607484 | validation: 0.11519251278124162]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1114.pth
	Model improved!!!
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618761260376321		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.1618761260376321 | validation: 0.12413211931351197]
	TIME [epoch: 9.52 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1650331853480227		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.1650331853480227 | validation: 0.12432049461967803]
	TIME [epoch: 9.51 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14132197692016146		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.14132197692016146 | validation: 0.10018617395893077]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1117.pth
	Model improved!!!
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15180577843820978		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.15180577843820978 | validation: 0.19763012166825739]
	TIME [epoch: 9.53 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911561645914095		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.1911561645914095 | validation: 0.12819195101504427]
	TIME [epoch: 9.51 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155740885152348		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.155740885152348 | validation: 0.19161158125101246]
	TIME [epoch: 9.52 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1710598583789153		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.1710598583789153 | validation: 0.2452963080380939]
	TIME [epoch: 9.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937428713523508		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.1937428713523508 | validation: 0.18116753331047256]
	TIME [epoch: 9.52 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17100776892116437		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.17100776892116437 | validation: 0.12243601930545424]
	TIME [epoch: 9.51 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1348071131153598		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.1348071131153598 | validation: 0.15209421362104905]
	TIME [epoch: 9.53 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15604018527636987		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.15604018527636987 | validation: 0.14940165866616265]
	TIME [epoch: 9.52 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15053274103898037		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.15053274103898037 | validation: 0.16057791561677676]
	TIME [epoch: 9.51 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20397853423538992		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.20397853423538992 | validation: 0.13490313905963341]
	TIME [epoch: 9.52 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13738205662692318		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.13738205662692318 | validation: 0.12886931465252174]
	TIME [epoch: 9.53 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14513776792564542		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.14513776792564542 | validation: 0.13600889334897506]
	TIME [epoch: 9.51 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793875473771498		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.1793875473771498 | validation: 0.18996853818683546]
	TIME [epoch: 9.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13748066095850636		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.13748066095850636 | validation: 0.15642234229708085]
	TIME [epoch: 9.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14688674024439602		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.14688674024439602 | validation: 0.2005196142282325]
	TIME [epoch: 9.52 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682284381902726		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.1682284381902726 | validation: 0.1798449589886254]
	TIME [epoch: 9.51 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21758586330782953		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.21758586330782953 | validation: 0.23002565425870392]
	TIME [epoch: 9.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20418922559622388		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.20418922559622388 | validation: 0.15657308625128333]
	TIME [epoch: 9.53 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675905412296661		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.1675905412296661 | validation: 0.21010049739145195]
	TIME [epoch: 9.51 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18053579910332784		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.18053579910332784 | validation: 0.13467076368443842]
	TIME [epoch: 9.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588562969169467		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.1588562969169467 | validation: 0.22658345439293295]
	TIME [epoch: 9.51 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.171719667752688		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.171719667752688 | validation: 0.36336807900588797]
	TIME [epoch: 9.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15782202063743617		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.15782202063743617 | validation: 0.31730202300144184]
	TIME [epoch: 9.49 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652258476155323		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.1652258476155323 | validation: 0.1554562895684533]
	TIME [epoch: 9.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1402571722259966		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.1402571722259966 | validation: 0.24955240556750155]
	TIME [epoch: 9.51 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24191540080217666		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.24191540080217666 | validation: 0.2443684038594685]
	TIME [epoch: 9.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16061991766344746		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.16061991766344746 | validation: 0.32083353691347427]
	TIME [epoch: 9.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18406339414325162		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.18406339414325162 | validation: 0.22569942165940604]
	TIME [epoch: 9.51 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692190757907193		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.1692190757907193 | validation: 0.2389523451951196]
	TIME [epoch: 9.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1688582833645381		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.1688582833645381 | validation: 0.25595347925200196]
	TIME [epoch: 9.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522872121651841		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.1522872121651841 | validation: 0.18053611108237505]
	TIME [epoch: 9.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20509545243307764		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.20509545243307764 | validation: 0.16567941914985126]
	TIME [epoch: 9.53 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14565071121764617		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.14565071121764617 | validation: 0.14078656938005527]
	TIME [epoch: 9.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502534083184803		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.2502534083184803 | validation: 0.42548551100947946]
	TIME [epoch: 9.51 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16724921070065632		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.16724921070065632 | validation: 0.2504790922170039]
	TIME [epoch: 9.52 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19224770234275845		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.19224770234275845 | validation: 0.14461053699162496]
	TIME [epoch: 9.52 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1309551922694486		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.1309551922694486 | validation: 0.27890157371490376]
	TIME [epoch: 9.51 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16601940492232597		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.16601940492232597 | validation: 0.13249827541260853]
	TIME [epoch: 9.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604759467768957		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.1604759467768957 | validation: 0.16929682920306546]
	TIME [epoch: 9.52 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12995756449097717		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.12995756449097717 | validation: 0.10809896884137386]
	TIME [epoch: 9.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15874089144481948		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.15874089144481948 | validation: 0.1439662575275945]
	TIME [epoch: 9.51 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16648028095784886		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.16648028095784886 | validation: 0.15619877263007198]
	TIME [epoch: 9.53 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14929752880271546		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.14929752880271546 | validation: 0.19730369039216242]
	TIME [epoch: 9.52 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16393899272695595		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.16393899272695595 | validation: 0.3519976780323239]
	TIME [epoch: 9.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2006194459574754		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.2006194459574754 | validation: 0.32472632013813796]
	TIME [epoch: 9.51 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17624856168305097		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.17624856168305097 | validation: 0.30554727147883315]
	TIME [epoch: 9.53 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17375902993031575		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.17375902993031575 | validation: 0.35818639873637637]
	TIME [epoch: 9.51 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2403572786022612		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.2403572786022612 | validation: 0.35790530456139336]
	TIME [epoch: 9.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.228558886804533		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.228558886804533 | validation: 0.16933902559538763]
	TIME [epoch: 9.53 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16506709512734985		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.16506709512734985 | validation: 0.13464137753528818]
	TIME [epoch: 9.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13891911079337388		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.13891911079337388 | validation: 0.16281045224892773]
	TIME [epoch: 9.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17100976535759857		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.17100976535759857 | validation: 0.14452093167124158]
	TIME [epoch: 9.51 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1450437743391389		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.1450437743391389 | validation: 0.10382708017112645]
	TIME [epoch: 9.51 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14499884038037014		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.14499884038037014 | validation: 0.4350354680486438]
	TIME [epoch: 9.51 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26562075724842993		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.26562075724842993 | validation: 0.22535126824055454]
	TIME [epoch: 9.51 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16106530870122246		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.16106530870122246 | validation: 0.13486857123607363]
	TIME [epoch: 9.53 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935812653831686		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.1935812653831686 | validation: 0.22620399758053286]
	TIME [epoch: 9.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22899333271077352		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.22899333271077352 | validation: 0.5878783394326773]
	TIME [epoch: 9.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24062538335426478		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.24062538335426478 | validation: 0.12787651678891096]
	TIME [epoch: 9.51 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12205497733250462		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.12205497733250462 | validation: 0.2018346796630128]
	TIME [epoch: 9.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15869275436830724		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.15869275436830724 | validation: 0.13732406223895502]
	TIME [epoch: 9.51 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.131250539337861		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.131250539337861 | validation: 0.1242812825838773]
	TIME [epoch: 9.51 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252576198743517		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.15252576198743517 | validation: 0.19491546180819275]
	TIME [epoch: 9.53 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18392014457940048		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.18392014457940048 | validation: 0.17570806625725283]
	TIME [epoch: 9.51 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12645596667864717		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.12645596667864717 | validation: 0.34093613199902023]
	TIME [epoch: 9.51 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22631848691449905		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.22631848691449905 | validation: 0.18242595855165525]
	TIME [epoch: 9.52 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13812990288926993		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.13812990288926993 | validation: 0.21821739067236473]
	TIME [epoch: 9.77 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19235255982133373		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.19235255982133373 | validation: 0.2058825819666528]
	TIME [epoch: 9.52 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16556176591025165		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.16556176591025165 | validation: 0.15306372132743407]
	TIME [epoch: 9.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15287793861021653		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.15287793861021653 | validation: 0.20522953696892743]
	TIME [epoch: 9.54 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16804581602257934		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.16804581602257934 | validation: 0.10964172249911565]
	TIME [epoch: 9.53 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12065633251340362		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.12065633251340362 | validation: 0.12318158784172231]
	TIME [epoch: 9.52 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15235207013167196		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.15235207013167196 | validation: 0.13916916828534984]
	TIME [epoch: 9.53 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16216730135644658		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.16216730135644658 | validation: 0.12255684264281877]
	TIME [epoch: 9.53 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1795785831510895		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.1795785831510895 | validation: 0.2584470574437544]
	TIME [epoch: 9.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638874745452285		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.1638874745452285 | validation: 0.11515344042898347]
	TIME [epoch: 9.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1381422718523868		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.1381422718523868 | validation: 0.19190829416672026]
	TIME [epoch: 9.54 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14243323060881152		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.14243323060881152 | validation: 0.15409748112526256]
	TIME [epoch: 9.52 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591120273827385		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.1591120273827385 | validation: 0.2594925583561059]
	TIME [epoch: 9.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671715151354287		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.1671715151354287 | validation: 0.13002513923271886]
	TIME [epoch: 9.53 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14345345406227963		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.14345345406227963 | validation: 0.1521772942351711]
	TIME [epoch: 9.53 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15901747921045856		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.15901747921045856 | validation: 0.13370706062038135]
	TIME [epoch: 9.52 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569550670789016		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.1569550670789016 | validation: 0.128278159876813]
	TIME [epoch: 9.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720397706881715		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.1720397706881715 | validation: 0.12710196817745864]
	TIME [epoch: 9.54 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15554735665120728		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.15554735665120728 | validation: 0.17467014722267643]
	TIME [epoch: 9.52 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15342204497292203		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.15342204497292203 | validation: 0.23016959035107576]
	TIME [epoch: 9.52 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18377359139429916		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.18377359139429916 | validation: 0.1288035768297672]
	TIME [epoch: 9.54 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12639156776826607		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.12639156776826607 | validation: 0.14387088397227152]
	TIME [epoch: 9.52 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25421620912161247		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.25421620912161247 | validation: 0.19481737660338241]
	TIME [epoch: 9.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18458636444764084		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.18458636444764084 | validation: 0.17477071089386978]
	TIME [epoch: 9.52 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13465198341943602		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.13465198341943602 | validation: 0.18725296029624872]
	TIME [epoch: 9.54 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16762577982480908		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.16762577982480908 | validation: 0.15165137437357126]
	TIME [epoch: 9.52 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515564398608314		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.1515564398608314 | validation: 0.11525508042099278]
	TIME [epoch: 9.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18179655852307164		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.18179655852307164 | validation: 0.22860815483724004]
	TIME [epoch: 9.54 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19388667307195773		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.19388667307195773 | validation: 0.22512212731099937]
	TIME [epoch: 9.52 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15664132498957958		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.15664132498957958 | validation: 0.1316189763670924]
	TIME [epoch: 9.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19418976371813113		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.19418976371813113 | validation: 0.3699563529613465]
	TIME [epoch: 9.52 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1952263861600619		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.1952263861600619 | validation: 0.15480050740585]
	TIME [epoch: 9.54 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1295537146008495		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.1295537146008495 | validation: 0.18781820661158008]
	TIME [epoch: 9.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595831999552036		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.1595831999552036 | validation: 0.1883790242164331]
	TIME [epoch: 9.52 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13132671639737725		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.13132671639737725 | validation: 0.18570194114014915]
	TIME [epoch: 9.54 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12117402906078115		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.12117402906078115 | validation: 0.145059143733341]
	TIME [epoch: 9.52 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18727223943739518		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.18727223943739518 | validation: 0.19735756165256543]
	TIME [epoch: 9.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15992964007681393		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.15992964007681393 | validation: 0.25582281632876763]
	TIME [epoch: 9.52 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15189550293959606		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.15189550293959606 | validation: 0.1446734815516016]
	TIME [epoch: 9.54 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14140915033229892		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.14140915033229892 | validation: 0.15687065727625263]
	TIME [epoch: 9.52 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15633803304808166		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.15633803304808166 | validation: 0.29186092033706634]
	TIME [epoch: 9.51 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19397460027959768		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.19397460027959768 | validation: 0.3677920681329217]
	TIME [epoch: 9.53 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1876986103782473		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.1876986103782473 | validation: 0.24827521953011952]
	TIME [epoch: 9.52 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16813930742989244		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.16813930742989244 | validation: 0.15627169933709673]
	TIME [epoch: 9.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1330480234426367		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.1330480234426367 | validation: 0.09987261296912316]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1228.pth
	Model improved!!!
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16202037261666175		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.16202037261666175 | validation: 0.1510949044874619]
	TIME [epoch: 9.53 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14112078523970786		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.14112078523970786 | validation: 0.14242422954211562]
	TIME [epoch: 9.51 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13357457381671212		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.13357457381671212 | validation: 0.15432352184990952]
	TIME [epoch: 9.51 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674629344415808		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.1674629344415808 | validation: 0.13950227461867595]
	TIME [epoch: 9.53 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14984536401044285		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.14984536401044285 | validation: 0.1392909480460138]
	TIME [epoch: 9.52 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14528340731847206		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.14528340731847206 | validation: 0.11262659746243552]
	TIME [epoch: 9.51 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15506196595459248		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.15506196595459248 | validation: 0.1610633657010665]
	TIME [epoch: 9.53 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13776926340775636		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.13776926340775636 | validation: 0.14288847571185975]
	TIME [epoch: 9.52 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15491374752442938		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.15491374752442938 | validation: 0.13129158466136084]
	TIME [epoch: 9.52 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14727631460049598		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.14727631460049598 | validation: 0.1660177084723785]
	TIME [epoch: 9.51 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14287638584338874		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.14287638584338874 | validation: 0.1551714668811646]
	TIME [epoch: 9.53 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15075450960388742		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.15075450960388742 | validation: 0.25604662859271854]
	TIME [epoch: 9.52 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1890360874840694		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.1890360874840694 | validation: 0.1803755261061657]
	TIME [epoch: 9.52 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711419094516713		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.1711419094516713 | validation: 0.17231280097652474]
	TIME [epoch: 9.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12689371252554058		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.12689371252554058 | validation: 0.13482232977498837]
	TIME [epoch: 9.52 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14376982827813528		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.14376982827813528 | validation: 0.16560993349620418]
	TIME [epoch: 9.51 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1926187901484105		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.1926187901484105 | validation: 0.2139353206643571]
	TIME [epoch: 9.51 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19612378365655367		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.19612378365655367 | validation: 0.15406934941403955]
	TIME [epoch: 9.53 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512319573381074		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.1512319573381074 | validation: 0.1643332633010511]
	TIME [epoch: 9.52 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16556802837266343		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.16556802837266343 | validation: 0.1645227429271349]
	TIME [epoch: 9.51 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513110679356004		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.1513110679356004 | validation: 0.1899277100111462]
	TIME [epoch: 9.52 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16550051670681987		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.16550051670681987 | validation: 0.14986825997824454]
	TIME [epoch: 9.52 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1442217471300917		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.1442217471300917 | validation: 0.1886715461375274]
	TIME [epoch: 9.51 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1409648884541363		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.1409648884541363 | validation: 0.10206369750980748]
	TIME [epoch: 9.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14100131949250497		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.14100131949250497 | validation: 0.1366179034379569]
	TIME [epoch: 9.54 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10961277223971955		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.10961277223971955 | validation: 0.17413498788515813]
	TIME [epoch: 9.51 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16326858992783183		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.16326858992783183 | validation: 0.10912912082635788]
	TIME [epoch: 9.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14258753017951933		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.14258753017951933 | validation: 0.17743150972120197]
	TIME [epoch: 9.53 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14191785131123807		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.14191785131123807 | validation: 0.12246867834929628]
	TIME [epoch: 9.51 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12184067963858536		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.12184067963858536 | validation: 0.18388500574560845]
	TIME [epoch: 9.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21802157925917162		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.21802157925917162 | validation: 0.3323471352356833]
	TIME [epoch: 9.51 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15849182889168595		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.15849182889168595 | validation: 0.10986865798762431]
	TIME [epoch: 9.52 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10869496524854409		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.10869496524854409 | validation: 0.12540640948033324]
	TIME [epoch: 9.51 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14035992517220378		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.14035992517220378 | validation: 0.12005373634490972]
	TIME [epoch: 9.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16665139244143737		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.16665139244143737 | validation: 0.12203435440226189]
	TIME [epoch: 9.53 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16385684533549566		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.16385684533549566 | validation: 0.19326642053488896]
	TIME [epoch: 9.51 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18304016507277304		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.18304016507277304 | validation: 0.14297204175526787]
	TIME [epoch: 9.52 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1722742420781379		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.1722742420781379 | validation: 0.2185581199309116]
	TIME [epoch: 9.51 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16898079193074353		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.16898079193074353 | validation: 0.12000150904492728]
	TIME [epoch: 9.53 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15782173616613918		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.15782173616613918 | validation: 0.18062346703658436]
	TIME [epoch: 9.51 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14506055364942053		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.14506055364942053 | validation: 0.12265235526605513]
	TIME [epoch: 9.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14918600568068863		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.14918600568068863 | validation: 0.14560021800075568]
	TIME [epoch: 9.52 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16717761356733757		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.16717761356733757 | validation: 0.2363336911036599]
	TIME [epoch: 9.52 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581786068443926		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.1581786068443926 | validation: 0.1585305131787707]
	TIME [epoch: 9.51 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14512623493486534		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.14512623493486534 | validation: 0.1333991808789938]
	TIME [epoch: 9.51 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14510597974046524		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.14510597974046524 | validation: 0.14790961574893746]
	TIME [epoch: 9.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154216102452494		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.154216102452494 | validation: 0.13304370875779384]
	TIME [epoch: 9.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14780987908037996		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.14780987908037996 | validation: 0.13089870758064492]
	TIME [epoch: 9.51 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13111135353608372		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.13111135353608372 | validation: 0.10508085581756799]
	TIME [epoch: 9.53 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10295732466594083		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.10295732466594083 | validation: 0.17281028952048316]
	TIME [epoch: 9.52 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1358170961292224		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.1358170961292224 | validation: 0.19983282311361542]
	TIME [epoch: 9.52 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399310768511015		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.15399310768511015 | validation: 0.13168627326678883]
	TIME [epoch: 9.52 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1278889286811018		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.1278889286811018 | validation: 0.15861590225037478]
	TIME [epoch: 9.53 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14520100693961424		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.14520100693961424 | validation: 0.16161148863580363]
	TIME [epoch: 9.51 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18456662171740174		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.18456662171740174 | validation: 0.17079519250435757]
	TIME [epoch: 9.51 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1461049942592321		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.1461049942592321 | validation: 0.14008072813745281]
	TIME [epoch: 9.53 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1523303679120309		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.1523303679120309 | validation: 0.14361123973193504]
	TIME [epoch: 9.51 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14839482320623745		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.14839482320623745 | validation: 0.14093029747544247]
	TIME [epoch: 9.51 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17620980922519242		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.17620980922519242 | validation: 0.2530294228484877]
	TIME [epoch: 9.51 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17545022898652224		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.17545022898652224 | validation: 0.15323495909766735]
	TIME [epoch: 9.53 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11717995029103223		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.11717995029103223 | validation: 0.16399678668109652]
	TIME [epoch: 9.51 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1396570092264034		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.1396570092264034 | validation: 0.17209558960005972]
	TIME [epoch: 9.51 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12700674811138415		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.12700674811138415 | validation: 0.21299305478066585]
	TIME [epoch: 9.53 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14318651698944426		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.14318651698944426 | validation: 0.15449489376537448]
	TIME [epoch: 9.51 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1356033680896047		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.1356033680896047 | validation: 0.19706297303573841]
	TIME [epoch: 9.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14390620874550378		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.14390620874550378 | validation: 0.29901021718351783]
	TIME [epoch: 9.52 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2697656244141213		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.2697656244141213 | validation: 0.2851886216105639]
	TIME [epoch: 9.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1487543373258597		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.1487543373258597 | validation: 0.20962701553997407]
	TIME [epoch: 9.51 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13532635404451904		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.13532635404451904 | validation: 0.17683120639585856]
	TIME [epoch: 9.51 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1357956291056309		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.1357956291056309 | validation: 0.2838237117995921]
	TIME [epoch: 9.52 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19723521258632312		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.19723521258632312 | validation: 0.16760343436408953]
	TIME [epoch: 9.52 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11201784326515649		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.11201784326515649 | validation: 0.2340349436536292]
	TIME [epoch: 9.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14673399457013686		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.14673399457013686 | validation: 0.1933271254092372]
	TIME [epoch: 9.52 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15296249896713912		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.15296249896713912 | validation: 0.20792062825318713]
	TIME [epoch: 9.52 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20237657585754804		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.20237657585754804 | validation: 0.3370312207295396]
	TIME [epoch: 9.51 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18265718872501577		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.18265718872501577 | validation: 0.30063160001434475]
	TIME [epoch: 9.51 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20855581205058144		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.20855581205058144 | validation: 0.3202476361937802]
	TIME [epoch: 9.53 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17442956260130438		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.17442956260130438 | validation: 0.20264752912400621]
	TIME [epoch: 9.51 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15522674474813475		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.15522674474813475 | validation: 0.1827997044094731]
	TIME [epoch: 9.51 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14295959054505522		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.14295959054505522 | validation: 0.23695322795082316]
	TIME [epoch: 9.52 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1874765512042759		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.1874765512042759 | validation: 0.22794970828111638]
	TIME [epoch: 9.52 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474723760761417		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.1474723760761417 | validation: 0.2371901652344608]
	TIME [epoch: 9.51 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15183347434641611		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.15183347434641611 | validation: 0.23037986465634636]
	TIME [epoch: 9.51 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12852332463800215		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.12852332463800215 | validation: 0.16161582304891056]
	TIME [epoch: 9.53 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14856054343689135		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.14856054343689135 | validation: 0.19111418100185673]
	TIME [epoch: 9.51 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13764051250896644		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.13764051250896644 | validation: 0.1685971485167674]
	TIME [epoch: 9.51 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13422577059992088		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.13422577059992088 | validation: 0.15320455761902116]
	TIME [epoch: 9.52 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166612975466336		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.1166612975466336 | validation: 0.17701264344696757]
	TIME [epoch: 9.52 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562673743618729		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.1562673743618729 | validation: 0.1414632541886308]
	TIME [epoch: 9.51 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15232416009751965		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.15232416009751965 | validation: 0.12708473728768094]
	TIME [epoch: 9.51 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254625582409098		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.1254625582409098 | validation: 0.15394011473246624]
	TIME [epoch: 9.53 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10560180787432874		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.10560180787432874 | validation: 0.12210104901707448]
	TIME [epoch: 9.51 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1005060504522706		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.1005060504522706 | validation: 0.10823531228043443]
	TIME [epoch: 9.52 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13248299401945188		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.13248299401945188 | validation: 0.22101887367175457]
	TIME [epoch: 9.52 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16531789970670147		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.16531789970670147 | validation: 0.12137582624777278]
	TIME [epoch: 9.51 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1372954609001763		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.1372954609001763 | validation: 0.12678374448369858]
	TIME [epoch: 9.51 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13113238903547308		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.13113238903547308 | validation: 0.12289009201913116]
	TIME [epoch: 9.51 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14127138365293293		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.14127138365293293 | validation: 0.16226262977584863]
	TIME [epoch: 9.52 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15298067039872681		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.15298067039872681 | validation: 0.13871479967071426]
	TIME [epoch: 9.51 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12587350584025386		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.12587350584025386 | validation: 0.1275720403150296]
	TIME [epoch: 9.51 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12120532431818216		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.12120532431818216 | validation: 0.19950370187477312]
	TIME [epoch: 9.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15720144124303292		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.15720144124303292 | validation: 0.12874620371125306]
	TIME [epoch: 9.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11571199550005562		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.11571199550005562 | validation: 0.1702269725596987]
	TIME [epoch: 9.51 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682805807485497		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.1682805807485497 | validation: 0.1703450660830621]
	TIME [epoch: 9.51 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15538147697840535		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.15538147697840535 | validation: 0.2525897907513007]
	TIME [epoch: 9.53 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2328465233866872		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.2328465233866872 | validation: 0.18640779749223477]
	TIME [epoch: 9.51 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15090101994732402		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.15090101994732402 | validation: 0.2072656926172727]
	TIME [epoch: 9.51 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14796030261709875		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.14796030261709875 | validation: 0.27013239077240137]
	TIME [epoch: 9.52 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14202379521466213		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.14202379521466213 | validation: 0.10168261832988719]
	TIME [epoch: 9.51 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11189609029630013		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.11189609029630013 | validation: 0.10971969906430898]
	TIME [epoch: 9.51 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1412153905468248		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.1412153905468248 | validation: 0.1780880721722408]
	TIME [epoch: 9.51 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17095705369694364		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.17095705369694364 | validation: 0.20962541959023526]
	TIME [epoch: 9.53 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15122170148181685		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.15122170148181685 | validation: 0.1988051585719694]
	TIME [epoch: 9.51 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1395215884102738		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.1395215884102738 | validation: 0.13663955163797653]
	TIME [epoch: 9.51 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10065401416402328		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.10065401416402328 | validation: 0.1798139658976881]
	TIME [epoch: 9.53 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12680278162897804		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.12680278162897804 | validation: 0.2237209207743416]
	TIME [epoch: 9.51 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11277755468709846		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.11277755468709846 | validation: 0.16343249703467463]
	TIME [epoch: 9.51 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1095140459525972		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.1095140459525972 | validation: 0.3576659645910948]
	TIME [epoch: 9.51 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16994125325087167		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.16994125325087167 | validation: 0.27497122159647835]
	TIME [epoch: 9.53 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1424565894859674		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.1424565894859674 | validation: 0.2003952961190298]
	TIME [epoch: 9.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1442607693267003		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.1442607693267003 | validation: 0.10117159149773372]
	TIME [epoch: 9.51 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11141596951298345		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.11141596951298345 | validation: 0.13872817932663334]
	TIME [epoch: 9.52 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14093044036511918		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.14093044036511918 | validation: 0.19862589679700912]
	TIME [epoch: 9.51 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12271494522591533		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.12271494522591533 | validation: 0.13861126108389793]
	TIME [epoch: 9.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1433775037186468		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.1433775037186468 | validation: 0.18153568532945172]
	TIME [epoch: 9.51 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16395312355508307		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.16395312355508307 | validation: 0.24553549521721568]
	TIME [epoch: 9.52 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515478087487419		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.1515478087487419 | validation: 0.1259162120996023]
	TIME [epoch: 9.51 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13870153174581618		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.13870153174581618 | validation: 0.09596767380651697]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1356.pth
	Model improved!!!
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.098114157838385		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.098114157838385 | validation: 0.12956760592305477]
	TIME [epoch: 9.54 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13032909960600422		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.13032909960600422 | validation: 0.10134932059853308]
	TIME [epoch: 9.52 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10179500152527432		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.10179500152527432 | validation: 0.13811205081937838]
	TIME [epoch: 9.52 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12058453701482041		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.12058453701482041 | validation: 0.1875374477581019]
	TIME [epoch: 9.52 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11338863432500021		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.11338863432500021 | validation: 0.13859610627743585]
	TIME [epoch: 9.53 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1367747125141568		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.1367747125141568 | validation: 0.24728378997403933]
	TIME [epoch: 9.51 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14577649563728692		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.14577649563728692 | validation: 0.2854967370206129]
	TIME [epoch: 9.51 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13969288452345627		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.13969288452345627 | validation: 0.1276773347907117]
	TIME [epoch: 9.53 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13031957632334462		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.13031957632334462 | validation: 0.13980778736213215]
	TIME [epoch: 9.52 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12793844505075375		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.12793844505075375 | validation: 0.16184547915347813]
	TIME [epoch: 9.51 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15079205548407462		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.15079205548407462 | validation: 0.13810979062471357]
	TIME [epoch: 9.53 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11866379576002732		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.11866379576002732 | validation: 0.138429726855002]
	TIME [epoch: 9.52 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10977944918142582		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.10977944918142582 | validation: 0.15379167530441748]
	TIME [epoch: 9.52 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12684540868432173		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.12684540868432173 | validation: 0.17606666633942616]
	TIME [epoch: 9.52 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11124344012112855		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.11124344012112855 | validation: 0.1194289376501711]
	TIME [epoch: 9.54 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11975370636384892		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.11975370636384892 | validation: 0.12511413564847776]
	TIME [epoch: 9.51 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11423715800832035		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.11423715800832035 | validation: 0.19480513106807024]
	TIME [epoch: 9.51 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12810565215309444		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.12810565215309444 | validation: 0.16155668968596892]
	TIME [epoch: 9.53 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12109097422454577		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.12109097422454577 | validation: 0.12034826931966279]
	TIME [epoch: 9.52 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12813110364440544		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.12813110364440544 | validation: 0.17703590810884137]
	TIME [epoch: 9.52 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1086326289648035		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.1086326289648035 | validation: 0.1280419085501359]
	TIME [epoch: 9.52 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13829573179332394		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.13829573179332394 | validation: 0.18997080774196565]
	TIME [epoch: 9.53 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14733361889558333		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.14733361889558333 | validation: 0.17128437031908725]
	TIME [epoch: 9.52 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14744477792186567		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.14744477792186567 | validation: 0.1257752020506104]
	TIME [epoch: 9.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12504736642546493		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.12504736642546493 | validation: 0.12075586095694753]
	TIME [epoch: 9.53 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09752360156331816		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.09752360156331816 | validation: 0.16927455318207213]
	TIME [epoch: 9.51 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154548249857747		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.154548249857747 | validation: 0.1298737476407309]
	TIME [epoch: 9.51 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12255448258752821		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.12255448258752821 | validation: 0.14955615943721792]
	TIME [epoch: 9.51 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475998671801843		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.1475998671801843 | validation: 0.22817146457028947]
	TIME [epoch: 9.53 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14311673067662273		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.14311673067662273 | validation: 0.2383622668794118]
	TIME [epoch: 9.51 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147229108689459		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.147229108689459 | validation: 0.16913303474315566]
	TIME [epoch: 9.51 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13079977619543304		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.13079977619543304 | validation: 0.10914907572625579]
	TIME [epoch: 9.53 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13762617206114078		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.13762617206114078 | validation: 0.11963156551161395]
	TIME [epoch: 9.52 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13068568627535826		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.13068568627535826 | validation: 0.1577017403373533]
	TIME [epoch: 9.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12752103143789312		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.12752103143789312 | validation: 0.17818871348527673]
	TIME [epoch: 9.51 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13693166992663058		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.13693166992663058 | validation: 0.15527442592879065]
	TIME [epoch: 9.53 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15259310939293264		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.15259310939293264 | validation: 0.11243587609704646]
	TIME [epoch: 9.52 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13418288917845228		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.13418288917845228 | validation: 0.17960848211053212]
	TIME [epoch: 9.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11407969379618962		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.11407969379618962 | validation: 0.12294554974503374]
	TIME [epoch: 9.53 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10036028418868717		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.10036028418868717 | validation: 0.13358349726126514]
	TIME [epoch: 9.51 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15180100951559355		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.15180100951559355 | validation: 0.14940021713337676]
	TIME [epoch: 9.52 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12189983000538315		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.12189983000538315 | validation: 0.14574999095707192]
	TIME [epoch: 9.51 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11362474942765037		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.11362474942765037 | validation: 0.12205413449985582]
	TIME [epoch: 9.54 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10964765423077358		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.10964765423077358 | validation: 0.10237834943030868]
	TIME [epoch: 9.52 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1116332715630618		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.1116332715630618 | validation: 0.1401624593751288]
	TIME [epoch: 9.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2122662179854478		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.2122662179854478 | validation: 0.26675309418220294]
	TIME [epoch: 9.53 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1787485277795596		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.1787485277795596 | validation: 0.2099487626629679]
	TIME [epoch: 9.52 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342820818061465		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.1342820818061465 | validation: 0.1743855977531729]
	TIME [epoch: 9.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12524508943151721		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.12524508943151721 | validation: 0.171095122604303]
	TIME [epoch: 9.52 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15303148162681496		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.15303148162681496 | validation: 0.22624134785818922]
	TIME [epoch: 9.53 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15943307592573114		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.15943307592573114 | validation: 0.22664813104876808]
	TIME [epoch: 9.51 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16954867019378733		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.16954867019378733 | validation: 0.265394125046436]
	TIME [epoch: 9.51 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689196799160529		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.1689196799160529 | validation: 0.2183135814545712]
	TIME [epoch: 9.53 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14876161289235085		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.14876161289235085 | validation: 0.2010477273992044]
	TIME [epoch: 9.52 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12956072046212272		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.12956072046212272 | validation: 0.1655371829063496]
	TIME [epoch: 9.52 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18720974293447923		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.18720974293447923 | validation: 0.18426623566831626]
	TIME [epoch: 9.52 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775199630764143		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.1775199630764143 | validation: 0.23178051561688648]
	TIME [epoch: 9.53 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1391116292248532		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.1391116292248532 | validation: 0.18050257500545847]
	TIME [epoch: 9.51 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11719602416211176		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.11719602416211176 | validation: 0.16625971444035087]
	TIME [epoch: 9.51 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11357334591833856		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.11357334591833856 | validation: 0.20672734702919232]
	TIME [epoch: 9.54 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13330027579407386		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.13330027579407386 | validation: 0.19567768188994272]
	TIME [epoch: 9.52 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1427723414284484		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.1427723414284484 | validation: 0.18427018492802036]
	TIME [epoch: 9.51 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14155762571793667		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.14155762571793667 | validation: 0.19582420975207046]
	TIME [epoch: 9.52 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1498565470461291		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.1498565470461291 | validation: 0.26828876019915215]
	TIME [epoch: 9.52 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521946553742014		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.1521946553742014 | validation: 0.23500849472246374]
	TIME [epoch: 9.51 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536208812501872		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.1536208812501872 | validation: 0.21723000458212532]
	TIME [epoch: 9.52 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11211670633678641		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.11211670633678641 | validation: 0.2153030991656624]
	TIME [epoch: 9.53 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11753499848298754		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.11753499848298754 | validation: 0.17077634465394867]
	TIME [epoch: 9.52 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12116835064071554		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.12116835064071554 | validation: 0.17102844502715908]
	TIME [epoch: 9.51 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12309250343390395		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.12309250343390395 | validation: 0.1649553680263663]
	TIME [epoch: 9.53 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09144881425835315		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.09144881425835315 | validation: 0.12053636565140177]
	TIME [epoch: 9.52 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11392813976303709		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.11392813976303709 | validation: 0.16513714672593957]
	TIME [epoch: 9.51 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16934374420431836		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.16934374420431836 | validation: 0.20522509383845078]
	TIME [epoch: 9.52 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14088263001800236		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.14088263001800236 | validation: 0.19458371854339473]
	TIME [epoch: 9.53 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21934375526084499		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.21934375526084499 | validation: 0.3525052415264267]
	TIME [epoch: 9.51 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16330582777411368		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.16330582777411368 | validation: 0.25035921944664863]
	TIME [epoch: 9.51 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14276319281343683		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.14276319281343683 | validation: 0.2812932961693053]
	TIME [epoch: 9.53 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1380143003631689		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.1380143003631689 | validation: 0.2368478458709491]
	TIME [epoch: 9.51 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12519246565302092		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.12519246565302092 | validation: 0.2705008167020932]
	TIME [epoch: 9.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14118479716302368		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.14118479716302368 | validation: 0.2898030520045591]
	TIME [epoch: 9.51 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172886171145224		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.172886171145224 | validation: 0.3041114204701518]
	TIME [epoch: 9.53 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18049700592156218		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.18049700592156218 | validation: 0.3159738702934726]
	TIME [epoch: 9.52 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13833261794258492		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.13833261794258492 | validation: 0.21713217403936494]
	TIME [epoch: 9.51 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11463169427977704		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.11463169427977704 | validation: 0.17463552598294677]
	TIME [epoch: 9.53 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13480082017973533		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.13480082017973533 | validation: 0.19932328921505404]
	TIME [epoch: 9.52 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16336052846143373		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.16336052846143373 | validation: 0.17535558139754845]
	TIME [epoch: 9.51 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13245933645939398		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.13245933645939398 | validation: 0.12293286596983626]
	TIME [epoch: 9.51 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10431648931300512		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.10431648931300512 | validation: 0.14707168896846265]
	TIME [epoch: 9.54 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13644870883710628		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.13644870883710628 | validation: 0.19944793327873642]
	TIME [epoch: 9.52 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17725635939834267		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.17725635939834267 | validation: 0.2091359520046125]
	TIME [epoch: 9.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11403150259938107		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.11403150259938107 | validation: 0.11835799102611365]
	TIME [epoch: 9.54 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10157474308236672		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.10157474308236672 | validation: 0.12470908472182585]
	TIME [epoch: 9.52 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10342474517466368		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.10342474517466368 | validation: 0.10917895445374687]
	TIME [epoch: 9.52 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12645216229430786		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.12645216229430786 | validation: 0.1883408721796154]
	TIME [epoch: 9.51 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1271413951845395		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.1271413951845395 | validation: 0.11298733076022018]
	TIME [epoch: 9.53 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11188386106473094		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.11188386106473094 | validation: 0.13661348686645033]
	TIME [epoch: 9.51 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11002109865289238		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.11002109865289238 | validation: 0.13434488113856533]
	TIME [epoch: 9.51 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12310028217968669		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.12310028217968669 | validation: 0.1451634108660325]
	TIME [epoch: 9.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13155320777981316		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.13155320777981316 | validation: 0.1598540295692023]
	TIME [epoch: 9.51 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13014648279831578		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.13014648279831578 | validation: 0.15532533118571992]
	TIME [epoch: 9.51 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1292195796410431		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.1292195796410431 | validation: 0.21272049953840472]
	TIME [epoch: 9.51 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14715864641365337		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.14715864641365337 | validation: 0.21640674643666383]
	TIME [epoch: 9.53 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20323485433064362		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.20323485433064362 | validation: 0.2336195367937674]
	TIME [epoch: 9.51 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18065334579339876		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.18065334579339876 | validation: 0.22523457068515967]
	TIME [epoch: 9.51 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595479887643581		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.1595479887643581 | validation: 0.20384301619841302]
	TIME [epoch: 9.53 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583918506631447		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.1583918506631447 | validation: 0.24929725577224646]
	TIME [epoch: 9.52 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17153541749145132		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.17153541749145132 | validation: 0.21637475575293216]
	TIME [epoch: 9.51 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269613200914096		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.16269613200914096 | validation: 0.1863659462192581]
	TIME [epoch: 9.51 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342571238391426		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.1342571238391426 | validation: 0.19154763974181252]
	TIME [epoch: 9.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1222008630746995		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.1222008630746995 | validation: 0.12753738498270262]
	TIME [epoch: 9.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10785107324887613		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.10785107324887613 | validation: 0.2184378899678866]
	TIME [epoch: 9.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1380017890730932		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.1380017890730932 | validation: 0.14979971842633025]
	TIME [epoch: 9.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10328687897513884		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.10328687897513884 | validation: 0.15528934310943537]
	TIME [epoch: 9.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10065200330457127		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.10065200330457127 | validation: 0.12570447122048123]
	TIME [epoch: 9.51 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12281126437296488		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.12281126437296488 | validation: 0.17532642844432783]
	TIME [epoch: 9.52 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17603975232830033		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.17603975232830033 | validation: 0.2169991326613822]
	TIME [epoch: 9.51 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14701970700579786		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.14701970700579786 | validation: 0.16558456583134074]
	TIME [epoch: 9.51 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12941986045536957		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.12941986045536957 | validation: 0.17478612482700137]
	TIME [epoch: 9.51 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11973218771710241		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.11973218771710241 | validation: 0.1904478726091841]
	TIME [epoch: 9.53 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11812074642581313		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.11812074642581313 | validation: 0.19365343878604094]
	TIME [epoch: 9.51 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13493188812421195		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.13493188812421195 | validation: 0.1914721941181821]
	TIME [epoch: 9.51 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14271241343045665		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.14271241343045665 | validation: 0.2005302308874439]
	TIME [epoch: 9.52 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14717345500113954		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.14717345500113954 | validation: 0.23464793656952643]
	TIME [epoch: 9.52 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16020415819274134		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.16020415819274134 | validation: 0.21096715739510175]
	TIME [epoch: 9.51 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12901422637407256		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.12901422637407256 | validation: 0.21570188469522722]
	TIME [epoch: 9.51 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16244841150951825		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.16244841150951825 | validation: 0.27156431778198203]
	TIME [epoch: 9.52 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15196660779787863		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.15196660779787863 | validation: 0.1776045835706801]
	TIME [epoch: 9.51 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13116115086351127		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.13116115086351127 | validation: 0.2032074830897559]
	TIME [epoch: 9.51 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11629211092107042		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.11629211092107042 | validation: 0.15639287983766229]
	TIME [epoch: 9.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11465076323788555		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.11465076323788555 | validation: 0.1892384757776344]
	TIME [epoch: 9.52 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16876172923988486		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.16876172923988486 | validation: 0.4150532086623066]
	TIME [epoch: 9.51 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21185939642751808		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.21185939642751808 | validation: 0.21664417486149923]
	TIME [epoch: 9.51 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11396016690432038		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.11396016690432038 | validation: 0.24495983274781444]
	TIME [epoch: 9.52 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11220742932753276		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.11220742932753276 | validation: 0.2721470507043215]
	TIME [epoch: 9.51 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13167314123288765		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.13167314123288765 | validation: 0.21406352930524905]
	TIME [epoch: 9.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11241904150803801		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.11241904150803801 | validation: 0.20704293150162123]
	TIME [epoch: 9.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10263531330040561		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.10263531330040561 | validation: 0.2095457901973287]
	TIME [epoch: 9.52 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205225956089661		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.10205225956089661 | validation: 0.25130032204764624]
	TIME [epoch: 9.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13190529331864032		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.13190529331864032 | validation: 0.2702948156568349]
	TIME [epoch: 9.51 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537583516853964		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.1537583516853964 | validation: 0.3164373658118945]
	TIME [epoch: 9.52 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14331407299898788		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.14331407299898788 | validation: 0.21833593923145164]
	TIME [epoch: 9.51 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13801867568632237		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.13801867568632237 | validation: 0.3413260886585448]
	TIME [epoch: 9.51 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711240757466763		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.15711240757466763 | validation: 0.2744058750525373]
	TIME [epoch: 9.53 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14614327339345476		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.14614327339345476 | validation: 0.2632853783382499]
	TIME [epoch: 9.51 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.123061882773802		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.123061882773802 | validation: 0.21604343003553098]
	TIME [epoch: 9.51 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12483903977861802		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.12483903977861802 | validation: 0.229663563632351]
	TIME [epoch: 9.51 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11204476877756833		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.11204476877756833 | validation: 0.1894671562867199]
	TIME [epoch: 9.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13420707815626196		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.13420707815626196 | validation: 0.27743466070099404]
	TIME [epoch: 9.51 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13473742788458487		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.13473742788458487 | validation: 0.12700594843454122]
	TIME [epoch: 9.51 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12572188179561697		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.12572188179561697 | validation: 0.15349391345718913]
	TIME [epoch: 9.53 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12212215246814957		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.12212215246814957 | validation: 0.14010143015422785]
	TIME [epoch: 9.51 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11485766301945628		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.11485766301945628 | validation: 0.13672810571235763]
	TIME [epoch: 9.51 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10220534715201013		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.10220534715201013 | validation: 0.12155620205806496]
	TIME [epoch: 9.51 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11535174846572768		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.11535174846572768 | validation: 0.12793198752013107]
	TIME [epoch: 9.53 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09881937462663401		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.09881937462663401 | validation: 0.13269374007788926]
	TIME [epoch: 9.51 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10002607246905862		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.10002607246905862 | validation: 0.17407251573050772]
	TIME [epoch: 9.51 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12070682845169159		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.12070682845169159 | validation: 0.19936343367516124]
	TIME [epoch: 9.53 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11185162386436756		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.11185162386436756 | validation: 0.11643891831379584]
	TIME [epoch: 9.51 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10842058809759154		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.10842058809759154 | validation: 0.11009814400656687]
	TIME [epoch: 9.51 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11426331989601464		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.11426331989601464 | validation: 0.19329868772274883]
	TIME [epoch: 9.51 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1286601105042092		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.1286601105042092 | validation: 0.11624073432088328]
	TIME [epoch: 9.53 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11235760314296958		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.11235760314296958 | validation: 0.12608044249989975]
	TIME [epoch: 9.51 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09642022225251909		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.09642022225251909 | validation: 0.11240226891867366]
	TIME [epoch: 9.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0989461537568674		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.0989461537568674 | validation: 0.10909119339069764]
	TIME [epoch: 9.52 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10567046152725057		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.10567046152725057 | validation: 0.13106265116924098]
	TIME [epoch: 9.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10473774823838697		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.10473774823838697 | validation: 0.14930405168313704]
	TIME [epoch: 9.51 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09957669246848898		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.09957669246848898 | validation: 0.10633278412481144]
	TIME [epoch: 9.51 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446179698092453		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.10446179698092453 | validation: 0.08445163008709454]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1524.pth
	Model improved!!!
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11038002042395174		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.11038002042395174 | validation: 0.09948203597161318]
	TIME [epoch: 9.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09326604261698876		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.09326604261698876 | validation: 0.07868163959952021]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1526.pth
	Model improved!!!
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343995244465182		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.09343995244465182 | validation: 0.14507644429884128]
	TIME [epoch: 9.53 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212731602994341		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.11212731602994341 | validation: 0.15013387540631112]
	TIME [epoch: 9.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10858907692462227		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.10858907692462227 | validation: 0.16085633608073927]
	TIME [epoch: 9.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11648442118986042		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.11648442118986042 | validation: 0.12921536392123315]
	TIME [epoch: 9.52 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09931367047337804		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.09931367047337804 | validation: 0.091117074648815]
	TIME [epoch: 9.52 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11408426334272884		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.11408426334272884 | validation: 0.13102882352275866]
	TIME [epoch: 9.51 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09342264156802713		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.09342264156802713 | validation: 0.10462821282551543]
	TIME [epoch: 9.49 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09527086266378178		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.09527086266378178 | validation: 0.11900563552051702]
	TIME [epoch: 9.52 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10368861682624056		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.10368861682624056 | validation: 0.10829105785480796]
	TIME [epoch: 9.51 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09625493592248384		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.09625493592248384 | validation: 0.09748931942435819]
	TIME [epoch: 9.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09461756207372904		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.09461756207372904 | validation: 0.12548886347427718]
	TIME [epoch: 9.52 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10078434777402205		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.10078434777402205 | validation: 0.1222860451063081]
	TIME [epoch: 9.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990953118776157		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.0990953118776157 | validation: 0.15020953975181475]
	TIME [epoch: 9.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09473294449696254		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.09473294449696254 | validation: 0.11263724249677573]
	TIME [epoch: 9.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10572923032650501		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.10572923032650501 | validation: 0.10121464895820814]
	TIME [epoch: 9.52 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11710610919105995		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.11710610919105995 | validation: 0.11561869692930087]
	TIME [epoch: 9.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10848923110806372		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.10848923110806372 | validation: 0.12768051427652696]
	TIME [epoch: 9.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12653698501888894		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.12653698501888894 | validation: 0.11001423905388392]
	TIME [epoch: 9.52 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1298935042403672		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.1298935042403672 | validation: 0.11138980515736631]
	TIME [epoch: 9.51 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09415050052246154		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.09415050052246154 | validation: 0.15944504948361238]
	TIME [epoch: 9.51 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1158093159159798		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.1158093159159798 | validation: 0.19451708127931916]
	TIME [epoch: 9.51 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11564290601861311		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.11564290601861311 | validation: 0.2236039138340689]
	TIME [epoch: 9.53 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14684625189345668		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.14684625189345668 | validation: 0.25146773143472545]
	TIME [epoch: 9.51 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1431605358202473		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.1431605358202473 | validation: 0.23689281159862483]
	TIME [epoch: 9.51 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13858445815324882		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.13858445815324882 | validation: 0.21880179583284387]
	TIME [epoch: 9.53 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14728844067104854		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.14728844067104854 | validation: 0.2426917519619383]
	TIME [epoch: 9.51 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14291191969039851		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.14291191969039851 | validation: 0.20749547666163318]
	TIME [epoch: 9.51 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11035578736058335		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.11035578736058335 | validation: 0.20131566734883663]
	TIME [epoch: 9.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12301487531986548		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.12301487531986548 | validation: 0.17815823446574428]
	TIME [epoch: 9.53 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10377259955792797		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.10377259955792797 | validation: 0.15782287411341847]
	TIME [epoch: 9.51 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12788690274135658		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.12788690274135658 | validation: 0.16914462174317257]
	TIME [epoch: 9.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09245791949005021		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.09245791949005021 | validation: 0.11284462597487956]
	TIME [epoch: 9.52 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08995380125092518		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.08995380125092518 | validation: 0.11335224293495973]
	TIME [epoch: 9.51 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09492641644322156		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.09492641644322156 | validation: 0.1474027316241419]
	TIME [epoch: 9.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08226675030727007		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.08226675030727007 | validation: 0.1374248575425773]
	TIME [epoch: 9.51 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08200613680871573		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.08200613680871573 | validation: 0.14137255998739826]
	TIME [epoch: 9.52 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10720754023938013		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.10720754023938013 | validation: 0.18183117506403867]
	TIME [epoch: 9.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10669740345218186		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.10669740345218186 | validation: 0.12806426188052403]
	TIME [epoch: 9.51 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10324660486533221		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.10324660486533221 | validation: 0.1706564758531044]
	TIME [epoch: 9.52 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10082575323248003		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.10082575323248003 | validation: 0.10998049353347579]
	TIME [epoch: 9.51 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11215621758745473		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.11215621758745473 | validation: 0.17453915324048638]
	TIME [epoch: 9.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13598455502609957		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.13598455502609957 | validation: 0.2876880793186439]
	TIME [epoch: 9.52 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15447113071181123		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.15447113071181123 | validation: 0.1846746823207186]
	TIME [epoch: 9.53 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12536950320861323		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.12536950320861323 | validation: 0.19595004079249392]
	TIME [epoch: 9.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12834333738338616		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.12834333738338616 | validation: 0.2067068326025971]
	TIME [epoch: 9.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11189561419519009		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.11189561419519009 | validation: 0.1578565387082564]
	TIME [epoch: 9.52 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11768323674039576		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.11768323674039576 | validation: 0.3043810809444887]
	TIME [epoch: 9.51 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13652066410642533		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.13652066410642533 | validation: 0.19455553122187055]
	TIME [epoch: 9.51 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08832783786507875		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.08832783786507875 | validation: 0.14290105408522544]
	TIME [epoch: 9.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10442503980779608		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.10442503980779608 | validation: 0.15074372743218475]
	TIME [epoch: 9.52 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10908836056516895		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.10908836056516895 | validation: 0.12710483423174357]
	TIME [epoch: 9.51 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08831972814002456		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.08831972814002456 | validation: 0.1253925503364297]
	TIME [epoch: 9.51 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09432829982824956		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.09432829982824956 | validation: 0.13354225374916343]
	TIME [epoch: 9.53 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10545831867825958		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.10545831867825958 | validation: 0.13470848406584676]
	TIME [epoch: 9.51 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09742548610742956		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.09742548610742956 | validation: 0.15159816457851813]
	TIME [epoch: 9.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09946898402805882		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.09946898402805882 | validation: 0.14221445541054156]
	TIME [epoch: 9.52 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10875936403322088		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.10875936403322088 | validation: 0.17211120775993233]
	TIME [epoch: 9.51 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1188033905028814		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.1188033905028814 | validation: 0.170261979875933]
	TIME [epoch: 9.51 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10425541254481577		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.10425541254481577 | validation: 0.13584586312376226]
	TIME [epoch: 9.51 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10332423358878473		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.10332423358878473 | validation: 0.1542964009652563]
	TIME [epoch: 9.52 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10119118620720084		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.10119118620720084 | validation: 0.21574255975256867]
	TIME [epoch: 9.51 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10802346942118476		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.10802346942118476 | validation: 0.14887534704831526]
	TIME [epoch: 9.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10145276594228998		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.10145276594228998 | validation: 0.1593903852115077]
	TIME [epoch: 9.52 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09371428591157988		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.09371428591157988 | validation: 0.15466914354026834]
	TIME [epoch: 9.51 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0957636434394336		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.0957636434394336 | validation: 0.20066111157869343]
	TIME [epoch: 9.51 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1117474877292679		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.1117474877292679 | validation: 0.15868319552408086]
	TIME [epoch: 9.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10521901333963676		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.10521901333963676 | validation: 0.18818883857933955]
	TIME [epoch: 9.52 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10231741495069997		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.10231741495069997 | validation: 0.20913178216446945]
	TIME [epoch: 9.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10756415645260498		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.10756415645260498 | validation: 0.16918171778784064]
	TIME [epoch: 9.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09138006749810579		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.09138006749810579 | validation: 0.1503252495047546]
	TIME [epoch: 9.51 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09011073357559263		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.09011073357559263 | validation: 0.14043953517107674]
	TIME [epoch: 9.51 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09585357435366813		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.09585357435366813 | validation: 0.12221656349516556]
	TIME [epoch: 9.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1096040824008647		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.1096040824008647 | validation: 0.17400565735214416]
	TIME [epoch: 9.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11558863280105174		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.11558863280105174 | validation: 0.2172047459922422]
	TIME [epoch: 9.54 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08876429325186604		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.08876429325186604 | validation: 0.1977832747595274]
	TIME [epoch: 9.51 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11103400582411771		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.11103400582411771 | validation: 0.16846944205001335]
	TIME [epoch: 9.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09795332322478909		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.09795332322478909 | validation: 0.15766085497882112]
	TIME [epoch: 9.53 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09238577037005516		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.09238577037005516 | validation: 0.1480790644508471]
	TIME [epoch: 9.52 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10834948265024417		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.10834948265024417 | validation: 0.1759951398855271]
	TIME [epoch: 9.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11016872251802041		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.11016872251802041 | validation: 0.1437885562051753]
	TIME [epoch: 9.52 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11832811704842175		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.11832811704842175 | validation: 0.19928575861400086]
	TIME [epoch: 9.53 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12087151494212392		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.12087151494212392 | validation: 0.14768777309971118]
	TIME [epoch: 9.51 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10588972419486109		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.10588972419486109 | validation: 0.13523382214126528]
	TIME [epoch: 9.52 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10064200408127791		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.10064200408127791 | validation: 0.1318138333357618]
	TIME [epoch: 9.53 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09055465478934707		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.09055465478934707 | validation: 0.13080995179401053]
	TIME [epoch: 9.51 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08949848332952946		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.08949848332952946 | validation: 0.16282613595035442]
	TIME [epoch: 9.51 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09914877427306926		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.09914877427306926 | validation: 0.15840792604262077]
	TIME [epoch: 9.51 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08878534455220602		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.08878534455220602 | validation: 0.2042520883203714]
	TIME [epoch: 9.53 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10214305654934579		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.10214305654934579 | validation: 0.23000900815170128]
	TIME [epoch: 9.51 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09326537336423231		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.09326537336423231 | validation: 0.15238088079996495]
	TIME [epoch: 9.51 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09313498224767627		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.09313498224767627 | validation: 0.15066940827650296]
	TIME [epoch: 9.53 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10009645049349936		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.10009645049349936 | validation: 0.16382288088551644]
	TIME [epoch: 9.52 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871955045994662		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.0871955045994662 | validation: 0.16498806202382987]
	TIME [epoch: 9.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10473106148376313		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.10473106148376313 | validation: 0.21277934252373257]
	TIME [epoch: 9.51 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10460569456542194		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.10460569456542194 | validation: 0.19427923828013385]
	TIME [epoch: 9.53 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10088370895273295		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.10088370895273295 | validation: 0.19105859918140003]
	TIME [epoch: 9.51 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265295662028565		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.09265295662028565 | validation: 0.16459323204980336]
	TIME [epoch: 9.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935026590699363		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.0935026590699363 | validation: 0.21202424393934693]
	TIME [epoch: 9.53 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11175319015607928		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.11175319015607928 | validation: 0.23582817895771108]
	TIME [epoch: 9.52 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12389312373870906		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.12389312373870906 | validation: 0.23970357164718464]
	TIME [epoch: 9.51 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12462718973497885		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.12462718973497885 | validation: 0.2716984477139497]
	TIME [epoch: 9.51 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13163006640749714		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.13163006640749714 | validation: 0.23583864941013033]
	TIME [epoch: 9.53 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09824096523311236		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.09824096523311236 | validation: 0.2372453363651806]
	TIME [epoch: 9.51 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10465603136215203		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.10465603136215203 | validation: 0.2670511318338062]
	TIME [epoch: 9.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1110263456529513		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.1110263456529513 | validation: 0.25308905861208175]
	TIME [epoch: 9.52 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11151201916038263		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.11151201916038263 | validation: 0.2728936396501946]
	TIME [epoch: 9.51 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11231584954817339		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.11231584954817339 | validation: 0.2621978074631073]
	TIME [epoch: 9.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0932443095632665		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.0932443095632665 | validation: 0.2416052803669185]
	TIME [epoch: 9.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10803381582432896		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.10803381582432896 | validation: 0.2538375361959311]
	TIME [epoch: 9.52 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11380751803579572		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.11380751803579572 | validation: 0.2630986213984511]
	TIME [epoch: 9.51 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10559211878002632		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.10559211878002632 | validation: 0.28887971865944906]
	TIME [epoch: 9.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11899204556481842		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.11899204556481842 | validation: 0.2657668780763919]
	TIME [epoch: 9.53 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10148483328344253		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.10148483328344253 | validation: 0.20978216842225728]
	TIME [epoch: 9.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466389149228525		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.1466389149228525 | validation: 0.2544229500146213]
	TIME [epoch: 9.51 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1361986591515127		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.1361986591515127 | validation: 0.17332683839614607]
	TIME [epoch: 9.52 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10164886929517199		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.10164886929517199 | validation: 0.18246499717119746]
	TIME [epoch: 9.52 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11256099354817657		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.11256099354817657 | validation: 0.17435714111073794]
	TIME [epoch: 9.52 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1045182908274842		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.1045182908274842 | validation: 0.16378600368647506]
	TIME [epoch: 9.51 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10048277069369901		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.10048277069369901 | validation: 0.21268047573238563]
	TIME [epoch: 9.53 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13838647884249913		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.13838647884249913 | validation: 0.24198668969147144]
	TIME [epoch: 9.51 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10922951376999286		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.10922951376999286 | validation: 0.13173895386140935]
	TIME [epoch: 9.51 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10486718637942456		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.10486718637942456 | validation: 0.1528122976494108]
	TIME [epoch: 9.52 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08695928372300545		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.08695928372300545 | validation: 0.09940883548729143]
	TIME [epoch: 9.51 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10290530500520192		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.10290530500520192 | validation: 0.12643246359230217]
	TIME [epoch: 9.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260456730465697		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.08260456730465697 | validation: 0.11449284535250148]
	TIME [epoch: 9.51 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09421458231938552		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.09421458231938552 | validation: 0.10697269538352287]
	TIME [epoch: 9.53 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10072519191958174		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.10072519191958174 | validation: 0.10525736774510805]
	TIME [epoch: 9.52 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10202900275108022		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.10202900275108022 | validation: 0.1265903770848228]
	TIME [epoch: 9.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11506844329098546		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.11506844329098546 | validation: 0.12950894283492642]
	TIME [epoch: 9.52 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1010701750076249		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.1010701750076249 | validation: 0.16505117677246453]
	TIME [epoch: 9.52 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11880661029943518		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.11880661029943518 | validation: 0.16447512938184974]
	TIME [epoch: 9.51 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12833912476036963		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.12833912476036963 | validation: 0.27497946571309473]
	TIME [epoch: 9.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12484732389070866		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.12484732389070866 | validation: 0.11885116962675746]
	TIME [epoch: 9.52 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0895502892501143		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.0895502892501143 | validation: 0.08278450726792226]
	TIME [epoch: 9.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08287731643827365		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.08287731643827365 | validation: 0.11071886592045456]
	TIME [epoch: 9.52 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0968021997523433		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.0968021997523433 | validation: 0.12860177231873626]
	TIME [epoch: 9.53 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09385827393325816		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.09385827393325816 | validation: 0.10363039135661248]
	TIME [epoch: 9.52 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801817423893101		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.0801817423893101 | validation: 0.10338171709801706]
	TIME [epoch: 9.51 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07912724716066363		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.07912724716066363 | validation: 0.0937035975404347]
	TIME [epoch: 9.51 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09915462025334058		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.09915462025334058 | validation: 0.14171705405520704]
	TIME [epoch: 9.53 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000249123635402		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.1000249123635402 | validation: 0.13091346585731578]
	TIME [epoch: 9.51 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09917535008802422		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.09917535008802422 | validation: 0.14083885736961727]
	TIME [epoch: 9.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692991248846861		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.08692991248846861 | validation: 0.18266826264665134]
	TIME [epoch: 9.53 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10741040255070153		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.10741040255070153 | validation: 0.1284689450037913]
	TIME [epoch: 9.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09811868912919046		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.09811868912919046 | validation: 0.11591797611024157]
	TIME [epoch: 9.51 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349772146313001		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.09349772146313001 | validation: 0.11086396318187998]
	TIME [epoch: 9.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08469284269760703		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.08469284269760703 | validation: 0.12425248445871681]
	TIME [epoch: 9.51 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09729292179277131		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.09729292179277131 | validation: 0.13981246290141577]
	TIME [epoch: 9.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771246448304494		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.08771246448304494 | validation: 0.10636185431093889]
	TIME [epoch: 9.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629425649925867		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.09629425649925867 | validation: 0.10005441890340525]
	TIME [epoch: 9.52 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08104795401721585		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.08104795401721585 | validation: 0.13458512137525033]
	TIME [epoch: 9.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09639470647437669		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.09639470647437669 | validation: 0.11605243640278541]
	TIME [epoch: 9.51 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08331520168601905		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.08331520168601905 | validation: 0.15948682202586445]
	TIME [epoch: 9.51 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09885870204430919		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.09885870204430919 | validation: 0.2024241732763564]
	TIME [epoch: 9.52 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10797209327871164		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.10797209327871164 | validation: 0.1536682899603778]
	TIME [epoch: 9.52 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09898324494736412		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.09898324494736412 | validation: 0.08914713200170078]
	TIME [epoch: 9.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09025865863142427		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.09025865863142427 | validation: 0.12013943109740875]
	TIME [epoch: 9.52 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689023636178032		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.08689023636178032 | validation: 0.11081784494692229]
	TIME [epoch: 9.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08438768831689471		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.08438768831689471 | validation: 0.08652695940989315]
	TIME [epoch: 9.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930146213762982		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.0930146213762982 | validation: 0.10689079982457343]
	TIME [epoch: 9.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08297094945001608		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.08297094945001608 | validation: 0.11364825876397873]
	TIME [epoch: 9.52 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09398966090976665		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.09398966090976665 | validation: 0.11349068277935614]
	TIME [epoch: 9.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09554109964584365		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.09554109964584365 | validation: 0.11519175825950662]
	TIME [epoch: 9.51 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912162930279622		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.0912162930279622 | validation: 0.10790431936206804]
	TIME [epoch: 9.52 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1096903112147801		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.1096903112147801 | validation: 0.12945963722490603]
	TIME [epoch: 9.51 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09465756695513408		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.09465756695513408 | validation: 0.08810038159334325]
	TIME [epoch: 9.51 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08904417783595166		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.08904417783595166 | validation: 0.0914628757522528]
	TIME [epoch: 9.52 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08549297837628651		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.08549297837628651 | validation: 0.1170745750048355]
	TIME [epoch: 9.53 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09078753172737088		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.09078753172737088 | validation: 0.09319334500827486]
	TIME [epoch: 9.51 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656877728454188		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.08656877728454188 | validation: 0.13823716357562918]
	TIME [epoch: 9.51 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1296502941930572		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.1296502941930572 | validation: 0.15041115973374386]
	TIME [epoch: 9.53 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161053375016785		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.09161053375016785 | validation: 0.12115410495465156]
	TIME [epoch: 9.51 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08688778649964198		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.08688778649964198 | validation: 0.1043538461886985]
	TIME [epoch: 9.52 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08049126626067868		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.08049126626067868 | validation: 0.10741823346926267]
	TIME [epoch: 9.51 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0993574979024421		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.0993574979024421 | validation: 0.13078244114532692]
	TIME [epoch: 9.52 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11900030310759672		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.11900030310759672 | validation: 0.15652067819326843]
	TIME [epoch: 9.51 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10322150355443849		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.10322150355443849 | validation: 0.12392886460724377]
	TIME [epoch: 9.51 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08907045286360274		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.08907045286360274 | validation: 0.125183627247471]
	TIME [epoch: 9.52 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08400709316123106		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.08400709316123106 | validation: 0.11057803379413769]
	TIME [epoch: 9.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08713078111621511		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.08713078111621511 | validation: 0.14094840911013573]
	TIME [epoch: 9.51 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287052679170373		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.09287052679170373 | validation: 0.09787764278843492]
	TIME [epoch: 9.51 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08495891856660778		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.08495891856660778 | validation: 0.12113238102942755]
	TIME [epoch: 9.51 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10668769913802315		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.10668769913802315 | validation: 0.15996132320659504]
	TIME [epoch: 9.51 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10757042895305965		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.10757042895305965 | validation: 0.09283744040979118]
	TIME [epoch: 9.51 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778050868033925		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.09778050868033925 | validation: 0.10606442490194469]
	TIME [epoch: 9.53 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08139641810794664		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.08139641810794664 | validation: 0.10728002458145515]
	TIME [epoch: 9.51 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08356903069443		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.08356903069443 | validation: 0.13574578264508333]
	TIME [epoch: 9.51 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09669897816071728		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.09669897816071728 | validation: 0.08447347423749381]
	TIME [epoch: 9.52 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08364352116234582		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.08364352116234582 | validation: 0.09346871131266013]
	TIME [epoch: 9.51 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827160715592035		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.08827160715592035 | validation: 0.09389239908629414]
	TIME [epoch: 9.51 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08792137354621547		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.08792137354621547 | validation: 0.10325135076662303]
	TIME [epoch: 9.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09487804367866606		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.09487804367866606 | validation: 0.13408826995720752]
	TIME [epoch: 9.53 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09861802711053964		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.09861802711053964 | validation: 0.10482416404646575]
	TIME [epoch: 9.51 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09188875880094904		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.09188875880094904 | validation: 0.09443820893529531]
	TIME [epoch: 9.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07946914444928524		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.07946914444928524 | validation: 0.1049902804080171]
	TIME [epoch: 9.52 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08951775355102468		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.08951775355102468 | validation: 0.09174429520873584]
	TIME [epoch: 9.52 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08476399719928042		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.08476399719928042 | validation: 0.09943528238980587]
	TIME [epoch: 9.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08189485741132338		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.08189485741132338 | validation: 0.08266581925125177]
	TIME [epoch: 9.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07998164369439989		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.07998164369439989 | validation: 0.09267332368731915]
	TIME [epoch: 9.52 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08631858683667477		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.08631858683667477 | validation: 0.10594450970422986]
	TIME [epoch: 9.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09653035588306218		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.09653035588306218 | validation: 0.10175622053829063]
	TIME [epoch: 9.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09514001273861902		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.09514001273861902 | validation: 0.08238454863131636]
	TIME [epoch: 9.53 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07961229823467669		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.07961229823467669 | validation: 0.1008849112026741]
	TIME [epoch: 9.51 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09027910817005538		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.09027910817005538 | validation: 0.0956539597595253]
	TIME [epoch: 9.51 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09150352531137072		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.09150352531137072 | validation: 0.07647795585951185]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1731.pth
	Model improved!!!
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932628482282352		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.08932628482282352 | validation: 0.1137943965264472]
	TIME [epoch: 9.53 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10040800727635071		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.10040800727635071 | validation: 0.07110307912184377]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1733.pth
	Model improved!!!
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09517576410882213		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.09517576410882213 | validation: 0.09332241286245241]
	TIME [epoch: 9.51 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0814401286056194		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.0814401286056194 | validation: 0.05855833602238862]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1735.pth
	Model improved!!!
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08165080595134247		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.08165080595134247 | validation: 0.08887028720666848]
	TIME [epoch: 9.51 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09921947191672445		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.09921947191672445 | validation: 0.1006009451618625]
	TIME [epoch: 9.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09360839696357245		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.09360839696357245 | validation: 0.06867240951351075]
	TIME [epoch: 9.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07216253323363504		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.07216253323363504 | validation: 0.08950812256931627]
	TIME [epoch: 9.53 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09936713845071268		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.09936713845071268 | validation: 0.10149609855560587]
	TIME [epoch: 9.51 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09045860113784507		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.09045860113784507 | validation: 0.08784476713351523]
	TIME [epoch: 9.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08031307816729039		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.08031307816729039 | validation: 0.08823885920417558]
	TIME [epoch: 9.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08137811572948081		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.08137811572948081 | validation: 0.10206867147348281]
	TIME [epoch: 9.51 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10450007819024645		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.10450007819024645 | validation: 0.10709444071126417]
	TIME [epoch: 9.51 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851704091505362		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.0851704091505362 | validation: 0.08588600543628493]
	TIME [epoch: 9.52 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169121094774683		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.08169121094774683 | validation: 0.11955679516058147]
	TIME [epoch: 9.51 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812056626403009		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.0812056626403009 | validation: 0.08973902228461855]
	TIME [epoch: 9.51 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09802269083980046		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.09802269083980046 | validation: 0.08998363675890433]
	TIME [epoch: 9.51 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08371438954483579		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.08371438954483579 | validation: 0.11539875292148054]
	TIME [epoch: 9.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11288821203614245		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.11288821203614245 | validation: 0.12340985304682235]
	TIME [epoch: 9.51 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09529950880512399		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.09529950880512399 | validation: 0.08131460216823376]
	TIME [epoch: 9.51 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08253059929859904		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.08253059929859904 | validation: 0.1389110217441191]
	TIME [epoch: 9.52 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10998084313978813		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.10998084313978813 | validation: 0.11026969020821184]
	TIME [epoch: 9.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08696084949496306		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.08696084949496306 | validation: 0.09404285032554309]
	TIME [epoch: 9.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08495408802735054		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.08495408802735054 | validation: 0.1092461413010853]
	TIME [epoch: 9.51 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0973839781625577		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.0973839781625577 | validation: 0.1318506649798891]
	TIME [epoch: 9.54 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09336059417603086		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.09336059417603086 | validation: 0.08980980829887093]
	TIME [epoch: 9.51 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07936656813330542		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.07936656813330542 | validation: 0.11333518010326805]
	TIME [epoch: 9.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09925544893796137		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.09925544893796137 | validation: 0.1747127606178962]
	TIME [epoch: 9.53 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12273522190930455		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.12273522190930455 | validation: 0.13044406570837766]
	TIME [epoch: 9.52 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09994456898998864		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.09994456898998864 | validation: 0.12329085394925389]
	TIME [epoch: 9.51 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871181488657134		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.08871181488657134 | validation: 0.1058522236147943]
	TIME [epoch: 9.51 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08280554862321021		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.08280554862321021 | validation: 0.09513458568611416]
	TIME [epoch: 9.52 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475732816295514		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.08475732816295514 | validation: 0.09609045689044342]
	TIME [epoch: 9.51 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09355279777358687		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.09355279777358687 | validation: 0.11240713182127446]
	TIME [epoch: 9.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09493551285467608		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.09493551285467608 | validation: 0.14228501182990616]
	TIME [epoch: 9.52 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10507937949322		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.10507937949322 | validation: 0.10344744029024314]
	TIME [epoch: 9.51 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424014205417541		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.09424014205417541 | validation: 0.11643128610347266]
	TIME [epoch: 9.51 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10099082077496946		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.10099082077496946 | validation: 0.09546566947974527]
	TIME [epoch: 9.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0985783661258054		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.0985783661258054 | validation: 0.12320544781798705]
	TIME [epoch: 9.52 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08777544475373403		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.08777544475373403 | validation: 0.12525057514363938]
	TIME [epoch: 9.51 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07835842773134931		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.07835842773134931 | validation: 0.10232301941568218]
	TIME [epoch: 9.51 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09854794536116739		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.09854794536116739 | validation: 0.12275655160018896]
	TIME [epoch: 9.52 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09688179666638583		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.09688179666638583 | validation: 0.09382882299316742]
	TIME [epoch: 9.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0939267776667452		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.0939267776667452 | validation: 0.09333986609024617]
	TIME [epoch: 9.51 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09051037041157764		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.09051037041157764 | validation: 0.1098203076656847]
	TIME [epoch: 9.51 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11394354278579641		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.11394354278579641 | validation: 0.18056673174091842]
	TIME [epoch: 9.53 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12854125084879303		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.12854125084879303 | validation: 0.19385043614844683]
	TIME [epoch: 9.51 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019823680559635		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.15019823680559635 | validation: 0.18657776383835015]
	TIME [epoch: 9.52 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11112893275895812		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.11112893275895812 | validation: 0.1214775769205906]
	TIME [epoch: 9.53 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09269313613466082		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.09269313613466082 | validation: 0.10800689616654321]
	TIME [epoch: 9.52 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08337614216343063		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.08337614216343063 | validation: 0.10085895118329057]
	TIME [epoch: 9.52 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09463999516878323		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.09463999516878323 | validation: 0.1070872352364367]
	TIME [epoch: 9.51 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08326335675349684		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.08326335675349684 | validation: 0.1073519148902934]
	TIME [epoch: 9.52 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09260865503139948		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.09260865503139948 | validation: 0.0938496036535205]
	TIME [epoch: 9.51 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09126264566804584		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.09126264566804584 | validation: 0.10940194176543276]
	TIME [epoch: 9.52 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080225022909041		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.09080225022909041 | validation: 0.09563094654047252]
	TIME [epoch: 9.54 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08570078258566002		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.08570078258566002 | validation: 0.09209085327881457]
	TIME [epoch: 9.51 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08198324443902036		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.08198324443902036 | validation: 0.11887041174271513]
	TIME [epoch: 9.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09068777087473621		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.09068777087473621 | validation: 0.1334902626752344]
	TIME [epoch: 9.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09425166580373279		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.09425166580373279 | validation: 0.14187590365606365]
	TIME [epoch: 9.53 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0984566722550977		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.0984566722550977 | validation: 0.14825753095106978]
	TIME [epoch: 9.51 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0865880470457955		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.0865880470457955 | validation: 0.14490806170404122]
	TIME [epoch: 9.51 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09197032149311897		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.09197032149311897 | validation: 0.11614918457525615]
	TIME [epoch: 9.53 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09177297084029426		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.09177297084029426 | validation: 0.10946323691118799]
	TIME [epoch: 9.52 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08756455910402564		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.08756455910402564 | validation: 0.08343825209337073]
	TIME [epoch: 9.52 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07988752174794764		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.07988752174794764 | validation: 0.10553923389182229]
	TIME [epoch: 9.51 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08767016614121557		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.08767016614121557 | validation: 0.10333882653002928]
	TIME [epoch: 9.52 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09243443457745919		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.09243443457745919 | validation: 0.10364922965393007]
	TIME [epoch: 9.51 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08506940575287922		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.08506940575287922 | validation: 0.11001146851716825]
	TIME [epoch: 9.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0880353973895029		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.0880353973895029 | validation: 0.1106052509569679]
	TIME [epoch: 9.52 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09435213625626894		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.09435213625626894 | validation: 0.10303108364712202]
	TIME [epoch: 9.51 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885847809439502		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.0885847809439502 | validation: 0.1299056832136918]
	TIME [epoch: 9.51 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07614316944419519		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.07614316944419519 | validation: 0.11871493425400495]
	TIME [epoch: 9.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07853723663910539		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.07853723663910539 | validation: 0.10506182342486152]
	TIME [epoch: 9.52 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08046797419142034		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.08046797419142034 | validation: 0.09501207751886635]
	TIME [epoch: 9.51 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07733352359859189		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.07733352359859189 | validation: 0.11091457323267775]
	TIME [epoch: 9.52 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08422038080031942		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.08422038080031942 | validation: 0.12158487598685583]
	TIME [epoch: 9.52 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08507623904766747		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.08507623904766747 | validation: 0.1227935426717306]
	TIME [epoch: 9.51 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09046914980596929		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.09046914980596929 | validation: 0.13667533957198685]
	TIME [epoch: 9.51 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08704272027513645		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.08704272027513645 | validation: 0.1336622495458322]
	TIME [epoch: 9.52 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10527948933455464		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.10527948933455464 | validation: 0.16025368820124217]
	TIME [epoch: 9.53 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08159401295564003		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.08159401295564003 | validation: 0.11498502505379637]
	TIME [epoch: 9.51 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08971969341148252		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.08971969341148252 | validation: 0.10999276728627018]
	TIME [epoch: 9.51 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658252715957185		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.08658252715957185 | validation: 0.11121078605356266]
	TIME [epoch: 9.54 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10048747803898721		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.10048747803898721 | validation: 0.1548170370064753]
	TIME [epoch: 9.52 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254196664231823		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.1254196664231823 | validation: 0.1785623025913934]
	TIME [epoch: 9.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10674440929206888		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.10674440929206888 | validation: 0.11236789291090896]
	TIME [epoch: 9.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09064896714122025		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.09064896714122025 | validation: 0.12556226175289403]
	TIME [epoch: 9.52 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10065246316982931		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.10065246316982931 | validation: 0.12089378617296496]
	TIME [epoch: 9.52 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08840734433257172		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.08840734433257172 | validation: 0.12417742583207302]
	TIME [epoch: 9.51 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0838300976477537		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.0838300976477537 | validation: 0.12475025995016079]
	TIME [epoch: 9.54 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.095463233763966		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.095463233763966 | validation: 0.13804046018152813]
	TIME [epoch: 9.51 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09083933555068302		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.09083933555068302 | validation: 0.12300739360295362]
	TIME [epoch: 9.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09049899156663452		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.09049899156663452 | validation: 0.13362341039372477]
	TIME [epoch: 9.53 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09815012760733069		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.09815012760733069 | validation: 0.14017488974713083]
	TIME [epoch: 9.51 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11074311817855298		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.11074311817855298 | validation: 0.1672159749187248]
	TIME [epoch: 9.52 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13447521097896994		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.13447521097896994 | validation: 0.1716333936913933]
	TIME [epoch: 9.51 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10487550856747223		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.10487550856747223 | validation: 0.1518722085185984]
	TIME [epoch: 9.54 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09129248572914087		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.09129248572914087 | validation: 0.13687880071386538]
	TIME [epoch: 9.51 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10036835908276842		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.10036835908276842 | validation: 0.1377794009228381]
	TIME [epoch: 9.52 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09836343516588983		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.09836343516588983 | validation: 0.11648138440986303]
	TIME [epoch: 9.53 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09574090774540592		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.09574090774540592 | validation: 0.12609769468834134]
	TIME [epoch: 9.51 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0897352166281167		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.0897352166281167 | validation: 0.11760624343916679]
	TIME [epoch: 9.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10148803134341496		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.10148803134341496 | validation: 0.09764259876025115]
	TIME [epoch: 9.51 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192356361592781		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.09192356361592781 | validation: 0.14117402501683501]
	TIME [epoch: 9.52 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07684520745608887		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.07684520745608887 | validation: 0.108639741728791]
	TIME [epoch: 9.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886801776841505		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.08886801776841505 | validation: 0.12016185804108016]
	TIME [epoch: 9.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222497812481071		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.08222497812481071 | validation: 0.09086434292614831]
	TIME [epoch: 9.53 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07359097962031895		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.07359097962031895 | validation: 0.10447166949683244]
	TIME [epoch: 9.52 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10080573129176854		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.10080573129176854 | validation: 0.13857267410582735]
	TIME [epoch: 9.52 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10232323608367737		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.10232323608367737 | validation: 0.16434028485764868]
	TIME [epoch: 9.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11560276655232068		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.11560276655232068 | validation: 0.1287343738566239]
	TIME [epoch: 9.53 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10447098340654906		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.10447098340654906 | validation: 0.1551962721422162]
	TIME [epoch: 9.51 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09394880432662875		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.09394880432662875 | validation: 0.11784451138582398]
	TIME [epoch: 9.51 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08282017086291185		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.08282017086291185 | validation: 0.09469999786929371]
	TIME [epoch: 9.53 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07367357176580398		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.07367357176580398 | validation: 0.11257586284002312]
	TIME [epoch: 9.51 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0816646695970775		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.0816646695970775 | validation: 0.11196868320267371]
	TIME [epoch: 9.51 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08756485737439654		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.08756485737439654 | validation: 0.1314470814126312]
	TIME [epoch: 9.52 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09410544192353479		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.09410544192353479 | validation: 0.11357136814143043]
	TIME [epoch: 9.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08837645332893765		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.08837645332893765 | validation: 0.12945957219491208]
	TIME [epoch: 9.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07797304045144982		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.07797304045144982 | validation: 0.10141655072763038]
	TIME [epoch: 9.51 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08605491748472387		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.08605491748472387 | validation: 0.10185439496458304]
	TIME [epoch: 9.53 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08580868730199494		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.08580868730199494 | validation: 0.11190476477322722]
	TIME [epoch: 9.52 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08444796553487663		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.08444796553487663 | validation: 0.11652299622740189]
	TIME [epoch: 9.52 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08059659111531733		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.08059659111531733 | validation: 0.10237370794060317]
	TIME [epoch: 9.53 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0729121651539192		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.0729121651539192 | validation: 0.09427820521671049]
	TIME [epoch: 9.53 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08177450612973856		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.08177450612973856 | validation: 0.07419063476302742]
	TIME [epoch: 9.52 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07951994728368565		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.07951994728368565 | validation: 0.07605385360488383]
	TIME [epoch: 9.51 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07525683077954574		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.07525683077954574 | validation: 0.07500158397333653]
	TIME [epoch: 9.53 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07512371719968794		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.07512371719968794 | validation: 0.10088967454835773]
	TIME [epoch: 9.51 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08815232915111312		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.08815232915111312 | validation: 0.11806070708260745]
	TIME [epoch: 9.52 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07937511109013103		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.07937511109013103 | validation: 0.08472684417728946]
	TIME [epoch: 9.53 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07425872416248357		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.07425872416248357 | validation: 0.08673109891325258]
	TIME [epoch: 9.51 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07682332068249206		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.07682332068249206 | validation: 0.08782990664427137]
	TIME [epoch: 9.51 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08058352712729262		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.08058352712729262 | validation: 0.09350032147643206]
	TIME [epoch: 9.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08648733533078377		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.08648733533078377 | validation: 0.11589296714857661]
	TIME [epoch: 9.54 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728615748335878		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.07728615748335878 | validation: 0.0993031471513897]
	TIME [epoch: 9.51 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07934107820321372		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.07934107820321372 | validation: 0.0975636693261287]
	TIME [epoch: 9.51 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0817319465671854		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.0817319465671854 | validation: 0.11159929800821074]
	TIME [epoch: 9.52 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09218855839651714		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.09218855839651714 | validation: 0.0828353088556205]
	TIME [epoch: 9.53 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07627657873685291		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.07627657873685291 | validation: 0.09667733561258592]
	TIME [epoch: 9.51 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08141958395945889		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.08141958395945889 | validation: 0.12191949815624677]
	TIME [epoch: 9.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09090882679919966		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.09090882679919966 | validation: 0.08446292914302467]
	TIME [epoch: 9.52 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07735998687766897		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.07735998687766897 | validation: 0.08103239717878333]
	TIME [epoch: 9.51 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08325742671860241		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.08325742671860241 | validation: 0.09472872232909307]
	TIME [epoch: 9.51 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08005229450374492		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.08005229450374492 | validation: 0.08916838137787712]
	TIME [epoch: 9.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08216129012946743		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.08216129012946743 | validation: 0.1319693858807096]
	TIME [epoch: 9.51 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374319415139297		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.09374319415139297 | validation: 0.12604214221192384]
	TIME [epoch: 9.51 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07903834321136502		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.07903834321136502 | validation: 0.11825475229193254]
	TIME [epoch: 9.51 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793623787395017		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.0793623787395017 | validation: 0.11709560156612588]
	TIME [epoch: 9.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07496055930610643		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.07496055930610643 | validation: 0.10911376617006915]
	TIME [epoch: 9.51 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09660546913046962		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.09660546913046962 | validation: 0.13548735321188526]
	TIME [epoch: 9.52 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964017029998395		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.07964017029998395 | validation: 0.10834824361282638]
	TIME [epoch: 9.53 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958381905622955		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.07958381905622955 | validation: 0.1180355501212605]
	TIME [epoch: 9.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608358748456974		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.10608358748456974 | validation: 0.10825869784411209]
	TIME [epoch: 9.51 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0804304511587696		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.0804304511587696 | validation: 0.10461412046314746]
	TIME [epoch: 9.51 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08105409063370234		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.08105409063370234 | validation: 0.09593207329928824]
	TIME [epoch: 9.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08164599102617712		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.08164599102617712 | validation: 0.10710706926859803]
	TIME [epoch: 9.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08306956562795194		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.08306956562795194 | validation: 0.10150650230977455]
	TIME [epoch: 9.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07476226596055005		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.07476226596055005 | validation: 0.09647257429223789]
	TIME [epoch: 9.53 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08201235289708536		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.08201235289708536 | validation: 0.09699338459244353]
	TIME [epoch: 9.51 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07495625858304644		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.07495625858304644 | validation: 0.10391302241755213]
	TIME [epoch: 9.51 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07942359151789542		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.07942359151789542 | validation: 0.13693347768332395]
	TIME [epoch: 9.51 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10029708726827222		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.10029708726827222 | validation: 0.09747619671653203]
	TIME [epoch: 9.53 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343734513947391		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.09343734513947391 | validation: 0.10672090118852758]
	TIME [epoch: 9.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402012406280576		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.08402012406280576 | validation: 0.11333654894248406]
	TIME [epoch: 9.51 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09915667052248796		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.09915667052248796 | validation: 0.10488277538327383]
	TIME [epoch: 9.53 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09488915647441024		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.09488915647441024 | validation: 0.0959358284192249]
	TIME [epoch: 9.52 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08513576774826413		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.08513576774826413 | validation: 0.09932064463586744]
	TIME [epoch: 9.51 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08352721376681863		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.08352721376681863 | validation: 0.08760865560740311]
	TIME [epoch: 9.51 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07609237605436452		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.07609237605436452 | validation: 0.09634204889650526]
	TIME [epoch: 9.52 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08561303364567557		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.08561303364567557 | validation: 0.1102276942502314]
	TIME [epoch: 9.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08742962914194194		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.08742962914194194 | validation: 0.10094048009092525]
	TIME [epoch: 9.49 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0876019987717584		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.0876019987717584 | validation: 0.08402757588436897]
	TIME [epoch: 9.52 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0830490072449543		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.0830490072449543 | validation: 0.09290986000210193]
	TIME [epoch: 9.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07387698216091568		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.07387698216091568 | validation: 0.08021084772797252]
	TIME [epoch: 9.51 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07751777110822503		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.07751777110822503 | validation: 0.0935725934361147]
	TIME [epoch: 9.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08880107931005617		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.08880107931005617 | validation: 0.08978228433017875]
	TIME [epoch: 9.51 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222201757495737		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.08222201757495737 | validation: 0.07669798261990426]
	TIME [epoch: 9.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07334771552738088		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.07334771552738088 | validation: 0.0919439053267506]
	TIME [epoch: 9.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07592466135542135		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.07592466135542135 | validation: 0.06713636096042762]
	TIME [epoch: 9.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07801774141983119		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.07801774141983119 | validation: 0.0695243217074711]
	TIME [epoch: 9.51 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07903947050775412		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.07903947050775412 | validation: 0.07387101347916253]
	TIME [epoch: 9.51 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467674098893301		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.09467674098893301 | validation: 0.09647974412219476]
	TIME [epoch: 9.51 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07650303075458602		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.07650303075458602 | validation: 0.07309833518251231]
	TIME [epoch: 9.52 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08030892528143388		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.08030892528143388 | validation: 0.05325138360180435]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240219_183144/states/model_tr_study5_1917.pth
	Model improved!!!
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08253387966901503		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.08253387966901503 | validation: 0.08462220206412599]
	TIME [epoch: 9.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07980438200788997		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.07980438200788997 | validation: 0.07566824094136992]
	TIME [epoch: 9.52 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08543860995113242		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.08543860995113242 | validation: 0.08778081127882549]
	TIME [epoch: 9.51 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07959024368200773		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.07959024368200773 | validation: 0.08547455327728935]
	TIME [epoch: 9.51 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08965738733185742		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.08965738733185742 | validation: 0.07504083467792545]
	TIME [epoch: 9.53 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0785787661269147		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.0785787661269147 | validation: 0.06979317404147085]
	TIME [epoch: 9.51 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08297222839183141		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.08297222839183141 | validation: 0.07672037468723339]
	TIME [epoch: 9.51 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08590819731189879		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.08590819731189879 | validation: 0.07036342306180471]
	TIME [epoch: 9.51 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08925886441474473		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.08925886441474473 | validation: 0.09438153116219013]
	TIME [epoch: 9.53 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10146697219708685		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.10146697219708685 | validation: 0.06294337894019499]
	TIME [epoch: 9.51 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07638756064607578		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.07638756064607578 | validation: 0.07346650762110561]
	TIME [epoch: 9.51 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09297661819894701		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.09297661819894701 | validation: 0.09735307106853881]
	TIME [epoch: 9.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09332095270738691		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.09332095270738691 | validation: 0.08902510186627378]
	TIME [epoch: 9.52 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07725553138529034		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.07725553138529034 | validation: 0.08826811988923686]
	TIME [epoch: 9.51 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0788420136277866		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.0788420136277866 | validation: 0.08696711776766383]
	TIME [epoch: 9.51 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07837559781810027		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.07837559781810027 | validation: 0.07471300664954048]
	TIME [epoch: 9.53 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0713463680212985		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.0713463680212985 | validation: 0.08992049590732909]
	TIME [epoch: 9.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07740173573618692		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.07740173573618692 | validation: 0.07307935002196214]
	TIME [epoch: 9.51 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07007347937523849		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.07007347937523849 | validation: 0.09527814072950049]
	TIME [epoch: 9.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08023244748133246		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.08023244748133246 | validation: 0.07928902305783352]
	TIME [epoch: 9.51 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07452580251971891		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.07452580251971891 | validation: 0.10160092088915101]
	TIME [epoch: 9.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07392105947319046		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.07392105947319046 | validation: 0.08216530108395541]
	TIME [epoch: 9.51 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07908209051892388		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.07908209051892388 | validation: 0.08727119178355892]
	TIME [epoch: 9.53 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07886874859711893		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.07886874859711893 | validation: 0.08622748133703301]
	TIME [epoch: 9.52 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07554964957579842		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.07554964957579842 | validation: 0.08732663655209041]
	TIME [epoch: 9.51 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07787685582809041		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.07787685582809041 | validation: 0.08875743873846961]
	TIME [epoch: 9.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0831594514101841		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.0831594514101841 | validation: 0.10577451798246862]
	TIME [epoch: 9.51 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09679210021338665		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.09679210021338665 | validation: 0.10157443159731315]
	TIME [epoch: 9.51 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09452749193445939		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.09452749193445939 | validation: 0.09374046669840222]
	TIME [epoch: 9.51 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08831764525792146		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.08831764525792146 | validation: 0.09468761952245931]
	TIME [epoch: 9.53 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367792678691299		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.08367792678691299 | validation: 0.10951961583683559]
	TIME [epoch: 9.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08391576664779903		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.08391576664779903 | validation: 0.09010307025061827]
	TIME [epoch: 9.51 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07877056907300399		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.07877056907300399 | validation: 0.08240630904818202]
	TIME [epoch: 9.53 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06982498151258336		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.06982498151258336 | validation: 0.060463781532591146]
	TIME [epoch: 9.51 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07132421013754975		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.07132421013754975 | validation: 0.07045068538775646]
	TIME [epoch: 9.59 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07075700599488316		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.07075700599488316 | validation: 0.08659004566345409]
	TIME [epoch: 9.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06845546855360297		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.06845546855360297 | validation: 0.08151684855608032]
	TIME [epoch: 9.52 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07908910920720096		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.07908910920720096 | validation: 0.08008637667969726]
	TIME [epoch: 9.51 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08308089737180582		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.08308089737180582 | validation: 0.08268044588312315]
	TIME [epoch: 9.51 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08743472677833997		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.08743472677833997 | validation: 0.1170166932200221]
	TIME [epoch: 9.53 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08081980217032451		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.08081980217032451 | validation: 0.1010445741937555]
	TIME [epoch: 9.51 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09663870192765533		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.09663870192765533 | validation: 0.1334773581637632]
	TIME [epoch: 9.51 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09402048523270759		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.09402048523270759 | validation: 0.09764819035326908]
	TIME [epoch: 9.52 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08346947122297348		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.08346947122297348 | validation: 0.07190959236042317]
	TIME [epoch: 9.52 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07005451932249915		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.07005451932249915 | validation: 0.0817789051641092]
	TIME [epoch: 9.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08231787977973729		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.08231787977973729 | validation: 0.09434997145868218]
	TIME [epoch: 9.51 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07537273061162639		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.07537273061162639 | validation: 0.0817692345340894]
	TIME [epoch: 9.52 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0759590157782407		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.0759590157782407 | validation: 0.07621632193375769]
	TIME [epoch: 9.52 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080617302836488		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.09080617302836488 | validation: 0.07684517755276966]
	TIME [epoch: 9.51 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07394583513733571		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.07394583513733571 | validation: 0.059242966285711456]
	TIME [epoch: 9.52 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07451950712777346		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.07451950712777346 | validation: 0.07351113858502942]
	TIME [epoch: 9.51 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07172603830349059		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.07172603830349059 | validation: 0.08105016117463543]
	TIME [epoch: 9.51 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07109620811608755		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.07109620811608755 | validation: 0.073000803501902]
	TIME [epoch: 9.51 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07008074005160468		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.07008074005160468 | validation: 0.08421423390283513]
	TIME [epoch: 9.53 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08083894657498114		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.08083894657498114 | validation: 0.07890381869785487]
	TIME [epoch: 9.51 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.075523270140517		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.075523270140517 | validation: 0.08417010477773643]
	TIME [epoch: 9.51 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08652531371186892		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.08652531371186892 | validation: 0.06367676646003266]
	TIME [epoch: 9.52 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482069809948758		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.08482069809948758 | validation: 0.07974609536528625]
	TIME [epoch: 9.52 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08095394456555631		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.08095394456555631 | validation: 0.09790006044086345]
	TIME [epoch: 9.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08456229871262629		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.08456229871262629 | validation: 0.07161327020232884]
	TIME [epoch: 9.51 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07403969092292087		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.07403969092292087 | validation: 0.08565252205933377]
	TIME [epoch: 9.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08187810622320574		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.08187810622320574 | validation: 0.07680957542693778]
	TIME [epoch: 9.51 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07331836395465222		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.07331836395465222 | validation: 0.08508362304082714]
	TIME [epoch: 9.51 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08305812412953725		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.08305812412953725 | validation: 0.09317672583078186]
	TIME [epoch: 9.53 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06515915603165803		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.06515915603165803 | validation: 0.07946780045796838]
	TIME [epoch: 9.51 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07448943060975713		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.07448943060975713 | validation: 0.08930363711972276]
	TIME [epoch: 9.51 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07893311748246848		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.07893311748246848 | validation: 0.08021159988694634]
	TIME [epoch: 9.51 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475445283486205		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.08475445283486205 | validation: 0.0805776531756949]
	TIME [epoch: 9.53 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08018087479142172		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.08018087479142172 | validation: 0.09404031507565278]
	TIME [epoch: 9.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0777109153291291		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.0777109153291291 | validation: 0.07514892314647399]
	TIME [epoch: 9.51 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07564387237222525		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.07564387237222525 | validation: 0.07959699286530712]
	TIME [epoch: 9.53 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859983241976424		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.0859983241976424 | validation: 0.10025662988078123]
	TIME [epoch: 9.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0951690279439899		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.0951690279439899 | validation: 0.08962884841902401]
	TIME [epoch: 9.51 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08980958254527147		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.08980958254527147 | validation: 0.1064930056517574]
	TIME [epoch: 9.51 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09309527645447335		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.09309527645447335 | validation: 0.08696896119214603]
	TIME [epoch: 9.53 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09275777279440722		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.09275777279440722 | validation: 0.09508278776133605]
	TIME [epoch: 9.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08504607068053455		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.08504607068053455 | validation: 0.09909387847285983]
	TIME [epoch: 9.51 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08777210133700965		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.08777210133700965 | validation: 0.08515206047599484]
	TIME [epoch: 9.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08331351438194377		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.08331351438194377 | validation: 0.07584829679689761]
	TIME [epoch: 9.51 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07648434501105095		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.07648434501105095 | validation: 0.08759679598269333]
	TIME [epoch: 9.51 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07677785446915285		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.07677785446915285 | validation: 0.07446977299682608]
	TIME [epoch: 9.51 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07250576773539161		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.07250576773539161 | validation: 0.07665267272592446]
	TIME [epoch: 9.53 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07952618152931579		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.07952618152931579 | validation: 0.07340290223003726]
	TIME [epoch: 9.51 sec]
Finished training in 19165.655 seconds.
