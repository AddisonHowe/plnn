Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3978412365

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 11.425622104729692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.425622104729692 | validation: 10.98617679516934]
	TIME [epoch: 49.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 10.653644963107153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.653644963107153 | validation: 9.59985484535918]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 9.57338541438989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.57338541438989 | validation: 8.810221184525588]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 8.670350221212855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.670350221212855 | validation: 8.090168031407702]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 7.889306661206215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.889306661206215 | validation: 7.521120832755714]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 7.527789098352729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.527789098352729 | validation: 7.442004457838102]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 7.5246767121631395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5246767121631395 | validation: 7.501688766864413]
	TIME [epoch: 10.1 sec]
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 7.953944195663221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.953944195663221 | validation: 7.590923464950861]
	TIME [epoch: 10.1 sec]
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 7.603810117166073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.603810117166073 | validation: 7.404904465024884]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 7.5393664167276855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5393664167276855 | validation: 7.526045178575853]
	TIME [epoch: 10.1 sec]
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 7.560854883205062		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 7.560854883205062 | validation: 7.561618719141678]
	TIME [epoch: 10.1 sec]
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 7.943278875443667		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 7.943278875443667 | validation: 7.525251220382772]
	TIME [epoch: 10.1 sec]
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 7.580575676683526		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 7.580575676683526 | validation: 7.489290661713841]
	TIME [epoch: 10.1 sec]
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 7.635402082134853		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 7.635402082134853 | validation: 7.393195656646817]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 7.539313158205694		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 7.539313158205694 | validation: 7.489671151162609]
	TIME [epoch: 10.1 sec]
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 7.570041076571224		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 7.570041076571224 | validation: 7.42277476295709]
	TIME [epoch: 10.1 sec]
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 7.485381054399054		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 7.485381054399054 | validation: 7.401358910501531]
	TIME [epoch: 10.1 sec]
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 7.449964527337583		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 7.449964527337583 | validation: 7.436637587460034]
	TIME [epoch: 10.1 sec]
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 7.4721982296291785		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 7.4721982296291785 | validation: 7.326130809461054]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 7.373297322599955		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 7.373297322599955 | validation: 7.218370697482992]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 7.324489976127022		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 7.324489976127022 | validation: 7.106656068002321]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 7.235411119629927		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 7.235411119629927 | validation: 7.193611504385345]
	TIME [epoch: 10.1 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 7.2612240348427886		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 7.2612240348427886 | validation: 6.87696517286158]
	TIME [epoch: 10 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 7.0275943308537565		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 7.0275943308537565 | validation: 6.76076074433178]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 6.950752354865777		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 6.950752354865777 | validation: 6.661897170528323]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 6.785186062989399		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 6.785186062989399 | validation: 6.218312627682725]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 6.387164385507875		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 6.387164385507875 | validation: 6.256306272742021]
	TIME [epoch: 10.1 sec]
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 6.512939306642229		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 6.512939306642229 | validation: 5.973835799584759]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 6.086733629021707		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 6.086733629021707 | validation: 5.76595258609611]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 6.065117383210492		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 6.065117383210492 | validation: 5.913188543593475]
	TIME [epoch: 10.1 sec]
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 6.056381177537276		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 6.056381177537276 | validation: 5.718307809493637]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 5.965041159552301		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 5.965041159552301 | validation: 5.954783977012124]
	TIME [epoch: 10.1 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9599809349351975		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 5.9599809349351975 | validation: 5.782503858111333]
	TIME [epoch: 10.1 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 5.947308623970629		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 5.947308623970629 | validation: 5.96989282404466]
	TIME [epoch: 10.1 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 5.954865207922569		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 5.954865207922569 | validation: 6.014185983696072]
	TIME [epoch: 10.1 sec]
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 6.487063345954434		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 6.487063345954434 | validation: 6.155274750552572]
	TIME [epoch: 10.1 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9007594621240695		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 5.9007594621240695 | validation: 5.55341488434144]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 5.98330465749713		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 5.98330465749713 | validation: 5.823874026555767]
	TIME [epoch: 10.1 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 5.939100596977168		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 5.939100596977168 | validation: 5.763173069392724]
	TIME [epoch: 10.1 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 5.863869292239383		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 5.863869292239383 | validation: 5.985128501524594]
	TIME [epoch: 10.1 sec]
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 5.830173069093791		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 5.830173069093791 | validation: 5.6193681765909504]
	TIME [epoch: 10.1 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 5.795296165080711		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 5.795296165080711 | validation: 5.67133784932659]
	TIME [epoch: 10.1 sec]
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 5.682736278372021		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 5.682736278372021 | validation: 5.44260138456996]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 5.6406418022038896		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 5.6406418022038896 | validation: 5.873639571392576]
	TIME [epoch: 10.1 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 5.729911565791118		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 5.729911565791118 | validation: 5.661504100246427]
	TIME [epoch: 10.1 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 5.749094567455205		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 5.749094567455205 | validation: 5.61293694756024]
	TIME [epoch: 10.1 sec]
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 5.733265581959055		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 5.733265581959055 | validation: 5.442131383965798]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 5.751404204997849		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 5.751404204997849 | validation: 5.652724028875148]
	TIME [epoch: 10.1 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 5.830709938770858		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 5.830709938770858 | validation: 5.599320250255187]
	TIME [epoch: 10.1 sec]
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 6.172542695257403		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 6.172542695257403 | validation: 5.958065561002966]
	TIME [epoch: 10.1 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 5.797277631763336		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 5.797277631763336 | validation: 5.525719761181533]
	TIME [epoch: 10.1 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 5.728233764589644		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 5.728233764589644 | validation: 5.6586730621092345]
	TIME [epoch: 10.1 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 5.66449050968247		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 5.66449050968247 | validation: 5.730861513578161]
	TIME [epoch: 10.1 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 5.581984881387581		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 5.581984881387581 | validation: 5.569767881642962]
	TIME [epoch: 10.1 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 5.58379410358888		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 5.58379410358888 | validation: 5.532768627644089]
	TIME [epoch: 10.1 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 6.154022938736041		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 6.154022938736041 | validation: 5.279323846819877]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 5.496898168991555		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 5.496898168991555 | validation: 5.434256863851757]
	TIME [epoch: 10.1 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 5.567990253412248		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 5.567990253412248 | validation: 5.41581539714294]
	TIME [epoch: 10.1 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 5.554014688464612		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 5.554014688464612 | validation: 5.574268745227876]
	TIME [epoch: 10.1 sec]
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 5.850180652660957		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 5.850180652660957 | validation: 5.560724489463389]
	TIME [epoch: 10.1 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 5.594721194416901		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 5.594721194416901 | validation: 5.348952064634725]
	TIME [epoch: 10.1 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 6.154233724305165		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 6.154233724305165 | validation: 6.7370077421855745]
	TIME [epoch: 10.1 sec]
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 5.781330313366829		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 5.781330313366829 | validation: 5.120057792203308]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 5.4101304598240105		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 5.4101304598240105 | validation: 5.22758808228083]
	TIME [epoch: 10.1 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 6.076747189931173		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 6.076747189931173 | validation: 6.850442548402095]
	TIME [epoch: 10.1 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 6.5400289665474345		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 6.5400289665474345 | validation: 5.3834673183051995]
	TIME [epoch: 10.1 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 5.776960810310447		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 5.776960810310447 | validation: 5.294382714731541]
	TIME [epoch: 10.1 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 5.477427870747187		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 5.477427870747187 | validation: 5.16022220072859]
	TIME [epoch: 10.1 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 5.459523696830759		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 5.459523696830759 | validation: 5.616811176019428]
	TIME [epoch: 10.1 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 5.411235556947312		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 5.411235556947312 | validation: 5.17077792113083]
	TIME [epoch: 10.1 sec]
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 5.592053501439682		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 5.592053501439682 | validation: 5.537379824053403]
	TIME [epoch: 10.1 sec]
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 5.818339195217101		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 5.818339195217101 | validation: 6.323734342175083]
	TIME [epoch: 10.1 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 5.485221920944835		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 5.485221920944835 | validation: 5.187418264076095]
	TIME [epoch: 10.1 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 5.218841860818277		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 5.218841860818277 | validation: 5.757669992454975]
	TIME [epoch: 10.1 sec]
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 5.618001219061391		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 5.618001219061391 | validation: 5.349375374123025]
	TIME [epoch: 10.1 sec]
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 5.847339592464022		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 5.847339592464022 | validation: 5.715385301076873]
	TIME [epoch: 10.1 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 5.553238909363446		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 5.553238909363446 | validation: 5.365716096044345]
	TIME [epoch: 10.1 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 5.3043589000728035		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 5.3043589000728035 | validation: 5.47482187921824]
	TIME [epoch: 10.1 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 5.293490945023102		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 5.293490945023102 | validation: 5.338418466201533]
	TIME [epoch: 10.1 sec]
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 5.3447558346572785		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 5.3447558346572785 | validation: 5.249568069507668]
	TIME [epoch: 10.1 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 5.419362262559246		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 5.419362262559246 | validation: 4.875474553050078]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 5.270473876759111		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 5.270473876759111 | validation: 5.155087388440643]
	TIME [epoch: 10.1 sec]
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 5.368711174264094		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 5.368711174264094 | validation: 5.501310658781842]
	TIME [epoch: 10.1 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 5.423973712848332		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 5.423973712848332 | validation: 5.147357635756633]
	TIME [epoch: 10.1 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 5.549039116032316		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 5.549039116032316 | validation: 5.613491359736902]
	TIME [epoch: 10.1 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 5.683093108592738		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 5.683093108592738 | validation: 5.14844305529992]
	TIME [epoch: 10.1 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 5.233279054213998		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 5.233279054213998 | validation: 5.060282578877751]
	TIME [epoch: 10.1 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 5.380315450262352		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 5.380315450262352 | validation: 6.529036652743443]
	TIME [epoch: 10.2 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 6.238019119297006		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 6.238019119297006 | validation: 6.501987201022721]
	TIME [epoch: 10.2 sec]
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 5.782437495921703		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 5.782437495921703 | validation: 4.97566453426766]
	TIME [epoch: 10.2 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 5.110824675203015		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 5.110824675203015 | validation: 4.903555841738942]
	TIME [epoch: 10.1 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 5.325640332172194		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 5.325640332172194 | validation: 5.213030267226686]
	TIME [epoch: 10.1 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 5.19224416457788		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 5.19224416457788 | validation: 5.090421459951519]
	TIME [epoch: 10.1 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 5.25025515389562		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 5.25025515389562 | validation: 4.753157325060845]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 4.891047704732987		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 4.891047704732987 | validation: 5.43883293181379]
	TIME [epoch: 10.1 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 7.137293909425395		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 7.137293909425395 | validation: 8.810384450481195]
	TIME [epoch: 10.1 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 9.762093203585072		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 9.762093203585072 | validation: 9.414311241631271]
	TIME [epoch: 10.1 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 9.602737579159468		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 9.602737579159468 | validation: 8.944790107639305]
	TIME [epoch: 10.1 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 8.067303980028836		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 8.067303980028836 | validation: 5.9068485265912605]
	TIME [epoch: 10.1 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 5.723496405451125		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 5.723496405451125 | validation: 5.322225101263431]
	TIME [epoch: 10.1 sec]
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 5.200670992352693		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 5.200670992352693 | validation: 5.190565524922822]
	TIME [epoch: 10.1 sec]
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 5.2594943472659965		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 5.2594943472659965 | validation: 5.2331302007093745]
	TIME [epoch: 10.1 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 5.325742950048484		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 5.325742950048484 | validation: 5.2508901507396635]
	TIME [epoch: 10.1 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 5.375905101611552		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 5.375905101611552 | validation: 5.23760105935887]
	TIME [epoch: 10.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 5.723310247522598		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 5.723310247522598 | validation: 5.52075981029245]
	TIME [epoch: 10.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 5.408306515505286		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 5.408306515505286 | validation: 5.19627286508209]
	TIME [epoch: 10.1 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 5.320272201731361		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 5.320272201731361 | validation: 5.146005959658448]
	TIME [epoch: 10.1 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 5.05321926763739		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 5.05321926763739 | validation: 5.423791772676942]
	TIME [epoch: 10.1 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 5.256560250378614		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 5.256560250378614 | validation: 5.54574768401121]
	TIME [epoch: 10.2 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 5.749990876298321		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 5.749990876298321 | validation: 5.075757125594836]
	TIME [epoch: 10.2 sec]
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 4.996653262401977		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 4.996653262401977 | validation: 5.081417746818257]
	TIME [epoch: 10.2 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 5.281040784530924		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 5.281040784530924 | validation: 4.994882494588995]
	TIME [epoch: 10.1 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 4.927214276372149		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 4.927214276372149 | validation: 4.90747232419872]
	TIME [epoch: 10.1 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 4.901505220757597		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 4.901505220757597 | validation: 4.888200134099482]
	TIME [epoch: 10.2 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 4.946433171718967		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 4.946433171718967 | validation: 4.737764105475756]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_115.pth
	Model improved!!!
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 4.891168084374655		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 4.891168084374655 | validation: 4.7494459150175485]
	TIME [epoch: 10.1 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 4.952663448606536		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 4.952663448606536 | validation: 4.749431080097367]
	TIME [epoch: 10.1 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 4.918951742145972		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 4.918951742145972 | validation: 4.511771252144211]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 7.068556778001425		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 7.068556778001425 | validation: 7.995944588925133]
	TIME [epoch: 10.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 7.787764185924454		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 7.787764185924454 | validation: 7.502785806484106]
	TIME [epoch: 10.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 7.393518484050384		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 7.393518484050384 | validation: 6.367734245889222]
	TIME [epoch: 10.1 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 5.90781282723899		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 5.90781282723899 | validation: 5.159046792448601]
	TIME [epoch: 10.2 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 5.042029285566576		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 5.042029285566576 | validation: 5.217889010492091]
	TIME [epoch: 10.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 5.428337257661209		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 5.428337257661209 | validation: 4.831663103128071]
	TIME [epoch: 10.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 4.780686484003515		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 4.780686484003515 | validation: 4.785887013143365]
	TIME [epoch: 10.2 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 4.702700423786069		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 4.702700423786069 | validation: 4.781755392721517]
	TIME [epoch: 10.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 4.986476011257741		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 4.986476011257741 | validation: 4.751960983431856]
	TIME [epoch: 10.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 5.023566150342619		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 5.023566150342619 | validation: 5.16356254787573]
	TIME [epoch: 10.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 4.776223015050811		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 4.776223015050811 | validation: 4.5909844570342]
	TIME [epoch: 10.1 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 4.668372403681028		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 4.668372403681028 | validation: 5.12761262175836]
	TIME [epoch: 10.1 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 5.161005963515917		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 5.161005963515917 | validation: 5.413711098522638]
	TIME [epoch: 10.1 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 4.874232748397415		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 4.874232748397415 | validation: 4.522432882976826]
	TIME [epoch: 10.1 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 5.084347128257813		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 5.084347128257813 | validation: 4.924287300110467]
	TIME [epoch: 10.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 4.81793595176199		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 4.81793595176199 | validation: 4.796357392762602]
	TIME [epoch: 10.1 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 4.998535654684128		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 4.998535654684128 | validation: 4.604567696000442]
	TIME [epoch: 10.1 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 4.612945517000077		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 4.612945517000077 | validation: 4.814966840756588]
	TIME [epoch: 10.2 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 4.732168239015126		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 4.732168239015126 | validation: 4.7407302252423245]
	TIME [epoch: 10.2 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 5.344134369655116		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 5.344134369655116 | validation: 5.383873155234832]
	TIME [epoch: 10.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 4.7449319756975		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 4.7449319756975 | validation: 4.43266763299858]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 4.619831252651227		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 4.619831252651227 | validation: 4.322229849426089]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 4.165954888534566		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 4.165954888534566 | validation: 4.198928458379256]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 4.530443724830092		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 4.530443724830092 | validation: 5.647058875570293]
	TIME [epoch: 10.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 4.692007937224899		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 4.692007937224899 | validation: 4.251976048848004]
	TIME [epoch: 10.1 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 4.045937113949484		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 4.045937113949484 | validation: 4.2448391773115945]
	TIME [epoch: 10.2 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 5.917922632902378		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 5.917922632902378 | validation: 6.4891612601622874]
	TIME [epoch: 10.1 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 5.095799442316112		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 5.095799442316112 | validation: 4.002680776057594]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 4.040315016268027		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 4.040315016268027 | validation: 4.293586482231391]
	TIME [epoch: 10.1 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 4.061516985715843		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 4.061516985715843 | validation: 3.7064062047576]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5800617075267978		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 3.5800617075267978 | validation: 4.107111803558576]
	TIME [epoch: 10.1 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7125403455186685		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 3.7125403455186685 | validation: 4.418255085558516]
	TIME [epoch: 10.1 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 4.05551364171542		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 4.05551364171542 | validation: 3.3518034722204813]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5114843393798125		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 3.5114843393798125 | validation: 3.264360744511041]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 3.500174573666483		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 3.500174573666483 | validation: 3.346205202514629]
	TIME [epoch: 10.1 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2415063332559777		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 3.2415063332559777 | validation: 3.032651296632084]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3377188720119917		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 3.3377188720119917 | validation: 3.2210389708106693]
	TIME [epoch: 10.2 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 3.225941299005251		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 3.225941299005251 | validation: 2.9856418162714715]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 3.656001912962503		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 3.656001912962503 | validation: 3.451774057647605]
	TIME [epoch: 10.1 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 3.126989181672748		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 3.126989181672748 | validation: 2.9059027576520555]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_158.pth
	Model improved!!!
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0829650199317777		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 3.0829650199317777 | validation: 2.9843048382881263]
	TIME [epoch: 10.2 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2213874452454467		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 3.2213874452454467 | validation: 3.0247461439909604]
	TIME [epoch: 10.1 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0353498637397847		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 3.0353498637397847 | validation: 2.8217260840674054]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_161.pth
	Model improved!!!
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0850176895768224		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 3.0850176895768224 | validation: 2.926664857732457]
	TIME [epoch: 10.1 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7903803222179295		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 2.7903803222179295 | validation: 2.513450348207616]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 2.608115507089983		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 2.608115507089983 | validation: 3.0565482837673486]
	TIME [epoch: 10.1 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5259802218934198		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 3.5259802218934198 | validation: 2.699810573076042]
	TIME [epoch: 10.1 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 3.024480101129565		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 3.024480101129565 | validation: 3.5462979065678577]
	TIME [epoch: 10.2 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0714899877252777		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 3.0714899877252777 | validation: 2.7726920641100468]
	TIME [epoch: 10.2 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 2.666633416555904		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 2.666633416555904 | validation: 2.6332604043764265]
	TIME [epoch: 10.1 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 2.789656950140315		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 2.789656950140315 | validation: 2.6952740360748964]
	TIME [epoch: 10.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9557253622722834		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 2.9557253622722834 | validation: 2.521746577884389]
	TIME [epoch: 10.2 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5414322346406877		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 2.5414322346406877 | validation: 2.2675888383957843]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_171.pth
	Model improved!!!
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 2.398674819368293		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 2.398674819368293 | validation: 2.351519580531732]
	TIME [epoch: 10.1 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 2.653927145488227		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 2.653927145488227 | validation: 2.4465344218871805]
	TIME [epoch: 10.2 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 2.123696325401893		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 2.123696325401893 | validation: 1.9260225324600921]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9621124268923424		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 1.9621124268923424 | validation: 2.0492070376668887]
	TIME [epoch: 10.2 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5946649149341368		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 3.5946649149341368 | validation: 6.718866053452346]
	TIME [epoch: 10.2 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 6.025844199215364		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 6.025844199215364 | validation: 5.233545283210029]
	TIME [epoch: 10.2 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 4.72146418860377		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 4.72146418860377 | validation: 2.532191145655129]
	TIME [epoch: 10.2 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 2.178023292715757		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 2.178023292715757 | validation: 2.0322525540688203]
	TIME [epoch: 10.2 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 2.321215171994968		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 2.321215171994968 | validation: 1.9993457549087423]
	TIME [epoch: 10.2 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 2.137947407908753		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 2.137947407908753 | validation: 2.483603973723428]
	TIME [epoch: 10.2 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1031629186218077		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 2.1031629186218077 | validation: 1.9601296399391805]
	TIME [epoch: 10.2 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0979015208836094		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 2.0979015208836094 | validation: 1.792468956100859]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 1.788898414257628		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 1.788898414257628 | validation: 1.8141223156868964]
	TIME [epoch: 10.2 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6613790546190377		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 1.6613790546190377 | validation: 1.7954644684346244]
	TIME [epoch: 10.2 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7509689266090565		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 1.7509689266090565 | validation: 3.1229830644171845]
	TIME [epoch: 10.2 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 2.598070258999205		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 2.598070258999205 | validation: 3.103592981713758]
	TIME [epoch: 10.2 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9682072811972648		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 1.9682072811972648 | validation: 2.249681195431308]
	TIME [epoch: 10.2 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 1.916376541708112		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 1.916376541708112 | validation: 1.7727124918426334]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5465674311976578		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 1.5465674311976578 | validation: 1.5470699180514682]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_190.pth
	Model improved!!!
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6316278082638394		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 1.6316278082638394 | validation: 1.7004916628454407]
	TIME [epoch: 10.1 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6956489657498892		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 1.6956489657498892 | validation: 1.9232349568971023]
	TIME [epoch: 10.2 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5523014952130947		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 1.5523014952130947 | validation: 3.412829421581489]
	TIME [epoch: 10.2 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 2.198985512476267		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 2.198985512476267 | validation: 5.466684122379157]
	TIME [epoch: 10.2 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 6.136201444339341		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 6.136201444339341 | validation: 6.056194043939029]
	TIME [epoch: 10.2 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 5.944540257053705		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 5.944540257053705 | validation: 4.77753598211629]
	TIME [epoch: 10.2 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6983924306209466		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 3.6983924306209466 | validation: 2.0154077686877936]
	TIME [epoch: 10.2 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 2.176940349377827		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 2.176940349377827 | validation: 3.9428946136805543]
	TIME [epoch: 10.2 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5837281771304474		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 2.5837281771304474 | validation: 1.8264863882129365]
	TIME [epoch: 10.2 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 1.672808935117962		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 1.672808935117962 | validation: 1.6294258885725055]
	TIME [epoch: 10.2 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0970515697361263		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 2.0970515697361263 | validation: 2.0723004748714913]
	TIME [epoch: 10.2 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8834042327006497		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 1.8834042327006497 | validation: 1.5684640668241856]
	TIME [epoch: 10.2 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9278052613117302		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 1.9278052613117302 | validation: 1.7198148202510306]
	TIME [epoch: 10.2 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3226248652556842		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 2.3226248652556842 | validation: 2.503176403264412]
	TIME [epoch: 10.2 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9454850313001217		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 1.9454850313001217 | validation: 1.7034900243063242]
	TIME [epoch: 10.2 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 2.008688921508896		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 2.008688921508896 | validation: 1.5691483273524085]
	TIME [epoch: 10.2 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3608172810625256		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 1.3608172810625256 | validation: 3.7905742222049517]
	TIME [epoch: 10.2 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4234427794645446		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 2.4234427794645446 | validation: 1.5932529083918787]
	TIME [epoch: 10.2 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3339173753580367		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 1.3339173753580367 | validation: 1.9001684802826855]
	TIME [epoch: 10.2 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3977272924400104		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 1.3977272924400104 | validation: 1.5410025461240966]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 1.390503210845598		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 1.390503210845598 | validation: 1.4154721901512173]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_211.pth
	Model improved!!!
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2534555576589708		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 1.2534555576589708 | validation: 1.6814708070230153]
	TIME [epoch: 10.1 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2694165626495213		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 1.2694165626495213 | validation: 1.7133669485931513]
	TIME [epoch: 10.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 2.03361068486359		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 2.03361068486359 | validation: 1.711643282581266]
	TIME [epoch: 10.1 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3846433182777862		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 1.3846433182777862 | validation: 1.5216303602175234]
	TIME [epoch: 10.1 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2234509567063456		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 1.2234509567063456 | validation: 1.317673728076141]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1985380696090626		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 1.1985380696090626 | validation: 5.145744155620966]
	TIME [epoch: 10.2 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4350348326363354		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 3.4350348326363354 | validation: 1.318280397959125]
	TIME [epoch: 10.2 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2336859179073265		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 1.2336859179073265 | validation: 1.7549516321745176]
	TIME [epoch: 10.2 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3468873185073378		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 1.3468873185073378 | validation: 2.4335165995938817]
	TIME [epoch: 10.2 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3784166563851548		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 2.3784166563851548 | validation: 2.5049344665438222]
	TIME [epoch: 10.2 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5749318055017043		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 1.5749318055017043 | validation: 1.6096178557268734]
	TIME [epoch: 10.2 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3448053525397516		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 1.3448053525397516 | validation: 1.9453093908956487]
	TIME [epoch: 10.2 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6076525611918207		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 1.6076525611918207 | validation: 1.3608081252724162]
	TIME [epoch: 10.2 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8115313661276133		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 1.8115313661276133 | validation: 1.734198663073592]
	TIME [epoch: 10.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4477522568436854		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 1.4477522568436854 | validation: 1.435855485817056]
	TIME [epoch: 10.2 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2491358135690755		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 1.2491358135690755 | validation: 1.3765410336759936]
	TIME [epoch: 10.2 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 1.960152615554763		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 1.960152615554763 | validation: 2.0416123520331366]
	TIME [epoch: 10.2 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 1.362222299363633		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 1.362222299363633 | validation: 1.3981013345941435]
	TIME [epoch: 10.2 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2441075712442242		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 1.2441075712442242 | validation: 1.7852865142869585]
	TIME [epoch: 10.2 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 1.495988100880575		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 1.495988100880575 | validation: 1.4591549778026671]
	TIME [epoch: 10.1 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6005271732454607		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 1.6005271732454607 | validation: 1.5320393545200315]
	TIME [epoch: 10.1 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4958999085947366		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 1.4958999085947366 | validation: 1.3699622901579784]
	TIME [epoch: 10.1 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1660958844817633		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 1.1660958844817633 | validation: 1.7250749125096507]
	TIME [epoch: 10.1 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0844895764365785		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 1.0844895764365785 | validation: 1.6718330494529547]
	TIME [epoch: 10.1 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0908038591667222		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 1.0908038591667222 | validation: 1.2276521530120779]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_236.pth
	Model improved!!!
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 1.240466971554962		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 1.240466971554962 | validation: 1.8463161166870503]
	TIME [epoch: 10.2 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6480583589128757		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 1.6480583589128757 | validation: 1.7544780690940271]
	TIME [epoch: 10.2 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7212625673908335		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 1.7212625673908335 | validation: 1.943792266274552]
	TIME [epoch: 10.2 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 1.624682964048469		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 1.624682964048469 | validation: 2.5503355102272915]
	TIME [epoch: 10.2 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4269020166178765		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 1.4269020166178765 | validation: 1.9005208398181117]
	TIME [epoch: 10.2 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3653423080508396		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 1.3653423080508396 | validation: 1.2088973487810981]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_242.pth
	Model improved!!!
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1729592147352306		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 1.1729592147352306 | validation: 1.511183138661241]
	TIME [epoch: 10.1 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 1.051522593488842		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 1.051522593488842 | validation: 1.1062823119875755]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_244.pth
	Model improved!!!
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0581144866350556		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 1.0581144866350556 | validation: 1.152567067421945]
	TIME [epoch: 10.1 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3625549989223051		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 1.3625549989223051 | validation: 1.5161492535220595]
	TIME [epoch: 10.1 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0940728503473105		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 1.0940728503473105 | validation: 1.0395648149732732]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_247.pth
	Model improved!!!
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 1.458119043365669		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 1.458119043365669 | validation: 1.6370218269076064]
	TIME [epoch: 10.1 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 1.310437253716702		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 1.310437253716702 | validation: 1.8035160221822342]
	TIME [epoch: 10.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6921189285275986		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 1.6921189285275986 | validation: 1.4845950931496268]
	TIME [epoch: 10.1 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3810029891514186		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 1.3810029891514186 | validation: 1.7318024209576317]
	TIME [epoch: 10.1 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1555557957165554		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 1.1555557957165554 | validation: 1.3018063224658165]
	TIME [epoch: 10.1 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2388167596985593		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 1.2388167596985593 | validation: 1.0092488583207457]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_253.pth
	Model improved!!!
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9835044606884364		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 0.9835044606884364 | validation: 3.406035706903063]
	TIME [epoch: 10.1 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 1.911303811283934		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 1.911303811283934 | validation: 1.1600281549271079]
	TIME [epoch: 10.1 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 0.978169002882936		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 0.978169002882936 | validation: 1.1902198194886433]
	TIME [epoch: 10.1 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1520958372538312		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 1.1520958372538312 | validation: 1.0339192414523741]
	TIME [epoch: 10.1 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2846038982623882		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 1.2846038982623882 | validation: 1.3547743785159616]
	TIME [epoch: 10.1 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3431319242998778		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 1.3431319242998778 | validation: 0.9864870906388977]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_259.pth
	Model improved!!!
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5374283753976747		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 1.5374283753976747 | validation: 1.1835939620822549]
	TIME [epoch: 10.2 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3715166651148656		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 1.3715166651148656 | validation: 1.0726988060308702]
	TIME [epoch: 10.1 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4825433996064943		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 1.4825433996064943 | validation: 1.1835214664340659]
	TIME [epoch: 10.1 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0986558270265132		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 1.0986558270265132 | validation: 0.991873939405437]
	TIME [epoch: 10.1 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9011140709962344		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 0.9011140709962344 | validation: 1.4631923626638876]
	TIME [epoch: 10.1 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 1.425633907649892		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 1.425633907649892 | validation: 1.7397857658000155]
	TIME [epoch: 10.1 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1556730090442353		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 1.1556730090442353 | validation: 1.1264517028638164]
	TIME [epoch: 10.1 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 1.266512322865299		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 1.266512322865299 | validation: 1.5129302548106347]
	TIME [epoch: 10.1 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 2.037344798975146		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 2.037344798975146 | validation: 1.8371938010739297]
	TIME [epoch: 10.1 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 1.241373164088102		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 1.241373164088102 | validation: 1.1148677429428862]
	TIME [epoch: 10.1 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9668476833078288		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 0.9668476833078288 | validation: 1.4056510737738597]
	TIME [epoch: 10.1 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1635481936486989		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 1.1635481936486989 | validation: 1.2702816497168679]
	TIME [epoch: 10.1 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2310288029882064		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 1.2310288029882064 | validation: 1.2437803219650863]
	TIME [epoch: 10.1 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1117097029292715		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 2.1117097029292715 | validation: 1.33927388624351]
	TIME [epoch: 10.1 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1427329066054543		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 1.1427329066054543 | validation: 1.777498687968494]
	TIME [epoch: 10.1 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0574351276550555		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 1.0574351276550555 | validation: 0.9661342769190183]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_275.pth
	Model improved!!!
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8987944268600655		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 0.8987944268600655 | validation: 1.5426184832437821]
	TIME [epoch: 10.1 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 1.523825057116897		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 1.523825057116897 | validation: 1.3217911607703539]
	TIME [epoch: 10.1 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2614567976958688		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 1.2614567976958688 | validation: 1.026154154353762]
	TIME [epoch: 10.1 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0532126704680647		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 1.0532126704680647 | validation: 1.39123286921497]
	TIME [epoch: 10.1 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9759863551656827		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 0.9759863551656827 | validation: 1.17412537875291]
	TIME [epoch: 10.1 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2347379537418033		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 1.2347379537418033 | validation: 1.4234396494774189]
	TIME [epoch: 10.1 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3564165547056366		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 1.3564165547056366 | validation: 1.93790614064525]
	TIME [epoch: 10.1 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0872921417890136		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 1.0872921417890136 | validation: 1.3694154587755223]
	TIME [epoch: 10.1 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8337995116574801		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 0.8337995116574801 | validation: 1.294511904711316]
	TIME [epoch: 10.1 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0460278292522243		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 1.0460278292522243 | validation: 1.323340882884462]
	TIME [epoch: 10.1 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1206263132128806		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 1.1206263132128806 | validation: 1.1268347854631793]
	TIME [epoch: 10.1 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9449382723477212		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 0.9449382723477212 | validation: 1.8476673397144308]
	TIME [epoch: 10.1 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2795946331255597		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 1.2795946331255597 | validation: 3.3740650705750377]
	TIME [epoch: 10.1 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2661835149444896		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 2.2661835149444896 | validation: 1.2200205014029815]
	TIME [epoch: 10.1 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 1.396064231938103		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 1.396064231938103 | validation: 2.1366258731672088]
	TIME [epoch: 10.1 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2586263330139902		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 1.2586263330139902 | validation: 2.1451277568138947]
	TIME [epoch: 10.1 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4680293515105183		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 1.4680293515105183 | validation: 1.2526890982457652]
	TIME [epoch: 10.1 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5992925847768782		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 1.5992925847768782 | validation: 1.3737967823226698]
	TIME [epoch: 10.1 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0603508332750682		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 1.0603508332750682 | validation: 1.0601883309493916]
	TIME [epoch: 10.1 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 1.064593335596728		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 1.064593335596728 | validation: 1.040829037158444]
	TIME [epoch: 10.1 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9089372097908812		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 0.9089372097908812 | validation: 1.0969912498616514]
	TIME [epoch: 10.2 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 1.424112435255663		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 1.424112435255663 | validation: 1.479631827673291]
	TIME [epoch: 10.1 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2934587237344686		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 1.2934587237344686 | validation: 0.9594699433463353]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_298.pth
	Model improved!!!
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7682238551473886		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.7682238551473886 | validation: 0.8848628210236446]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_299.pth
	Model improved!!!
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7160660177129373		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 0.7160660177129373 | validation: 1.648113880129694]
	TIME [epoch: 10.2 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 1.219362869858476		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 1.219362869858476 | validation: 1.5479014336921075]
	TIME [epoch: 10.2 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 1.069382578695971		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 1.069382578695971 | validation: 0.9453803922746484]
	TIME [epoch: 10.1 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8619450731418425		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.8619450731418425 | validation: 1.6966870751495577]
	TIME [epoch: 10.1 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0011572394415844		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 1.0011572394415844 | validation: 0.9207922464498277]
	TIME [epoch: 10.2 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 1.190630725873962		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 1.190630725873962 | validation: 1.4004241528184775]
	TIME [epoch: 10.1 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1832541313684395		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 1.1832541313684395 | validation: 1.217285432362235]
	TIME [epoch: 10.1 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9833729429975776		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 0.9833729429975776 | validation: 1.3069160198542984]
	TIME [epoch: 10.2 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8921360490454671		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 0.8921360490454671 | validation: 1.8324396618771466]
	TIME [epoch: 10.2 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1546652518950151		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 1.1546652518950151 | validation: 0.9400153415143356]
	TIME [epoch: 10.1 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2044542716017044		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 1.2044542716017044 | validation: 1.2080873870140434]
	TIME [epoch: 10.2 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0157007108065408		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 1.0157007108065408 | validation: 0.9905343771854851]
	TIME [epoch: 10.1 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1144487366574538		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 1.1144487366574538 | validation: 0.8426958535190073]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_312.pth
	Model improved!!!
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1078221496366092		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 1.1078221496366092 | validation: 2.2245178099417195]
	TIME [epoch: 10.1 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2567858125336424		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 1.2567858125336424 | validation: 1.3564213465624437]
	TIME [epoch: 10.1 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0340304670736444		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 1.0340304670736444 | validation: 0.937776612398321]
	TIME [epoch: 10.2 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2426695755460968		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 1.2426695755460968 | validation: 1.2020984471244847]
	TIME [epoch: 10.1 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 1.48670966569752		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 1.48670966569752 | validation: 1.4593662564771]
	TIME [epoch: 10.2 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9838433058845015		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 1.9838433058845015 | validation: 4.159408189805218]
	TIME [epoch: 10.1 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1271781256001923		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 2.1271781256001923 | validation: 1.072506686476514]
	TIME [epoch: 10.2 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0303871981994854		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 1.0303871981994854 | validation: 0.8678266648399973]
	TIME [epoch: 10.2 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0403931174933887		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 1.0403931174933887 | validation: 1.4559925112087542]
	TIME [epoch: 10.1 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 1.013169195225186		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 1.013169195225186 | validation: 0.859512997934676]
	TIME [epoch: 10.1 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 1.099407758376432		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 1.099407758376432 | validation: 1.0818070241512703]
	TIME [epoch: 10.2 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9622957529291039		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 0.9622957529291039 | validation: 2.741986392856851]
	TIME [epoch: 10.1 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6339227698627057		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 2.6339227698627057 | validation: 1.0745312123936985]
	TIME [epoch: 10.2 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 1.213350942613982		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 1.213350942613982 | validation: 1.0622255881220892]
	TIME [epoch: 10.2 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.97299836430887		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.97299836430887 | validation: 1.6860126426486852]
	TIME [epoch: 10.1 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2769031287417174		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 1.2769031287417174 | validation: 1.526547833140027]
	TIME [epoch: 10.2 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 1.040732498358881		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 1.040732498358881 | validation: 1.0178820074012516]
	TIME [epoch: 10.1 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7284524462240727		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.7284524462240727 | validation: 1.3147658463653344]
	TIME [epoch: 10.2 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 1.015816157327602		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 1.015816157327602 | validation: 3.421932210962284]
	TIME [epoch: 10.2 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0575564575370384		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 2.0575564575370384 | validation: 1.1974048108134125]
	TIME [epoch: 10.2 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1561126486551014		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 1.1561126486551014 | validation: 2.262482354578787]
	TIME [epoch: 10.2 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 1.430600240075264		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 1.430600240075264 | validation: 0.8011234794531552]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_334.pth
	Model improved!!!
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1515190544135825		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 1.1515190544135825 | validation: 1.022579377288538]
	TIME [epoch: 10.1 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8389009867294952		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.8389009867294952 | validation: 1.2065914444865937]
	TIME [epoch: 10.1 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0952418695727144		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 1.0952418695727144 | validation: 1.4238332882321165]
	TIME [epoch: 10.2 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9227324541683052		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.9227324541683052 | validation: 0.8135883232445476]
	TIME [epoch: 10.2 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8350119271519214		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.8350119271519214 | validation: 0.9754389931994092]
	TIME [epoch: 10.2 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8983934841085702		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.8983934841085702 | validation: 0.9657764334723621]
	TIME [epoch: 10.2 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7563413771576524		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.7563413771576524 | validation: 1.055128480328079]
	TIME [epoch: 10.2 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9720643691384382		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.9720643691384382 | validation: 1.31401085432991]
	TIME [epoch: 10.2 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7866016171157975		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.7866016171157975 | validation: 0.9376386748419837]
	TIME [epoch: 10.2 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9675082767305296		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.9675082767305296 | validation: 1.399503991381035]
	TIME [epoch: 10.2 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8353767703273698		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.8353767703273698 | validation: 1.1116379895745547]
	TIME [epoch: 10.2 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.735555346622467		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.735555346622467 | validation: 0.9280059972936525]
	TIME [epoch: 10.2 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1332626229367568		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 1.1332626229367568 | validation: 0.7757606636072838]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_347.pth
	Model improved!!!
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7075274770866391		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.7075274770866391 | validation: 0.898190392663067]
	TIME [epoch: 10.1 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8297075435194424		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.8297075435194424 | validation: 1.3590550484880848]
	TIME [epoch: 10.2 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7289610677974652		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.7289610677974652 | validation: 0.8410591059298941]
	TIME [epoch: 10.2 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7791714216809991		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.7791714216809991 | validation: 0.9224076401249609]
	TIME [epoch: 10.1 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7949059438634531		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.7949059438634531 | validation: 0.8084263595203608]
	TIME [epoch: 10.2 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7013980712103036		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.7013980712103036 | validation: 0.8494536148611627]
	TIME [epoch: 10.2 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7421646821724972		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.7421646821724972 | validation: 0.6190398551682017]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_354.pth
	Model improved!!!
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6956523646493651		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.6956523646493651 | validation: 0.8572147168323662]
	TIME [epoch: 10.2 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8704938463688011		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.8704938463688011 | validation: 1.0067892380297825]
	TIME [epoch: 10.2 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7343743838604244		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.7343743838604244 | validation: 1.0696415126543268]
	TIME [epoch: 10.2 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7269010705844812		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.7269010705844812 | validation: 0.7753938681724468]
	TIME [epoch: 10.2 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.767868804053536		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.767868804053536 | validation: 1.0974074755569034]
	TIME [epoch: 10.2 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7294223792939567		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.7294223792939567 | validation: 0.9649040721640054]
	TIME [epoch: 10.2 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7766985260765669		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.7766985260765669 | validation: 1.4319445490479894]
	TIME [epoch: 10.2 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7094444420229931		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.7094444420229931 | validation: 0.725469534735875]
	TIME [epoch: 10.2 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6133716009837614		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.6133716009837614 | validation: 0.589779300910537]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_363.pth
	Model improved!!!
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8628565345598508		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.8628565345598508 | validation: 0.7436030320883456]
	TIME [epoch: 10.1 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6353368447866293		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.6353368447866293 | validation: 0.7930479098180357]
	TIME [epoch: 10.1 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7087100062988492		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.7087100062988492 | validation: 0.7410228666940941]
	TIME [epoch: 10.2 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7284524321881981		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.7284524321881981 | validation: 1.0441382506951014]
	TIME [epoch: 10.2 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7431305835924795		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.7431305835924795 | validation: 0.821210195841584]
	TIME [epoch: 10.2 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6225873621458821		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.6225873621458821 | validation: 1.033314807018283]
	TIME [epoch: 10.1 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6175371754320282		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.6175371754320282 | validation: 0.7490172071504402]
	TIME [epoch: 10.2 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6298225865253476		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.6298225865253476 | validation: 0.8682754296719324]
	TIME [epoch: 10.2 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6782563130572538		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.6782563130572538 | validation: 0.7001627027825421]
	TIME [epoch: 10.2 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5043080250899501		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.5043080250899501 | validation: 0.6528980774730969]
	TIME [epoch: 10.2 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8607724160424759		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.8607724160424759 | validation: 0.6651194768943379]
	TIME [epoch: 10.2 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7164116062544992		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.7164116062544992 | validation: 0.8403688946093627]
	TIME [epoch: 10.1 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7155780307227848		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.7155780307227848 | validation: 1.0237782324475893]
	TIME [epoch: 10.2 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7599164356472234		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.7599164356472234 | validation: 0.7066468909630755]
	TIME [epoch: 10.2 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7084297243465881		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.7084297243465881 | validation: 1.0956064525807345]
	TIME [epoch: 10.2 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8649230911807464		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.8649230911807464 | validation: 0.703133665744436]
	TIME [epoch: 10.2 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6533620583152517		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.6533620583152517 | validation: 0.8578803593618736]
	TIME [epoch: 10.1 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9852455631507432		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.9852455631507432 | validation: 0.8145207173062332]
	TIME [epoch: 10.2 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6321409263744695		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.6321409263744695 | validation: 1.3335921460918638]
	TIME [epoch: 10.2 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9701220320327864		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.9701220320327864 | validation: 0.975973258537294]
	TIME [epoch: 10.2 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9478734390652175		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.9478734390652175 | validation: 0.9735469537149598]
	TIME [epoch: 10.1 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1675632345575446		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 1.1675632345575446 | validation: 0.7151977623820583]
	TIME [epoch: 10.1 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7784031456126975		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.7784031456126975 | validation: 0.7499509882727972]
	TIME [epoch: 10.2 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 1.011380226300174		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 1.011380226300174 | validation: 1.0261405187743196]
	TIME [epoch: 10.1 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5978093866614439		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.5978093866614439 | validation: 1.0446127154260976]
	TIME [epoch: 10.2 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6418497987961773		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.6418497987961773 | validation: 0.8007386635349174]
	TIME [epoch: 10.1 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5590364768514122		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.5590364768514122 | validation: 1.362560043488548]
	TIME [epoch: 10.2 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9563242687771002		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.9563242687771002 | validation: 0.7808750905637374]
	TIME [epoch: 10.1 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6142911662634811		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.6142911662634811 | validation: 1.0478568999587503]
	TIME [epoch: 10.2 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7753187139053912		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.7753187139053912 | validation: 0.8038452638533705]
	TIME [epoch: 10.1 sec]
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5252770982803913		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.5252770982803913 | validation: 0.9680308824710585]
	TIME [epoch: 10.2 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7624237367131392		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.7624237367131392 | validation: 0.6615457016749611]
	TIME [epoch: 10.1 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6536812802084099		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.6536812802084099 | validation: 0.5788432498047883]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_396.pth
	Model improved!!!
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6808452220083717		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.6808452220083717 | validation: 1.25745536229949]
	TIME [epoch: 10.2 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6467076567461335		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.6467076567461335 | validation: 0.8757853996542707]
	TIME [epoch: 10.1 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7554259798633302		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.7554259798633302 | validation: 0.9975640186388895]
	TIME [epoch: 10.2 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6173115325290942		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.6173115325290942 | validation: 0.6631103242888725]
	TIME [epoch: 10.2 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5300643940598866		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.5300643940598866 | validation: 1.0800221855161065]
	TIME [epoch: 10.2 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6110853273220617		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.6110853273220617 | validation: 0.7560405522966993]
	TIME [epoch: 10.2 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6910919011417246		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.6910919011417246 | validation: 0.734201186217769]
	TIME [epoch: 10.2 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.659679424133266		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.659679424133266 | validation: 1.029275946067994]
	TIME [epoch: 10.2 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.506466779981993		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.506466779981993 | validation: 1.1081802506803167]
	TIME [epoch: 10.2 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7509907033640401		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.7509907033640401 | validation: 1.0525363674025883]
	TIME [epoch: 10.2 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0546205830295419		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 1.0546205830295419 | validation: 0.7689119677981908]
	TIME [epoch: 10.2 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7612671260391102		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.7612671260391102 | validation: 1.5688541473903366]
	TIME [epoch: 10.2 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7373675465340023		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.7373675465340023 | validation: 0.6245830534764322]
	TIME [epoch: 10.2 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6153229201328949		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.6153229201328949 | validation: 1.3044253890361222]
	TIME [epoch: 10.2 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5584589616350688		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 1.5584589616350688 | validation: 1.0882179945593282]
	TIME [epoch: 10.2 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7964708202506949		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.7964708202506949 | validation: 0.8461192022992592]
	TIME [epoch: 10.2 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.616878308738111		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.616878308738111 | validation: 0.764080327579945]
	TIME [epoch: 10.1 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5284995774486541		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.5284995774486541 | validation: 0.9171674883807084]
	TIME [epoch: 10.2 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7549383884754669		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.7549383884754669 | validation: 0.5512856344108035]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_415.pth
	Model improved!!!
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5049582390251766		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.5049582390251766 | validation: 1.4428695768200681]
	TIME [epoch: 10.2 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8858044743240056		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.8858044743240056 | validation: 0.7038517037547747]
	TIME [epoch: 10.2 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6672756917064664		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.6672756917064664 | validation: 0.5772821207848452]
	TIME [epoch: 10.2 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4287260865405315		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.4287260865405315 | validation: 0.7232544054093569]
	TIME [epoch: 10.2 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.631406359949503		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.631406359949503 | validation: 1.045077955463922]
	TIME [epoch: 10.2 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9181301484353239		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.9181301484353239 | validation: 0.5838304771566654]
	TIME [epoch: 10.2 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5197377307535855		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.5197377307535855 | validation: 0.5593965193217779]
	TIME [epoch: 10.2 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4731719713746719		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.4731719713746719 | validation: 0.5702857950358111]
	TIME [epoch: 10.2 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4826093676537996		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.4826093676537996 | validation: 0.6332591138224405]
	TIME [epoch: 10.2 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7551197667486607		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.7551197667486607 | validation: 0.6841045399090038]
	TIME [epoch: 10.2 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.460890493409394		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.460890493409394 | validation: 0.5245916365173854]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_426.pth
	Model improved!!!
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5288274078105126		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.5288274078105126 | validation: 0.6311268829198768]
	TIME [epoch: 10.2 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 1.37348990165308		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 1.37348990165308 | validation: 0.8307493553241981]
	TIME [epoch: 10.2 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 1.201273770540141		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 1.201273770540141 | validation: 0.6188985859197814]
	TIME [epoch: 10.2 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5071138683663224		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.5071138683663224 | validation: 0.9592231307953881]
	TIME [epoch: 10.2 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5239633867584459		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.5239633867584459 | validation: 1.1289539785880265]
	TIME [epoch: 10.2 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6191481105615405		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.6191481105615405 | validation: 0.6410831353275197]
	TIME [epoch: 10.2 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.501774069773424		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.501774069773424 | validation: 0.6354603895338764]
	TIME [epoch: 10.2 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46967456443164723		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.46967456443164723 | validation: 0.882491610220917]
	TIME [epoch: 10.2 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8065901977219099		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.8065901977219099 | validation: 0.6830968648084274]
	TIME [epoch: 10.2 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5625685907744098		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.5625685907744098 | validation: 0.994198858794877]
	TIME [epoch: 10.2 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5255062856667118		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.5255062856667118 | validation: 0.702413913572046]
	TIME [epoch: 10.1 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47513530304203994		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.47513530304203994 | validation: 0.801571738785193]
	TIME [epoch: 10.2 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6501270779452077		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 0.6501270779452077 | validation: 0.9556210520124837]
	TIME [epoch: 10.2 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5509686802346367		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.5509686802346367 | validation: 1.2995781964180566]
	TIME [epoch: 10.2 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8643117001935522		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.8643117001935522 | validation: 0.8299600943714469]
	TIME [epoch: 10.2 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5631953317543469		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.5631953317543469 | validation: 0.49914990084336697]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_442.pth
	Model improved!!!
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4181075719669449		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.4181075719669449 | validation: 0.6112695111748107]
	TIME [epoch: 10.1 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4958372582313773		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.4958372582313773 | validation: 0.5198071528301736]
	TIME [epoch: 10.2 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5713023088653834		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.5713023088653834 | validation: 0.5682547399447148]
	TIME [epoch: 10.2 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4797580523073185		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.4797580523073185 | validation: 0.7037973064758923]
	TIME [epoch: 10.2 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6324644168886724		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.6324644168886724 | validation: 0.7165619655482729]
	TIME [epoch: 10.2 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6045083037398208		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.6045083037398208 | validation: 0.43727674355963353]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_448.pth
	Model improved!!!
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4944762609247889		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.4944762609247889 | validation: 0.7350638474602917]
	TIME [epoch: 10.2 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6869357216354846		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.6869357216354846 | validation: 0.4478078472265558]
	TIME [epoch: 10.2 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44354332573745536		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.44354332573745536 | validation: 0.544741967670381]
	TIME [epoch: 10.2 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3897204892690658		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.3897204892690658 | validation: 0.4720004843662306]
	TIME [epoch: 10.2 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.432281274082681		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.432281274082681 | validation: 0.5335229934045088]
	TIME [epoch: 10.2 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6367671388996751		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.6367671388996751 | validation: 0.5691218009948059]
	TIME [epoch: 10.2 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45753039571552057		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.45753039571552057 | validation: 0.5974428247181868]
	TIME [epoch: 10.2 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7826894398766662		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.7826894398766662 | validation: 0.8478701963918123]
	TIME [epoch: 10.2 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4108047450340101		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.4108047450340101 | validation: 0.8826484126737023]
	TIME [epoch: 10.2 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5729872379525431		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.5729872379525431 | validation: 1.087600885684242]
	TIME [epoch: 10.2 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.497409922209877		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.497409922209877 | validation: 1.079803133865342]
	TIME [epoch: 10.2 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.601447526608783		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.601447526608783 | validation: 0.8424337831765693]
	TIME [epoch: 10.2 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5248395013099232		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.5248395013099232 | validation: 0.43199750026662254]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_461.pth
	Model improved!!!
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4738687749372425		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.4738687749372425 | validation: 0.631501676108332]
	TIME [epoch: 10.2 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7682168705089307		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.7682168705089307 | validation: 0.5898081138732728]
	TIME [epoch: 10.2 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3717712419332898		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.3717712419332898 | validation: 0.5467774449526103]
	TIME [epoch: 10.2 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5084394327327375		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.5084394327327375 | validation: 0.5297914930610682]
	TIME [epoch: 10.2 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7417065828828301		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.7417065828828301 | validation: 1.3813542363525897]
	TIME [epoch: 10.2 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.764901419419217		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.764901419419217 | validation: 0.3972326458428087]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240214_234940/states/model_tr_study5_467.pth
	Model improved!!!
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48429884449490207		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.48429884449490207 | validation: 0.8708539859857866]
	TIME [epoch: 10.2 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6000942312649314		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.6000942312649314 | validation: 0.8409998094893956]
	TIME [epoch: 10.2 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5584252037956456		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.5584252037956456 | validation: 0.45166053701676667]
	TIME [epoch: 10.2 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5764990723673526		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.5764990723673526 | validation: 0.5385530317047841]
	TIME [epoch: 10.2 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6821614697312385		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.6821614697312385 | validation: 0.4635033548253377]
	TIME [epoch: 10.2 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5045900540220931		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.5045900540220931 | validation: 0.44115423974368806]
	TIME [epoch: 10.2 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.39742258739492986		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.39742258739492986 | validation: 0.5829934908092542]
	TIME [epoch: 10.2 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5820763584359778		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.5820763584359778 | validation: 0.5082914540797764]
	TIME [epoch: 10.2 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.406285052282108		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.406285052282108 | validation: 0.5603227655341406]
	TIME [epoch: 10.2 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43794807327878027		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.43794807327878027 | validation: 0.7930244042624369]
	TIME [epoch: 10.2 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49462283318188593		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.49462283318188593 | validation: 0.4819418285209845]
	TIME [epoch: 10.2 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.518661215689073		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.518661215689073 | validation: 0.8428711064011805]
	TIME [epoch: 10.1 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5471563710530973		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.5471563710530973 | validation: 0.6540482884548118]
	TIME [epoch: 10.1 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4019039575157315		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.4019039575157315 | validation: 0.6393050671146396]
	TIME [epoch: 10.1 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5712795323329136		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.5712795323329136 | validation: 0.5562800945068003]
	TIME [epoch: 10.2 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4640023696369317		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.4640023696369317 | validation: 0.7682742988201805]
	TIME [epoch: 10.2 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6269621926777481		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.6269621926777481 | validation: 0.6967266880504187]
	TIME [epoch: 10.2 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5960799870077504		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.5960799870077504 | validation: 0.4799202830517558]
	TIME [epoch: 10.2 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5285360750598833		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.5285360750598833 | validation: 0.5386905504794333]
	TIME [epoch: 10.2 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5024564582143972		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.5024564582143972 | validation: 0.6969736314951541]
	TIME [epoch: 10.1 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7205967477931138		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.7205967477931138 | validation: 0.5701625991828436]
	TIME [epoch: 10.2 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6441708286789678		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.6441708286789678 | validation: 0.7707473400255698]
	TIME [epoch: 10.2 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5496592112636122		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.5496592112636122 | validation: 0.9823779919845186]
	TIME [epoch: 10.2 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7466379632210136		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.7466379632210136 | validation: 0.5996277605112907]
	TIME [epoch: 10.2 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4444557555035993		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.4444557555035993 | validation: 0.43558527617001846]
	TIME [epoch: 10.1 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5788614227593458		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.5788614227593458 | validation: 0.4925043466116069]
	TIME [epoch: 10.2 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5684904238038954		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.5684904238038954 | validation: 0.5676613109651301]
	TIME [epoch: 10.1 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5061330040179635		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.5061330040179635 | validation: 0.48131604289324914]
	TIME [epoch: 10.2 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.41900683507582404		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.41900683507582404 | validation: 0.7512359109857218]
	TIME [epoch: 10.1 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5671833546730061		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.5671833546730061 | validation: 0.6309427042783796]
	TIME [epoch: 10.2 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49369471761902817		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.49369471761902817 | validation: 0.6551490412612816]
	TIME [epoch: 10.2 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4806564383582933		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.4806564383582933 | validation: 0.5492943448927047]
	TIME [epoch: 10.2 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46062981225643773		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.46062981225643773 | validation: 0.7313869919100654]
	TIME [epoch: 10.2 sec]
Finished training in 5142.236 seconds.
